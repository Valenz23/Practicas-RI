Authors,Title,Year,Source title,Cited by,Link,Abstract,Author Keywords,Index Keywords,EID
"Guido R.C.","A tutorial review on entropy-based handcrafted feature extraction for information fusion",2018,"Information Fusion",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029359276&doi=10.1016%2fj.inffus.2017.09.006&partnerID=40&md5=28f24a1a0908162013b72bee742c7173","Entropy (H) is the main subject of this article, concisely written to serve as a tutorial introducing two feature extraction (FE) methods for usage in digital signal processing (DSP) and pattern recognition (PR). The theory, carefully exposed, is supplemented with numerical cases, augmented with C/C++ source-codes and enriched with example applications on restricted-vocabulary speech recognition and image synthesis. Complementarily and as innovatively shown, the ordinary calculation of H corresponds to the outcome of a partially pre-tuned deep neural network architecture which fuses important information, bringing a cutting-edge point-of-view for both DSP and PR communities. © 2017 Elsevier B.V.","Deep networks; Entropy; Handcrafted feature extraction; Image synthesis; Information fusion; Restricted-vocabulary speech recognition","C (programming language); Deep neural networks; Digital signal processing; Entropy; Extraction; Feature extraction; Image processing; Information fusion; Network architecture; Pattern recognition; Signal processing; Cutting edges; Digital signal processing (DSP); Entropy-based; Image synthesis; Source codes; Speech recognition",2-s2.0-85029359276
"Bulinski Z., Szczygiel I., Kabaj A., Krysinski T., Gladysz P., Czarnowska L., Stanek W.","Performance Analysis of the Small-Scale α-Type Stirling Engine Using Computational Fluid Dynamics Tools",2018,"Journal of Energy Resources Technology, Transactions of the ASME",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030330957&doi=10.1115%2f1.4037810&partnerID=40&md5=c3f40ebbc8336a776c2f9b97a0a00e4d","This paper presents the computational fluid dynamics (CFD) model of small-scale α-type Stirling engine. The developed mathematical model comprises of unsteady Reynolds averaged Navier-Stokes set of equations, i.e., continuity, momentum, and energy equations; turbulence was modeled using standard κ-ω model. Moreover, presented numerical model covers all modes of heat transfer inside the engine: conduction, convection, and radiation. The model was built in the framework of the commercial CFD software ANSYS fluent. Piston movements were modeled using dynamic mesh capability in ANSYS fluent; their movement kinematics was described based on the crankshaft geometry and it was implemented in the model using user-defined functions written in C programming language and compiled with a core of the ANSYS fluent software. The developed numerical model was used to assess the performance of the analyzed Stirling engine. For this purpose, different performance measures were defined, including coefficient of performance (COP), exergy efficiency, and irreversibility factor. The proposed measures were applied to evaluate the influence of different heating strategies of the small-scale α-type Stirling engine. © 2018 by ASME.",,"C (programming language); Computational fluid dynamics; Crankshafts; Engines; Fluid dynamics; Heat transfer; Numerical models; Stirling engines; Coefficient of Performance; Computational fluid dynamics modeling; Exergy efficiencies; Movement kinematics; Performance analysis; Performance measure; Unsteady reynolds-averaged navier-stokes; User Defined Functions; Navier Stokes equations",2-s2.0-85030330957
"Vatankhah H., Taherian A.R., Ramaswamy H.S.","High-pressure induced thermo-viscoelasticity and dynamic rheology of gum Arabic and chitosan aqueous dispersions",2018,"LWT - Food Science and Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032721054&doi=10.1016%2fj.lwt.2017.10.059&partnerID=40&md5=588913d7089423c563829c70eac18947","Effect of high pressure treatment (200 MPa, 400 MPa, 600 MPa) on rheological properties of aqueous dispersions of gum Arabic (6 g/100 g, 15 g/100 g, and 20 g/100 g) and chitosan (2 g/100 g, 4 g/100 g) was studied. Dynamic properties were assessed using an angular frequency range of 1–25 rad s−1. Flow properties were measured by applying a programmed shear rate of 0.1–100 s−1 for 10 min (upward) and 100–0.1 s−1 for the next 10 min (downward). A power law shift function was used to describe the deviations from the Cox-Merz theory in all samples. Thermo-viscoelasticity was evaluated using a programmed heat/hold/cool cycle (22 °C/70 °C/20 °C). Two term-exponential and a Gaussian model well fitted the thermo-viscoelastic behavior of both gums. The thermal compatibility, regarding a logarithmic phase shift of loss tangent ratios, was also studied. Results showed higher incompatibilities at lower temperatures, while the shift phases tended to zero at higher temperatures. Overall, HP treatment intensified the existence of a stronger and temperature sensitive hydrocolloid network for 4 g/100 g chitosan and 20 g/100 g GA. The highest incompatibility was seen in 20 g/100 g gum Arabic which was a 1–1.5 order of magnitude. © 2017 Elsevier Ltd","Consistency; Hydrocolloids; Modeling; Power-law; Viscosity","Adhesives; Chitin; Chitosan; Colloids; Dispersions; High pressure effects; Models; Shear flow; Viscoelasticity; Viscosity; Consistency; Effect of high pressure; Hydrocolloids; Power-law; Rheological property; Temperature sensitive; Thermal compatibility; Thermoviscoelasticity; C (programming language)",2-s2.0-85032721054
"Benáček P., Puš V., Kubátová H., Čejka T.","P4-To-VHDL: Automatic generation of high-speed input and output network blocks",2018,"Microprocessors and Microsystems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032722803&doi=10.1016%2fj.micpro.2017.10.012&partnerID=40&md5=6e9f6dec0a2327de25ce736c3877aba4","High-performance embedded architectures typically contain many stand-alone blocks which communicate and exchange data; additionally a high-speed network interface is usually needed at the boundary of the system. The software-based data processing is typically slow which leads to a need for hardware accelerated approaches. The problem is getting harder if the supported protocol stack is rapidly changing. Such problem can be effectively solved by the Field Programmable Gate Arrays and high-level synthesis which together provide a high degree of generality. This approach has several advantages like fast development or possibility to enable the area of packet-oriented communication to domain oriented experts. However, the typical disadvantage of this approach is the insufficient performance of generated system from a high-level description. This can be a serious problem in the case of a system which is required to process data at high packet rates. This work presents a generator of high-speed input (Parser) and output (Deparser) network blocks from the P4 language which is designed for the description of modern packet processing devices. The tool converts a P4 description to a synthesizable VHDL code suitable for the FPGA implementation. We present design, analysis and experimental results of our generator. Our results show that the generated circuits are able to process 100 Gbps traffic with fairly complex protocol structure at line rate on Xilinx Virtex-7 XCVH580T FPGA. The approach can be used not only in networking devices but also in other applications like packet processing engines in embedded cores because the P4 language is device and protocol independent. © 2017 Elsevier B.V.","100 Gbps; Deparser; FPGA; High-level language; P4; Parser","Computational linguistics; Computer programming languages; Data handling; Field programmable gate arrays (FPGA); High level languages; High level synthesis; HIgh speed networks; Interfaces (computer); Logic Synthesis; 100 Gbps; Automatic Generation; Deparser; Embedded architecture; Hardware-accelerated; High level description; Packet processing engines; Parser; Computer hardware description languages",2-s2.0-85032722803
"Xu Y., Shan S., Qiu Z., Jia Z., Shen Z., Wang Y., Shi M., Chang E.I.-C.","End-to-end subtitle detection and recognition for videos in East Asian languages via CNN ensemble",2018,"Signal Processing: Image Communication",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032028544&doi=10.1016%2fj.image.2017.09.013&partnerID=40&md5=798dd9d57cddd283cd33cac91ce2dda0","In this paper, we propose an innovative end-to-end subtitle detection and recognition system for videos in East Asian languages. Our end-to-end system consists of multiple stages. Subtitles are firstly detected by a novel image operator based on the sequence information of consecutive video frames. Then, an ensemble of Convolutional Neural Networks (CNNs) trained on synthetic data is adopted for detecting and recognizing East Asian characters. Finally, a dynamic programming approach leveraging language models is applied to constitute results of the entire body of text lines. The proposed system achieves average end-to-end accuracies of 98.2% and 98.3% on 40 videos in Simplified Chinese and 40 videos in Traditional Chinese respectively, which is a significant outperformance of other existing methods. The near-perfect accuracy of our system dramatically narrows the gap between human cognitive ability and state-of-the-art algorithms used for such a task. © 2017 Elsevier B.V.","Convolutional neural networks; East Asian language; Subtitle text detection; Subtitle text recognition; Synthetic training data; Video sequence information","Convolution; Dynamic programming; Neural networks; Asian languages; Convolutional neural network; Synthetic training data; Text detection; Text recognition; Video sequences; Character recognition",2-s2.0-85032028544
"An C.-C., Hsu H.-Y., Sun Y.-T., Ke L.-D., Hsu T.-G., Ting C.-C.","Developing an audio analyzer for instantaneous stroke position identification on table tennis racket to assist technical training",2018,"Measurement: Journal of the International Measurement Confederation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031742335&doi=10.1016%2fj.measurement.2017.10.028&partnerID=40&md5=d7c3aa6c990c92ba6911efb9ff8be191","This study has successfully developed an audio analyzer system to identify the stroke position on table tennis racket instantaneously, which can effectively help the technical training. It's well known, a good stroke is often determined by the exact stroke position on table tennis racket during the play. Therefore, instantaneous identification of the stroke position on table tennis racket during play can provide good adjusting reference of action and effectively help the technical training. In this research, this developed audio analyzer consists of a microphone and the analysing program with fast Fourier transform (FFT) using LabVIEW software. The face of table tennis racket is divided into four blocks which are the center, the left-of-center, the right-of-center, and the trail. The stroke sound generated between table tennis racket and ball during play is captured by the microphone and synchronously analyzed through FFT to determine the principal frequency, where the different stroke position on the table tennis racket yields different principal frequency. The results of calibration show that every table tennis racket has three characteristic principal frequencies on the four blocks, which can distinguish center, right/left, and trail respectively. The positional verification rate of the center position identification is all higher than 90% even up to 100% which can assist technical training. © 2017 Elsevier Ltd","Audio analyzer; Fast Fourier transform; Principal frequency; Stroke position; Table tennis","Computer programming languages; Fast Fourier transforms; Microphones; Sporting goods; Technical presentations; Audio analyzers; Lab-view softwares; Position identification; Principal frequency; Stroke position; Table tennis racket; Table-tennis; Technical training; Sports",2-s2.0-85031742335
"Herajy M., Liu F., Heiner M.","Efficient modelling of yeast cell cycles based on multisite phosphorylation using coloured hybrid Petri nets with marking-dependent arc weights",2018,"Nonlinear Analysis: Hybrid Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030871546&doi=10.1016%2fj.nahs.2017.09.002&partnerID=40&md5=9661a2f3ff6adaf70eb1d9242971f599","With the increasing interest in systems biology to investigate the dynamics and behaviour of biological reaction networks, the scales as well as the complexities of the models under study grew rapidly and continue to grow at even faster pace. Traditional single-scale simulation methods become more and more impractical and inefficient to study these complex reaction networks. A daunting example of biological systems that falls into this category is the cell cycle regulation. In order to accurately model repeated cell growth and division, the corresponding reaction network should exhibit some sort of nonlinearity. One of the techniques able to reproduce this nonlinear behaviour is to include a series of phosphorylation and dephosphorylation reactions of the regulating proteins. However, this modelling approach results in two main challenges: the existence of components with different abundance of molecules and substantially larger biochemical networks in terms of number of reactions and species, with many of them exposing equivalent structure and behaviour. In this paper, we address these two issues by exploiting the modelling power of coloured hybrid Petri nets (HPNC). HPNC are a hybrid Petri net class that combines stochastic and deterministic events over a continuous time scale at the coloured level. Moreover, motivated by this case study we extend HPNC to include marking-dependent arc weights instead of just having constant values to define such weights. © 2017 Elsevier Ltd","Cell cycle regulation; Coloured hybrid Petri nets; Hybrid simulation; Marking-dependent arc weights; Multisite phosphorylation","Cells; Continuous time systems; Cytology; Petri nets; Phosphorylation; Stochastic systems; Cell cycle regulation; Dependent arc; Hybrid Petri net; Hybrid simulation; Multi-site; C (programming language)",2-s2.0-85030871546
"Huang H., Yao W., Li R., Ali A., Du J., Guo D., Xiao R., Guo Z., Zhang Z., Awasthi M.K.","Effect of pyrolysis temperature on chemical form, behavior and environmental risk of Zn, Pb and Cd in biochar produced from phytoremediation residue",2018,"Bioresource Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031905036&doi=10.1016%2fj.biortech.2017.10.020&partnerID=40&md5=176ffeafee9c560b9bb10a4991aedc80","This study aimed to evaluate the chemical forms, behavior and environmental risk of heavy metal (HMs) Zn, Pb and Cd in phytoremediation residue (PMR) pyrolyzed at 350 °C, 550 °C and 750 °C, respectively. The behavior of HMs variation during the PMR pyrolysis process was analyzed and the potential HMs environmental risk of phytoremediation residue biochars (PMB) was assessed which was seldom investigated before. The results showed that the pyrolysis temperature increase decreased the soluble/exchangeable HMs fraction and alleviated the HMs bioavailability. When the temperature was over 550 °C, the adsorbed Zn(II), Pb(II) and Cd(II) were turned into oxides forms and concentrated in PMB with more stable forms exhibiting lower risk assessment code and potential ecological risk index. The ecotoxicity test showed higher pyrolysis temperature favored the reduction of PMB ecotoxicity. It is suggested that pyrolysis temperature above 550 °C may be suitable for thermal treatment of PMR with acceptable environmental risk. © 2017 Elsevier Ltd","Biochar; Ecotoxicity; Heavy metals; Phytoremediation residue; Risk evaluation","Biochemistry; Bioremediation; Cadmium; Cadmium compounds; Cracking (chemical); Heavy metals; Lead; Lead compounds; Pyrolysis; Risk assessment; Zinc; Zinc compounds; Bio chars; Ecotoxicity; Environmental risks; Phytoremediation; Potential ecological risk; Pyrolysis temperature; Risk assessment code; Risk evaluation; C (programming language); cadmium; lead; zinc; biogenic material; cadmium; ecotoxicology; environmental risk; heavy metal; lead; phytoremediation; pyrolysis; risk assessment; temperature; zinc; Article; Brassica juncea; Chinese cabbage; controlled study; ecotoxicity; electric conductivity; environmental impact; environmental temperature; germination; infrared spectrometry; leaching; nonhuman; pH; physical chemistry; phytoremediation; phytoremediation residue; priority journal; pyrolysis; risk assessment; scanning electron microscopy; surface property; X ray diffraction",2-s2.0-85031905036
"Kermani N.A., Petrushina I., Nikiforov A., Rokni M.","Metal alloys for the new generation of compressors at hydrogen stations: Parametric study of corrosion behavior",2018,"Renewable Energy",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031715629&doi=10.1016%2fj.renene.2017.08.066&partnerID=40&md5=62dae5a651fd338d82105fd3b053218d","Compressors are one of the most costly components at hydrogen stations, which leads to the high price of hydrogen production. The substitution of a solid piston with ionic liquid is a promising option that may solve some of the challenges related to conventional reciprocating compressors and, consequently, significantly reduce the final cost of hydrogen production. The correct choice of ionic liquid and construction materials is critical for avoiding significant corrosion problems. Hence, the objective of this study is to evaluate the compatibility of various austenitic stainless steels and nickel-based alloys as construction materials in contact with 80 °C ionic liquids in an ionic liquid hydrogen compressor, considering the role of parameters such as the temperature, viscosity, ionic liquid cation and anion, and water absorption. The results show that temperature contributes to increasing the corrosion rate. However, even at 80 °C, the very low corrosion current densities proved that all of the tested alloys are safe to use as construction materials. AISI 347 showed very high corrosion resistance in all of the ionic liquids. The highest corrosion resistance among all of the tested alloys was observed in trihexyltetradecylphosphonium bis (trifluoromethylsulfonyl) imide, which had a relatively high viscosity and the lowest water content. © 2017 Elsevier Ltd","Corrosion resistance; Gravimetric method; Hydraulic and pneumatic industry; Hydrogen; Ionic liquids; Tafel plots","Alloy steel; Austenitic stainless steel; C (programming language); Compressibility of liquids; Compressors; Corrosion; Corrosion rate; Corrosion resistance; Corrosion resistant alloys; Hydrogen; Hydrogen production; Liquefied gases; Liquids; Nickel alloys; Reciprocating compressors; Viscosity; Water absorption; Water content; Corrosion behavior; Corrosion current densities; Corrosion problems; Gravimetric methods; Nickel based alloy; Parametric study; Tafel plots; Trihexyltetradecylphosphonium; Ionic liquids; alloy; analytical method; anion; cation; construction material; corrosion; gravimetry; hydraulics; hydrogen; ionic liquid; parameterization; temperature; viscosity",2-s2.0-85031715629
"Pirouzi S., Aghaei J., Vahidinasab V., Niknam T., Khodaei A.","Robust linear architecture for active/reactive power scheduling of EV integrated smart distribution networks",2018,"Electric Power Systems Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030084552&doi=10.1016%2fj.epsr.2017.09.021&partnerID=40&md5=c61de4af03e6ee53b10a569e61623d6c","This paper develops a robust bundled active and reactive power management of EV integrated smart distribution networks. To model the problem, at first, the deterministic formulation of the problem is expressed as a non-linear programing (NLP), which minimizes the difference between the energy cost and the revenue of EVs’ (parking lot's) reactive power exchange with the network as the objective function, subject to the AC power flow equations, system operation limits and EVs’ characteristics as the problem constraints. Then, while the NLP optimization reveals local optima, the NLP model is converted into a linear programming (LP) model using linearized AC power flow equations. The system uncertainties including active and reactive loads, electrical energy and reactive power prices as well as EVs’ charging/discharging schedules are modeled in the proposed linear model. Accordingly, the robust model is implemented and it considers one scenario, namely the most-conservative scenario of the objective function in the main problem. To decrease the calculation time, Benders decomposition (BD) approach is used to speed up the total processing time. The proposed robust linear architecture is tested on three distribution test networks to demonstrate its efficiency and performance. The results show that the NLP model can be substituted with the high-speed LP model. Moreover, the computation speed is improved by using the BD method. In addition, the capacity of the injected power of EVs is reduced in the most-conservative scenario in comparison with the deterministic model's scenario, while the consumed power of loads and EVs have been increased in this scenario. The proposed robust architecture against uncertainties is shown to yield a more robust solutions at the expense of higher operation cost. © 2017 Elsevier B.V.","Active and reactive power management; Benders decomposition; Electric vehicles (EVs); Linear programming; Robust optimization","Costs; Electric load flow; Electric power measurement; Energy management; Linear programming; Natural language processing systems; Nonlinear programming; Optimization; Power management; Reactive power; Stochastic programming; Active and Reactive Power; Benders decomposition; Deterministic modeling; Electric Vehicles (EVs); Linear programming models; Robust optimization; Smart distribution networks; Total processing time; Network architecture",2-s2.0-85030084552
"Zivanovic S., Slavkovic N., Milutinovic D.","An approach for applying STEP-NC in robot machining",2018,"Robotics and Computer-Integrated Manufacturing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027962773&doi=10.1016%2fj.rcim.2017.08.009&partnerID=40&md5=c26c81eaab14589b5382083e6b5623f0","This paper presents an approach for applying new machining standard ISO 10303-238 in machining operations by using industrial robots. The methodology developed according to this standard is proposed for executing programming, simulation and machining by industrial robots. A detailed description is given of a developed RoboSTEP-NC module which, being part of established methodology, translates the program according to ISO 10303-238 for 3-axis machining into a robot programming language. Programming verification has been realized, first, by simulation on virtual robots configured in STEP-NC Machine environment, and thereafter also by machining on a real available robot after translating machining program by applying the developed RoboSTEP-NC module. © 2017 Elsevier Ltd","Industrial robots; Machining; Programming; Simulation; STEP-NC","Industrial robots; Machining; Mathematical programming; Program translators; Robots; Virtual reality; 3-Axis machining; Machining operations; Machining program; Robot machining; Simulation; STEP-NC; Virtual robots; Robot programming",2-s2.0-85027962773
"Schröder T., Lauven L.-P., Geldermann J.","Improving biorefinery planning: Integration of spatial data using exact optimization nested in an evolutionary strategy",2018,"European Journal of Operational Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011008962&doi=10.1016%2fj.ejor.2017.01.016&partnerID=40&md5=4ca98924ae973c1c97ca0833fc05c172","Biorefineries can provide a product portfolio from renewable biomass similar to that of crude oil refineries. To operate biorefineries of any kind, however, the availability of biomass inputs is crucial and must be considered during planning. Here, we develop a planning approach that uses Geographic Information Systems (GIS) to account for spatially scattered biomass when optimizing a biorefinery's location, capacity, and configuration. To deal with the challenges of a non-smooth objective function arising from the geographic data, higher dimensionality, and strict constraints, the planning problem is repeatedly decomposed by nesting an exact nonlinear program (NLP) inside an evolutionary strategy (ES) heuristic, which handles the spatial data from the GIS. We demonstrate the functionality of the algorithm and show how including spatial data improves the planning process by optimizing a synthesis gas biorefinery using this new planning approach. © 2017 Elsevier B.V.","Biorefinery; Evolutionary computations; Evolutionary strategy; Geographic Information System; Location planning; NLP","Bioconversion; Biomass; Crude oil; Evolutionary algorithms; Information systems; Natural language processing systems; Nonlinear programming; Optimization; Planning; Refining; Biorefineries; Evolutionary strategies; Location planning; Nonlinear programs; Objective functions; Planning problem; Product portfolios; Strict constraint; Geographic information systems",2-s2.0-85011008962
"Rakotonirina A.D., Wachs A.","Grains3D, a flexible DEM approach for particles of arbitrary convex shape - Part II: Parallel implementation and scalable performance",2018,"Powder Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032343789&doi=10.1016%2fj.powtec.2017.10.033&partnerID=40&md5=fc1609d7e5e920aec69a87f91048611a","In [1] we suggested an original Discrete Element Method that offers the capability to consider non-spherical particles of arbitrary convex shape. We elaborated on the foundations of our numerical method and validated it on assorted test cases. However, the implementation was serial and impeded to examine large systems. Here we extend our method to parallel computing using a classical domain decomposition approach and inter-domain MPI communication. The code is implemented in C++ for multi-CPU architecture. Although object-oriented C++ offers high-level programming concepts that enhance the versatility required to treat multi-shape and multi-size granular systems, particular care has to be devoted to memory management on multi-core architecture to achieve reasonable computing efficiency. The parallel performance of our code Grains3D is assessed on various granular flow configurations comprising both spherical and angular particles. We show that our parallel granular solver is able to compute systems with up to a few hundreds of millions of particles. This opens up new perspectives in the study of granular material dynamics. © 2017 Elsevier B.V.","Angular particles; Discrete Element Method; Granular flow; Parallel computing","C++ (programming language); Computer architecture; Confined flow; Domain decomposition methods; Finite difference method; Multicore programming; Numerical methods; Object oriented programming; Parallel flow; Parallel processing systems; Particles (particulate matter); Angular particles; Computing efficiency; Domain decompositions; Granular flows; High-level programming; Multicore architectures; Nonspherical particle; Parallel implementations; Granular materials; decomposition; grain; memory",2-s2.0-85032343789
"Pourhashem S., Ghasemy E., Rashidi A., Vaezi M.R.","Corrosion protection properties of novel epoxy nanocomposite coatings containing silane functionalized graphene quantum dots",2018,"Journal of Alloys and Compounds",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032001689&doi=10.1016%2fj.jallcom.2017.10.150&partnerID=40&md5=f1f390e632e1e159c54a35b409732eae","In this research, the effect of silane functionalized graphene quantum dots (f-GQDs) on the corrosion resistance of solvent-based epoxy coatings was investigated. The GQDs were prepared under hydrothermal method by using citric acid as precursor at 160 °C for 4 h. In order to increase the structural compatibility between GQDs and polymer matrix, the synthesized GQDs were chemically modified by (3-aminopropyl) triethoxysilane. The GQDs were characterized by X-ray diffraction, Fourier transform infrared spectroscopy, fluorescence emission, and transmission electron microscopy. Then, epoxy nanocomposite coatings containing f-GQDs were spray coated on mild steel substrate and the corrosion protection properties of epoxy/f-GQDs were studied via potentiodynamic polarization test and electrochemical impedance spectroscopy. The results showed that the corrosion protection performance of epoxy coatings had improved effectively with addition of low-cost and highly tunable f-GQDs due to their barrier performance in polymer coatings. © 2017 Elsevier B.V.","Corrosion protection; Epoxy; Graphene quantum dots; Nanocomposite coatings; Silane functionalization","C (programming language); Carbon steel; Coatings; Corrosion; Corrosion protection; Corrosion resistance; Electrochemical impedance spectroscopy; Epoxy resins; Fourier transform infrared spectroscopy; Graphene; High resolution transmission electron microscopy; Nanocomposites; Nanocrystals; Semiconductor quantum dots; Silanes; Transmission electron microscopy; X ray diffraction; Corrosion protection performance; Epoxy; Functionalized graphene; Mild steel substrates; Nano-composite coating; Potentiodynamic polarization tests; Silane functionalization; Structural compatibility; Plastic coatings",2-s2.0-85032001689
"Saleh M., Kariem M.M., Luzin V., Toppler K., Li H., Ruan D.","High strain rate deformation of ARMOX 500T and effects on texture development using neutron diffraction techniques and SHPB testing",2018,"Materials Science and Engineering A",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031748412&doi=10.1016%2fj.msea.2017.09.022&partnerID=40&md5=36ee73f79ed2e337663755fb14623f0f","The authors evaluated the crystallographic texture, defined as the distribution of orientation of crystals (or grains), to gauge the deformation and microstructural evolution of ARMOX 500T armour plates at elevated strain rates. Using neutron diffraction, the authors examined a number of specimens deformed at room temperature and high strain rates and contrasted these with equivalent samples deformed quasi-statically. Since crystallographic texture can play a part in the armour's ballistic response the authors were able to observe a rate dependent textural development, with the strengthening of the rolling α-fibre. The hot rolling process used in the manufacture of these steels leads to a through thickness texture variation that leads to an asymmetric transitional texture in the strain regime (1–2%) but with increased strain a symmetric texture develops irrespective of the strain rate, albeit with different intensities. By extending the testing program the authors were also able to deduce the strength parameters for the Johnson-Cook model through split Hopkinson pressure bar testing at high strain rates (1000–3000 s−1) and elevated temperatures (20–600 °C). The results, when compared with existing literature, show deviations in the strain rate sensitives of the tested specimens and, subsequently, variations in the computed flow stress parameters. © 2017","Armour; Johnson-Cook; Neutron-diffraction; SHPB; Texture","Armor; C (programming language); Crystal orientation; Deformation; Hot rolling; Mechanical testing; Neutron diffraction; Neutrons; Software testing; Strain; Testing; Textures; Armour; Crystallographic textures; Elevated temperature; High strain rate deformation; Johnson-Cook; Neutron diffraction technique; SHPB; Split Hopkinson pressure bars; Strain rate",2-s2.0-85031748412
"Bağcı B.B., Kamaşak M., Ince G.","The effect of the programming interfaces of robots in teaching computer languages",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029420883&doi=10.1007%2f978-3-319-62875-2_8&partnerID=40&md5=6481a38cd75d1a9a0de5d4043801a433","Programming is a popular subject in education and experts emphasize the importance of teaching programming to the children in the high school or even earlier. In this study, we used robots for teaching programming basics to the high school and college students and observed the effects of different interfaces. We used an educational robot called Thymio-II with Aseba Event Script Language (AESL), which is designed specifically for the Thymio. In this work, our hypothesis is that visual programming interfaces are more successful on learning programming and facilitate the learning with other interfaces and languages. In order to teach programming, as well as the interfaces and the robot features, we created a curriculum applicable to all interfaces. We taught students ages ranging from 15 to 24 using lecture content prepared in the form of video recordings. Students were given 30Â min of lectures and at the end of each lecture students were expected to write a program according to predefined requirements. Students were divided to groups using different interfaces and we observed the difference of the learning curves of students for each programming interface. In our tests, we used original English AESL, Turkish version of AESL and a graphical interface called Visual Programming Language (VPL). We compared the performance of the students using the graphical icon based against the classical text based programming languages. © 2018, Springer International Publishing AG.","Programming interfaces; Robots in teaching programming; Teaching computer languages; Visual programming","Computer programming; Computer programming languages; Educational robots; Robot programming; Robotics; Robots; Students; Video recording; Visual languages; College students; Graphical interface; Learning programming; Programming interface; Script Languages; Teaching programming; Visual programming; Visual programming languages; Education",2-s2.0-85029420883
"Swacha J.","SIPE: A domain-specific language for specifying interactive programming exercises",2018,"Studies in Computational Intelligence",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027265688&doi=10.1007%2f978-3-319-65208-5_2&partnerID=40&md5=19ffd83df9d03c374c23a2bef4d5a074","The paper introduces a new domain-specific language designed essentially for specifying exercises for interactive programming courses. The language covers the four crucial elements of interactive programming exercise, i.e.: metainformation, exercise description, solution checking and feedback, and aims at conciseness, human readability and ease of use. The paper discusses the issues with alternative forms of specifying programming exercises, presents the general concepts and syntax of the language, and reports on its implementation and validation. © Springer International Publishing AG 2018.","E-learning; Exercise specification; Programming learning environments",,2-s2.0-85027265688
"Barmpoutis A., Huynh K., Ariet P., Saunders N.","Assessing the effectiveness of emoticon-like scripting in computer programming",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026208806&doi=10.1007%2f978-3-319-60011-6_7&partnerID=40&md5=a64c13c54b8447b1c381163ba7615dae","In this paper a new method is proposed for learning computer programming. This method utilizes a set of human-readable graphemes and tokens that interactively replace the grammatical tokens of programming languages, using a concept similar to emoticons in social media. The theoretical framework of the proposed method is discussed in detail and two implementations are presented for the programming language ECMAScript (JavaScript). The results from user testing with undergraduate students show that the proposed technique improves the student’s learning outcomes in terms of syntax recall and logic comprehension, in comparison to traditional source code editors. © Springer International Publishing AG 2018.","Computer education; Emoticons; Graphemes; Human factors; Interaction design; Programming languages","Computer programming languages; Computer software; Education; Human computer interaction; Human engineering; Java programming language; Students; Systems engineering; Computer education; Emoticons; Graphemes; Human-readable; Interaction design; Learning outcome; Theoretical framework; Undergraduate students; Computer programming",2-s2.0-85026208806
"Cárdenas-Cobo J., Novoa-Hernández P., Puris A., Benavides D.","Recommending exercises in scratch: An integrated approach for enhancing the learning of computer programming",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025820192&doi=10.1007%2f978-3-319-60937-9_20&partnerID=40&md5=c1eb8e1263a850f6be1a71fb56670774","In this chapter we focused on how to improve the learning of computer programming in college students. From the reported success, we relied on Scratch, a visual programming language for enhancing the informal learning. Despite the progress achieved in the past, we have observed some issues regarding the use of Scratch by college students. First, there is a gap between the employed learning approaches since professors are constrained to classroom activities. Second, certain students feel unmotivated because they are confronted with programming exercises that do not fulfill their individual expectations. So, in order to solve this issue we propose an integrated approach consisting of a simple Web Application that includes Scratch as a project editor along with an Recommender System for exercises. The preliminary results demonstrate the positive impact of our proposal. © Springer International Publishing AG 2018.",,"Computer programming; Engineering education; Integrated control; Students; Visual languages; Classroom activity; College students; Informal learning; Integrated approach; Learning approach; Programming exercise; Visual programming languages; WEB application; Education",2-s2.0-85025820192
"Coenen J., Gross S., Pinkwart N.","Comparison of feedback strategies for supporting programming learning in integrated development environments (IDEs)",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025134292&doi=10.1007%2f978-3-319-61911-8_7&partnerID=40&md5=2d373e25991c2a5e62b6ef4417e55ef6","In this paper we investigate whether providing feedback to learners within an Integrated Development Environment (IDE) helps them write correct programs. Here, we use two approaches: feedback based on stack trace analysis, and feedback based on structural comparisons of a learner program and appropriate sample programs. In order to investigate both approaches, we developed two prototypical extensions for the Eclipse IDE. In a laboratory study, we empirically evaluated the impact of the extensions on learners’ performance while they solved programming tasks. The statistical analyses did not reveal any statistically significant effects of the prototype extensions on the performance of the learners, however, the results of a qualitative analysis imply that the provided feedback had at least a marginal impact on the performance of some learners. Also, feedback from the participants confirmed the benefit of providing feedback directly within IDEs. © Springer International Publishing AG 2018.","Adaptive feedback; Integrated development environment; Java programming","Computer programming; Education; Integrodifferential equations; Adaptive feedback; Feedback strategies; Integrated development environment; Java programming; Laboratory studies; Programming learning; Qualitative analysis; Structural comparison; Java programming language",2-s2.0-85025134292
"Ji X., Shen C.","The introspective may achieve more: Enhancing existing Geoscientific models with native-language emulated structural reflection",2018,"Computers and Geosciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032468347&doi=10.1016%2fj.cageo.2017.09.014&partnerID=40&md5=4f5c7ef28ac27ec6816bd98dc3d6576e","Geoscientific models manage myriad and increasingly complex data structures as trans-disciplinary models are integrated. They often incur significant redundancy with cross-cutting tasks. Reflection, the ability of a program to inspect and modify its structure and behavior at runtime, is known as a powerful tool to improve code reusability, abstraction, and separation of concerns. Reflection is rarely adopted in high-performance Geoscientific models, especially with Fortran, where it was previously deemed implausible. Practical constraints of language and legacy often limit us to feather-weight, native-language solutions. We demonstrate the usefulness of a structural-reflection-emulating, dynamically-linked metaObjects, gd. We show real-world examples including data structure self-assembly, effortless input/output (IO) and upgrade to parallel I/O, recursive actions and batch operations. We share gd and a derived module that reproduces MATLAB-like structure in Fortran and C++. We suggest that both a gd representation and a Fortran-native representation are maintained to access the data, each for separate purposes. Embracing emulated reflection allows generically-written codes that are highly re-usable across projects. © 2017 Elsevier Ltd","Data I/O; Efficient programming; FORTRAN; Generic data structure; Geoscientific modeling; Reflection","C++ (programming language); Computer software reusability; Data structures; FORTRAN (programming language); MATLAB; Object oriented programming; Reflection; Reusability; Self assembly; Batch operation; Code reusability; Complex data structures; Data I/O; Generic data structures; Native language; Separation of concerns; Structural reflection; Information management; data set; geology; input-output analysis; modeling; software",2-s2.0-85032468347
"Baek N.","Design of openGL SC 2.0 shader language features",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022179331&doi=10.1007%2f978-981-10-5281-1_27&partnerID=40&md5=59c0fb1a0a17cc502915a4af9558defd","OpenGL is one of the most generally used 3D graphics libraries. Their new versions have special-purpose embedded high-level programming languages, named OpenGL Shading Language (OpenGL SL). The new safety critical version of OpenGL, OpenGL SC 2.0 is now available. To support the shading language features of OpenGL SC 2.0, we need an off-line compiling feature. In this paper, we present the overall design and implementation strategy for the OpenGL SC 2.0 off-line shader language specification. © Springer Science+Business Media Singapore 2018.","Design; OpenGL SC; Shading language","Application programming interfaces (API); Computer graphics; Design; Wireless telecommunication systems; 3D graphics libraries; High-level programming language; Language features; Language specification; Opengl sc; Overall design; Shading languages; High level languages",2-s2.0-85022179331
"Dobesova Z.","Testing of Perceptual Discriminability in Workflow Diagrams by Eye-Tracking Method",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029596683&doi=10.1007%2f978-3-319-67618-0_30&partnerID=40&md5=d46d6faad1383465535ef54704a84798","Workflow diagrams are used for the design of steps of the algorithm in spatial processing data in geographic information system (GIS). The colour fills, and various shapes are used for basic symbols in the workflow diagram vocabularies. The Perceptual Discriminability and Visual Expressiveness are two basic principles of the theory Physics Notations. This theory revealed the zero visual distance between yellow Built-in Tool symbol and Script Tool symbol (resp. Sub-model symbol) in ArcGIS ModelBuilder. The eye-tracking experiment tested the influence of increasing the visual distance of symbols in workflow diagrams on the user cognition. The visual distance was increased by a change of fill colour for two mentioned symbols. Eye-tracking measuring brought objective results and affirmed that diagrams, where symbols have better perceptual discriminability, have an average lower time of response, lower number of fixations, and shorter length of scanpath. The result is a recommendation for changes of symbols in the visual vocabulary of ModelBuilder that introduce two new symbols for Script Tool and Sub-model. © 2018, Springer International Publishing AG.","Colour; Eye-tracking; Human-computer interaction; Perception; Shape; Visual programming language; Workflow","Color; Computation theory; Computational methods; Computer programming; Data handling; Eye movements; Geographic information systems; Graphic methods; Human computer interaction; Intelligent systems; Sensory perception; Eye tracking methods; Eye-tracking; Number of fixations; Shape; Spatial processing; Visual programming languages; Visual vocabularies; Workflow; Visual languages",2-s2.0-85029596683
"Balas M.M., Boran R.A.","Basic expert system",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029471579&doi=10.1007%2f978-3-319-62521-8_2&partnerID=40&md5=1f74fdf4cd288866731dfe702cba32bd","The paper is presenting a new visual software tool for developing expert systems: Basic Expert System. The Graphical User Interface is organized in expert diagrams, facilitating and accelerating the design of complex applications. An expert system for tomato disease diagnostic illustrates the BES operation. © 2018, Springer International Publishing AG.","Dataflow; Expert system; Tomato disease; Visual programming language","Computer programming; Diagnosis; Fruits; Graphical user interfaces; Soft computing; User interfaces; Visual languages; Complex applications; Dataflow; Tomato disease; Visual programming languages; Expert systems",2-s2.0-85029471579
"Cherepovskaya E.N., Gorshkova E.V., Lyamin A.V.","Assessment of students’ programming skills by using multi-style code editor",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020431451&doi=10.1007%2f978-3-319-59451-4_22&partnerID=40&md5=8480897f72059ccf11602c1c51bf4adb","e-Learning tools and environments, especially virtual laboratories, are becoming of great interest nowadays as the reason of fast improvement of learning management systems and education itself. Virtual laboratories are often used for developing and assessing students’ programming skills. However, these environments are commonly related to the specific programming language, so that some students may experience difficulties, while dealing with them. Hence, it is expedient to construct such learning tools that will not be connected to the specific language. This paper presents the results of evaluation of the developed virtual laboratory Multi-style code editor that corresponds with the stated rule. © Springer International Publishing AG 2018.","Computer science; e-Learning; Remote Laboratory Control Protocol; Virtual laboratories","Computer science; Distance education; E-learning; Education; Laboratories; Code editors; Control protocols; E-learning tool; Learning management system; Learning tool; Programming skills; Specific languages; Virtual laboratories; Students",2-s2.0-85020431451
"Yali Y., Qin Y.F., Xiao Z.","How to help students learn class combination in the course of java language",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031417131&doi=10.1007%2f978-981-10-3187-8_40&partnerID=40&md5=89d11796e0e9dd9f93ca2ba5daf4595c","The combination of the class is a common method in software reuse. The teacher carried out a detailed analysis of class combination related difficulties such as object memory model representation, parameter transmission of method, the UML diagram of classes, effectively made the class combination less difficult and abstract, improved the classroom teaching effect, and facilitated students to master the core course of The Java Language Programming faster and better. © Springer Nature Singapore Pte Ltd. 2018.","Object memory distribution; Parameter transmission of method; The UML diagram","Computation theory; Computer software reusability; Education; Students; Teaching; Classroom teaching; Core course; Java language; Memory modeling; Object memory distribution; Parameter transmission of method; UML diagrams; Java programming language",2-s2.0-85031417131
"Sitek P., Wikarek J., Stefański T.","Optimization of urban freight distribution with different time constraints - A hybrid approach",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022187384&doi=10.1007%2f978-3-319-62410-5_1&partnerID=40&md5=cf41f00dae0c096307d6c30b6cb3849e","The efficient and timely distribution of freight is critical for supporting the demands of modern urban areas. Without optimal freight distribution, urban areas could not survive and develop. The paper presents the concepts of hybrid approach to optimization of urban freight distribution. This approach proposed combines the strengths of mathematical programming (MP) and constraint logic programming (CLP), which leads to a significant reduction in the search time necessary to find the optimal solution and allows solving larger problems. It also presents the formal model for optimization of urban freight distribution with different types of time constraints. The application of the hybrid approach to the optimization of urban freight distribution is the primary contribution of this paper. The proposed model was implemented using both the hybrid approach and pure mathematical programming for comparison. Several experiments were performed for both computational implementations in order to evaluate both approaches. © Springer International Publishing AG 2018.","Constraint logic programming; Hybrid methods; Mathematical programming; Optimization; Presolving; Urban freight distribution","Artificial intelligence; Computation theory; Computer circuits; Computer programming languages; Distributed computer systems; Mathematical programming; Optimization; Computational implementations; Constraint Logic Programming; Freight distribution; Hybrid method; Optimal solutions; Presolving; Primary contribution; Urban freight distribution; Logic programming",2-s2.0-85022187384
"Kartiev S.B., Kureychick V.M.","Algorithm for building recommendations for intelligent systems",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031314033&doi=10.1007%2f978-3-319-68324-9_9&partnerID=40&md5=8896f97e3446d28d128c21744dcafb97","At present, when developing intellectual systems, one of the most important questions is the construction of a formal description of the data domain. This allows to improve the quality of development. The ontological models are currently used for these purposes. The paper describes the development of a model of the recommendation system based on the ontological approach. When developing recommendatory systems, the usual methods of describing objects are applied, which leads to the impossibility of configuring the system being developed. The purpose of this study was to develop an ontological model for configurable recommender systems. An introduction is given to the topic of ontological modeling, sufficient for understanding the main material of the article. The formal ontology model is presented, the main ontology classes, ontology levels, ontology usage objectives are described. The main principle of modeling the domain object-oriented design is described. Next, the application of ontologies in the recommendation system is described. It describes the conceptual model of the system with UML. A model of the ontology of the data domain description for the development of the recommendatory system was developed. The principal difference of this model from existing models is its customization on the data domain. Using the developed model, it is possible to develop configurable advisory systems. A recommendatory system has been developed using the Python programming language to solve the problem of making recommendations using the developed ontological model of the domain model presentation. Studies were conducted on the effectiveness of modeling the subject area with regard to the compilation of requirements for the recommendation system. © 2018, Springer International Publishing AG.","Ontological modeling; Recommended system; Semantic web","Intelligent systems; Object oriented programming; Ontology; Semantic Web; Application of ontologies; Data domain description; Formal ontology model; Intellectual systems; Object oriented design; Ontological modeling; Python programming language; Recommended systems; Recommender systems",2-s2.0-85031314033
"Singleton J.L., Leavens G.T.","A layered approach to specification authoring, sharing, and usage",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027862188&doi=10.1007%2f978-3-319-56157-8_8&partnerID=40&md5=a9f0516946768fc74ae511f7c258535d","Compositional reuse of software libraries is important for productivity. To promote reliability and correctness, there must also be a way to compose specifications for reuse. However, specifications cannot be adapted by the use of wrappers in the same ways as code, which leads to specifications being copied and modified. This copying and modification of specifications leads to poor maintainability and technical debt. We propose a system, Spekl, that solves these problems and makes compositional reuse of specifications possible in a way independent of the choice of specification languages and tools. We provide a detailed description of our system as well as provide details on our domain specific language for creating new tools, provide details on how to author new specifications, and demonstrate how Spekl facilitates compositional reuse through specification layering. © 2018, Springer International Publishing AG.","JML; Reuse; Specification; Specification languages; Specification management; Spekl","Computer programming languages; Computer software reusability; Problem oriented languages; Specification languages; Domain specific languages; Layered approaches; Reuse; Software libraries; Spekl; Technical debts; Specifications",2-s2.0-85027862188
"Basha M., Sidik N.A.C.","Numerical predictions of laminar and turbulent forced convection: Lattice Boltzmann simulations using parallel libraries",2018,"International Journal of Heat and Mass Transfer",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029677808&doi=10.1016%2fj.ijheatmasstransfer.2017.09.072&partnerID=40&md5=8b32d3de6d3656d9ad3bd6115f80e1e9","This paper presents the performance comparison of various parallel lattice Boltzmann codes for simulation of incompressible laminar convection in 2D and 3D channels. Five different parallel libraries namely; matlabpool, pMatlab, GPU-Matlab, OpenMP and OpenMP+OpenMPI were used to parallelize the serial lattice Boltzmann method code. Domain decomposition method was adopted for parallelism for 2D and 3D uniform lattice grids. Bhatnagar-Gross-Krook approximation with lattice types D2Q9, D2Q19 and D2Q5, D2Q6 were considered to solve 2D and 3D fluid flow and heat transfer respectively. Parallel computations were conducted on a workstation and an IBM HPC cluster with 32 nodes. Laminar forced convection in a 2D and turbulent forced convection in a 3D channels was considered as a test case. The performance of parallel LBM codes was compared with serial LBM code. Results show that for a given problem, parallel simulations using matlabpool and pMatlab library perform almost equal. Parallel simulations using C language with OpenMP libraries were 10 times faster than simulations involving Matlab parallel libraries. Parallel simulations with OpenMP+OpenMPI were 0.35 times faster than the reported parallel lattice Boltzmann method code in the literature. © 2017 Elsevier Ltd","Domain-decomposition; Matlabpool; MPI; OpenMP; OpenMPI; Parallel lattice Boltzmann method","Application programming interfaces (API); C (programming language); Codes (symbols); Computational fluid dynamics; Domain decomposition methods; Flow of fluids; Forced convection; Incompressible flow; Kinetic theory; MATLAB; Bhatnagar-Gross-Krook approximations; Fluid flow and heat transfers; Lattice Boltzmann method; Lattice Boltzmann simulations; Matlabpool; OpenMP; Openmpi; Turbulent forced convection; Heat transfer",2-s2.0-85029677808
"Miao S., Zhou J., Liu S., Cai X.","Formation mechanisms and characteristics of transition patterns in oblique detonations",2018,"Acta Astronautica",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032665730&doi=10.1016%2fj.actaastro.2017.10.035&partnerID=40&md5=4518c9b83a6de04f24d0b8d590e639d0","The transition structures of wedge-induced oblique detonation waves (ODWs) in high-enthalpy supersonic combustible mixtures are studied with two-dimensional reactive Euler simulations based on the open-source program AMROC (Adaptive Mesh Refinement in Object-oriented C++). The formation mechanisms of different transition patterns are investigated through theoretical analysis and numerical simulations. Results show that transition patterns of ODWs depend on the pressure ratio Pd/Ps, (Pd, Ps are the pressure behind the ODW and the pressure behind the induced shock, respectively). When Pd/Ps &gt; 1.3, an abrupt transition occurs, while when Pd/Ps &lt; 1.3, a smooth transition appears. A parameter ε is introduced to describe the transition patterns quantitatively. Besides, a criterion based on the velocity ratio Φ=U0/UCJ is proposed to predict the transition patterns based on the inflow conditions. It is concluded that an abrupt transition appears when Φ &lt; 0.98Φ*, while a smooth transition occurs when Φ &gt; 1.02Φ∗ (Φ∗ is the critical velocity ratio calculated with an empirical formula). © 2017 IAA","Formation mechanisms; Numerical simulation; Oblique detonation wave; Quantitative criterion; Transition structure","C++ (programming language); Computer simulation; Computer software; Numerical models; Object oriented programming; Shock waves; Velocity; Adaptive mesh refinement; Combustible mixture; Critical velocities; Formation mechanism; Oblique detonation waves; Quantitative criteria; Transition patterns; Transition structures; Detonation",2-s2.0-85032665730
"Durak H.Y., Saritepeci M.","Analysis of the relation between computational thinking skills and various variables with the structural equation model",2018,"Computers and Education",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030159191&doi=10.1016%2fj.compedu.2017.09.004&partnerID=40&md5=bf6d77d17af237f78bb34a3615c1a0aa","The aim of this study is to determine how much various variables explain students' computational thinking (CT) skills. Furthermore, it was aimed to produce a model that explains and predicts the relations between computational thinking skills and various variables. Study group consists of 156 students who were studying in 5–12. Class in 2015–2016 academic year in different schools in Ankara. Relational screening model was used in this research. Two different data collection instruments were used in this research. The first one is “Personal Information Form”. The second one is “Computational Thinking Skills Scale”. Structural Equation Model was used in data analysis so as to produce a model that explains and predicts the relations between computational thinking skills and various variables. According to research results, it was found that computational thinking skill was highly predicted by variables, respectively; “thinking styles, academic success in mathematic class, attitude against mathematic class”. © 2017 Elsevier Ltd","Computational thinking; Evaluation methodologies; Media in education; Programming and programming languages; Secondary education","Computational methods; Education; Education computing; Computational thinkings; Evaluation methodologies; Media in education; Personal information; Programming and programming languages; Research results; Screening models; Structural equation modeling; Students",2-s2.0-85030159191
"Caban D., Walkowiak T.","Specification of constraints in a system-of-systems configuration",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020798130&doi=10.1007%2f978-3-319-59415-6_9&partnerID=40&md5=0e057f1a0fa904163d32018c629c37a3","A class of Systems-of-Systems (SoS) is considered, where systems are hierarchically composed of subsystems. The structure of the system changes during its lifetime, i.e. component subsystems are moved to other parents. Each system has its configurable parameters. When the configuration changes, it may lead to conflicts in the configuration of its components. There are constraints on component systems configurations that are not limited to the systems, or even to their ancestors in the hierarchy. A domain specific language is proposed to describe constraints in the SoS. It consists of a list of assertions that the SoS configuration must meet. Each assertion is a logical expression that is scoped to a specific subset of component systems. © Springer International Publishing AG 2018.","Configuration; Constraint; Systems-of-systems","Computer programming languages; Problem oriented languages; Systems engineering; Component systems; Configurable parameter; Configuration; Constraint; Domain specific languages; Logical expressions; Specific subset; Systems of systems; System of systems",2-s2.0-85020798130
"Al-Mahfoudh M.S., Gopalakrishnan G., Stutsman R.","Operational semantics for the rigorous analysis of distributed systems",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027842460&doi=10.1007%2f978-3-319-56157-8_10&partnerID=40&md5=a68d752ec67d3ecb22ae496f70ece793","The development of distributed systems based on poorly specified abstractions can hinder unambiguous understanding and the creation of common formal analysis methods. In this paper, we outline the design of a system modeling language called DS2, and point out how its primitives are well matched with concerns that naturally arise during distributed system design. We present an operational semantics for DS2 as well as results from an ongoing Scala-based implementation slated to support a variety of state-space exploration techniques. The driving goals of this project are to: (1) provide a prototyping framework within which complex distributed system protocols can be stated and modeled without breaking the primitives down to low level ones, and (2) drive the development of interesting and distributed system-relevant property checking methods (e.g., linearizability). © 2018, Springer International Publishing AG.","Actors; Concurrency; Distributed systems; Operational semantics; Scheduling","Modeling languages; Scheduling; Semantics; Space research; Actors; Complex distributed system; Concurrency; Distributed system designs; Distributed systems; Operational semantics; State space exploration; System modeling languages; Computer programming languages",2-s2.0-85027842460
"Samson A.J., Mabayo J.N., Frieszer P., Ang L.B.","A case study of integrating a proprietary evaluation system into the failure analysis processes of optical sensors",2018,"Engineering Failure Analysis",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031709368&doi=10.1016%2fj.engfailanal.2017.09.021&partnerID=40&md5=039a48014b076a7ca5e3dcc1d343d4c5","This paper presents a new and novel approach in characterizing and verifying failure mechanisms of optical sensors using a patter-driven, real-time evaluation tool, whose initial purpose is to address automated characterizations and validations. The goal of this paper is to create a series of programs that are specifically aimed at understanding the optical failure parameters of optical sensors. The devices were then subjected to full failure analysis process to correlate and verify the results obtained. Preliminary results showed that this approach: (a) significantly shortens the cycle time of the FA process of optical sensors as complicated test set-ups in the automatic test equipment (ATE) can be turned into a secondary verification tool; (b) provides better understanding of the optical as well as the electrical failures of optical sensors since the programming of our automated evaluation system can be adjusted to explore different failure characterizations and evaluations; and (c) it optimizes the failure analysis process by providing the analyst with more data and information about the device failures. © 2017","Digital characterization; Failure analysis; Optical sensors","Automatic testing; C (programming language); Characterization; Equipment testing; Failure analysis; Optical sensors; Automated evaluation systems; Automatic test equipment; Data and information; Electrical failures; Failure characterization; Failure parameters; Real time evaluation; Verification tools; Failure (mechanical)",2-s2.0-85031709368
"Thakar B., Parekh C.","Reverse engineering of botnet (APT)",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028402382&doi=10.1007%2f978-3-319-63645-0_28&partnerID=40&md5=7cd512362bcbc7f936f0ad313393f8a7","Grown internet usage by individual and industries have also increased the attack vector in cyberspace rapidly. Botnet is a digital weapon used by attackers to commit cybercrime in stealthiest way for all type of illegal online activity. Botnet is well articulated attack responsible for many malicious activities in large volume and mass effective against any targeted organization such as confidential data theft, financial loss, distribution of pirated products, e-business extortion and network or service disruption. Because of its global nature of infection and innovative covert techniques of malware development to evade detection, it is also known as advance persistent threat. An analysis of this APT revealed the advancement in sophistication of bot malware by encryption methods, concealed network connections and silent escape as an effective tool for profit-motivated e-crime. Reverse engineering is procedure to analyze malware to classify its type, hazard, impact on machine, information outflow and removal of signature technique. Botnet (APT) detection needs improvised process to identify the channel, architecture and encryption weakness. In bot examination; Programming style, network protocol and behavior analysis can mitigate the APT by creating signature, prototype of behavior based approach and elimination of C&C servers. Reverse engineering is excellent way for defense the modern botnets to immune valuable information by identifying the evidence behavior, log collection and digital forensics. The main aim of study is to determine the most adequate approach to recreate a botnet incident. Network security is prime concern to avoid state sponsored attacks like botnet so security of digital nation and e-governance can be assured. © Springer International Publishing AG 2018.","APT; BOTNET; Botware; Cyber forensics; Cyber security; Dynamic analysis; Malware; Malware analysis; Mirai; Network security; Reverse engineering; Robot network; Static analysis","Botnet; C (programming language); Classification (of information); Computer crime; Crime; Cryptography; Digital forensics; Dynamic analysis; Forensic engineering; Government data processing; Intelligent systems; Losses; Malware; Network protocols; Reverse engineering; Static analysis; Telemedicine; Botware; Cyber forensics; Cyber security; Malware analysis; Mirai; Robot networks; Network security",2-s2.0-85028402382
"Xiao Q., Li J., Xiao C.","Research on performance optimization of several frequently-used genetic algorithm selection operators",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032665554&doi=10.1007%2f978-3-319-67071-3_14&partnerID=40&md5=1092fa5967c5cac27381878e32fc9276","Genetic Algorithm is an intelligent algorithm for simulation of biological evolution, is widely applied to solve all kinds of problems. In this paper, several Frequently-used selection operators of Genetic Algorithm are programmed by C language, and are tested in an optimization problem. © 2018, Springer International Publishing AG.","Genetic algorithm; Hausdorff measure; Selection operator; Sierpinski carpet","Bioinformatics; Biology; C (programming language); Evolutionary algorithms; Genetic algorithms; Algorithm selection; Biological evolution; Hausdorff measures; Intelligent Algorithms; Optimization problems; Performance optimizations; Selection operators; Sierpinski carpet; Optimization",2-s2.0-85032665554
"Cuzzocrea A., Mumolo E., Tessarotto M., Grasso G.M., Amendola D.","XML-VM: An XML-based grid computing middleware",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026313010&doi=10.1007%2f978-3-319-61566-0_32&partnerID=40&md5=edcc5b8b7bd72a07b2e3627981b4c596","This paper describes a novel distributing computing middleware named XML-VM. Its architecture is inspired by the ‘Grid Computing’ paradigm. The proposed system improves many characteristics of previous Grid systems, in particular the description of the distributed computation, the distribution of the code and the execution times. XML is a markup language commonly used to interchange arbitrary data over the Internet. The idea behind this work is to use XML to describe algorithms; XML documents are distributed by means of XML-RPC, interpreted and executed using virtual machines. XML-VM is an assembly-like language, coded in XML. Parsing of XML-VM programs is performed with a fast SAX parser for JAVA. XML-VM interpreter is coded in JAVA. Several algorithms are written in XML-VM and executed in a distributed environment. Representative experimental results are reported. © Springer International Publishing AG 2018.",,"Computer software; Distributed computer systems; Hypertext systems; Java programming language; Middleware; Virtual machine; XML; Distributed computations; Distributed environments; Distributing computing; Grid computing middleware; Grid systems; ITS architecture; XML-RPC; Grid computing",2-s2.0-85026313010
"Soumya K., Arunkumar M.","SSD implementation and spark integration",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028406860&doi=10.1007%2f978-3-319-63673-3_30&partnerID=40&md5=14b393a5657ae9f4db8a0b47bac16bbe","One of the main challenges in Big data is the processing speed and scalability. Solid State Drive (SSD) helps for faster processing than HDD. Here along with SSD, Spark is also accompanied with hadoop framework for more scalability and fast processing. Apache Spark is a general-purpose engine for large-scale data processing on any cluster. It is a framework which can afford more than 8000 nodes in a cluster Spark allows for code reuse across batch, interactive, and streaming applications. Spark is much faster than MapReduce. It was generally coded from Java; Spark supports not only Java, but also Python and Scala, which is a newer language that contains some attractive properties for manipulating data. Spark runs up to 100 times faster than Hadoop MapReduce in memory and 10 times faster on disk. This paper tries to integrate spark with Hadoop ecosystem along the SSD. It increases the processing speed. © 2018, Springer International Publishing AG.","Hadoop; MapReduce; Spark; SSD","Data handling; Digital storage; Electric sparks; Hard disk storage; Intelligent systems; Java programming language; Scalability; Hadoop; Hadoop frameworks; Hadoop MapReduce; Large-scale data processing; Map-reduce; Processing speed; Solid state drives (SSD); Streaming applications; Big data",2-s2.0-85028406860
"Bluemke I., Gawkowski P., Grabski W., Grochowski K.","On the performance of some C# constructions",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020783409&doi=10.1007%2f978-3-319-59415-6_4&partnerID=40&md5=a4e654b1d2b14da666aaf221a1e4e63f","In some types of dependable applications (e.g. controlling some electronic devices) the execution time of a program has to be very short to enable the appropriate control of the device. Implementing code for Kamika’s device that measures small particles in the air or in the liquid we are using C# language. Some parts of the code were also transformed into C++ to find overheads. The main part of the paper are results of some comparative experiments measuring the performance of alternative C# constructions. We were especially interested in extension methods which enable to “add” methods to existing types without creating a new derived type, recompiling, or modifying the original type. © Springer International Publishing AG 2018.","C#; C++; Extension methods; Performance","Application programs; Cesium; Comparative experiments; Electronic device; Extension methods; Performance; Recompiling; Small particles; C++ (programming language)",2-s2.0-85020783409
"Nam S.-N., Cho H., Han J., Her N., Yoon J.","Photocatalytic degradation of acesulfame K: Optimization using the Box–Behnken design (BBD)",2018,"Process Safety and Environmental Protection",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030184656&doi=10.1016%2fj.psep.2017.09.002&partnerID=40&md5=a9c1adedc1c21c86433a21e8f4945f8c","In this research, photocatalytic degradation of acesulfame K, one of the most popular artificial sweeteners, has been carried out under variations of the initial concentration, pH, concentration of persulfate, and amount of natural organic matter (NOM). The removal efficiencies for 30-min, 60-min and 180-min reaction time have been applied to response surface methodology using the experimental responses obtained by a four-factor-three-level Box–Behnken design (BBD). This provided 29 experimental data for the initial concentration of acesulfame K ranging from 300 to 900 μg/L, pH of solution ranging from 4 to 10, persulfate concentration ranging from 0 to 10 mg/L, and amount of natural organic matter (NOM) ranging from 0 to 5 mg/L, which were consecutively coded as A, B, C, and D at three levels (−1, 0, and 1). The analysis of variance (ANOVA) tests with 95% confidence limits determined the significance of independent variables and their interactions consisting of the polynomial regression equation. The optimum values of the selected variables were determined by numerical optimization, and the experimental conditions were found to reach complete mineralization for 30 min and thereafter, at initial concentration of 887.2 μg/L; pH of 4; persulfate concentration of 9 mg/L, and NOM concentration of 5 mg/L. © 2017 Institution of Chemical Engineers","Acesulfame K; Box–Behnken design (BBD); Optimization; Persulfate; Photocatalysis; Response surface methodology (RSM)","Biogeochemistry; Biological materials; C (programming language); Optimization; Organic compounds; Photocatalysis; Sugar substitutes; Surface properties; Artificial sweeteners; Experimental conditions; Natural organic matters; Numerical optimizations; Persulfate; Photo catalytic degradation; Polynomial regression equations; Response surface methodology; Analysis of variance (ANOVA)",2-s2.0-85030184656
"Vishwas P.G., Premananda B.S.","Development of LIN 2.1 driver with SAE standards for RL78 microcontroller",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026725975&doi=10.1007%2f978-981-10-3373-5_49&partnerID=40&md5=233c04b2606d31d8fc79afcb0665c6fc","Communication Protocols play a vital role in the functioning of various communication systems. LIN is cheaper compared to other communication protocols and is used wherever low costs are essential and speed is not an issue. To enable cold start in case of diesel engines, the cylinders are fitted with glow plugs to preheat the cylinder. The signals for controlling the GLPs are sent using LIN bus from the ECUs. This paper involves design and implementation of LIN 2.1 driver for RL78 microcontroller and configuration of IDs for communication of messages between ECU and the driver. The driver is designed to operate in slave mode with fixed baud rate as per SAE standards and incorporates sleep mode and error handling capability. Embedded C codes are written for various modules and are compiled using IAR Embedded Workbench. The functionality of driver is tested using the CANalyzer tool. © Springer Nature Singapore Pte Ltd. 2018.","CANalyzer; LIN; RL78; SAE J2602; Sleep mode","C (programming language); Computation theory; Diesel engines; Engine cylinders; Glow plugs; Intelligent computing; Microcontrollers; CANalyzer; Cold start; Design and implementations; Error handling; Low costs; RL78; SAE J2602; SLEEP mode; Power management (telecommunication)",2-s2.0-85026725975
"Meng S.H., Hu S.B., Huang A.C., Huang T.J., Jia J.J., Huang X.","Car Collision Warning System for Cornering on Mountain Roads",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030863769&doi=10.1007%2f978-3-319-68527-4_24&partnerID=40&md5=886b54cdb7ed3bfc1586dd479b6348e9","This study proposes an ultrasound-based collision avoidance/warning safety system for vehicles cornering on mountain roads. The design includes a hardware and a software system. The hardware system consists of a single-chip microcontroller with a minimum system board, a power module, and an automotive radar system. The radar system includes a stc98c52 control module, LCD 1602 display module, and hc-sr04 ultrasonic detection module. The software was programmed using C on the Keil uVision4 platform. © 2018, Springer International Publishing AG.","Early warning; Obstacle; Ultrasound","Alarm systems; Data handling; Hardware; Highway planning; Information analysis; Liquid crystal displays; Radar; Radar systems; Ultrasonic applications; Ultrasonic testing; Ultrasonics; Automotive radar system; Display modules; Early warning; Hardware system; Obstacle; Single-chip microcontrollers; Software systems; Ultrasonic detection; C (programming language)",2-s2.0-85030863769
"Kimmich D., Taffa D.H., Dosche C., Wark M., Wittstock G.","Combinatorial screening of photoanode materials - Uniform platform for compositional arrays and macroscopic electrodes",2018,"Electrochimica Acta",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032684586&doi=10.1016%2fj.electacta.2017.10.147&partnerID=40&md5=8165b7690ecc3e34ffa79068be3a4a61","A new work flow for high-throughput evaluation of complex metal oxides for water splitting relies on the use of commercial material printer for library production and scanning photoelectrochemical microscopy (SPECM) for hit identification. The printing process is optimized into several directions using as an example binary mixtures of Zn2+ and Fe3+ salts as precursors. Firstly, temporary barrier layers from eicosane are printed to confine the spots to a particular region and to allow larger drop sizes without merging of neighboring droplets. Secondly, a glycerol droplet is printed before the application of metal salts to serve as a carrier liquid that is non-volatile at room temperature. The metal salt solutions are printed from ethylene glycol solutions into the carrier droplets. With these precautions, the drop remained as liquid phase on the substrate with their lateral position locked by the eicosane grid. This avoids problems with the early crystallization of metal salts between successive printing and ensured complete mixing of the precursor solution. The liquid drops are then thermally processed by temperature-programmed heating up to 600 °C allowing the sequential drying of the spots, evaporation of the grid structures and formation of ferrites. The same procedure is used to cover macroscopic electrodes with a large number of spots of identical composition to verify hits in laboratory photoelectrochemical cells and to use photocurrent transient and chopped light voltammetry for their further characterization. Structural characterization of the composition (Zn0.17Fe0.83Ox) with highest activity is performed by Raman and photoelectron spectroscopy. The opportunity to use the same printing protocols to form compositional libraries as well as extended single component electrodes allows screening of medium-sized arrays and the fast transition to more in depth single component experimentation using exclusively standard laboratory instrumentation. © 2017 Elsevier Ltd","Combinatorial chemistry; Material printing; Oxygen evolution; Raman spectroscopy; Scanning photoelectrochemical microscopy; Solar water splitting; Transition metal oxides; XPS","Binary mixtures; Bioassay; Biochips; C (programming language); Characterization; Drops; Electrochemistry; Electrodes; Ethylene; Ethylene glycol; Iron compounds; Liquids; Metals; Microarrays; Paraffins; Photoelectrochemical cells; Photoelectron spectroscopy; Printing; Printing presses; Raman spectroscopy; Salts; Throughput; Transition metals; X ray photoelectron spectroscopy; Zinc compounds; Combinatorial chemistry; Oxygen evolution; Scanning photoelectrochemical microscopy; Solar water splitting; Transition-metal oxides; Transition metal compounds",2-s2.0-85032684586
"Biederman D.M., Posham R., Durrani R.J., Titano J.J., Patel R.S., Tabori N.E., Nowakowski F.S., Fischman A.M., Lookstein R.A., Kim E.","Outcomes of radioembolization for unresectable hepatocellular carcinoma in patients with marginal functional hepatic reserve",2018,"Clinical Imaging",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027707593&doi=10.1016%2fj.clinimag.2017.07.011&partnerID=40&md5=34f83fd7090826a4720d09d66b43f48b","Purpose To evaluate the outcomes of radioembolization (RE) as a therapy for unresectable hepatocellular carcinoma (HCC) in patients with marginal functional hepatic reserve. Methods A retrospective review of 471 patients (1/2010–7/2015) treated with RE (Therasphere, BTG, UK) was performed. A total of 36 patients (mean age: 66.1 ± 9.3, male: 86.1%) underwent therapy for HCC with a MELD ≥ 15 (median: 16, range: 15–22). Baseline demographics of the study cohort were as follows: etiology (HCV: 26, 72.2%), cirrhosis (n = 32, 88.9%), ECOG 0 (n = 16, 44.4%), Child-Pugh class (A = 15, B = 19, C = 2), unilobar distribution (n = 27, 75%), AFP > 200 (n = 11, 30.6%), portal vein thrombosis (PVT, n = 7, 19.4%), metastasis (n = 3, 8.3%). Outcomes analyzed included CTCAEv4.03 laboratory toxicities (120-day), imaging response (mRECIST), progression-free survival (PFS), and overall survival (OS). Results A total of 42 treatments were performed with mean dose of 2.02 ± 1.23 GBq. The cumulative grade 3/4 toxicity was 28% overall and 21% for bilirubin at 120-days. The objective response and disease control rates were 48.3% (14/29) and 69% (20/29) respectively. The median (95% CI) PFS was 5.9 (4.4–7.7) months. Ten (27.8%) patients received additional locoregional therapy at a median (IQR) of 138 (102–243) days post RE. The mean (95% CI) OS was 21.9 (14.8–29.0) months. The absence of PVT was associated with improved OS (p = 0.005) Disease control at 90-days was also associated with an OS benefit (p = 0.037). Conclusions Patients with unresectable HCC and marginal functional hepatic reserve treated with RE had favorable objective response and disease control rates, both predictive of overall survival. © 2017 Elsevier Inc.","Hepatocellular carcinoma treatment; Interventional oncology; Radioembolization","C (programming language); Disease control; Toxicity; Hepatic reserves; Hepatocellular carcinoma; Interventional; Mean ages; Overall survival; Portal vein thrombosis; Progression free survival; Radioembolization; Patient treatment",2-s2.0-85027707593
"Tang S., Zhang Z., Wu J., Zhu H.","FPGA-based turbo decoder hardware accelerator in cloud radio access network (C-RAN)",2018,"Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031294521&doi=10.1007%2f978-3-319-66625-9_21&partnerID=40&md5=7d153fd350a31ca14523b0eced5ad0a7","In the Cloud Radio Access Network (C-RAN), the Software Defined Radio (SDR) is combined with multi-mode base stations (BSs) together. A lot of BSs are centralized in a Cloud center, the centralized BSs need high bandwidth and cost-effective resource allocation. Since BSs may also run on the virtualized machines, the hardware accelerator can provide faster signal processing speed. This paper uses the Xen virtualization to set up a C-RAN platform, where the SDR and the FPGA hardware connected with PCIe interface to server as the signal processing hardware accelerator. Experimental results demonstrate the turbo decoder accelerator based on the FPGA and Xen platform has good performance to support the SDR signal processing with high bandwidth. The turbo decoder hardware accelerator solved the timing constraints in C-RAN. © 2018, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.","C-RAN; FPGA; Hardware accelerator; SDR; Turbo decoder; Xen","Acceleration; Bandwidth; Computer hardware; Cost effectiveness; Decoding; Field programmable gate arrays (FPGA); Hardware; Signal processing; Software radio; Cost effective; FPGA hardwares; Hardware accelerators; Radio access networks; Signal processing hardwares; Software-defined radios; Timing constraints; Turbo decoders; C (programming language)",2-s2.0-85031294521
"Agarwal S., Kaur G.","Virtual field and wave laboratory using scilab and java",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031420269&doi=10.1007%2f978-981-10-6614-6_24&partnerID=40&md5=bf2b42d71c8341cd3953534734969db2","Combining the open source tools to efficiently process the data can enable anyone to experiment, explore as well as share their outcomes with the rest of the community. This paper describes and implements Virtual and Remote Laboratory using Scilab and Java. The main objective of this lab is to improve the study of field and wave theory by allow the user to work at any place without installing Scilab and Java. In addition to this, the application also provides Graphical user Interface (GUI) on Web where user can alter the coordinates of amplitude, frequency of wave, direction, wavelength, and time. Thus, students can develop the Scilab program on different parameters and then deploy to see the results in form of graph and Text. © 2018, Springer Nature Singapore Pte Ltd.","Java; JavaSci; Scilab; Wave propagation","Graphical user interfaces; Image processing; Open source software; User interfaces; Wave propagation; Graphical user interfaces (GUI); Java; JavaSci; Open source tools; Remote laboratories; Scilab; Virtual fields; Wave theory; Java programming language",2-s2.0-85031420269
"Phummiphan I., Horpibulsuk S., Rachan R., Arulrajah A., Shen S.-L., Chindaprasirt P.","High calcium fly ash geopolymer stabilized lateritic soil and granulated blast furnace slag blends as a pavement base material",2018,"Journal of Hazardous Materials",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027282298&doi=10.1016%2fj.jhazmat.2017.07.067&partnerID=40&md5=400e304aacda93eefd843038b79261b4","Granulated Blast Furnace Slag (GBFS) was used as a replacement material in marginal lateritic soil (LS) while class C Fly Ash (FA) was used as a precursor for the geopolymerization process to develop a low-carbon pavement base material at ambient temperature. Unconfined Compression Strength (UCS) tests were performed to investigate the strength development of geopolymer stabilized LS/GBFS blends. Scanning Electron Microscopy and X-ray Diffraction analysis were undertaken to examine the role of the various influencing factors on UCS development. The influencing factors studied included GBFS content, Na2SiO3:NaOH ratio (NS:NH) and curing time. The 7-day soaked UCS of FA geopolymer stabilized LS/GBFS blends at various NS:NH ratios tested was found to satisfy the specifications of the Thailand national road authorities. The GBFS replacement was found to be insignificant for the improvement of the UCS of FA geopolymer stabilized LS/GBFS blends at low NS:NH ratio of 50:50. Microstructural analysis indicated the coexistence of Calcium Silicate Hydrate (CSH) and Sodium Alumino Silicate Hydrate products in FA geopolymer stabilized LS/GBFS blends. This research enables GBFS, which is traditionally considered as a waste material, to be used as a replacement and partially reactive material in FA geopolymer pavement applications. © 2017 Elsevier B.V.","Fly ash; Geopolymer; Granulated blast furnace slag; Lateritic soil; Pavement base","Blast furnaces; C (programming language); Calcium; Calcium silicate; Carbon; Fly ash; Hydrates; Hydration; Inorganic polymers; Pavements; Scanning electron microscopy; Silicate minerals; Silicates; Slags; Soils; X ray diffraction analysis; Calcium silicate hydrate; Geopolymer; Granulated blast furnace slag; Granulated blast-furnace slags; Lateritic soils; Pavement base; Sodium alumino silicate hydrate; Unconfined compression strength; Geopolymers; aluminum sodium silicate; calcium; calcium silicate; geopolymer; inorganic compound; silicate; sodium hydroxide; sodium silicate; unclassified drug; calcium; compressive strength; fly ash; granular medium; laterite; microstructure; pavement; polymer; polymerization; replacement; scanning electron microscopy; slag; soil stabilization; X-ray diffraction; Article; building material; chemical composition; compressive strength; environmental temperature; fly ash; furnace; geopolymerization; granulated blast furnace slag; lateritic soil; polymerization; scanning electron microscopy; slag; soil; X ray diffraction; Thailand",2-s2.0-85027282298
"Li L., Zhu Y., Yang J.","3D bioprinting of cellulose with controlled porous structures from NMMO",2018,"Materials Letters",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028968295&doi=10.1016%2fj.matlet.2017.09.015&partnerID=40&md5=647d91756183d8f9f7746eab4a3889e5","In the present work, dissolved cellulose has been 3D bioprinted to produce complex structures with ordered interconnected pores. The process consists of the dissolution of dissolving pulps in N-methylmorpholine-N-oxide (NMMO), multilayered dispensing, water removal of NMMO and freeze-drying. 3D bioprinting of cellulose/NMMO solution at 70 °C was analogous to that of thermoplastics by the process of melting and solidification to produce cellulose/NMMO objects in the solid form. However, 3D bioprinting of cellulose/NMMO solution at a higher temperature than 70 °C produced cellulose/NMMO objects in the gel form. Cellulose was regenerated by water; thereafter, freeze-drying treatment maintained the 3D bioprinted structures without collapsing. The final cellulose products had remarkable Young's compressive modulus (12.9 MPa) and tensile modulus (160.6 MPa). This work demonstrated the feasibility of cellulose as an alternative in the 3D printing industry to the production of complex structures. © 2017 Elsevier B.V.","3D bioprinting; Cellulose; Controlled interconnected porous structures; NMMO","C (programming language); Cellulose; Dissolution; Drying; Low temperature drying; Porosity; Bioprinting; Cellulose products; Compressive moduli; Interconnected pores; Interconnected porous structure; Melting and solidification; N methylmorpholine N oxide; NMMO; 3D printers; Cellulose; Printing; Structures; Three Dimensional Design",2-s2.0-85028968295
"He M.X., Hu Z.B.","Matrix representations of genetic codes and human emotions",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028657880&doi=10.1007%2f978-3-319-67349-3_3&partnerID=40&md5=e859ff59597b48f668625fe3500bb271","The genetic code is encoded in combinations of the four nucleotides (A, C, G, T) found in DNA and then RNA. DNA defines the structure and function of an organism and contains the complete genetic information. Using the genetic code of the DNA, according to central dogma of molecular biology proteins are formed. In recent years, it has been suggested that our emotions are molecules. The peptides connect to human emotions that influence every move, function and thought. The peptides as information substances bring the messages to all our body cells. In this paper, we present recent advances in genetic code-based matrices generated by RNA bases (A, C, G, U) and then draw a parallel of matrices of emotions generated by primary emotions (Sadness, Happiness, Anger, Fear) = (S, H, A, F) along with facial expressions of markers. This parallel shows a similarity connection between universal genetic codes and the universality of facial expressions for emotions. We further show that the frequency of 64 compound emotions/facial expression markers follow a law of normal distribution. © 2018, Springer International Publishing AG.","facial expressions; Genetic code; genetic matrix; human emotions; matrix of human emotions","Biomedical engineering; Codes (symbols); DNA; Gene encoding; Genes; Molecular biology; Normal distribution; Nucleic acids; Peptides; Proteins; RNA; Body cells; Central dogma of molecular biologies; Facial Expressions; Genetic code; Genetic information; Human emotion; Matrix representation; C (programming language)",2-s2.0-85028657880
"Smiari P., Bibi S., Stamelos I.","Knowledge acquisition during software development: Modeling with anti-patterns",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030677165&doi=10.1007%2f978-3-319-64161-4_4&partnerID=40&md5=36f1e3c7653b636328d430a8d323010e","Knowledge is a strategic resource; that should be timely acquired and exploited to manage and control software development. Software development is a knowledge intensive process characterized by increased uncertainty, presenting large variations among different development environments. Project uncertainty and volatility confounds the traditional knowledge-based processes since at any time traditional software project management techniques and patterns may be considered out of scope. In this chapter a dynamic and constantly adaptive knowledge encapsulation framework is presented. This framework analytically describes (a) metric collection methods along with metrics that attribute to knowledge creation regarding successful software development (b) representation mechanisms of the knowledge created in the form of anti-patterns (c) Bayesian Network analysis technique for converting the data to knowledge allowing inference mechanisms for testing the applicability of the anti-pattern. The presented approach is demonstrated into a case study showing both its feasibility and applicability. © 2018, Springer International Publishing AG.",,"Bayesian networks; C (programming language); Design for testability; Knowledge based systems; Knowledge engineering; Knowledge management; Potassium compounds; Project management; Software engineering; Software testing; Statistical tests; Development environment; Inference mechanism; Knowledge creations; Knowledge intensive process; Project uncertainty; Representation mechanism; Software project management; Traditional knowledge; Software design",2-s2.0-85030677165
"Deniziak S., Michno T.","Query-by-Shape interface for content based image retrieval based on shape analysis",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028616927&doi=10.1007%2f978-3-319-62120-3_14&partnerID=40&md5=7a30d494826c14131155f98c444fa0bf","The paper presents a novel Content-Based Image Retrieval interface. The method decompose an object int a set of features. Each feature may consist of a colour, a texture or a shape with attributes representing additional information (e.g. a the type of material from which it is made). During the query process a graph of object is compared with graphs stored in the database. One of the main advantages of our approach is that there is no need of a full knowledge about the searched object. The interface which we propose allow users to draw a query with a defined set of basic shapes. Some users may also need objects which are not the same as searched object, therefore two results sets should be returned. The prototyped application written in Python and C++ was prepared in order to perform experiments. © Springer International Publishing AG 2018.",,"C++ (programming language); Image retrieval; Query processing; Basic shapes; Content based image retrieval; Query by shape; Shape analysis; Content based retrieval",2-s2.0-85028616927
"Hao X., Zhou Q., Liu Z.","Experiment study of weight-bearing walking fatigue of human body based on ECG signal characteristics",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028698298&doi=10.1007%2f978-981-10-6232-2_32&partnerID=40&md5=06bb7a7e9305ff6bc0951d430fe1c259","To discuss the judgment for the variation of the human body fatigue under the weight-bearing walking condition and based on the characteristics of the indexes of heart rate, heart rate variability, etc., the paper uses the LabVIEW software to realize the preprocessing of ECG signals, detection of R wave, and HRV analysis, which is based on confirming the relativity of the ECG signal index and human body weight-bearing fatigue. Results indicate through the analysis of ECG characteristic indexes, with the increase of the weight-bearing walking time and the increase of the human body fatigue, HRmean, RMSSD, HFnorm, LF/HF, and sample entropies clearly change, wherein HRmean, HFnorm, LF/HF, and sample entropies are sensitive to the fatigue variation, and then does the RMSSD. The principal component analysis (PCA) method is used for establishing the ECG comprehensive index which is the basis for judging that under the condition of the weight-bearing walking experiment of the paper, the volunteers are clearly fatigue in stage 3, and the fatigue is significantly increased in stage 5. © Springer Nature Singapore Pte Ltd. 2018.","ECG; HRV; LabVIEW; Weight-bearing walking","Computer programming languages; Electrocardiography; Entropy; Heart; Systems engineering; Comprehensive indices; Experiment study; Heart rate variability; Human bodies; Lab-view softwares; LabViEW; Sample entropy; Weight bearing; Principal component analysis",2-s2.0-85028698298
"Babichev D.","Development of geometric descriptors for gears and gear tools",2018,"Mechanisms and Machine Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023607183&doi=10.1007%2f978-3-319-60399-5_11&partnerID=40&md5=c931aea5c9d85939e84405b2d42cb3b0","Important parameters of a gear tool are values of deflection of the machined surface at its different points, appearing due to errors of tool set-up, its re-sharpening and so on. An important parameter of a gear is its sensitivity to variation in the mutual arrangement of links appearing at gear assembly and due to deformations by loads and temperature influence. It is almost impossible for a production engineer, designer, product assembler or repairman to find this information; it can be obtained through complicated computer-aided analysis, individually tailored to each specific tool and gear. The place for keeping this information may be geometric descriptors of tools and gears proposed in this paper. The geometric descriptor will allow the manufacturers to solve multiple complex tasks quickly and reliably: (a) to obtain the proper location of the bearing contact in a gear; (b) to estimate the behavior of the bearing contact and the value of cyclic variations of the gear ratio when a gear is operated; (c) to assign deviations in tool-setting parameters in order to compensate for organic errors in the re-sharpening of tool front surfaces; (d) to determine the re-sharpening parameters in order to decrease organic errors in re-sharpening or obtain the required modification of tooth surfaces and other tasks. Theoretical basics for creating geometric descriptors are kinematic methods of the classical theory of gearing, developed later in the theory of real gearing. Choosing the most valuable references for development of geometric descriptors, we have to list works [11–20, 22–24]. The previous theoretical works written by the author are essentially useful for computer-aided design of generating processes, which precedes the development of geometric descriptors [2–4, 6, 7]. In these works, investigations of generating processes are carried out through applying: (i) the concepts of fans, wedges and bunches of normal lines [2–4, 7] (one can determine surfaces generated by jogs on generating solids, including those of secondary cutting); (ii) multi-parametric enveloping [2] (surfaces of shear are determined within tool supply and withdrawal); (iii) interrelated systems of curvilinear coordinates: integral, natural, unified, regulated [3] (one can even describe the geometry of all cutting edges for any edge-type tool as a continuous, smooth surface differentiable at all points with two unified regulated curvilinear coordinates on it [7]). The paper also presents: (a) analysis of features for gear machining cutting by edge-type tools and requirements for the geometry of operating flanks of teeth; (b) specification of types of geometric descriptor (paper, computer-aided and combined) and of tasks solved by their means; (c) statement of theoretical basics of development of geometric descriptors; (d) approximate contents of works on development of a system of geometrical descriptors for tools and gears; (e) theoretical investigations and specification of developed computer-aided programs aimed at development of geometrical descriptors; (f) results of computer-aided simulation through these programs for generation of helical surfaces by solids of revolution, i.e., fundamentals of geometric descriptors for disk-type cutters and disks for profile grinding; (g) structure of paper geometric descriptors and basic components of one sheet of such a descriptor. The present paper does not provide examples of geometric descriptors for specific tools and gears. © 2018, Springer International Publishing Switzerland.","Gear; Geometric descriptor; Geometry of meshing; Machine-tool meshing; Theory of generation","C (programming language); Computer aided analysis; Computer aided design; Computer operating systems; Cutting tools; Errors; Gear cutters; Gear cutting; Gear teeth; Gears; Grinding (machining); Helical gears; Machinery; Sensitivity analysis; Specifications; Wheels; Computer aided simulations; Curvilinear coordinate; Cyclic variations; Geometric descriptor; Sensitivity to variations; Temperature influence; Theoretical investigations; Theory of generation; Geometry",2-s2.0-85023607183
"Charubin T., Nowicki M., Szewczyk R.","Measurement system for magnetic field sensors testing with earth’s magnetic field compensation",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029213888&doi=10.1007%2f978-3-319-65960-2_76&partnerID=40&md5=286bd8127a7ab749aa3cbd8767817df9","The design and construction of a measurement system for magnetic field sensors testing with a maximum induction range of 10 mT was described. In order to verify the uniformity of the magnetic field, the distribution of the field in the measurement area was measured. Main goals of the construction were: the ability to compensate for the Earth’s magnetic field and high uniformity of the generated field in the working area of the system. Therefore, a coil arrangement similar to the Helmholtz coils was used. The study also includes the design of the software realized in LabView environment. © 2018, Springer International Publishing AG.","Helmholtz coil; Magnetic field sensors; Measurement system","Computer programming languages; Magnetic fields; Magnetic sensors; Magnetism; Magnetometers; Design and construction; Helmholtz coil; High uniformity; LabViEW; Magnetic field sensors; Measurement system; Working areas; Magnetic field measurement",2-s2.0-85029213888
"Dang Q., Li W., Guo D., Ning S., Wang X.","Designed on operation and management system for aerospace TT&C station",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028328738&doi=10.1007%2f978-981-10-4837-1_47&partnerID=40&md5=b9b901f7b8c3b3df19bdc4863fd5d99a","According to the status quo of TT&C equipment, communication equipment, meteorological equipment, service support equipment vertical management, node management dispersed, and the running status cannot be real-time acquired within the TT&C station domain, the TT&C station operation management system is designed and developed, including the TT&C Equipment Protocol Conversion Software, the Meteorological Operation Management Software, the Service Operation Management Software, the TT&C Information Check and Test Software, the Comprehensive Information Management Software and the Integrated Status Revelation Software, realized the hierarchical management model of the running status acquisition, data processing, information display and fault alarming of four professional domain equipment in TT&C station management domain, established the standardized TT&C station management system, standardized the tracking process of TT&C station, realized the whole process management from mission starting, equipment calibration, tracking and capturing to the analysis of data quality, improved the TT&C station management quality and the automation operation efficiency. © Tsinghua University Press, Beijing and Springer Nature Singapore Pte Ltd. 2018.","Architecture; TT&C equipment; TT&C station; TT&C station operation and management","Architecture; Computer software selection and evaluation; Data communication equipment; Data handling; Equipment; Information management; Software testing; Automation operation; Communication equipments; Comprehensive information; Hierarchical management; Operation and management; Operation management; Station operations; Whole process managements; C (programming language)",2-s2.0-85028328738
"Zhang T., Ke L., Li J., Li J., Huang J., Li Z.","Metaheuristics for the tabu clustered traveling salesman problem",2018,"Computers and Operations Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026413102&doi=10.1016%2fj.cor.2017.07.008&partnerID=40&md5=6fed8cf2d86831383597c604d3dd1a4b","This paper considers a new variant of traveling salesman problem (TSP), called tabu clustered TSP (TCTSP). The nodes in TCTSP are partitioned into two kinds of subsets: clusters and tabu node sets, then the salesman has to visit exactly one node for each tabu node set and ensures that the nodes within a same cluster are visited consecutively, and the problem calls for a minimum cost cycle. The TCTSP can be used to model a class of telemetry tracking and command (TT&C) resources scheduling problem (TTCRSP), the goal of which is to efficiently schedule the TT&C resources in order to enable the satellites to be operated normally in their designed orbits. To solve it, two metaheuristics combined with path relinking are proposed. The one is Ant Colony Optimization (ACO) and the other is Greedy Randomized Adaptive Search Procedure (GRASP). The proposed algorithms are tested on the benchmark instances and real-life instances of the TTCRSP. The computational results show that the hybrid ACO with two path relinking strategies works the best among the studied metaheuristics in terms of solution quality within the same computational time. © 2017 Elsevier Ltd","Ant Colony Optimization; Greedy Randomized Adaptive Search Procedure; Metaheuristics; Tabu clustered traveling salesman problem; TT&C resources scheduling problem","Ant colony optimization; Artificial intelligence; Benchmarking; C (programming language); Heuristic algorithms; Optimization; Scheduling; Ant Colony Optimization (ACO); Clustered traveling salesman problems; Computational results; Computational time; Greedy randomized adaptive search procedure; Meta heuristics; Resources scheduling; Solution quality; Traveling salesman problem",2-s2.0-85026413102
"Shimada K., Noguchi S., Makino M., Naito T.","Exceptional association rule set mining from oral health assessment database",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030779640&doi=10.1007%2f978-3-319-67792-7_42&partnerID=40&md5=70e56f8995be80d14a1aca604a93f9c7","This paper proposes an extended method to discover exceptional association rule sets from incomplete databases. The proposed method calculates an odds ratio directly for the rule evaluation. The exceptional rule set is defined as each itemset X, Y has a weak or no statistical relation to class C, respectively; however, the join of X and Y has a strong relation to C. The exceptional rule set has potential to interpret long rules for the join of X and Y. The proposed method is applied to rule mining for oral health assessment databases. We obtained interesting exceptional rule sets and the results showed effectiveness of the method in the medical and health care fields. © 2018, Springer International Publishing AG.","Association analysis; Association rule; Evolutionary computation; Missing value","Association rules; Database systems; Evolutionary algorithms; Association analysis; Missing values; Odds ratios; Oral healths; Rule evaluation; Rule mining; Rule set; Statistical relations; C (programming language)",2-s2.0-85030779640
"Hu J., Xu H., Li T., Liu T., Yang H.","Discussion on networked and integrated space-ground information system",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028342606&doi=10.1007%2f978-981-10-4837-1_1&partnerID=40&md5=6732cf319d3a4488810e8426e1451b8f","For application needs of effective information delivery and exchange between space and ground network nodes in space-ground network, an integrated multi-function common platform based on information integration technology is implemented and a resource pool for space-based and ground systems is constructed using software defined network (SDN) architecture, network protocol, and route gateway in order to remove information block caused by physical border around nodes within network. It’s an integrated space-ground information system with function and physical resources virtualization and intelligent information flow. It enables improvement of space-based information resource utilization, information tailoring by demand and effective information sharing capability. Based on space-based information system development trends, application advices and development focus of integrated space-ground information system are proposed, and key technical development directions are discussed. © Tsinghua University Press, Beijing and Springer Nature Singapore Pte Ltd. 2018.","Cloud computing; Integration; Multi-function common platform; Networking; Resource pool; Software defined everything (SDX); Space-based information system; TT&C","Application programs; C (programming language); Cloud computing; Gateways (computer networks); Information analysis; Information systems; Integral equations; Integration; Network architecture; Network protocols; Common platform; Ground information systems; Information integration; Intelligent information; Networking; Resource pool; Space based information systems; Technical development; Distributed computer systems",2-s2.0-85028342606
"Zhu Y.","C2 positivity-preserving rational interpolation splines in one and two dimensions",2018,"Applied Mathematics and Computation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028527941&doi=10.1016%2fj.amc.2017.08.026&partnerID=40&md5=432e2b46ce64b21e3576bd8ae7c7f350","A class of rational quartic/cubic interpolation spline with two local control parameters is presented, which can be C2 continuous without solving a linear system of consistency equations for the derivative values at the knots. The effects of the local control parameters on generating interpolation curves are illustrated. For C2 interpolation, the given interpolant can locally reproduce quadratic polynomials and has O(h2) or O(h3) convergence. Simple schemes for the C2 interpolant to preserve the shape of 2D positive data are developed. Moreover, based on the Boolean sum of quintic interpolating operators, a class of bi-quintic partially blended rational quartic/cubic interpolation surfaces is also constructed. The given interpolation surface provides four local control parameters and can be C2 continuous without using the second or higher mixed partial derivatives on a rectangular grid. Simple sufficient data dependent constraints are also derived on the local control parameters to preserve the shape of a 3D positive data set arranged over a rectangular grid. © 2017 Elsevier Inc.","Approximation order; Convergence analysis; Positivity-preserving; Rational interpolation","C (programming language); Linear systems; Approximation orders; Convergence analysis; Interpolation curves; Interpolation surfaces; Partial derivatives; Positivity preserving; Quadratic polynomial; Rational interpolation; Interpolation",2-s2.0-85028527941
"Li G.-Y., Li A.-Q., Zhang H., Wang J.-P., Chen S.-Y., Liang Y.-H.","Theoretical study of the CO formation mechanism in the CO2 gasification of lignite",2018,"Fuel",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029715123&doi=10.1016%2fj.fuel.2017.09.030&partnerID=40&md5=c05f3fd84bf541d950c9bbea7e08380a","Reactive force field (ReaxFF) molecular dynamics simulations of lignite and lignite-CO2 models were performed to investigate the CO formation mechanism of CO2 gasification process of lignite. A C++ program was developed to assess ReaxFF trajectories and to analyze elementary reactions involved in the mechanism. Calculated product distribution and relative amounts of main gas products show good agreement with reported experimental observations. We found that the CO formation pathways in the CO2 gasification of lignite begin with the chain carbon radical (Rn), which is formed by C–H/C–C bond cleavage reactions of aromatic moieties in the lignite or produced semicoke at high temperatures. These chain carbon radicals can react with CO2, forming oxidized carbon radicals, such as Rn-O-C-O, Rn-CO2 and Rn-O. Among these radicals, Rn-O and Rn-O-C-O are important precursors of CO. They produce CO molecules by releasing their C-O moieties at the end. The thermodynamic properties of these elementary reactions were obtained by density functional theory calculations at the B3LYP/6-311 + G(2d,2p) level. The calculated overall enthalpy and entropy changes could clearly explain the experimental data. The density functional theory results show that most of these elementary reactions are endothermic and entropy increasing. High gasification temperatures are favorable for the reactions. © 2017 Elsevier Ltd","Carbon transformation; CO; CO2 gasification; Lignite; Mechanism","C++ (programming language); Carbon dioxide; Chains; Chemical bonds; Cobalt; Computer software; Entropy; Gasification; Lignite; Mechanisms; Molecular dynamics; Reaction kinetics; Thermodynamic properties; Bond cleavage reaction; CO2 gasification; Elementary reaction; Gasification temperatures; Molecular dynamics simulations; Product distributions; Reactive force field; Theoretical study; Density functional theory",2-s2.0-85029715123
"Qasem N.A.A., Ben-Mansour R.","Energy and productivity efficient vacuum pressure swing adsorption process to separate CO2 from CO2/N2 mixture using Mg-MOF-74: A CFD simulation",2018,"Applied Energy",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032731463&doi=10.1016%2fj.apenergy.2017.10.098&partnerID=40&md5=5653ba0ead6b39b6be8bdbc97b517e9b","Quantitatively, carbon dioxide is the main gas emitted from the burning of fossil fuels; thus, it is the primary contributor to global warming. However, climate change could be mitigated using “carbon capture and storage” (CCS) methods. CO2 separation by physical adsorption is a promising technology to achieve CO2 capture with minimum energy costs. Mg-MOF-74 is a distinguished adsorbent amongst porous materials owing to its high CO2 uptake under flue gas conditions. In this study, a vacuum pressure swing adsorption (VPSA) process composed of five steps (pressurization, feed, rinse, blowdown, and purge) for separating CO2 from a CO2/N2 mixture using Mg-MOF-74 was mathematically modeled. Two- and three-dimensional computational fluid dynamics (CFD) models were developed using a user-defined-function (UDF, written in C) linked to the ANSYS Fluent program. The models have been validated against published pressure swing adsorption experimental data. The regeneration (blowdown and purge) time has been tuned to explore the performance improvement for the VPSA process. The key optimum performance indices for VPSA in terms of CO2 purity, recovery, productivity, and process power consumption were found to be 95.3%, 94.8%, 0.50 kg_CO2 h−1 kg_MOF−1, and 68.71 kW h tonne_CO2 −1, respectively. The corresponding operating carbon capture cost has been evaluated as $6.87 tonne_CO2 −1 for a 500-MW post-combustion power plant. These CO2 productivity and power consumption performances represent a significant enhancement in CO2 separation using physical adsorption technology compared to those reported in the literature. © 2017 Elsevier Ltd","Adsorption; Carbon capture; Carbon-dioxide; CFD; Mg-MOF-74; Separation; VPSA","Adsorption; C (programming language); Carbon capture; Climate change; Computational fluid dynamics; Digital storage; Electric power utilization; Fluidized bed combustion; Fossil fuels; Gas adsorption; Global warming; Magnesium compounds; Mixtures; Porous materials; Productivity; Separation; Minimum energy costs; Optimum performance; Physical adsorption; Pressure swing adsorption; Three dimensional computational fluid dynamics; User Defined Functions; Vacuum pressure swing adsorptions; VPSA; Carbon dioxide",2-s2.0-85032731463
"Patel A., Singh R., Patel J., Kapadia H.","Industrial internet of thing based smart process control laboratory: A case study on level control system",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028443485&doi=10.1007%2f978-3-319-63645-0_21&partnerID=40&md5=ed862e7e5960c37b65f33f4d611367e2","This paper tells us about the smart process control laboratory in which the concept of industrial internet of things (IIOT) is implemented on laboratory-scale trainer kit. A case study of level control trainer is discussed along with implementation and results. PID control algorithm is implemented in order to control level of water in the tank. Today, IIoT is an emerging technology that brought the control and automation on the platform of IoT, i.e., the control and monitoring of sensors and actuator is done from remote location. This example is relatively for home automation where the mobile devices comes into the picture. The device challenges and requirements of the systems are discussed. The software platform chosen is NI LabVIEW through which the application data dashboard is used in mobile devices to communicate with the process computer. © Springer International Publishing AG 2018.","Data dashboard; Internet of things; Laboratory scale trainer kit; LabVIEW; PID","Application programs; Computer programming languages; Intelligent systems; Internet of things; Laboratories; Level control; Leveling (machinery); Research laboratories; Three term control systems; Control and automation; Control and monitoring; Control Laboratory; Data dashboard; Emerging technologies; LabViEW; Sensors and actuators; Software platforms; Process control",2-s2.0-85028443485
"Bekker T.B., Rashchenko S.V., Seryotkin Y.V., Kokh A.E., Davydov A.V., Fedorov P.P.","BaO−B2O3 system and its mysterious member Ba3B2O6",2018,"Journal of the American Ceramic Society",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029217791&doi=10.1111%2fjace.15194&partnerID=40&md5=29cb09230f972d1743c6948cdeceee04","The first systematic study of the BaO–B2O3 system and barium orthoborate Ba3B2O6 (3BaO·B2O3) was reported in 1949. Thereafter, the system was repeatedly refined but the structure of Ba3B2O6 compound has not been adequately studied yet. In our study we have, for the first time, obtained the crystalline samples of Ba3B2O6. The solved structure (Pbam, a = 13.5923(4) Å, b = 13.6702(4) Å, c = 14.8894(3) Å) belongs to the class of ‘anti-zeolite’ borates with a pseudotetragonal [Ba12(BO3)6]6+ cation pattern which contains channels along the c axis filled with anionic clusters. The Ba3B2O6 compound may be regarded as a fluorine-free end-member of the Ba3(BO3)2– xF3x solid solution. The BaO–B2O3 phase diagram presented in our study is based on our research and literature data. © 2017 The American Ceramic Society","Borates; boron oxide; crystals/crystallization; phase diagrams; structure","Crystal structure; Phase diagrams; Structure (composition); Anionic clusters; Borates; Boron oxides; Crystalline samples; Fluorine-free; Literature data; Systematic study; C (programming language)",2-s2.0-85029217791
"Medeiros R.L.D.S., Souza S.O., Araújo R.G.O., da Silva D.R., Maranhão T.D.A.","Chlorine determination via MgCl molecule in environmental samples using high resolution continuum source graphite furnace molecular absorption spectrometry",2018,"Talanta",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029373157&doi=10.1016%2fj.talanta.2017.08.026&partnerID=40&md5=b39c05a9089afc85931087bc06a20ba2","This paper describes a method development for chlorine determination through the formation of MgCl molecule, applied for the first time for Cl quantification, by high resolution continuum source graphite furnace molecular absorption spectrometry (HR-CS GF MAS) in environmental samples. Pyrolysis and vaporization temperatures were optimized as well as the use of chemical modifier. Determinations were carried out at the wavelength of 377.010 and the compromise conditions of the graphite furnace temperature program were 500 °C and 2500 °C for pyrolysis and vaporization, respectively, using 10 µg of chemical modifier Pd. The concentration of reactants for the generation of MgCl molecule was optimized through Box-Behnken experimental design, using MgCl2 solution as source of chlorine. The optimum values according to the surface response were 5 g L−1 Mg, 25 mg L−1 of chlorine and 2% v v−1 of HNO3, condition in which the amount of Mg is at least 200 times higher than that of chloride. This excess of the forming agent ensures the complete formation of MgCl molecular species, since Cl is the limiting reactant. Certified reference materials, BCR 182 and NIST 8414, and addition and recovery tests were used to evaluate the accuracy of the method and good results were achieved at a 95% confidence level. The method was applied to direct determination of Cl in five produced water samples from offshore oil wellbore, high complex matrix, whose conventional methods require tedious treatment before the analysis. © 2017","Chemical modifier; Chlorine determination; HR-CS MAS; MgCl","Absorption spectroscopy; C (programming language); Chlorine; Cracking (chemical); Furnaces; Graphite; Molecules; Offshore boreholes; Offshore oil wells; Oil wells; Palladium; Produced Water; Pyrolysis; Spectrometry; Vaporization; Box-Behnken experimental design; Certified reference materials; Chemical modifiers; Chlorine determination; HR-CS MAS; MgCl; Molecular absorption spectrometry; Vaporization temperature; Chlorine compounds",2-s2.0-85029373157
"Batra A.K., Currie J.R., Alomari A.A., Aggarwal M.D., Bowen C.R.","A versatile and fully instrumented test station for piezoelectric energy harvesters",2018,"Measurement: Journal of the International Measurement Confederation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029391348&doi=10.1016%2fj.measurement.2017.08.038&partnerID=40&md5=61a87643fdf52af24b585934b56f9696","This paper describes the implementation of LabVIEW software to control instruments and acquire data from a piezoelectric energy harvesting test station which is based on a cantilever structure. The experiment is run in the Clean Energy Laboratory on the Ambient Energy Harvester Test Station. A digital multimeter, a programmable resistance selector, an arbitrary waveform generator, a shaker table, an accelerometer and a laser displacement sensor are used to control and acquire data in terms of harvested energy as a function of vibration frequency and load resistance. LabVIEW software is used to control the test station which makes near real-time data measurements, displays waveforms on a PC screen, and stores data for later analysis. Acquired waveforms are presented in terms of frequency versus voltage of the vibrating cantilever at preselected ranges of load resistances in terms of either AC or DC voltages. The vibration of the cantilever beam is measured with an accelerometer and beam movement is measured with a laser displacement meter. Test results are stored in a comma separated variable text file which can be imported into any data analysis software package. All experiments are performed on an isolated optical bench to avoid interference from mechanical noise that may exist in the surrounding environment. The system provides an integrated approach to characterize key performance indicators for energy harvesting materials and devices. © 2017 Elsevier Ltd","Cantilever; LabVIEW; Piezoelectric energy harvesting","Accelerometers; Benchmarking; Computer programming languages; Nanocantilevers; Piezoelectricity; Software testing; Testing; Arbitrary waveform generator; Cantilever; Key performance indicators; LabViEW; Laser displacement meter; Laser displacement sensors; Piezoelectric energy harvesters; Piezoelectric energy harvesting; Energy harvesting",2-s2.0-85029391348
"Grebe A., Leveling A., Lu T., Mokhov N., Pronskikh V.","The MARS15-based FermiCORD code system for calculation of the accelerator-induced residual dose",2018,"Nuclear Instruments and Methods in Physics Research, Section A: Accelerators, Spectrometers, Detectors and Associated Equipment",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032037190&doi=10.1016%2fj.nima.2017.08.055&partnerID=40&md5=4e153fe394bd1fce7f80a756c3051ff3","The FermiCORD code system, a set of codes based on MARS15 that calculates the accelerator-induced residual doses at experimental facilities of arbitrary configurations, has been developed. FermiCORD is written in C++ as an add-on to Fortran-based MARS15. The FermiCORD algorithm consists of two stages: 1) simulation of residual doses on contact with the surfaces surrounding the studied location and of radionuclide inventories in the structures surrounding those locations using MARS15, and 2) simulation of the emission of the nuclear decay γ-quanta by the residuals in the activated structures and scoring the prompt doses of these γ-quanta at arbitrary distances from those structures. The FermiCORD code system has been benchmarked against similar algorithms based on other code systems and against experimental data from the CERF facility at CERN, and FermiCORD showed reasonable agreement with these. The code system has been applied for calculation of the residual dose of the target station for the Mu2e experiment and the results have been compared to approximate dosimetric approaches. © 2017 Elsevier B.V.","MARS15; Monte-Carlo; Residual activation","Codes (symbols); Monte Carlo methods; Code system; Experimental facilities; Gamma quanta; MARS15; Nuclear decays; Radionuclide inventories; C++ (programming language)",2-s2.0-85032037190
"del Val L., Machimbarrena M., Herráez M., Monteiro C., Johansson R.","Translation between existing and proposed harmonized impact sound insulation descriptors and alignment within a proposed common acoustic classification scheme for buildings",2018,"Applied Acoustics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026921755&doi=10.1016%2fj.apacoust.2017.07.025&partnerID=40&md5=d34129f3f480b6df5f58cc277ca85f46","An international standard defining a common acoustic classification scheme for dwellings is under development by ISO TC43/SC2/WG29, based on the outcomes of the European project COST Action TU0901. The proposal offers an opportunity for countries to establish building acoustic requirements using a harmonized set of descriptors. This harmonized set considers the possibility of using impact sound insulation descriptors including the impact spectrum adaptation term CI or not. Furthermore, it also considers the possibility of using different frequency ranges for the impact spectrum adaptation term, CI50 and CI100. In order to evaluate the potential effect of such changes, it is necessary to provide translation equations between existing and proposed harmonized descriptors. The main objective of this paper is to provide, based on a statistical analysis of a large experimental data set, a translation equation for each pair (existing/proposed) of selected impact sound insulation descriptors. Additionally, the paper aims at investigating if the obtained translation equations are independent of the building type, so the same statistical analysis has been performed with two separated databases including either only heavy floors or only light floors. From the first results, it is concluded that the obtained translation equations are dependent on the building type when different assessment frequency range and rating methods are considered in both descriptors. In spite of this conclusion and in order to provide a tool for estimating the potential consequences of adopting a different impact sound insulation descriptor, the existing impact sound insulation national requirements have been translated into two proposed harmonized descriptors (L′nT,w and L′nT,50) using the translation equation obtained using the full data set, that is, not considering the building type. Additionally, the translated requirements have been aligned within the acoustic classification scheme, which is being developed by ISO TC43/SC2/WG29. The results show that, if the proposed common acoustic classification scheme is adopted, the existing requirements would lie, as expected, mainly within classes C and D, although, in some countries with more permissive requirements, the new built dwellings would be ranked class E or even class F. There is only one country where the requirements are such that the new build dwellings would be classified as B, concerning impact sound performance. © 2017 Elsevier Ltd","Acoustic classification scheme; Building regulations; Descriptors; Impact sound insulation requirements","Acoustic waves; Architectural acoustics; Building codes; Buildings; C (programming language); Floors; Housing; Insulation; Sound insulating materials; Statistical methods; Acoustic classification; Building regulations; Descriptors; Different frequency; Impact sound insulation; International standards; Spectrum adaptation; Translation equations; Sound insulation",2-s2.0-85026921755
"Goto T., Nakahata R., Kirishima T., Yaku T., Tsuchida K.","A transducing system between Hichart and XC on a visual software development environment",2018,"Studies in Computational Intelligence",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020409785&doi=10.1007%2f978-3-319-60170-0_15&partnerID=40&md5=790f8631a612c716ccb46a54731a2ab0","In recent years, embedded systems have been widely used in various fields. However, the development burden of embedded systems tends to be high because they are complex. A visual development environment is one way to reduce this burden. We have already proposed a visual programming development environment for program diagrams called Hichart. In this paper, we describe a visual development environment for the XC language, which is a programming language for XMOS evaluation boards. © Springer International Publishing AG 2018.",,"Computer programming; Embedded systems; Software design; Evaluation board; Software development environment; Transducing; Visual development; Visual programming; Visual languages",2-s2.0-85020409785
"Zabawa P., Hnatkowska B.","CDMM-F – Domain Languages Framework",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029524403&doi=10.1007%2f978-3-319-67229-8_24&partnerID=40&md5=c5ce1c47a69d829d3f44612eb3a1bc27","Domain Specific Languages (DSLs) are mini-programming languages which enable their users to abstract from technical details and focus on business domain. DSLs can be used within a framework, i.e. platform for developing software applications. The paper presents such a framework called CDMM-F for building Java applications. The additional tools, prepared by the authors, support DSL definition. The constraints a DSL should fulfill to be CDMM-F compliant are thoroughly described in the paper, expressed in the form of the CDMM meta-meta-model and demonstrated in a case-study. The main advantage of proposed solution is meta-meta-model simplicity and high reusability of DSL elements. Once defined they can be connected in different configurations (contexts) according to the actual needs. The framework architecture that enables this feature is also presented. © 2018, Springer International Publishing AG.","Domain Specific Language; DSL; Framework; Meta-meta-model; Meta-model; Model; Modeling language",,2-s2.0-85029524403
"Obdalova O.A., Minakova L.Y., Tikhonova E.V., Soboleva A.V.","Insights into receptive processing of authentic foreign discourse by EFL learners",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030648672&doi=10.1007%2f978-3-319-67843-6_28&partnerID=40&md5=c5204fc47440753125b9a75c10a13243","Learning a foreign language nowadays is not just remembering words and grammar rules; it is a process of penetration into the hidden meaning of the message. Context plays a major role in the success of oral comprehension. This investigation looks at the issue of perception of authentic speech from the perspective of discourse approach. The authors study various factors influencing EFL learners’ comprehension of authentic English American speech. Our observations and empirical data have led us to believe that there are some major difficulties of comprehension in the level of discourse which include not only unknown words but also lack of cultural awareness and pragmatic competence. Problems arise when the learners cannot infer the right meaning of the utterance because their perception stays in the vocabulary or grammar level without integrating both linguistic and extra linguistic features of the context of communication. © 2018, Springer International Publishing AG.","Context; Cross-cultural communication; EFL learners; Foreign language discourse; Oral comprehension; Processing","Computer programming; Computer science; Processing; Context; Cross-cultural communication; EFL learners; Foreign language; Oral comprehension; Linguistics",2-s2.0-85030648672
"Bongir A., Attar V., Janardhanan R.","Automated quiz generator",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032696233&doi=10.1007%2f978-3-319-68385-0_15&partnerID=40&md5=461cb303010f793dfef4a38e38ae3a2d","Automated Quiz Generator (AQG) is an extension of the factual question generation system implemented by Michael Heilman, which is generic and therefore applicable to any given domain of discourse in natural language. The extensions mainly include the ability to make MCQs out of generated questions and ranking questions by interestingness of the sentence in the input text from which the respective question was generated. Besides, it has functionality to extract interesting trivia from Wikipedia articles of important entities in the input text. Being domain independent, this system relies on DBpedia - a database of structured content extracted from Wikipedia, the largest general reference work on the Internet. © Springer International Publishing AG 2018.",,"Computer programming; Computer science; Dbpedia; Domain independents; Generation systems; Interestingness; Natural languages; Wikipedia; Wikipedia articles; Intelligent systems",2-s2.0-85032696233
"Mazurkiewicz J.","Agent approach to network systems experimental analysis in case of critical situations",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020819043&doi=10.1007%2f978-3-319-59415-6_30&partnerID=40&md5=92ed37f11696974941cf2ef77fae9d1a","Paper presents the analysis and discussion of the network systems in case of the critical situation that happens during ordinary work. The formal model is proposed with the approach to its modeling based on the system behavior observation. The agent approach to constant network monitoring is given using hierarchical structure. The definition of the critical situation sets are created by reliability, functional and human reasons. The proposed method is based on specified description languages that can be seen as a bridge between system description and an analysis tools. Using a multilevel-agent based architecture the realistic data are collected. Analysis is done with a usage of open-source simulation environment that can be easily modified and extended for further work. Based on the simulation results, some alternatives can be chosen in case of system or service failure. This way it is possible to operate with large and complex networks described by various - not only classic – distributions and set of parameters. The presented problem is practically essential for organization of network systems. © Springer International Publishing AG 2018.","Critical sets; Dependability modeling; Network systems; Reliability","Computer programming; Computer science; Reliability; Agent based architectures; Critical sets; Dependability modeling; Description languages; Experimental analysis; Hierarchical structures; Network systems; Simulation environment; Complex networks",2-s2.0-85020819043
"Summers K., Pointer A., Cotton M.","Designing to include judges and inner-city tenants",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026314914&doi=10.1007%2f978-3-319-60597-5_14&partnerID=40&md5=f6f4844309fee2a1daf9e46a1fa28734","Between 2012 and 2015, an analysis of more than 300 rent escrow cases in the city of Baltimore revealed that neither judges nor plaintiffs in rent escrow cases understood or were correctly applying the relevant laws [1, 2]. Tenants didn’t understand the applicable laws or available remedies, and were unable to fill out their rent escrow applications accurately. Judges knew that the documents provided by tenants were probably filled out incorrectly, so they routinely ignored these documents. Thus, many rent escrow cases were decided based on established custom rather than on the facts of the case or relevant laws, and the results tended to favor landlords [1, 3]. A year of iterative design, testing, and re-design resulted in a rent escrow form that could (1) help tenants understand their options and provide accurate information to the court, and (2) provide judges with accurate information while simultaneously reinforcing their understanding of the applicable laws. © Springer International Publishing AG 2018.","Inclusive design; Legal forms; Low literacy; Plain language","Computer programming; Baltimore; Inclusive design; Iterative design; Low literacies; Plain language; Computer science",2-s2.0-85026314914
"Hayat K., Liu X.-C., Cao B.-Y.","Bipolar fuzzy BRK-ideals in BRK-algebras",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030762191&doi=10.1007%2f978-3-319-66514-6_1&partnerID=40&md5=e0af02dd6a1ab64b1b1b894f3768fdce","In this paper, we investigated bipolar fuzzy BRK-ideals in BRK-algebras and discussed related properties. We presented some results on images and pre-images of bipolar fuzzy BRK-ideals in BRK-algebras. Finally, we introduced translation, extension and multiplications of bipolar fuzzy BRK-ideals in BRK-algebras and discussed related results. © Springer International Publishing AG 2018.","Bipolar fuzzy BRK-ideal; BRK-algebra; Extensions; Images; Multiplications; Pre-images; Translations","Computer programming; Computer science; Translation (languages); Bipolar fuzzy BRK-ideal; Extensions; Images; Multiplications; Pre images; Algebra",2-s2.0-85030762191
"Popescu D.A., Bold N., Popescu A.I.","The generation of tests of knowledge check using genetic algorithms",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031397290&doi=10.1007%2f978-3-319-62524-9_3&partnerID=40&md5=7f6406c267100bd28fa6e0e92c8a9b57","In this paper, we will present a modality for generating knowledge-check tests using questions characterized by keywords. The obtained tests have certain restrictions regarding the keywords labeling the questions. These restrictions will be defined in the paper. The test generation will be made using genetic algorithms, whose chromosomes will be considered the tests and genes will be considered questions. At the end of the paper some results obtained with the algorithm implemented in Java programming language will be presented. © Springer International Publishing AG 2018.","Algorithm; Assessment; Chromosomes; Genetic; Learning","Algorithms; Chromosomes; Computer programming; Genetic algorithms; Soft computing; Assessment; Genetic; Learning; Test generations; Testing",2-s2.0-85031397290
"Kumari S., Gupta P.","Implementation of couchdbviews",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031401615&doi=10.1007%2f978-981-10-6620-7_24&partnerID=40&md5=4774eb7719ff711f38c76ac99cc2686e","Flexible data model and horizontal scalability are the need of contemporary era to handle huge heterogeneous data. This has lead to the popularity of NoSQL Databases. CouchDB is an admired and easy to use choice among NoSQL Document-Oriented databases. CouchDB is developed in Erlang language. CouchDB’s RESTful (Representational State Transfer) APIs (Application Programming Interface) make it special because they allow database access through http (Hyper Text Transfer Protocol) requests. This access in the form of HTTP requests is achieved with the help of command line utility Curl. The Futon, web-based utility of CouchDB, is also used to manage documents, databases, and replication in CouchDB. CouchDB uses a special type of system for querying data than traditional RDBMS (Relational Database Management Systems) i.e. views. This paper explains various unique features of CouchDB which distinguish it from RDBMS. It also includes implementation of temporary and permanent views using MapReduce. © 2018, Springer Nature Singapore Pte Ltd.","CouchDB; Curl; Futon; MapReduce; Views","Application programming interfaces (API); HTTP; Hypertext systems; Information management; Interface states; Query processing; Relational database systems; CouchDB; Curl; Futon; Map-reduce; Views; Big data",2-s2.0-85031401615
"Masche J., Le N.-T.","A review of technologies for conversational systems",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025125649&doi=10.1007%2f978-3-319-61911-8_19&partnerID=40&md5=182f15da5f62d07487bd4eb5c1514b66","During the last 50 years, since the development of ELIZA by Weizenbaum, technologies for developing conversational systems have made a great stride. The number of conversational systems is increasing. Conversational systems emerge almost in every digital device in many application areas. In this paper, we present the review of the development of conversational systems regarding technologies and their special features including language tricks. © Springer International Publishing AG 2018.",,"Computer programming; Computer science; Application area; Conversational systems; Review of technologies; Digital devices",2-s2.0-85025125649
"Afanasyev A., Voit N., Timofeeva O., Epifanov V.","Analysis and control of hybrid diagrammatical workflows",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031425155&doi=10.1007%2f978-3-319-68321-8_13&partnerID=40&md5=e09f77667a351ecb81ab843ba95b660d","The paper presents a method for analyzing hybrid project workflows based on the author’s RV-grammar by using BPMN as an example, as well as translations of such project workflows into languages describing business processes (e.g., BPEL with the author’s RVTt-grammar). The effectiveness of author’s grammars for hybrid project workflows’ analysis and translation at large design and manufacturing enterprises is assessed. © Springer International Publishing AG 2018.","Analysis; Diagrammatic workflows; Grammars; Translating","Computer programming; Computer science; Analysis; Analysis and controls; Business Process; Grammars; Large designs; Manufacturing enterprise; Translating; Work-flows; Industrial economics",2-s2.0-85031425155
"Caldarola E.G., Rinaldi A.M.","A multi-strategy approach for ontology reuse through matching and integration techniques",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027842434&doi=10.1007%2f978-3-319-56157-8_4&partnerID=40&md5=0e6b09a215222869fc8db74b3900b13f","The new revolutionary web today, the Semantic Web, has augmented the previous one by promoting common data formats and exchange protocols in order to provide a framework that allows data to be shared and reused across application, enterprise, and community boundaries. This revolution, together with the increasing digitization of the world, has led to a high availability of knowledge models, i.e., more or less formal representations of concepts underlying a certain universe of discourse, which span throughout a wide range of topics, fields of study and applications, mostly heterogeneous from each other at a different dimensions. As more and more outbreaks of this new revolution light up, a major challenge came soon into sight: addressing the main objectives of the semantic web, the sharing and reuse of data, demands effective and efficient methodologies to mediate between models speaking different languages. Since ontologies are the de facto standard in representing and sharing knowledge models over the web, this paper presents a comprehensive methodology to ontology integration and reuse based on various matching techniques. The approach proposed here is supported by an ad hoc software framework whose scope is easing the creation of new ontologies by promoting the reuse of existing ones and automatizing, as much as possible, the whole ontology construction procedure. © 2018, Springer International Publishing AG.","Ontology; Ontology integration; Ontology matching; Ontology reuse; Semantic network; WordNet","Computer programming; Computer software reusability; Integration; Semantic Web; Ontology integration; Ontology matching; Ontology reuse; Semantic network; Wordnet; Ontology",2-s2.0-85027842434
"Guda A.N., Ilicheva V.V., Chislov O.N.","Executable logic prototypes of systems engineering complexes and processes on railway transport",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031311765&doi=10.1007%2f978-3-319-68324-9_18&partnerID=40&md5=a21e802defe078b20c5813a5f421dca8","In this paper we examine software tools and design examples of executable logic prototypes for modelling of complex systems. The prototype is set by the specification in predicate calculus language. Semantics of specification supposes effectively realized interpretation whose result is a prototype and/or diagnosis of project errors. We use rapid prototyping techniques, the specification is easily modified. The approach provides three levels of logic modelling in the same programming environment: prototyping of static structure of a system, logic of processes, dynamic behaviour. Prototyping of structure and technological processes of freight terminal “Taganrog” has been chosen as an example. © 2018, Springer International Publishing AG.","Error diagnosis; Freight railway terminal; Logic language; Logic prototype; Predicate calculus","Calculations; Railroads; Semantics; Software prototyping; Specifications; Error diagnosis; Freight railways; Logic languages; Logic prototype; Predicate calculus; Computer circuits",2-s2.0-85031311765
"Zaragoza M.G., Lee R.Y., Kim H.-K.","Mobile development tools and method integration",2018,"Studies in Computational Intelligence",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026662252&doi=10.1007%2f978-3-319-64051-8_12&partnerID=40&md5=0178e1fb0861d4baec3e85582ccf6395","As to providing a common framework for a sound generic framework methods and integration tools, software development and distribution support management in the development process is needed in order to meet the required standards of mobile development. This paper supports technical software development activities, integrated software management, and software distribution management. It is used in the MTICASE environment (Method Tool Integration CASE) for the development of software distribution, and is extended to the configurations of heterogeneous components programmed in the programming languages differently. This article shows how a similar set of principles, practices, and programming tools can be combined with recent work by MetaObjects to provide a framework for methods and tools as well as configuration. © Springer International Publishing AG 2018.","Application domain; Configuration MetaObject; Framework",,2-s2.0-85026662252
"Święcicki B., Borzemski L.","How is server software configured? examining the structure of configuration files",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029521419&doi=10.1007%2f978-3-319-67220-5_20&partnerID=40&md5=fc3dcaa043f06acdb9796bb41f524f33","Contemporary software on servers is usually configured through editing configuration files. Surprisingly, to the extent of our knowledge, the diversity of configuration file formats remains unstudied. Our goal in this work is to determine what data structures are used in configuration files and what formats are being used to encode them, in order to have a foundation for semantic analysis of their contents in the future. We examine 14133 files in 3409 packages comprising the whole set of software available in Debian stable repositories that has configuration files in the/etc directory. After eliminating files that are not configuration (such as init scripts), we assign them to categories using various criteria, some of them being the data structure they express or whether the order of statements matter. In this examination we find that even custom configuration formats can usually be expressed using one of several commonly used data structures. Some software packages, however, are configured in a Turing-complete programming language, usually the same one that the configured program was written in, and are therefore unsuitable for static analysis. Regardless, we provide a taxonomy of configuration formats, and highlight common themes in custom formats used by various packages. Ultimately, we describe a data structure that is able to hold information about all of these configuration files for further analysis. © 2018, Springer International Publishing AG.","Configuration; Configuration management automation; Data modeling; Static analysis; System configuration",,2-s2.0-85029521419
"Achunala D., Sathiyanarayanan M., Abubakar B.","Traffic classification analysis using OMNeT++",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032621579&doi=10.1007%2f978-981-10-3376-6_45&partnerID=40&md5=3da3cdce785101c047f7700ecf6a9b84","There has been a lot of research on effective monitoring and management of the network traffic, where a large amount of internet traffic requires more accurate and efficient ways of traffic classification methods and approaches with an aim to improve network performance. In our research, we introduce the subject of packet classification in IP traffic analysis with a simple technique that relies on prototype classifier using OMNET++ (Optical Modelling Network using C++ programming language) which unfolds one new possibility for an online classification focusing on application detection in the absence of payload information. In this research, we evaluated our novel IATP (Inter-arrival time and precision) clustering algorithm with the help of OMNET++ scheduler for classification of network traffic. The analysis is based on the measure combined with inter-arrival time and precision which was able to distinguish fairly as a small different subset of clusters. With our implementation of a range of flow attributes, the simulation result demonstrates the effectiveness of 100% accuracy of classifying packets but does not constitute the same level of accuracy with real-time traffic classifier which operates under certain constraints. Accuracy for real-time traffic might normally varies from 80 to 95% and depends on the type of each application. Further study and heuristics are required for detecting much better methodologies for detecting applications with real-time traffic measurements. © Springer Nature Singapore Pte Ltd. 2018.","Clustering; k-means; OMNet++; Quality of service (QoS); Traffic classification",,2-s2.0-85032621579
"Elsayed D.H., Nasr E.S., El Ghazali A.E.D.M., Gheith M.H.","A new hybrid approach using genetic algorithm and q-learning for qos-aware web service composition",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029496479&doi=10.1007%2f978-3-319-64861-3_50&partnerID=40&md5=e48668ef71a36e715f87e8130e8a6708","Web Service composition (WSC) is a technology for building an application in Service Oriented Architecture (SOA). In WSC the sets of atomic Web services combine together to satisfy users’ requirements. Due to the increase in number of Web services with the same functionality and variety of Quality of Services (QoS), it became difficult to find a suitable Web service that satisfies the functional requirements, as well as optimizing the QoS. This has led to the emergence of QoS-aware WSC. However, to find an optimal solution in QoS-aware WSC is an NP-hard problem. In this paper, we propose a new approach that combines the use of Genetic Algorithm (GA) and Q-learning to find the optimal WSC. The performance of GAs depends on the initial population, so the Q-learning is utilized to generate the initial population to enhance the effectiveness of GA. We implemented our approach over the.NET Framework platform 4.7 using C# programming language. The experiment results show the effectiveness of our proposed approach compared to Q-learning algorithm and GA. © 2018, Springer International Publishing AG.","Genetic algorithm; Q-learning; Quality of Services; Web service composition",,2-s2.0-85029496479
"Pleshkova S., Bekiarski A.","Development of fast parallel algorithms based on visual and audio information in motion control systems of mobile robots",2018,"Intelligent Systems Reference Library",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032591050&doi=10.1007%2f978-3-319-67994-5_5&partnerID=40&md5=ab0f120ef9cb562046a4209f790a7108","Decision making for movement is one of the essential activities in motion control systems of mobile robots. It is based on methods and algorithms of data processing obtained from the mobile robot sensors, usually video and audio sensors, like video cameras and microphone arrays. After image processing, information about the objects and persons including their current positions in area of mobile robot observation can be obtained. The aim of methods and algorithms is to achieve the appropriate precision and effectiveness of mobile robot’s visual perception, as well as the detection and tracking of objects and persons applying the mobile robot motion path planning. The precision in special cases of visual speaking person’s detection and tracking can be augmented adding the information of sound arrival in order to receive and execute the voice commands. There exist algorithms using only visual perception and attention or also the joined audio perception and attention. These algorithms are usually tested in the most cases as simulations and cannot provide a real time tracking objects and people. Therefore, the goal in this chapter is to develop and test the fast parallel algorithms for decision making in the motion control systems of mobile robots. The depth analysis of the existing methods and algorithms was conducted, which provided the main ways to increase the speed of an algorithm, such as the optimization, simplification of calculations, applying high level programming languages, special libraries for image and audio signal processing based on the hybrid hardware and software implementations, using processors like Digital Signal Processor (DSP) and Field-Programmable Gate Array (FPGA). The high speed proposed algorithms were implemented in the parallel computing multiprocessor hardware structure and software platform using the well known NVIDIA GPU processor and GUDA platform, respectively. The experimental results with different parallel structures confirm the real time execution of algorithms for the objects and speaking person’s detection and tracking using the given mobile robot construction. © 2018, Springer International Publishing AG.","CUDA; GPU; Mobile robot; Motion control system; Parallel algorithm; Visual and audio decision making; Visual and audio perception and attention",,2-s2.0-85032591050
"Nalepa G.J.","Designing robot control logic with rules",2018,"Intelligent Systems Reference Library",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030623954&doi=10.1007%2f978-3-319-66655-6_16&partnerID=40&md5=6ffe511622291bef57ebc34ef08e718f","In this chapter we present the application of the SKE methods, to support the design of control logic for basic mobile robots implemented with LEGO Mindstorms. This work addresses the second generation of the LEGO hardware, also known as the NXT. A dedicated programming solution based on the Prolog language is described. On top of it the HeaRT rule engine is integrated. This allows for the use of XTT for the control of NXT. Examples of such control cases are presented. © 2018, Springer International Publishing AG.",,,2-s2.0-85030623954
"Gudwin R.R.","A hands-on laboratory tutorial on using CST to build a cognitive architecture",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028338815&doi=10.1007%2f978-3-319-63940-6_9&partnerID=40&md5=9c13027cfe608928bfb6b0b7bce83a88","In this tutorial laboratory, we provide a step-by-step set of programming experiments illustrating the main foundations of the CST Cognitive Systems Toolkit in building a cognitive architecture to work as an artificial mind for controlling an NPC (non-player character) in a 3D virtual environment computer game. We start by understanding the sensors and actuators available in the NPC and how to control it inside the game. Then, we introduce the main foundations of CST: Codelets and Memories, and how they should be used to integrate a cognitive architecture. Then, we start building specific codelets and memories for a simple instance of the CST Reference Cognitive Architecture and start using it to control the NPC. The lab is a hands-on programming lab, using Java and Netbeans as language/tool. © Springer International Publishing AG 2018.","Cognitive architecture; CST; Tutorial; Virtual environment",,2-s2.0-85028338815
"Qi T.Y., Lei B., Wang R., Li Y., Li Z.Y.","Solid-fluid-gas coupling prediction of harmful gas eruption in shield tunneling",2018,"Tunnelling and Underground Space Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028080100&doi=10.1016%2fj.tust.2017.08.014&partnerID=40&md5=e6f40ff7d6a71a1a8df0acffd6c4bd91","In some cities in the south of China, a stratum of explosive gas was often be encountered in shield tunneling, as well as in other countries. However there is no function of explosion-proof function in the shield machine, and it is likely to cause a large number of harmful gases gushing out instantaneously. The harmful gas concentration can exceed the safety alarm value and even lead to explosion. Based on the above issues, solid-fluid-gas three-phase coupling is analyzed with relevant theories and assumptions through FISH language programming in FLAC3D, which originally only has the solid-fluid two-phase coupling function. The prediction of harmful gas eruptions in shield construction is realized. On this basis, a set of real-time monitoring systems for the harmful gases is constructed, which realizes staff evacuation warnings. The research achievement has been successfully applied in a practical project. © 2017 Elsevier Ltd","Engineering protection; Harmful gas eruption; Shield tunnel; Solid-fluid-gas coupling","Real time systems; Shielding; Gas concentration; Harmful gas eruption; Practical projects; Real time monitoring system; Research achievements; Shield construction; Shield tunnel; Shield tunneling; Gases",2-s2.0-85028080100
"Cools S., Conradie P., Ciocci M.-C., Saldien J.","The diorama project: Development of a tangible medium to foster STEAM education using storytelling and electronics",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022207955&doi=10.1007%2f978-3-319-61322-2_17&partnerID=40&md5=7c3486f64e92ec7a07434694061deaf6","Children of the 21st century grow up in a world full of information and technology. Education should equip them with useful skills and competencies, allowing them to actively and effectively take part in a globalised society. Teachers feel the need for educational tools that support innovative teaching. To this end, this paper describes the development of The Diorama Project. This series of trans-disciplinary workshops combines familiar subjects, like language and art, with new topics such as programming and electronics, to foster valuable skills and knowledge in a more fun and tangible way. Pupils team up to write, record and tinker a story. Programmable electronics let their theatre plays come alive. An open source platform provides all the information for teachers to organise the workshops by themselves. They can use it to share their experience and knowledge with colleagues worldwide. © Springer International Publishing AG 2018.","21st century skills; Play; STEAM education","E-learning; Ecology; Ecosystems; Open source software; Regional planning; Teaching; 21<sup>st</sup> century skills; Educational tools; Information and technologies; Innovative teaching; Open source platforms; Play; Education",2-s2.0-85022207955
[No author name available],"AHFE 2017 International Conference on Human Factors, Software, and Systems Engineering, 2017",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026208035&partnerID=40&md5=a1c0e9261556d12769e087aa972f2116","The proceedings contain 19 papers. The special focus in this conference is on Human Factors, Software, and Systems Engineering. The topics include: Usage perspective development approach in the fuzzy front end; human factors approach to study border control automation impacts and needs; building the knowledge-based system of machining supplier matching; software cost estimation for user-centered mobile app development in large enterprises; assessing the effectiveness of emoticon-like scripting in computer programming; adaptive interface combined to interface patterns in human factors; a stochastic programming model for resource allocation with uncertainties and carbon emission constraints; body temperature monitoring system for slaughterhouse workers; efficient language model generation algorithm for mobile voice commands; the modeling of technological trade-off in battery system design based on an ergonomic and low-cost alternative battery technology; design of a secure location based service for mobile cloud applications; ground penetrating radar for measuring thickness of an unbound layer of a pavement; research on paper submission management system by using automatic text categorization; the key success factors in the development of platform-based business in china - case study on alibaba and jingdong.",,,2-s2.0-85026208035
[No author name available],"8th International Conference on Robotics in Education, RiE 2017",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029432322&partnerID=40&md5=223a355412801b45dd0ac68df9aaf9c5","The proceedings contain 29 papers. The special focus in this conference is on Robotics in Education. The topics include: Comprehensive educational robotics activities TechColleges; robotics peer-to-peer teaching summer school project involving university students, summer interns and middle school students; methods for managing student-driven robotics research; robotics education in saint petersburg secondary school; LEGO WeDO curriculum for lower secondary school; teaching robotics concepts to elementary school children; the effect of the programming interfaces of robots in teaching computer languages; creativity and contextualization activities in educational robotics to improve engineering and computational thinking; educational robotics for communication, collaboration and digital fluency; using robotics to foster creativity in early gifted education; designing robotics student projects from concept inventories; teaching research methodologies with a robot in a CS lab course; teaching robotics for computer science students; open source robotics course at engineering: infrastructure and methodology; architectural overview and hedgehog in use; open-source robotic manipulator and sensory platform; an elementary science class with a robot teacher; teaching robotics with cloud tools; needs, opportunities and constraints on the way to the wide introduction of robotics to teaching at secondary vocational schools; an open robotics environment motivates students to learn the key concepts of artificial neural networks and reinforcement learning.",,,2-s2.0-85029432322
[No author name available],"4th International KES conference on Smart Education and Smart e-Learning, SEEL 2017",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020419524&partnerID=40&md5=8bae7baba236b3f2c16f18e9871cf2c4","The proceedings contain 48 papers. The special focus in this conference is on Smart Education and Smart e-Learning. The topics include: Smart pedagogy for smart universities; information channel based measure of effectiveness of computer-assisted assessment in flipped classroom; efforts for upward spirals based on both teacher and student feedback on smart education; a serious game to promote environmental attitude; the development of the critical thinking as strategy for transforming a traditional university into a smart university; RLCP-compatible virtual laboratories with 3D-models and demonstration mode: development and application in e-learning; remote laboratory environments for smart e-learning; an automata model for an adaptive course development; algorithm of contextual information formation for smart learning object; information technologies in musical and art education of children; a SPOC produced by sophomores for their junior counterparts; an outcome-based framework for developing learning trajectories; a simple MVC-framework for local management of online course material; multi-agent smart-system of distance learning for people with vision disabilities; use of smart technologies in the e-learning course project management; approaches to the description of model massive open online course based on the cloud platform in the educational environment of the university; a half-duplex dual-lingual video chat to enhance simultaneous second language speaking skill; a recommender system for supporting students in programming online judges; eye tracking technology for assessment of electronic hybrid text perception by students and motivation of students and young scientists in robotics.",,,2-s2.0-85020419524
[No author name available],"AHFE 2017 International Conference on Human Factors in Training, Education, and Learning Sciences, 2017",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022211336&partnerID=40&md5=5d1ac73520f9a4a8d61b629a02057aac","The proceedings contain 42 papers. The special focus in this conference is on Human Factors in Training, Education, and Learning Sciences. The topics include: A learning assessment platform for adult; interactions between learner assessment and content requirement; a review of personal profile features in personalized learning systems; research on the effects of post-doctoral system on the university faculty in china; satisfaction and cognitive styles in students of the virtual collaborative project; detection system for distinguishing between initial reading and rereading of a digital document by observing focal point movement; early engagement of schoolchildren in research activities; ergonomic intervention using a train-the-trainer approach in a biotechnology company; educational effect using expert model in fire process of quartz glass; an intelligent system to automatically generate video-summaries for accessible learning objects for people with hearing loss; effectiveness of learning management system application in the learnability of tertiary students in an undergraduate engineering program in the Philippines; development of learning habit scale and situational analysis of Japanese junior high school student learning habits; competency-based training system for personalized learning; influences of mentoring functions on job satisfaction and organizational commitment of graduate employees; applying a constructive learning method in the virtual reality canine skeletal system; sign language trainer using leap motion; high-level context information for tasks in teaching and the positive effect of digital game based programming on students.",,,2-s2.0-85022211336
[No author name available],"World Engineering Education Forum and Global Engineering Deans Council, WEEF and GEDC 2016",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025808765&partnerID=40&md5=d598b2376f6ca62f458308ee420fec4a","The proceedings contain 27 papers. The special focus in this conference is on World Engineering Education Forum and Global Engineering Deans Council. The topics include: The empirical research on human knowledge processing in natural language within engineering education; study on interest and perception of value in multinational collaborative design projects among engineering students; the content and structure of code of ethics for engineers in china; introducing responsible resource management to the engineering education; recruiting and developing academic leaders; picking low hanging fruits - integrating interdisciplinary learning in traditional engineering curricula by interdisciplinary project courses; metacognitive development in engineering students through cooperative problem based learning; developing an internet-of-things based design course for engineering undergraduate students; motivating engineering students to engage in learning computer programming; the power of self-evaluation based cross-sparring in developing the quality of engineering programmes; theoretical foundations of vocational and technical education and the part they play in the process of state building; engineering challenges in terms of academic and professional training; perception of complex engineering problem solving among engineering educators; a subjective examination of implicit root stereotypes of STEM disciplines; leveraging professional networks for an equitable, smart society - a case study on the international federation of engineering education societies; an international study of faculty perceptions on communication development in engineering education and application of graph theory to analysing student success through development of progression maps.",,,2-s2.0-85025808765
[No author name available],"2nd International Conference on Information and Communication Technology for Intelligent Systems, ICTIS 2017",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028404555&partnerID=40&md5=3c3a976cbadbc5216c903724917addd7","The proceedings contain 147 papers. The special focus in this conference is on Information and Communication Technology for Intelligent Systems. The topics include: Design of high-speed LVDS data communication link using FPGA; face super resolution by tangential and exponential kernel weighted regression model; monitoring of distributed resources based on client-server (single-hop) mobile agents in homogeneous network of interconnected nodes; energy balanced clustering protocol using particle swarm optimization for wireless sensor networks; routing protocol for device-to-device communication in softnet towards 5G; a survey of computer vision based corrosion detection approaches; word sense ambiguity in question sentence translation; implementing a hybrid crypto-coding algorithm for an image on FPGA; realization of FPGA based PID controller for speed control of DC motor using xilinx sysgen; emerging trends in ADR; natural language interface for multilingual database; a simple and efficient text-based CAPTCHA verification scheme using virtual keyboard; outcome fusion-based approaches for user-based and item-based collaborative filtering; a practical perspective; financial time series clustering; financial time series clustering; challenges and research issues; simplified process of obstructive sleep apnea detection using ECG signal based analysis with data flow programming; smart two level k-means algorithm to generate dynamic user pattern cluster; notification of data congestion intimation [NDCI] for IEEE 802.11 adhoc network with power save mode; a case study on level control system and deep neural network based classification of tumourous and non-tumorous medical images.",,,2-s2.0-85028404555
"Wang X., Zang N., Liang P., Cai Y., Li C., Yang Z.","Identifying priority management intervals of discharge and TN/TP concentration with copula analysis for Miyun Reservoir inflows, North China",2017,"Science of the Total Environment",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026772341&doi=10.1016%2fj.scitotenv.2017.07.135&partnerID=40&md5=8c5c401c0e25521ed7f029115fb128f5","The quantitative environmental management of reservoir inflows is challenging due to complex coexistence relationships between water quantity and water quality variables. Taking discharge as a representative water quantity indicator, as well as total nitrogen (TN) and total phosphorus (TP) as water quality indicators for the twin rivers (i.e., the Chaohe and Baihe rivers) which run into the Miyun Reservoir in North China, this study calculated marginal probability distributions of these indicators, and analyzed the joint probability distribution of discharge and TN/TP concentration by applying the Frank copula function. According to an analysis of various scenario combinations of discharge and TN/TP concentration, the quantitative management intervals including the priority control interval, the key attention interval and the daily maintenance interval, were identified. The results were as follows: (a) a fitting degree evaluation indicated that the Pearson-III distribution for the marginal probability distribution of discharge and the lognormal distribution for that of TN/TP concentration were feasible. Additionally, the Frank copula theory was applicable for their joint probability analysis according to the applicability analysis and goodness-of-fit test; (b) regarding to the water quality of the Miyun Reservoir inflows, it is more important to enhance the control of the Chaohe River and the monitoring of TP concentration; and (c) the TN concentration within division values of discharge (i.e., 16.59, 24.14 m3/s) was tend to exceed the class III limitation of the Environmental Quality Standard for Surface Water in China, and the concentrations of TN and TP increased as the discharge increased for the two rivers. The quantitative management intervals based on copula analysis is an intuitive and effective solution for comprehensive risk management of reservoir inflows. © 2017 Elsevier B.V.","Copula analysis; Joint probabilities of discharge and TN/TP concentration; Priority management intervals; Reservoir inflows; Twin river system","C (programming language); Environmental management; Probability; Quality control; Reservoir management; Reservoirs (water); Risk assessment; Risk management; Rivers; Runoff; Stream flow; Surface waters; Water quality; Water resources; Copula analysis; Joint probability; Priority management intervals; Reservoir inflow; River systems; Probability distributions; nitrogen; phosphorus; river water; surface water; concentration (composition); discharge; environmental management; inflow; nitrogen; phosphorus; reservoir; river system; water quality; Article; China; concentration (parameters); controlled study; copula analysis; environmental management; feasibility study; Frank copula theory; goodness of fit test; priority journal; probability; risk management; river; statistical analysis; theory; water analysis; water flow; water quality; water supply; Beijing [China]; China; Miyun Reservoir",2-s2.0-85026772341
"Cámara B., de Buergo M.Á., Bethencourt M., Fernández-Montblanc T., La Russa M.F., Ricca M., Fort R.","Biodeterioration of marble in an underwater environment",2017,"Science of the Total Environment",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024894728&doi=10.1016%2fj.scitotenv.2017.07.103&partnerID=40&md5=c82e77265ac35b7f0b7949cf4670f699","This study examines the deterioration of geomaterials used throughout history that today may be found lying on the ocean floor. Submerged archaeological sites including cargoes from shipwrecks or ancient city ruins have been a topic of interest from a perspective of in situ musealization, as a way of making underwater cultural heritage accessible to the public. In an experimental study conducted at an underwater archaeological site in the Bay of Cádiz (SW Spain), we subjected two types of marble (Carrara and Macael) to three conditions to which submerged archaeological objects are often exposed: full exposure to the water column, natural processes of burial and unearthing, or permanent burial. After an 18-month study period, the factor found to mostly affect these materials was their biological colonization. This factor was assessed by estimating total surface biocover and the rate of surface biocolonization, and also through the identification of skeletons and associated alteration forms by light microscopy, and scanning electron microscopy (SEM). Biofouling and bioerosion were the main causes of biodeterioration and dependent on the position of the marble specimens in the seawater. The response of both materials was similar, though dolomite crystals in the Carrara marble acted as a protective barrier against actively penetrating microorganisms. These investigations have allowed the study of tracers left by epilithic encrusting organisms and endolithic bioeroders on marbles intentionally exposed to seawater, providing new insights to the understanding of the biodeterioration processes occurring in cultural heritage stones, with significant implications when they are part of underwater archaeological remains. © 2017 Elsevier B.V.","Bioerosion; Biofouling; Carrara; Decay; Macael; Submerged archeology","Architecture; Biodegradation; Biofouling; Biological materials; C (programming language); Marble; Scanning electron microscopy; Seawater; Bioerosion; Carrara; Decay; Macael; Submerged archeology; Deterioration; sea water; archaeology; biodegradation; bioerosion; biofouling; cultural heritage; experimental study; marble; underwater environment; Article; Balanus; barnacle; biofouling; bioremediation; Bryozoa; controlled study; coralline alga; crystal structure; diatom; environmental exposure; environmental impact assessment; environmental monitoring; marble; marine environment; mollusc; nonhuman; priority journal; rock; scanning electron microscopy; surface area; X ray diffraction; X ray fluorescence; Andalucia; Cadiz Bay; Cadiz [Andalucia]; Spain",2-s2.0-85024894728
"Wang S.","On extremal cacti with respect to the revised Szeged index",2017,"Discrete Applied Mathematics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028329609&doi=10.1016%2fj.dam.2017.07.027&partnerID=40&md5=432714fbb4a915fc0c7890cfcb26249d","The revised Szeged index of a graph G is defined as Sz∗(G)=∑e=uv∈E(nu(e)+[formula presented])(nv(e)+[formula presented]), where nu(e) and nv(e) are, respectively, the number of vertices of G lying closer to vertex u than to vertex v and the number of vertices of G lying closer to vertex v than to vertex u, and n0(e) is the number of vertices equidistant to u and v. A cactus is a graph in which any two cycles have at most one common vertex. Let C(n,k) denote the class of all cacti with n vertices and k cycles. In this paper, sharp lower bound on revised Szeged index of graph G in C(n,k) is established and the corresponding extremal graph is determined. Furthermore, the graph G in C(n,k) with the second minimal revised Szeged index is identified as well. © 2017 Elsevier B.V.","Cactus; Revised Szeged index; Szeged index; Wiener index","C (programming language); Cactus; Extremal; Extremal graph; K -cycle; Lower bounds; Revised szeged indices; Szeged index; Wiener index; Graph theory",2-s2.0-85028329609
"Pelto M.","The number of completely different optimal identifying codes in the infinite square grid",2017,"Discrete Applied Mathematics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026775889&doi=10.1016%2fj.dam.2017.07.012&partnerID=40&md5=b585a9033e681160f44308aa9a77545a","Let G be a graph with vertex set V and edge set E. We call any subset C⊆V an identifying code if the sets I(v)={c∈C|{c,v}∈E or c=v}are distinct and non-empty for all vertices v∈V. We study identifying codes in the infinite square grid. The vertex set of this graph is Z2 and two vertices are connected by an edge if the Euclidean distance between these vertices is one. Ben-Haim &amp; Litsyn have proved that the minimum density of identifying code in the infinite square grid is [formula presented]. Such codes are called optimal. We study the number of completely different optimal identifying codes in the infinite square grid. Two codes are called completely different if there exists an integer n such that no n×n-square of one code is equivalent with any n×n-square of the other code. In particular, we show that there are exactly two completely different optimal periodic codes and no optimal identifying code is completely different with both of these two periodic codes. © 2017 Elsevier B.V.","Density; Difference; Discrete geometry; Identifying code; Lattice","Codes (symbols); Density (specific gravity); Graph theory; Optimal systems; Difference; Discrete geometry; Euclidean distance; Identifying code; Lattice; Minimum density; Square grid; Vertex set; C (programming language)",2-s2.0-85026775889
"Mennouni A.","Piecewise constant Galerkin method for a class of Cauchy singular integral equations of the second kind in L2",2017,"Journal of Computational and Applied Mathematics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021178698&doi=10.1016%2fj.cam.2017.05.028&partnerID=40&md5=6cc479f4d9670a30c482ae6f08799eaa","In this work, we present piecewise constant Galerkin method for a class of Cauchy singular integral equations of the second kind with constant coefficients in L2([0,1],C), using a sequence of orthogonal finite rank projections. We prove the existence and uniqueness theorems for the Cauchy integral equation and the approximate equation, respectively. We perform the error analysis for which we give new and improved estimates for the rates of convergence. Numerical example illustrates the theoretical results. © 2017 Elsevier B.V.","Cauchy kernel; Piecewise constant functions; Projection method","C (programming language); Crack propagation; Galerkin methods; Approximate equation; Cauchy kernels; Cauchy singular integral equations; Constant coefficients; Existence and uniqueness theorem; Piece-wise constants; Piece-wise-constant functions; Projection method; Integral equations",2-s2.0-85021178698
"Kosar N., Mahmood T., Ayub K.","Role of dispersion corrected hybrid GGA class in accurately calculating the bond dissociation energy of carbon halogen bond: A benchmark study",2017,"Journal of Molecular Structure",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029074578&doi=10.1016%2fj.molstruc.2017.08.104&partnerID=40&md5=d91b73a40c973561531804728fe8b227","Benchmark study has been carried out to find a cost effective and accurate method for bond dissociation energy (BDE) of carbon halogen (C–X) bond. BDE of C-X bond plays a vital role in chemical reactions, particularly for kinetic barrier and thermochemistry etc. The compounds (1–16, Fig. 1) with C–X bond used for current benchmark study are important reactants in organic, inorganic and bioorganic chemistry. Experimental data of C–X bond dissociation energy is compared with theoretical results. The statistical analysis tools such as root mean square deviation (RMSD), standard deviation (SD), Pearson's correlation (R) and mean absolute error (MAE) are used for comparison. Overall, thirty-one density functionals from eight different classes of density functional theory (DFT) along with Pople and Dunning basis sets are evaluated. Among different classes of DFT, the dispersion corrected range separated hybrid GGA class along with 6-31G(d), 6-311G(d), aug-cc-pVDZ and aug-cc-pVTZ basis sets performed best for bond dissociation energy calculation of C-X bond. ωB97XD show the best performance with less deviations (RMSD, SD), mean absolute error (MAE) and a significant Pearson's correlation (R) when compared to experimental data. ωB97XD along with Pople basis set 6–311g(d) has RMSD, SD, R and MAE of 3.14 kcal mol−1, 3.05 kcal mol−1, 0.97 and −1.07 kcal mol−1, respectively. [figure presented] © 2017 Elsevier B.V.","Benchmark study; Bond dissociation energy; Density functional theory; Deviations; Pearson's correlation","Biochemistry; Bond strength (chemical); Chemical bonds; Chemical compounds; Correlation methods; Cost effectiveness; Density functional theory; Dispersions; Dissociation; Benchmark study; Bioorganic chemistry; Bond dissociation energies; Carbon-halogen bond; Deviations; Mean absolute error; Root mean square deviations; Statistical analysis tools; C (programming language)",2-s2.0-85029074578
"Yadav V., Bhurjee A.K., Karmakar S., Dikshit A.K.","A facility location model for municipal solid waste management system under uncertain environment",2017,"Science of the Total Environment",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017254692&doi=10.1016%2fj.scitotenv.2017.02.207&partnerID=40&md5=6941a31e173343abc15e7bec26668634","In municipal solid waste management system, decision makers have to develop an insight into the processes namely, waste generation, collection, transportation, processing, and disposal methods. Many parameters (e.g., waste generation rate, functioning costs of facilities, transportation cost, and revenues) in this system are associated with uncertainties. Often, these uncertainties of parameters need to be modeled under a situation of data scarcity for generating probability distribution function or membership function for stochastic mathematical programming or fuzzy mathematical programming respectively, with only information of extreme variations. Moreover, if uncertainties are ignored, then the problems like insufficient capacities of waste management facilities or improper utilization of available funds may be raised. To tackle uncertainties of these parameters in a more efficient manner an algorithm, based on interval analysis, has been developed. This algorithm is applied to find optimal solutions for a facility location model, which is formulated to select economically best locations of transfer stations in a hypothetical urban center. Transfer stations are an integral part of contemporary municipal solid waste management systems, and economic siting of transfer stations ensures financial sustainability of this system. The model is written in a mathematical programming language AMPL with KNITRO as a solver. The developed model selects five economically best locations out of ten potential locations with an optimum overall cost of [394,836, 757,440] Rs.1 Rs. is Indian currency and 1 Rs. = 0.015 USD as of 18th October 2016. /day ([5906, 11,331] USD/day) approximately. Further, the requirement of uncertainty modeling is explained based on the results of sensitivity analysis. © 2017 Elsevier B.V.","Facility location problem; Interval analysis; Municipal solid waste management; Optimization; Uncertainty","Costs; Decision making; Distribution functions; Economics; Facilities; Functions; Location; Mathematical programming; Membership functions; Municipal solid waste; Optimization; Probability distributions; Sensitivity analysis; Solid wastes; Stochastic systems; Sustainable development; Transfer stations; Uncertainty analysis; Waste disposal; Facility location models; Facility location problem; Financial sustainability; Fuzzy mathematical programming; Interval analysis; Uncertain environments; Uncertainty; Waste management facility; Waste management; algorithm; decision making; facility location; fuzzy mathematics; municipal solid waste; optimization; uncertainty analysis; waste disposal; waste management; Article; composting; decision making; fuzzy logic; landfill; learning algorithm; mathematical analysis; mathematical model; methodology; municipal solid waste; priority journal; probability; process optimization; recycling; sensitivity analysis; solid waste management; system analysis; urban area; waste disposal facility",2-s2.0-85017254692
"Homaioon Ebrahimi A., Martinez-Vazquez P., Baniotopoulos C.C.","Numerical studies on the effect of plan irregularities in the progressive collapse of steel structures",2017,"Structure and Infrastructure Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016230944&doi=10.1080%2f15732479.2017.1303842&partnerID=40&md5=85ffb81002448d630e7b2739470608fe","This research examines the effect of plan irregularities on the progressive collapse of four steel structures located in regions with different seismic activity. The plans of the first and second structure are irregular, whilst those of the third and fourth structures are regular. The collapse patterns of the four buildings are examined and compared under seven loading scenarios using non-linear dynamic and static analyses. In the non-linear dynamic analyses, node displacements above the removed columns and the additional force on the columns adjacent to them are discussed. Furthermore, the strength and capacities of the columns are compared to determine their susceptibility to collapse. In the non-linear static analyses, the pushdown curve and yield load factor of the structures are obtained after column removal. The results indicate that an irregular structure designed in site class C seismic zone, collapses in most of the column-removal scenarios. Moreover, when comparing regular and irregular structures designed in site class E seismic zone, the demand force to capacity ratio (D/C) of the columns in the irregular structures is on average between 1.5 and 2 times that of the regular ones. © 2017 Informa UK Limited, trading as Taylor & Francis Group.","irregularity in plans; non-linear dynamic analysis; non-linear static analysis; Progressive collapse; pushdown; steel building","C (programming language); Dynamic analysis; Seismology; Static analysis; Steel structures; irregularity in plans; Non-linear dynamic analysis; Non-linear static analysis; Progressive collapse; Pushdown; Steel buildings; Structural dynamics",2-s2.0-85016230944
"Bergenti F., Iotti E., Monica S., Poggi A.","Agent-oriented model-driven development for JADE with the JADEL programming language",2017,"Computer Languages, Systems and Structures",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021341185&doi=10.1016%2fj.cl.2017.06.001&partnerID=40&md5=d8f4ae09ace1f67bf0c864eb0d35b1ee","This paper describes, from motivations and main objectives to actual implementation, a novel agent-oriented programming language called JADEL. JADEL is designed to support the effective implementation of JADE agents and multi-agent systems in the scope of real-world model-driven development because it concretely helps developers by natively supporting agent-oriented abstractions, and because it is based on mature industrial-strength technologies. The four core abstractions that JADEL supports, namely agents, behaviours, communication ontologies, and interaction protocols, are presented by gradually introducing the specific syntaxes that the language provides for them. In the last part of the paper, a complete example of a simple JADEL multi-agent system is presented and discussed. Such an example is a well-known example from the official distribution of JADE and many programmers learned the basics of JADE from it. The choice of this example allows comparing JADEL source code with reference Java source code using JADE, and it clearly emphasizes the practical advantages of agent-oriented programming. Section 1 introduces and motivates the presented work. Section 2 surveys major AOP languages and, even if it cannot be considered exhaustive, it highlights the specific features of selected languages that have been relevant for the design of JADEL. Section 3 provides an overview of the features of JADE that are supported by JADEL. Section 4 presents the language in details by discussing main supported abstractions, and by specifying its formal syntax. Section 5 presents the most interesting parts of a complete example of the use of JADEL to develop a simple multi-agent system. Finally, Section 6 concludes the paper with a discussion of the current state of the presented work, and a preliminary assessment of the proposed language. © 2017 Elsevier Ltd","Domain specific languages; JADE; Multi-agent systems","Abstracting; Computer programming; Computer programming languages; Syntactics; Agent-oriented abstraction; Agent-oriented modeling; Agent-oriented programming languages; Domain specific languages; Inter-action protocols; JADE; Preliminary assessment; Real-world modeling; Multi agent systems",2-s2.0-85021341185
"Fan X., Mehrabi M., Sinnen O., Giacaman N.","Supporting Enhanced Exception Handling with OpenMP in Object-Oriented Languages",2017,"International Journal of Parallel Programming",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994709909&doi=10.1007%2fs10766-016-0474-x&partnerID=40&md5=8e829bf8d92ead539fe31271ba765727","The proliferation of parallel processing in shared-memory applications has encouraged developing assistant frameworks such as OpenMP. OpenMP has become increasingly prevalent due to the simplicity it offers to elegantly and incrementally introduce parallelism. However, it still lacks some high-level language features that are essential in object-oriented programming. One such mechanism is that of exception handling. In languages such as Java, the concept of exception handling has been an integral aspect to the language since the first release. For OpenMP to be truly embraced within this object-oriented community, essential object-oriented concepts such as exception handling need to be given some attention. The official OpenMP standard has little specification on error recovery, as the challenges of supporting exception-based error recovery in OpenMP extends to both the semantic specifications and related runtime support. This paper proposes a systematic mechanism for exception handling with the co-use of OpenMP directives, which is based on a Java implementation of OpenMP. The concept of exception handling with OpenMP directives has been formalized and categorized. Hand in hand with this exception handling proposal, a flexible approach to thread cancellation is also proposed (as an extension on OpenMP directives) that supports this exception handling within parallel execution. The runtime support and its implementation are discussed. The evaluation shows that while there is no prominent overhead introduced, the new approach provides a more elegant coding style which increases the parallel development efficiency and software robustness. © 2016, Springer Science+Business Media New York.","Error recovery; Exception handling; OpenMP; Parallel programming; Software robustness","Application programming interfaces (API); Computer programming languages; Computer system recovery; Errors; High level languages; Java programming language; Parallel programming; Recovery; Semantics; Specifications; Exception handling; Java implementation; Object-oriented concepts; OpenMP; Parallel development; Parallel executions; Semantic specification; Software robustness; Object oriented programming",2-s2.0-84994709909
"Miller A.D., Reges S., Obourn A.","JGRASP: A simple, visual, intuitive programming environment for CS1 and CS2",2017,"ACM Inroads",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032731402&doi=10.1145%2f3148562&partnerID=40&md5=5f65d38ef7639bd5f60d2b183475b43a","Instructors of CS1 and CS2 have access to a wide range of sophisticated Integrated Development Environments (IDEs) to choose from, and most are free. Having such a wealth of options can be overwhelming, especially given that each instructor must consider the most relevant issues for their institution. This paper describes the experience of the authors-instructors at a large, public university-in using the jGRASP IDE to teach both a Java CS1 course and a Java CS2 course. The primary considerations were ease of installation and use, support for interactive programming exercises, and debugging support with intuitive visual representations of data structures. © 2017 ACM.",,"Curricula; Teaching; CS2 course; Debugging support; Integrated development environment; Intuitive programming; Programming exercise; Public universities; Visual representations; Java programming language",2-s2.0-85032731402
"Erol O., Kurt A.A.","The effects of teaching programming with scratch on pre-service information technology teachers' motivation and achievement",2017,"Computers in Human Behavior",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027543543&doi=10.1016%2fj.chb.2017.08.017&partnerID=40&md5=779eda6803b97126059c92498fb13fb8","The aim of this study is to examine the effect of programming instruction with Scratch on student motivation and their programming achievements. The study group consisted of 52 sophomore students attending the Department of Computer Education and Instructional Technologies of Mehmet Akif Ersoy University's Faculty of Education, Turkey. Participants were randomly divided into two groups in order to have 26 students in both the test group and the control group. During the first seven weeks of the study, it is aimed that the students will understand programming logic and learn basic programming structures. For this purpose, participants in the test group were instructed using Scratch, whilst in the control group, flowcharting and problem-solving activities were conducted as per the curriculum. During the second seven weeks of the study, C# programming language instruction was conducted using the same method for both the test and control groups. Achievement Test and Motivated Strategies for Learning Questionnaire were utilized as data collection tools in the study, and a 3 × 2 (measurement time x groups) factorial design was employed. Study findings revealed that programming achievement scores for both the test and control groups increased at the end of the whole process; however, the increase was significantly different in favor of the test group at the end of the whole process. It was observed that motivation scores decreased in the control group, while the test group's scores increased. © 2017","Flowcharts; Motivation; Programming; Scratch","Curricula; Flowcharting; Mathematical programming; Motivation; Problem solving; Students; Teaching; Testing; Computer education; Data collection tools; Instructional technology; Programming instruction; Programming structures; Scratch; Student motivation; Teaching programming; Education; achievement test; computer language; control group; controlled clinical trial; controlled study; curriculum; factorial design; female; human; information technology; learning; logic; major clinical study; male; motivation; problem solving; questionnaire; randomized controlled trial; student; teacher; teaching; Turkey (republic); university",2-s2.0-85027543543
"Buaria D., Yeung P.K.","A highly scalable particle tracking algorithm using partitioned global address space (PGAS) programming for extreme-scale turbulence simulations",2017,"Computer Physics Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029532297&doi=10.1016%2fj.cpc.2017.08.022&partnerID=40&md5=3609298b228b97ee595428d1eeae0cf2","A new parallel algorithm utilizing a partitioned global address space (PGAS) programming model to achieve high scalability is reported for particle tracking in direct numerical simulations of turbulent fluid flow. The work is motivated by the desire to obtain Lagrangian information necessary for the study of turbulent dispersion at the largest problem sizes feasible on current and next-generation multi-petaflop supercomputers. A large population of fluid particles is distributed among parallel processes dynamically, based on instantaneous particle positions such that all of the interpolation information needed for each particle is available either locally on its host process or neighboring processes holding adjacent sub-domains of the velocity field. With cubic splines as the preferred interpolation method, the new algorithm is designed to minimize the need for communication, by transferring between adjacent processes only those spline coefficients determined to be necessary for specific particles. This transfer is implemented very efficiently as a one-sided communication, using Co-Array Fortran (CAF) features which facilitate small data movements between different local partitions of a large global array. The cost of monitoring transfer of particle properties between adjacent processes for particles migrating across sub-domain boundaries is found to be small. Detailed benchmarks are obtained on the Cray petascale supercomputer Blue Waters at the University of Illinois, Urbana–Champaign. For operations on the particles in a 81923 simulation (0.55 trillion grid points) on 262,144 Cray XE6 cores, the new algorithm is found to be orders of magnitude faster relative to a prior algorithm in which each particle is tracked by the same parallel process at all times. This large speedup reduces the additional cost of tracking of order 300 million particles to just over 50% of the cost of computing the Eulerian velocity field at this scale. Improving support of PGAS models on major compilers suggests that this algorithm will be of wider applicability on most upcoming supercomputers. © 2017 Elsevier B.V.","Co-Array Fortran; One-sided communication; Parallel interpolation; Particle tracking; Partitioned global address space (PGAS) programming; Turbulence","Costs; Flow of fluids; Fluid dynamics; FORTRAN (programming language); Supercomputers; Tracking (position); Turbulence; Velocity; Co-array Fortran; Interpolation method; One sided communication; Particle tracking; Partitioned Global Address Space; Petascale supercomputers; Turbulence simulation; University of Illinois; Interpolation",2-s2.0-85029532297
"Hoisl B., Sobernig S., Strembeck M.","Reusable and generic design decisions for developing UML-based domain-specific languages",2017,"Information and Software Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027512992&doi=10.1016%2fj.infsof.2017.07.008&partnerID=40&md5=1ea5b76992ee8776aa9dd9e8e1a31372","Context: In recent years, UML-based domain-specific model languages (DSMLs) have become a popular option in model-driven development projects. However, making informed design decisions for such DSMLs involves a large number of non-trivial and inter-related options. These options concern the language-model specification, UML extension techniques, concrete-syntax language design, and modeling-tool support. Objective: In order to make the corresponding knowledge on design decisions reusable, proven design rationale from existing DSML projects must be collected, systematized, and documented using an agreed upon documentation format. Method: We applied a sequential multi-method approach to identify and to document reusable design decisions for UML-based DSMLs. The approach included a Web-based survey with 80 participants. Moreover, 80 DSML projects1 which have been identified through a prior systematic literature review, were analyzed in detail in order to identify reusable design decisions for such DSMLs. Results: We present insights on the current state of practice in documenting UML-based DSMLs (e.g., perceived barriers, documentation techniques, reuse potential) and a publicly available collection of reusable design decisions, including 35 decision options on different DSML development concerns (especially concerning the language model, concrete-syntax language design, and modeling tools). The reusable design decisions are documented using a structured documentation format (decision record). Conclusion: Our results are both, scientifically relevant (e.g. for design-space analyses or for creating classification schemas for further research on UML-based DSML development) and important for actual software engineering projects (e.g. by providing best-practice guidelines and pointers to common pitfalls). © 2017 Elsevier B.V.","Design decision; Design rationale; Domain-specific language; Model-driven software development; Survey; Unified modeling language","Computational linguistics; Computer programming languages; Concretes; Graphical user interfaces; Modeling languages; Problem oriented languages; Software engineering; Surveying; Surveys; Syntactics; Unified Modeling Language; Visual languages; Best practice guidelines; Design decisions; Design rationale; Domain specific languages; Domain specific modeling languages; Model-Driven Software Development; Software engineering projects; Systematic literature review; Software design",2-s2.0-85027512992
"Li X., Zakharov L.E.","Equilibrium Spline Interface (ESI) for magnetic confinement codes",2017,"Computer Physics Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028828577&doi=10.1016%2fj.cpc.2017.08.015&partnerID=40&md5=cb6d12707f10119c1bf554a2c67cb71f","A compact and comprehensive interface between magneto-hydrodynamic (MHD) equilibrium codes and gyro-kinetic, particle orbit, MHD stability, and transport codes is presented. Its irreducible set of equilibrium data consists of three (in the 2-D case with occasionally one extra in the 3-D case) functions of coordinates and four 1-D radial profiles together with their first and mixed derivatives. The C reconstruction routines, accessible also from FORTRAN, allow the calculation of basis functions and their first derivatives at any position inside the plasma and in its vicinity. After this all vector fields and geometric coefficients, required for the above mentioned types of codes, can be calculated using only algebraic operations with no further interpolation or differentiation. Program summary Program Title: ESI Program Files doi: http://dx.doi.org/10.17632/w6z58s6ntv.1 Licensing provisions: GNU General Public License 3 (GPL) Programming language: C Supplementary material: C2esi.c, F2esi.f, demoC.c, demoF.c RZdemoC.c, RZdemoF.f programs for generation the ESI data and demonstration of their use. Nature of problem: In plasma simulations, the equilibrium codes play a fundamental role in supplying the information about magnetic configuration for different more sophisticated plasma problems: stability, transport, particle orbit or gyro-kinetics. At present, there are two extreme approaches to make a choice of output data from numerical equilibria. One of them requires all functions, necessary for the client code, at all necessary positions to be supplied by the equilibrium codes. This approach works only for closely related pairs of codes, making them highly dependent on each other. It requires excessive storage capacities because the required data may not be very smooth. This approach is not-suitable also for the situation when the client codes need physics variables at unpredictable positions inside the plasma. The other approach uses only primitive information from the equilibrium codes, such as coordinates of grid points and a few radial profiles. Then, the client codes generate all the necessary functions from equilibrium data with their own mappers, which use interpolation and numerical differentiation of original data, both causing convergence problems in the client codes. Solution method: The Equilibrium Spline Interface (ESI), is proposed as a universal buffer between the equilibrium codes and the other plasma physics codes. ESI possesses comprehensive information about magnetic configuration and is able to provide it to magnetic confinement codes in the ready to use form. Additional comments: The main file esiXZ.c with ESI routines is described in the main text. Two (C and FORTRAN) programs C2esi.c, F2esi.f demonstrate the generation of ESI data files. Four other demo programs, linked with esiXZ.c demonstrate the use of the interface in magnetic flux coordinates (demoC.c, demoF.f) and in laboratory cylindrical coordinates r,z (RZdemoC.c, RZdemoF.f). © 2017 Elsevier B.V.","Equilibrium codes; Interfacing plasma codes; MHD equilibrium; Tokamaks","Algebra; Codes (symbols); Differentiation (calculus); Digital storage; FORTRAN (programming language); Gyroscopes; Interpolation; Magnetism; Magnetohydrodynamics; Magnetoplasma; Open source software; Plasma stability; Problem oriented languages; Comprehensive information; Cylindrical coordinates; GNU general public license; Interfacing plasma codes; Magnetic configuration; MHD equilibrium; Numerical differentiation; Tokamaks; C (programming language)",2-s2.0-85028828577
"Landhäußer M., Weigelt S., Tichy W.F.","NLCI: a natural language command interpreter",2017,"Automated Software Engineering",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982947800&doi=10.1007%2fs10515-016-0202-1&partnerID=40&md5=7cda30337a63d20f1cbe8c23ac7be327","Natural language interfaces are becoming more and more common, because they are powerful and easy to use. Examples of such interfaces are voice controlled navigation devices, Apple’s personal assistant Siri, Google Voice Search, and translation services. However, such interfaces are extremely difficult to build, to maintain, and to port to new domains. We present an approach for building and porting such interfaces quickly. NLCI is a natural language command interpreter that accepts action commands in English and translates them into executable code. The core component is an ontology that models an API. Once the API is “ontologized”, NLCI translates input sentences into sequences of API calls that implement the intended actions. Two radically different APIs were ontologized: openHAB for home automation and Alice for building 3D animations. Construction of the ontology can be automated if the API uses descriptive names for its components. In that case, the language interface can be generated completely automatically. Recall and precision of NLCI on a benchmark of 50 input scripts are 67 and 78 %, resp. Though not yet acceptable for practical use, the results indicate that the approach is feasible. NLCI accepts typed input only. Future work will use a speech front-end to test spoken input. © 2016, Springer Science+Business Media New York.","End-user programming; Knowledge-based software engineering; Natural language processing for software engineering; Program synthesis; Programming in natural language","Computational linguistics; Computer programming; Human computer interaction; Knowledge based systems; Natural language processing systems; Software engineering; End user programming; Knowledge-based softwares; NAtural language processing; Natural languages; Program synthesis; Translation (languages)",2-s2.0-84982947800
"Huang L.","iQIST v0.7: An open source continuous-time quantum Monte Carlo impurity solver toolkit",2017,"Computer Physics Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029706452&doi=10.1016%2fj.cpc.2017.08.026&partnerID=40&md5=921e138ee94c394f536cec7083a1f463","In this paper, we present a new version of the iQIST software package, which is capable of solving various quantum impurity models by using the hybridization expansion (or strong coupling expansion) continuous-time quantum Monte Carlo algorithm. In the revised version, the software architecture is completely redesigned. New basis (intermediate representation or singular value decomposition representation) for the single-particle and two-particle Green's functions is introduced. A lot of useful physical observables are added, such as the charge susceptibility, fidelity susceptibility, Binder cumulant, and autocorrelation time. Especially, we optimize measurement for the two-particle Green's functions. Both the particle–hole and particle–particle channels are supported. In addition, the block structure of the two-particle Green's functions is exploited to accelerate the calculation. Finally, we fix some known bugs and limitations. The computational efficiency of the code is greatly enhanced. New version program summary Program Title:iQIST Program Files doi: http://dx.doi.org/10.17632/mvz87z5w3t.1 Licensing provisions: GPLv3 Programming language: Fortran 90, Python, Bash shell Journal reference of previous version: Computer Physics Communications 195, 140 (2015) Does the new version supersede the previous version?: Yes Reasons for the new version: Since the release of iQIST v0.5 in 2015 [1], we keep improving this code. The new version incorporates many new features, optimizations, and bug-fixes, which will be detailed below. Summary of revisions: • In the revised version, only the narcissus component and the hibiscus component are retained. The former implements a hybridization expansion continuous-time quantum Monte Carlo impurity solver for density–density type interaction. The latter includes many auxiliary tools and useful scripts. The two components are carefully benchmarked and verified.• New representation (intermediate representation or singular value decomposition representation) for the single-particle and two-particle Green's functions is implemented [2]. It is better than the Legendre orthogonal polynomial representation.• Now many physical observables can be measured, including the spin susceptibility, charge susceptibility, fidelity susceptibility, kinetic energy fluctuation, kurtosis and skewness of perturbation expansion order, and Binder cumulant [3]. The fidelity susceptibility can be used to detect the quantum phase transition efficiently.• The measurement of two-particle Green's functions is reimplemented. Both the particle–hole and particle–particle channels are supported on the same footing. The block structure and symmetry of the two-particle Green's functions are also utilized to reduce the CPU burden and memory requirement. The iQIST software package usually acts as a computational engine (i.e, quantum impurity solver) in the calculations of the dynamical mean-field theory and its diagrammatic extensions, such as the dual fermions, dual bosons, and dynamical vertex approximation [4]. The essential inputs for these diagrammatic extensions are the two-particle Green's functions. We design the data structure and file format for the two-particle Green's functions carefully, so that they can be easily accessed by the open source dual fermions code opendf [5].• Now the code can output the standard deviations (error bars) for all of the physical observables.• Now the code can measure the autocorrelation function/time for the total occupation number, and then use it to adjust automatically the interval between two successive measurements.• Usually we have to perform analytical continuations for the single-particle Green's function, spin susceptibility, and self-energy function, and convert them from imaginary time or Matsubara frequency space to real-frequency space. These tasks are extremely non-trivial. Some scripts are provided to deal with the output data. They are converted into column-wise files, so that some external codes, such as SpM [6] and ΩMaxEnt [7], can be used to do the analytical continuations.• We also provide some scripts to generate initial hybridization function and retarded interaction function, and make animation movie for the random walk in the Monte Carlo configuration space.• In the previous version of iQIST [1], once the Coulomb interaction U is dynamic and the improved estimator for the self-energy function [8] is employed, the real-part of Matsubara self-energy function is wrong. In the revised version, we fix this severe bug.• We maintain a comprehensive online manual for the code. The users can read the newest iQIST's documentation in the following website: www.gitbook.com/book/huangli712/iqist/.• Now the code repository is transferred to Github. The users can download the newest version of iQIST from the following website: www.github.com/huangli712/iqist. Nature of problem: In the dynamical mean-field theory and its diagrammatic extensions, the bottleneck is to solve a quantum impurity model self-consistently [4,9]. The quantum impurity model is a Hamiltonian that is used to describe quantum impurities embedded in bath environment or metallic hosts. The goal of the iQIST software package is to provide highly effective quantum impurity solvers. Solution method: In the iQIST software package, we only implement the hybridization expansion continuous-time quantum Monte Carlo algorithm [10]. Additional comments including Restrictions and Unusual features: In the revised version, the manjushaka component which implements a hybridization expansion continuous-time quantum Monte Carlo impurity solver for general Coulomb interaction is removed temporally due to numerical unstable problem. The application programming interfaces for Python and Fortran languages are also disabled. They will be released in the next version. [1] Li Huang, Yilin Wang, Zi Yang Meng, Liang Du, Philipp Werner, and Xi Dai, iQIST: An open source continuous-time quantum Monte Carlo impurity solver toolkit, Computer Physics Communications 195 (2015), 140.[2] Hiroshi Shinaoka, Junya Otsuki, Masayuki Ohzeki, and Kazuyoshi Yoshimi, Compressing Green's function using intermediate representation between imaginary-time and real-frequency domains, Phys. Rev. B 96 (2017), 035147.[3] Li Huang, Yilin Wang, Lei Wang and Philipp Werner, Detecting phase transitions and crossovers in Hubbard models using the fidelity susceptibility, Phys. Rev. B 94 (2016), 235110.[4] G. Rohringer, H. Hafermann, A. Toschi, A. A. Katanin, A. E. Antipov, M. I. Katsnelson, A. I. Lichtenstein, A. N. Rubtsov, and K. Held, Diagrammatic routes to non-local correlations beyond dynamical mean field theory, arXiv:1705.00024.[5] Andrey E. Antipov, James P.F. LeBlanc, and Emanuel Gull, opendf - an implementation of the dual fermion method for strongly correlated systems, Phys. Procedia 68 (2015), 43.[6] Junya Otsuki, Masayuki Ohzeki, Hiroshi Shinaoka, and Kazuyoshi Yoshimi, Sparse modeling approach to analytical continuation of imaginary-time quantum Monte Carlo data, Phys. Rev. E 95 (2017), 061302.[7] Dominic Bergeron and A.-M. S. Tremblay, Algorithms for optimized maximum entropy and diagnostic tools for analytic continuation, Phys. Rev. E 94 (2016), 023303.[8] Hartmut Hafermann, Self-energy and vertex functions from hybridization-expansion continuous-time quantum Monte Carlo for impurity models with retarded interaction, Phys. Rev. B 89 (2014), 235128.[9] Antoine Georges, Gabriel Kotliar, Werner Krauth, and Marcelo J. Rozenberg, Dynamical mean-field theory of strongly correlated fermion systems and the limit of infinite dimensions, Rev. Mod. Phys. 68 (1996), 13.[10] Emanuel Gull, Andrew J. Millis, Alexander I. Lichtenstein, Alexey N. Rubtsov, Matthias Troyer, and Philipp Werner, Continuous-time Monte Carlo methods for quantum impurity models, Rev. Mod. Phys. 83 (2011), 349. © 2017 Elsevier B.V.","Continuous-time quantum Monte Carlo; Quantum impurity solver; Two-particle Green's function","Application programming interfaces (API); Autocorrelation; Binders; Bins; Codes (symbols); Computation theory; Computational efficiency; Computer programming; Computer software; Continuous time systems; Correlation detectors; Coulomb interactions; Dynamical systems; FORTRAN (programming language); Green computing; High level languages; Higher order statistics; Impurities; Kinetic energy; Kinetics; Magnetic susceptibility; Mean field theory; Monte Carlo methods; Open source software; Open systems; Optimization; Phase transitions; Preforming; Problem oriented languages; Quantum theory; Singular value decomposition; Software packages; Space time codes; Statistical methods; Websites; Continuous time Monte Carlo methods; Continuous-time; Dynamical mean-field theory; Intermediate representations; Quantum impurity; Strongly correlated fermion system; Strongly correlated systems; Two particles; Quantum efficiency",2-s2.0-85029706452
"Halder P., Das H.S.","JaSTA-2: Second version of the Java Superposition T-matrix Application",2017,"Computer Physics Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029803599&doi=10.1016%2fj.cpc.2017.08.020&partnerID=40&md5=485d65f37db56d3eace2c2a27e0cad6d","In this article, we announce the development of a new version of the Java Superposition T-matrix App (JaSTA-2), to study the light scattering properties of porous aggregate particles. It has been developed using Netbeans 7.1.2, which is a java integrated development environment (IDE). The JaSTA uses double precision superposition T-matrix codes for multi-sphere clusters in random orientation, developed by Mackowski and Mischenko (1996). The new version consists of two options as part of the input parameters: (i) single wavelength and (ii) multiple wavelengths. The first option (which retains the applicability of older version of JaSTA) calculates the light scattering properties of aggregates of spheres for a single wavelength at a given instant of time whereas the second option can execute the code for a multiple numbers of wavelengths in a single run. JaSTA-2 provides convenient and quicker data analysis which can be used in diverse fields like Planetary Science, Atmospheric Physics, Nanoscience, etc. This version of the software is developed for Linux platform only, and it can be operated over all the cores of a processor using the multi-threading option. New version program summary Program Title: Java superposition T-matrix Application: version - 2.0 Program Files doi: http://dx.doi.org/10.17632/bbtjj8kd74.1 Licensing provisions: GPLv3 Programming language: Fortran, Java. External routines/libraries: jfreechart-1.0.14 [1] (free plotting library for java), j3d-jre-1.5.2 [2] StdDraw3D (3D visualization) Subprograms used: spline.f90, splinek.f90, wavesort.f90 Journal reference of previous version: Comput. Phys. Commun., 2014, 185, 2369 Does the new version supersede the previous version?: No. Nature of problem: Light scattering properties of cosmic dust aggregates Solution method: Java application based on Mackowski and Mishchenko's Superposition T-Matrix code (1996). Reasons for the new version: The earlier version was mainly developed to calculate the optical properties of cosmic dust aggregates for a single wavelength in vacuum. The user had to calculate multiple times for different wavelengths to analyze the variation of different scattering parameters (e.g., phase function, polarization, the extinction efficiency, the absorption efficiency, the scattering efficiency, etc.) of aggregate particles for a range of wavelengths which was quite time-consuming. Therefore we have developed the new version of JaSTA with an ability to calculate the scattering parameters for a wide range of wavelength. In this new version, we have introduced the multi-threading option to distribute the multi-wavelength calculations to the maximum number of processing cores present in a computer. Hence the calculation time decreases considerably. Summary of revisions: Java superposition T-matrix App (JaSTA) [3] is a Java swing application developed to study the light scattering properties of cosmic dust aggregates based on the Mackowski & Mischenko's Superposition T-matrix (STM) code [4]. This application calculates the polarization and other scattering matrix elements along with extinction, absorption, and scattering efficiencies for a single wavelength. JaSTA was solely devoted to the light scattering properties of cosmic dust aggregates. Cosmic dust includes comet dust, interplanetary dust, and interstellar dust. Many investigators studied the light scattering properties of comet dust [5]–[10], interplanetary dust [11], interstellar dust [12] using the superposition T-matrix code. JaSTA provided a much better platform for the STM code as a packaged software which can calculate light scattering properties of cosmic dust aggregates for a single wavelength in the vacuum with a click of a button and saves the results in a database so that the saved data can be re-utilized. Recently JaSTA has been used to compute the orientation-averaged scattering matrix elements for fractal aggregates of black carbon aerosols [13]. The interesting feature of the new version of JaSTA is that it can calculate the extinction efficiency at different wavelengths for a given size in a single run which is applicable in the study of interstellar extinction by aggregates at different wavelengths. To analyze the wavelength dependence of extinction one had to execute the calculation for several wavelengths by changing the wavelength and refractive indices in the input for each run in older version of JaSTA. This was very much time consuming and cumbersome. Hence this major drawback led us to rethink and re-establish JaSTA with the multi-wavelength option. JaSTA-2 is the second version of JaSTA aimed to provide the multi-wavelength facility along with the default single wavelength option. JaSTA-2 comes with some other two major updates: cubic spline interpolation of refractive index with wavelengths and multi-threading option for faster calculation. It is developed using Netbeans IDE and is available only for Linux OS. It uses jFreechart-1.0.14 java library to plot various graphs. The multi-wavelength feature will help us to extract the dependence of extinction efficiency on wavelength. Further information on the new features and applicability of JaSTA-2 are provided in the documentation file ‘ JaSTA-2_doc.pdf’, and ‘ readme.txt’ file which are available in the software package. [1] http://www.jfree.org/index.html[2] https://java3d.java.net/[3] P. Halder, A. Chakraborty, P. Deb Roy & H.S. Das, Computer Physics Communications, 185 (2014) 2369-2379.[4] D.W. Mackowski & M.I. Mischenko, J. Opt. Soc. Am. Am., 13 (1996) 2266-2278.[5] H. Kimura, L. Kolokolova & I. Mann, A&A, 407 (2003) L5-L8.[6] H. Kimura, L. Kolokolova & I. Mann, A&A, 449 (2006) 1243-1254.[7] H.S. Das, S.R. Das, T. Paul, A. Suklabaidya & A.K. Sen, MNRAS, 389 (2008) 787-791.[8] H.S. Das, S.R. Das & A.K Sen, MNRAS, 390 (2008) 1195-1199.[9] H.S. Das, A. Suklabaidya, S. Datta Majumder & A.K. Sen, Research in A&A, 10 (2010) 355-362[10] H.S. Das, D. Paul, A. Suklabaidya & A.K. Sen, MNRAS, 416 (2011) 94-100.[11] J. Lasue, A.C. Levasseur-Regourd, N. Fray & H. Cottin, A&A, 473 (2007) 641-649.[12] M. A. Iati, A. Giusto, R. Saija, F. Borghese, P. Denti, C. Cecchi-Pestellini & S. Aielo, ApJ, 615 (2004), 286.[13] A. Pandey & R. K. Chakrabarty, Optics Letters, 41 (2016) 3351-3354. © 2017 Elsevier B.V.","Cosmic dust aggregates; Extinction; Java; Light scattering; Polarization; Superposition T-matrix code","Aggregates; Application programs; Carbon; Codes (symbols); Computer architecture; Computer operating systems; Computer software; Cosmology; Dust; Efficiency; Fog; FORTRAN (programming language); Geophysics; Integrodifferential equations; Interpolation; Light; Light extinction; Light scattering; Linux; Matrix algebra; Optical properties; Polarization; Refractive index; Scattering parameters; Three dimensional computer graphics; Cosmic dusts; Cubic-spline interpolation; Integrated development environment; Interstellar extinction; Java; Scattering matrix elements; T matrix; Wavelength dependence; Java programming language",2-s2.0-85029803599
"Humeniuk A., Mitrić R.","DFTBaby: A software package for non-adiabatic molecular dynamics simulations based on long-range corrected tight-binding TD-DFT(B)",2017,"Computer Physics Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029214654&doi=10.1016%2fj.cpc.2017.08.012&partnerID=40&md5=9c3859a12f515159d1beb720752f18c8","A software package, called DFTBaby, is published, which provides the electronic structure needed for running non-adiabatic molecular dynamics simulations at the level of tight-binding DFT. A long-range correction is incorporated to avoid spurious charge transfer states. Excited state energies, their analytic gradients and scalar non-adiabatic couplings are computed using tight-binding TD-DFT. These quantities are fed into a molecular dynamics code, which integrates Newton's equations of motion for the nuclei together with the electronic Schrödinger equation. Non-adiabatic effects are included by surface hopping. As an example, the program is applied to the optimization of excited states and non-adiabatic dynamics of polyfluorene. The python and Fortran source code is available at http://www.dftbaby.chemie.uni-wuerzburg.de. Program summary Program title: DFTBaby Licensing provisions: MIT license Programming language: python and Fortran 90 Journal Reference: J. Chem. Phys. 143, 134120 (2015) Nature of problem: Trajectory-based non-adiabatic molecular dynamics simulations in excited singlet states for closed-shell molecular systems. Solution method: The electronic structure is solved using charge-consistent tight-binding DFT with a long-range correction to avoid spurious charge transfer states. Excited state energies, their analytic gradients and scalar non-adiabatic couplings are computed using tight-binding TD-DFT. These quantities are fed in a molecular dynamics code, which integrates Newton's equations of motion for the nuclei together with the electronic Schrödinger equation. Non-adiabatic effects are included by surface hopping. © 2017 Elsevier B.V.","Analytic gradients of excited states; Charge transfer; Fluorene; Long-range correction; Non-adiabatic molecular dynamics; Semiempirical; Surface hopping; Tight-binding DFT","Binding energy; Bins; Charge transfer; Codes (symbols); Computer programming; Couplings; Electronic structure; Equations of motion; Excited states; FORTRAN (programming language); High level languages; Software packages; Fluorenes; Long-range corrections; Nonadiabatic molecular dynamics; Semi-empirical; Surface hopping; Tight binding; Molecular dynamics",2-s2.0-85029214654
"Zouaoui C.M.A., Taleb N.","CL_ARRAY: A new generic library of multidimensional containers for c++ compilers with extension for OpenCL framework",2017,"Computer Languages, Systems and Structures",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021317788&doi=10.1016%2fj.cl.2017.04.004&partnerID=40&md5=aef07af55f56ca9b6cd80e8a09a279ff","This paper presents a new metaprogramming library, CL_ARRAY, that offers multiplatform and generic multidimensional data containers for C++ specifically adapted for parallel programming. The CL_ARRAY containers are built around a new formalism for representing the multidimensional nature of data as well as the semantics of multidimensional pointers and contiguous data structures. We also present OCL_ARRAY_VIEW, a concept based on metaprogrammed enveloped objects that supports multidimensional transformations and multidimensional iterators designed to simplify and formalize the interfacing process between OpenCL APIs, standard template library (STL) algorithms and CL_ARRAY containers. Our results demonstrate improved performance and energy savings over the three most popular container libraries available to the developer community for use in the context of multi-linear algebraic applications. © 2017 Elsevier Ltd","C++ multidimensional data container; Metaprogramming; Parallel programming","Containers; Parallel programming; Semantics; Container libraries; Generic libraries; Linear-algebraic; Meta Programming; Multidimensional data; Multidimensional nature; OpenCL frameworks; Standard template library; C++ (programming language)",2-s2.0-85021317788
"Zhang S., Guo H., Zhu K., Yu S., Li J.","Multistage assignment optimization for emergency rescue teams in the disaster chain",2017,"Knowledge-Based Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029751348&doi=10.1016%2fj.knosys.2017.09.024&partnerID=40&md5=4b0cf217d34eeec6219bef17624dea03","Human resources and potential secondary disasters are often neglected in the existing emergency resource allocation methods. This paper presents a multistage assignment model for rescue teams to dynamically respond to the disaster chain and develops three priority scheduling strategies defined under the burden-benefit accord principle. A designed NSGA-II, C-METRIC and fuzzy logic methods were developed to solve the above multi-objective integer nonlinear programming model. Finally, the experimental scenarios results indicated that the overall performance of the proposed method was satisfactory in comparison with current method regardless of whether the secondary disasters occurred sooner or later. It was demonstrated that the three proposed priority scheduling strategies outperformed the others; however, which of these three priority strategies is most appropriate for a specific disaster situation depends on the maximum rescue time allowed by the disaster. © 2017","Disaster chain; Multistage optimization; Non-dominated sorting genetic algorithm (NSGA-II); Rescue team; Scheduling strategy","C (programming language); Chains; Fuzzy logic; Genetic algorithms; Integer programming; Nonlinear programming; Scheduling; Disaster chains; Multi-stage optimization; Non dominated sorting genetic algorithm (NSGA II); Rescue team; Scheduling strategies; Disasters",2-s2.0-85029751348
"Alves M., Carreira P., Costa A.A.","BIMSL: A generic approach to the integration of building information models with real-time sensor data",2017,"Automation in Construction",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030102878&doi=10.1016%2fj.autcon.2017.09.005&partnerID=40&md5=40fc77784eed557de3abebda985fb121","The surge of interest in digital building models combined with increasing sensorization of spaces is prompting an integration of Building Information Modelling (BIM) with real-time sensor data. However, current approaches reported in literature either remain theoretical or target very specific application domains, showing that there is no generic approach to assist in the creation of service and application software that combines sensor data with BIM models. The solution presented in this article addresses the engineering complexity associated with integrating sensor data with BIM by leveraging an advanced software engineering technique known as a Domain-Specific Language (DSL). We demonstrate also that the language herein proposed, named Building Information Modeling Sensor Language(BIMSL) provides substantial gains of expressiveness and ease of use in developing queries that process sensor data with complex conditions over BIM models. BIMSL is validated with experienced software developers according to a consistent evaluation protocol for DSLs focused on effectiveness, efficiency, satisfaction, and usability attributes. The results outperform the standard existing alternatives, indicating that our proposal contributes to reducing the human effort associated with integrating BIM with sensor data. © 2017 Elsevier B.V.","BIM sensor language; Building information modeling; Domain-specific language; Internet of things; Real-time data; Sensors","Application programs; Buildings; Computer programming languages; Data integration; Digital subscriber lines; Information theory; Internet of things; Modeling languages; Modems; Problem oriented languages; Sensors; Software engineering; BIM sensor language; Building Information Model - BIM; Building Information Modelling; Digital building models; Domain specific languages; Engineering techniques; Real-time data; Usability attributes; Architectural design",2-s2.0-85030102878
"Dercks D., Desai N., Kim J.S., Rolbiecki K., Tattersall J., Weber T.","CheckMATE 2: From the model to the limit",2017,"Computer Physics Communications",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029607605&doi=10.1016%2fj.cpc.2017.08.021&partnerID=40&md5=da0fd568b2a116ce68b29c80d2f3127c","We present the latest developments to the CheckMATE program that allows models of new physics to be easily tested against the recent LHC data. To achieve this goal, the core of CheckMATE now contains over 60 LHC analyses of which 12 are from the 13 TeV run. The main new feature is that CheckMATE 2 now integrates the Monte Carlo event generation via MadGraph5_aMC@NLO and Pythia 8. This allows users to go directly from a SLHA file or UFO model to the result of whether a model is allowed or not. In addition, the integration of the event generation leads to a significant increase in the speed of the program. Many other improvements have also been made, including the possibility to now combine signal regions to give a total likelihood for a model. Program summary Program Title: CheckMATE Program Files doi: http://dx.doi.org/10.17632/k4pnk5wrfm.1 Licensing provisions: GPLv3 Programming language: C++, Python External routines/libraries: ROOT, Python, HepMC (optional) Pythia 8 (optional), Madgraph5_aMC@NLO (optional) Subprograms used: Delphes Nature of problem: The LHC experiments have performed a huge number of searches for new physics in the past few years. However the results can only be given for a few benchmark models out of the huge number that exist in the literature. Solution method: CheckMATE is a program that automatically calculates limits for new physics models. The original version required the user to generate Monte Carlo events themselves before CheckMATE could be run but the new version now integrates this step. The simplest output of CheckMATE is whether the model is ruled out at 95% CLs or not. However, more complicated statistical metrics are also available, including the combination of many signal regions. Restrictions: Only a subset of available experimental results have been implemented. Additional comments: • CheckMATE is built upon the tools and hard work of many people. If CheckMATE is used in your publication it is extremely important that all of the following citations are included, – Delphes 3 [1]. https://cp3.irmp.ucl.ac.be/projects/delphes– FastJet [2,3]. http://fastjet.fr/– Anti-kt jet algorithm [4].– CLS prescription [5].– All experimental analyses that were used to set limits in the study and if the analysis was implemented by non- CheckMATE authors, the relevant implementation reference.– MadGraph5_aMC@NLO [6] if it is used to calculate the hard matrix element from within CheckMATE. https://launchpad.net/mg5amcnlo– Pythia8.2 [7] if showering or matching is done from within CheckMATE. http://home.thep.lu.se/~torbjorn/Pythia.html– The Monte Carlo event generator that was used if.hepmc or.lhe files were generated externally.– In analyses that use the mT2 kinematical discriminant [8,9] we use the mt2_bisect library [10]. We also include the MT2 bℓ and MT2 W derivatives [11]. http://particle.physics.ucdavis.edu/hefti/projects/doku.php?id=wimpmass https://sites.google.com/a/ucdavis.edu/mass/– In analyses that use the MCT family of kinematical discriminants we use the MctLib library that includes the following variables, MCT [12], MCT corrected [13], MCT parallel and perpendicular [14]. https://mctlib.hepforge.org/– In analyses that use topness variable we use the topness library [15]. https://github.com/michaelgraesser/topness– Super-Razor [16] in analyses that use this variable. [1] J. de Favereau et al. [DELPHES 3 Collaboration], JHEP 1402 (2014) 057 [arXiv:1307.6346 [hep-ex]]. [2] M. Cacciari, G. P. Salam and G. Soyez, Eur. Phys. J. C 72 (2012) 1896 [arXiv:1111.6097 [hep-ph]]. [3] M. Cacciari and G. P. Salam, Phys. Lett. B 641 (2006) 57 [hep-ph/0512210]. [4] M. Cacciari, G. P. Salam and G. Soyez, JHEP 0804 (2008) 063 [arXiv:0802.1189 [hep-ph]]. [5] A. L. Read, J. Phys. G 28 (2002) 2693. [6] J. Alwall et al., JHEP 1407 (2014) 079 [arXiv:1405.0301 [hep-ph]]. [7] T. Sjöstrand et al., Comput. Phys. Commun. 191 (2015) 159 [arXiv:1410.3012 [hep-ph]]. [8] C. G. Lester and D. J. Summers, Phys. Lett. B 463 (1999) 99 [hep-ph/9906349]. [9] A. Barr, C. Lester and P. Stephens, J. Phys. G 29 (2003) 2343 [hep-ph/0304226]. [10] H. C. Cheng and Z. Han, JHEP 0812 (2008) 063 [arXiv:0810.5178 [hep-ph]]. [11] Y. Bai, H. C. Cheng, J. Gallicchio and J. Gu, JHEP 1207 (2012) 110 [arXiv:1203.4813 [hep-ph]]. [12] D. R. Tovey, JHEP 0804 (2008) 034 [arXiv:0802.2879 [hep-ph]]. [13] G. Polesello and D. R. Tovey, JHEP 1003 (2010) 030 [arXiv:0910.0174 [hep-ph]]. [14] K. T. Matchev and M. Park, Phys. Rev. Lett. 107 (2011) 061801 [arXiv:0910.1584 [hep-ph]]. [15] M. L. Graesser and J. Shelton, Phys. Rev. Lett. 111 (2013) no.12, 121802 [arXiv:1212.4495 [hep-ph]]. [16] M. R. Buckley, J. D. Lykken, C. Rogan and M. Spiropulu, Phys. Rev. D 89 (2014) no.5, 055020 [arXiv:1310.4827 [hep-ph]]. © 2017 Elsevier B.V.","Beyond the Standard Model; Confidence limits; Delphes; Detector simulation; LHC; Monte Carlo; Recasting","Aluminum; C++ (programming language); Computer programming; Fighter aircraft; High energy physics; High level languages; HTTP; Software testing; Tellurium compounds; Confidence limit; Delphes; Detector simulations; Recasting; The standard model; Monte Carlo methods",2-s2.0-85029607605
"Qu S., Ji Y., Jiang J., Zhang Q.","Nonmonotone gradient methods for vector optimization with a portfolio optimization application",2017,"European Journal of Operational Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020095849&doi=10.1016%2fj.ejor.2017.05.027&partnerID=40&md5=5288782cc58b6c1c2349db3a9cae6445","This paper proposes two nonmonotone gradient algorithms for a class of vector optimization problems with a C−convex objective function. We establish both the global and local convergence results for the new algorithms. We then apply the new algorithms to a portfolio optimization problem under multi-criteria considerations. © 2017 Elsevier B.V.","(S) Multiple objective programming; Convergence; Nonmonotone gradient algorithms; Pareto optimum; Portfolio optimization","C (programming language); Financial data processing; Gradient methods; Multiobjective optimization; Pareto principle; Convergence; Gradient algorithm; Multiple objective programming; Pareto optima; Portfolio optimization; Optimization",2-s2.0-85020095849
"Rocha H., Durelli R.S., Terra R., Bessa S., Valente M.T.","DCL 2.0: modular and reusable specification of architectural constraints",2017,"Journal of the Brazilian Computer Society",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027676230&doi=10.1186%2fs13173-017-0061-z&partnerID=40&md5=49e30c317c838f4876dfa9718c4ec694","Background: Due to the abstract nature of software architecture concepts, ensuring the correct implementation of architectural decisions is not a trivial task. Divergences between the planned architecture and source code may occur in the early stages of the software development, which denotes a phenomenon known as software architecture erosion. Architectural conformance checking techniques have been proposed to tackle the problem of divergences between the planned architecture and source code. Among such techniques, we can note the DCL (dependency constraint language), which is a domain-specific language that has interesting results in architectural conformance contexts. However, the current version of DCL has some limitations, such as lack of modularity and low degree of reuse, which may prevent its adoption in real software development scenarios. In this article, we extend DCL with a reusable, modular, and hierarchical specification. Method: We propose and evaluate DCL 2.0—an extension of the original DCL—and its tool in a real-world development scenario of a large system used by a government branch of Minas Gerais, Brazil. Result: We were able to detect 771 architectural violations where 74% of them could only be detected due to the new violation types proposed in DCL 2.0. Conclusion: By using DCL 2.0 herein presented, it was possible to conclude the following: (i) DCL 2.0 proved importance in helping the development team consistently address violations, and (ii) after using DCL 2.0 for months, the number of architectural violations being committed into the system branches was reduced to zero. Therefore, we argue that DCL 2.0 can have a positive impact on the architectural conformance of systems. © 2017, The Author(s).","Architecture conformance; Architecture reuse; Hierarchical specification; Structural violation","Abstracting; Computer programming languages; Computer software reusability; Problem oriented languages; Software architecture; Specifications; Architectural constraints; Architectural decision; Dependency constraints; Development scenarios; Domain specific languages; Minas Gerais , Brazil; Reusable specifications; Structural violation; Software design",2-s2.0-85027676230
"Daniluk A.","RHEED intensities from two-dimensional heteroepitaxial nanoscale systems of GaN on a 3C-SiC(111) surface",2017,"Computer Physics Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029436085&doi=10.1016%2fj.cpc.2017.08.019&partnerID=40&md5=f5e1ba951f5f20ab4a31283391a4624e","This paper presents a version of simulation program, which facilitates the calculation of changes to the intensity of RHEED oscillations in the function of the glancing angle of incidence of the electron beam, employing various models of scattering crystal potential for heteroepitaxial structure of hexagonal (0001) GaN film nucleated on a 3C-SiC surface, including the possible existence of various diffuse scattering models through the layer parallel to the surface. New version program summary Title of program: RHEED_DIFF_Z Program Files doi: http://dx.doi.org/10.17632/52nxmwzkxx.1 Licensing provisions: GNU General Public License 3 Programming language used: C++ Journal reference of previous version: Computer Physics Communications 207 (2016) 536–538 Does the new version supersede the previous version?: No. It is a supplement to the previous version. Reasons for new version: Responding to users’ feedback we present a practical procedure of construction of simulation program, which facilitates the calculation of changes to the intensity of RHEED rocking curves, employing various models of scattering crystal potential for heteroepitaxial structure of hexagonal (0001) GaN film nucleated on a 3C-SiC(111) surface. Nature of problem: Growth of GaN layers on SiC is of importance for potential electronic device applications. Silicon carbide crystallizes in numerous different modifications, so-called polytypes [1]. Among them, only hexagonal structure 4H-SiC and 6H-SiC have been thoroughly investigated while the cubic 3C-SiC polytype is lagging behind in technological developments. The 3C-SiC has a Zincblende crystal structure and is characterized by an identical orientation of all bilayers in the crystal, where the atomic geometry is repeated every three bilayers along the c-axis this crystal structure (Fig. 1). For this reason, 3C-SiC has the high electron mobility and saturation velocity by reducing phonon scattering resulting from the high symmetry. The lattice mismatch between GaN(0001) and 3C-SiC(111) is about 3.3%, and is smaller than the mismatch between GaN(0001) and Si(111) [2]. Therefore progress in investigations on crystal growth of GaN on 3C-SiC is a key issue for device developments related to this heterostructure. Researchers and technologists manufacturing two-dimensional heterostructures frequently use RHEED rocking curves to control growth of samples at the atomistic level of accuracy. The fundamental scientific problem in such research is to specify both interface type and growth mechanism for subsequent layers. Method of solution: RHEED intensities are calculated within the general framework described in Refs. [2] and [3]. Summary of revisions: The presented version of the program implements an original algorithm of self-consistent calculations for scattering potentials GaN(0001)/3C-SiC(111) and solving a time-independent Schrödinger equation for high-energy electrons. During the numerical calculations of the changes in the intensity of the specular beam in the function of the glancing angle, it was assumed that the azimuth of the incident beam direction corresponds to the one-beam condition, the electron energy equals 10 keV, the glancing angle was increased from 0.5∘ to 6.5∘, and the value of αparameter=0.1 and β=0.5 for the MODEL3 of the scattering potential [3] with the model of ideal SiC/GaN interface [4]. References [1] G. R. Fisher and P. Barnes, Phil. Mag. B 61(2) (1990) 217-236.[2] A. Daniluk, Comput. Phys. Commun. 207 (2016) 536-538.[3] A. Daniluk, Comput. Phys. Commun. 185 (2014) 3001-3009.[4] H. Morkoç, Handbook of Nitride Semiconductors and Devices, Vol. 1: Materials Properties, Physics and Growth, Wiley VCH 2008. © 2017 Elsevier B.V.","Diffuse scattering; GaN; RHEED; Scientific computing; SiC","C++ (programming language); Carbides; Crystal atomic structure; Crystal orientation; Crystal structure; Crystals; Electron energy levels; Epitaxial growth; Gallium nitride; Heterojunctions; Lattice mismatch; Materials properties; Natural sciences computing; Open source software; Problem oriented languages; Reflection high energy electron diffraction; Silicon carbide; Surface scattering; Zinc sulfide; Diffuse scattering; Glancing angle of incidence; GNU general public license; Heteroepitaxial structure; Incident beam direction; Self-consistent calculation; Technological development; Zincblende crystal structures; Wide band gap semiconductors",2-s2.0-85029436085
"Sibidanov A.","A revision of the subtract-with-borrow random number generators",2017,"Computer Physics Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029700522&doi=10.1016%2fj.cpc.2017.09.005&partnerID=40&md5=70a43a0b640385cb3d246122f9470618","The most popular and widely used subtract-with-borrow generator, also known as RANLUX, is reimplemented as a linear congruential generator using large integer arithmetic with the modulus size of 576 bits. Modern computers, as well as the specific structure of the modulus inferred from RANLUX, allow for the development of a fast modular multiplication — the core of the procedure. This was previously believed to be slow and have too high cost in terms of computing resources. Our tests show a significant gain in generation speed which is comparable with other fast, high quality random number generators. An additional feature is the fast skipping of generator states leading to a seeding scheme which guarantees the uniqueness of random number sequences. Program summary/New version program summary Program Title: RANLUX++ Licensing provisions: GPLv3 Programming language: C++, C, Assembler © 2017 Elsevier B.V.","GMP; Linear congruential generator; RANLUX; Subtract-with-borrow generator","C++ (programming language); Number theory; Programmable logic controllers; Computing resource; Integer arithmetic; Linear congruential generator; Modular Multiplication; Random number generators; Random Numbers; RANLUX; Subtract-with-borrow generator; Random number generation",2-s2.0-85029700522
"Noble J.H., Lubasch M., Stevens J., Jentschura U.D.","Diagonalization of complex symmetric matrices: Generalized Householder reflections, iterative deflation and implicit shifts",2017,"Computer Physics Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028728933&doi=10.1016%2fj.cpc.2017.06.014&partnerID=40&md5=c66399e1923a98eec60fec1ea870dfc9","We describe a matrix diagonalization algorithm for complex symmetric (not Hermitian) matrices, A̲=A̲T, which is based on a two-step algorithm involving generalized Householder reflections based on the indefinite inner product 〈u̲,v̲〉∗=∑iuivi. This inner product is linear in both arguments and avoids complex conjugation. The complex symmetric input matrix is transformed to tridiagonal form using generalized Householder transformations (first step). An iterative, generalized QL decomposition of the tridiagonal matrix employing an implicit shift converges toward diagonal form (second step). The QL algorithm employs iterative deflation techniques when a machine-precision zero is encountered “prematurely” on the super-/sub-diagonal. The algorithm allows for a reliable and computationally efficient computation of resonance and antiresonance energies which emerge from complex-scaled Hamiltonians, and for the numerical determination of the real energy eigenvalues of pseudo-Hermitian and PT-symmetric Hamilton matrices. Numerical reference values are provided. Program summary Program Title: HTDQLS Program Files doi: http://dx.doi.org/10.17632/x24wjxtrsg.1 Licensing provisions: GPLv3 Programming language: Fortran 90 using fixed form notation Nature of problem: Calculating the eigenvalues and optionally the eigenvectors of complex symmetric (non-Hermitian), densely populated matrices. Solution method: The complex symmetric (not Hermitian) input matrix is diagonalized in two steps. First step: The matrix is tridiagonalized via a series of (n−2) generalized Householder reflections, where n is the rank of the input matrix. Second step: The tridiagonal matrix is diagonalized via a generalization of the “chasing the bulge” technique, which is an iterative process utilizing an implicitly shifted initial rotation followed by (n−2) Givens rotations. This technique is an implementation of QL factorization, and converges roughly as [(λi−σi)∕(λi+1−σi)]j where λi is the eigenvalue located in the (i,i) position of the final diagonal matrix and the eigenvalues are ordered (|λ1|&lt;|λ2|&lt;…&lt;|λn|), and j is the iteration. The “educated guess” σi for the eigenvalue λi is obtained from the analytic determination of the eigenvalues of (k×k)-submatrices of A̲, in the vicinity of the ith element, where k=0,1,2,3 (here, k=0 means that the implicit shift vanishes, σi=0). The routine optionally calculates the rotation matrix Z̲, such that Z̲−1A̲Z̲=D̲ where A̲ is the input matrix and D̲ is the diagonal matrix containing the eigenvalues. The ith column of Z̲ then is the eigenvector of A̲ corresponding to the eigenvalue found at the element D̲(i,i), in the ith position on the diagonal of the matrix D̲. Unusual features: For simplicity, the “wrapper” program which contains an example application and the HTDQLS routine are distributed in the same file. © 2017 Elsevier B.V.","Complex symmetric matrix diagonalization; Deflation techniques; Implicit shift; Indefinite inner product","Application programs; Computational efficiency; Eigenvalues and eigenfunctions; FORTRAN (programming language); Iterative methods; Linear transformations; Complex symmetric matrix; Computationally efficient; Deflation techniques; Householder reflections; Householder transformation; Implicit shift; Indefinite inner product; Matrix diagonalization; Matrix algebra",2-s2.0-85028728933
"Wautelet Y., Heng S., Kiv S., Kolp M.","User-story driven development of multi-agent systems: A process fragment for agile methods",2017,"Computer Languages, Systems and Structures",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024871644&doi=10.1016%2fj.cl.2017.06.007&partnerID=40&md5=de49b719d2bddd903f4de2e1316df02e","Agile software development methods are mostly built as a set of managerial guidelines and development concepts on how to handle a software development but are not bounded to software development paradigms like object or agent orientation. Some methods, like eXtreme Programming and SCRUM are driven by operational requirements representation models called User Stories. These User Stories can be used as an anchoring point to agile methods; this means that we could take a User Stories set to drive a software transformation approach embedded in a particular development paradigm. This paper presents a process fragment for Multi-Agent Systems development with agile methods based on User Stories sets. The process fragment indeed takes advantage of an initial set of User Stories to build a reasoning model (called the Rationale Tree; typically several of these are built for a single project) that documents decompositions and means-end alternatives in scenarios for requirements realization. A Rationale Tree can then be aligned with a Multi-Agent design and implemented in an agent-oriented development language. In this paper the transformation is targeted to the JAVA Agent DEvelopment (JADE) framework. The process fragment (at least partially) covers the Requirements Analysis, Multi-Agent System Design and Multi-Agent System Implementation phases. Transformation from one phase to the other is overseen and illustrated on an example. © 2017 Elsevier Ltd","Agent software engineering; Agile development; i*-based software process modeling; JADE; JAVA Agent DEvelopment framework; Multi-agent system; Process fragment; Rationale tree; User story","Agile manufacturing systems; Computer software; Forestry; Iodine; Java programming language; Software agents; Software design; Software engineering; Agent software; Agile development; JADE; Java agent development framework; Process Fragments; Rationale tree; Software process modeling; User stories; Multi agent systems",2-s2.0-85024871644
"Khatchadourian R.","Automated refactoring of legacy Java software to enumerated types",2017,"Automated Software Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006340197&doi=10.1007%2fs10515-016-0208-8&partnerID=40&md5=916ccd07dcbae7e601f4a37c5ae1dea8","Modern Java languages introduce several new features that offer significant improvements over older Java technology. In this article we consider the new enum construct, which provides language support for enumerated types. Prior to recent Java languages, programmers needed to employ various patterns (e.g., the weak enum pattern) to compensate for the absence of enumerated types in Java. Unfortunately, these compensation patterns lack several highly-desirable properties of the enum construct, most notably, type safety. We present a novel fully-automated approach for transforming legacy Java code to use the new enumeration construct. This semantics-preserving approach increases type safety, produces code that is easier to comprehend, removes unnecessary complexity, and eliminates brittleness problems due to separate compilation. At the core of the proposed approach is an interprocedural type inferencing algorithm which tracks the flow of enumerated values. The algorithm was implemented as an open source, publicly available Eclipse plug-in and evaluated experimentally on 17 large Java benchmarks. Our results indicate that analysis cost is practical and the algorithm can successfully refactor a substantial number of fields to enumerated types. This work is a significant step towards providing automated tool support for migrating legacy Java software to modern Java technologies. © 2016, Springer Science+Business Media New York.","Automated refactoring; Enumerated types; Java; Software environments; Software maintenance; Software tools","Automation; Computer aided software engineering; Computer software; Computer software maintenance; Embedded systems; Fracture mechanics; Java programming language; Semantics; Automated tool support; Enumerated types; Inter-procedural; Java; Java technologies; Refactorings; Separate compilation; Software environments; Open source software",2-s2.0-85006340197
"Wang D., Xue R., Sun Y.","A ranging code based on the improved Logistic map for future GNSS signals: code design and performance evaluation",2017,"Eurasip Journal on Wireless Communications and Networking",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016278469&doi=10.1186%2fs13638-017-0840-4&partnerID=40&md5=66933ccf5766bb76405a456f0d6cf5e0","Ranging code is the core component of the signal transmission scheme in any global navigation satellite system (GNSS); its performance directly influences on the technical indexes of positioning accuracy, compatibility, interoperability, anti-interference, security, synchronization realization, and so on. Therefore, research on ranging codes could provide theoretical support for the improvement of the performance of ranging codes and extension of their design methods to future satellite navigation signal structures. In order to improve the balance in classical chaotic sequences, a novel ranging code is proposed in this paper and constructed by a series of the improved Logistic-map chaotic sequences with different initial values through weighted optimization, summation, and quantization. Then a comprehensive performance evaluation method based on the Welch bound including three main indexes has been introduced, namely the performance of acquisition, tracking, and robustness against interfering narrowband signals. Finally, the three indexes are combined in a cost function by weighting to evaluate the proposed code, coarse/acquisition (C/A), Gold, Weil, and Random as well as the conventional chaotic codes, and the corresponding weighted coefficients can be adjusted flexibly according to the user groups or application types. Theoretical analysis and simulation results over an additive white Gaussian noise (AWGN) channel show that the proposed ranging code cannot only demonstrate excellent performance in acquisition and anti-narrowband interference while maintaining high quality in tracking performance as the C/A code but also significantly improve balance performance and strengthen reliability and security. © 2017, The Author(s).","Chaotic sequences; Ranging codes; Satellite navigation; Weighed processing","Codes (symbols); Communication channels (information theory); Cost functions; Design; Gaussian noise (electronic); Global positioning system; Interoperability; Navigation; Quality control; Reliability analysis; Satellite navigation aids; Satellites; Tracking (position); Transmissions; White noise; Additive white Gaussian noise channel; Chaotic sequence; Comprehensive performance evaluation; Global Navigation Satellite Systems; Narrow band interference; Ranging codes; Satellite navigation; Satellite navigation signals; C (programming language)",2-s2.0-85016278469
"Li M., Xu Z., Mei H.","Effect of structural parameters on the torsional behavior of C/SiC pipe",2017,"Ceramics International",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028298706&doi=10.1016%2fj.ceramint.2017.08.152&partnerID=40&md5=d0ad669575b41ab897be58c6bfefe19c","Based on the principles of classical laminate theory, the 3D finite element analysis model of C/SiC pipe has been established by using finite element analysis software ABAQUS. Tsai-Hill failure criterion was applied to identify the critical areas of failure in composite laminates. Through the finite element simulation, the torsional properties of C/SiC pipe under different length, internal diameters and wall thickness were studied. The simulation results show that with the increase of the pipe length, the angle of twist per unit length decreased. With the increase of internal diameters of the pipe, the anti-torsion performance of the pipe increases gradually, and the angle of twist per unit length gradually decreases until it remains the same, and the wall thickness of the pipe have little effect on the torsional performance. The experimental results show that the simulated torsional properties are in good agreement with the experimental results. © 2017","C/SiC; Finite element analysis (FEA); Structural parameters; Torsional properties","ABAQUS; C (programming language); Laminated composites; Laminates; Offshore pipelines; 3D-finite element analysis; Classical laminate theory; Composite laminate; Finite element analysis software; Finite element simulations; Structural parameter; Torsional behaviors; Torsional properties; Finite element method",2-s2.0-85028298706
"Semino R., Ramsahye N.A., Ghoufi A., Maurin G.","Role of MOF surface defects on the microscopic structure of MOF/polymer interfaces: A computational study of the ZIF-8/PIMs systems",2017,"Microporous and Mesoporous Materials",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013168604&doi=10.1016%2fj.micromeso.2017.02.031&partnerID=40&md5=1ed80c88bcb40e2ef8ccd3b9e9499881","The influence of defects at the metal-organic framework (MOF) surface on the microscopic structure of a MOF/polymer composite has been studied by a computational methodology that combines density functional theory calculations with force field-based molecular dynamics simulations. This has been applied to composites formed by ZIF-8 and two different polymers of intrinsic microporosity: PIM-1 and PIM-EA-TB. Analysis of the MOF/polymer interactions, surface coverage, polymer conformation/stiffness and a full characterization of the interfacial voids are provided. We found that, although the nature of the MOF/polymer interactions changes in the presence of defects, the coverage and conformation of the polymer as well as the morphology of the “interfacial microvoids” remain practically unchanged from a microscopic point of view. These results suggest that there is no microscopic evidence that defective MOF surfaces drastically change the geometry of the MOF/polymer interface and the strength of the physisorption-type interactions in play. © 2017 Elsevier Inc.","Defects at MOF surfaces; Density functional theory; Mixed-matrix membranes; MOF/polymer interface; Molecular dynamics; PIM-1; PIM-EA-TB; ZIF-8","Computation theory; Computational chemistry; Crystalline materials; Density functional theory; Java programming language; Molecular dynamics; Molecular structure; Organometallics; Polymers; Computational methodology; Interfacial micro-voids; Metal organic framework; Mixed matrix membranes; Molecular dynamics simulations; PIM-1; Polymers of intrinsic microporosities; ZIF-8; Surface defects",2-s2.0-85013168604
"Chiangga S., Racknoi P., Yupapin P.","Computational surface plasmonic micro-device for sub-wavelength switching and sensing applications",2017,"Journal of Optics (India)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988734670&doi=10.1007%2fs12596-016-0380-z&partnerID=40&md5=3db8fcc04847bd0605ad0f149239cc35","In this paper, the cross coupling between two surface plasmon polariton waveguide is designed by the cross coupling mode theory, where the output results are computed and obtained by the MATLAB program. The two vertical metal-dielectric waveguides of silicon waveguides with the gold thin films on the tops are performed, where such a device is known as a coupler. The other simulation program is the Opti-wave, which is used a finite difference time domain method. Simulation results obtained have shown that the behavior as the cross coupling transverse mode of surface plasmon polariton between the two waveguides occurs. The other forms of surface plasmon polariton couplers are 1 × 2, 2 × 1 and 2 × 2 couplers, which are designed and manipulated using the Opti-wave software, where the results are agreed well with the mathematical computation of the coupling length Lc, in which the Hy and Ez peak oscillations are agreed well with the mathematical computation of the coupling length (Lc). The switching and sensing aspects of the device are also simulated and interpreted, from which the result shows that the Hy amplitude is linear relationship to the dielectric gap refractive index between the two surface plasmon polariton waveguides, where the coupling length is fixed. From the simulation results, it is found that such a proposed device has the potential of using for liquid switching and sensing applications within micrometer scale. © 2016, The Optical Society of India.","Micro-optical device; Sub-wavelength coupler; Surface plasmon sensors; Surface plasmonic device","C (programming language); Chemical reactions; Computation theory; Dielectric waveguides; Electromagnetic wave polarization; Finite difference time domain method; MATLAB; Phonons; Photons; Quantum theory; Refractive index; Surface plasmon resonance; Thin films; Time domain analysis; Waveguides; Mathematical computation; Metal-dielectric waveguide; Microoptical devices; Plasmonic devices; Sub-wavelength; Surface plasmon polaritons; Surface plasmon sensors; Surface plasmon-polariton waveguides; Plasmons",2-s2.0-84988734670
"Osvaldo S.S., Jr., Lopes D., Silva A.C., Abdelouahab Z.","Developing software systems to Big Data platform based on MapReduce model: An approach based on Model Driven Engineering",2017,"Information and Software Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025631316&doi=10.1016%2fj.infsof.2017.07.006&partnerID=40&md5=85844ee21dd60c4ec4c39fb3bf47604a","Context: The need to analyze a large volume and variety of data for the purpose of extracting information has been promoting investments in Big Data, e.g., for storage, analysis and, more recently, methodologies and approaches for software system development for Big Data platforms. The application of software engineering for Big Data is recent and emerging, so in the literature we find a number of challenges and opportunities related to Big Data, but few practical approaches. Objective In this paper, we propose a practical approach based on MDE (Model Driven Engineering) to support the semi-automated development of software systems for Big Data platform that use MapReduce model. Method The proposed approach consists of framework, process, metamodels, visual Alf, transformation definitions written in ATL and Eclipse IDE plug-in. The proposed framework uses concepts of MDE, Weaving and software development based on Y. Our proposed process guides the use of our approach. A graphical notation and extended metamodel for Alf (i.e. visual Alf) assign executable behavior for UML or DSLs. An Eclipse IDE plug-in implements our approach. Results We show the applicability of the proposed approach through an illustrative example. Conclusion Our approach brings a contribution because the development of software systems is assisted by models which preserves the business logic and adds Big Data features throughout the development process. © 2017 Elsevier B.V.","Big Data; Framework; Metamodels; Model Driven Engineering","Application programs; Computer software; Data mining; Digital storage; Integrodifferential equations; Java programming language; Software design; Software engineering; Development process; Extracting information; Framework; Graphical notation; MapReduce models; Meta model; Model-driven Engineering; Software systems; Big data",2-s2.0-85025631316
"Jiménez-Carvelo A.M., Osorio M.T., Koidis A., González-Casado A., Cuadros-Rodríguez L.","Chemometric classification and quantification of olive oil in blends with any edible vegetable oils using FTIR-ATR and Raman spectroscopy",2017,"LWT - Food Science and Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026645818&doi=10.1016%2fj.lwt.2017.07.050&partnerID=40&md5=cdee7e18ca3e277e6932d97fb9b86a47","Samples of olive oils (n = 67) from different qualities and samples of other vegetable edible oils (including soybean, sunflower, rapeseed, corn oil etc; n = 79) were used in this study as pure oils. Previous to spectroscopy analysis, a transesterification step was applied to the pure vegetable oil samples and all the different oil blends were then prepared to create in-house blended samples. Spectral acquisition was performed with typical parameters to collect the FTIR and Raman fingerprints. For the olive/non-olive classification model, three classification strategies have been applied: (i) one input-class (1iC) classification; (ii) two input-class (2iC) classification; and (iii) one input-class plus one ‘dummy’ class classification (or pseudo two input-class (p2iC) classification). The multivariate classification methods used were k-nearest neighbours (kNN), partial least squared-discriminant analysis (PLS-DA), one-class partial least squares (OCPLS), support vector machine classification (SVM-C), and soft independent modelling of class analogies (SIMCA). The multivariate quantification method used was partial least square-regression (PLS-R). FTIR fingerprints showed excellent classification ability to distinguish pure olive from non-olive oil. When PLS-DA or SVM-C techniques are applied, 100% of olive oil samples and 92% of other vegetable edible oils are correctly classified. In general FTIR fingerprints were more discriminative than Raman's in both classification and regression scenarios. © 2017 Elsevier Ltd","Discrimination; Fingerprinting; Pattern recognition; Spectroscopic techniques; Vegetable oils","C (programming language); Classification (of information); Discriminant analysis; Fourier transform infrared spectroscopy; Least squares approximations; Nearest neighbor search; Olive oil; Pattern recognition; Principal component analysis; Sunflower oil; Support vector machines; Vegetable oils; Discrimination; Fingerprinting; K nearest neighbours (k-NN); Multivariate classification; Partial least square (PLS); Partial least square regression; Spectroscopic technique; Support vector machine classification; Soybean oil",2-s2.0-85026645818
"Zhang Z., Ma X., Huang H., Wang Y.","Shea olein based specialty fats: Preparation, characterization and potential application",2017,"LWT - Food Science and Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027513447&doi=10.1016%2fj.lwt.2017.08.035&partnerID=40&md5=3628ebf9c62f6f28e272d66a04f8d273","To expand low melting point “liquid” base oil categories of plastic fats, the soft fat named SheaOL25 as a byproduct of shea butter with a melting point of 25.5 °C was achieved via solvent fractionating of shea butter, and abounded in oleic acid and stearic acid/oleic acid/oleic acid (SOO) type triacylglycerols. The compatibility test with palm-based oil and coconut oil showed the desirable linear relationship of isothermal curve. At temperatures above 25 °C, SheaOL25 exhibits good compatibility and could serve as a blending base oil for preparing specialty fats. Compared with palm olein, blending SheaOL25 and palm stearin can significantly expedite crystallization rate and retard crystallization rate after interesterification, thereby stabilizing the β′ crystal form in the system. Further exploration of SheaOL25 as “liquid” oil in oil-in-water emulsion system revealed that SheaOL25 as the oil phase can significantly improve the system's stability compared with the control groups of soybean oil and palm olein towards maintaining the particle size and emulsion stability under high temperatures. © 2017 Elsevier Ltd","Compatibility; Crystallization rate; Oil-in-water emulsion; Shea olein","Blending; C (programming language); Crystallization kinetics; Emulsification; Emulsions; Melting point; Particle size; Soybean oil; Compatibility; Crystallization rates; Good compatibility; Interesterification; Linear relationships; Oil-in-water emulsions; Shea olein; System's stabilities; Palm oil",2-s2.0-85027513447
"Yu Y., Lei T., Chen H., Zang B.","Characterizing and optimizing Java-based HPC applications on Intel many-core architecture",2017,"Science China Information Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019450751&doi=10.1007%2fs11432-015-0989-3&partnerID=40&md5=802d430c21cbfbc2be2fc03821c981c6","The increasing demand for performance has stimulated the wide adoption of many-core accelerators like Intel® Xeon PhiTM Coprocessor, which is based on Intel’s Many Integrated Core architecture. While many HPC applications running in native mode have been tuned to run efficiently on Xeon Phi, it is still unclear how a managed runtime like JVM performs on such an architecture. In this paper, we present the first measurement study of a set of Java HPC applications on Xeon Phi under JVM. One key obstacle to the study is that there is currently little support of Java for Xeon Phi. This paper presents the result based on the first porting of OpenJDK platform to Xeon Phi, in which the HotSpot virtual machine acts as the kernel execution engine. The main difficulty includes the incompatibility between Xeon Phi ISA and the assembly library of Hotspot VM. By evaluating the multithreaded Java Grande benchmark suite and our ported Java Phoenix benchmarks, we quantitatively study the performance and scalability issues of JVM on Xeon Phi and draw several conclusions from the study. To fully utilize the vector computing capability and hide the significant memory access latency on the coprocessor, we present a semi-automatic vectorization scheme and software prefetching model in HotSpot. Together with 60 physical cores and tuning, our optimized JVM achieves averagely 2.7x and 3.5x speedup compared to Xeon CPU processor by using vectorization and prefetching accordingly. Our study also indicates that it is viable and potentially performance-beneficial to run applications written for such a managed runtime like JVM on Xeon Phi. © 2017, Science China Press and Springer-Verlag Berlin Heidelberg.","HPC; Java; many-core; prefetching; Xeon Phi","Benchmarking; Coprocessor; Java programming language; Memory architecture; Java; Many core; Many-core accelerators; Many-core architecture; Memory access latency; Performance and scalabilities; Prefetching; Xeon Phi; Computer architecture",2-s2.0-85019450751
"Kato T., Yamamoto Y., Kato H., Dedmon S., Pilch J.","Effect of fracture toughness on vertical split rim failure in railway wheels",2017,"Engineering Fracture Mechanics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032195241&doi=10.1016%2fj.engfracmech.2017.09.025&partnerID=40&md5=eebcd57e930448e9e9b43a8554af2e9c","Vertical split rim (VSR) cracks are the most common cause for the removal of broken or cracked heavy haul car wheels in North America. This failure mode is characterized by rapid, unstable crack propagation in the hoop or in the tangential direction. To investigate the methods to prevent VSRs, an understanding of how the service loads correlate to their occurrence is necessary. In this study, a finite element analysis is conducted to evaluate the rim stresses below the tread surface during rolling contact between the wheel tread and the rail. Then, the stress intensity factor is calculated using the stress distribution in the wheel rim obtained using the finite element analysis. The results of the analysis show that axial residual tensile stress, which contributes to unstable vertical crack propagation, increases at deeper positions below the tread surface owing to cyclic rolling contact. These results indicate that a vertical crack can propagate rapidly below the tread surface. The fracture toughness of the wheel steel is measured using Charpy impact tests. The results of the test show that Weibull distribution enables the approximation of the relationship between fracture probability and fracture toughness. To evaluate the effect of the fracture toughness of wheel steel on the differences in VSR crack probability, a comparison between high fracture toughness wheels and conventional Class-C wheels is made. The VSR rate can be predicted from the stress intensity factor and Weibull equation for fracture toughness. The prediction results show that the VSR rate of high fracture toughness wheels is only 5% of that of conventional Class-C wheels. Therefore, high fracture toughness steel wheels are considered to have a higher resistance to VSR cracks compared with conventional Class-C wheels. © 2017 Elsevier Ltd","Finite element analysis; Fracture toughness; Railway wheel; Stress intensity factors; Vertical split rim","C (programming language); Charpy impact testing; Crack propagation; Cracks; Factor analysis; Finite element method; Fracture; Friction; Probability distributions; Railroads; Rails; Stress intensity factors; Vehicle wheels; Weibull distribution; Wheels; Cyclic rolling contact; Fracture probability; Railway wheels; Residual tensile stress; Rolling contacts; Tangential directions; Vertical split rims; Weibull equations; Fracture toughness",2-s2.0-85032195241
"Jiang M., Wang X., Ke S., Zhang F., Zeng X.","Large scale layering laser surface texturing system based on high speed optical scanners and gantry machine tool",2017,"Robotics and Computer-Integrated Manufacturing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016253660&doi=10.1016%2fj.rcim.2017.03.005&partnerID=40&md5=df2d8c79f247d732a5b9134ff7c3190e","A layering laser surface texturing system for large freeform surface workpiece was realized with a reconfigurable structure of usual mechanical gantry machine tool plus laser processing head, which is composed of dual high speed galvanometer optical scanning axes and a mechanical linear axis. The principle of layering processing ability of laser focus point and the method to divide freeform surface into partitions and layers was analyzed. The kinematic of five axes machine tool with three axes laser processing head was derived. A novel computer aided laser texturing software named WnloLaserRobots was designed on visual C++ platform, which provides full function of 3D model data analyzing and real time processing control. The laser head position, the orientation data, and the layering scanning paths for processing a freeform surface were generated through importing and analyzing the universal initial graphics exchange specification (IGES) model file. In the control module, the software sends command to five axes gantry machine tool to position laser head normal to the processing surface partition and control laser processing head to accomplish layering laser texturing. This proposed system is particular suitable for laser ablation of film layer from multilayer materials on large scale free form surface. It has been used in practical application and satisfactory results were obtained. © 2017 Elsevier Ltd","Computer aided laser manufacturing; Freeform surface; Laser surface texturing; Reconfigurable system","C++ (programming language); Computer software; Data flow analysis; Laser ablation; Laser recording; Scanning; Texturing; Free-form surface; Initial graphics exchange specifications; Laser manufacturing; Laser surface texturing; Multilayer materials; Realtime processing; Reconfigurable structure; Reconfigurable systems; Machine tools",2-s2.0-85016253660
"Calderín L., Karasiev V.V., Trickey S.B.","Kubo–Greenwood electrical conductivity formulation and implementation for projector augmented wave datasets",2017,"Computer Physics Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030860637&doi=10.1016%2fj.cpc.2017.08.008&partnerID=40&md5=9ccd707d036cbdbd98b9393eed17ce11","As the foundation for a new computational implementation, we survey the calculation of the complex electrical conductivity tensor based on the Kubo–Greenwood (KG) formalism (Kubo, 1957; Greenwood, 1958), with emphasis on derivations and technical aspects pertinent to use of projector augmented wave datasets with plane wave basis sets (Blöchl, 1994). New analytical results and a full implementation of the KG approach in an open-source Fortran 90 post-processing code for use with Quantum Espresso (Giannozzi et al., 2009) are presented. Named KGEC ([K]ubo [G]reenwood [E]lectronic [C]onductivity), the code calculates the full complex conductivity tensor (not just the average trace). It supports use of either the original KG formula or the popular one approximated in terms of a Dirac delta function. It provides both Gaussian and Lorentzian representations of the Dirac delta function (though the Lorentzian is preferable on basic grounds). KGEC provides decomposition of the conductivity into intra- and inter-band contributions as well as degenerate state contributions. It calculates the dc conductivity tensor directly. It is MPI parallelized over k-points, bands, and plane waves, with an option to recover the plane wave processes for their use in band parallelization as well. It is designed to provide rapid convergence with respect to k-point density. Examples of its use are given. © 2017 Elsevier B.V.","Electrical conductivity; Electron transport; Kohn–Sham density functional theory; Kubo–Greenwood; Plane wave; Projector augmented wave","C (programming language); Computation theory; Delta functions; Elastic waves; Electric conductivity; Electron transport properties; Open systems; Tensors; Wave propagation; Electrical conductivity; Electron transport; Kohn-Sham density-functional theory; Kubo-Greenwood; Plane wave; Projector augmented waves; Density functional theory",2-s2.0-85030860637
"Chu Y., Ahmad T., Bebis G., Zhao L.","Low-resolution face recognition with single sample per person",2017,"Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020457004&doi=10.1016%2fj.sigpro.2017.05.012&partnerID=40&md5=63f15ae08b634a0d297e4c853a2f8abd","As a growing number of low-resolution (LR) face images are captured by surveillance cameras, LR face recognition has been a hot issue for recent years. Previous efforts on LR face recognition typically assume each subject has multiple high-resolution (HR) training samples. However, this assumption may not hold in some special cases such as law-enforcement where only a single HR sample per person exists in the training set. For LR face recognition in SSPP scenario, it often suffers from overfitting and singular matrix problems. In this paper, we are the first to investigate LR face recognition with single sample per person, and propose a cluster-based regularized simultaneous discriminant analysis (C-RSDA) method based on SDA. C-RSDA regularizes the between-class and within-class scatter matrices respectively with inter-cluster and intra-cluster scatter matrices, where the cluster-based scatter matrices are computed from unsupervised clustering. With the cluster-based scatter matrices, not only the singularity problem is resolved, but overfitting problem is overcomed as more variations are exploited from the limited training samples. Thus, the proposed C-RSDA enhances the discriminative power of the feature subspace. We extensively evaluate C-RSDA on recognizing LR face images captured in both controlled and uncontrolled environments. The encouraging experimental results demonstrate the effectiveness of the proposed approach. © 2017","Cluster-based regularization; Coupled mappings; Low-resolution; Single sample per person","C (programming language); Discriminant analysis; Laws and legislation; Sampling; Security systems; Cluster-based; Discriminative power; Low resolution; Low resolution face recognition; Single sample; Singularity problems; Unsupervised clustering; Within class scatter; Face recognition",2-s2.0-85020457004
"Santos C.D.D., Jr.","Changes in free and open source software licenses: managerial interventions and variations on project attractiveness",2017,"Journal of Internet Services and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026914900&doi=10.1186%2fs13174-017-0062-3&partnerID=40&md5=c3fd4143f92d300f015897b772a8efed","The license adopted by an open source software is associated with its success in terms of attractiveness and maintenance of an active ecosystem of users, bug reporters, developers, and sponsors because what can and cannot be done with the software and its derivatives in terms of improvement and market distribution depends on legal terms there specified. By knowing this licensing effect through scientific publications and their experience, project managers became able to act strategically, loosening up the restrictions associated with their source code due to sponsor interests, for example; or the contrary, tightening restrictions up to guarantee source code openness, adhering to the “forever free” strategy. But, have project managers behaved strategically like that, changing their projects license? Up to this paper, we did not know if and what types of changes in these legal allowances project managers have made and, more importantly, whether such managerial interventions are associated with variations in intervened project attractiveness (i.e., related to their numbers of web hits, downloads and members). This paper accomplishes these two goals and demonstrates that: 1) managers of free and open source software projects do change the distribution rights of their source code through a change in the (group of) license(s) adopted; and 2) variations in attractiveness are associated with the strategic choice of a licensing schema. To reach these conclusions, a unique dataset of open source projects that have changed license was assembled in a comparative form, analyzing intervened projects over its monthly periods of different licenses. Based on a sample of more than 3500 active projects over 44 months obtained from the FLOSSmole repository of Sourceforge.net data, 756 projects that had changed their source code distribution allowances and restrictions were identified and analyzed. A dataset on these projects’ type of changes was assembled to enable a descriptive and exploratory analysis of the types of license interventions observed over a period of almost four years anchored on projects’ attractiveness. More than 35 types of interventions were detected. The results indicate that variations in attractiveness after a license intervention are not symmetric; that is, if a change from license schema A to B is beneficial to attractiveness, a change from B to A is not necessarily prejudicial. This and other interesting findings are discussed in detail. In general, the results here reported support the current literature knowledge that the restrictions imposed by the license on the source code distribution are associated with market success vis-a-vis project attractiveness, but they also suggest that the state-of-the-science is superficial in terms of what is known about why these differences in attractiveness can be observed. The complexity of the results indicates to free software managers that no licensing schema should be seen as the right one, and its choice should be carefully made, considering project strategic goals as perceived relevant to stakeholders of the application and its production. These conclusions create awareness of several limitations of our current knowledge, which are discussed along with guidelines to understand them deeper in future research endeavors. © 2017, The Author(s).","Attractiveness; Free software; Governance; GPL; Information technology; Intellectual property; Open source; Open source software; Project and people management; Software license; Software project","Application programs; Codes (symbols); Commerce; Computer programming languages; Computer software; Copyrights; Information technology; Intellectual property; Managers; Open systems; Software engineering; Attractiveness; Free software; Governance; Open sources; People management; Software license; Software project; Open source software",2-s2.0-85026914900
"Kant N.A., Dar M.R., Khanday F.A., Psychalinos C.","Ultra-low-Voltage Integrable Electronic Realization of Integer- and Fractional-Order Liao’s Chaotic Delayed Neuron Model",2017,"Circuits, Systems, and Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029928112&doi=10.1007%2fs00034-017-0615-5&partnerID=40&md5=fe602f16f89c621ef0d8a5976b51f191","The neurons are proven to show chaotic dynamical behavior, and due to this behavior, they find applications in several fields. Recently, the chaotic behavior of the neuron model using non-monotonous Liao’s activation function was described and its design using op-amp was presented. The presented design is a high-voltage one and is not integrable, as both passive resistors and inductors have been employed. Besides, most of the components are of floating type, which are difficult to design on an integrated chip. In addition, only integer-order design has been considered. In this paper, an ultra-low-voltage sinh-domain implementation of the neuron model has been introduced. Moreover, for the first time, the fractional-order implementation of the model has also been presented. The design offers the advantages of: (a) low-voltage implementation, (b) integrable design, (c) resistor and inductor less design, (d) using only grounded components, and (e) low-power design due to the inherent class AB nature of sinh-domain technique. The proper functioning of the model has been verified through different cases where the time constant of the integrator, delay and fractional order have been varied. The behavior of the neuron models is evaluated through HSPICE simulator using the metal oxide semiconductor transistor (MOSFET) models provided by Taiwan Semiconductor Manufacturing Company Limited (TSMC) 130 nm complementary metal oxide (CMOS) process. © 2017, Springer Science+Business Media, LLC.","Chaos; Companding technique; Fractional-order circuits; Liao’s chaotic delayed neuron; Low-voltage analog implementation; Neural networks; Nonlinear dynamics","C (programming language); Chaos theory; Dynamics; Electric grounding; Electric power supplies to apparatus; Metallic compounds; Metals; MOS devices; Neural networks; Neurons; Operational amplifiers; Oxide semiconductors; Power amplifiers; Resistors; Semiconductor device manufacture; Activation functions; Analog implementation; Companding technique; Dynamical behaviors; Fractional-order circuit; Metal-oxide-semiconductor transistor; Taiwan semiconductor manufacturing companies; Ultra-low-voltage; Integrated circuit design",2-s2.0-85029928112
"Imran T., Hussain M., Figueira G.","Computer controlled multi-shot frequency-resolved optical gating diagnostic system for femtosecond optical pulse measurement",2017,"Microwave and Optical Technology Letters",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029726700&doi=10.1002%2fmop.30894&partnerID=40&md5=9086857da9248c61a13f2563a72817f8","The control and data acquisition of homemade, second harmonic generation (SHG) multi-shot frequency-resolved optical gating (FROG) diagnostic technique reported here. We have designed and developed the computer controlled multi-shot FROG diagnostic system using reflecting optics to minimize the dispersion while LabVIEW software has employed to control and data acquisition. The femtosecond laser system at laboratory for intense lasers (L2I) optimized and characterized using LabVIEW-based FROG system. We have measured and retrieved the oscillator and compressed amplified laser pulse profiles in temporal domains having full width half maximum (FWHM) of 150 and 270 fs, respectively, and relatively small temporal phase ∼1 radians peak to peak variations with FROG error ∼0.003. The grating detuning data acquired in the form of the single data file to observe the FROG trace pattern evaluation with the change of grating positions to confirm the reliability of the LabVIEW-based FROG system. © 2017 Wiley Periodicals, Inc.","femtosecond laser; LabVIEW; second harmonic generation multi-shot frequency-resolved optical gating","Computer control systems; Computer programming languages; Data acquisition; Electromagnetic pulse; Nonlinear optics; Ultrashort pulses; Amplified laser pulse; Diagnostic techniques; Femtosecond laser system; Femtosecond optical pulse; Frequency-resolved optical gatings; Full width half maximum; LabViEW; Multi-shot; Harmonic generation",2-s2.0-85029726700
"Wahiduzzaman, Allmond K., Stone J., Harp S., Mujibur K.","Synthesis and Electrospraying of Nanoscale MOF (Metal Organic Framework) for High-Performance CO2 Adsorption Membrane",2017,"Nanoscale Research Letters",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008448701&doi=10.1186%2fs11671-016-1798-6&partnerID=40&md5=dccc40faba5ea57f71c36553e62c7d1c","We report the sonochemical synthesis of MOF (metal organic framework) nanoparticles of 30–200 nm in size and electrospraying of those particles on electrospun nanofibers to process a MOF-attached nanofibrous membrane. This membrane displayed significant selectivity towards CO2 and capacity of adsorbing with 4000–5000 ppm difference from a mixed gas flow of 1% CO2 and 99% N2. Applying ultrasonic waves during the MOF synthesis offered rapid dispersion and formation of crystalline MOF nanoparticles in room temperature. The MOF nanoparticles of 100–200 nm in size displayed higher surface area and adsorption capacity comparing to that of 30–60 nm in size. Nanofibrous membrane was produced by electrospinning of MOF blended PAN solution followed by electrospraying of additional MOF nanoparticles. This yielded uniform MOF deposition on nanofibers, occurred due to electrostatic attraction between highly charged nanoparticles and conductive nanofibers. A test bench for real-time CO2 adsorption at room temperature was built with non-dispersive Infrared (NDIR) CO2 sensors. Comparative tests were performed on the membrane to investigate its enhanced adsorption capacity. Three layers of the as-produced membranes displayed CO2 adsorption for approximately 2 h. Thermogravimetric analysis (TGA) of the membrane showed the thermal stability of the MOF and PAN up to 290 and 425 °C, respectively. © 2017, The Author(s).","CO2 adsorption; Electrospinning; Electrospraying; MOF; Nanofibers; PAN","Adsorption; Crystalline materials; Dispersion (waves); Electrospinning; Flow of gases; Java programming language; Membranes; Metal nanoparticles; Nanofibers; Nanoparticles; Organometallics; Sonochemistry; Spinning (fibers); Synthesis (chemical); Thermodynamic stability; Thermogravimetric analysis; Charged nanoparticles; Electrospraying; Electrospun nanofibers; Electrostatic attractions; Metal organic framework; Nanofibrous membranes; Non-dispersive infrared; Sonochemical synthesis; Carbon dioxide",2-s2.0-85008448701
"Ramm A.G.","Global existence, uniqueness and estimates of the solution to the Navier–Stokes equations",2017,"Applied Mathematics Letters",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021126414&doi=10.1016%2fj.aml.2017.05.009&partnerID=40&md5=18bd8fbeb37b06688998edfed04c3389","The Navier–Stokes (NS) problem consists of finding a vector-function v from the Navier–Stokes equations. The solution v to NS problem is defined in this paper as the solution to an integral equation. The kernel G of this equation solves a linear problem which is obtained from the NS problem by dropping the nonlinear term (v⋅∇)v. The kernel G is found in closed form. Uniqueness of the solution to the integral equation is proved in a class of solutions v with finite norm N1(v)=supξ∈R3,t∈[0,T](1+|ξ|)(|v|+|∇v|)≤c(∗), where T&gt;0 and C&gt;0 are arbitrary large fixed constants. In the same class of solutions existence of the solution is proved under some assumption. Estimate of the energy of the solution is given. © 2017 Elsevier Ltd","Global existence; Navier–Stokes equations; Uniqueness and estimates","C (programming language); Integral equations; Nonlinear equations; Closed form; Global existence; Linear problems; Nonlinear terms; Stokes equations; Uniqueness and estimates; Vector functions; Navier Stokes equations",2-s2.0-85021126414
"Valente G., Crimi G., Vanella N., Schileo E., Taddei F.","NMSBUILDER: Freeware to create subject-specific musculoskeletal models for OpenSim",2017,"Computer Methods and Programs in Biomedicine",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029677158&doi=10.1016%2fj.cmpb.2017.09.012&partnerID=40&md5=14078cd1605ce55cac079c2d61c2ca55","Background and objective Musculoskeletal modeling and simulations of movement have been increasingly used in orthopedic and neurological scenarios, with increased attention to subject-specific applications. In general, musculoskeletal modeling applications have been facilitated by the development of dedicated software tools; however, subject-specific studies have been limited also by time-consuming modeling workflows and high skilled expertise required. In addition, no reference tools exist to standardize the process of musculoskeletal model creation and make it more efficient. Here we present a freely available software application, NMSBUILDER 2.0, to create musculoskeletal models in the file format of OpenSim, a widely-used open-source platform for musculoskeletal modeling and simulation. NMSBUILDER 2.0 is the result of a major refactoring of a previous implementation that moved a first step toward an efficient workflow for subject-specific model creation. Methods NMSBUILDER includes a graphical user interface that provides access to all functionalities, based on a framework for computer-aided medicine written in C++. The operations implemented can be used in a workflow to create OpenSim musculoskeletal models from 3D surfaces. A first step includes data processing to create supporting objects necessary to create models, e.g. surfaces, anatomical landmarks, reference systems; and a second step includes the creation of OpenSim objects, e.g. bodies, joints, muscles, and the corresponding model. Results We present a case study using NMSBUILDER 2.0: the creation of an MRI-based musculoskeletal model of the lower limb. The model included four rigid bodies, five degrees of freedom and 43 musculotendon actuators, and was created from 3D surfaces of the segmented images of a healthy subject through the modeling workflow implemented in the software application. Conclusions We have presented NMSBUILDER 2.0 for the creation of musculoskeletal OpenSim models from image-based data, and made it freely available via nmsbuilder.org. This application provides an efficient workflow for model creation and helps standardize the process. We hope this would help promote personalized applications in musculoskeletal biomechanics, including larger sample size studies, and might also represent a basis for future developments for specific applications. © 2017 Elsevier B.V.","Freeware; Image-based model; Imaging data processing; Musculoskeletal model; OpenSim; Subject-specific model","Application programs; C++ (programming language); Computer aided software engineering; Computer software; Data handling; Degrees of freedom (mechanics); Graphical user interfaces; Musculoskeletal system; Open source software; Open systems; User interfaces; Freeware; Image-based modeling; Imaging data; Musculoskeletal model; OpenSim; Subject specific modeling; Three dimensional computer graphics; access to information; adult; anatomic landmark; Article; biomechanics; computer aided design; computer interface; computer simulation; conceptual framework; data processing; geometry; human; image analysis; joint; lower limb; muscle; musculoskeletal system; nmsbuilder; normal human; nuclear magnetic resonance imaging; opensim musculoskeletal model; process model; software; surface property; three dimensional imaging; workflow",2-s2.0-85029677158
"Ni J., Wang Y., Ma C., Geng Y., Jiang J., Li Y., Shi J., Song D.","Simulating and analyzing the thermal cycle behaviors of conductive film bonding PV module",2017,"Solar Energy",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032304350&doi=10.1016%2fj.solener.2017.10.019&partnerID=40&md5=a49b675fe484d211dfb56d1812fc0262","The purpose of paper is to identify the root cause of conductive film bonded n-type mono Si module failed after TC200 test. Firstly, it established 2D model of CF photovoltaic module based on FEA software, which simulated the developing trend of stress concentration at distinct locations relative to ribbon on substrate of cell when temperature repeated from −40 °C to 85 °C with the rate of 40 °C/h. Then it compared the stress nephogram of typical position in module with various thickness of encapsulant. Meantime, the rheological property of EVA and PO investigated by TMA to distinguish the potential factors of material in changing temperature stage. EL images and microscope pictures of cross profile applied to straightforward validate the effectiveness of simulations. It concluded that the distribution of stress indicated the high risky breakage of silicon substrate happened during hypothermia stage, especially for thin EVA. © 2017","Conductive film (CF); Simulation; Stress concentrated; Thermal cycle (TC); Validation","Photovoltaic cells; Stress concentration; Substrates; Thermal conductivity; Thermal cycling; Changing temperature; Developing trend; FEA software; Photovoltaic modules; Rheological property; Silicon substrates; Simulation; Validation; C (programming language); film; model validation; photovoltaic system; simulation; software; temperature effect; thermal conductivity; two-dimensional modeling",2-s2.0-85032304350
"Aguilar M.A., Eusse J.F., Ray P., Leupers R., Ascheid G., Sheng W., Sharma P.","Towards Parallelism Extraction for Heterogeneous Multicore Android Devices",2017,"International Journal of Parallel Programming",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006873388&doi=10.1007%2fs10766-016-0479-5&partnerID=40&md5=0e50e0cac56c1b05d59421f22672e1ad","Modern Android mobile devices are enabled by complex heterogeneous MPSoC platforms. To exploit the full potential of these hardware platforms, computationally intensive parts of applications have to be properly parallelized. However, the current practice involves several manual steps, which is a cumbersome task for programmers. In this paper, we present an automated approach to extract multiple forms of parallelism from native C code within Android applications, targeting heterogeneous multicore devices. We show the effectiveness of our approach by parallelizing a set of benchmarks on a Nexus 7 tablet, which is based on a Snapdragon MPSoC that features a quad-core Krait CPU cluster and an Adreno 320 GPU. © 2016, Springer Science+Business Media New York.","Android; Mobile GPUs; MPSoC; Parallelization","C (programming language); Multiprocessing systems; Program processors; System-on-chip; Android; Android applications; Heterogeneous mpsoc; Heterogeneous multicore; Mobile GPUs; MPSoC; Parallelism extraction; Parallelizations; Android (operating system)",2-s2.0-85006873388
"Katayanagi N., Fumoto T., Hayano M., Shirato Y., Takata Y., Leon A., Yagi K.","Estimation of total CH4 emission from Japanese rice paddies using a new estimation method based on the DNDC-Rice simulation model",2017,"Science of the Total Environment",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019735675&doi=10.1016%2fj.scitotenv.2017.05.090&partnerID=40&md5=28d278f6333538518617eed9a4197bfc","Methane (CH4) is a greenhouse gas, and paddy fields are one of its main anthropogenic sources. In Japan, country-specific emission factors (EFs) have been applied since 2003 to estimate national-scale CH4 emission from paddy field. However, these EFs did not consider the effects of factors that influence CH4 emission (e.g., amount of organic C inputs, field drainage rate, climate) and can therefore produce estimates with high uncertainty. To improve the reliability of national-scale estimates, we revised the EFs based on simulations by the DeNitrification-DeComposition-Rice (DNDC-Rice) model in a previous study. Here, we estimated total CH4 emission from paddy fields in Japan from 1990 to 2010 using these revised EFs and databases on independent variables that influence emission (organic C application rate, paddy area, proportions of paddy area for each drainage rate class and water management regime). CH4 emission ranged from 323 to 455 kt C yr− 1 (1.1 to 2.2 times the range of 206 to 285 kt C yr− 1 calculated using previous EFs). Although our method may have overestimated CH4 emissions, most of the abovementioned differences were presumably caused by underestimation by the previous method due to a lack of emission data from slow-drainage fields, lower organic C inputs than recent levels, neglect of regional climatic differences, and underestimation of the area of continuously flooded paddies. Our estimate (406 kt C in 2000) was higher than that by the IPCC Tier 1 method (305 kt C in 2000), presumably because regional variations in CH4 emission rates are not accounted for by the Tier 1 method. © 2017 Elsevier B.V.","CH4 emission; Climate change; DNDC-Rice; Greenhouse gases; Japan; Rice","Climate change; Greenhouse gases; Uncertainty analysis; Water management; Anthropogenic sources; DNDC-Rice; Estimation methods; Independent variables; Japan; Management regime; Regional variation; Rice; C (programming language); methane; organic carbon; climate change; decomposition; denitrification; emission; estimation method; greenhouse gas; methane; modeling; paddy field; rice; Article; carbon footprint; climate change; irrigation (agriculture); Japan; land drainage; priority journal; rice; temporal analysis; Japan; Oryza sativa (japonica cultivar-group)",2-s2.0-85019735675
"La D.D., Thi H.P.N., Kim Y.S., Rananaware A., Bhosale S.V.","Facile fabrication of Cu(II)-porphyrin MOF thin films from tetrakis(4-carboxyphenyl)porphyrin and Cu(OH)2 nanoneedle array",2017,"Applied Surface Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009895089&doi=10.1016%2fj.apsusc.2017.01.110&partnerID=40&md5=427b0b99045d4010264b716cce186d94","Herein, we report a facile synthetic protocol to grow thin films of Cu(II) tetrakis(4-carboxyphenyl)porphyrin (CuTCPP) metal-organic frameworks (MOF) from a tetrakis(4-carboxyphenyl)porphyrin (H2TCPP) solution and the copper hydroxide (Cu(OH)2) nanoneedle array formed on a Cu substrate at room temperature. The formations of Cu-centered TCPP ligands and crystalline platelet-like Cu MOFs were successfully probed by SEM, XRD, FTIR, UV–vis and XPS. The formation process from Cu(OH)2 was monitored by using SEM images obtained at different reaction times during the first 24 h, thus suggesting the reaction pathway of Cu(OH)2 dissolution followed by the reprecipitation of CuTCPP MOFs at a near surface. In addition, the CuTCPP MOFs exhibited a high specific surface area of 408 m2/g. © 2017 Elsevier B.V.","Cu(II) tetrakis(4-carboxyphenyl)porphyrin; Cu(OH)2 nanoneedle array; Cu-based prophyrin MOFs; Metal organic frameworks; MOFs thin film","Crystalline materials; Java programming language; Nanoneedles; Organometallics; Porphyrins; Thin films; Crystalline platelets; Cu-based; Facile fabrication; High specific surface area; Metal organic framework; Nanoneedle arrays; Synthetic protocols; Tetrakis; Copper",2-s2.0-85009895089
"Xue Y., Beauseroy P.","Transfer learning for one class SVM adaptation to limited data distribution change",2017,"Pattern Recognition Letters",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032258241&doi=10.1016%2fj.patrec.2017.10.030&partnerID=40&md5=68e9c1c774359a641aff44c165b032f9","Data based one class classification rules are widely used in system monitoring. Due to maintenance for example, we may come across a change of data distribution with respect to training data. While lacking of representative samples for the new data set, one can try to adapt the former learned detection rule to the new data set instead of retraining a new rule which implies to gather a significant amount of data. Based on the above, a multi-task learning detection rule approach is proposed to deal with the training of the updated system as some new data are available. The key feature of the new approach is the introduction of a parameter to control how much we rely on the former model. This parameter has to be set and changed as the amount of new data coming from the system increases. We define the new detection model as a classical one class SVM with a specific kernel matrix which depends on the parameter we introduced. A kernel adaptation method for C-one class SVM is developed in order to get the path solution along that parameter and a criteria is established to select a good value. Experiments conducted on toy data and real data set show that the proposed method could adapt to data change, and it gives a good transition from the old detection rule to the new one which is just obtained using the new data set only when the number of samples gathered from that new one is large enough. © 2017 Elsevier B.V.","Distribution change; Fault detection; Kernel adaptation; One class classification; Transfer learning","Fault detection; Data distribution; Distribution change; Kernel adaptation; Multitask learning; Number of samples; One-class Classification; Representative sample; Transfer learning; C (programming language)",2-s2.0-85032258241
"Hoffman A.H., Teng Z., Zheng J., Wu Z., Woodard P.K., Billiar K.L., Wang L., Tang D.","Stiffness Properties of Adventitia, Media, and Full Thickness Human Atherosclerotic Carotid Arteries in the Axial and Circumferential Directions",2017,"Journal of Biomechanical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030448703&doi=10.1115%2f1.4037794&partnerID=40&md5=aac1342f3761ca1b9635c542530fc8c0","Arteries can be considered as layered composite material. Experimental data on the stiffness of human atherosclerotic carotid arteries and their media and adventitia layers are very limited. This study used uniaxial tests to determine the stiffness (tangent modulus) of human carotid artery sections containing American Heart Association type II and III lesions. Axial and circumferential oriented adventitia, media, and full thickness specimens were prepared from six human carotid arteries (total tissue strips: 71). Each artery yielded 12 specimens with two specimens in each of the following six categories; axial full thickness, axial adventitia (AA), axial media (AM), circumferential full thickness, circumferential adventitia (CA), and circumferential media (CM). Uniaxial testing was performed using Inspec 2200 controlled by software developed using labview. The mean stiffness of the adventitia was 3570 ± 667 and 2960 ± 331 kPa in the axial and circumferential directions, respectively, while the corresponding values for the media were 1070 ± 186 and 1800 ± 384 kPa. The adventitia was significantly stiffer than the media in both the axial (p = 0.003) and circumferential (p = 0.010) directions. The stiffness of the full thickness specimens was nearly identical in the axial (1540 ± 186) and circumferential (1530 ± 389 kPa) directions. The differences in axial and circumferential stiffness of media and adventitia were not statistically significant. © 2017 by ASME.",,"Computer programming languages; Software testing; Carotid artery; Circumferential direction; Human carotid artery; Stiffness properties; Tangent moduli; Tissue strips; Uniaxial testing; Uniaxial tests; Stiffness",2-s2.0-85030448703
"Razaque A., Rizvi S.S.","Privacy preserving model: a new scheme for auditing cloud stakeholders",2017,"Journal of Cloud Computing",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016256127&doi=10.1186%2fs13677-017-0076-1&partnerID=40&md5=a774912d94c42af517957c51fd5ae2e9","The Cloud computing paradigm provides numerous attractive services to customers such as the provision of the on-demand self-service, usage-based pricing, ubiquitous network access, transference of risk, and location independent resource sharing. However, the security of cloud computing, especially its data privacy, is a highly challengeable task. To address the data privacy issues, several mechanisms have been proposed that use the third party auditor (TPA) to ensure the integrity of outsourced data for the satisfaction of cloud users (CUs). However, the role of the TPA could be the potential security threat itself and can create new security vulnerabilities for the customer’s data. Moreover, the cloud service providers (CSPs) and the CUs could also be the adversaries while deteriorating the stored private data. As a result, the objective of this research is twofold. Our first research goal is to analyze the data privacy-preserving issues by identifying unique privacy requirements and presenting a supportable solution that eliminates the possible threats towards data privacy. Our second research goal is to develop the privacy-preserving model (PPM) to audit all the stakeholders in order to provide a relatively secure cloud computing environment. Specifically, the proposed model ensures the quality of service (QoS) of cloud services and detects potential malicious insiders in CSPs and TPAs. Furthermore, our proposed model provides a methodology to audit a TPA for minimizing any potential insider threats. In addition, CUs can use the proposed model to periodically audit the CSPs using the TPA to ensure the integrity of the outsourced data. For demonstrating and validating the performance, the proposed PPM is programmed in C++ and tested on GreenCloud with NS2 by applying merging processes. The experimental results help to identify the effectiveness, operational efficiency, and reliability of the CSPs. In addition, the results demonstrate the successful rate of handling the negative role of the TPA and determining the TPA’s malicious insider detection capabilities. © 2017, The Author(s).","Authentication; Cloud computing; Cloud service provider; Cloud user; Privacy preserving model; Third party auditor","Authentication; C++ (programming language); Cloud computing; Distributed computer systems; Distributed database systems; Location based services; Network function virtualization; Quality of service; Ubiquitous computing; Cloud service providers; Data-privacy preserving; Operational efficiencies; Privacy preserving; Privacy requirements; Secure cloud computing; Security vulnerabilities; Third parties; Data privacy",2-s2.0-85016256127
"Zheng Q.R., Zhu Z.W., Chen J., Yu W.S.","Preparation of carbon based getter for glass fiber core vacuum insulation panels (VIPs) used on marine reefer containers",2017,"Vacuum",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030229337&doi=10.1016%2fj.vacuum.2017.09.040&partnerID=40&md5=f8398663e39cf0ea64bc12bea61449bf","Mechanism of adsorption instead of chemical reaction was employed to develop a getter for glass fiber core VIPs used on marine reefer containers. A programmed temperature gas chromatography-mass spectrometer method was designed to detect the released gases from the core at temperature 50 °C-290 °C. Adsorption equilibrium data of water vapor, ethylene, propylene and hydrogen at temperature 298.15 K and pressure 0–500 Pa were measured on silica gel (SBET = 300 m2/g), carbon molecular sieve (SBET = 810 m2/g) and activated carbon (SBET = 1916 m2/g). The activated carbon sample was undergone surface modification and then mixed with the same amount of expanded graphite (ENG) to form the getter JMU-01. Comparisons were made in terms of adsorption capacities and thermal conductivities of getters, VIPs and VIP composite plates. It shows that, at 273.15 K and 0–1 kPa, adsorption for ethylene, propylene and hydrogen on JMU-01 had maximum increment 242.42%, 272.65% and 85.24% than currently available getter SAT-01 containing desiccant and lithium-barium alloys. Within temperature range 15°C–60 °C, thermal conductivities of VIPs and VIP composite plates prepared by above two getters were nearly equal with a mean value respectively about 0.00245 W/(m °C) and 0.00443 W/(m °C). It suggests that surface modification and densification by ENG on activated carbon may be a possible solution to synthesizing the getter. © 2017","Activated carbon; Expanded graphite; Getter; Vacuum insulation panels","Activated carbon; Adsorption; Chromatography; Containers; Driers (materials); Electron emission; Ethylene; Gas chromatography; Getters; Glass; Glass fibers; Graphite; Metals; Molecular sieves; Propylene; Silica gel; Surface treatment; Thermal conductivity; Thermal insulation; Adsorption capacities; Adsorption equilibria; Carbon molecular sieve; Expanded graphite; Gas chromatography-mass spectrometers; Programmed temperature; Temperature range; Vacuum insulation panel; C (programming language)",2-s2.0-85030229337
"Mihcin S., Karakitsios I., Le N., Strehlow J., Demedts D., Schwenke M., Haase S., Preusser T., Melzer A.","Methodology on quantification of sonication duration for safe application of MR guided focused ultrasound for liver tumour ablation",2017,"Computer Methods and Programs in Biomedicine",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029879739&doi=10.1016%2fj.cmpb.2017.09.006&partnerID=40&md5=8e64e5887f2a3a4cb86163f78961f077","Background and objective Magnetic Resonance Guided Focused Ultrasound (MRgFUS) for liver tumour ablation is a challenging task due to motion caused by breathing and occlusion due the ribcage between the transducer and the tumour. To overcome these challenges, a novel system for liver tumour ablation during free breathing has been designed. Methods The novel TRANS-FUSIMO Treatment System (TTS, EUFP7) interacts with a Magnetic Resonance (MR) scanner and a focused ultrasound transducer to sonicate to a moving target in liver. To meet the requirements of ISO 13485; a quality management system for medical device design, the system needs to be tested for certain process parameters. The duration of sonication and, the delay after the sonication button is activated, are among the parameters that need to be quantified for efficient and safe ablation of tumour tissue. A novel methodology is developed to quantify these process parameters. A computerised scope is programmed in LabVIEW to collect data via hydrophone; where the coordinates of fiber-optic sensor assembly was fed into the TRANS-FUSIMO treatment software via Magnetic Resonance Imaging (MRI) to sonicate to the tip of the sensor, which is synchronised with the clock of the scope, embedded in a degassed water tank via sensor assembly holder. The sonications were executed for 50 W, 100 W, 150 W for 10 s to quantify the actual sonication duration and the delay after the emergency stop by two independent operators for thirty times. The deviation of the system from the predefined specs was calculated. Student's-T test was used to investigate the user dependency. Results The duration of sonication and the delay after the sonication were quantified successfully with the developed method. TTS can sonicate with a maximum deviation of 0.16 s (Std 0.32) from the planned duration and with a delay of 14 ms (Std 0.14) for the emergency stop. Student's T tests indicate that the results do not depend on operators (p >.05). Conclusion The evidence obtained via this protocol is crucial for translation- of-research into the clinics for safe application of MRgFUS. The developed protocol could be used for system maintenance in compliance with quality systems in clinics for daily quality assurance routines. © 2017 Elsevier B.V.","Computer control of laboratory machines and device; Experiment and measurement technics, medical device legislation; MR guided FUS; Protocol development; Quality Management Systems; Safety; Sonication duration","Ablation; Accident prevention; Biomedical equipment; Computer programming languages; Fiber optic sensors; Magnetic resonance imaging; Magnetism; Quality assurance; Quality management; Resonance; Sonication; Statistical tests; Transducers; Tumors; Ultrasonic transducers; Water tanks; Magnetic resonance scanners; Magnetic resonance-guided focused ultrasound (MRgFUS); Medical device design; Medical Devices; MR guided FUS; Process parameters; Protocol development; Quality management systems; Computer control systems; Article; fiber optics; liver tumor; MR-guided focused ultrasound; nuclear magnetic resonance scanner; sensor; tumor ablation; ultrasound; ultrasound transducer",2-s2.0-85029879739
"Jiang Y.-Z., Wang Y.-L., Wang C.-Y., Bai L.-M., Li X., Li Y.-B.","Magnesium hydroxide whisker modified via in situ copolymerization of n-butyl acrylate and maleic anhydride",2017,"Rare Metals",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014235550&doi=10.1007%2fs12598-016-0826-0&partnerID=40&md5=97dd8c5805892a41fd0259960a6096b8","Magnesium hydroxide (MH) whiskers were modified via in situ polymerization of n-butyl acrylate and maleic anhydride. Sodium dodecyl sulfonate was used as emulsifier. The modifying effect was evaluated by using contact angle and activation index. The thermal stability, functional groups, structure, morphology, phase composition and surface element valence of MH whiskers were characterized by thermogravimetry–differential scanning calorimetry (TG-DSC), Fourier transform infrared spectroscopy (FTIR), X-ray diffraction (XRD), scanning electron microscopy (SEM) and X-ray photoelectron spectroscopy (XPS). Results reveal that the contact angle and activation index of modified MH whiskers are 105° and 76.5%, the thermal stability shows little change, and the decomposition temperature ranges between 38 and 419 °C. The copolymer of n-butyl acrylate and maleic anhydride absorbed on the surface of MH whiskers leads to the increased diameter and makes the surface of whiskers be rougher. Furthermore, the absorption of element C on the surface of MH whiskers increases, and the diffraction intensity of C 1s spectra increases; thus, the compatibility of whiskers in the organic phase can be improved significantly. Lastly, the surface molecular model of MH whiskers modified via in situ copolymerization of n-butyl acrylate and maleic anhydride is established. © 2017, The Author(s).","In situ copolymerization; Magnesium hydroxide whiskers; Maleic anhydride; n-Butyl acrylate; Surface molecular model","C (programming language); Chemical activation; Contact angle; Copolymerization; Differential scanning calorimetry; Emulsification; Fourier transform infrared spectroscopy; Magnesium; Maleic anhydride; Molecular mechanics; Molecular modeling; Scanning electron microscopy; Thermodynamic stability; Thermogravimetric analysis; X ray diffraction; Decomposition temperature; Diffraction intensity; In-situ polymerization; Magnesium hydroxide; Modifying effects; N-butyl acrylate; Situ copolymerization; Sodium dodecyl sulfonate; X ray photoelectron spectroscopy",2-s2.0-85014235550
"Yu X., Yu Q., Shang Y., Zhang H.","Dense structural learning for infrared object tracking at 200+ Frames per Second",2017,"Pattern Recognition Letters",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032345629&doi=10.1016%2fj.patrec.2017.10.026&partnerID=40&md5=8a228534d423834d06d2a04ac207e68b","Infrared object tracking is a key technology in many surveillance applications. General visual tracking algorithms designed for color images can not handle infrared targets very well due to their relatively low resolutions and blurred edges. This paper presents a new tracking by detection method based on online structural learning. We show how to train the classifier efficiently with dense samples through Fourier techniques and careful implementation. Furthermore, we introduce an effective feature representation for infrared objects. Finally, we demonstrate the performance of the proposed tracker on public infrared sequences with top accuracy and robustness. Meanwhile, our single thread C++ implementation of the algorithm achieves an average tracking speed of 215 FPS on a modern cpu. © 2017 Elsevier B.V.","Dense sampling; High speed; Infrared object tracking; Structural learning","C++ (programming language); Edge detection; Feature representation; Frames per seconds; High Speed; Infrared object tracking; Structural learning; Surveillance applications; Tracking by detections; Visual tracking algorithm; Tracking (position)",2-s2.0-85032345629
"Osuna D.E., Castro C., Arredondo C.A., Luna M.A., Villegas S., Mejías N.Y., Orozco E.E., Hernández J.","ePV-Trainer: Software for dimensioning stand-alone and grid-connected photovoltaic systems for educational purposes",2017,"Measurement: Journal of the International Measurement Confederation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027862786&doi=10.1016%2fj.measurement.2017.08.026&partnerID=40&md5=ec223fe27ff72dc9ffb37bc6c19c6db2","ePV-Trainer is a user-friendly desktop application that allows users to dimension stand-alone and grid-connected photovoltaic systems. In addition, data on any geographic location in the world can be uploaded to the platform. The aim of this paper is to describe and assess the operation of the software developed in LabVIEW™. The study concludes with practical examples to verify that data delivered by the program match the one executed on manual calculations. The result is an intuitive software, which also allows to estimate the electricity generation of photovoltaic systems, based on real parameters of solar radiation and temperature. The software has been developed for educational purposes. © 2017 Elsevier Ltd","Dimensioning; Educational; Grid-connected systems; Payback period; Photovoltaic; Stand-alone systems","Investments; Photovoltaic cells; Solar power generation; Dimensioning; Educational; Grid connected systems; Payback periods; Photovoltaic; Standalone systems; Computer programming languages",2-s2.0-85027862786
"Pinheiro C.T., Ascensão V.R., Reis M.S., Quina M.J., Gando-Ferreira L.M.","A data-driven approach for the study of coagulation phenomena in waste lubricant oils and its relevance in alkaline regeneration treatments",2017,"Science of the Total Environment",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019625300&doi=10.1016%2fj.scitotenv.2017.05.124&partnerID=40&md5=ef9993d3db5f84d9b1b35317b31c5972","Coagulation phenomena can occur in certain types of waste lubricant oils (WLO) during regeneration processes involving alkaline treatments, causing plant shutdowns. In this context, this study addresses the nature of the compounds responsible for the coagulation phenomena after the alkaline treatment. For such, an empirical test was developed to assess the coagulation behaviour of WLO, consisting in the addition of KOH to the WLO followed by heating under stirring conditions. This test was performed on 133 samples and four coagulation classes were identified: A; B1; B2 and C. Moreover, a physicochemical characterization of WLO was carried out regarding viscosity at 40 °C, saponification number (SN), total acid number (TAN), surface tension, water content, elemental analysis and functional groups (FTIR). 56 samples of fresh lubricant oils for different applications were also characterized and their properties assessed and compared. Multivariate methods were applied to WLO to discriminate among coagulation classes based on FTIR spectra. It was found that coagulation classes A and B1 exhibit statistically similar patterns for all properties determined. Spectral discriminating analysis did not reveal discriminant peaks for class B1 samples, and the presence of specific additives was pointed as the possible factor underlying the increase in viscosity in this oils. Class B2 presents the absence of additives and oxidation products as differentiating features. In addition, B2 samples showed lower TAN SN, and lower concentration of some elements. Lubricants from gear or hydraulic applications can give rise to this class of WLO. Oils of Class C are mainly composed by synthetic ester type base oils, which hamper regeneration processes using alkaline pretreatments. In future studies, WLO type A and B1 can be classified as a single class. The coagulation phenomena classification becomes A – negative, B – precipitate formation and C – positive. © 2017 Elsevier B.V.","Characterization; Classification; Coagulation phenomena; FTIR spectroscopy; Regeneration; Waste lubricant oil","Characterization; Chemical water treatment; Classification (of information); Coagulation; Fourier transform infrared spectroscopy; Lubricants; Lubricating oils; Plant shutdowns; Viscosity; FTIR spectroscopy; Hydraulic application; Multivariate methods; Physico-chemical characterization; Regeneration; Regeneration treatment; Saponification numbers; Waste lubricant oil; C (programming language); functional group; lubricating agent; oil; potassium hydroxide; additive; coagulation; FTIR spectroscopy; lubricant; oil; oxidation; viscosity; Article; chemical parameters; coagulation phenomena; data analysis; elemental analysis; heating; industrial waste; physical chemistry; priority journal; regeneration; saponification; spectroscopy; surface tension; viscosity; water content",2-s2.0-85019625300
"Dirgantara R., Gunasekara C., Law D.W., Molyneaux T.K.","Suitability of brown coal fly ash for geopolymer production",2017,"Journal of Materials in Civil Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031322961&doi=10.1061%2f%28ASCE%29MT.1943-5533.0002093&partnerID=40&md5=b2ea13e5397631d92306354d4194e8bc","The use of low-calcium Class F fly ash both as a replacement material for cement and to produce geopolymers has become established practice. However, much of the fly ash produced globally is either high-calcium Class C or brown coal (BC) fly ash, whose use as a cement replacement or geopolymeric material is very limited. This study reports the results of using BC fly ash from three separate sources to assess the feasibility of geopolymer concrete manufacturing and factors affecting the compressive strength of the geopolymeric material produced. The effects of the chemical composition of the raw fly ash, alkali modulus of the activator, and mineralogical properties of the raw material are reported. The results show that the manufacture of geopolymer mortar from BC fly ash was feasible, with compressive strengths of up to 50 MPa obtained. The key factors in selecting BC fly ash and determining its geopolymer compressive strength were the combined aluminate-silicate content of raw material, reactive amorphous content, and zeta potential. The data also emphasize the need for careful consideration of the modification of the activator modulus when designing a specific geopolymer mix. © 2017 American Society of Civil Engineers.","Brown coal fly ash; Compressive strength; Geopolymer; Mix design; Zeta potential","Amorphous materials; C (programming language); Calcium; Cements; Coal; Compressive strength; Fly ash; Geopolymers; Inorganic polymers; Lignite; Manufacture; Silicates; Strength of materials; Zeta potential; Chemical compositions; Coal fly ash; Geopolymer; Geopolymer concrete; Geopolymer mortars; Mineralogical properties; Mix designs; Replacement materials; Coal ash; chemical composition; compressive strength; design; fly ash; lignite; mineralogy; polymer",2-s2.0-85031322961
"Feng J.-L., Yang Z.-J., Bai W.-W., Chen S.-P., Xu W.-Q., El-Kassaby Y.A., Chen H.","Transcriptome comparative analysis of two Camellia species reveals lipid metabolism during mature seed natural drying",2017,"Trees - Structure and Function",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026530994&doi=10.1007%2fs00468-017-1588-5&partnerID=40&md5=e69154e28dd5c3e636912e35d149b82d","Key message: The molecular mechanisms of fatty acid biosynthesis and accumulation duringCamellia meiocarpa andCamellia oleifera seed natural drying are characterized through transcriptome analyses. Abstract: Camellia seed oil has been used as high quality and healthy food for over two thousand years. Seed drying affects oil quality and quantity; however, the molecular mechanisms of fatty acid biosynthesis and accumulation during the drying process remain unknown. In this study, the transcriptomes of Camellia meiocarpa and C. oleifera seed were characterized at five moisture content levels (10–50%) to identify the major processes and reveal genes affecting lipid metabolism in response to natural drying. We found a total of 111,156 unigenes by de novo assembled from RNA-Seq libraries of five moisture content levels during after-ripening of C. meiocarpa (74,016) and C. oleifera (76,374). Ten pathways were closely linked to changes in oil content and composition with 244 genes involved in fatty acid synthesis and accumulation. Gene ontology enrichment of differentially expressed genes (DEGs) indicated that fatty acid synthesis and accumulation are essential in C. meiocarpa while fatty acid accumulation in C. oleifera during natural drying process. Comparative analyses of DEGs between any two consecutive moisture contents identified six and three key unigenes in C. meiocarpaand C.oleifera seeds, respectively, and one additional unigene responsible for the difference between the two species’ fatty acid synthesis and accumulation. Natural drying has improved the quality and quantity of the camellia seed oil. The study provided: (a) global transcriptional profiles at five moisture content levels during seed natural drying, (b) highlighting transcripts putatively involved in the regulation of gene expression program and in specific processes likely essential for lipid metabolism, and (c) discovery of genes associated with oil seed quantity and quality improvement for the studied two camellia species. © 2017, The Author(s).","Camellia meiocarpa; Camellia oleifera; Lipid metabolism; Natural drying; Transcriptome","Biochemistry; Biosynthesis; C (programming language); Drying; Gene expression; Gene expression regulation; Genes; Metabolism; Moisture; Moisture determination; Oils and fats; Physiology; Thermal processing (foods); Camellia meiocarpa; Camellia oleifera; Lipid metabolisms; Natural drying; Transcriptomes; Fatty acids",2-s2.0-85026530994
"Sarvghad M., Will G., Steinberg T.A.","Corrosion of Inconel 601 in molten salts for thermal energy storage",2017,"Solar Energy Materials and Solar Cells",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026444991&doi=10.1016%2fj.solmat.2017.07.036&partnerID=40&md5=e1dacc2da81295a7e2f41006af47228b","Inconel 601 superalloy was examined for compatibility with the eutectic mixtures of NaCl + Na2SO4 and NaCl + Na2CO3 at 700 °C and Li2CO3 + K2CO3 + Na2CO3 at 450 °C in air for thermal energy storage. Electrochemical measurements combined with advanced microscopy and microanalysis techniques were employed. Oxidation was the primary attack leading to the development of oxide deposits on the alloy surface. The deposit was not stable in NaCl + Na2CO3 because of the fluxing action and high solubility of chromium in the salt leading to very high corrosion current density values. De-alloying threatened the material at 700 °C while the availability of oxygen controlled its rate. The availability of oxygen was seen to limit the corrosion rate in NaCl + Na2SO4 and NaCl + Na2CO3. De-alloying also appeared as pits on the metal surface at 700 °C. For the metal in contact with NaCl + Na2SO4 an additional layer attacked by sulfur was found under the pitting corroded layer. The attack morphology on the metal surface in contact with Li2CO3 + K2CO3 + Na2CO3 at 450 °C was found to be uniform. © 2017 Elsevier B.V.","Corrosion; Impedance spectroscopy; Inconel 601; Microscopy; Molten salt; Polarization","Alloying; C (programming language); Corrosion; Deposits; Electrochemical corrosion; Energy storage; Fused salts; Heat storage; Microscopic examination; Polarization; Thermal energy; Attack morphologies; Corrosion current densities; Electrochemical measurements; Eutectic mixture; Impedance spectroscopy; Inconel 601; Microscopy and microanalysis techniques; Molten salt; Corrosion rate",2-s2.0-85026444991
"Novosel L., Šišul G.","Performance evaluation of chaotic spreading sequences on software-defined radio",2017,"Eurasip Journal on Wireless Communications and Networking",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018241589&doi=10.1186%2fs13638-017-0866-7&partnerID=40&md5=a260dcf70604f5cb89f6af6c355b9e83","In this paper, bit error performance evaluation of chaotic sequences is presented. Performance of chaotic sequences is evaluated on multiple access spread spectrum system model for USRP software defined radio. LabVIEW is used to perform numerical simulations and bit error rate analysis. Chaotic sequences of different lengths are generated using one-dimensional, two-dimensional, and three-dimensional maps. It is expected that sequences generated from complex maps will have better multiple access performance. Performance of chaotic sequences is evaluated against orthogonal sequences in multiple access scenario. Using Golay figure of merit and Pearson correlation coefficient, analysis of correlation properties and a comparison is performed on orthogonal and chaotic sequences for correlation properties comparison. The results show that chaotic sequences from two-dimensional maps have lower bit error rate than orthogonal and other chaotic sequences. Comparison of correlation properties shows that sequences with a low figure of merit and low Pearson coefficient have lower bit error rate. Those results can be used to generate chaotic sequences with desired correlation properties. © 2017, The Author(s).","Chaotic map; Chaotic sequence; LabVIEW; Multiple access; Software-defined radio; Spread spectrum; USRP","Analog circuits; Chaos theory; Chaotic systems; Computer programming languages; Correlation methods; Errors; Optical communication; Radio; Radio receivers; Software radio; Spectroscopy; Chaotic map; Chaotic sequence; LabViEW; Multiple access; Software-defined radios; Spread spectra; USRP; Bit error rate",2-s2.0-85018241589
"Sun Q., Chen Z., Han R., Nie Y., Zhang S., Luo F., Shi F., Tian G., Lin W., Ren P., Song L., Ruan X., Ren J.","Experiment on uranium slabs of different thicknesses with D-T neutrons and validation of evaluated nuclear data",2017,"Fusion Engineering and Design",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032507059&doi=10.1016%2fj.fusengdes.2017.10.021&partnerID=40&md5=1f27015de2e9f68e9f3dcffeb87f59b8","In order to validate the evaluated nuclear data for 238U, leakage neutron spectra from pure 238U slab samples of different thicknesses bombarded with 14.8 MeV D-T neutrons were measured at 60 ° (for 10 cm × 10 cm × 2 cm, 10 cm × 10 cm × 5 cm, 10 cm × 10 cm × 11 cm samples) and 120 ° (for 10 cm × 10 cm × 5 cm, 10 cm × 10 cm × 11 cm samples) respectively. The measurement was performed at China Institute of Atomic Energy using time-of-flight method. Monte Carlo simulations were carried out by MCNP-4C code combined with various evaluated nuclear data libraries, namely, ENDF/B-VII.1, JENDL-4.0, CENDL-3.1, JEFF-3.2 and TENDL-2015. The experimental results were compared with the corresponding calculated ones, and the calculation-to-experiment ratio (C/E) which indicates the agreement between them was obtained. The results show that the JENDL4.0 fitted the experimental data best. © 2017 Elsevier B.V.","238U slabs; Evaluated data validation; Integral experiments; Leakage neutron spectra","Intelligent systems; Libraries; Monte Carlo methods; DT neutron; Evaluated data; Integral experiments; Leakage neutrons; Nuclear data; Nuclear data library; Time of Flight methods; ^238U slabs; C (programming language)",2-s2.0-85032507059
"Le Thi H.A., Pham Dinh T.","Difference of convex functions algorithms (DCA) for image restoration via a Markov random field model",2017,"Optimization and Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020102535&doi=10.1007%2fs11081-017-9359-0&partnerID=40&md5=48aa903b62de45aafca11ce36322ba85","In this paper, we introduce a novel approach in the nonconvex optimization framework for image restoration via a Markov random field (MRF) model. While image restoration is elegantly expressed in the language of MRF’s, the resulting energy minimization problem was widely viewed as intractable: it exhibits a highly nonsmooth nonconvex energy function with many local minima, and is known to be NP-hard. The main goal of this paper is to develop fast and scalable approximation optimization approaches to a nonsmooth nonconvex MRF model which corresponds to an MRF with a truncated quadratic (also known as half-quadratic) prior. For this aim, we use the difference of convex functions (DC) programming and DC algorithm (DCA), a fast and robust approach in smooth/nonsmooth nonconvex programming, which have been successfully applied in various fields in recent years. We propose two DC formulations and investigate the two corresponding versions of DCA. Numerical simulations show the efficiency, reliability and robustness of our customized DCAs with respect to the standard GNC algorithm and the Graph-Cut based method—a more recent and efficient approach to image analysis. © 2017, Springer Science+Business Media New York.","DC programming; DCA; GNC; Graph-Cut method; Image restoration; Markov random field model; Smooth/nonsmooth nonconvex programming","Functions; Graphic methods; Image reconstruction; Image segmentation; Markov processes; Numerical methods; Reliability analysis; Restoration; Structural frames; Approximation optimization; D-C programming; Difference of convex functions; Energy minimization problem; Graph-cut methods; Markov Random Field model; Non-convex programming; Reliability and robustness; Optimization",2-s2.0-85020102535
"Riguzzi F., Cota G., Bellodi E., Zese R.","Causal inference in cplint",2017,"International Journal of Approximate Reasoning",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030328525&doi=10.1016%2fj.ijar.2017.09.007&partnerID=40&md5=1a709713719cf1e38f146038575e5020","cplint is a suite of programs for reasoning and learning with Probabilistic Logic Programming languages that follow the distribution semantics. In this paper we describe how we have extended cplint to perform causal reasoning. In particular, we consider Pearl's do calculus for models where all the variables are measured. The two cplint modules for inference, PITA and MCINTYRE, have been extended for computing the effect of actions/interventions on these models. We also executed experiments comparing exact and approximate inference with conditional and causal queries, showing that causal inference is often cheaper than conditional inference. © 2017 Elsevier Inc.","Causal inference; Distribution semantics; Logic programs with annotated disjunctions; Probabilistic Logic Programming; ProbLog; Statistical relational artificial intelligence","Calculations; Computation theory; Computer circuits; Logic programming; Probability distributions; Semantics; Causal inferences; Causal reasoning; Conditional inference; Distribution semantics; Do-calculus; Exact and approximate inferences; Logic programs; ProbLog; Probabilistic logics",2-s2.0-85030328525
"Brambilla M., Umuhoza E., Acerbis R.","Model-driven development of user interfaces for IoT systems via domain-specific components and patterns",2017,"Journal of Internet Services and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029936829&doi=10.1186%2fs13174-017-0064-1&partnerID=40&md5=4787a4ae6ced934fd98d032da24e6b3f","Internet of Things technologies and applications are evolving and continuously gaining traction in all fields and environments, including homes, cities, services, industry and commercial enterprises. However, still many problems need to be addressed. For instance, the IoT vision is mainly focused on the technological and infrastructure aspect, and on the management and analysis of the huge amount of generated data, while so far the development of front-end and user interfaces for IoT has not played a relevant role in research. On the contrary, user interfaces can play a key role in the acceptance of IoT solutions by final adopters. In this paper we discuss the requirements and usage scenarios covering the front end aspects of IoT systems and we present a model-driven approach to the design of such interfaces by: defining specific components and design patterns using a visual modeling language for IoT applications; describing an implementation of the solution that comprises also automatic code generation from models; and by showing the solution at work. © 2017, The Author(s).","Design pattern; IFML; Internet of things; Mobile applications; Model-driven development; Modeling; Software engineering; User experience; User interaction","Application programs; Automatic programming; Modeling languages; Models; Research and development management; Software engineering; Systems analysis; User interfaces; Visual languages; Design Patterns; IFML; Mobile applications; Model driven development; User experience; User interaction; Internet of things",2-s2.0-85029936829
"Morse P., Reading A., Lueg C.","Animated analysis of geoscientific datasets: An interactive graphical application",2017,"Computers and Geosciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027585807&doi=10.1016%2fj.cageo.2017.07.006&partnerID=40&md5=70281a71f55a7c760e948abf127a3141","Geoscientists are required to analyze and draw conclusions from increasingly large volumes of data. There is a need to recognise and characterise features and changing patterns of Earth observables within such large datasets. It is also necessary to identify significant subsets of the data for more detailed analysis. We present an innovative, interactive software tool and workflow to visualise, characterise, sample and tag large geoscientific datasets from both local and cloud-based repositories. It uses an animated interface and human-computer interaction to utilise the capacity of human expert observers to identify features via enhanced visual analytics. ‘Tagger’ enables users to analyze datasets that are too large in volume to be drawn legibly on a reasonable number of single static plots. Users interact with the moving graphical display, tagging data ranges of interest for subsequent attention. The tool provides a rapid pre-pass process using fast GPU-based OpenGL graphics and data-handling and is coded in the Quartz Composer visual programing language (VPL) on Mac OSX. It makes use of interoperable data formats, and cloud-based (or local) data storage and compute. In a case study, Tagger was used to characterise a decade (2000–2009) of data recorded by the Cape Sorell Waverider Buoy, located approximately 10 km off the west coast of Tasmania, Australia. These data serve as a proxy for the understanding of Southern Ocean storminess, which has both local and global implications. This example shows use of the tool to identify and characterise 4 different types of storm and non-storm events during this time. Events characterised in this way are compared with conventional analysis, noting advantages and limitations of data analysis using animation and human interaction. Tagger provides a new ability to make use of humans as feature detectors in computer-based analysis of large-volume geosciences and other data. © 2017 The Authors","Animated; Interactive; Time series analysis; Visual analytics","Application programming interfaces (API); Computational linguistics; Computer aided analysis; Computer aided software engineering; Computer graphics; Digital storage; Feature extraction; Human computer interaction; Storms; Time series analysis; Visual languages; Visualization; Animated; Computer-based analysis; Graphical applications; Graphical displays; Interactive; Interactive software tool; Tasmania , Australia; Visual analytics; Data handling",2-s2.0-85027585807
"Carreras A., Togo A., Tanaka I.","DynaPhoPy: A code for extracting phonon quasiparticles from molecular dynamics simulations",2017,"Computer Physics Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028880735&doi=10.1016%2fj.cpc.2017.08.017&partnerID=40&md5=37a9c4c17e6987dd4a7c9aa4d90d20e0","We have developed a computational code, DYNAPHOPY, that allows us to extract the microscopic anharmonic phonon properties from molecular dynamics (MD) simulations using the normal-mode-decomposition technique as presented by Sun et al. (2014). Using this code we calculated the quasiparticle phonon frequencies and linewidths of crystalline silicon at different temperatures using both of first-principles and the Tersoff empirical potential approaches. In this work we show the dependence of these properties on the temperature using both approaches and compare them with reported experimental data obtained by Raman spectroscopy (Balkanski et al., 1983; Tsu and Hernandez, 1982). Program summary Manuscript Title: DynaPhoPy: A code for extracting phonon quasiparticles from molecular dynamics simulations Authors: Abel Carreras, Atsushi Togo and Isao Tanaka Program Title: DynaPhoPy Journal Reference: Catalogue identifier: Licensing provisions: MIT License Programming language: Python and C Computer: PC and cluster computers Operating system: UNIX/OSX RAM: Depends strongly on number of input data (several Gb) Number of processors used: 1–16 Supplementary material: Keywords: anharmonicity, phonon, linewidth, frequency shift, molecular dynamics Classification: 7.8 Structure and Lattice Dynamics External routines/libraries: phonopy, numpy, matplotlib, scipy and h5py python modules. Optional: FFTW and Cuda Subprograms used: Catalogue identifier of previous version: * Journal reference of previous version: * Does the new version supersede the previous version?: * Nature of problem: Increasing temperature, a crystal potential starts to deviate from the harmonic regime and anharmonicity is getting to be evident [1]. To treat anharmonicity, perturbation approach often describes successfully phenomena such as phonon lifetime and lattice thermal conductivity. However it fails when the system contains large atomic displacements. Solution method: Extracting the phonon quasiparticles from molecular dynamics (MD) simulations using the normal-mode-decomposition technique. Reasons for the new version: * Summary of revisions: * Restrictions: Quantum effects of lattice dynamics are not considered. Unusual features: Additional comments: Running time: It is highly dependent on the type of calculation requested. It depends mainly on the number of atoms in the primitive cell, the number of time steps of the MD simulation and the method employed to calculate the power spectra. Currently two methods are implemented in DyaPhoPy: The Fourier transform and the maximum entropy methods. The Fourier transform method scales to O [N2] and the maximum entropy method scales to O [N×M] where N is the number of time steps and M is the number of coefficients. © 2017 Elsevier B.V.","Anharmonicity; Frequency shift; Linewidth; Molecular dynamics; Phonon","Atoms; Calculations; Codes (symbols); Computational chemistry; Computer programming; Crystal lattices; High level languages; Lattice vibrations; Linewidth; Maximum entropy methods; Phonons; Quantum electronics; Quantum theory; Thermal conductivity; Anharmonicities; Catalogue identifiers; Fourier transform method; Frequency shift; Increasing temperatures; Lattice thermal conductivity; Molecular dynamics simulations; Perturbation approach; Molecular dynamics",2-s2.0-85028880735
"Li X., Wang X., Zhang H., Guo Y.","Trajectory optimization using analytical target cascading",2017,"Journal of Mechanical Design, Transactions of the ASME",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030792687&doi=10.1115%2f1.4037714&partnerID=40&md5=e6d39c3507dd121217a0aac2d24930d3","In the previous reports, analytical target cascading (ATC) is generally applied to product optimization. In this paper, the application area of ATC is expanded to trajectory optimization. Direct collocation method is utilized to convert a trajectory optimization into a nonlinear programing (NLP) problem. The converted NLP is a large-scale problem with sparse matrix of functional dependence table (FDT) suitable for the application of ATC. Three numerical case studies are provided to show the effects of ATC in solving trajectory optimization problems.",,"Aerodynamics; Natural language processing systems; Nonlinear programming; Optimization; Trajectories; Analytical target cascading; Application area; Direct collocation methods; Functional dependence; Large-scale problem; Product optimization; Sparse matrices; Trajectory optimization; Problem solving",2-s2.0-85030792687
"Boutellier J., Nyländen T.","Design Flow for GPU and Multicore Execution of Dynamic Dataflow Programs",2017,"Journal of Signal Processing Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021239311&doi=10.1007%2fs11265-017-1260-8&partnerID=40&md5=14960725664f09fec51858cb483e393d","Dataflow programming has received increasing attention in the age of multicore and heterogeneous computing. Modular and concurrent dataflow program descriptions enable highly automated approaches for design space exploration, optimization and deployment of applications. A great advance in dataflow programming has been the recent introduction of the RVC-CAL language. Having been standardized by the ISO, the RVC-CAL dataflow language provides a solid basis for the development of tools, design methodologies and design flows. This paper proposes a novel design flow for mapping RVC-CAL dataflow programs to parallel and heterogeneous execution platforms. Through the proposed design flow the programmer can describe an application in the RVC-CAL language and map it to multi- and many-core platforms, as well as GPUs, for efficient execution. The functionality and efficiency of the proposed approach is demonstrated by a parallel implementation of a video processing application and a run-time reconfigurable filter for telecommunications. Experiments are performed on GPU and multicore platforms with up to 16 cores, and the results show that for high-performance applications the proposed design flow provides up to 4 × higher throughput than the state-of-the-art approach in multicore execution of RVC-CAL programs. © 2017, Springer Science+Business Media, LLC.","Dataflow computing; Design automation; Parallel processing; Signal processing","Application programs; Computer aided design; Design; Graphics processing unit; Program processors; Signal processing; Video signal processing; Dataflow; Design automations; Design space exploration; High performance applications; Parallel implementations; Parallel processing; State-of-the-art approach; Video processing applications; Multicore programming",2-s2.0-85021239311
"Cabodi G., Garbo A., Loiacono C., Quer S., Francini G.","Efficient Complex High-Precision Computations on GPUs without Precision Loss",2017,"Journal of Circuits, Systems and Computers",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026530869&doi=10.1142%2fS0218126617501870&partnerID=40&md5=dbbb02d9f02239b5de10db55268be70e","General-purpose computing on graphics processing units is the utilization of a graphics processing unit (GPU) to perform computation in applications traditionally handled by the central processing unit. Many attempts have been made to implement well-known algorithms on embedded and mobile GPUs. Unfortunately, these applications are computationally complex and often require high precision arithmetic, whereas embedded and mobile GPUs are designed specifically for graphics, and thus are very restrictive in terms of input/output, precision, programming style and primitives available. This paper studies how to implement efficient and accurate high-precision algorithms on embedded GPUs adopting the OpenGL ES language. We discuss the problems arising during the design phase, and we detail our implementation choices, focusing on the SIFT and ALP key-point detectors. We transform standard, i.e., single (or double) precision floating-point computations, to reduced-precision GPU arithmetic without precision loss. We develop a desktop framework to simulate Gaussian Scale Space transforms on all possible target embedded GPU platforms, and with all possible range and precision arithmetic. We illustrate how to re-engineer standard Gaussian Scale Space computations to mobile multi-core parallel GPUs using the OpenGL ES language. We present experiments on a large set of standard images, proving how efficiency and accuracy can be maintained on different target platforms. To sum up, we present a complete framework to minimize future programming effort, i.e., to easily check, on different embedded platforms, the accuracy and performance of complex algorithms requiring high-precision computations. © 2017 World Scientific Publishing Company.","arithmetic precision; concurrent computing; Gaussian scale space; General-purpose graphics processing units (GPGPU)","Application programming interfaces (API); Computer graphics; Computer graphics equipment; Digital arithmetic; Gaussian distribution; Image coding; Program processors; Space platforms; Concurrent computing; Gaussian scale space; General purpose graphics processing unit (GPGPU); General-purpose computing; High precision computation; Multi-core parallels; Precision arithmetic; Precision floating point; Graphics processing unit",2-s2.0-85026530869
"Kiršanskas G., Pedersen J.N., Karlström O., Leijnse M., Wacker A.","QmeQ 1.0: An open-source Python package for calculations of transport through quantum dot devices",2017,"Computer Physics Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028709688&doi=10.1016%2fj.cpc.2017.07.024&partnerID=40&md5=987a83a10764544525b36a9159ca2101","QmeQ is an open-source Python package for numerical modeling of transport through quantum dot devices with strong electron–electron interactions using various approximate master equation approaches. The package provides a framework for calculating stationary particle or energy currents driven by differences in chemical potentials or temperatures between the leads which are tunnel coupled to the quantum dots. The electronic structures of the quantum dots are described by their single-particle states and the Coulomb matrix elements between the states. When transport is treated perturbatively to lowest order in the tunneling couplings, the possible approaches are Pauli (classical), first-order Redfield, and first-order von Neumann master equations, and a particular form of the Lindblad equation. When all processes involving two-particle excitations in the leads are of interest, the second-order von Neumann approach can be applied. All these approaches are implemented in QmeQ. We here give an overview of the basic structure of the package, give examples of transport calculations, and outline the range of applicability of the different approximate approaches. Program summary Program Title: QmeQ Program Files doi: http://dx.doi.org/10.17632/8687mrhgg9.1 Licensing provisions: BSD 2-Clause Programming language: Python External libraries: NumPy, SciPy, Cython Nature of problem: Calculation of stationary state currents through quantum dots tunnel coupled to leads. Solution method: Exact diagonalization of the quantum dot Hamiltonian for a given set of single particle states and Coulomb matrix elements. Numerical solution of the stationary-state master equation for a given approximate approach. Restrictions: Depending on the approximate approach the temperature needs to be sufficiently large compared to the coupling strength for the approach to be valid. © 2017 Elsevier B.V.","Anderson-type model; Coulomb blockade; Open quantum systems; Python; Quantum dots","Coulomb blockade; Electron-electron interactions; Electronic structure; Equations of state; High level languages; Nanocrystals; Open source software; Quantum chemistry; Quantum optics; Quantum theory; Systems analysis; Andersons; Coulomb matrix elements; Exact diagonalization; Open quantum systems; Python; Quantum dot devices; Single particle state; Transport calculation; Semiconductor quantum dots",2-s2.0-85028709688
"Rutkai G., Köster A., Guevara-Carrion G., Janzen T., Schappals M., Glass C.W., Bernreuther M., Wafai A., Stephan S., Kohns M., Reiser S., Deublein S., Horsch M., Hasse H., Vrabec J.","ms2: A molecular simulation tool for thermodynamic properties, release 3.0",2017,"Computer Physics Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028607352&doi=10.1016%2fj.cpc.2017.07.025&partnerID=40&md5=6dc49e2dbd7a39b13829a27a960dd70d","A new version release (3.0) of the molecular simulation tool ms 2 (Deublein et al., 2011; Glass et al. 2014) is presented. Version 3.0 of ms 2 features two additional ensembles, i.e. microcanonical (NVE) and isobaric–isoenthalpic (NpH), various Helmholtz energy derivatives in the NVE ensemble, thermodynamic integration as a method for calculating the chemical potential, the osmotic pressure for calculating the activity of solvents, the six Maxwell–Stefan diffusion coefficients of quaternary mixtures, statistics for sampling hydrogen bonds, smooth-particle mesh Ewald summation as well as the ability to carry out molecular dynamics runs for an arbitrary number of state points in a single program execution. New version program summary Program Title:ms2 Program Files doi: http://dx.doi.org/10.17632/9rcrykvkyh.1 Licensing provisions: CC by NC 3.0 Programming language: Fortran95 Supplementary material: A detailed description of the parameter setup for thermodynamic integration and hydrogen bonding is given in the supplementary material. Furthermore, all molecular force field models developed by our group are provided Journal reference of previous versions: Deublein et al., Comput. Phys. Commun. 182 (2011) 2350 and Glass et al., Comput. Phys. Commun. 185 (2014) 3302 Does the new version supersede the previous version?: Yes Reasons for the new version: Introduction of new features as well as enhancement of computational efficiency Summary of revisions: Two new ensembles (NVE and NpH), new properties (Helmholtz energy derivatives, chemical potential via thermodynamic integration, activity coefficients via osmotic pressure, Maxwell–Stefan diffusion coefficients of quaternary mixtures), new functionalities (detection and statistics of hydrogen bonding, smooth-particle mesh Ewald summation, ability to carry out molecular dynamics runs for an arbitrary number of state points in a single program execution). Nature of problem: Calculation of application oriented thermodynamic properties: vapor–liquid equilibria of pure fluids and multi-component mixtures, thermal, caloric and entropic data as well as transport properties and data on microscopic structure Solution method: Molecular dynamics, Monte Carlo, various ensembles, Grand Equilibrium method, Green–Kubo formalism, Lustig formalism, OPAS method, smooth-particle mesh Ewald summation Restrictions: Typical problems addressed by ms2 are solved by simulating systems containing 1000 to 5000 molecules that are modeled as rigid bodies. Additional comments: Documentation is available at http://www.ms-2.de © 2017 Elsevier B.V.","Molecular dynamics; Molecular simulation; Monte Carlo","Aluminum; Chemical bonds; Chemical detection; Chemical potential; Computational efficiency; Diffusion; Glass; Hydrogen bonds; Integration; Mesh generation; Mixtures; Molecular dynamics; Molecular structure; Osmosis; Phase equilibria; Problem oriented languages; Sampling; Thermodynamic properties; Thermodynamics; Application-oriented; Green-Kubo formalism; Maxwell-Stefan diffusion coefficients; Microscopic structures; Molecular force field; Molecular simulations; Multicomponent mixture; Thermodynamic integration; Monte Carlo methods",2-s2.0-85028607352
"Exl L.","A GPU accelerated and error-controlled solver for the unbounded Poisson equation in three dimensions",2017,"Computer Physics Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028818850&doi=10.1016%2fj.cpc.2017.08.014&partnerID=40&md5=b679a3b24f9b9dee6b7559e9a10c1707","An efficient solver for the three dimensional free-space Poisson equation is presented. The underlying numerical method is based on finite Fourier series approximation. While the error of all involved approximations can be fully controlled, the overall computation error is driven by the convergence of the finite Fourier series of the density. For smooth and fast-decaying densities the proposed method will be spectrally accurate. The method scales with O(NlogN) operations, where N is the total number of discretization points in the Cartesian grid. The majority of the computational costs come from fast Fourier transforms (FFT), which makes it ideal for GPU computation. Several numerical computations on CPU and GPU validate the method and show efficiency and convergence behavior. Tests are performed using the Vienna Scientific Cluster 3 (VSC3). A free MATLAB implementation for CPU and GPU is provided to the interested community. Program summary Program Title: GSPoisson3d Program Files doi: http://dx.doi.org/10.17632/xh6d47sxx8.1 Licensing provisions: MIT Programming language: MATLAB R2015b Nature of problem: Efficient and accurate computation of the unbounded Poisson equation in three dimensions. Solution method: Fourier based approach with Gaussian-sum approximation of the singular convolution kernel and near field correction — both utilizing FFT. Additional comments: Incorporated GPU acceleration via MATLAB's GPU fft implementation. © 2017 Elsevier B.V.","Convolution via fast Fourier transform (FFT); Free space Coulomb/dipole–dipole potential; GPU computing; Separable Gaussian-sum (GS) approximation","Computational efficiency; Convergence of numerical methods; Convolution; Errors; Fourier series; Graphics processing unit; MATLAB; Numerical methods; Poisson equation; Signal receivers; Accurate computations; Convergence behaviors; Finite Fourier series; Free spaces; Gaussian sum; Gaussian sum approximation; GPU computing; Numerical computations; Fast Fourier transforms",2-s2.0-85028818850
"Georgoudis A., Larsen K.J., Zhang Y.","AZURITE: An algebraic geometry based package for finding bases of loop integrals",2017,"Computer Physics Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031931497&doi=10.1016%2fj.cpc.2017.08.013&partnerID=40&md5=fa96eeb53876158ef03b58028bba8b63","For any given Feynman graph, the set of integrals with all possible powers of the propagators spans a vector space of finite dimension. We introduce the package AZURITE (A ZUR ich-bred method for finding master I nTE grals), which efficiently finds a basis of this vector space. It constructs the needed integration-by-parts (IBP) identities on a set of generalized-unitarity cuts. It is based on syzygy computations and analyses of the symmetries of the involved Feynman diagrams and is powered by the computer algebra systems SINGULAR and MATHEMATICA. It can moreover analytically calculate the part of the IBP identities that is supported on the cuts. In some cases, the basis obtained by AZURITE may be slightly overcomplete. Program summary Program Title:AZURITE Licensing provisions: GNU General Public License (GPL) Programming language: Wolfram MATHEMATICA version 10.0 or higher Supplementary material: A manual in the form of a MATHEMATICA notebook Nature of problem: Determination of a basis of the space of loop integrals spanned by a given Feynman diagram and all of its subdiagrams Solution method:MATHEMATICA implementation © 2017 Elsevier B.V.","Computational algebraic geometry; Feynman diagrams; Integration-by-parts identities","Algebra; Computational geometry; Geometry; Open source software; Quantum theory; Algebraic geometry; Computational algebraic geometry; Computer algebra systems; Feynman diagrams; Finite dimensions; GNU general public license; Integration by parts; Solution methods; Vector spaces",2-s2.0-85031931497
"Kazmi M., Schüller P., Saygın Y.","Improving scalability of inductive logic programming via pruning and best-effort optimisation",2017,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021056454&doi=10.1016%2fj.eswa.2017.06.013&partnerID=40&md5=e412a6b9307af4cbfe10a79737fd105d","Inductive Logic Programming (ILP) combines rule-based and statistical artificial intelligence methods, by learning a hypothesis comprising a set of rules given background knowledge and constraints for the search space. We focus on extending the XHAIL algorithm for ILP which is based on Answer Set Programming and we evaluate our extensions using the Natural Language Processing application of sentence chunking. With respect to processing natural language, ILP can cater for the constant change in how we use language on a daily basis. At the same time, ILP does not require huge amounts of training examples such as other statistical methods and produces interpretable results, that means a set of rules, which can be analysed and tweaked if necessary. As contributions we extend XHAIL with (i) a pruning mechanism within the hypothesis generalisation algorithm which enables learning from larger datasets, (ii) a better usage of modern solver technology using recently developed optimisation methods, and (iii) a time budget that permits the usage of suboptimal results. We evaluate these improvements on the task of sentence chunking using three datasets from a recent SemEval competition. Results show that our improvements allow for learning on bigger datasets with results that are of similar quality to state-of-the-art systems on the same task. Moreover, we compare the hypotheses obtained on datasets to gain insights on the structure of each dataset. © 2017 Elsevier Ltd","Answer Set Programming; Chunking; Inductive logic programming; Natural Language Processing","Budget control; Computer circuits; Computer programming; Education; Logic programming; Natural language processing systems; Optimization; Answer set programming; Artificial intelligence methods; Back-ground knowledge; Chunking; Natural languages; Optimisation method; State-of-the-art system; Training example; Inductive logic programming (ILP)",2-s2.0-85021056454
"Søndergaard H., Korsholm S.E., Ravn A.P.","Conformance test development with the Java modeling language",2017,"Concurrency Computation ",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011632659&doi=10.1002%2fcpe.4071&partnerID=40&md5=b3993a79fdcea803d2dd8f6a7b2d0bc9","In order to claim conformance with a Java Specification Request, a Java implementation has to pass all tests in an associated Technology Compatibility Kit. This paper presents a model-based development of a Technology Compatibility Kit test suite and a test execution tool for the draft safety-critical Java profile specification. The Java Modeling Language is used to model conformance constraints for the profile. Java Modeling Language annotations define contracts for classes and interfaces. The annotations are translated by a tool into runtime assertion checks. Hereby, the design and elaboration of the concrete test cases are simplified, because the expected results are derived from contracts and thus do not need to be provided explicitly. Bottom-up testing is applied for testing methods of the safety-critical Java classes, whereas top-down testing is applied for testing global properties, such as protocols, memory management, and real-time properties, including scheduling. The tests are executed using a simplified version of JUnit, which makes the test suite executable on resource-constrained platforms. Copyright © 2017 John Wiley & Sons, Ltd. Copyright © 2017 John Wiley & Sons, Ltd.","conformance test; formal specification; Java Modeling Language; model-based testing; real-time Java; safety-critical Java; Technology Compatibility Kit; test","Acceptance tests; Formal specification; Integration testing; Model checking; Modeling languages; Real time systems; Safety engineering; Safety testing; Scheduling; Specifications; Testing; Java implementation; Java Modeling Language; Java specification requests; Memory management; Model based development; Model based testing; Real-time Java; Real-time properties; Java programming language",2-s2.0-85011632659
"Luckow K.S., Thomsen B., Korsholm S.E.","HVMTP: A time predictable and portable java virtual machine for hard real-time embedded systems",2017,"Concurrency Computation ",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963690369&doi=10.1002%2fcpe.3828&partnerID=40&md5=5258f4f651ed6051d880737a602316d0","We present HVMTP, a time predictable and portable Java virtual machine (JVM) implementation with applications in resource-constrained, hard real-time embedded systems, which implements all levels of the safety critical Java (SCJ) specification. Time predictability is achieved by a combination of time-predictable algorithms, exploiting the programming model of the SCJ profile and harnessing static knowledge of the hosted SCJ system. This paper presents HVMTP in terms of its design and capabilities and demonstrates how a complete timing model of the JVM represented as a network of timed automata can be obtained using the tool TETASARTSJVM. The timing model readily integrates with the rest of the TETASARTS tool set for temporal verification of SCJ systems. We will also show how a complete timing scheme in terms of safe worst-case execution times and best-case execution times of the Java bytecodes can be derived from the model. Furthermore, we take a first look at how to support the new Java 8 language feature of Lambda expressions in a SCJ context – we look in particular at how the invokedynamic bytecode can be implemented in a time-predictable way and integrated in HVMTP. Copyright © 2016 John Wiley &amp; Sons, Ltd. Copyright © 2016 John Wiley & Sons, Ltd.","Java virtual machine; model checking; real-time Java; time predictability","Embedded systems; Java programming language; Model checking; Hard real-time embedded systems; Java virtual machines; Language features; Programming models; Real-time Java; Temporal verification; Time predictabilities; Worst-case execution time; Real time systems",2-s2.0-84963690369
"Schoeberl M., Dalsgaard A.E., Hansen R.R., Korsholm S.E., Ravn A.P., Rios Rivas J.R., Strøm T.B., Søndergaard H., Wellings A., Zhao S.","Safety-critical Java for embedded systems",2017,"Concurrency Computation ",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010611289&doi=10.1002%2fcpe.3963&partnerID=40&md5=0e9952fa20df217d8f858b7f725dc4c9","This paper presents the motivation for and outcomes of an engineering research project on certifiable Java for embedded systems. The project supports the upcoming standard for safety-critical Java, which defines a subset of Java and libraries aiming for development of high criticality systems. The outcome of this project include prototype safety-critical Java implementations, a time-predictable Java processor, analysis tools for memory safety, and example applications to explore the usability of safety-critical Java for this application area. The text summarizes developments and key contributions and concludes with the lessons learned. Copyright © 2016 John Wiley & Sons, Ltd. Copyright © 2016 John Wiley & Sons, Ltd.","embedded systems; real-time systems; safety-critical Java","Interactive computer systems; Java programming language; Real time systems; Safety engineering; Analysis tools; Application area; Criticality systems; Java implementation; Java processors; Memory safety; Embedded systems",2-s2.0-85010611289
"Varga M., Csukas B.","Generation of extensible ecosystem models from a network structure and from locally executable programs",2017,"Ecological Modelling",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029821380&doi=10.1016%2fj.ecolmodel.2017.09.014&partnerID=40&md5=20e20f6fea1efcc4d8ddd510d3658284","Analysis and planning of the Water/Food/Energy Nexus must be extended with the Ecosystem related interactions. Considering this, present work studies the further development and implementation of a methodology that has already been tried for the modelling and simulation of other processes within the Nexus. This methodology aims to support the unified and integrated dynamic modelling of multidisciplinary process networks, instead of interfacing amongst various field-specific tools. An additional challenge, inspired also by different approaches of food web modelling, is to build bridge between the topological network analysis and the mass/energy conservation based dynamic simulation of the underlying (often non-linear) processes. In the proposed framework the generated model appears in form of a modifiable and extensible GraphML structure that, having edited, may be interpreted into a model database for a general purpose simulation program. A very simple, food web example helps to illustrate the general method. © 2017 Elsevier B.V.","Dynamic mass balance; Ecosystem modelling; Extensible model; Model generation; Network structure","Computer programming languages; Ecology; Dynamic mass balance; Ecosystem modelling; Executable programs; Model generation; Modelling and simulations; Multi-disciplinary process; Network structures; Topological networks; Ecosystems; database; ecosystem modeling; energy balance; food web; model test; network analysis; simulation; topology",2-s2.0-85029821380
"Shen D., Shi S., Xu T.","Effects of two-dimensional programming on microstructures and thermal properties of shape memory polymer-based composites",2017,"Journal of Applied Polymer Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022187359&doi=10.1002%2fapp.45480&partnerID=40&md5=e859659c97c172cd50233c52ad013a8a","To evaluate the effects of two-dimensional (2D) programming on thermal properties of shape memory polymer (SMP)-based composites when exposed to high temperature, the specimens of composites were prepared and programmed. Then the morphology, thermal properties, dynamic evolution, and constituents of released gaseous products were characterized. Results indicate that the programmed composite is more compacted, but the proportion of interconnected voids is larger than that in the nonprogrammed sample. 2D programming causes molecular or segmental orientations in SMP, and leads to the decrease in the char yield from 16.1 to 8.1%. The programmed sample shows a lower thermal stability. Further, the melting enthalpy of nonprogrammed composite is 1012 J/g which is lower than 1100 J/g of the programmed sample. The prestored stress in oriented molecules or segments of SMP is more prone to cause the chain scissions. The dynamic evolution and constituents of released volatiles from nonprogrammed and programmed samples are similar, but the release amount of volatiles from the latter is larger. Finally, the more compacted charring layer of nonprogrammed composite is more efficient to prevent volatiles from releasing out. The 2D programming has a slight influence on the elemental contents of O, Si, and C in the charring layer. © 2017 Wiley Periodicals, Inc. J. Appl. Polym. Sci. 2017, 134, 45480. © 2017 Wiley Periodicals, Inc.","composites; degradation; thermogravimetric analysis","Composite materials; Degradation; High temperature effects; Shape memory effect; Thermodynamic properties; Thermogravimetric analysis; Dynamic evolution; Elemental contents; Gaseous products; High temperature; Melting enthalpy; Segmental orientation; Shape memory polymers; Two Dimensional (2 D); C (programming language)",2-s2.0-85022187359
"Sangwin C.J., O’Toole C.","Computer programming in the UK undergraduate mathematics curriculum",2017,"International Journal of Mathematical Education in Science and Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018500429&doi=10.1080%2f0020739X.2017.1315186&partnerID=40&md5=ff0f0e0f1a79668413d424a13ca6c34f","This paper reports a study which investigated the extent to which undergraduate mathematics students in the United Kingdom are currently taught to programme a computer as a core part of their mathematics degree programme. We undertook an online survey, with significant follow-up correspondence, to gather data on current curricula and received replies from 46 (63%) of the departments who teach a BSc mathematics degree. We found that 78% of BSc degree courses in mathematics included computer programming in a compulsory module but 11% of mathematics degree programmes do not teach programming to all their undergraduate mathematics students. In 2016, programming is most commonly taught to undergraduate mathematics students through imperative languages, notably MATLAB, using numerical analysis as the underlying (or parallel) mathematical subject matter. Statistics is a very popular choice in optional courses, using the package R. Computer algebra systems appear to be significantly less popular for compulsory first-year courses than a decade ago, and there was no mention of logic programming, functional programming or automatic theorem proving software. The modal form of assessment of computing modules is entirely by coursework (i.e. no examination). © 2017 Informa UK Limited, trading as Taylor & Francis Group.","country-specific developments; Programming and programming languages; undergraduate mathematics",,2-s2.0-85018500429
"Lavbič D., Matek T., Zrnec A.","Recommender system for learning SQL using hints",2017,"Interactive Learning Environments",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991457687&doi=10.1080%2f10494820.2016.1244084&partnerID=40&md5=63b7aac9e00739d289520c8fc9ab67d9","Today’s software industry requires individuals who are proficient in as many programming languages as possible. Structured query language (SQL), as an adopted standard, is no exception, as it is the most widely used query language to retrieve and manipulate data. However, the process of learning SQL turns out to be challenging. The need for a computer-aided solution to help users learn SQL and improve their proficiency is vital. In this study, we present a new approach to help users conceptualize basic building blocks of the language faster and more efficiently. The adaptive design of the proposed approach aids users in learning SQL by supporting their own path to the solution and employing successful previous attempts, while not enforcing the ideal solution provided by the instructor. Furthermore, we perform an empirical evaluation with 93 participants and demonstrate that the employment of hints is successful, being especially beneficial for users with lower prior knowledge. © 2016 Informa UK Limited, trading as Taylor & Francis Group.","improving classroom teaching; Intelligent Tutoring Systems; interactive learning environments; programming and programming languages; recommender system; SQL learning",,2-s2.0-84991457687
"Wang L., Wang C., Zhang Z., Wu J., Ding R., Lv B.","Thermal induced BCN nanosheets evolution and its usage as metal-free catalyst in ethylbenzene dehydrogenation",2017,"Applied Surface Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020424547&doi=10.1016%2fj.apsusc.2017.06.075&partnerID=40&md5=3c90939aba69057047547aab36406409","Compared with mushroomed progress in metal-free C-rich BCN catalysts, little is known about the BN-rich BCN or even BN ones. Its related study has drawn great interest recently but still in its infancy stage. In this study, three kinds of BCN nanosheets (NSs) with tuned surface carbon contents (5.5–14.3%), specific surface area (SSA, 82–290 m2/g) and morphologies (ultrathin nanosheets, triangular plates) were fabricated through a solid state reaction by simply adjusting the reaction temperature, and those effects on the ethylbenzene dehydrogenation performances were studied in CO2 atmosphere. The morphology evolution of BCN NSs from ultrathin nanosheets to the triangular plates was observed and control experiments were carried out. The BCN nanosheets show relatively strong interaction with CO2 and distinct CO2 absorption properties. The CO2 temperature programmed desorption also indicates that the desorption peaks of CO2 are above 400 °C, enabling them potential CO2 utilization catalysts. A weak association was found between the surface C contents and the catalytic performance as it normalized with SSA, and the B-O species could be taken as an active site in CO2 atmosphere. Though much progress still needed, it is convincing that the BCN catalyst could be a promising metal-free catalyst in dehydrogenation beyond carbocatalyst. © 2017 Elsevier B.V.","BCN nanosheets; Ethylbenzene dehydrogenation; Metal-free catalysis; Morphology evolution","C (programming language); Carbon; Catalysts; Dehydrogenation; Desorption; Ethylbenzene; Metals; Morphology; Nanosheets; Solid state reactions; Temperature programmed desorption; Bcn nanosheets; Catalytic performance; Ethylbenzene dehydrogenation; Metal-free catalysis; Metal-free catalysts; Morphology evolution; Reaction temperature; Ultrathin nanosheets; Carbon dioxide",2-s2.0-85020424547
"Yildirim I.Z., Prezzi M.","Experimental evaluation of EAF ladle steel slag as a geo-fill material: Mineralogical, physical & mechanical properties",2017,"Construction and Building Materials",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026481594&doi=10.1016%2fj.conbuildmat.2017.07.149&partnerID=40&md5=a3d8dce1b46b34e89fab97b5140d2f13","Despite of significant efforts in the last decades towards utilization of steel slag in the construction industry, steel slag stockpiling and landfilling operations do not seem to be declining in steel-producing countries. Use of steel slag as a construction material requires understanding of its engineering properties and development of a methodology to address its swelling potential. This paper focuses on the results of a series of laboratory tests (grain-size analysis, X-ray diffraction, specific gravity, compaction, maximum and minimum dry unit weight, direct shear, and long-term swelling tests) performed on samples of electric-arc-furnace ladle (EAF(L)) steel slag to assess its potential to be used as a geo-material. Direct shear test results indicated that the EAF(L) steel slag exhibits comparable frictional properties to angular crushed sand. Based on the leachate concentration levels from TCLP analyses, the EAF(L) steel slag tested was classified as Type III Solid Waste. The long-term, one-dimensional (1D) swelling test results showed continued volumetric expansion even after more than 16 months of monitoring. Replacing 5–10% by weight of EAF (L) steel slag with Class C fly ash reduced the 1D swelling to negligible levels. © 2017 Elsevier Ltd","Class C fly ash; EAF steel slag; Ladle steel slag; Long-term swelling; Mechanical properties; Mineralogy","C (programming language); Construction industry; Electric furnaces; Fly ash; Ladles; Mechanical properties; Mineralogy; Minerals; Slags; X ray diffraction; Class C fly ashes; Eaf steel slags; Engineering properties; Experimental evaluation; Frictional properties; Leachate concentrations; Minimum dry unit weight; Steel slag; Swelling",2-s2.0-85026481594
"Wu W., Li B., Gu C., Wang J., Singh A., Kumar A.","Luminescent sensing of Cu2+, CrO4 2− and photocatalytic degradation of methyl violet by Zn(II) metal-organic framework (MOF) having 5,5′-(1H-2,3,5-triazole-1,4-diyl)diisophthalic acid ligand",2017,"Journal of Molecular Structure",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026424763&doi=10.1016%2fj.molstruc.2017.07.083&partnerID=40&md5=c238750afa06dda81787cd1b4944025f","A porous Zn(II) metal–organic framework (MOF) [Zn(H2L)(4,4′-bipy)0.5]n (1) has been selected and its luminescence sensing for cations and anions as well as the photocatalytic property against methyl violet have been explored. Luminescence studies indicated that 1 could be an efficient multifunctional fluorescent material for highly sensitive detection of metal cation Cu2+ and anions CrO4 2−. The luminescence intensity of 1 was found to decrease proportionately with increase in the concentration of Cu2+ and CrO4 2−. Furthermore, the photocatalytic property of 1 for degradation of the methyl violet (MV) have been explored and a possible photocatalytic mechanism have been proposed using density of states (DOS) and partial DOS (pDOS) calculations. © 2017 Elsevier B.V.","DOS calculation; Luminescence sensing; Photocatalytic activity","Crystalline materials; Java programming language; Luminescence; Photocatalysis; Positive ions; Zinc; Zinc compounds; Fluorescent materials; Highly sensitive detections; Luminescence intensity; Luminescence studies; Metal organic framework; Photo catalytic degradation; Photocatalytic activities; Photocatalytic property; Copper",2-s2.0-85026424763
"Zaalov N.Y., Moskaleva E.V., Burmakina T.S.","Application of the IRI model to the HF propagation model with optimization of the ionosphere parameters to day-to-day variation",2017,"Advances in Space Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030854769&doi=10.1016%2fj.asr.2017.08.018&partnerID=40&md5=e815d263b92d82da5a4638e9689b4269","The HF propagation model, North Ionospheric Model and Ray Tracing (NIM-RT) was developed and tested for a number of years by comparing measured vertical and oblique ionograms over a number of radio links (especially in high latitude area) with the simulated ionograms. The present paper extends the model in order to include: (a) Implementation of the data retrieved from the International Reference Ionosphere (IRI-2012) model into the software for radio channel modeling.(b) The algorithm for IRI data optimization to the real time condition.(c) Results of comparison between simulated and measured ionograms. Based on these updates, a new software tool called North Ionospheric Model with IRI and Ray Tracing (NIMIRI-RT) was developed, and a number of vertical ionograms corresponding to multiple ionospheric reflections was simulated. The vertical ionograms observed at various ionosondes were compared with the synthesized ionograms, generated by applying NIM-RT in conjunction with initial and optimized IRI data. The ionogram structure simulated by NIMIRI-RT based on the data retrieved from optimized IRI is more reminiscent to the observations than ionograms synthesized with the initial NIMIRI-RT without parameters optimization. © 2017 COSPAR","High-latitude ionosphere; IRI; NIM-RT model; Propagation HF waves; Vertical ionogram","C (programming language); Ionosphere; Ionospheric electromagnetic wave propagation; Ionospheric measurement; Radio links; Ray tracing; High-latitude ionosphere; International reference ionospheres; Ionograms; Ionosphere parameters; Ionospheric model; Parameters optimization; Propagation modeling; Radio channel modeling; Graphic methods",2-s2.0-85030854769
"Tan W., Wang G., Huang C., Gao R., Xi B., Zhu B.","Physico-chemical protection, rather than biochemical composition, governs the responses of soil organic carbon decomposition to nitrogen addition in a temperate agroecosystem",2017,"Science of the Total Environment",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018522875&doi=10.1016%2fj.scitotenv.2017.04.143&partnerID=40&md5=46a985c81871e7238f6ad0117299671f","The heterogeneous responses of soil organic carbon (SOC) decomposition in different soil fractions to nitrogen (N) addition remain elusive. In this study, turnover rates of SOC in different aggregate fractions were quantified based on changes in δ13C following the conversion of C3 to C4 vegetation in a temperate agroecosystem. The turnover of both total organic matter and specific organic compound classes within each aggregate fraction was inhibited by N addition. Moreover, the intensity of inhibition increases with decreasing aggregate size and increasing N addition level, but does not vary among chemical compound classes within each aggregate fraction. Overall, the response of SOC decomposition to N addition is dependent on the physico-chemical protection of SOC by aggregates and minerals, rather than the biochemical composition of organic substrates. The results of this study could help to understand the fate of SOC in the context of increasing N deposition. © 2017 Elsevier B.V.","13C natural abundance; Aggregate size fraction; N addition; Organic compound class; Physico-chemical protection; Soil organic carbon turnover","Aggregates; C (programming language); Decay (organic); Decomposition; Ecosystems; Nitrogen; Organic compounds; Organic minerals; Soils; Aggregate-size fractions; Biochemical composition; Natural abundance; Nitrogen additions; Physico-chemicals; Soil organic carbon; Soil organic carbon turnovers; Total organic matter; Organic carbon; carbon 13; mineral; nitrogen; organic carbon; organic compound; organic matter; soil organic carbon; unclassified drug; agricultural ecosystem; biochemical composition; carbon isotope; decomposition; nitrogen; physicochemical property; soil carbon; soil organic matter; agroecosystem; Article; biochemical composition; controlled study; decomposition; nitrogen deposition; nonhuman; physical chemistry; soil aggregation; turnover time; vegetation",2-s2.0-85018522875
"Xie H., Shen Z., Chen L., Qiu J., Dong J.","Time-varying sensitivity analysis of hydrologic and sediment parameters at multiple timescales: Implications for conservation practices",2017,"Science of the Total Environment",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018570214&doi=10.1016%2fj.scitotenv.2017.04.074&partnerID=40&md5=3b2dce6df3f1c2b1b695ee823ee8b884","Environmental models can be used to better understand the hydrologic and sediment behavior in a watershed system. However, different processes may dominate at different time periods and timescales, which highly complicate the model interpretation. The related parameter uncertainty may be significant and needs to be addressed to avoid bias in the watershed management. In this study, we used the time-varying and multi-timescale (TVMT) method to characterize the temporal dynamics of parameter sensitivity at different timescales in hydrologic and sediment modeling. As a case study, the first order sensitivity indices were estimated with the Fourier amplitude sensitivity test (FAST) method for the Hydrological Simulation Program - Fortran (HSPF) model in the Zhangjiachong catchment in the Three Gorge Reservoir Region (TGRR) in China. The results were compared to those of the traditional aggregate method to demonstrate the merits of the TVMT method. The time-varying nature of the hydrologic and sediment parameters was revealed and explained mainly by the variation of hydro-climatic conditions. The baseflow recession parameter, evapotranspiration (ET) parameter for the soil storage, and sediment washoff parameter showed high sensitivities almost across the whole period. However, parameters related to canopy interception and channel sediment scour varied notably over time due to changes in the climate forcing. The timescale-dependent characteristics was observed and was most evident for the baseflow recession parameter and ET parameter. At last, the parameters affecting the sediment export and transport were discussed together with the inferred conservation practices. Reasonable controls for sediment must be storm-dependent. Compared to management practices on the land surface, practices affecting channel process would be more effective during storm events. Our results present one of the first investigations for sediment modeling in terms of the importance of parameter sensitivity in both time periods and evaluation timescales for the model calibration, diagnostic evaluation, and prioritizing efforts for conservation practices. © 2017 Elsevier B.V.","Best management practices; Hydrological Simulation Program - Fortran; Moving window; Scale-dependent; Temporal sensitivity; Three Gorge Reservoir Region","Catchments; FORTRAN (programming language); Reservoir management; Reservoirs (water); Sediments; Sensitivity analysis; Software testing; Soil conservation; Soil testing; Storms; Water conservation; Water management; Watersheds; Best management practices; Hydrological simulation program - fortrans; Moving window; Scale-dependent; Temporal sensitivity; Three Gorge reservoir region; Parameter estimation; baseflow; best management practice; conservation management; evapotranspiration; hydrological modeling; reservoir; sensitivity analysis; timescale; Article; canopy; catchment; climate; controlled study; environmental protection; evapotranspiration; hurricane; hydrology; sediment; sensitivity analysis; time; watershed; watershed management; China; Three Gorges Reservoir",2-s2.0-85018570214
"Rahli V., Guaspari D., Bickford M., Constable R.L.","EventML: Specification, verification, and implementation of crash-tolerant state machine replication systems",2017,"Science of Computer Programming",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020922656&doi=10.1016%2fj.scico.2017.05.009&partnerID=40&md5=077fb9897a1e0af73d46f46f869621d7","Distributed programs are known to be extremely difficult to implement, test, verify, and maintain. This is due in part to the large number of possible unforeseen interactions among components, and to the difficulty of precisely specifying what the programs should accomplish in a formal language that is intuitively clear to the programmers. We discuss here a methodology that has proven itself in building a state of the art implementation of Multi-Paxos and other distributed protocols used in a deployed database system. This article focuses on the logical foundations as well as the basic ideas of formal EventML programming, illustrated by implementing a fault-tolerant consensus protocol and showing how we prove its safety properties with the Nuprl proof assistant. © 2017 Elsevier B.V.","Event logic; EventML; Fault tolerant distributed systems; Formal verification; Nuprl","Fault tolerant computer systems; Formal languages; Formal verification; Consensus protocols; Distributed program; Distributed protocols; Event logic; EventML; Fault tolerant distributed systems; Nuprl; State machine replication; Distributed database systems",2-s2.0-85020922656
"Wang R., Ji H., Ma P., Zeng H., Xu Y., Zhang Z.-M., Lu H.-M.","Fast pure ion chromatograms extraction method for LC-MS",2017,"Chemometrics and Intelligent Laboratory Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031104797&doi=10.1016%2fj.chemolab.2017.10.001&partnerID=40&md5=8d23acd0090358d0268a0622c1b01369","Liquid chromatography coupled with mass spectrometry (LC-MS) has shown great potential in analysis complex samples. However, informative feature extraction is still challenge since the electrospray ionization in LC-MS tends to produce ninety percent or more ions not originated from compounds of interest. The concept of pure ion chromatogram (PIC) is effective to extract informative ions, but tradition PIC methods are time-consuming because of their theories and programming languages. In this study, we present a novel method, called Fast Pure Ions Chromatograms (FPIC), for extracting PICs from raw LC-MS dataset effectively and quickly. This method can search ion of PIC from its maximum bi-directionally and adaptively, which can improve the stability and reduce the computation time drastically. A further speedup has been achieved by exploiting modern software engineering techniques. FPIC was validated by analyzing four LC-MS datasets: MM14 and MM48, simulated MM48 and quantification (MTBLS234) datasets. Results show that FPIC outperformed traditional methods in the recall, precision and F-score, and it has good reliability of quantification. Furthermore, the method is very fast with few adjustable parameters, which leads to an approximately 125-fold speedup over PITracer and 18-fold speedup over XCMS. An open source implementation of the FPIC method is available at https://github.com/zmzhang/pymass. © 2017 Elsevier B.V.","Feature extraction; LC-MS; Pure ion chromatogram","Article; chemical database; controlled study; data analysis; fast pure ion chromatography; feature extraction; ion chromatography; liquid chromatography-mass spectrometry; measurement precision; priority journal; software",2-s2.0-85031104797
"Pfeuffer J., Sachsenberg T., Alka O., Walzer M., Fillbrunn A., Nilse L., Schilling O., Reinert K., Kohlbacher O.","OpenMS – A platform for reproducible analysis of mass spectrometry data",2017,"Journal of Biotechnology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020715888&doi=10.1016%2fj.jbiotec.2017.05.016&partnerID=40&md5=ebc5f6e097ac34a0257fddcdddb59840","Background In recent years, several mass spectrometry-based omics technologies emerged to investigate qualitative and quantitative changes within thousands of biologically active components such as proteins, lipids and metabolites. The research enabled through these methods potentially contributes to the diagnosis and pathophysiology of human diseases as well as to the clarification of structures and interactions between biomolecules. Simultaneously, technological advances in the field of mass spectrometry leading to an ever increasing amount of data, demand high standards in efficiency, accuracy and reproducibility of potential analysis software. Results This article presents the current state and ongoing developments in OpenMS, a versatile open-source framework aimed at enabling reproducible analyses of high-throughput mass spectrometry data. It provides implementations of frequently occurring processing operations on MS data through a clean application programming interface in C++ and Python. A collection of 185 tools and ready-made workflows for typical MS-based experiments enable convenient analyses for non-developers and facilitate reproducible research without losing flexibility. Conclusions OpenMS will continue to increase its ease of use for developers as well as users with improved continuous integration/deployment strategies, regular trainings with updated training materials and multiple sources of support. The active developer community ensures the incorporation of new features to support state of the art research. © 2017 The Authors","Analysis workflows; Mass spectrometry; Reproducible research; Software libraries; Tool collection","Application programming interfaces (API); C++ (programming language); Computer programming; Diagnosis; Mass spectrometry; Open source software; Continuous integrations; Mass spectrometry data; Open source frameworks; Processing operations; Reproducible research; Software libraries; Technological advances; Work-flows; Spectrometry; Article; bioinformatics; computer analysis; computer interface; data analysis software; data mining; documentation; machine learning; mass spectrometry; priority journal; workflow",2-s2.0-85020715888
"Reinert K., Dadi T.H., Ehrhardt M., Hauswedell H., Mehringer S., Rahn R., Kim J., Pockrandt C., Winkler J., Siragusa E., Urgese G., Weese D.","The SeqAn C++ template library for efficient sequence analysis: A resource for programmers",2017,"Journal of Biotechnology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028996790&doi=10.1016%2fj.jbiotec.2017.07.017&partnerID=40&md5=8f84aa598d98ae5a0af20da9277d773d","Background The use of novel algorithmic techniques is pivotal to many important problems in life science. For example the sequencing of the human genome (Venter et al., 2001) would not have been possible without advanced assembly algorithms and the development of practical BWT based read mappers have been instrumental for NGS analysis. However, owing to the high speed of technological progress and the urgent need for bioinformatics tools, there was a widening gap between state-of-the-art algorithmic techniques and the actual algorithmic components of tools that are in widespread use. We previously addressed this by introducing the SeqAn library of efficient data types and algorithms in 2008 (Döring et al., 2008). Results The SeqAn library has matured considerably since its first publication 9 years ago. In this article we review its status as an established resource for programmers in the field of sequence analysis and its contributions to many analysis tools. Conclusions We anticipate that SeqAn will continue to be a valuable resource, especially since it started to actively support various hardware acceleration techniques in a systematic manner. © 2017 The Author(s)","C++; Data structures; NGS analysis; Software libraries","Biotechnology; Cesium; Data structures; Algorithmic techniques; Assembly algorithm; Bioinformatics tools; C++ template library; Hardware acceleration; NGS analysis; Software libraries; Technological progress; C++ (programming language); DNA; Article; bioinformatics; comparative study; DNA library; DNA sequence; DNA template; genetic algorithm; human; human genome; priority journal; seqan library; sequence alignment; sequence analysis; software",2-s2.0-85028996790
"Xu B., Xing Z., Xia X., Lo D., Li S.","Domain-specific cross-language relevant question retrieval",2017,"Empirical Software Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032785172&doi=10.1007%2fs10664-017-9568-3&partnerID=40&md5=214d6a09bd27b91c422f1ccd0f4d9946","Chinese developers often cannot effectively search questions in English, because they may have difficulties in translating technical words from Chinese to English and formulating proper English queries. For the purpose of helping Chinese developers take advantage of the rich knowledge base of Stack Overflow and simplify the question retrieval process, we propose an automated cross-language relevant question retrieval (CLRQR) system to retrieve relevant English questions for a given Chinese question. CLRQR first extracts essential information (both Chinese and English) from the title and description of the input Chinese question, then performs domain-specific translation of the essential Chinese information into English, and finally formulates an English query for retrieving relevant questions in a repository of English questions from Stack Overflow. We propose three different retrieval algorithms (word-embedding, word-matching, and vector-space-model based methods) that exploit different document representations and similarity metrics for question retrieval. To evaluate the performance of our approach and investigate the effectiveness of different retrieval algorithms, we propose four baseline approaches based on the combination of different sources of query words, query formulation mechanisms and search engines. We randomly select 80 Java, 20 Python and 20 .NET questions in SegmentFault and V2EX (two Chinese Q&A websites for computer programming) as the query Chinese questions. We conduct a user study to evaluate the relevance of the retrieved English questions using CLRQR with different retrieval algorithms and the four baseline approaches. The experiment results show that CLRQR with word-embedding based retrieval achieves the best performance. © 2017 Springer Science+Business Media, LLC","Cross-language question retrieval; Domain-specific translation","Computer programming; Knowledge based systems; Linguistics; Search engines; Vector spaces; Cross-language question; Document Representation; Domain-specific translation; Query formulation; Retrieval algorithms; Retrieval process; Similarity metrics; Vector space models; Translation (languages)",2-s2.0-85032785172
"Dintzner N., van Deursen A., Pinzger M.","FEVER: An approach to analyze feature-oriented changes and artefact co-evolution in highly configurable systems",2017,"Empirical Software Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032800319&doi=10.1007%2fs10664-017-9557-6&partnerID=40&md5=b96390ac05ed6fb00fb1c78700b3550c","The evolution of highly configurable systems is known to be a challenging task. Thorough understanding of configuration options their relationships, and their implementation in various types of artefacts (variability model, mapping, and implementation) is required to avoid compilation errors, invalid products, or dead code. Recent studies focusing on co-evolution of artefacts detailed feature-oriented change scenarios, describing how related artefacts might change over time. However, relying on manual analysis of commits, such work do not provide the means to obtain quantitative information on the frequency of described scenarios nor information on the exhaustiveness of the presented scenarios for the evolution of a large scale system. In this work, we propose FEVER and its instantiation for the Linux kernel. FEVER extracts detailed information on changes in variability models (KConfig files), assets (preprocessor based C code), and mappings (Makefiles). We apply this methodology to the Linux kernel and build a dataset comprised of 15 releases of the kernel history. We performed an evaluation of the FEVER approach by manually inspecting the data and compared it with commits in the system’s history. The evaluation shows that FEVER accurately captures feature related changes for more than 85% of the 810 manually inspected commits. We use the collected data to reflect on occurrences of co-evolution in practice. Our analysis shows that complex co-evolution scenarios occur in every studied release but are not among the most frequent change scenarios, as they only occur for 8 to 13% of the evolving features. Moreover, only a minority of developers working on a given release will make changes to all artefacts related to a feature (between 10% and 13% of authors). While our conclusions are derived from observations on the evolution of the Linux kernel, we believe that they may have implications for tool developers as well as guide further research in the field of co-evolution of artefacts. © 2017 The Author(s)","Co-evolution; Feature; Highly variable systems; Variability","C (programming language); Computer operating systems; Large scale systems; Mapping; Co-evolution; Configurable systems; Configuration options; Feature; Quantitative information; Variability; Variability model; Variable systems; Linux",2-s2.0-85032800319
"Besson F., Blazy S., Wilke P.","A Verified CompCert Front-End for a Memory Model Supporting Pointer Arithmetic and Uninitialised Data",2017,"Journal of Automated Reasoning",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032816141&doi=10.1007%2fs10817-017-9439-z&partnerID=40&md5=6b97a33db797e1d3786239efea66eea4","The CompCert C compiler guarantees that the target program behaves as the source program. Yet, source programs without a defined semantics do not benefit from this guarantee and could therefore be miscompiled. To reduce the possibility of a miscompilation, we propose a novel memory model for CompCert which gives a defined semantics to challenging features such as bitwise pointer arithmetics and access to uninitialised data. We evaluate our memory model both theoretically and experimentally. In our experiments, we identify pervasive low-level C idioms that require the additional expressiveness provided by our memory model. We also show that our memory model provably subsumes the existing CompCert memory model thus cross-validating both semantics. Our memory model relies on the core concepts of symbolic value and normalisation. A symbolic value models a delayed computation and the normalisation turns, when possible, a symbolic value into a genuine value. We show how to tame the expressive power of the normalisation so that the memory model fits the proof framework of CompCert. We also adapt the proofs of correctness of the compiler passes performed by CompCert’s front-end, thus demonstrating that our model is well-suited for proving compiler transformations. © 2017 Springer Science+Business Media B.V.","C semantics; Pointer arithmetic; Verified compilation","C (programming language); Semantics; C compilers; Compiler transformations; Expressive power; Memory modeling; Normalisation; Pointer arithmetic; Symbolic value; Verified compilation; Program compilers",2-s2.0-85032816141
"Rahimi M., Cleland-Huang J.","Evolving software trace links between requirements and source code",2017,"Empirical Software Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032801677&doi=10.1007%2fs10664-017-9561-x&partnerID=40&md5=ec9d4622a811c321c5101e4d294fbfbc","Traceability provides support for diverse software engineering activities including safety analysis, compliance verification, test-case selection, and impact prediction. However, in practice, there is a tendency for trace links to degrade over time as the system continually evolves. This is especially true for links between source-code and upstream artifacts such as requirements – because developers frequently refactor and change code without updating the links. In this paper we present TLE (Trace Link Evolver), a solution for automating the evolution of bidirectional trace links between source code classes or methods and requirements. TLE depends on a set of heuristics coupled with refactoring detection tools and informational retrieval algorithms to detect predefined change scenarios that occur across contiguous versions of a software system. We first evaluate TLE at the class level in a controlled experiment to evolve trace links for revisions of two Java applications. Second, we comparatively evaluate several variants of TLE across six releases of our in-house Dronology project. We study the results of integrating human analyst feed back in the evolution cycle of this emerging project. Additionally, in this system, we compare the efficacy of class-level versus method-level evolution of trace links. Finally, we evaluate TLE in a larger scale across 27 releases of the Cassandra Database System and show that the evolved trace links are significantly more accurate than those generated using only information retrieval techniques. © 2017 Springer Science+Business Media, LLC","Evolution; Maintenance; Traceability","Codes (symbols); Compliance control; Computer programming languages; Maintenance; Software engineering; Software testing; Verification; Compliance verification; Controlled experiment; Engineering activities; Evolution; Java applications; Retrieval algorithms; Test case selection; Traceability; Search engines",2-s2.0-85032801677
"Li Y., Cai J.W., Alonso J.A., Lian H.Q., Cui X.G., Goodenough J.B.","Evaluation of LaNi0.6M0.4O3 (M = Fe, Co) cathodes in LSGM-electrolyte-supported solid-oxide fuel cells",2017,"International Journal of Hydrogen Energy",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030707286&doi=10.1016%2fj.ijhydene.2017.09.031&partnerID=40&md5=dcfdbbcbea49d859e868a58c8298f046","We evaluated the electrochemical performances of LaNi0.6Fe0.4O3 (LNFO) and LaNi0.6Co0.4O3 (LNCO) perovskites as cathodes in La0.8Sr0.2Ga0.83Mg0.17O2.815 (LSGM) electrolyte-supported solid oxide fuel cell. Both samples show excellent chemical compatibility with the LSGM electrolyte up to 900 °C, and exhibit small-polaron type electrical conduction with a high conductivity σ ≈ 510 (430) S·cm−1 at 800 °C and a small activation energy Ea e = 54.9 (44.4) meV for LNFO (LNCO). The oxygen-reduction reaction evaluated in a symmetric LNFO(LNCO)|LSGM|LNFO(LNCO) cell gives a polarization resistance Rp ≈ 0.51 (0.34) Ω·cm2 at 800 °C in air and an activation energy Ea O = 1.61 (1.87) eV. For a single cell composed of LNFO (LNCO) cathode, 300-μm-thick LSGM electrolyte, and a composite Ni + Gd-doped ceria anode, the maximum power densities reach Pmax = 490 (650) and 850 (1015) mW·cm−2 at 800 and 850 °C, respectively. These results demonstrated that LNFO and LNCO are promising cathode materials for the IT-SOFCs. © 2017 Hydrogen Energy Publications LLC","LaNi0.6Co0.4O3; LaNi0.6Fe0.4O3; LSGM electrolyte; Solid oxide fuel cell","Activation energy; C (programming language); Cathodes; Chemical activation; Electrodes; Electrolytes; Electrolytic reduction; Fuel cells; Solid oxide fuel cells (SOFC); Chemical compatibility; Electrochemical performance; LaNi0.6Co0.4O3; LaNi0.6Fe0.4O3; LSGM electrolyte; Maximum power density; Oxygen reduction reaction; Polarization resistances; Solid electrolytes",2-s2.0-85030707286
"Li Y., Zhang Z., Feng L., Zhao X., Zhang D.C., Yin H.","Gene and expression analysis of the hexamerin family proteins from the grasshopper, Locusta migratoria (Orthoptera: Acridoidea)",2017,"Biotechnology and Biotechnological Equipment",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028891316&doi=10.1080%2f13102818.2017.1373601&partnerID=40&md5=f36e3390c0bf8a1faa01c4b208372f19","Hexamerins are large hemolymph-proteins that have been discovered in all insect species. According to the present study, hexamerins are not only storage proteins that provide amino acids and energy, but also transport hormones such as ecdysteroids. The hexamerin family genes cDNA from the grasshopper Locusta migratoria were cloned using RT-PCR and RACE methods. The biological functions of LmiHx5 were studied by RNA interference (RNAi), and qRT-PCR was performed to detect LmiHx transcripts after RNAi. Compared to the transcription database previously obtained, four family members (LmiHx1, LmiHx2, LmiHx4 and LmiHx5) of different LmiHx were determined. Homologous sequence alignments showed that the consistency of the amino acid sequence of LmiHx family members was 32%–43% and their encoded protein have the same three hemocyanin domains: hemocyanin-C, hemocyanin-N and hemocyanin-M. Gene expression patterns in different tissues and at different developmental stages showed that the LmiHx family genes are widely expressed in both female and male adults and at all developmental stages. The expression showed cyclical fluctuation with the nymphs molt. In addition, LmiHx2 mRNA expression level was the highest in fat body. LmiHx5 mRNA levels substantially decreased at 12, 24 and 48 h after dsLmiHx5 injection compared to the negative controls and almost not expressed at 96 h after dsRNA injection. The relative expression levels of other hexamerin family members showed varying degrees of increase after LmiHx5 RNAi. We speculate that hexamerin family gene members showed functional compensation. © 2017 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.","cloning; expression; Grasshopper; hexamerin family genes; RNAi","Amino acids; C (programming language); Cloning; Genes; Nucleic acids; Polymerase chain reaction; Proteins; Transcription; Amino acid sequence; Biological functions; expression; Gene expression patterns; Grasshopper; Homologous sequences; MRNA expression level; RNAi; Gene expression",2-s2.0-85028891316
"Weisz A., James I.C., Tae C.J., Ridge C.D., Ito Y.","Determination of Sudan I and a newly synthesized Sudan III positional isomer in the color additive D&C Red No. 17 using high-performance liquid chromatography",2017,"Food Additives and Contaminants - Part A Chemistry, Analysis, Control, Exposure and Risk Assessment",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023208345&doi=10.1080%2f19440049.2017.1347285&partnerID=40&md5=56f8109ea35f6d7e95d8715f052f0f0f","Specifications in the Code of Federal Regulations for the color additive D&C Red No. 17 (Colour Index 26100) limit the levels of two subsidiary colors, 1-(phenylazo)-2-naphthol (Sudan I) and 1-[[2-(phenylazo)phenyl]azo]-2-naphthalenol (Sudan III o-isomer), to 3% and 2%, respectively. The present work reports the development of a high-performance liquid chromatography (HPLC) method for the quantitative determination of these subsidiary colors. Since Sudan III o-isomer needed to be synthesized for use as a reference material, a two-step procedure was devised: (i) preparative-scale synthesis of the intermediate 2-aminoazobenzene (2AAB) and its purification by counter-current chromatography and (ii) diazotization of 2AAB and coupling with 2-naphthol. Characterization of the newly synthesized Sudan III o-isomer is also reported. Sudan I and Sudan III o-isomer were quantified by using five-point calibration curves with data points ranging from 0.108 to 3.240% and 0.077 to 2.227% by weight, respectively. The HPLC method is rapid (14 min for the total analysis cycle) and simple to implement. It was applied to the analysis of test portions from 25 batches of D&C Red No. 17 submitted to the U.S. Food and Drug Administration (USFDA) for certification, and it has recently been implemented by USFDA for routine batch certification of that color additive. © 2017 Informa UK Limited, trading as Taylor & Francis.","1-[[2-(phenylazo)phenyl]azo]-2-naphthalenol; Color additive D&C Red No. 17; counter-current chromatography; HPLC; Sudan I; Sudan III","C (programming language); Chromatography; Color; Food additives; High performance liquid chromatography; Isomers; Naphthol; 1-[[2-(phenylazo)phenyl]azo]-2-naphthalenol; Color additives; Countercurrent chromatography; HPLC; Sudan I; Sudan III; Liquid chromatography; 2 naphthol; food additive; food dye; oil scarlet; sudan I; 1-(phenylazophenylazo)-2-naphthol; 1-phenylazo-2-naphthol; azo compound; coloring agent; naphthol derivative; oil scarlet; Article; certification; counter current chromatography; diazotization; food and drug administration; heteronuclear multiple bond correlation; heteronuclear single quantum coherence; high performance liquid chromatography; isomer; liquid chromatograph; liquid chromatography-mass spectrometry; priority journal; proton nuclear magnetic resonance; chemistry; high performance liquid chromatography; stereoisomerism; synthesis; Azo Compounds; Chromatography, High Pressure Liquid; Coloring Agents; Naphthols; Stereoisomerism",2-s2.0-85023208345
"Rea Minango S.N., Ferreira J.C.E.","Combining the STEP-NC standard and forward and inverse kinematics methods for generating manufacturing tool paths for serial and hybrid robots",2017,"International Journal of Computer Integrated Manufacturing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015667045&doi=10.1080%2f0951192X.2017.1305507&partnerID=40&md5=23515e962ee6118962974e8ed8b4a9a3","The different forms of data representation have created the need for a common language capable of describing the design, manufacturing and measurement data. ISO 14649, known as STEP-NC, began as an effort to standardise product data exchange typically for computerised numerical control (CNC). However, although there are several studies involving the application of STEP-NC in CNC machines, which use the G-code format (ISO 6983), there is not much work on the application of STEP-NC in generating programmes for industrial robots, which are being increasingly used in production lines, both in quantity and variety. One of the reasons for the difficulty in applying STEP-NC to robots is that the controller needs to receive commands in a specific language imposed by each manufacturer, resulting in a large number of robot programming languages and difficulty in achieving standardisation. This work proposes a procedure that uses forward and inverse kinematics methods applicable to serial and hybrid robots, allowing STEP-NC-compliant information to be received and generates the path along which the robot should move, reducing the time for setup and integration of robots in manufacturing. These paths were tested on three robots with different morphologies, in a virtual environment, confirming the feasibility of the method. © 2017 Informa UK Limited, trading as Taylor & Francis Group.","industrial robots; inverse kinematics; prismatic parts; STEP-NC; tool path generation","Computer control systems; Electronic data interchange; Inverse kinematics; Inverse problems; Kinematics; Manufacture; Robot programming; Robots; Virtual reality; Computerised numerical control; Data representations; Forward and inverse kinematics; Manufacturing tools; Prismatic parts; Product data exchange; STEP-NC; Tool path generation; Industrial robots",2-s2.0-85015667045
"Costa J.M., Miranda G.L.","Relation between Alice software and programming learning: A systematic review of the literature and meta-analysis",2017,"British Journal of Educational Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978251006&doi=10.1111%2fbjet.12496&partnerID=40&md5=c955a135be36cf9ec8ad85e49e31d809","This paper presents the results of a systematic review of the literature, including a meta-analysis, about the effectiveness of the use of Alice software in programming learning when compared to the use of a conventional programming language. Our research included studies published between the years 2000 and 2014 in the main databases. We gathered 232 papers. Taking into account the selection criteria to make the meta-analysis, we retained six papers with a quasi-experimental design, with 464 participants in total. To combine the results we used the random effect model. It resulted in an effect size of 0.54 (Cohen's d) with a confidence interval between 0.34 and 0.74. We concluded that until now there have been few experimental results on the effectiveness of Alice programming language to introduce students in learning how to program. The results we found were the expression of different experimental treatments and distinguished teaching methods which made the comparison of the results obtained more subtle. However, the existing experimental results that were submitted to the meta-analysis allowed us to assume with a certain margin of safety that a teaching strategy that uses Alice should obtain more effective results than the use of a conventional programming language. © 2016 British Educational Research Association",,"Ada (programming language); Computational linguistics; Random processes; Confidence interval; Margin of safety; Programming learning; Random-effect models; Selection criteria; Systematic Review; Teaching methods; Teaching strategy; Computer programming languages",2-s2.0-84978251006
"Miao Y., Liu Y., Chen Y., Zhou J., Ji P.","Two uncertain chance-constrained programming models to setting target levels of design attributes in quality function deployment",2017,"Information Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021217106&doi=10.1016%2fj.ins.2017.06.025&partnerID=40&md5=797672a4c7cd0cc1bc9ffc55438184dc","Quality function deployment (QFD) is widely acknowledged as a customer-oriented product design tool, which is generated by translating consumer demands into design attributes of a product. In order to depict the internal ambiguous factors in the development process more appropriately, uncertain variables with a specialized kind of regular uncertainty distributions based on uncertainty theory are applied. Subsequently, two uncertain chance-constrained programming (CCP) models used for formulating the QFD procedure are set forth, whose objectives are maximizing the consumer satisfaction and minimizing the design cost, respectively. To demonstrate the feasibility of the proposed modelling approach, an example of the motorcycle design problem is illustrated, in which the new target levels of design attributes are selected and analyzed according to the decision-makers’ subjectivity and preference at different confidence levels. Additionally, a comparative study between the uncertain CCP approach and another uncertain expected value modelling approach is conducted. The results indicate that uncertain CCP models are more suitable for optimization in the QFD procedure. © 2017 Elsevier Inc.","Design attribute; Quality function deployment; Uncertain chance-constrained programming; Uncertain variable","Computer programming; FORTH (programming language); Quality function deployment; Chance-constrained programming; Chance-constrained programming model; Consumer satisfactions; Customer oriented product design; Design attributes; Quality function deployments (QFD); Uncertain variables; Uncertainty distributions; Product design",2-s2.0-85021217106
"Young-S. L.E., Muruganandam P., Adhikari S.K., Lončar V., Vudragović D., Balaž A.","OpenMP GNU and Intel Fortran programs for solving the time-dependent Gross–Pitaevskii equation",2017,"Computer Physics Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028046668&doi=10.1016%2fj.cpc.2017.07.013&partnerID=40&md5=faf5764e02f34b8e58d4b99d8398495e","We present Open Multi-Processing (OpenMP) version of Fortran 90 programs for solving the Gross–Pitaevskii (GP) equation for a Bose–Einstein condensate in one, two, and three spatial dimensions, optimized for use with GNU and Intel compilers. We use the split-step Crank–Nicolson algorithm for imaginary- and real-time propagation, which enables efficient calculation of stationary and non-stationary solutions, respectively. The present OpenMP programs are designed for computers with multi-core processors and optimized for compiling with both commercially-licensed Intel Fortran and popular free open-source GNU Fortran compiler. The programs are easy to use and are elaborated with helpful comments for the users. All input parameters are listed at the beginning of each program. Different output files provide physical quantities such as energy, chemical potential, root-mean-square sizes, densities, etc. We also present speedup test results for new versions of the programs. New version program summary Program title: BEC-GP-OMP-FOR software package, consisting of: (i) imag1d-th, (ii) imag2d-th, (iii) imag3d-th, (iv) imagaxi-th, (v) imagcir-th, (vi) imagsph-th, (vii) real1d-th, (viii) real2d-th, (ix) real3d-th, (x) realaxi-th, (xi) realcir-th, (xii) realsph-th. Program files doi: http://dx.doi.org/10.17632/y8zk3jgn84.2 Licensing provisions: Apache License 2.0 Programming language: OpenMP GNU and Intel Fortran 90. Computer: Any multi-core personal computer or workstation with the appropriate OpenMP-capable Fortran compiler installed. Number of processors used: All available CPU cores on the executing computer. Journal reference of previous version: Comput. Phys. Commun. 180 (2009) 1888; ibid. 204 (2016) 209. Does the new version supersede the previous version?: Not completely. It does supersede previous Fortran programs from both references above, but not OpenMP C programs from Comput. Phys. Commun. 204 (2016) 209. Nature of problem: The present Open Multi-Processing (OpenMP) Fortran programs, optimized for use with commercially-licensed Intel Fortran and free open-source GNU Fortran compilers, solve the time-dependent nonlinear partial differential (GP) equation for a trapped Bose–Einstein condensate in one (1d), two (2d), and three (3d) spatial dimensions for six different trap symmetries: axially and radially symmetric traps in 3d, circularly symmetric traps in 2d, fully isotropic (spherically symmetric) and fully anisotropic traps in 2d and 3d, as well as 1d traps, where no spatial symmetry is considered. Solution method: We employ the split-step Crank–Nicolson algorithm to discretize the time-dependent GP equation in space and time. The discretized equation is then solved by imaginary- or real-time propagation, employing adequately small space and time steps, to yield the solution of stationary and non-stationary problems, respectively. Reasons for the new version: Previously published Fortran programs [1,2 have now become popular tools [3] for solving the GP equation. These programs have been translated to the C programming language [4] and later extended to the more complex scenario of dipolar atoms [5]. Now virtually all computers have multi-core processors and some have motherboards with more than one physical computer processing unit (CPU), which may increase the number of available CPU cores on a single computer to several tens. The C programs have been adopted to be very fast on such multi-core modern computers using general-purpose graphic processing units (GPGPU) with Nvidia CUDA and computer clusters using Message Passing Interface (MPI) [6]. Nevertheless, previously developed Fortran programs are also commonly used for scientific computation and most of them use a single CPU core at a time in modern multi-core laptops, desktops, and workstations. Unless the Fortran programs are made aware and capable of making efficient use of the available CPU cores, the solution of even a realistic dynamical 1d problem, not to mention the more complicated 2d and 3d problems, could be time consuming using the Fortran programs. Previously, we published auto-parallel Fortran programs [2] suitable for Intel (but not GNU) compiler for solving the GP equation. Hence, a need for the full OpenMP version of the Fortran programs to reduce the execution time cannot be overemphasized. To address this issue, we provide here such OpenMP Fortran programs, optimized for both Intel and GNU Fortran compilers and capable of using all available CPU cores, which can significantly reduce the execution time. Summary of revisions: Previous Fortran programs [1] for solving the time-dependent GP equation in 1d, 2d, and 3d with different trap symmetries have been parallelized using the OpenMP interface to reduce the execution time on multi-core processors. There are six different trap symmetries considered, resulting in six programs for imaginary-time propagation and six for real-time propagation, totaling to 12 programs included in BEC-GP-OMP-FOR software package. All input data (number of atoms, scattering length, harmonic oscillator trap length, trap anisotropy, etc.) are conveniently placed at the beginning of each program, as before [2]. Present programs introduce a new input parameter, which is designated by Number_of_Threads and defines the number of CPU cores of the processor to be used in the calculation. If one sets the value 0 for this parameter, all available CPU cores will be used. For the most efficient calculation it is advisable to leave one CPU core unused for the background system's jobs. For example, on a machine with 20 CPU cores such that we used for testing, it is advisable to use up to 19 CPU cores. However, the total number of used CPU cores can be divided into more than one job. For instance, one can run three simulations simultaneously using 10, 4, and 5 CPU cores, respectively, thus totaling to 19 used CPU cores on a 20-core computer. The Fortran source programs are located in the directory src, and can be compiled by the make command using the makefile in the root directory BEC-GP-OMP-FOR of the software package. The examples of produced output files can be found in the directory output, although some large density files are omitted, to save space. The programs calculate the values of actually used dimensionless nonlinearities from the physical input parameters, where the input parameters correspond to the identical nonlinearity values as in the previously published programs [1], so that the output files of the old and new programs can be directly compared. The output files are conveniently named such that their contents can be easily identified, following the naming convention introduced in Ref. [2]. For example, a file named <code>-out.txt, where <code> is a name of the individual program, represents the general output file containing input data, time and space steps, nonlinearity, energy and chemical potential, and was named fort.7 in the old Fortran version of programs [1]. A file named <code>-den.txt is the output file with the condensate density, which had the names fort.3 and fort.4 in the old Fortran version [1] for imaginary- and real-time propagation programs, respectively. Other possible density outputs, such as the initial density, are commented out in the programs to have a simpler set of output files, but users can uncomment and re-enable them, if needed. In addition, there are output files for reduced (integrated) 1d and 2d densities for different programs. In the real-time programs there is also an output file reporting the dynamics of evolution of root-mean-square sizes after a perturbation is introduced. The supplied real-time programs solve the stationary GP equation, and then calculate the dynamics. As the imaginary-time programs are more accurate than the real-time programs for the solution of a stationary problem, one can first solve the stationary problem using the imaginary-time programs, adapt the real-time programs to read the pre-calculated wave function and then study the dynamics. In that case the parameter NSTP in the real-time programs should be set to zero and the space mesh and nonlinearity parameters should be identical in both programs. The reader is advised to consult our previous publication where a complete description of the output files is given [2]. A readme.txt file, included in the root directory, explains the procedure to compile and run the programs. We tested our programs on a workstation with two 10-core Intel Xeon E5-2650 v3 CPUs. The parameters used for testing are given in sample input files, provided in the corresponding directory together with the programs. In Table 1 we present wall-clock execution times for runs on 1, 6, and 19 CPU cores for programs compiled using Intel and GNU Fortran compilers. The corresponding columns “Intel speedup” and “GNU speedup” give the ratio of wall-clock execution times of runs on 1 and 19 CPU cores, and denote the actual measured speedup for 19 CPU cores. In all cases and for all numbers of CPU cores, although the GNU Fortran compiler gives excellent results, the Intel Fortran compiler turns out to be slightly faster. Note that during these tests we always ran only a single simulation on a workstation at a time, to avoid any possible interference issues. Therefore, the obtained wall-clock times are more reliable than the ones that could be measured with two or more jobs running simultaneously. We also studied the speedup of the programs as a function of the number of CPU cores used. The performance of the Intel and GNU Fortran compilers is illustrated in Fig. 1, where we plot the speedup and actual wall-clock times as functions of the number of CPU cores for 2d and 3d programs. We see that the speedup increases monotonically with the number of CPU cores in all cases and has large values (between 10 and 14 for 3d programs) for the maximal number of cores. This fully justifies the development of OpenMP programs, which enable much faster and more efficient solving of the GP equation. However, a slow saturation in the speedup with the further increase in the number of CPU cores is observed in all cases, as expected. The speedup tends to increase for programs in higher dimensions, as they become more complex and have to process more data. This is why the speedups of the supplied 2d and 3d programs are larger than those of 1d programs. Also, for a single program the speedup increases with the size of the spatial grid, i.e., with the number of spatial discretization points, since this increases the amount of calculations performed by the program. To demonstrate this, we tested the supplied real2d-th program and varied the number of spatial discretization points NX=NY from 20 to 1000. The measured speedup obtained when running this program on 19 CPU cores as a function of the number of discretization points is shown in Fig. 2. The speedup first increases rapidly with the number of discretization points and eventually saturates. Additional comments: Example inputs provided with the programs take less than 30 minutes to run on a workstation with two Intel Xeon E5-2650 v3 processors (2 QPI links, 10 CPU cores, 25 MB cache, 2.3 GHz). © 2017 Elsevier B.V.","Bose–Einstein condensate; Gross–Pitaevskii equation; Intel and GNU Fortran programs; Open Multi-Processing; OpenMP; Partial differential equation; Split-step Crank–Nicolson scheme","Anisotropy; Application programming interfaces (API); Atoms; Bose-Einstein condensation; C (programming language); Chemical potential; Clocks; Codes (symbols); Computer programming; Computer programming languages; Computer software; Computer workstations; Control nonlinearities; Distributed computer systems; Dynamics; FORTRAN (programming language); Graphics processing unit; Image coding; Input output programs; Message passing; Multiprocessing systems; Nonlinear equations; Open source software; Partial differential equations; Personal computers; Problem oriented languages; Problem solving; Program compilers; Program processors; Publishing; Software packages; Space time codes; Statistical mechanics; Wave effects; Wave functions; Bose-Einstein condensates; Crank-Nicolson scheme; FORTRAN programs; Gross-Pitaevskii equation; Multi-processing; OpenMP; Multicore programming",2-s2.0-85028046668
"De Angelis E., Fioravanti F., Pettorossi A., Proietti M.","Semantics-based generation of verification conditions via program specialization",2017,"Science of Computer Programming",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007497655&doi=10.1016%2fj.scico.2016.11.002&partnerID=40&md5=643eab72a1a7abd5952af9ee1c06e1bc","We present a method for automatically generating verification conditions for a class of imperative programs and safety properties. Our method is parametric with respect to the semantics of the imperative programming language, as it generates the verification conditions by specializing, using unfold/fold transformation rules, a Horn clause interpreter that encodes that semantics. We define a multi-step operational semantics for a fragment of the C language and compare the verification conditions obtained by using this semantics with those obtained by using a more traditional small-step semantics. The flexibility of the approach is further demonstrated by showing that it is possible to easily take into account alternative operational semantics definitions for modeling additional language features. We have proved that the verification condition generation takes a number of transformation steps that is linear with respect to the size of the imperative program to be verified. Also the size of the verification conditions is linear with respect to the size of the imperative program. Besides the theoretical computational complexity analysis, we also provide an experimental evaluation of the method by generating verification conditions using the multi-step and the small-step semantics for a few hundreds of programs taken from various publicly available benchmarks, and by checking the satisfiability of these verification conditions by using state-of-the-art Horn clause solvers. These experiments show that automated verification of programs from a formal definition of the operational semantics is indeed feasible in practice. © 2016 Elsevier B.V.","Horn clauses; Program specialization; Program verification; Semantics of programming languages; Software model checking","Computer programming languages; Formal logic; Linear transformations; Logic programming; Mathematical transformations; Model checking; Modeling languages; Program interpreters; Semantics; Verification; Horn clause; Program specialization; Program Verification; Semantics of programming languages; Software model checking; C (programming language)",2-s2.0-85007497655
"Bachelet B., Yon L.","Designing expression templates with concepts",2017,"Software - Practice and Experience",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015169369&doi=10.1002%2fspe.2483&partnerID=40&md5=c4a087a5a5591ea3dc2fcaa08291d587","Concepts are likely to be introduced in a future C++ standard. They can be used for constraining template parameters, which enables checking requirements on template parameters sooner in the compilation process, and thus providing more intelligible error messages to the user. They can also be used in the specialization of templates, thus leading to a better control over the selection of the most appropriate version of a template for a given instantiation. This latter aspect offers new possibilities in the design of template libraries, as it enhances the specialization mechanism of templates, and set it up as a solid alternative to inheritance when static binding can replace dynamic binding. This article addresses the design of expression templates (i.e., templates that represent expressions and are usually built through operator overloading) that are useful to develop an embedded domain specific language (EDSL), and can speed up the evaluation of an expression by delaying the evaluation of intermediate operations to avoid unnecessary temporary objects. We propose to use concept-based template specialization to parse expression templates in order to ease the design of an EDSL. This approach is a static variant of the well-known visitor design pattern that replaces the overridden methods in the double dispatch of the original design pattern by template specializations based on concepts. An example of EDSL for linear programming developed with our solution demonstrates that a concept-based design helps producing concise and reliable code. Copyright © 2017 John Wiley & Sons, Ltd. Copyright © 2017 John Wiley & Sons, Ltd.","concept-based specialization; expression templates; generic programming; template metaprogramming; template specialization","Bins; Computer programming languages; Linear programming; Object oriented programming; Problem oriented languages; Concept-based; Expression templates; Generic programming; Template metaprogramming; Template specialization; C++ (programming language)",2-s2.0-85015169369
"Chekanov S.V., Pogrebnyak I., Wilbern D.","Cross-platform validation and analysis environment for particle physics",2017,"Computer Physics Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024102984&doi=10.1016%2fj.cpc.2017.06.017&partnerID=40&md5=faa59060026ddc37ca5e35f98e425699","A multi-platform validation and analysis framework for public Monte Carlo simulation for high-energy particle collisions is discussed. The front-end of this framework uses the Python programming language, while the back-end is written in Java, which provides a multi-platform environment that can be run from a web browser and can easily be deployed at the grid sites. The analysis package includes all major software tools used in high-energy physics, such as Lorentz vectors, jet algorithms, histogram packages, graphic canvases, and tools for providing data access. This multi-platform software suite, designed to minimize OS-specific maintenance and deployment time, is used for online validation of Monte Carlo event samples through a web interface. © 2017","Analysis software; Format; IO; Monte Carlo","Computer aided software engineering; Computer programming; High energy physics; Java programming language; Analysis frameworks; Analysis softwares; Cross-platform; Deployment time; Format; High-energy particles; Multi-platform environment; Python programming language; Monte Carlo methods",2-s2.0-85024102984
"Méndez-Acuña D., Galindo J.A., Combemale B., Blouin A., Baudry B.","Reverse engineering language product lines from existing DSL variants",2017,"Journal of Systems and Software",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019863772&doi=10.1016%2fj.jss.2017.05.042&partnerID=40&md5=9044fed0e6dd6ea28924b4e8244dd4bd","The use of domain-specific languages (DSLs) has become a successful technique to develop complex systems. In this context, an emerging phenomenon is the existence of DSL variants, which are different versions of a DSL adapted to specific purposes but that still share commonalities. In such a case, the challenge for language designers is to reuse, as much as possible, previously defined language constructs to narrow implementation from scratch. To overcome this challenge, recent research in software languages engineering introduced the notion of language product lines. Similarly to software product lines, language product lines are often built from a set of existing DSL variants. In this article, we propose a reverse-engineering technique to ease-off such a development scenario. Our approach receives a set of DSL variants which are used to automatically recover a language modular design and to synthesize the corresponding variability models. The validation is performed in a project involving industrial partners that required three different variants of a DSL for finite state machines. This validation shows that our approach is able to correctly identify commonalities and variability. © 2017 Elsevier Inc.","Domain-specific languages; Language product lines; Reverse-engineering; Software languages engineering","Computer programming languages; Problem oriented languages; Reverse engineering; Development scenarios; Domain specific languages; Industrial partners; Language constructs; Product-lines; Reverse engineering techniques; Software languages; Software Product Line; Digital subscriber lines",2-s2.0-85019863772
"Barták R., Chrpa L., Dovier A., Vodrážka J., Zhou N.-F.","Modeling and solving planning problems in tabled logic programming: Experience from the Cave Diving domain",2017,"Science of Computer Programming",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019569606&doi=10.1016%2fj.scico.2017.04.007&partnerID=40&md5=9f1957b5ea9ab03e55200c2db7309e30","Action planning deals with the problem of finding a sequence of actions transferring the world from a given state to a desired (goal) state. This problem is important in various areas such as robotics, manufacturing, transportation, autonomic computing, computer games, etc. Action planning is a form of a reachability problem in a huge state space so it is critical to efficiently represent world states and actions (transitions between states). In this paper we present a modeling framework for planning problems based on tabled logic programming that exploits a planner module in the Picat language. In particular, we suggest techniques for structured representation of states and for including control knowledge in the description of actions. We demonstrate these techniques using the complex planning domain Cave Diving from the International Planning Competition. Experimentally, we show properties of the model for different search approaches and we compare the performance of the proposed approach with state-of-the-art automated planners. The focus of this paper is on providing guidelines for manual modeling of planning domains rather than on automated reformulation of models. © 2017 Elsevier B.V.","Domain modeling; Logic programming; Planning; Tabling","Caves; Computation theory; Computer circuits; Computer games; Computer programming; Logic programming; Modeling languages; Planning; Robot programming; Autonomic Computing; Domain model; International Planning Competitions; Planning domains; Reachability problem; Sequence of actions; State of the art; Tabling; Problem solving",2-s2.0-85019569606
"Allanach B.C., Cridge T.","The calculation of sparticle and Higgs decays in the minimal and next-to-minimal supersymmetric standard models: SOFTSUSY4.0",2017,"Computer Physics Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028387536&doi=10.1016%2fj.cpc.2017.07.021&partnerID=40&md5=16c35614e2e15c540cabfd8db94a7029","We describe a major extension of the SOFTSUSY spectrum calculator to include the calculation of the decays, branching ratios and lifetimes of sparticles into lighter sparticles, covering the next-to-minimal supersymmetric standard model (NMSSM) as well as the minimal supersymmetric standard model (MSSM). This document acts as a manual for the new version of SOFTSUSY, which includes the calculation of sparticle decays. We present a comprehensive collection of explicit expressions used by the program for the various partial widths of the different decay modes in the appendix. Program Summary Program title: SOFTSUSY Program Files doi: http://dx.doi.org/10.17632/5hhwwmp43g.1 Licensing provisions: GPLv3 Programming language: C++, fortran Nature of problem: Calculating supersymmetric particle partial decay widths in the MSSM or the NMSSM, given the parameters and spectrum which have already been calculated by SOFTSUSY. Solution method: Analytic expressions for tree-level 2 body decays and loop-level decays and one-dimensional numerical integration for 3 body decays. Restrictions: Decays are calculated in the real R−parity conserving MSSM or the real R−parity conserving NMSSM only. No additional charge-parity violation (CPV) relative to the Standard Model (SM). Sfermion mixing has only been accounted for in the third generation of sfermions in the decay calculation. Decays in the MSSM are 2-body and 3-body, whereas decays in the NMSSM are 2-body only. Does the new version supersede the previous version?: Yes. Reasons for the new version: Significantly extended functionality. The decay rates and branching ratios of sparticles are particularly useful for collider searches. Decays calculated in the NMSSM will be a particularly useful check of the other programs in the literature, of which there are few. Summary of revisions: Addition of the calculation of sparticle and Higgs decays. All 2-body and important 3-body tree-level decays, including phenomenologically important loop-level decays (notably, Higgs decays to gg, γγ and Zγ). Next-to-leading order corrections are added to neutral Higgs decays to qq̄ for quarks q of any flavour and to the neutral Higgs decays to gg. Additional comments: Program obtainable from: http://softsusy.hepforge.org/ © 2017 Elsevier B.V.","Branching ratio; Lifetime; MSSM; NMSSM","C++ (programming language); Computer operating systems; Computer programming; Forestry; FORTRAN (programming language); High energy physics; Linux; Numerical methods; One dimensional; Personal computers; Supersymmetry; Branching ratio; Charge-parity violations; Lifetime; Minimal supersymmetric standard models; MSSM; Next-to-leading order corrections; Next-to-minimal supersymmetric standard models; NMSSM; Fractals",2-s2.0-85028387536
"Bosse Y., Gerosa M.A.","Difficulties of Programming Learning from the Point of View of Students and Instructors",2017,"IEEE Latin America Transactions",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032615697&doi=10.1109%2fTLA.2017.8070426&partnerID=40&md5=769df26a8afbf6161c5cc7f898bb02d8","Computer programming courses are mandatory for many majors. However, the high rate of failures shows that students have difficulties in assimilating the topics. The objective of this research is to understand these difficulties. Analyzing diaries filled out by students and interviews with instructors, we identified difficulties related to language and understanding and some strategies used to mitigate them. The analysis and understanding of the difficulties may support the creation of teaching strategies and tools to facilitate the teaching and learning of computer programming. © 2003-2012 IEEE.","barriers; computational thinking; Difficulties; introduction to programming; novices; programming learning","Computer programming; Students; Teaching; barriers; Computational thinkings; Difficulties; Introduction to programming; novices; Programming learning; Education",2-s2.0-85032615697
"Vimmr J., Bublík O., Pecka A.","A parallel implementation of an implicit discontinuous Galerkin finite element scheme for fluid flow problems",2017,"Advances in Engineering Software",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008224855&doi=10.1016%2fj.advengsoft.2016.11.007&partnerID=40&md5=33c8593ee009087e8cfc64c9ceb901b0","The discontinuous Galerkin (DG) method is frequently used in computational fluid dynamics for its stability and high order of accuracy. A disadvantage of the DG method is its high computational demands. The aim of this paper is to weaken this drawback by means of parallelization of the DG algorithm. The computation is performed on a network of computers with distributed memory using the Java Remote Method Invocation, which is included in the Java programming language. The partition of the boundary value problem into n subproblems, which is then solved by n computers separately, is based on the overlapping Schwarz method. On basis of physical nature of the problem, the present paper proposes minimal size of the overlap that allows for only one Schwarz iteration thereby increasing efficiency of parallelization. The scalability and efficiency of the presented parallelization approach is demonstrated on several test problems. In order to stabilize the DG method in presence of shocks, a recently developed technique by Huerta et al. (Int. J. Numer. Meth. Fluids 69(10), 2012, 1614–1632), which introduces discontinuities in basis functions in regions with a shock, is adopted here. A modification of this approach, which lowers the computational and implementational demands, is presented here. © 2017 Civil-Comp Ltd and Elsevier Ltd","Compressible Navier–Stokes equations; Discontinuous Galerkin finite element method; Implicit scheme; Java RMI; Overlapping Schwarz method; Parallel computing; Shock capturing","Boundary value problems; Computational fluid dynamics; Computer aided software engineering; Computer programming; Computer systems programming; Distributed computer systems; Efficiency; Finite element method; Flow of fluids; Iterative methods; Java programming language; Navier Stokes equations; Parallel processing systems; Problem oriented languages; 35Q35; 65N30; 65Y05; 76N10; Compressible Navier-Stokes equations; Discontinuous Galerkin finite-element method; Implicit schemes; Java RMI; Overlapping Schwarz; Shock-capturing; Galerkin methods",2-s2.0-85008224855
"Benveniste A., Bourke T., Caillaud B., Pagano B., Pouzet M.","A type-based analysis of causality loops in hybrid systems modelers",2017,"Nonlinear Analysis: Hybrid Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021115287&doi=10.1016%2fj.nahs.2017.04.004&partnerID=40&md5=3fe36cb1d50c77200ff51d90e464b1f9","Explicit hybrid systems modelers like Simulink/Stateflow allow for programming both discrete- and continuous-time behaviors with complex interactions between them. An important step in their compilation is the static detection of algebraic or causality loops. Such loops can cause simulations to deadlock and prevent the generation of statically scheduled code. This paper addresses this issue for a hybrid modeling language that combines synchronous data-flow equations with Ordinary Differential Equations (ODEs). We introduce the operator lastx for the left-limit of a signal x. The lastx operator is used to break causality loops and permits a uniform treatment of discrete and continuous state variables. The semantics of the language relies on non-standard analysis, defining an execution as a sequence of infinitesimally small steps. A signal is deemed causally correct when it can be computed sequentially and only changes infinitesimally outside of announced discrete events like zero-crossings. The causality analysis takes the form of a type system that expresses dependencies between signals. In well-typed programs, (i) signals are provably continuous during integration provided that imported external functions are also continuous, and (ii) sequential code can be generated. The effectiveness of the system is illustrated with several examples written in ZÉLUS, a LUSTRE-like synchronous language extended with ODEs. © 2017","Hybrid systems; Synchronous programming languages; Type systems","Computer simulation languages; Differential equations; Hybrid systems; Modeling languages; Ordinary differential equations; Semantics; Causality analysis; Hybrid modeling language; Static detections; Synchronous data flow; Synchronous languages; Synchronous programming; Type systems; Type-based analysis; Continuous time systems",2-s2.0-85021115287
"Yang S.-C., Lu Z.-Y., Qian H.-J., Wang Y.-L., Han J.-P.","A hybrid parallel architecture for electrostatic interactions in the simulation of dissipative particle dynamics",2017,"Computer Physics Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027273998&doi=10.1016%2fj.cpc.2017.07.005&partnerID=40&md5=a3c5bb1710e948a7d1eee7634fcebdb3","In this work, we upgraded the electrostatic interaction method of CU-ENUF (Yang, et al., 2016) which first applied CUNFFT (nonequispaced Fourier transforms based on CUDA) to the reciprocal-space electrostatic computation and made the computation of electrostatic interaction done thoroughly in GPU. The upgraded edition of CU-ENUF runs concurrently in a hybrid parallel way that enables the computation parallelizing on multiple computer nodes firstly, then further on the installed GPU in each computer. By this parallel strategy, the size of simulation system will be never restricted to the throughput of a single CPU or GPU. The most critical technical problem is how to parallelize a CUNFFT in the parallel strategy, which is conquered effectively by deep-seated research of basic principles and some algorithm skills. Furthermore, the upgraded method is capable of computing electrostatic interactions for both the atomistic molecular dynamics (MD) and the dissipative particle dynamics (DPD). Finally, the benchmarks conducted for validation and performance indicate that the upgraded method is able to not only present a good precision when setting suitable parameters, but also give an efficient way to compute electrostatic interactions for huge simulation systems. Program summary Program title: HP-ENUF Program Files doi: http://dx.doi.org/10.17632/zncf24fhpv.1 Licensing provisions: GNU General Public License 3 (GPL) Programming language: C, C++, and CUDA C Supplementary material: The program is designed for effective electrostatic interactions of large-scale simulation systems, which runs on particular computers equipped with NVIDIA GPUs. It has been tested on (a) single computer node with Intel(R) Core(TM) i7-3770@ 3.40 GHz (CPU) and GTX 980 Ti (GPU), and (b) MPI parallel computer nodes with the same configurations. Nature of problem: For molecular dynamics simulation, the electrostatic interaction is the most time-consuming computation because of its long-range feature and slow convergence in simulation space, which approximately take up most of the total simulation time. Although the parallel method CU-ENUF (Yang et al., 2016) based on GPU has achieved a qualitative leap compared with previous methods in electrostatic interactions computation, the computation capability is limited to the throughput capacity of a single GPU for super-scale simulation system. Therefore, we should look for an effective method to handle the calculation of electrostatic interactions efficiently for a simulation system with super-scale size. Solution method: We constructed a hybrid parallel architecture, in which CPU and GPU are combined to accelerate the electrostatic computation effectively. Firstly, the simulation system is divided into many subtasks via domain-decomposition method. Then MPI (Message Passing Interface) is used to implement the CPU-parallel computation with each computer node corresponding to a particular subtask, and furthermore each subtask in one computer node will be executed in GPU in parallel efficiently. In this hybrid parallel method, the most critical technical problem is how to parallelize a CUNFFT (nonequispaced fast Fourier transform based on CUDA) in the parallel strategy, which is conquered effectively by deep-seated research of basic principles and some algorithm skills. Restrictions: The HP-ENUF is mainly oriented to super-scale system simulations, in which the performance superiority is shown adequately. However, for a small simulation system containing less than 106 particles, the mode of multiple computer nodes has no apparent efficiency advantage or even lower efficiency due to the serious network delay among computer nodes, than the mode of single computer node. References: (1) S.-C. Yang, H.-J. Qian, Z.-Y. Lu, Appl. Comput. Harmon. Anal. 2016, http://dx.doi.org/10.1016/j.acha.2016.04.009. (2) S.-C. Yang, Y.-L. Wang, G.-S. Jiao, H.-J. Qian, Z.-Y. Lu, J. Comput. Chem. 37 (2016) 378. (3) S.-C. Yang, Y.-L. Zhu, H.-J. Qian, Z.-Y. Lu, Appl. Chem. Res. Chin. Univ., 2017, http://dx.doi.org/10.1007/s40242-016-6354-5. (4) Y.-L. Zhu, H. Liu, Z.-W. Li, H.-J. Qian, G. Milano, Z.-Y. Lu, J. Comput. Chem. 34 (2013) 2197. © 2017 Elsevier B.V.","CU-ENUF; CUNFFT; Electrostatic interaction; GPU; Molecular dynamics; Parallel computing","Benchmarking; C++ (programming language); Computer programming; Computer software; Computer systems programming; Coulomb interactions; Distributed computer systems; Domain decomposition methods; Efficiency; Electrostatic separators; Electrostatics; Fast Fourier transforms; Graphics processing unit; Message passing; Molecular dynamics; Network architecture; Open source software; Parallel processing systems; Problem oriented languages; Program processors; Atomistic molecular dynamics; CUNFFT; Dissipative particle dynamics; GNU general public license; Hybrid parallel architectures; Large scale simulations; Message passing interface; Molecular dynamics simulations; Parallel architectures",2-s2.0-85027273998
"Kastens U., Waite W.","Name analysis for modern languages: a general solution",2017,"Software - Practice and Experience",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015217344&doi=10.1002%2fspe.2489&partnerID=40&md5=33bdef62cc48be9ea20f8896d1d3fdc2","Classical strategies for matching identifier uses with declarations cannot handle the complexities of modern languages: arbitrarily qualified superclass names, cyclic dependence among lookup operations, and contextual access constraints. We have developed a language-independent algorithm and supporting data structure that overcome these problems. A well-defined interface allows introduction of arbitrary code to enforce language-specific constraints within the basic lookup operations. This paper explains the limitations of the classical strategies, presents the concepts on which our approach is based, and showcases an implementation based on attribute grammars. We explore the major issues through a series of examples and show how one can deal with those issues in a general framework. Many of the issues are specific to a particular language, and in those cases, we explain the solutions that our general interface supports. Although attribute grammars simplify the task of incorporating the model into a compiler, the model itself is completely independent of attribute grammars. We validated our model by using an implementation to process programs in several representative languages. In particular, we mechanically compared the results produced by that implementation with those produced by the Java SE 8 compiler on complete Java programs that are in general use. Performance data obtained during this processing show that our implementation is efficient. Copyright © 2017 John Wiley & Sons, Ltd. Copyright © 2017 John Wiley & Sons, Ltd.","attribute grammars; compilers; framework; name analysis; reuse","Computer software; Context sensitive grammars; Program compilers; Attribute grammars; Framework; General solutions; Language independents; Lookup operations; Name analysis; Process projects; Reuse; Java programming language",2-s2.0-85015217344
"Ramadasan D., Chevaldonné M., Chateau T.","LMA: A generic and efficient implementation of the Levenberg–Marquardt Algorithm",2017,"Software - Practice and Experience",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018332754&doi=10.1002%2fspe.2497&partnerID=40&md5=023461ee3cb552f93cdfca54fa1ebc08","This paper presents an open-source, generic and efficient implementation of a very popular nonlinear optimization method: the Levenberg–Marquardt algorithm (LMA). This minimization algorithm is well known and hundreds of implementations have already been released. However, none of them offer at the same time a high level of genericity, a friendly syntax and a high computational performance. In this paper, we propose a solution to gather all those advantages in one library named LMA. The main challenge is to implement an efficient solver for every encounter problem. To overcome this difficulty, LMA uses compile time algorithms to design a code specific to the given optimization problem. The features of LMA are presented and the performances are compared with the state-of-the-art best alternatives through extensive benchmarks on different kind of problems. Copyright © 2017 John Wiley & Sons, Ltd. Copyright © 2017 John Wiley & Sons, Ltd.","C++; genericity; Levenberg–Marquardt; meta-programming; nonlinear least squares","C (programming language); Cesium; Nonlinear programming; Open source software; Computational performance; Efficient implementation; Genericity; Levenberg-Marquardt; Levenberg-Marquardt algorithm; Meta Programming; Non-linear least squares; Nonlinear optimization methods; Optimization",2-s2.0-85018332754
"Yang C.-T., Huang C.-W., Chen S.-T.","Improvement of workload balancing using parallel loop self-scheduling on Intel Xeon Phi",2017,"Journal of Supercomputing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019215725&doi=10.1007%2fs11227-017-2068-9&partnerID=40&md5=c78f8b4605b5c3b357ce25009cc842fe","In recent years, Intel promotes its new product Xeon Phi coprocessor, which is similar to the x86 architecture coprocessor. It has about 60 cores and can be regarded as a single computing node, with the computing power that cannot be ignored. This work aims to improve the workload balance by parallel loop self-scheduling scheme performed on Xeon Phi-based computer cluster. The proposed concept is implemented by hybrid MPI and OpenMP parallel programming in C language. Since parallel loop self-scheduling composes of static and dynamic allocation, weighting algorithm is adopted in the static part, while the well-known loop self-scheduling is adopted in dynamic part. The loop block is partitioned according to the weighting of MIC and HOST nodes. Accordingly, Xeon Phi with many-core is adopted to implement parallel loop self-scheduling. Finally, we test the performance in the experiments by four applicable problems: matrix multiplication, sparse matrix multiplication, Mandelbrot set and circuit meet. The experimental results indicate how to do the weight allocation and which scheduling method can achieve the best performance. © 2017, Springer Science+Business Media New York.","Intel Xeon Phi; Many-core; MPI; OpenMP; Parallel loop; Self-scheduling","Application programming interfaces (API); C (programming language); Coprocessor; Matrix algebra; Parallel programming; Intel Xeon Phi; Many core; OpenMP; Parallel loops; Self-scheduling; Scheduling",2-s2.0-85019215725
"Neumann P., Bian X.","MaMiCo: Transient multi-instance molecular-continuum flow simulation on supercomputers",2017,"Computer Physics Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027267365&doi=10.1016%2fj.cpc.2017.06.026&partnerID=40&md5=8b9b5a63709712fbc2ae3a8aa88cb44f","We present extensions of the macro–micro-coupling tool MaMiCo, which was designed to couple continuum fluid dynamics solvers with discrete particle dynamics. To enable local extraction of smooth flow field quantities especially on rather short time scales, sampling over an ensemble of molecular dynamics simulations is introduced. We provide details on these extensions including the transient coupling algorithm, open boundary forcing, and multi-instance sampling. Furthermore, we validate the coupling in Couette flow using different particle simulation software packages and particle models, i.e. molecular dynamics and dissipative particle dynamics. Finally, we demonstrate the parallel scalability of the molecular-continuum simulations by using up to 65 536 compute cores of the supercomputer Shaheen II located at KAUST. New version program summary Program Title: MaMiCo Program Files doi: http://dx.doi.org/10.17632/w7rgdrhb85.1 Licensing provisions: BSD 3-clause Programming language: C, C++ External routines/libraries: For compiling: SCons, MPI (optional) Subprograms used: ESPResSo, LAMMPS, ls1 mardyn, waLBerla For installation procedures of the MaMiCo interfaces, see the README files in the respective code directories located in coupling/interface/impl. Journal reference of previous version: P. Neumann, H. Flohr, R. Arora, P. Jarmatz, N. Tchipev, H.-J. Bungartz. MaMiCo: Software design for parallel molecular-continuum flow simulations, Computer Physics Communications 200: 324–335, 2016 Does the new version supersede the previous version?: Yes. The functionality of the previous version is completely retained in the new version. Nature of problem: Coupled molecular-continuum simulation for multi-resolution fluid dynamics: parts of the domain are resolved by molecular dynamics or another particle-based solver whereas large parts are covered by a mesh-based CFD solver, e.g. a lattice Boltzmann automaton. Solution method: We couple existing MD and CFD solvers via MaMiCo (macro–micro coupling tool). Data exchange and coupling algorithmics are abstracted and incorporated in MaMiCo. Once an algorithm is set up in MaMiCo, it can be used and extended, even if other solvers are used (as soon as the respective interfaces are implemented/available). Reasons for the new version: We have incorporated a new algorithm to simulate transient molecular-continuum systems and to automatically sample data over multiple MD runs that can be executed simultaneously (on, e.g., a compute cluster). MaMiCo has further been extended by an interface to incorporate boundary forcing to account for open molecular dynamics boundaries. Besides support for coupling with various MD and CFD frameworks, the new version contains a test case that allows to run molecular-continuum Couette flow simulations out-of-the-box. No external tools or simulation codes are required anymore. However, the user is free to switch from the included MD simulation package to LAMMPS. For details on how to run the transient Couette problem, see the file README in the folder coupling/tests, Remark on MaMiCo V1.1. Summary of revisions: Open boundary forcing; Multi-instance MD sampling; support for transient molecular-continuum systems Restrictions: Currently, only single-centered systems are supported. For access to the LAMMPS-based implementation of DPD boundary forcing, please contact Xin Bian, xin.bian@tum.de. Additional comments: Please see file license_mamico.txt for further details regarding distribution and advertising of this software. © 2017 Elsevier B.V.","Coupling; Fluid dynamics; Molecular dynamics; Molecular-continuum; Parallel; Sampling; Software design; Transient","Clustering algorithms; Computational fluid dynamics; Computer programming; Computer software; Continuum mechanics; Couplings; Electronic data interchange; Flow simulation; Fluid dynamics; Molecular dynamics; Problem oriented languages; Sampling; Software design; Supercomputers; Transients; Dissipative particle dynamics; Installation procedures; Molecular dynamics simulations; Molecular-continuum; Molecular-continuum simulations; Parallel; Parallel scalability; Particle simulations; C++ (programming language)",2-s2.0-85027267365
"Carrete J., Vermeersch B., Katre A., van Roekeghem A., Wang T., Madsen G.K.H., Mingo N.","almaBTE : A solver of the space–time dependent Boltzmann transport equation for phonons in structured materials",2017,"Computer Physics Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025169458&doi=10.1016%2fj.cpc.2017.06.023&partnerID=40&md5=4328fd08bb54d59c9fae1963ea0f9497","almaBTE is a software package that solves the space- and time-dependent Boltzmann transport equation for phonons, using only ab-initio calculated quantities as inputs. The program can predictively tackle phonon transport in bulk crystals and alloys, thin films, superlattices, and multiscale structures with size features in the nm–μm range. Among many other quantities, the program can output thermal conductances and effective thermal conductivities, space-resolved average temperature profiles, and heat-current distributions resolved in frequency and space. Its first-principles character makes almaBTE especially well suited to investigate novel materials and structures. This article gives an overview of the program structure and presents illustrative examples for some of its uses. PROGRAM SUMMARY Program Title: almaBTE Program Files doi: http://dx.doi.org/10.17632/8tfzwgtp73.1 Licensing provisions: Apache License, version 2.0 Programming language: C++ External routines/libraries: BOOST, MPI, Eigen, HDF5, spglib Nature of problem: Calculation of temperature profiles, thermal flux distributions and effective thermal conductivities in structured systems where heat is carried by phonons Solution method: Solution of linearized phonon Boltzmann transport equation, Variance-reduced Monte Carlo © 2017 Elsevier B.V.","Boltzmann transport equation; Phonon; Thermal conductivity","Boltzmann equation; C++ (programming language); Calculations; Computer programming; Monte Carlo methods; Periodic structures; Phonons; Temperature control; Boltzmann transport equation; Calculation of temperature; Effective thermal conductivity; Multi-scale structures; Program structures; Structured materials; Temperature profiles; Thermal conductance; Thermal conductivity",2-s2.0-85025169458
"Šibalić N., Pritchard J.D., Adams C.S., Weatherill K.J.","ARC: An open-source library for calculating properties of alkali Rydberg atoms",2017,"Computer Physics Communications",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028080621&doi=10.1016%2fj.cpc.2017.06.015&partnerID=40&md5=9e838a60cce624c6aa3ef9a94ee979e5","We present an object-oriented Python library for the computation of properties of highly-excited Rydberg states of alkali atoms. These include single-body effects such as dipole matrix elements, excited-state lifetimes (radiative and black-body limited) and Stark maps of atoms in external electric fields, as well as two-atom interaction potentials accounting for dipole and quadrupole coupling effects valid at both long and short range for arbitrary placement of the atomic dipoles. The package is cross-referenced to precise measurements of atomic energy levels and features extensive documentation to facilitate rapid upgrade or expansion by users. This library has direct application in the field of quantum information and quantum optics which exploit the strong Rydberg dipolar interactions for two-qubit gates, robust atom-light interfaces and simulating quantum many-body physics, as well as the field of metrology using Rydberg atoms as precise microwave electrometers. Program summary Program Title: ARC: Alkali Rydberg Calculator Program Files doi: http://dx.doi.org/10.17632/hm5n8w628c.1 Licensing provisions: BSD-3-Clause Programming language: Python 2.7 or 3.5, with C extension External Routines: NumPy [1], SciPy [1], Matplotlib [2] Nature of problem: Calculating atomic properties of alkali atoms including lifetimes, energies, Stark shifts and dipole–dipole interaction strengths using matrix elements evaluated from radial wavefunctions. Solution method: Numerical integration of radial Schrödinger equation to obtain atomic wavefunctions, which are then used to evaluate dipole matrix elements. Properties are calculated using second order perturbation theory or exact diagonalisation of the interaction Hamiltonian, yielding results valid even at large external fields or small interatomic separation. Restrictions: External electric field fixed to be parallel to quantisation axis. Supplementary material: Detailed documentation (.html), and Jupyter notebook with examples and benchmarking runs (.html and.ipynb). [1] T.E. Oliphant, Comput. Sci. Eng. 9, 10 (2007). http://www.scipy.org/. [2] J.D. Hunter, Comput. Sci. Eng. 9, 90 (2007). http://matplotlib.org/. © 2017 The Author(s)","Alkali atom; Dipole–dipole interactions; Förster resonances; Matrix elements; Stark shift","Atomic beams; C (programming language); Computation theory; Dipole moment; Electric dipole moments; Electric fields; Excited states; Hamiltonians; High level languages; Numerical methods; Object oriented programming; Open source software; Perturbation techniques; Quantum optics; Rydberg states; Alkali atoms; Dipole dipole interactions; Excited state lifetimes; External electric field; Matrix elements; Quadrupole coupling effects; Second order perturbation theory; Stark shift; Atoms",2-s2.0-85028080621
"Giantsios A., Papaspyrou N., Sagonas K.","Concolic testing for functional languages",2017,"Science of Computer Programming",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020060869&doi=10.1016%2fj.scico.2017.04.008&partnerID=40&md5=c563e54ca2c810a932d739df3c144895","Concolic testing is a software testing technique that simultaneously combines concrete execution of a program (given specific input, along specific paths) with symbolic execution (generating new test inputs that explore other paths, which gives better path coverage than random test case generation). So far, concolic testing has been applied, mainly at the level of bytecode or assembly code, to programs written in imperative languages that manipulate primitive data types such as integers and arrays. In this article, we demonstrate its application to a functional programming language core, the functional subset of Core Erlang, that supports pattern matching, structured recursive data types such as lists, recursion and higher-order functions. We present CutEr, a tool implementing this testing technique, and describe its architecture, the challenges that it needs to address, its current limitations, and report some experiences from its use. © 2017 Elsevier B.V.","Concolic testing; Erlang; Pattern matching; Symbolic execution","Concrete testing; Functional programming; Integer programming; Model checking; Pattern matching; Testing; Concolic testing; Current limitation; Erlang; Functional languages; Higher order functions; Imperative languages; Software testing techniques; Symbolic execution; Software testing",2-s2.0-85020060869
"Nourazar M., Rashtchi V., Azarpeyvand A., Merrikh-Bayat F.","Memristor-based approximate matrix multiplier",2017,"Analog Integrated Circuits and Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027032375&doi=10.1007%2fs10470-017-1029-9&partnerID=40&md5=48d39f0539b5737779a80720593f2026","The parallel structure of matrix multipliers makes them fascinating candidates to benefit from memristors’ high density architecture. This paper first explains a memristor-based analog vector–matrix multiplier suitable for approximate computing. According to the existence of fast and efficient converters, namely, DACs and ADCs, in the field of approximate computing and the programmability of memristors, the presented vector–matrix multiplier is combined with digital circuits which it leads to a matrix–matrix multiplier as an extension. In this work, opamps’ characteristics such as power and speed, distribution of matrix elements, and memristors’ faults have been considered and their effects on performance, accuracy, and efficiency of the proposed multiplier have been analyzed. Also, a new structure for handling negative numbers has been proposed. All the circuits have been simulated using “Ngspice mixed-signal circuit simulator” in C++ programming environment. The simulation results revealed that the multiplier’s analog core brought gains in terms of performance and energy when acceptable ranges of inaccuracies in results could be tolerated. © 2017, Springer Science+Business Media, LLC.","Accelerator; Analog computing; Approximate computing; Matrix multiplier; Memristor","C++ (programming language); Circuit simulation; Computer software; Electric signal systems; Memristors; Mixed signal integrated circuits; Operational amplifiers; Particle accelerators; Analog computing; Approximate computing; C++ programming; Matrix elements; Memristor; Mixed-signal circuits; Parallel structures; Programmability; Matrix algebra",2-s2.0-85027032375
"Aurentz J.L., Kalantzis V., Saad Y.","Cucheb: A GPU implementation of the filtered Lanczos procedure",2017,"Computer Physics Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024115458&doi=10.1016%2fj.cpc.2017.06.016&partnerID=40&md5=cabfca21047074c434ce26e6727fd0f2","This paper describes the software package Cucheb, a GPU implementation of the filtered Lanczos procedure for the solution of large sparse symmetric eigenvalue problems. The filtered Lanczos procedure uses a carefully chosen polynomial spectral transformation to accelerate convergence of the Lanczos method when computing eigenvalues within a desired interval. This method has proven particularly effective for eigenvalue problems that arise in electronic structure calculations and density functional theory. We compare our implementation against an equivalent CPU implementation and show that using the GPU can reduce the computation time by more than a factor of 10. Program Summary Program title: Cucheb Program Files doi: http://dx.doi.org/10.17632/rjr9tzchmh.1 Licensing provisions: MIT Programming language: CUDA C/C++ Nature of problem: Electronic structure calculations require the computation of all eigenvalue–eigenvector pairs of a symmetric matrix that lie inside a user-defined real interval. Solution method: To compute all the eigenvalues within a given interval a polynomial spectral transformation is constructed that maps the desired eigenvalues of the original matrix to the exterior of the spectrum of the transformed matrix. The Lanczos method is then used to compute the desired eigenvectors of the transformed matrix, which are then used to recover the desired eigenvalues of the original matrix. The bulk of the operations are executed in parallel using a graphics processing unit (GPU). Runtime: Variable, depending on the number of eigenvalues sought and the size and sparsity of the matrix. Additional comments: Cucheb is compatible with CUDA Toolkit v7.0 or greater. © 2017 Elsevier B.V.","Density functional theory; Eigenvalues; Eigenvectors; Electronic structure calculations; GPU; Quantum mechanics","C++ (programming language); Computation theory; Computer graphics; Computer graphics equipment; Density functional theory; Electronic structure; Graphics processing unit; Linear transformations; Matrix algebra; Polynomials; Problem oriented languages; Program processors; Quantum theory; Computation time; Eigenvalue problem; Eigenvalues; Electronic structure calculations; GPU implementation; Large sparse symmetric eigenvalue problems; Polynomial spectral transformations; Symmetric matrices; Eigenvalues and eigenfunctions",2-s2.0-85024115458
"Perez R.N., Schunck N., Lasseri R.-D., Zhang C., Sarich J.","Axially deformed solution of the Skyrme–Hartree–Fock–Bogolyubov equations using the transformed harmonic oscillator basis (III) HFBTHO (v3.00): A new version of the program",2017,"Computer Physics Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024096878&doi=10.1016%2fj.cpc.2017.06.022&partnerID=40&md5=510ee66af0d1b7cfd501747ddbf64d2c","We describe the new version 3.00 of the code HFBTHO that solves the nuclear Hartree–Fock (HF) or Hartree–Fock–Bogolyubov (HFB) problem by using the cylindrical transformed deformed harmonic oscillator basis. In the new version, we have implemented the following features: (i) the full Gogny force in both particle–hole and particle–particle channels, (ii) the calculation of the nuclear collective inertia at the perturbative cranking approximation, (iii) the calculation of fission fragment charge, mass and deformations based on the determination of the neck, (iv) the regularization of zero-range pairing forces, (v) the calculation of localization functions, (vi) a MPI interface for large-scale mass table calculations. PROGRAM SUMMARY Program title:HFBTHO v3.00 Program Files doi: http://dx.doi.org/10.17632/c5g2f92by3.1 Licensing provisions: GPL v3 Programming language: FORTRAN-95 Journal reference of previous version: M.V. Stoitsov, N. Schunck, M. Kortelainen, N. Michel, H. Nam, E. Olsen, J. Sarich, and S. Wild, Comput. Phys. Commun. 184 (2013). Does the new version supersede the previous one: Yes Summary of revisions: 1. the Gogny force in both particle–hole and particle–particle channels was implemented; 2. the nuclear collective inertia at the perturbative cranking approximation was implemented; 3. fission fragment charge, mass and deformations were implemented based on the determination of the position of the neck between nascent fragments; 4. the regularization method of zero-range pairing forces was implemented; 5. the localization functions of the HFB solution were implemented; 6. a MPI interface for large-scale mass table calculations was implemented. Nature of problem:HFBTHO is a physics computer code that is used to model the structure of the nucleus. It is an implementation of the energy density functional (EDF) approach to atomic nuclei, where the energy of the nucleus is obtained by integration over space of some phenomenological energy density, which is itself a functional of the neutron and proton intrinsic densities. In the present version of HFBTHO, the energy density derives either from the zero-range Skyrme or the finite-range Gogny effective two-body interaction between nucleons. Nuclear super-fluidity is treated at the Hartree–Fock–Bogolyubov (HFB) approximation. Constraints on the nuclear shape allows probing the potential energy surface of the nucleus as needed e.g., for the description of shape isomers or fission. The implementation of a local scale transformation of the single-particle basis in which the HFB solutions are expanded provide a tool to properly compute the structure of weakly-bound nuclei. Solution method: The program uses the axial Transformed Harmonic Oscillator (THO) single-particle basis to expand quasiparticle wave functions. It iteratively diagonalizes the Hartree–Fock–Bogolyubov Hamiltonian based on generalized Skyrme-like energy densities and zero-range pairing interactions or the finite-range Gogny force until a self-consistent solution is found. A previous version of the program was presented in M.V. Stoitsov, N. Schunck, M. Kortelainen, N. Michel, H. Nam, E. Olsen, J. Sarich, and S. Wild, Comput. Phys. Commun. 184 (2013) 1592–1604 with much of the formalism presented in the original paper M.V. Stoitsov, J. Dobaczewski, W. Nazarewicz, P. Ring, Comput. Phys. Commun. 167 (2005) 43–63. Additional comments: The user must have access to (i) the LAPACK subroutines DSYEEVR, DSYEVD, DSYTRF and DSYTRI, and their dependencies, which compute eigenvalues and eigenfunctions of real symmetric matrices, (ii) the LAPACK subroutines DGETRI and DGETRF, which invert arbitrary real matrices, and (iii) the BLAS routines DCOPY, DSCAL, DGEMM and DGEMV for double-precision linear algebra (or provide another set of subroutines that can perform such tasks). The BLAS and LAPACK subroutines can be obtained from the Netlib Repository at the University of Tennessee, Knoxville: http://netlib2.cs.utk.edu/. © 2017 Elsevier B.V.","Axial harmonic oscillator basis; Collective inertia; Energy density functional theory; Gogny force; Hartree–Fock–Bogoliubov theory; Pairing regularization; Skyrme force; Transformed harmonic oscillator","Carrier concentration; Deformation; Density functional theory; Eigenvalues and eigenfunctions; Fission reactions; FORTRAN (programming language); Harmonic analysis; Isomers; Iterative methods; Linear algebra; Matrix algebra; Molecular physics; Oscillators (mechanical); Problem oriented languages; Quantum chemistry; Collective inertia; Energy density functional theory; Gogny force; Harmonic oscillators; Hartree-Fock-Bogoliubov theories; Pairing regularization; Skyrme-forces; Hartree approximation",2-s2.0-85024096878
"Barash L.Y., Weigel M., Borovský M., Janke W., Shchur L.N.","GPU accelerated population annealing algorithm",2017,"Computer Physics Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028032759&doi=10.1016%2fj.cpc.2017.06.020&partnerID=40&md5=8e4cf9b4fb25a56ec68d8333fd813f44","Population annealing is a promising recent approach for Monte Carlo simulations in statistical physics, in particular for the simulation of systems with complex free-energy landscapes. It is a hybrid method, combining importance sampling through Markov chains with elements of sequential Monte Carlo in the form of population control. While it appears to provide algorithmic capabilities for the simulation of such systems that are roughly comparable to those of more established approaches such as parallel tempering, it is intrinsically much more suitable for massively parallel computing. Here, we tap into this structural advantage and present a highly optimized implementation of the population annealing algorithm on GPUs that promises speed-ups of several orders of magnitude as compared to a serial implementation on CPUs. While the sample code is for simulations of the 2D ferromagnetic Ising model, it should be easily adapted for simulations of other spin models, including disordered systems. Our code includes implementations of some advanced algorithmic features that have only recently been suggested, namely the automatic adaptation of temperature steps and a multi-histogram analysis of the data at different temperatures. Program summary Program Title: PAIsing Program Files doi: http://dx.doi.org/10.17632/sgzt4b7b3m.1 Licensing provisions: Creative Commons Attribution license (CC BY 4.0) Programming language: C, CUDA External routines/libraries: NVIDIA CUDA Toolkit 6.5 or newer Nature of problem: The program calculates the internal energy, specific heat, several magnetization moments, entropy and free energy of the 2D Ising model on square lattices of edge length L with periodic boundary conditions as a function of inverse temperature β. Solution method: The code uses population annealing, a hybrid method combining Markov chain updates with population control. The code is implemented for NVIDIA GPUs using the CUDA language and employs advanced techniques such as multi-spin coding, adaptive temperature steps and multi-histogram reweighting. Additional comments: Code repository at https://github.com/LevBarash/PAising. The system size and size of the population of replicas are limited depending on the memory of the GPU device used. For the default parameter values used in the sample programs, L=64, θ=100, β0=0, βf=1, Δβ=0.005, R=20000, a typical run time on an NVIDIA Tesla K80 GPU is 151 seconds for the single spin coded (SSC) and 17 seconds for the multi-spin coded (MSC) program (see Section 2 for a description of these parameters). © 2017 Elsevier B.V.","Graphics processing units; Ising model; Monte Carlo simulations; Multi-spin coding; Parallel computing; Population annealing","Annealing; C (programming language); Chains; Codes (symbols); Computer graphics; Free energy; Graphic methods; Graphics processing unit; Importance sampling; Intelligent systems; Inverse problems; Ising model; Markov processes; Parallel processing systems; Population statistics; Program processors; Specific heat; Automatic adaptation; Ferromagnetic Ising models; Free energy landscape; Massively parallel computing; Multi-spin coding; Optimized implementation; Periodic boundary conditions; Sequential Monte Carlo; Monte Carlo methods",2-s2.0-85028032759
"Zhang S.H., Zhang R.F.","AELAS: Automatic ELAStic property derivations via high-throughput first-principles computation",2017,"Computer Physics Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028343345&doi=10.1016%2fj.cpc.2017.07.020&partnerID=40&md5=a610b7345ac7a5bccb88648fbb944aa0","The elastic properties are fundamental and important for crystalline materials as they relate to other mechanical properties, various thermodynamic qualities as well as some critical physical properties. However, a complete set of experimentally determined elastic properties is only available for a small subset of known materials, and an automatic scheme for the derivations of elastic properties that is adapted to high-throughput computation is much demanding. In this paper, we present the AELAS code, an automated program for calculating second-order elastic constants of both two-dimensional and three-dimensional single crystal materials with any symmetry, which is designed mainly for high-throughput first-principles computation. Other derivations of general elastic properties such as Young's, bulk and shear moduli as well as Poisson's ratio of polycrystal materials, Pugh ratio, Cauchy pressure, elastic anisotropy and elastic stability criterion, are also implemented in this code. The implementation of the code has been critically validated by a lot of evaluations and tests on a broad class of materials including two-dimensional and three-dimensional materials, providing its efficiency and capability for high-throughput screening of specific materials with targeted mechanical properties. Program summary Program title: AELAS Program Files doi: http://dx.doi.org/10.17632/f8fwg4j9tw.1 Licensing provisions: BSD 3-Clause Programming language: Fortran Nature of problem: To automate the calculations of second-order elastic constants and the derivations of other elastic properties for two-dimensional and three-dimensional materials with any symmetry via high-throughput first-principles computation. Solution method: The space-group number is firstly determined by the SPGLIB code [1] and the structure is then redefined to unit cell with IEEE-format [2]. Secondly, based on the determined space group number, a set of distortion modes is automatically specified and the distorted structure files are generated. Afterwards, the total energy for each distorted structure is calculated by the first-principles codes, e.g. VASP [3]. Finally, the second-order elastic constants are determined from the quadratic coefficients of the polynomial fitting of the energies vs strain relationships and other elastic properties are accordingly derived. References [1] http://atztogo.github.io/spglib/. [2] A. Meitzler, H.F. Tiersten, A.W. Warner, D. Berlincourt, G.A. Couqin, F.S. Welsh III, IEEE standard on piezoelectricity, Society, 1988. [3] G. Kresse, J. Furthmüller, Phys. Rev. B 54 (1996) 11169. © 2017 Elsevier B.V.","Elastic properties; First-principles calculation; High-throughput computation; Two-dimensional materials","Calculations; Codes (symbols); Crystal symmetry; Crystalline materials; Crystallography; Elastic constants; Elasticity; FORTRAN (programming language); Mechanical properties; Single crystals; Stability criteria; Thermal expansion; Elastic properties; First-principles calculation; High throughput; High throughput screening; Quadratic coefficients; Single-crystal materials; Thermodynamic quality; Two-dimensional materials; Throughput",2-s2.0-85028343345
"Durand-Petiteville A., Vougioukas S., Slaughter D.C.","Real-time segmentation of strawberry flesh and calyx from images of singulated strawberries during postharvest processing",2017,"Computers and Electronics in Agriculture",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029509988&doi=10.1016%2fj.compag.2017.09.011&partnerID=40&md5=8b9ad64827b53c7129f1aea61193fc35","This paper presents an image processing algorithm that automatically extracts the flesh and calyx areas from strawberry images. Images are captured by a camera included in a strawberry de-capping machine. Lighting is controlled and the background is known, conditions that are typical of postharvest processing. The goal is to extract as many flesh and calyx pixels as possible while rejecting any pixels belonging to the background. The proposed approach relies on image color segmentation in a two-dimensional color space, followed by a blob detection and selection stage. A set of 250 images is used to analyze the sensitivity of the algorithm with respect to user-defined parameters, and evaluate the performance of the approach. The algorithm appears to be easy to tune and allows accurate extraction of the areas of interest despite natural variation in strawberry shape and visual appearance. More than 98% of the flesh area was successfully extracted by the algorithm with less than 1% of the background pixels falsely included. Moreover, up to 79% of the calyx area could be extracted with less than 0.25% erroneous background pixels. Finally, the algorithm has been implemented using the C++ and Cuda languages and can be executed in real-time. © 2017 Elsevier B.V.","Image processing; Postharvest processing; Strawberries","C++ (programming language); Color; Fruits; Image segmentation; Pixels; Background pixels; Image processing algorithm; Natural variation; Postharvest processing; Real-time segmentation; Strawberries; User-defined parameters; Visual appearance; Image processing; algorithm; anatomy; color; detection method; fruit; image processing; machinery; pixel; real time; Fragaria x ananassa",2-s2.0-85029509988
"Yu H., Cheng W., Wang H., Peng H., Xie Y.","Formation mechanisms of a dust-removal air curtain in a fully-mechanized excavation face and an analysis of its dust-removal performances based on CFD and DEM",2017,"Advanced Powder Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028699480&doi=10.1016%2fj.apt.2017.08.010&partnerID=40&md5=733fbcb1396f2c8e1bdaf4f6af8821c3","A high concentration of dust in a fully-mechanized excavation face is a serious threat to the safety of production underground and miners’ health. This paper discusses the use of a novel air curtain generator and proposes a novel dust control and prevention technique. Based on the k-ε two-equation turbulence model, Hertz-Mindlin model and the CFD-DEM coupled interface compiled with C++ language, this paper firstly constructs a simulation model of the coupling between airflows and dust in a fully-mechanized excavation face, and then simulates the airflow fields and dust fields under forced/exhaust ventilation conditions with and without a novel air curtain generator being utilized. The results show that when only the forced/exhaust ventilation was used, a high concentration of dust spread throughout the entire tunnel space and no effective air curtain was formed. Furthermore, after the air curtain generator was turned on, as the radial-to-axial forced air ratio (PFQ) increased, the horizontal vortex in the front of the head-on section weakened gradually, and the originally disordered airflows behind the heading machine moved uniformly towards the head-on section. As the PFQ further increased, the distance (d) between the formed air curtain and head-on section decreased overall; through a curve fitting, this relationship can be written as: d = −5.247 ln(PFQ) + 13.569. When the PFQ &gt; 5:5, the average negative-pressure-induced dust-exhaust capacity increased, the distance between the formed air curtain and the head-on section decreased, and the re-entrainment of dust did not take place in a straightforward manner. Finally, some field measurements were carried out in order to validate the simulated results, with the subsequent comparison showing that the numerical simulated results were basically accurate. © 2017 The Society of Powder Technology Japan","Air curtain generator; CFD-DEM; Dust-prevention air curtain; Forced-exhaust ventilation; Fully-mechanized excavation face","Air curtains; C++ (programming language); Computer software; Curve fitting; Dust control; Excavation; Health risks; Mindlin plates; Supports; Turbulence models; Ventilation; Ventilation exhausts; CFD-DEM; Control and prevention; Exhaust ventilation; Formation mechanism; Fully-mechanized excavations; Negative pressures; Numerical simulated; Two-equation turbulence models; Air entrainment",2-s2.0-85028699480
"Adame M.F., Cherian S., Reef R., Stewart-Koster B.","Mangrove root biomass and the uncertainty of belowground carbon estimations",2017,"Forest Ecology and Management",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027497718&doi=10.1016%2fj.foreco.2017.08.016&partnerID=40&md5=a2a7d8c7a6685c4dae60aa01b17ac06c","Mangroves sequester large amounts of carbon (C) and they are increasingly recognized for their potential role in climate change mitigation programs. However, there is uncertainty in the C content of many mangrove forests because the amount of C stored in the roots is usually estimated from allometric equations and not from direct field measurements. There are only a handful of allometric equations in mangroves that are used worldwide to estimate root biomass, however, root biomass can vary from the allometric relationship if the environmental conditions are different from those where the equation was developed. In this study, we compiled recent information on how mangrove roots are affected by environmental conditions. Then, we explored the effect of sampling methodology on root biomass estimations. Finally, we compared published values of root biomass from field measurements against our estimations from allometric equations. The goal was to calculate the uncertainty associated with the estimation of root biomass and thus, the belowground C content of mangroves. The results showed that sampling methodology has a significant effect on root biomass estimations. The highest biomass estimations are reported where both live and dead roots are measured and when the roots are sampled by digging trenches. When comparing measured values against estimations from allometric equations, on average the general allometric equation provided root biomass values that were 40 ± 12% larger than those obtained from field measurements with cores. The result suggests that either: (a) sampling with cores largely underestimates root biomass, or (b) allometric equations overestimate root biomass when used outside the region where they were developed. The uncertainty in root biomass estimates from allometric equations corresponds to 4–15% of the ecosystem C stock (trees + soil), with higher uncertainties in forests with low tree density and low interstitial salinity. We provide a statistical model that includes salinity, forest density and root biomass to correct for this systematic bias. The estimated uncertainty is important to consider when quantifying C budgets at large spatial scales and to validate methodological approaches to C stock estimations. © 2017","Allometric equations; Blue carbon; Carbon stocks; Forested wetlands; Salinity","Biomass; Budget control; Climate change; Forestry; Plants (botany); Uncertainty analysis; Wetlands; Allometric equations; Allometric relationship; Carbon stocks; Climate change mitigation; Environmental conditions; Forested wetlands; Methodological approach; Salinity; C (programming language); Rhizophoraceae",2-s2.0-85027497718
"Chen W., Chen L., Ter A.B., Zhu Y., Yue L.","BHF-window-based research of BHF technology applicability at elevated temperature",2017,"International Journal of Advanced Manufacturing Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021269645&doi=10.1007%2fs00170-017-0649-7&partnerID=40&md5=f6474bcd8bbe8c5c6b8b88f063038b28","Thermal forming processes and blank-holder force (BHF) technology can both effectively improve the formability of high strength steel (HSS). However, whether the BHF technology is applicable at elevated temperature has yet to be researched. So, in this paper, to evaluate its applicability, BHF window was selected and its size was observed. The cylindrical cup was selected as the research object and its theoretical BHF windows at temperatures from room temperature (RT) to 400 °C, based on plastic theory, were constructed and verified by experiments. Then, main factors contributing to the change of BHF window as temperature rose were analyzed and effective methods for expanding BHF window size were studied. The experimental date, according well with the theoretical BHF windows with the exception of that at temperature of 300~350 °C because of the “blue brittle,” prove the validity of theoretical BHF window. The size of BHF window kept shrinking as temperature rose, which means that it will be more difficult to implement BHF technology at higher temperatures. Initial diameter of blank, coefficient of friction (COF) between blank and die surface and material property are the main factors that affect the size of BHF window at RT or elevated temperatures. Therefore, certain temperatures possibly resulting in brittle fracture of blank should be avoided. Then, reasonable blank sizes and reducing COF could provide a reasonable size of BHF window and make implementing BHF technology in thermal sheet-forming feasible. © 2017, Springer-Verlag London Ltd.","BHF technology; BHF window; Cylindrical cup; Thermal sheet forming","C (programming language); Friction; High strength steel; Blank holder forces; Coefficient of frictions; Cylindrical cups; Elevated temperature; Plastic theory; Research object; Sheet forming; Thermal-forming process; Brittle fracture",2-s2.0-85021269645
"Kumar V., Lee D.-J.","Iron particle and anisotropic effects on mechanical properties of magneto-sensitive elastomers",2017,"Journal of Magnetism and Magnetic Materials",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019565837&doi=10.1016%2fj.jmmm.2017.05.049&partnerID=40&md5=c6c316784c0f147ad640f53aba28ea62","Rubber specimens were prepared by mixing micron-sized iron particles dispersed in room-temperature-vulcanized (RTV) silicone rubber by solution mixing. The possible correlations of the particle volume, size, and distribution with the mechanical properties of the specimens were examined. An isotropic mechanical test shows that at 60 phr, the elastic modulus was 3.29 MPa (electrolyte), 2.92 MPa (carbonyl), and 2.61 MPa (hybrid). The anisotropic effect was examined by curing the specimen under magnetic fields of 0.5–2.0 T at 90° relative to the applied strain. The measurements show anisotropic effects of 11% (carbonyl), 9% (electrolyte), and 6% (hybrid) at 40 phr and 1 T. At 80 phr, the polymer-filler compatibility factor (c-factor) was estimated using the Pythagorean theorem as 0.53 (regular) and 0.73 (anisotropic studies). The improved features could be useful in applications such as controlled damping, vibrational absorption, or automotive bushings. © 2017 Elsevier B.V.","Anisotropic effect; Carbonyl; Electrolyte; Isotropy; RTV silicone rubber","Anisotropy; C (programming language); Elastomers; Electrolytes; Filled polymers; Mechanical properties; Mixing; Silicones; Anisotropic effects; Carbonyl; Isotropy; Magneto-sensitive elastomers; Pythagorean theorem; Room temperature vulcanized; RTV silicone rubber; Vibrational absorption; Rubber",2-s2.0-85019565837
"Zuppolini S., Quero G., Consales M., Diodato L., Vaiano P., Venturelli A., Santucci M., Spyrakis F., Costi M.P., Giordano M., Cutolo A., Cusano A., Borriello A.","Label-free fiber optic optrode for the detection of class C β-lactamases expressed by drug resistant bacteria",2017,"Biomedical Optics Express",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032793305&doi=10.1364%2fBOE.8.005191&partnerID=40&md5=deefe3e3751e78287d2f79f8730ccc6d","This paper reports the experimental assessment of an automated optical assay based on label free optical fiber optrodes for the fast detection of class C β-lactamases (AmpC BLs), actually considered as one of the most important sources of resistance to β-lactams antibiotics expressed by resistant bacteria. Reflection-type long period fiber gratings (RT-LPG) have been used as highly sensitive label free optrodes, while a higher affine boronic acid-based ligand was here selected to enhance the overall assay performances compared to those obtained in our first demonstration. In order to prove the feasibility analysis towards a fully automated optical assay, an engineered system was developed to simultaneously manipulate and interrogate multiple fiber optic optrodes in the different phases of the assay. The automated system tested in AmpC solutions at increasing concentrations demonstrated a limit of detection (LOD) of 6 nM, three times better when compared with the results obtained in our previous work. Moreover, the real effectiveness of the proposed optical assay has been also confirmed in complex matrices as the case of lysates of Escherichia coli overexpressing AmpC. © 2017 Optical Society of America.",,"Automation; Bacteria; Diffraction gratings; Escherichia coli; Fiber optics; Fibers; Optical fibers; Automated systems; Drug-resistant bacteria; Engineered systems; Experimental assessment; Feasibility analysis; Limit of detection; Long period fiber grating; Resistant bacteria; C (programming language)",2-s2.0-85032793305
"Schweitzer P.","Towards an Isomorphism Dichotomy for Hereditary Graph Classes",2017,"Theory of Computing Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021106512&doi=10.1007%2fs00224-017-9775-8&partnerID=40&md5=164d279747168fcb549e95a5239b774d","In this paper we resolve the complexity of the isomorphism problem on all but finitely many of the graph classes characterized by two forbidden induced subgraphs. To this end we develop new techniques applicable for the structural and algorithmic analysis of graphs. First, we develop a methodology to show isomorphism completeness of the isomorphism problem on graph classes by providing a general framework unifying various reduction techniques. Second, we generalize the concept of the modular decomposition to colored graphs, allowing for non-standard decompositions. We show that, given a suitable decomposition functor, the graph isomorphism problem reduces to checking isomorphism of colored prime graphs. Third, we extend the techniques of bounded color valence and hypergraph isomorphism on hypergraphs of bounded color class size as follows. We say a colored graph has generalized color valence at most k if, after removing all vertices in color classes of size at most k, for each color class C every vertex has at most k neighbors in C or at most k non-neighbors in C. We show that isomorphism of graphs of bounded generalized color valence can be solved in polynomial time. © 2017, Springer Science+Business Media New York.","Bounded color valence; Forbidden induced subgraphs; Graph isomorphism; Modular decomposition; Reductions","C (programming language); Color; Graphic methods; Polynomial approximation; Reduction; Set theory; Bounded color valence; Forbidden induced subgraphs; Graph isomorphism; Graph isomorphism problem; Hypergraph isomorphisms; Isomorphism problems; Modular decomposition; Reduction techniques; Graph theory",2-s2.0-85021106512
"Yang S., Ren W., Chen J.","Facile synthesis of spinel LiNi0.5Mn1.5O4 cathode materials using M2(OH)2(C8H4O4)-class metal-organic frameworks",2017,"Ionics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018697549&doi=10.1007%2fs11581-017-2102-1&partnerID=40&md5=7a4c4e0a0b65511f4626872093f348a2","Various synthesis methods have been developed to synthesize mixed metal oxide cathode materials, whereas the scale-up production is hindered by issues of complicated processes, high cost, and inhomogeneity of the prepared materials. Herein, a facile, low-cost, and scalable synthesis route using M2(OH)2(C8H4O4)-class metal-organic frameworks (PTA-based MOFs) as precursors has been explored to synthesize LiNi0.5Mn1.5O4 materials with homogeneity and high crystallinity. Bimetallic PTA-based MOFs were first prepared by the reaction of metal acetates and PTA in the aqueous solution at room temperature. After thermal treatment of PTA-based MOFs, bimetal oxides (Ni-Mn-O) with the inherited morphology of porous nanoplates consisting of 20–30-nm nanoparticles were obtained. The LiNi0.5Mn1.5O4 materials prepared by calcination of Ni-Mn-O with lithium salts exhibit excellent rate capability and cycling performance, delivering a specific capacity of 115.9 mAh g−1 at 20 C and retaining 83.8% after 500 cycles. This work opens a new way for fabrication of PTA-based MOFs and mixed metal oxides as cathode materials for lithium-ion batteries. © 2017, Springer-Verlag Berlin Heidelberg.","Cathode materials; LiNi0.5Mn1.5O4; Metal-organic frameworks; PTA","Bimetals; Cathodes; Crystalline materials; Electrodes; Lithium alloys; Lithium compounds; Lithium-ion batteries; Manganese; Metals; Nickel; Organometallics; Solutions; Cath-ode materials; Cycling performance; High crystallinity; LiNi<sub>0.5</sub>Mn<sub>1.5</sub>O<sub>4</sub>; Metal organic framework; Mixed metal oxide; Scalable synthesis; Specific capacities; C (programming language)",2-s2.0-85018697549
"Ximing G., Bin G., Yuanlin W., Shuanghong G.","Preparation of spherical metal–organic frameworks encapsulating ag nanoparticles and study on its antibacterial activity",2017,"Materials Science and Engineering C",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024931836&doi=10.1016%2fj.msec.2017.07.027&partnerID=40&md5=f80830e97d9e1f3451b09e1cdcecdd71","A metal–organic frameworks (CuTCPP MOFs) were synthesized with Cu(NO3)2·3H2O and 5,10,15,20-tetrakis(4-carboxyphenyl)porphyrin (TCPP) by the solvothermal method. The structure and morphology of the CuTCPP MOFs were characterized by UV–vis absorption spectra, X-ray diffraction (PXRD), energy dispersive spectra, scanning electron microscopy (EDS-SEM) and transmission electron microscopy (TEM). The structure of the as-synthesized MOF includes copper ions and copper metalloporphyrin (Cu-TCPP) by UV–vis absorption spectra and PXRD. The SEM and TEM images of the as-synthesized MOF showed the morphology of the CuTCPP MOFs were spherical. The as-synthesized spherical MOFs as the carriers were used to encapsulate the Ag nanoparticles and prepared Ag-CuTCPP MOFs. The Ag-CuTCPP MOFs was also characterized by UV–vis, PXRD, SEM and TEM. The Ag nanoparticles were completely encapsulated into the CuTCPP MOFs and no surface absorption, which have been confirmed by comparing TEM and SEM-EDS of Ag-CuTCPP MOFs before crushing with that of Ag-CuTCPP MOFs after crushing. In addition, the release of Ag ions from Ag-CuTCPP MOFs was also investigated by Inductively Coupled Plasma Optical Emission Spectrometer (ICP-OES). Furthermore, the antimicrobial activities and cytotoxicity of Ag-CuTCPP MOFs were performed by in vitro and in vivo experiment. In vitro, the antibacterial effect of Ag-CuTCPP MOFs was even better than that of the penicillin as the positive control and the cytotoxicity of Ag-CuTCPP MOFs was significantly lower than that of naked Ag nanoparticles and Ag ions; in vivo, Ag-CuTCPP MOFs not only exhibited the excellently antibacterial effect and extremely low cytotoxicity but also effectively promoted the wound healing. © 2017","Ag nanoparticles; Antibacterial effect; In vitro; In vivo; MOFs","Copper; Crushing; Cytotoxicity; Electromagnetic wave absorption; Electron microscopy; High resolution transmission electron microscopy; Inductively coupled plasma; Ions; Java programming language; Metal ions; Metal nanoparticles; Nanoparticles; Pollution detection; Porphyrins; Scanning electron microscopy; Spheres; Synthesis (chemical); Transmission electron microscopy; X ray diffraction; Ag nanoparticle; Antibacterial effects; In-vitro; In-vivo; MOFs; Silver",2-s2.0-85024931836
"Ouyang Y.","Permutation-invariant qudit codes from polynomials",2017,"Linear Algebra and Its Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021436886&doi=10.1016%2fj.laa.2017.06.031&partnerID=40&md5=eb878e8a828b14cefdc3aa442a47e468","A permutation-invariant quantum code on N qudits is any subspace stabilized by the matrix representation of the symmetric group SN as permutation matrices that permute the underlying N subsystems. When each subsystem is a complex Euclidean space of dimension q≥2, any permutation-invariant code is a subspace of the symmetric subspace of (Cq)N. We give an algebraic construction of new families of d-dimensional permutation-invariant codes on at least (2t+1)2(d−1) qudits that can also correct t errors for d≥2. The construction of our codes relies on a real polynomial with multiple roots at the roots of unity, and a sequence of q−1 real polynomials that satisfy some combinatorial constraints. When N&gt;(2t+1)2(d−1), we prove constructively that an uncountable number of such codes exist. © 2017 Elsevier Inc.","Combinatorial codes; Quantum coding","Codes (symbols); Matrix algebra; Polynomials; Quantum computers; Algebraic constructions; Combinatorial codes; Euclidean spaces; Matrix representation; Permutation matrix; Quantum coding; Roots of unity; Symmetric groups; C (programming language)",2-s2.0-85021436886
"Wei S., Wang C., Tian W., Qiu S., Su G.H.","Thermal hydraulic design and analysis of Thorium-based Advanced CANDU Reactor (TACR)",2017,"Nuclear Engineering and Design",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026779233&doi=10.1016%2fj.nucengdes.2017.07.036&partnerID=40&md5=c2f267c6ef72fdf9db213333928692a2","The application of thorium fuel in advanced CANDU (CANadian Deuterium Uranium) reactors is an economic solution to sustainable development of nuclear energy. In this paper, the thermal hydraulic design and transient analysis of Thorium-based Advanced CANDU Reactor (TACR) heat transport system are conducted using self-programmed code CANTHAC (CANDU Thermal Hydraulic Analysis Code). In the code CANTHAC, the single channel model and the point kinetics model are adopted to simulate the core thermal hydraulic and neutronic behaviors. A distributed parameter model is adopted in the simulation of integral economizer U-tube steam generator (IEUTSG). Multi-region non-equilibrium model is applied to simulate the pressurizer. The characteristics of heat transport pumps were simulated by four-quadrant analogy curves. The code is verified with ACR-700 steady-state analysis. The calculation results agreed well with ACR-700 design values and the relative errors are all within 2%. With CANTHAC steady-state module, the preliminary thermal hydraulic design of TACR is conducted. A 1000 MW double loop reactor with 520 fuel channels is designed. Single loop mass flow rate was designed to be 3202 kg/s. Under the design scheme, the maximum cladding temperature and the maximum temperature are 340.2 °C and 1369.9 °C, which satisfied the design requirements. The transient analysis of TACR heat transport system was performed with CANTHAC transient module. SG feed water temperature reduction accident, and complete loss of Class IV accident were conducted. In the SG feed water temperature reduction accident, a new balance of neutron and thermal hydraulic is reached and the core power increases by 5% at last. In the complete loss of Class IV accident, the maximum fuel temperature reaches peak value at 1172 °C and still has some safety margin. The ROH (Reactor Outlet Header) pressure does not exceed 105% of the design value, which meet the safety criterion demand. © 2017 Elsevier B.V.","TACR; Thermal hydraulic design; Transient safety analysis","Accidents; Boilers; Codes (symbols); Fuels; Heat transfer; Heavy water reactors; Nuclear reactors; Steam generators; Temperature; Thorium; Transient analysis; Transportation; Water; Water piping systems; Distributed-parameter model; Maximum fuel temperatures; Non-equilibrium modeling; Safety analysis; TACR; Thermal-hydraulic analysis; Thermal-hydraulic designs; U-tube steam generators; C (programming language)",2-s2.0-85026779233
"Rughetti D., Di Sanzo P., Ciciani B., Quaglia F.","Machine learning-based thread-parallelism regulation in software transactional memory",2017,"Journal of Parallel and Distributed Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022022359&doi=10.1016%2fj.jpdc.2017.06.001&partnerID=40&md5=a5bc76946a5645df123c1cb5546cf133","Transactional Memory (TM) stands as a powerful paradigm for manipulating shared data in concurrent applications. It avoids the drawbacks of coarse grain locking schemes, namely the potentially excessive limitation of concurrency, while jointly providing support for synchronization transparency to the programmers, which is achieved by embedding code-blocks accessing shared data within transactions. On the downside, excessive transaction aborts may arise in scenarios with non-negligible volumes of conflicting data accesses, which might significantly impair performance. TM needs therefore to resort to methods enabling applications to run with the maximum degree of transaction concurrency that still avoids thrashing. In this article, we focus on Software TM (STM) implementations and present a machine learning-based approach that enables the dynamic selection of the best suited number of threads to be kept alive along specific phases of the execution of STM applications, depending on (variations of) the shared data access pattern. Two key contributions are provided with our approach: (i) the identification of the well suited set of features allowing the instantiation of a reliable neural network-based performance model and (ii) the introduction of mechanisms enabling the reduction of the run-time overhead for sampling these features. We integrated a real implementation of our machine learning-based thread-parallelism regulation approach within the TinySTM open source package and present experimental data, based on the STAMP benchmark suite, which show the effectiveness of the presented thread-parallelism regulation policy in optimizing transaction throughput. © 2017 Elsevier Inc.","Concurrency; Performance optimization; Performance prediction; Transactional memory","Application programs; Artificial intelligence; Java programming language; Learning algorithms; Learning systems; Locks (fasteners); Open source software; Storage allocation (computer); Concurrency; Open source package; Performance optimizations; Performance prediction; Shared data access patterns; Software transactional memory; Transaction throughput; Transactional memory; Education",2-s2.0-85022022359
"Sametoglu F., Celikel O., Witt F.","A differential spectral responsivity measurement system constructed for determining of the spectral responsivity of a single-and triple-junction photovoltaic cells",2017,"EPJ Applied Physics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032687928&doi=10.1051%2fepjap%2f2017170162&partnerID=40&md5=a53524dfa40c89c56d15a6f8949d0f76","A differential spectral responsivity (DSR) measurement system has been designed and constructed at National Metrology Institute of Turkey (TUBITAK UME) to determine the spectral responsivity (SR) of a single-or a multi-junction photovoltaic device (solar cell). The DSR setup contains a broad band light bias source composed of a constructed Solar Simulator based on a 1000 W Xe-arc lamp owning a AM-1.5 filter and 250 W quartz-tungsten-halogen lamp, a designed and constructed LED-based Bias Light Sources, a DC voltage bias circuit, and a probe beam optical power tracking and correction circuit controlled with an ADuC847 microcontroller card together with an embedded C based software, designed and constructed in TUBITAK UME under this project. By using the constructed DSR measurement system, the SR calibration of solar cells, the monolitic triple-junction solar cell GaInP/GaInAs/Ge and its corresponding component cells have been performed within the EURAMET Joint Research Project SolCell. © EDP Sciences, 2017.",,"C (programming language); Computer software; Light emitting diodes; Light sources; Multi-junction solar cells; Photoelectrochemical cells; Photovoltaic cells; Solar power generation; Correction circuits; Measurement system; Multi-junctions; National Metrology Institute of Turkey; Photovoltaic devices; Quartz tungsten halogen lamps; Spectral responsivity; Triple junction solar cells; Solar cells",2-s2.0-85032687928
"Ren Z., Chen C., Tang J., Chen H., Hu S., Zhou C., Xiao X.","Closed-form formula of magnetic gradient tensor for a homogeneous polyhedral magnetic target: A tetrahedral grid example",2017,"Geophysics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028468561&doi=10.1190%2fGEO2016-0470.1&partnerID=40&md5=74d518c9f6ccf20c062304e35a4e203f","A closed-form formula is developed for the full magnetic gradient tensor of a polyhedral body with a homogeneous magnetization vector. It is based on the direct derivative technique on the closed form of the magnetic field. These analytical expressions are implemented into an easy-to-use C++ package which simultaneously calculates the magnetic potential, the magnetic field, and the full magnetic gradient tensor for magnetic targets. Modern unstructured tetrahedral grids are adopted to represent the polyhedral body so that our code can deal with arbitrarily complicated magnetic targets. A prismatic body is tested to verify the accuracies of our closedform formula. Excellent agreements are obtained between our closed-form solutions and solutions of a prismatic magnetic body with differences up to machine precision. A pipeline model is used to demonstrate its capability to deal with complicated magnetic targets. This C++ code is freely available to the magnetic exploration community. © 2017 Society of Exploration Geophysicists.",,"C++ (programming language); Magnetic fields; Magnetic prospecting; Tensors; Analytical expressions; Closed form solutions; Closed-form formulae; Derivative technique; Magnetic gradient tensor; Magnetic potentials; Magnetization vector; Polyhedral bodies; Magnetism",2-s2.0-85028468561
"Xu G., Shi X.","Exploratory investigation into a chemically activated fly ash binder for mortars",2017,"Journal of Materials in Civil Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029349556&doi=10.1061%2f%28ASCE%29MT.1943-5533.0002075&partnerID=40&md5=5e48830d9b718989fce625a9df9b14b2","This paper explores the beneficial use of low-reactivity coal fly ashes as cementitious binder in mortars without heat activation. A uniform design scheme was employed for the statistical design of experiments. Predictive models were developed to quantify the influence of mix design parameters on the compressive strength of fly ash mortars and enable the optimization of mortar designs. The slump flow and the 28-day surface resistivity of fly ash mortars were also studied. The first group of mortar specimens was fabricated using Class C and Class F coal fly ashes and admixtures intended to improve the strength and durability of hardened mortar. In the absence of chemical activation, these fly ash mortars exhibited a relatively low 28-day compressive strength in the range of 2.9-20.5 MPa. The second group of mortar specimens was fabricated using the same Class C fly ash along with the following chemical activators: sodium silicate, quicklime, calcium chloride, and sodium sulfate. Admixing chemical activators into fly ash mortars led to a noticeable improvement in their mechanical properties, with a 28-day compressive strength in the range of 16.8-33.6 MPa. Microscopic examination was conducted to shed light on the hydration behavior of fly ash particles using an electron probe microanalyzer. The results revealed the active role of chemical activators in promoting the dissolution of fly ash particles and the formation of hydration products. © 2017 American Society of Civil Engineers.","Chemical activation; Clink-free binder; Fly ash; Microstructure; Mortar; Scanning electron microscopy; Uniform design","Binders; C (programming language); Cements; Chemical activation; Coal ash; Compressive strength; Design of experiments; Hydration; Microstructure; Mortar; Scanning electron microscopy; Silicates; Silicon compounds; Sodium; Sodium sulfate; Strength of materials; Cementitious binders; Chemical activators; Chemically activated fly ash; Electron probe micro analyzer; Hydration behaviors; Statistical design of experiments; Surface resistivity; Uniform design; Fly ash; chemical binding; compressive strength; design; dissolution; fly ash; microstructure; mortar; scanning electron microscopy",2-s2.0-85029349556
"Lee S.-J., Kwak S.-K., Kim S.-H., Jeon H.-J., Jung J.-H.","Test platform development of vessel’s power management system using hardware-in-the-loop simulation technique",2017,"Journal of Electrical Engineering and Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032874297&doi=10.5370%2fJEET.2017.12.6.2298&partnerID=40&md5=ec7e8f59f8f1d8de47eba38772a9c494","A PMS (Power Management System) controls vessel's power systems to improve the system efficiency and to protect a blackout condition. The PMS should be developed with considering the type and the capacity of the vessel’s power system. It is necessary to test the PMS functions developed for vessel’s safe operations under various sailing situations. Therefore, the function tests in cooperation with practical power systems are required in the PMS development. In this paper, a hardware-in-the-loop (HIL) simulator is developed for the purposes of the PMS function tests. The HIL simulator can be more cost-effective, more time-saved, easier to reproduce, and safer beyond the normal operating range than conventional off-line simulators, especially at early stages in development processes or during fault tests. Vessel's power system model is developed by using a MATLAB/ SIMULINK software and by communicating between an OPAL-RT’s OP5600 simulator. The PMS uses a Modbus communication protocol implemented using LabVIEW software. Representative tests of the PMS functions are performed to verify the validity of the proposed HIL-based test platform. © The Korean Institute of Electrical Engineers.","HIL; Power management system; Power system modeling; Real-time simulation","Braking; Computer programming languages; Computer software; Cost effectiveness; Energy management; Hardware; MATLAB; Power management; Simulators; Synthetic apertures; Traction (friction); Development process; Hardware in the loop simulator; Hardware in-the-loop simulation; Matlab-Simulink software; Off-line simulators; Power management systems; Power system model; Real time simulations; Testing",2-s2.0-85032874297
"Mirachi S., da Costa Guerra V., da Cunha A.M., Dias L.A.V., Villani E.","Applying agile methods to aircraft embedded software: an experimental analysis",2017,"Software - Practice and Experience",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012908695&doi=10.1002%2fspe.2477&partnerID=40&md5=50a7de372951d0dc477b70738372799b","This paper discusses the applicability of agile methods to aircraft embedded software development. It presents the main results of an experiment that combines agile practices from Scrum with model-based development and distributed development. The experiment consists of the development of an aircraft cockpit display system divided in five distributed teams. Three features are analysed and quantified, using the output artefacts of each team: the artefacts' quality, the adherence to agile methods, and the adherence to standard DO-178C. The main conclusion of the experiment is that there is a high correlation between the adherence to agile methods and the artefacts' quality, motivating the use of agile methods in aircraft industry. Also, the experiment evinced that agile methods does not specifically address the integration of distributed teams and the hardware/software integration. This lacuna affects the artefacts' quality. The results of the experiment emphasize the importance of concentrating future work in the proposal of specific agile practices for these activities. Copyright © 2017 John Wiley & Sons, Ltd. Copyright © 2017 John Wiley & Sons, Ltd.","agile methods; aircraft software; DO-178C; embedded system; model-based development","Agile manufacturing systems; Aircraft; C (programming language); Display devices; Embedded software; Embedded systems; Software design; Software engineering; Agile methods; Aircraft industries; Cockpit display systems; Distributed development; Distributed teams; Experimental analysis; Hardware/software integration; Model based development; Cockpits (aircraft)",2-s2.0-85012908695
"Song T.-Y., Tao Z., Han L.-H., Uy B.","Bond Behavior of Concrete-Filled Steel Tubes at Elevated Temperatures",2017,"Journal of Structural Engineering (United States)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028335388&doi=10.1061%2f%28ASCE%29ST.1943-541X.0001890&partnerID=40&md5=2f65265eb0a6182355c2e2e44ba4c0c6","Extensive studies have been conducted into the bond behavior in concrete-filled steel tubes (CFST) at ambient temperature. However, the bond behavior of CFST columns subjected to fire is still unclear. A total of 24 push-out tests were conducted to investigate the bond strength of CFST columns at elevated temperatures, 12 reference specimens at ambient temperature, and 16 postfire specimens were also tested for comparison. The main test parameters explored in this test program include: steel type (carbon and stainless steels), concrete type (normal and expansive concretes), cross-section type (circular and square sections), interface type (normal interface, interface with shear studs, and interface with an internal ring), temperature level (20, 200, 400, 600, and 800°C), hold time period of heating (45, 90, 135, and 180 min), and applied axial load during heating. The experimental results indicated that the bond of specimens with normal interface could be completely broken in fire. However, welding internal rings or shear studs onto the inner surface of the steel tube can effectively retain a portion of the bond strength in fire. © 2017 American Society of Civil Engineers.","Bond strength; Concrete-filled steel tubes; Fire; Metal and composite structures; Push-out; Stainless steel","Bond strength (materials); C (programming language); Carbon; Composite structures; Concretes; Expansive concrete; Fires; Software testing; Studs (fasteners); Studs (structural members); Temperature; Tubular steel structures; Concrete filled steel tube; Concrete-filled steel tubes; Elevated temperature; Inner surfaces; Push-out; Reference specimens; Temperature level; Test parameters; Stainless steel",2-s2.0-85028335388
"Li S., Sha F., Liu R., Li W., Li Z., Wang G.","Properties of cement-based grouts with high amounts of ground granulated blast-furnace slag and fly ash",2017,"Journal of Materials in Civil Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028694718&doi=10.1061%2f%28ASCE%29MT.1943-5533.0002083&partnerID=40&md5=de3d61c19cd5ff1b2877ee29784d9221","A substantial amount of portland cement (PC) is required in grouting practice for soils and rocks. These grouting applications are relatively new areas in which PC could be substituted by high amounts of granulated blast furnace slag (GGBFS) and fly ash (FA) to produce grouts with low cost, environmental friendliness, good workability, and excellent long-term performance. In this study, rheological performance, i.e., flowability, minislump, setting time, bleeding capacity; mechanical properties, i.e., flexural strength, compressive strength, shear bonding strength, and shrinkage; and impermeability of cement-based grouts containing 60% GGBFS, 60% FA, or 20% GGBF + 50% FA were investigated. The fluidity, spreading ability, and stability of grouts were also studied in the presence of a superplasticizer (SP) by itself and in combination with an antiwashout agent (AWA). The range of the water-solid ratio was 0.4-1.2, and the curing durations were 28, 91, and, in a few cases, 182 days. The results show that fluidity, spreading ability, stability, and drying shrinkages of the cementbased grouts were improved by the incorporation of GGBFS (20%) + FA (50%). The SP and AWA should be used together to improve both fluidity and stability. The flexural strength, compressive strength, shear bonding strength, and impermeability of equivalent binary and ternary grouts were close to those of PC-only grouts at later ages. The use of Class C FA offers more benefits than the use of Class F FA. The applications of cement-based grouts containing GGBFS (20%) + FA (50%) are promising in geotechnical engineering. © 2017 American Society of Civil Engineers.","Fly ash (Class F and C); Ground granulated blast furnace slag (GGBFS); Grouts; Impermeability; Mechanical property; Rheological property","Bending strength; Blast furnaces; C (programming language); Compressive strength; Concrete construction; Curing; Diffusion bonding; Fluidity; Fly ash; Geotechnical engineering; Grouting; Mechanical properties; Mortar; Portland cement; Setting; Shrinkage; Slags; Class-f; Environmental friendliness; Granulated blast furnace slag; Ground granulated blast furnace slag; Ground granulated blast-furnace slag (GGBFS); Impermeability; Long term performance; Rheological property; Cements; cement; fly ash; grout; grouting; mechanical property; permeability; rheology; slag",2-s2.0-85028694718
"Bora S.S., Cotton F., Scherbaum F., Edwards B., Traversa P.","Stochastic source, path and site attenuation parameters and associated variabilities for shallow crustal European earthquakes",2017,"Bulletin of Earthquake Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020720266&doi=10.1007%2fs10518-017-0167-x&partnerID=40&md5=2307817b5c60c20362bbfa07b495859f","We have analyzed the recently developed pan-European strong motion database, RESORCE-2012: spectral parameters, such as stress drop (stress parameter, Δσ), anelastic attenuation (Q), near surface attenuation (κ0) and site amplification have been estimated from observed strong motion recordings. The selected dataset exhibits a bilinear distance-dependent Q model with average κ0 value 0.0308 s. Strong regional variations in inelastic attenuation were also observed: frequency-independent Q0 of 1462 and 601 were estimated for Turkish and Italian data respectively. Due to the strong coupling between Q and κ0, the regional variations in Q have strong impact on the estimation of near surface attenuation κ0. κ0 was estimated as 0.0457 and 0.0261 s for Turkey and Italy respectively. Furthermore, a detailed analysis of the variability in estimated κ0 revealed significant within-station variability. The linear site amplification factors were constrained from residual analysis at each station and site-class type. Using the regional Q0 model and a site-class specific κ0, seismic moments (M0) and source corner frequencies fc were estimated from the site corrected empirical Fourier spectra. Δσ did not exhibit magnitude dependence. The median Δσ value was obtained as 5.75 and 5.65 MPa from inverted and database magnitudes respectively. A comparison of response spectra from the stochastic model (derived herein) with that from (regional) ground motion prediction equations (GMPEs) suggests that the presented seismological parameters can be used to represent the corresponding seismological attributes of the regional GMPEs in a host-to-target adjustment framework. The analysis presented herein can be considered as an update of that undertaken for the previous Euro-Mediterranean strong motion database presented by Edwards and Fäh (Geophys J Int 194(2):1190–1202, 2013a). © 2017, Springer Science+Business Media Dordrecht.","Attenuation; Crustal earthquakes; Kappa; Stochastic model; Stress parameter","C (programming language); Database systems; Earthquake effects; Earthquakes; Equations of motion; Geophysics; Motion estimation; Seismology; Stochastic systems; Anelastic attenuation; Attenuation; Crustal earthquakes; Frequency independent; Ground-motion prediction equations; Kappa; Spectral parameters; Stress parameter; Stochastic models; amplification; database; earthquake; earthquake magnitude; estimation method; ground motion; parameterization; seismic attenuation; stochasticity; stress analysis; strong motion; Italy; Turkey",2-s2.0-85020720266
"Zhang W., Han S., He H., Chen H.","Network-aware virtual machine migration in an overcommitted cloud",2017,"Future Generation Computer Systems",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962016088&doi=10.1016%2fj.future.2016.03.009&partnerID=40&md5=6d1299f06de7a9997d44044b4b965d6a","Virtualization, which acts as the underlying technology for cloud computing, enables large amounts of third-party applications to be packed into virtual machines (VMs). VM migration enables servers to be reconsolidated or reshuffled to reduce the operational costs of data centers. The network traffic costs for VM migration currently attract limited attention. However, traffic and bandwidth demands among VMs in a data center account for considerable total traffic. VM migration also causes additional data transfer overhead, which would also increase the network cost of the data center. This study considers a network-aware VM migration (NetVMM) problem in an overcommitted cloud and formulates it into a non-deterministic polynomial time-complete problem. This study aims to minimize network traffic costs by considering the inherent dependencies among VMs that comprise a multi-tier application and the underlying topology of physical machines and to ensure a good trade-off between network communication and VM migration costs. The mechanism that the swarm intelligence algorithm aims to find is an approximate optimal solution through repeated iterations to make it a good solution for the VM migration problem. In this study, genetic algorithm (GA) and artificial bee colony (ABC) are adopted and changed to suit the VM migration problem to minimize the network cost. Experimental results show that GA has low network costs when VM instances are small. However, when the problem size increases, ABC is advantageous to GA. The running time of ABC is also nearly half than that of GA. To the best of our knowledge, we are the first to use ABC to solve the NetVMM problem. © 2016 Elsevier B.V.","Artificial bee colony algorithm; Cloud computing; Genetic algorithm; Migration costs; Network communication costs; Network-aware virtual machine migration","Algorithms; Artificial intelligence; Cloud computing; Computer networks; Costs; Data transfer; Economic and social effects; Evolutionary algorithms; Genetic algorithms; Java programming language; Optimization; Polynomial approximation; Problem solving; Approximate optimal solutions; Artificial bee colony algorithms; Migration costs; Network communications; Non-deterministic polynomial-time complete problems; Swarm intelligence algorithms; Third party application (Apps); Virtual machine migrations; Distributed computer systems",2-s2.0-84962016088
"Francisco Ronszcka A., Zarate Valenca G., Ribeiro Linhares R., Alberto Fabro J., Cezar Stadzisz P., Marcelo Simao J.","Notification-Oriented Paradigm Framework 2.0: An Implementation Based on Design Patterns",2017,"IEEE Latin America Transactions",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032637927&doi=10.1109%2fTLA.2017.8070430&partnerID=40&md5=7c36d275b27da93f442f029600436df3","The Notification-Oriented Paradigm (NOP) is a new technique to develop software. NOP is a rule-oriented approach where every rule and fact-base element is derived into less complex entities with specific tasks. These entities particularly collaborate by means of notifications, which occur only when their state changes. This allows carrying out an inference process completely active. Due to this particular arrangement, NOP can eliminate most of the structural and temporal redundancies that affects program execution performance, difficulties in codification level, and high coupling in program modules. In order to validate the NOP state of art, a framework was initially implemented in C++. Even though it quite demonstrated the features of the paradigm in terms of the development process, it still presented a gap in execution performance. In this context, this paper presents the NOP Framework 2.0. This new version was reengineered aiming better structuration and improvements in the execution time of NOP applications. The experiments show that the new implementation is two times faster than the former one. In addition, new experiments were presented comparing the NOP applications to equivalent implementations based on Oriented-Object Paradigm (OOP) in C++. The NOP applications presented, in some cases, better performance than the OOP applications. © 2003-2012 IEEE.","NOP Framework 2; Notification-Oriented Paradigm","Network function virtualization; Complex entities; Development process; Execution performance; Inference process; NOP Framework 2; Notification-Oriented Paradigm; Program execution; Temporal redundancy; C++ (programming language)",2-s2.0-85032637927
"Trabelsi T., Kumar M., Francisco J.S.","How Does the Central Atom Substitution Impact the Properties of a Criegee Intermediate? Insights from Multireference Calculations",2017,"Journal of the American Chemical Society",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032646141&doi=10.1021%2fjacs.7b08412&partnerID=40&md5=bc7374a6257a22dd7f151efc94107111","Complete active space self-consistent field (CASSCF) and multireference configuration interaction (MRCI)-based multireference calculations have been performed to better understand the ground state properties and the photodissociation mechanism of SiH2OO, a silicon analogue of the parent Criegee intermediate, CH2OO. The CASSCF/aug-cc-pV(T+d)Z results suggest that the ground state of SiH2OO is severely multireference in nature. This explains why SiH2OO could not be characterized in recently reported coupled cluster calculations. An important implication of this multireference character is the dramatically enhanced reactivity of SiH2OO, i.e., the calculated barrier for the cyclization of SiH2OO is only 4.4 kcal/mol, which is nearly 10 kcal/mol lower than that reported for the CH2OO case. The MRCI/aug-cc-pV(T+d)Z results on the evolution of the low-lying singlet electronic states along the OO bond suggest that SiH2OO absorbs strongly in the near UV-vis region. These results improve our fundamental understanding of the thermal and photobehavior of XH2OO (X = C, Si, Ge, and Sn) that serve as precursors for dioxiranes, an important class of oxidants for the synthesis of value-added chemicals, and also find their applications in optodevices. © 2017 American Chemical Society.",,"C (programming language); Germanium; Ground state; Hydrogen bonds; Large scale systems; Numerical methods; Photodissociation; Complete active space self consistent fields; Coupled-cluster calculations; Criegee intermediates; Ground state properties; Multi reference configuration interactions; Multireference calculations; Photodissociation mechanism; Value-added chemicals; Silicon compounds",2-s2.0-85032646141
"Ronconi T., Marulli F.","Cosmological exploitation of cosmic void statistics: New numerical tools in the CosmoBolognaLib to extract cosmological constraints from the void size function",2017,"Astronomy and Astrophysics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032699656&doi=10.1051%2f0004-6361%2f201730852&partnerID=40&md5=295037e200f290fdb2ffee3f90b8c9cd","Context. We present new numerical tools to analyse cosmic void catalogues, implemented inside the CosmoBolognaLib, a large set of open source C++/Python numerical libraries. Aims. The CosmoBolognaLib provides a common numerical environment for cosmological calculations. This work extends these libraries by adding new algorithms for cosmological analyses of cosmic voids, covering the existing gap between theory and observations. Methods. We implemented new methods to model the size function of cosmic voids, in both observed and simulated samples of dark matter and biased tracers. Moreover, we provide new numerical tools to construct unambiguous void catalogues. The latter are designed to be independent of the void finder, in order to allow a high versatility in comparing independent results. Results. The implemented open source software is available at the GitHub repository of the CosmoBolognaLib. We also provide a full doxygen documentation and some example codes that explain how to use these libraries. © ESO, 2017.","Catalogs; Cosmological parameters; Cosmology: observations; Cosmology: Theory; Large-scale structure of Universe; Surveys","C++ (programming language); Libraries; Open source software; Open systems; Software engineering; Surveying; Catalogs; Cosmological parameters; Cosmology: observation; Cosmology: theory; Large scale structure of universe; Cosmology",2-s2.0-85032699656
"Bonilla J., Bittante A.M.Q.B., Sobral P.J.A.","Thermal analysis of gelatin–chitosan edible film mixed with plant ethanolic extracts",2017,"Journal of Thermal Analysis and Calorimetry",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020092150&doi=10.1007%2fs10973-017-6472-4&partnerID=40&md5=4b094eeb70fb5b9c242839561cc20a30","Films based on blends with different gelatin (GEL) and chitosan (CH) (GEL100, GEL75:CH25, GEL50:CH50 and CH100) ratios, with and without ethanolic extracts (boldo of Chile, guarana, cinnamon and rosemary), were prepared by casting technique. The thermal behavior of all films was studied by DSC analysis, and glass transition (Tg) temperature, melting temperature (Tm) and melting enthalpy (ΔHm) were determined. In addition, crystallinity (X) was calculated. In the first scan, GEL100 presented higher Tm (81.9 ± 0.5 °C), ΔHm (22.6 ± 0.2 J g−1) and X (36.4 ± 0.3%) values than CH100 (p ≥ 0.05). In the second scan, the Tg of GEL100 films dislocated a lower temperature (28.2 ± 1.1 °C). Films based on blends (GEL75:CH25 and GEL50:CH50) without extracts exhibited a Tg of around 50 °C and intermediate Tm and X values in the first scan, which significantly decreased as CH increased (GEL50:CH50: Tm = 74.3 ± 1.0 °C, ΔHm = 16.6 ± 0.1 J g−1 and X = 15.7 ± 0.1%) (p ≥ 0.05), showing good compatibility among these biopolymers. Furthermore, ethanolic extracts addition decreased significantly the ΔHm and X of films based on blends with 50% of chitosan polymer in the formulation (p ≥ 0.05), showing intermediate values between pure biopolymers. © 2017, Akadémiai Kiadó, Budapest, Hungary.","Active films; Glass transition; Plant extract; Thermal properties","Biomolecules; Biopolymers; Chitin; Chitosan; Glass; Glass transition; Melting; Plant extracts; Polymer blends; Polymer films; Thermoanalysis; Thermodynamic properties; Active films; Casting techniques; Crystallinities; Ethanolic extracts; Good compatibility; Lower temperatures; Melting enthalpy; Thermal behaviors; C (programming language)",2-s2.0-85020092150
"Huang X., Zhuang T., Kates P.A., Gao H., Chen X., Groves J.T.","Alkyl Isocyanates via Manganese-Catalyzed C-H Activation for the Preparation of Substituted Ureas",2017,"Journal of the American Chemical Society",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032631469&doi=10.1021%2fjacs.7b07658&partnerID=40&md5=2cf20cf1ea58abc0f429e249bce59606","Organic isocyanates are versatile intermediates that provide access to a wide range of functionalities. In this work, we have developed the first synthetic method for preparing aliphatic isocyanates via direct C-H activation. This method proceeds efficiently at room temperature and can be applied to functionalize secondary, tertiary, and benzylic C-H bonds with good yields and functional group compatibility. Moreover, the isocyanate products can be readily converted to substituted ureas without isolation, demonstrating the synthetic potential of the method. To study the reaction mechanism, we have synthesized and characterized a rare MnIV-NCO intermediate and demonstrated its ability to transfer the isocyanate moiety to alkyl radicals. Using EPR spectroscopy, we have directly observed a MnIV intermediate under catalytic conditions. Isocyanation of celestolide with a chiral manganese salen catalyst followed by trapping with aniline afforded the urea product in 51% enantiomeric excess. This represents the only example of an asymmetric synthesis of an organic urea via C-H activation. When combined with our DFT calculations, these results clearly demonstrate that the C-NCO bond was formed through capture of a substrate radical by a MnIV-NCO intermediate. © 2017 American Chemical Society.",,"Activation analysis; Chemical activation; Electron spin resonance spectroscopy; Manganese; Metabolism; Nitrogen compounds; Organic polymers; Reaction intermediates; Urea; Aliphatic isocyanates; Alkyl isocyanate; Asymmetric synthesis; Catalytic conditions; Enantiomeric excess; Reaction mechanism; Substituted ureas; Synthetic methods; C (programming language)",2-s2.0-85032631469
"Jiang K., Li M., Zhao Q., Li W., Guo X.","BeiDou geostationary satellite code bias modeling using fengyun-3C onboard measurements",2017,"Sensors (Switzerland)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032679014&doi=10.3390%2fs17112460&partnerID=40&md5=9443ef0a4143345f76d3c9728f54e988","This study validated and investigated elevation- and frequency-dependent systematic biases observed in ground-based code measurements of the Chinese BeiDou navigation satellite system, using the onboard BeiDou code measurement data from the Chinese meteorological satellite Fengyun-3C. Particularly for geostationary earth orbit satellites, sky-view coverage can be achieved over the entire elevation and azimuth angle ranges with the available onboard tracking data, which is more favorable to modeling code biases. Apart from the BeiDou-satellite-induced biases, the onboard BeiDou code multipath effects also indicate pronounced near-field systematic biases that depend only on signal frequency and the line-of-sight directions. To correct these biases, we developed a proposed code correction model by estimating the BeiDou-satellite-induced biases as linear piece-wise functions in different satellite groups and the near-field systematic biases in a grid approach. To validate the code bias model, we carried out orbit determination using single-frequency BeiDou data with and without code bias corrections applied. Orbit precision statistics indicate that those code biases can seriously degrade single-frequency orbit determination. After the correction model was applied, the orbit position errors, 3D root mean square, were reduced from 150.6 to 56.3 cm. © 2017 by the authors. Licensee MDPI, Basel, Switzerland.","BeiDou code biases; Fengyun-3C; Onboard BeiDou; Single-frequency orbit determination","Codes (symbols); Geostationary satellites; Orbits; Radio navigation; Satellites; BeiDou code biases; Beidou navigation satellite systems; Frequency dependent; Geostationary earth orbit satellites; On-board measurements; Onboard BeiDou; Orbit determination; Precision statistics; C (programming language)",2-s2.0-85032679014
"Wang B., Liu W., Zhang W., Liu J.","Nanoparticles@nanoscale metal-organic framework composites as highly efficient heterogeneous catalysts for size- and shape-selective reactions",2017,"Nano Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025448932&doi=10.1007%2fs12274-017-1595-2&partnerID=40&md5=bd861075135ef823705035e827e94e75","Composites incorporating nanoparticles (NPs) within metal-organic frameworks (MOFs) find applications in many different fields. In particular, using MOF layers as molecular sieves built on the NPs could enable selectivity in heterogeneous catalysis. However, such composites typically exhibit low catalytic efficiency, due to the slow diffusion of the reactants in the long and narrow channels of the MOF shell. In order to improve the catalytic efficiency of these systems, here we report the fabrication of NPs incorporated in nanosized MOFs (NPs@nano-MOFs), obtained by reducing the size of the MOF crystals grown around the NPs. The crystal size of the composites was controlled by modulating the nucleation rate of the MOFs during the encapsulation of pre-synthesized and catalytically active NPs; in this way, NPs@MOF crystals smaller than 50 nm were synthesized and subsequently used as highly efficient catalysts. Due to the shorter path from the MOF surface to the active sites, the obtained Pt@nano-MOFs composites showed a higher conversion rate than their larger-sized counterparts in the synthesis of imines via cascade reaction of nitrobenzene and in the hydrogenation of olefins, while retaining the excellent size and shape selectivity associated with the molecular sieving effect of the MOF layer. The present strategy can also be applied to prepare other encapsulated nanostructures combining various types of NPs and nano-MOFs, thus highlighting the broad potential of this approach for developing optimized catalysts with high reactivity and selectivity. [Figure not available: see fulltext.]. © 2017, Tsinghua University Press and Springer-Verlag GmbH Germany.","heterogeneous catalysts; metal-organic frameworks; nanoparticles; selective catalysis","Catalysis; Catalyst selectivity; Catalysts; Crystalline materials; Efficiency; Java programming language; Molecular sieves; Nanoparticles; Nanostructures; Catalytic efficiencies; Efficient catalysts; Heterogeneous catalyst; Hydrogenation of olefins; Metal organic framework; Metalorganic frameworks (MOFs); Molecular-sieving effects; Nanoparticle (NPs); Metal nanoparticles",2-s2.0-85025448932
"Stankiewicz B., Pałko K.J., Darowski M., Zieliński K., Kozarski M.","A new infant hybrid respiratory simulator: preliminary evaluation based on clinical data",2017,"Medical and Biological Engineering and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016230310&doi=10.1007%2fs11517-017-1635-9&partnerID=40&md5=29f304120034829f69ba383745bb6769","A new hybrid (numerical–physical) simulator of the respiratory system, designed to simulate spontaneous and artificial/assisted ventilation of preterm and full-term infants underwent preliminary evaluation. A numerical, seven-compartmental model of the respiratory system mechanics allows the operator to simulate global and peripheral obstruction and restriction of the lungs. The physical part of the simulator is a piston-based construction of impedance transformer. LabVIEW real-time software coordinates the work of both parts of the simulator and its interaction with a ventilator. Using clinical data, five groups of “artificial infants” were examined: healthy full-term infants, very low-birth-weight preterm infants successfully (VLBW) and unsuccessfully extubated (VLBWun) and extremely low-birth-weight preterm infants without (ELBW) and with bronchopulmonary dysplasia (ELBW_BPD). Pressure-controlled ventilation was simulated to measure peak inspiratory pressure, mean airway pressure, total (patient + endotracheal tube) airway resistance (R), total dynamic compliance of the respiratory system (C), and total work of breathing by the ventilator (WOB). The differences between simulation and clinical parameters were not significant. High correlation coefficients between both types of data were obtained for R, C, and WOB (γR = 0.99, P &lt; 0.0005; γC = 0.85, P &lt; 0.005; γWOB = 0.96, P &lt; 0.05, respectively). Thus, the simulator accurately reproduces infant respiratory system mechanics. © 2017, International Federation for Medical and Biological Engineering.","Decision support techniques; Infant; Mechanical ventilation; Respiratory system","Computer programming languages; Computer software; Decision support systems; Respiratory system; Simulators; Ventilation; Clinical parameters; Compartmental model; Correlation coefficient; Decision support techniques; Impedance transformers; Infant; Mechanical ventilation; Very low birth weights; Respirators; airway pressure; airway resistance; Article; artificial ventilation; breathing pattern; clinical evaluation; clinical study; compartment model; decision support system; extremely low birth weight; extubation; human; infant; lung compliance; lung dysplasia; lung mechanics; lung minute volume; lung model; lung volume; neonatologist; peak inspiratory flow; positive end expiratory pressure; prematurity; priority journal; respiratory care; respiratory system; simulation; thorax pressure; very low birth weight; work of breathing",2-s2.0-85016230310
"Pinto da Costa A., Seeger A., Simões F.M.F.","Complementarity eigenvalue problems for nonlinear matrix pencils",2017,"Applied Mathematics and Computation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019973630&doi=10.1016%2fj.amc.2017.05.028&partnerID=40&md5=711d91b37e50c7d64bb01803462ccc63","This work deals with a class of nonlinear complementarity eigenvalue problems that, from a mathematical point of view, can be written as an equilibrium model [A(λ)B(λ)C(λ)D(λ)][uw]=[v0],u≥0,v≥0,uTv=0,where the vectors u and v are subject to complementarity constraints. The block structured matrix appearing in this partially constrained equilibrium model depends continuously on a real scalar λ ∈ Λ. Such a scalar plays the role of a non-dimensional load parameter, but it may have also other physical meanings. The symbol Λ stands for a given bounded interval, possibly non-closed. The numerical problem at hand is to find all the values of λ (and, in particular, the smallest one) for which the above equilibrium model admits a nontrivial solution. By using the so-called Facial Reduction Technique, we solve efficiently such a numerical problem in various randomly generated test examples and in two mechanical examples of unilateral buckling of columns. © 2017 Elsevier Inc.","Complementarity conditions; Nonlinear complementarity eigenproblem; Nonpolynomial matrix pencil; Unilateral buckling; Zeros of a nonpolynomial function","Buckling; C (programming language); Complementarity conditions; Complementarity constraint; Constrained equilibriums; Eigenproblem; Equilibrium modeling; Matrix pencil; Nonpolynomial functions; Reduction techniques; Eigenvalues and eigenfunctions",2-s2.0-85019973630
"Fischer D.","The R-package GenomicTools for multifactor dimensionality reduction and the analysis of (exploratory) Quantitative Trait Loci",2017,"Computer Methods and Programs in Biomedicine",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028592442&doi=10.1016%2fj.cmpb.2017.08.012&partnerID=40&md5=4ec71f85a3cf86b1ea8c02a0df1c4716","Background and objectives We introduce the R-package GenomicTools to perform, among others, a Multifactor Dimensionality Reduction (MDR) for the identification of SNP-SNP interactions. The package further provides a new class of tests for an (exploratory) Quantitative Trait Loci analysis that overcomes some of the limitations of other popular (e)QTL approaches. Popular (e)QTL approaches that use linear models or ANOVA are often based on over-simplified models that have weak statistical properties and which are not robust against outlying observations. Method The algorithm to calculate the MDR is well established. To speed up its calculation in R, we implemented it in C++. Further, our implementation also supports the combination of several MDR results to an MDR ensemble classifier. The (e)QTL test procedure is based on a generalized Mann-Whitney test that is tailored for directional alternatives, as they are present in an (e)QTL analysis. Results Our package GenomicTools provides functions to determine SNP combinations that have the highest accuracy for a MDR classification problem. It also provides functions to combine the best MDR results to a joined ensemble classifier for improved classification results. Further, the (e)QTL analysis is based on a solid statistical theory. In addition, informative visualizations of the results are provided. Conclusion The here presented new class of tests and methods have an easy to apply syntax, so that also researchers inexperienced in R are able to apply our proposed methods and implementations. The package creates publication ready Figures and hence could be a valuable tool for genomic data analysis. © 2017 Elsevier B.V.","eQTL; MDR; QTL; R-package","Testing; Classification results; Ensemble classifiers; eQTL; Multifactor dimensionality reductions; Outlying observation; Quantitative trait locus; Statistical properties; Statistical theory; C++ (programming language); calculation; classification; classifier; data analysis; human; multifactor dimensionality reduction; publication; quantitative trait locus; rank sum test; scientist; theoretical study; velocity",2-s2.0-85028592442
"Liao S.-W., Kao C.-L., Shimizu Y.","A profile-guided synergistic computation framework for Halide",2017,"Journal of Systems Architecture",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031748235&doi=10.1016%2fj.sysarc.2017.10.005&partnerID=40&md5=bbcad4cd9383756d035be58bb79cf272","Recently, heterogeneous computing that incorporates the main processor(s) with accelerator(s) for boosting the performance of applications becomes popular. While joining forces of the accelerators could help improve performance, it may also sometimes produce the negative results. In particular, this happens during the execution of the image processing applications. Halide, in particular, has such a problem. Our previous study found that dynamically dispatching image processing tasks to the CPU and the GPU could often lead to prolonged execution time. In this paper, we propose a profile-guided job dispatching mechanism to better harness the computing power of the different types of computing elements. The proposed mechanism assigns the computation tasks onto the proper computing elements, based on the measured performance during the early rounds of the task execution. We implemented the proposed mechanism in the Halide framework. We evaluate the efficiency of the dispatching method with two benchmarks, including bilateral grid filters and local Laplacian filters using the CPU-only, the GPU-only and the hybrid CPU-GPU configurations. Our results show that the profile-guided approach boosts the performance with 1K resolution which is 52% faster than the dynamic approach for local Laplacian filters. On the other hand, for bilateral grid filters, the difference is within 7%. For local Laplacian filters with 8K resolution, the boosted performance is 38% faster than the dynamic approach. In addition, for bilateral grid filters, the difference is within 7%. As a result, it delivers better results than dispatching mechanism in previous work. Since the high-level C++ objects are offered to the programmers and the implementation details of the proposed method are hidden from them, the programmers are allowed to focus on the application logics rather than coordinating the computation between the heterogeneous computing elements. © 2017 Elsevier B.V.","Halide; Heterogeneous computing; Image processing","C++ (programming language); Computation theory; Dynamics; Electric load dispatching; Graphics processing unit; Laplace transforms; Application logic; Computing element; Dispatching methods; Dynamic approaches; Halide; Heterogeneous computing; Image processing applications; Improve performance; Image processing",2-s2.0-85031748235
"Borhani S., Moradi M., Kiani M.A., Hajati S., Toth J.","CoxZn1−x ZIF-derived binary Co3O4/ZnO wrapped by 3D reduced graphene oxide for asymmetric supercapacitor: Comparison of pure and heat-treated bimetallic MOF",2017,"Ceramics International",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026420930&doi=10.1016%2fj.ceramint.2017.07.211&partnerID=40&md5=dd16fdcd7afacbc45a88445de9e39059","Sodalite zeolitic imidazolate frameworks containing Co (ZIF-67) and Zn (ZIF-8) as well as three hybrid MOFs (Co0.75Zn0.25, Co0.5Zn0.5 and Co0.25Zn0.75-ZIFs) were successfully synthesized at room temperature under aqueous conditions within 24 h. These MOFs (ZIF1 to 5) were used as template for the synthesis of nanoporous metal oxide (pure CO3O4, three hybrids of CO3O4/ZnO with different ratios of CO3O4 and ZnO, as well as pure ZnO; named as HTZIF1 to 5, respectively). X-ray photoelectron spectroscopy and energy dispersive X-ray analysis were applied to obtain stoichiometric ratios of Co/Zn in pure and heat-treated MOFs. Performances of the reduced graphene oxide/active material composites were investigated by cyclic voltammetry, galvanostatic charge-discharge and electrochemical impedance spectroscopy. Amongst the two groups (rGO/ZIFn and rGO/HTZIFn) of electrodes, the rGO/ZIF2 and rGO/HTZIF3 exhibited favorable specific capacitances of 163 and 204 F g−1, respectively, at 1 A g−1. The rGO/HTZIF3 electrode demonstrated a 1.6 V potential window in hydrous electrolyte when it was used in an asymmetric supercapacitor device with rGO nanosheets as anode electrode, which led to achieve a high specific energy of 12.4 W h kg−1. Furthermore, the asymmetric supercapacitor device provided a maximum specific power of 8500 W kg−1 and a specific energy of 12.4 W h kg−1 with a large working potential of 1.6 V. In addition, 87% of its capacity was kept after 2000 cycles at a current density of 3 A g−1. This indicates that the heat-treated ZIF electrode can be suggested as a promising candidate for future applications in renewable energy storage. © 2017 Elsevier Ltd and Techna Group S.r.l.","Electrochemical analysis; Hybrid MOF; Stoichiometric analysis; Supercapacitor","Cyclic voltammetry; Electric discharges; Electrochemical impedance spectroscopy; Electrodes; Electrolytes; Graphene; Java programming language; Metals; Polyacrylonitriles; Silver; X ray photoelectron spectroscopy; Zinc oxide; Asymmetric supercapacitor; Electrochemical analysis; Galvanostatic charge discharges; Hybrid MOF; Reduced graphene oxides; Renewable energy storages; Stoichiometric analysis; Zeolitic imidazolate frameworks; Supercapacitor",2-s2.0-85026420930
"Jiang X.-R., Yao Z.-H., Chen G.-Q.","Controlling cell volume for efficient PHB production by Halomonas",2017,"Metabolic Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029476168&doi=10.1016%2fj.ymben.2017.09.004&partnerID=40&md5=b7c1fa5a2877b6504b5f5fab44be6013","Bacterial morphology is decided by cytoskeleton protein MreB and cell division protein FtsZ encoded by essential genes mreB and ftsZ, respectively. Inactivating mreB and ftsZ lead to increasing cell sizes and cell lengths, respectively, yet seriously reduce cell growth ability. Here we develop a temperature-responsible plasmid expression system for compensated expression of relevant gene(s) in mreB or ftsZ disrupted recombinants H. campaniensis LS21, allowing mreB or ftsZ disrupted recombinants to grow normally at 30 °C in a bioreactor for 12 h so that a certain cell density can be reached, followed by 36 h cell size expansions or cell shape elongations at elevated 37 °C at which the mreB and ftsZ encoded plasmid pTKmf failed to replicate in the recombinants and thus lost themselves. Finally, 80% PHB yield increase was achieved via controllable morphology manipulated H. campaniensis LS21. It is concluded that controllable expanding cell volumes (widths or lengths) provides more spaces for accumulating more inclusion body polyhydroxybutyrate (PHB) and the resulting cell gravity precipitation benefits the final separation of cells and product during downstream. © 2017 International Metabolic Engineering Society","Cell size; Halomonas; Morphology engineering; mreB; Open fermentation; PHB","C (programming language); Cell proliferation; Cells; Cytology; DNA; Gene expression; Genes; Gravitation; Morphology; Precipitation (chemical); Proteins; Bacterial morphology; Cell size; Controllable morphology; Expression system; Halomonas; Inclusion bodies; mreB; Polyhydroxybutyrate; Cell engineering; FtsZ protein; MreB protein; poly(3 hydroxybutyric acid); Article; bacterial genome; bacterial growth; bioreactor; biotechnological production; cell density; cell growth; cell inclusion; cell shape; cell size; cell structure; cell volume; controlled study; essential gene; gene expression system; gene inactivation; genetic recombination; Halomonas; Halomonas campaniensis; metabolic engineering; nonhuman; plasmid; priority journal; temperature",2-s2.0-85029476168
"Roberts N.J., Thomas D.J., Visser T.P.P.","Improved Bonner sphere neutron spectrometry measurements for the nuclear industry",2017,"Radiation Physics and Chemistry",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012940201&doi=10.1016%2fj.radphyschem.2017.02.019&partnerID=40&md5=ba845ceaf27bd07588b8d96c3af39b0b","A novel, two-stage approach has been developed for producing the a priori spectrum for Bonner sphere unfolding in a case where neutrons are produced by spontaneous fission and (α,n) reactions, e.g. in UF6. The code SOURCES 4C is first used to obtain the energy spectrum of the neutrons inside the material, which is then fed into a MCNP model of the entire geometry to derive the neutron spectrum at the location of the Bonner sphere. Using this as the a priori spectrum produces a much more detailed unfolded Bonner sphere spectrum retaining fine structure from the calculation that would not be present if a simple estimated spectrum had been used as the a priori spectrum. This is illustrated using a Bonner sphere measurement of the neutron energy spectrum produced by a 48Y cylinder of UF6. From the unfolded spectrum an estimate has been made of the neutron ambient dose equivalent, i.e. the quantity which a neutron survey instrument should measure. The difference in the ambient dose equivalent of the unfolded spectrum is over 10% when using the novel approach instead of using a simpler estimate consisting of a single high energy peak, 1/E continuum, and thermal peak. © 2017 Elsevier Ltd","Bonner spheres; Monte Carlo; Neutron spectrometry; Neutron survey instruments; UF6; Unfolding","C (programming language); Monte Carlo methods; Neutron spectrometers; Nuclear industry; Spectrometry; Spectroscopy; Spheres; Surveys; Bonner spheres; Neutron spectrometry; Survey instruments; UF<sub>6</sub>; Unfolding; Neutrons; calculation; geometry; model; neutron radiation; nuclear industry; spectrometry",2-s2.0-85012940201
"Poungsombate A., Imyen T., Dittanet P., Embley B., Kongkachuichay P.","Direct synthesis of dimethyl carbonate from CO2 and methanol by supported bimetallic Cu–Ni/ZIF-8 MOF catalysts",2017,"Journal of the Taiwan Institute of Chemical Engineers",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026313888&doi=10.1016%2fj.jtice.2017.07.019&partnerID=40&md5=53c5fd1dcd648aab0e9c361f4e884dd1","Supported bimetallic Cu–Ni/ZIF-8 metal oxide framework (MOF) catalysts were synthesized for the production of dimethyl carbonate (DMC) from CO2 and methanol. The catalytic support material, zeolitic imidazolate framework-8 (ZIF-8), was prepared by solvothermal method using methanol (MeOH) as a solvent and then loaded with bimetallic Cu–Ni catalyst (1:1 by weight) via an incipient wetness impregnation. The support material and synthesized catalysts were first characterized using powder XRD, TGA, FT-IR, FE-SEM, TEM, BET and ICP–OES analysis. Then, the ZIF-8 supported bimetallic catalysts were tested for catalytic activity in the direct synthesis of DMC from CO2 and MeOH. Various parameters—metal loading content, reaction temperature, weight of catalyst loading and reaction time—and their effects were investigated. The highest DMC yield (6.39%) and the highest MeOH conversion (12.79%) were achieved at 20 bar of CO2, 110 °C and 12 h using 0.7 g of 5%Cu–Ni/ZIF-8 catalyst. Under the optimized conditions, the catalyst was able to retain its catalytic performance up to 4 regeneration cycles. These results indicate that supported bimetallic Cu–Ni/ZIF-8 catalysts have a high potential for synthesis of DMC. © 2017 Taiwan Institute of Chemical Engineers","Carbon dioxide; Copper; Dimethyl carbonate; Methanol; Nickel; ZIF-8","Binary alloys; Carbon; Carbon dioxide; Carbonation; Catalyst activity; Catalysts; Copper; Copper alloys; Java programming language; Metals; Methanol; Nickel; Nickel alloys; Organic solvents; Catalytic performance; Dimethyl carbonate; Incipientwetness impregnation; Metal-oxide frameworks; Optimized conditions; Reaction temperature; Zeolitic imidazolate framework-8; ZIF-8; Catalyst supports",2-s2.0-85026313888
"Giraldo D., Correa H., Peña Lara D.","Implementation of a programmable electromechanical chopper with adjustable frequency and duty cycle for specific heat measurements",2017,"Measurement: Journal of the International Measurement Confederation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021171410&doi=10.1016%2fj.measurement.2017.06.017&partnerID=40&md5=e4ffe7cff5c148b0b9d2d8897bb256aa","A hard disk mechanism was used as an electromechanical light chopper controlled by software developed in LabVIEW with an accuracy of ±0.01 Hz in frequency to realize specific heat measurements. This chopper can be used in applications in experimental techniques in which low-frequency light excitation is required. The software provides an user interface to set the excitation frequency and its duty cycle. The evaluation of the efficiency was measured by installing the device in a fully automated high-resolution AC calorimetry system. The device provides a light cutter signal with a frequency varying from 1 mHz to 40 Hz. Employing the desired wave function, the excitation mode provided by this design can be used under theoretical models proposed for the specific heat technique, obtaining an increased efficiency in the measurements of the specific heat response for the studied materials. This paper reports the performance characteristics of the technology of an asymmetric CA-chopper, which can optimize efficiency in capturing the measurement of the response of specific heat of any given study material in a high-resolution ac calorimetry system. The chopper consists entirely of the positioning mechanism of a hard disk. © 2017 Elsevier Ltd","AC calorimetry; Electromechanical light chopper; LabVIEW; Specific heat","Calorimeters; Calorimetry; Choppers (circuits); Computer programming languages; Efficiency; Thermal variables measurement; User interfaces; AC-calorimetry; Adjustable frequency; Electromechanical chopper; Excitation frequency; Experimental techniques; LabViEW; Optimize efficiency; Performance characteristics; Specific heat",2-s2.0-85021171410
"Cescutti G., Kobayashi C.","Manganese spread in Ursa Minor as a proof of sub-classes of type Ia supernovae",2017,"Astronomy and Astrophysics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032634652&doi=10.1051%2f0004-6361%2f201731398&partnerID=40&md5=511dd2a60e9eec960905b8c3fd207e8c","Context. Recently, new sub-classes of Type Ia supernovae (SNe Ia) were discovered, including SNe Iax. The suggested progenitors of SNe Iax are relatively massive, possibly hybrid C+O+Ne white dwarfs, which can cause white dwarf winds at low metallicities. There is another class that can potentially occur at low or zero metallicities; sub-Chandrasekhar mass explosions in single and/or double degenerate systems of standard C+O white dwarfs. These explosions have different nucleosynthesis yields compared to the normal, Chandrasekhar mass explosions. Aims. We test these SN Ia channels using their characteristic chemical signatures. Methods. The two sub-classes of SNe Ia are expected to be rarer than normal SNe Ia and do not affect the chemical evolution in the solar neighbourhood; however, because of the shorter delay time and/or weaker metallicity dependence, they could influence the evolution of metal-poor systems. Therefore, we have included both in our stochastic chemical evolution model for the dwarf spheroidal galaxy Ursa Minor. Results. The model predicts a butterfly-shape spread in [Mn/Fe] in the interstellar medium at low metallicity and - at the same time - a decrease of [α/Fe] ratios at lower [Fe/H] than in the solar neighbourhood, both of which are consistent with the observed abundances in stars of Ursa Minor. Conclusions. The surprising agreement between our models and available observations provides a strong indication of the origins of these new sub-classes of SNe Ia. This outcome requires confirmation by future abundance measurements of manganese in stars of other satellite galaxies of our Milky Way. It will be vital for this project to measure not the most extreme metal-poor tail, as more commonly happens, but the opposite; the metal-rich end of dwarf spheroidals. © 2017 ESO.","abundances; Galaxies: dwarf; Galaxies: evolution; Nuclear reactions; nucleosynthesis; Stars: abundances; Supernovae: general","Astrophysics; C (programming language); Chemical elements; Galaxies; Manganese; Metals; Nuclear reactions; Nucleosynthesis; Stars; Stochastic models; Stochastic systems; Supernovae; abundances; Galaxies: dwarf; Galaxies: evolutions; Stars: abundances; Supernovae: general; White dwarfs",2-s2.0-85032634652
"Zhang F., Yao H., Zhao Y., Li X., Zhang G., Yang Y.","Mixed matrix membranes incorporated with Ln-MOF for selective and sensitive detection of nitrofuran antibiotics based on inner filter effect",2017,"Talanta",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021711805&doi=10.1016%2fj.talanta.2017.07.007&partnerID=40&md5=1a921d5b0f6196a8a649c9e144eb0c2b","The detection of antibiotics is critical and challenging due to the pervasive use of antibiotics had inevitably brought some negative impacts on ecosystem and human health. Herein, we reported an anti-interfere ability enhanced luminescent sensor of lanthanide metal–organic framework (Ln-MOF) filled mixed matrix membranes (MMMs), which combining the processibility of poly(methyl methacrylate) (PMMA) polymer with Ln-MOF of {[Tb2(AIP)2(H2O)10]·(AIP)·4H2O}n (Tb-AIP, where AIP is 5-aminoisophthalate) fillers. The as-fabricated Tb-AIP MMMs are stable in water with a wide pH range and exhibit characteristic blue emission of Tb3+. Significantly, the Tb-AIP MMMs show highly selective and sensitive to nitrofuran antibiotics (NFAs) via inner filter effect (IFE), and yet remain unaffected not only by other common antibiotics but also by other types of analytes (metal ions and anions) that may coexist. The limits of detection for nitrofurantoin (NFT) and nitrofurazone (NFZ) are 0.30 and 0.35 μM, respectively. As a proof of concept, the proposed MMMs sensor are demonstrated to be feasible for application in detecting NFAs in original water of Pearl River and bovine serum samples, the corresponding quenching constants and limits of detection are similar to their standard detections in an acceptable range. Furthermore, this MMMs sensor for NFAs detection was reversible after washing with deionized water. The luminescent Ln-MOF filled MMMs presented here provides a functional platform for simple yet useful in sensing of NFAs in environment and biology systems. © 2017 Elsevier B.V.","Antibiotics; Inner filter effect; Lanthanide metal–organic framework; Mixed matrix membranes; Sensor","Bandpass filters; Deionized water; Esters; Filled polymers; Java programming language; Luminescence; Metal ions; Metals; Nanostructured materials; Rare earth elements; Sensors; Terbium; Enhanced luminescent; Inner filter effects; Limits of detection; Mixed matrix membranes; Poly(methyl methacrylate) (PMMA); Proof of concept; Quenching constant; Sensitive detection; Antibiotics",2-s2.0-85021711805
"Shamsipur M., Barati A., Karami S.","Long-wavelength, multicolor, and white-light emitting carbon-based dots: Achievements made, challenges remaining, and applications",2017,"Carbon",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029004215&doi=10.1016%2fj.carbon.2017.08.072&partnerID=40&md5=642b11a5a38fa16b22e15cdf7d306c07","The use of carbon-based dots (C-bDs), involving carbon dots, carbon quantum dots, and graphene quantum dots, as a new class of photoluminescent nanomaterials is rapidly expanding. Their many advantages including water solubility, high stability, low toxicity, ease of functionalization, and cost-efficient and simple synthetic routes have introduced them as potential alternatives to conventional semiconductor-based quantum dots. However, difficulty in preparing long-wavelength and multicolor-emitting C-bDs has caused some major disadvantages for these nanomaterials and limited their application in fields such as bioimaging and multicolor patterning. Although different emission colors from C-bDs can be observed by varying their excitation wavelength, this is not identified as real photoluminescence tuning, and in fact, preparing C-bDs with such special photoluminescence properties has proven to be a challenging task. This review summarizes to date successes in preparing long-wavelength, multicolor, and white-light-emitting C-bDs along with their potential applications. We discuss the developments in using specific precursors, synthetic methods, heteroatom doping, and post treatments such as separation and surface modification methods that have led to C-bDs with unique emission colors. © 2017 Elsevier Ltd","Carbon-based dots; Multicolor emission; Nanomaterials; Photoluminescence; White-light emission","Light emission; Nanocrystals; Nanostructured materials; Photoluminescence; Semiconductor doping; Semiconductor quantum dots; Surface treatment; Carbon quantum dots; Carbon-based; Excitation wavelength; Multi-color emissions; Photoluminescence properties; Surface modification methods; White light emission; White light-emitting; C (programming language)",2-s2.0-85029004215
"Lin C.-H., Pan Y.-C., Liu F.-W., Chen C.-Y.","Prokaryotic expression and action mechanism of antimicrobial LsGRP1C recombinant protein containing a fusion partner of small ubiquitin-like modifier",2017,"Applied Microbiology and Biotechnology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030177283&doi=10.1007%2fs00253-017-8530-z&partnerID=40&md5=62b7b2fec095c009ab9050388923b4d1","Antimicrobial peptides (AMPs) are peptides exhibiting broad-spectrum antimicrobial activities and considered as potential therapeutic agents. LsGRP1C, a novel AMP derived from defense-related LsGRP1 protein of Lilium, was proven to inhibit kinds of bacteria and fungi via alteration of microbial membrane permeability and induction of fungal programmed cell death-like phenomena by in vitro assays using synthetic LsGRP1C. In this study, the prokaryotic production of LsGRP1C recombinant protein containing an N-terminal fusion partner of the yeast small ubiquitin-like modifier (SUMO) was achieved by using optimized Escherichia coli host and purification buffer system, which lead to a high yield of soluble SUMO-LsGRP1C fusion protein. In vitro assay revealed that E. coli-expressed SUMO-LsGRP1C exhibited even better antifungal activity as compared to synthetic LsGRP1C. Meanwhile, the ability of SUMO-LsGRP1C in conducting fungal membrane permeabilization and programmed cell death was verified by SYTOX Green staining and 4′,6-diamidino-2-phenylindole staining/terminal deoxynucleotidyl transferase dUTP nick-end labeling assays, respectively, indicating that E. coli-expressed SUMO-LsGRP1C shares identical modes of action with synthetic LsGRP1C. Herein, this E. coli expression system enables the effective and convenient production of antimicrobial LsGRP1C in a form of SUMO-fused recombinant protein. © 2017, Springer-Verlag GmbH Germany.","Antimicrobial peptide; Escherichia coli expression system; LsGRP1C; SUMO fusion partner","Antimicrobial agents; Assays; Cell death; Cell membranes; Escherichia coli; Fungi; Microorganisms; Peptides; Polypeptides; Proteins; Recombinant proteins; Anti-microbial activity; Antimicrobial peptide; Escherichia coli expression systems; Fusion partners; Membrane permeabilization; Programmed cell deaths; Prokaryotic production; Small ubiquitin-like modifiers; C (programming language); buffer; hybrid protein; polypeptide antibiotic agent; recombinant LsGRP1 protein; SUMO protein; unclassified drug; antimicrobial activity; coliform bacterium; fungus; gene expression; laboratory method; membrane; optimization; prokaryote; protein; purification; antifungal activity; apoptosis; Article; bacterial strain; cell inclusion; controlled study; drug mechanism; Escherichia coli; fungal membrane; gene expression system; in vitro study; nonhuman; plasmid; protein expression; TUNEL assay; Escherichia coli; Fungi; Lilium; Prokaryota",2-s2.0-85030177283
"Garcia A., Laneve C., Lienhardt M.","Static analysis of cloud elasticity",2017,"Science of Computer Programming",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019393843&doi=10.1016%2fj.scico.2017.03.008&partnerID=40&md5=7f35f0fab65d95a8c004013452c6a73b","We propose a static analysis technique that computes upper bounds of virtual machine usages in a concurrent language with explicit acquire and release operations of virtual machines. In our language it is possible to delegate other (ad-hoc or third party) concurrent code to release virtual machines (by passing them as arguments of invocations). Our technique is modular and consists of (i) a type system associating programs with behavioural types that record relevant information for resource usage (creations, releases, and concurrent operations), (ii) a translation function that takes behavioural types and returns cost equations, and (iii) an automatic off-the-shelf solver for the cost equations. A soundness proof of the type system establishes the correctness of our technique with respect to the cost equations. We have experimentally evaluated our technique using a cost analysis solver and we report some results. © 2017 Elsevier B.V.","Behavioural type system; Cloud computing; Concurrent programming; Resource consumption analysis; Subject reduction","Cloud computing; Computer programming; Concurrency control; Costs; Distributed computer systems; Network security; Program translators; Static analysis; Virtual machine; Analysis techniques; Behavioural types; Concurrent languages; Concurrent operations; Concurrent programming; Resource consumption; Subject reduction; Translation functions; Cost benefit analysis",2-s2.0-85019393843
"Shigarov A.O., Mikhailov A.A.","Rule-based spreadsheet data transformation from arbitrary to relational tables",2017,"Information Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027526043&doi=10.1016%2fj.is.2017.08.004&partnerID=40&md5=02089dfbfee9b99a73226be1ee154cc8","The paper discusses issues of rule-based data transformation from arbitrary spreadsheet tables to a canonical (relational) form. We present a novel table object model and rule-based language for table analysis and interpretation. The model is intended to represent a physical (cellular) and logical (semantic) structure of an arbitrary table in the transformation process. The language allows drawing up this process as consecutive steps of table understanding, i. e. recovering implicit semantics. Both are implemented in our tool for spreadsheet data canonicalization. The presented case study demonstrates the use of the tool for developing a task-specific rule-set to convert data from arbitrary tables of the same genre (government statistical websites) to flat file databases. The performance evaluation confirms the applicability of the implemented rule-set in accomplishing the stated objectives of the application. © 2017 Elsevier Ltd","Rule-based programming; Spreadsheet data transformation; Table analysis; Table interpretation; Table model; Table understanding","Computer programming; Data handling; Logic programming; Semantics; Spreadsheets; Data transformation; Table analysis; Table interpretation; Table modeling; Table understanding; Metadata",2-s2.0-85027526043
"Schmidt-Schauß M., Sabel D.","Improvements in a call-by-need functional core language: Common subexpression elimination and resource preserving translations",2017,"Science of Computer Programming",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010618989&doi=10.1016%2fj.scico.2017.01.001&partnerID=40&md5=a644cf983f923e38cd5b7e5d8419085a","An improvement is a correct program transformation that optimizes the program, where the criterion is that the number of computation steps until a value is obtained is not strictly increased in any context. This paper investigates improvements in both – an untyped and a polymorphically typed variant – of a call-by-need lambda calculus with letrec, case, constructors and seq. Besides showing that several local transformations are optimizations, a main result of this paper is a proof that common subexpression elimination is correct and an improvement, which proves a conjecture and thus closes a gap in the improvement theory of Moran and Sands. The improvement relation used in this paper is generic in which essential computation steps are counted and thus the obtained results apply for several notions of improvement. Besides the small-step operational semantics, also an abstract machine semantics is considered for counting computation steps. We show for several length measures that the call-by-need calculus of Moran and Sands and our calculus are equivalent. © 2017 Elsevier B.V.","Functional programming; Improvement; Lambda calculus; Lazy evaluation; Semantics","Computation theory; Computational mechanics; Differentiation (calculus); Functional programming; Semantics; Call by need lambda calculus; Common subexpression elimination; Improvement; Lambda calculus; Lazy evaluation; Local transformations; Operational semantics; Program transformations; Calculations",2-s2.0-85010618989
"Moreton-Fernandez A., Gonzalez-Escribano A., Llanos D.R.","A technique to automatically determine Ad-hoc communication patterns at runtime",2017,"Parallel Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028928076&doi=10.1016%2fj.parco.2017.08.009&partnerID=40&md5=c910d7ccbabafa9ab31e126b20bc0aa6","Current High Performance Computing (HPC) systems are typically built as interconnected clusters of shared-memory multicore computers. Several techniques to automatically generate parallel programs from high-level parallel languages or sequential codes have been proposed. To properly exploit the scalability of HPC clusters, these techniques should take into account the combination of data communication across distributed memory, and the exploitation of shared-memory models. In this paper, we present a new communication calculation technique to be applied across different SPMD (Single Program Multiple Data) code blocks, containing several uniform data access expressions. We have implemented this technique in Trasgo, a programming model and compilation framework that transforms parallel programs from a high-level parallel specification that deals with parallelism in a unified, abstract, and portable way. The proposed technique computes at runtime exact coarse-grained communications for distributed message-passing processes. Applying this technique at runtime has the advantage of being independent of compile-time decisions, such as the tile size chosen for each process. Our approach allows the automatic generation of pre-compiled multi-level parallel routines, libraries, or programs that can adapt their communication, synchronization, and optimization structures to the target system, even when computing nodes have different capabilities. Our experimental results show that, despite our runtime calculation, our approach can automatically produce efficient programs compared with MPI reference codes, and with codes generated with auto-parallelizing compilers. © 2017 Elsevier B.V.","Distributed communications; Parallel programming; SPMD models; Trasgo","Codes (symbols); Memory architecture; Message passing; Parallel programming; Program compilers; Structural optimization; Ad-hoc communication; Calculation techniques; Distributed communications; High performance computing systems; Message passing process; Single program multiple data; SPMD model; Trasgo; High level languages",2-s2.0-85028928076
"Legat C., Vogel-Heuser B.","A configurable partial-order planning approach for field level operation strategies of PLC-based industry 4.0 automated manufacturing systems",2017,"Engineering Applications of Artificial Intelligence",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030713189&doi=10.1016%2fj.engappai.2017.06.014&partnerID=40&md5=cb7421ad4109351fba16b7324e9330b0","The machine and plant automation domain is faced with an ever increasing demand for ensuring the adaptability of manufacturing facilities in context of Industry 4.0. Field level automation software plays a dominant role in strengthening the overall flexibility of manufacturing resources. Classical programming approaches based typically on signal-oriented languages result in disproportionate effort for ensuring necessary flexibility. To address this challenge, a novel approach based on artificial intelligence planning techniques is presented which is able to handle domain specific requirements while facilitating efficient, scalable problem solving. Throughout this article, a discussion of specific requirements on automated planning techniques for field level automation software in the machine and plant automation domain with respect to Industry 4.0 is provided. An intensive study on existing works and their drawbacks towards addressing these requirements is presented. The proposed configurable partial-order planning approach is based upon a combination of an adapted goal-based planning formulation and its reformulation by means of linear programming techniques. It is shown that the proposed approach is able to efficiently solve large planning problems by exhibiting positive scalability characteristics which indicates its applicability for real-size plants. © 2017 Elsevier Ltd","Automated production systems; Field level automation software; Industry 4.0; Linear programming; Machine and plant automation; Partial order planning","Linear programming; Manufacture; Planning; Problem solving; Artificial intelligence planning; Automated manufacturing systems; Automated production systems; Automation software; Linear programming techniques; Manufacturing resource; Partial order planning; Plant automation; Automation",2-s2.0-85030713189
"Russo I.L.S., Bernardino H.S., Barbosa H.J.C.","A massively parallel Grammatical Evolution technique with OpenCL",2017,"Journal of Parallel and Distributed Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025648230&doi=10.1016%2fj.jpdc.2017.06.017&partnerID=40&md5=0aaa52d79ecba94acc1f23ff57af735b","Grammatical Evolution (GE) is a bio-inspired metaheuristic capable of evolving programs in an arbitrary language using a formal grammar. Among the major applications of the technique, the automatic inference of models from data can be highlighted. As with other genetic programming techniques, GE has a high computational cost. However, the algorithm has steps that can be computed independently, enabling the use of parallel computing to reduce the execution time and, consequently, making it possible its application to larger and more complex problems. Here, models of massively parallel computation for GE are studied and proposed using OpenCL, a framework for the creation of parallel algorithms in heterogeneous computing environments. Computational experiments were conducted to analyze the performance of an implementation using GPUs (Graphics Processing Units), when compared to a sequential implementation in CPUs (Central Processing Units). Finally, speedups of up to 528× were achieved, when all steps are performed in parallel in a GPU. © 2017 Elsevier Inc.","Genetic programming; Grammatical evolution; OpenCL; Parallel computing","Computational grammars; Computer graphics; Genetic algorithms; Graphics processing unit; Parallel processing systems; Program processors; Automatic inference; Computational costs; Computational experiment; Genetic programming technique; Grammatical evolution; Heterogeneous computing; OpenCL; Sequential implementation; Genetic programming",2-s2.0-85025648230
"Cerqueira R., Trocoli T., Neves G., Joyeux S., Albiez J., Oliveira L.","A novel GPU-based sonar simulator for real-time applications",2017,"Computers and Graphics (Pergamon)",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028715072&doi=10.1016%2fj.cag.2017.08.008&partnerID=40&md5=aec178d76e4b8c35b012214fd670011f","Mainly when applied in the underwater environment, sonar simulation requires great computational effort due to the complexity of acoustic physics. Simulation of sonar operation allows evaluating algorithms and control systems without going to the real underwater environment; that reduces the costs and risks of in-field experiments. This paper tackles with the problem of real-time underwater imaging sonar simulation by using the OpenGL shading language chain on GPU. Our proposed system is able to simulate two main types of acoustic devices: mechanical scanning imaging sonars and forward-looking sonars. The underwater scenario simulation is performed based on three frameworks: (i) OpenSceneGraph reproduces the ocean visual effects, (ii) Gazebo deals with physical forces, and (iii) the Robot Construction Kit controls the sonar in underwater environments. Our system exploits the rasterization pipeline in order to simulate the sonar devices, which are simulated by means of three parameters: the pulse distance, the echo intensity and the sonar field-of-view, being all calculated over observable objects shapes in the 3D rendered scene. Sonar-intrinsic operational parameters, speckle noise and object material properties are also considered as part of the acoustic image. Our evaluation demonstrated that the proposed system is able to operate close to or faster than the real-world devices. Also, our method generates visually realistic sonar images when compared with real-world sonar images of the same scenes. © 2017 Elsevier Ltd","GPU-based processing; Robot construction kit (Rock); Simulated sensor data; Sonar imaging; Underwater robotics","Application programming interfaces (API); Computer simulation languages; Graphics processing unit; Rasterization; Sonar; Underwater imaging; Gpu-based; Robot construction; Sensor data; Sonar imaging; Underwater robotics; Underwater acoustics",2-s2.0-85028715072
"de Andrade D.C., Trabasso L.G.","An OpenCL framework for high performance extraction of image features",2017,"Journal of Parallel and Distributed Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020885429&doi=10.1016%2fj.jpdc.2017.05.011&partnerID=40&md5=ff1983ddea98d39b17e1ebdaf9e5ad2f","Image features are widely used for object identification in many situations, including interpretation of data containing natural scenes captured by unmanned aerial vehicles. This paper presents a parallel framework to extract additive features (such as color features and histogram of oriented gradients) using the processing power of GPUs and multicore CPUs to accelerate the algorithms with the OpenCL language. The resulting features are available in device memory and then can be fed into classifiers such as SVM, logistic regression and boosting methods for object recognition. It is possible to extract multiple features with better performance. The GPU accelerated image integral algorithm speeds up computations up to 35x when compared to the single-thread CPU implementation in a test bed hardware. The proposed framework allows real-time extraction of a very large number of image features from full-HD images (better than 30 fps) and makes them available for access in coalesced order by GPU classification algorithms. © 2017 Elsevier Inc.","Additive features; Haar features; Heterogeneous programming; Histogram of oriented gradients; Image descriptors; OpenCL; Parallel processing","Extraction; Graphic methods; Graphics processing unit; Multicore programming; Object recognition; Program processors; Haar features; Heterogeneous programming; Histogram of oriented gradients; Image descriptors; OpenCL; Parallel processing; Image processing",2-s2.0-85020885429
"Hellesen C., Qvist S.","Benchmark and demonstration of the CHD code for transient analysis of fast reactor systems",2017,"Annals of Nuclear Energy",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021391176&doi=10.1016%2fj.anucene.2017.05.031&partnerID=40&md5=897decb07c05deb1cd904ed55cc2e47c","In this paper the dynamic thermal hydraulic fast reactor simulation code CHD is presented. The code is built around a scriptable object-oriented framework in the programming language Python to be able to flexibly describe different reactor geometries including thermal-hydraulics models of an arbitrary number of coolant channels as well as pumps, heat-exchangers and pools etc. In addition, custom objects such as the Autonomous Reactivity Control (ARC) system for enhanced passive safety are modeled in detail. In this paper we compare the performance of the CHD code with other similar fast reactor dynamics codes using a benchmark study of the European Sodium cooled Fast Reactor (ESFR). The results agree well, both qualitatively and quantitatively with the code benchmark. In addition, we demonstrate the code's ability to simulate the long-term asymptotic behavior of a neutronically shut down reactor in an unprotected loss of flow scenario using a model of the Advanced Burner Reactor (ABR). © 2017 Elsevier Ltd","Fast reactor; Passive safety; Point-kinetics; Thermal-hydraulics; Transient; ULOF","Benchmarking; Fast reactors; Hydraulics; Object oriented programming; Transient analysis; Transients; Object-oriented frameworks; Passive safety; Point kinetics; Reactor simulation codes; Sodium cooled fast reactor; Thermal hydraulics; Thermal-hydraulics models; ULOF; Codes (symbols)",2-s2.0-85021391176
"Rosat S., Elhallaoui I., Soumis F., Lodi A.","Integral simplex using decomposition with primal cutting planes",2017,"Mathematical Programming",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015032290&doi=10.1007%2fs10107-017-1123-x&partnerID=40&md5=e234db9181a348ad96c6807ba4e1a692","This paper concentrates on the addition of cutting planes to the integral simplex using decomposition (ISUD) of Zaghrouti et al. (Oper Res 62(2):435–449, 2014). This method solves the set partitioning problem by iteratively improving an existing feasible solution. We present the algorithm in a primal language and relate it to existing augmenting methods. The resulting theoretical properties, stronger than the ones already known, simplify termination proofs and deepen the geometrical insights on ISUD in particular. We show that primal cuts, that is, cutting planes that are tight at the current feasible integer solution, can be used to improve the performance of the algorithm, and further that such cutting planes are enough to solve each augmentation problem. We propose efficient separation procedures for well-known polyhedral inequalities, namely primal clique and odd-cycle cuts. Numerical results demonstrate the effectiveness of primal cutting planes; tests are performed on small and large-scale set partitioning problems from aircrew and bus-driver scheduling instances up to 1600 constraints and 570,000 variables. © 2017, Springer-Verlag Berlin Heidelberg and Mathematical Optimization Society.","Integral simplex; Primal algorithms; Primal cutting-planes; Scheduling; Set partitioning; {0, 1}-Programming","Bus drivers; Iterative methods; Scheduling; Augmentation problems; Cutting planes; Feasible solution; Integral simplex; Large scale set partitioning; Primal algorithm; Set partitioning; Set partitioning problem; Problem solving",2-s2.0-85015032290
"Negreira Rey M.C., López García X.","Web-native media in Galicia. Trends and characteristics of a booming model",2017,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84997206831&doi=10.1007%2f978-3-319-46068-0_15&partnerID=40&md5=6cdd590dcbbd86cff063761e8c77153e","The social and economic reality of recent years has led to a series of changes in the media, evolving into new organizational, productive and distributive models. In this new reality, the presence of online media is growing in relation to traditional media, prompting its emergence as an increasingly important site of communicative influence and citizen participation. In Galicia, where the first digital newspaper appeared two decades ago, it is not difficult to perceive a continuous growth of web-native media. Such media has been born as a space that seeks greater diversity and freedom of information, whether in terms of geographical space, editorial models, specialization or language. Moreover, it is in this type of online media where citizen journalism is most present, offering spaces for participation and allowing citizens to be the drivers of many digital web-natives. The objective of this paper is to study this media reality, the trends of its development and its particular characteristics. The research is based on an exploratory study involving the identification and location of web-native media. The relevance of such media throughout the Galician media ecosystem is analyzed by applying both quantitative and qualitative techniques, so as to identify the representative characteristics of web-natives. © Springer International Publishing Switzerland 2017.","Communications; Galicia; Journalism; Online media; Web-native media","Communication; Computer programming; Citizen participation; Digital newspapers; Exploratory studies; Freedom of informations; Galicia; Journalism; nocv1; Online media; Web-native media; Computer science",2-s2.0-84997206831
"Kumar A., Verma G., Gupta M.K.","FM Receiver Design Using Programmable PLL",2017,"Wireless Personal Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019758127&doi=10.1007%2fs11277-017-4536-1&partnerID=40&md5=e72947b456dce6038fbec5febd8b9ce5","The research article presents the design of different components of FM receiver. The design approach is based on digital components rather than analog components such as phase detector, loop filter and voltage controlled oscillator. The signal is presented using digital words instead of analog voltages. In digital FM receiver, PLL is the main part to capture and lock the signals at different frequency and phase. The main purpose of PLL is to maintain the coherence between the modulated signal frequency (fi) and the respective frequency (fo), with the concept of phase comparison. PLL permits to track the frequency changes of applied input signals, as it is locked once. There is a use of 8 bit analog to digital conversion circuit, which is accepting frequency modulated signal as a series of digital numerical values. The same signals are demodulated by the receiver on every clock cycle. The paper proposed the design and FPGA implementation of digital PLL and programmable all FM receiver. The design is developed in Xilinx 14.2 ISE software and simulated in Modelsim 10.1b software with the help of VHDL programming language and the targeted onVirtex-5 FPGA. © 2017, Springer Science+Business Media New York.","Field programmable gate array (FPGA); Frequency modulation (FM); Phase locked loop (PLL); System on chip (SoC)","Analog to digital conversion; Circuit oscillations; Computer hardware description languages; Digital to analog conversion; Field programmable gate arrays (FPGA); Integrated circuit design; Locks (fasteners); Oscillistors; Phase comparators; Phase locked loops; Programmable logic controllers; Radio receivers; System-on-chip; Variable frequency oscillators; Design approaches; Different frequency; Digital components; FPGA implementations; Frequency changes; Frequency modulated signal; Phase Locked Loop (PLL); System on chips (SoC); Frequency modulation",2-s2.0-85019758127
"Basen-Engquist K., Alfano C.M., Maitin-Shepard M., Thomson C.A., Schmitz K.H., Pinto B.M., Stein K., Zucker D.S., Syrjala K.L., Fallon E., Doyle C., Demark-Wahnefried W.","Agenda for Translating Physical Activity, Nutrition, and Weight Management Interventions for Cancer Survivors into Clinical and Community Practice",2017,"Obesity",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032483950&doi=10.1002%2foby.22031&partnerID=40&md5=7ea51af7b523c38946dba6cceb74f6c3","Evidence supporting physical activity, diet, and weight management for cancer survivors has grown, leading to the development of guidelines and interventions. The next step is to identify necessary practice and policy changes and to develop a research agenda to inform how interventions can be delivered to survivors most effectively and efficiently in health care settings and by community-based organizations. Here, an agenda is proposed for research, practice, and policy that incorporates recommendations for a range of programming options, a patient-centered, tailored screening and referral approach, and training needs for survivorship care providers and providers of exercise, nutrition, and weight management services. Research needs to focus on sustainability, dissemination, and implementation. Needed policy changes are presented, as well as opportunities to leverage current health care policies. © 2017 The Obesity Society",,"adult; body weight; cancer survivor; exercise; health care policy; human; language; nutrition; patient referral; physical activity",2-s2.0-85032483950
"Paprzycki P., Tuttle N., Czerniak C.M., Molitor S., Kadervaek J., Mendenhall R.","The impact of a Framework-aligned science professional development program on literacy and mathematics achievement of K-3 students",2017,"Journal of Research in Science Teaching",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030636465&doi=10.1002%2ftea.21400&partnerID=40&md5=c4d4f66b9dfa7c04c66f7aa6e0f55f80","This study investigates the effect of a Framework-aligned professional development program at the PreK-3 level. The NSF funded program integrated science with literacy and mathematics learning and provided teacher professional development, along with materials and programming for parents to encourage science investigations and discourse around science in the home. This quasi-experimental study used a three-level hierarchical linear model to compare the Renaissance STAR Early Literacy, Reading, and Mathematics scores from 2015 to 2016 of K-3 students in treatment and control classrooms in a large Midwestern urban school district. The statistically significant results indicate that, on average, every year that a student has a program teacher adds 8.6 points to a student's spring STAR Early Literacy score, 17.0 points to a student's STAR Mathematics score, and 41.4 points to a student's STAR Reading score compared to control students. Implications for early elementary teacher education and policy are discussed. © 2017 Wiley Periodicals, Inc. J Res Sci Teach 54:1174–1196, 2017. © 2017 Wiley Periodicals, Inc.","language and literacy; mathematics; professional development","Education; Education computing; Mathematical techniques; Professional aspects; Stars; Teaching; Elementary teacher educations; Hierarchical linear modeling; language and literacy; Mathematics learning; Professional development; Professional development program; Science professional development; Teacher professional development; Students",2-s2.0-85030636465
"Herrera J.F.R., Salmerón J.M.G., Hendrix E.M.T., Asenjo R., Casado L.G.","On parallel Branch and Bound frameworks for Global Optimization",2017,"Journal of Global Optimization",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014769819&doi=10.1007%2fs10898-017-0508-y&partnerID=40&md5=e0aa79e1cce631c75b59004f597f45d3","Branch and Bound (B&B) algorithms are known to exhibit an irregularity of the search tree. Therefore, developing a parallel approach for this kind of algorithms is a challenge. The efficiency of a B&B algorithm depends on the chosen Branching, Bounding, Selection, Rejection, and Termination rules. The question we investigate is how the chosen platform consisting of programming language, used libraries, or skeletons influences programming effort and algorithm performance. Selection rule and data management structures are usually hidden to programmers for frameworks with a high level of abstraction, as well as the load balancing strategy, when the algorithm is run in parallel. We investigate the question by implementing a multidimensional Global Optimization B&B algorithm with the help of three frameworks with a different level of abstraction (from more to less): Bobpp, Threading Building Blocks (TBB), and a customized Pthread implementation. The following has been found. The Bobpp implementation is easy to code, but exhibits the poorest scalability. On the contrast, the TBB and Pthread implementations scale almost linearly on the used platform. The TBB approach shows a slightly better productivity. © 2017, The Author(s).","Branch-and-Bound; Framework; Load balancing; Shared-memory; TBB","Abstracting; Branch and bound method; Global optimization; Information management; Resource allocation; Algorithm performance; Framework; High level of abstraction; Load balancing strategy; Management structure; Parallel branch and bounds; Shared memory; Threading building blocks; Optimization",2-s2.0-85014769819
"Chang Y.-M., Wang S.-C., Yang C.-C., Hwang Y.-S., Lee J.-K.","Enabling PoCL-based runtime frameworks on the HSA for OpenCL 2.0 support",2017,"Journal of Systems Architecture",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032217603&doi=10.1016%2fj.sysarc.2017.10.004&partnerID=40&md5=0139ad1f55a79c243b18df529b0afad4","The heterogeneous system architecture (HSA), announced by the HSA Foundation, is an approach to integrate central processing unit (CPU) and graphics processing unit (GPU) architectures. The open computing language (OpenCL) is a programming framework that can help utilize heterogeneous architectures. The well-known OpenCL framework, currently in version 1.2, provides programming models for heterogeneous computing. The proposed specifications of OpenCL 2.0 can help utilize HSA features, such as shared virtual memory (SVM). In previous work, we helped enable Portable Computing Language (PoCL)-based OpenCL 1.2 runtime frameworks on the HSA. In this paper, we further extend the PoCL-based runtime on the HSA to support OpenCL 2.0 features. In addition, this is the first work, to our best knowledge, to support PoCL-based OpenCL 2.0 features on HSA. Compared with the widely used OpenCL 1.2, OpenCL 2.0 will support SVM, nested parallelism, pipes, and atomic operations. It can further support parallel design patterns such as tree searches, pointer-based programming and nested parallelism models. Note that PoCL is a widely used open source implementation of OpenCL. Our design flow can help academics to enable OpenCL 2.0 flow on the HSA and benefit further from advanced academic research. The experimental results indicate that our framework provides adequate features to support advanced research. © 2017 Elsevier B.V.","HSA; OpenCL; PoCL; Runtime","Computer graphics; Computer graphics equipment; Graphics processing unit; Open source software; Program processors; Heterogeneous architectures; Heterogeneous computing; Open source implementation; OpenCL; Parallel design patterns; PoCL; Runtimes; Shared virtual memory; Computer architecture",2-s2.0-85032217603
"Kanes R., Ramirez Marengo M.C., Abdel-Moati H., Cranefield J., Véchot L.","Developing a framework for dynamic risk assessment using Bayesian networks and reliability data",2017,"Journal of Loss Prevention in the Process Industries",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030710042&doi=10.1016%2fj.jlp.2017.09.011&partnerID=40&md5=16ab5a1b5a49208bca69ccf08945fdfc","Process Safety in the oil and gas industry is managed through a robust Process Safety Management (PSM) system that involves the assessment of the risks associated with a facility in all steps of its life cycle. Risk levels tend to fluctuate throughout the life cycle of many processes due to several time varying risk factors (performances of the safety barriers, equipment conditions, staff competence, incidents history, etc.). While current practices for quantitative risk assessments (e.g. Bow-tie analysis (BT), Layer of protection analysis (LOPA) etc.) have brought significant improvements in the management of major hazards, they are static in nature and do not fully take into account the dynamic nature of risk and how it improves risk-based decision making. In an attempt to continually enhance the risk management in process facilities, the oil and gas industry has put in very significant efforts over the last decade toward the development of process safety key performance indicators (KPI or parameters to be observed) to continuously measure or gauge the efficiency of safety management systems and reduce the risks of major incidents. This has increased the sources of information that are used to assess risks in real-time. The use of such KPIs has proved to be a major step forward in the improvement of process safety in major hazards facilities. Looking toward the future, there appears to be an opportunity to use the multiple KPIs measured at a process plant to assess the quantitative measure of risk levels at the facility on a time-variant basis. ExxonMobil Research Qatar (EMRQ) has partnered with the Mary Kay O'Connor Process Safety Center – Qatar (MKOPSC-Q) to develop a tool that monitors, in real time, the potential increases in risk levels as a result of pre-identified risk factors and process safety related data, using Bayesian Belief Networks (BN). The development of the tool involved two phases: 1) Development of a methodology that establishes the framework for the tool and 2) Development of the tool itself with the use of JAVA programming language. The overall tool is to be called PULSE, which stands for Process Unit Life Safety Evaluation. In this context, the paper presents a case study of the quantitative risk assessment of a process unit using BN. The different steps of the development of the BN are detailed, including: translation of a Bowtie into a skeletal BN, modification of the skeletal BN to incorporate reliability data, and insertion of equipment failure evidence into the BN for dynamic modeling. In addition, an overview of PULSE is presented. The outcomes of the dynamic modeling of the BN with real time insertion of evidence are discussed and recommendation for the framework for a dynamic risk assessment tool are made. © 2017 Elsevier Ltd","Bayesian networks applications; Bowtie analysis; Process safety performance metrics; Reliability",,2-s2.0-85030710042
"Butykai A., Domínguez-García P., Mor F.M., Gaál R., Forró L., Jeney S.","PFMCal : Photonic force microscopy calibration extended for its application in high-frequency microrheology",2017,"Computer Physics Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029286181&doi=10.1016%2fj.cpc.2017.07.019&partnerID=40&md5=04c56d3a040448335e9a97361b288b3a","The present document is an update of the previously published MatLab code for the calibration of optical tweezers in the high-resolution detection of the Brownian motion of non-spherical probes [1]. In this instance, an alternative version of the original code, based on the same physical theory [2], but focused on the automation of the calibration of measurements using spherical probes, is outlined. The new added code is useful for high-frequency microrheology studies, where the probe radius is known but the viscosity of the surrounding fluid maybe not. This extended calibration methodology is automatic, without the need of a user's interface. A code for calibration by means of thermal noise analysis [3] is also included; this is a method that can be applied when using viscoelastic fluids if the trap stiffness is previously estimated [4]. The new code can be executed in MatLab and using GNU Octave. New version program summary Program Title: PFMCal Program Files doi: http://dx.doi.org/10.17632/s59f3gz729.1 Licensing provisions: GPLv3 Programming language: MatLab 2016a (MathWorks Inc.) and GNU Octave 4.0 Operating system: Linux and Windows. Supplementary material: A new document README.pdf includes basic running instructions for the new code. Journal reference of previous version: Computer Physics Communications, 196 (2015) 599 Does the new version supersede the previous version?: No. It adds alternative but compatible code while providing similar calibration factors. Nature of problem (approx. 50–250 words): The original code uses a MatLab-provided user's interface, which is not available in GNU Octave, and cannot be used outside of a proprietary software as MatLab. Besides, the process of calibration when using spherical probes needs an automatic method when calibrating big amounts of different data focused to microrheology. Solution method (approx. 50–250 words): The new code can be executed in the latest version of MatLab and using GNU Octave, a free and open-source alternative to MatLab. This code generates an automatic calibration process which requires only to write the input data in the main script. Additionally, we include a calibration method based on thermal noise statistics, which can be used with viscoelastic fluids if the trap stiffness is previously estimated. Reasons for the new version: This version extends the functionality of PFMCal for the particular case of spherical probes and unknown fluid viscosities. The extended code is automatic, works in different operating systems and it is compatible with GNU Octave. Summary of revisions: The original MatLab program in the previous version, which is executed by PFMCal.m, is not changed. Here, we have added two additional main archives named PFMCal_auto.m and PFMCal_histo.m, which implement automatic calculations of the calibration process and calibration through Boltzmann statistics, respectively. The process of calibration using this code for spherical beads is described in the README.pdf file provided in the new code submission. Here, we obtain different calibration factors, β (given in μm/V), according to [2], related to two statistical quantities: the mean-squared displacement (MSD), βMSD, and the velocity autocorrelation function (VAF), βVAF. Using that methodology, the trap stiffness, k, and the zero-shear viscosity of the fluid, η, can be calculated if the value of the particle's radius, a, is previously known. For comparison, we include in the extended code the method of calibration using the corner frequency of the power-spectral density (PSD) [5], providing a calibration factor βPSD. Besides, with the prior estimation of the trap stiffness, along with the known value of the particle's radius, we can use thermal noise statistics to obtain calibration factors, β, according to the quadratic form of the optical potential, βE, and related to the Gaussian distribution of the bead's positions, βσ2. This method has been demonstrated to be applicable to the calibration of optical tweezers when using non-Newtonian viscoelastic polymeric liquids [4]. An example of the results using this calibration process is summarized in Table 1. Using the data provided in the new code submission, for water and acetone fluids, we calculate all the calibration factors by using the original PFMCal.m and by the new non-GUI code PFMCal_auto.m and PFMCal_histo.m. Regarding the new code, PFMCal_auto.m returns η, k, βMSD, βVAF and βPSD, while PFMCal_histo.m provides βσ2 and βE. Table 1 shows how we obtain the expected viscosity of the two fluids at this temperature and how the different methods provide good agreement between trap stiffnesses and calibration factors. Additional comments including Restrictions and Unusual features (approx. 50–250 words): The original code, PFMCal.m, runs under MatLab using the Statistics Toolbox. The extended code, PFMCal_auto.m and PFMCal_histo.m, can be executed without modification using MatLab or GNU Octave. The code has been tested in Linux and Windows operating systems. References [1] A. Butykai, F. Mor, R. Gaál, P. Domínguez-García, L. Forró, J. S., Calibration of optical tweezers with non-spherical probes via high-resolution detection of brownian motion, Comput. Phys. Commun. 196 (2015) 599–610.[2] M. Grimm, T. Franosch, S. Jeney, High-resolution detection of brownian motion for quantitative optical tweezers experiments, Phys. Rev. E 86 (2012) 021912.[3] E.-L. Florin, A. Pralle, E. H. K. Stelzer, J. K. H. Hörber, Photonic force microscope calibration by thermal noise analysis, Appl. Phys. A 66 (1998) S75–S78.[4] P. Domínguez-García, L. Forró, S. Jeney, Interplay between optical, viscous, and elastic forces on an optically trapped brownian particle immersed in a viscoelastic fluid, Appl. Phys. Lett. 109 (14) (2016) 143702.[5] K. Berg-Sørensen, H. Flyvbjerg, Power spectrum analysis for optical tweezers, Rev. Sci. Instrum. 75 (3) (2004) 594–612. © 2017 Elsevier B.V.","Brownian motion; Calibration of optical tweezers; Mean square displacement (MSD); Power spectral density (PSD); Velocity autocorrelation function (VAF)","Acetone; Autocorrelation; Brownian movement; Calibration; Codes (symbols); Computer operating systems; Correlation detectors; Gaussian noise (electronic); Kinetic theory of gases; Linux; Non Newtonian flow; Non Newtonian liquids; Number theory; Open source software; Open systems; Optical tweezers; Power spectral density; Probes; Spectral density; Spectrum analysis; Spheres; Statistics; Stiffness; Thermal noise; Viscoelasticity; Windows operating system; Calibration methodologies; High resolution detection; High-frequency microrheology; Mean square displacement; Photonic force microscope; Photonic Force Microscopy; Power spectral densities (PSD); Velocity autocorrelation functions; MATLAB",2-s2.0-85029286181
"Huang Q., Liu X., Sun X., Zhang J.","Partial Sorting Problem on Evolving Data",2017,"Algorithmica",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014758636&doi=10.1007%2fs00453-017-0295-3&partnerID=40&md5=a152d003739c6e18ca21ea306f7cd9a1","In this paper we investigate the top-k-selection problem, i.e. to determine and sort the top k elements, in the dynamic data model. Here dynamic means that the underlying total order evolves over time, and that the order can only be probed by pair-wise comparisons. It is assumed that at each time step, only one pair of elements can be compared. This assumption of restricted access is reasonable in the dynamic model, especially for massive data sets where it is impossible to access all the data before the next change occurs. Previously only two special cases were studied (Anagnostopoulos et al. in 36th international colloquium on automata, languages and programming (ICALP). LNCS, vol 5566, pp 339–350, 2009) in this model: selecting the element of a given rank, and sorting all elements. This paper systematically deals with 1 ≤ k≤ n. Specifically, we identify the critical point k∗ such that the top-k-selection problem can be solved error-free with probability 1 - o(1) if and only if k= o(k∗). A lower bound of the error when k= Ω(k∗) is also determined, which actually is tight under some conditions. In contrast, we show that the top-k-set problem, which means finding the top k elements without sorting them, can be solved error-free with probability 1 - o(1) for all 1 ≤ k≤ n. Additionally, we consider some extensions of the dynamic data model and show that most of these results still hold. © 2017, Springer Science+Business Media New York.",,"Errors; Dynamic data; Evolving datum; K-selection; Lower bounds; Massive data sets; Pair-wise comparison; Set problems; Total order; Sorting",2-s2.0-85014758636
"Din S., Paul A., Ahmad A., Kim J.H.","Energy efficient topology management scheme based on clustering technique for software defined wireless sensor network",2017,"Peer-to-Peer Networking and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032349494&doi=10.1007%2fs12083-017-0607-z&partnerID=40&md5=69c8f435a52fde448fbc6d880da37ae7","Load balancing and energy conservation techniques are one of the significant constraints in the design of in software defined wireless sensor network (SD-WSN). Usually, clustering method helps the network in the minimum utilization of energy that results in enhancing network lifetime. Moreover, various nodes in the multi-hop network that are near to the base station drain their battery very quickly thus lead to creating hot spot problem in a network. To overcome such constraints, this paper proposes a multilayer clustering architecture for selection of forwarding node, rotation of cluster head, and inter and intra-cluster routing communication. The proposed scheme efficiently tackle the rotation of forwarder node by incorporating routing table (table list) at each node. Moreover, the rotation is performed by the consideration of two threshold levels of the residual energy of a node. Also, the exploitation of decision maker node, forwarder node, backup forwarder node, and non-forwarder node enhancing the routing strategy in a network. The performance of the proposed scheme is tested and evaluated by C programming language. The results show that the proposed scheme successful achieve better results than TLPER and EADUC in energy consumption per node, end-to-end communication, hop count in cluster formation. © 2017 Springer Science+Business Media, LLC","And non-forwarder node; Backup forwarder node; Cluster design; Decision maker node; Forwarder node; Multi-layer; Routing; Software define network; Wireless sensor network","C (programming language); Cluster analysis; Cluster computing; Decision making; Energy efficiency; Energy utilization; Mobile telecommunication systems; Network routing; Wireless sensor networks; And non-forwarder node; Backup forwarder node; Cluster designs; Decision makers; Forwarder node; Routing; Sensor nodes",2-s2.0-85032349494
"Bi C., Yuan Y., Zhang R., Xiang Y., Wang Y., Zhang J.","A Dynamic Mode Decomposition Based Edge Detection Method for Art Images",2017,"IEEE Photonics Journal",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032457826&doi=10.1109%2fJPHOT.2017.2766881&partnerID=40&md5=2d0202877ff0e9a899bfb981e5c1c716","Edge detection is a widely used feature extraction method in various fields, such as image processing, computer vision, machine vision, and so forth. However, it is still a challenging task to extract edges from art images, due to the False Edge, Shadow, and Double Lines of art images. In this paper, we propose a Dynamic Mode Decomposition algorithm (DMD) based method for edge detection of art images. This is achieved by proposing a new color space based denoise method to deal with the shadow issue. Then, the false edge and double lines can be resolved by employing DMD method, which can be used to extract sparse features from the denoised images. Here, the sparse features have been enhanced by a new designed Eight Direction Gradient Operator (EDGO). Finally, the effectiveness of our method will be demonstrated through detecting the edges of three classical types of art images (Comic, Oil Painting, and Printmaking). CCBY","filtering; image edge detection; image processing; optical engineering; optical filters","Computer vision; Feature extraction; Filtration; FORTH (programming language); Image processing; Optical data processing; Optical engineering; Optical filters; Double line; Dynamic mode decompositions; Edge detection methods; Feature extraction methods; Gradient operators; Image edge detection; Oil paintings; Sparse features; Edge detection",2-s2.0-85032457826
"Ragkhitwetsagul C., Krinke J., Clark D.","A comparison of code similarity analysers",2017,"Empirical Software Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032177107&doi=10.1007%2fs10664-017-9564-7&partnerID=40&md5=5aa10eb650e19bda3f23f49699bd67ab","Copying and pasting of source code is a common activity in software engineering. Often, the code is not copied as it is and it may be modified for various purposes; e.g. refactoring, bug fixing, or even software plagiarism. These code modifications could affect the performance of code similarity analysers including code clone and plagiarism detectors to some certain degree. We are interested in two types of code modification in this study: pervasive modifications, i.e. transformations that may have a global effect, and local modifications, i.e. code changes that are contained in a single method or code block. We evaluate 30 code similarity detection techniques and tools using five experimental scenarios for Java source code. These are (1) pervasively modified code, created with tools for source code and bytecode obfuscation, and boiler-plate code, (2) source code normalisation through compilation and decompilation using different decompilers, (3) reuse of optimal configurations over different data sets, (4) tool evaluation using ranked-based measures, and (5) local + global code modifications. Our experimental results show that in the presence of pervasive modifications, some of the general textual similarity measures can offer similar performance to specialised code similarity tools, whilst in the presence of boiler-plate code, highly specialised source code similarity detection techniques and tools outperform textual similarity measures. Our study strongly validates the use of compilation/decompilation as a normalisation technique. Its use reduced false classifications to zero for three of the tools. Moreover, we demonstrate that optimal configurations are very sensitive to a specific data set. After directly applying optimal configurations derived from one data set to another, the tools perform poorly on the new data set. The code similarity analysers are thoroughly evaluated not only based on several well-known pair-based and query-based error measures but also on each specific type of pervasive code modification. This broad, thorough study is the largest in existence and potentially an invaluable guide for future users of similarity detection in source code. © 2017 The Author(s)","Clone detection; Code similarity measurement; Empirical study; Parameter optimisation; Plagiarism detection","Boilers; Cloning; Codes (symbols); Computer programming languages; Intellectual property; Software engineering; Clone detection; Code similarities; Empirical studies; Parameter optimisation; Plagiarism detection; Optimal systems",2-s2.0-85032177107
"Petrovic G., Fujita H.","SpringBoard: game-agnostic tool for scenario editing with meta-programming support",2017,"Applied Intelligence",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031911273&doi=10.1007%2fs10489-017-1069-y&partnerID=40&md5=598e354314fc0bab8a47048372be0de0","Although we have recently seen an increase of good, free game engine editors, general purpose scenario (level) editors are still lagging behind in terms of functionalities and ease of use. Using them to create game scenarios can be difficult as they often expose general engine capabilities instead of limiting the toolset to fit game-specific requirements. They often require programming skills to use, which introduce additional user skill requirements, and configuring them for a specific game can be equally difficult. In this paper we have developed SpringBoard, an open source scenario editor for games using the SpringRTS engine. Extending it to support game and level requirements is achieved with multi-level meta-programming, while still providing a system that is integrated with the GUI editor and therefore intuitive to use. Our meta-programming system has support for trigger elements (events, functions and actions), custom (composite) data types, scoped data access, higher order functions and actions, and data synchronization mechanics. This novel approach allows us to have the full expressiveness of the underlying programming language, while exposing a user-friendly GUI that consists of terminology familiar to the domain expert. © 2017 Springer Science+Business Media, LLC","Game creation tool; Level editor; Meta-programming; Scenario editor","Graphical user interfaces; Data synchronization; Domain experts; Higher order functions; Level editor; Meta Programming; Programming skills; Scenario editors; Skill requirements; Open source software",2-s2.0-85031911273
"Pint B.A., Unocic K.A., Brese R.G., Keiser J.R.","Characterization of chromia scales formed in supercritical carbon dioxide",2017,"Materials at High Temperatures",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032006244&doi=10.1080%2f09603409.2017.1389371&partnerID=40&md5=e28508529b73bf447bc212e3e60f5907","Initial experimental work at 700°–800 °C is in progress to develop a lifetime model for supercritical CO2 (sCO2) compatibility for a 30-year lifetime of a &gt;700 °C concentrated solar power system. Nickel-based alloys 282, 740H and 625 and Fe-based alloy 25 are being evaluated in 500-h cycles at 1 and 300 bar, and 10-h cycles in 1 bar industrial grade CO2. The alloys showed similar low rates of oxidation in 1 and 300 bar CO2 in 500-h cycles at 750 °C. However, in 10-h cycles, alloy 25 showed accelerated attack at 700° and 750 °C. Transmission electron microscopy scale cross-sections on alloy 25 after 1000 h at 700 °C in sCO2 and in air only showed a small row of carbides beneath the scale in the former environment. Similar characterisation was performed on alloys 625 and 282 after sCO2 exposure at 750 °C. © 2017 Informa UK Limited, trading as Taylor & Francis Group","high temperature oxidation; scanning transmission electron microscopy; Supercritical carbon dioxide","Carbides; Carbon dioxide; Electron microscopy; High resolution transmission electron microscopy; Iron alloys; Nickel alloys; Scanning electron microscopy; Solar energy; Supercritical fluid extraction; Thermooxidation; Transmission electron microscopy; Chromia scale; Concentrated solar power; Fe-based alloys; Lifetime models; Nickel based alloy; Scanning transmission electron microscopy; Supercritical carbon dioxides; Supercritical CO2; C (programming language)",2-s2.0-85032006244
"Lin C., Prasad M., Chung C., Puthal D., El-Sayed H., Sankar S., Wang Y., Singh J., Sangaiah A.K.","IoT-based Wireless Polysomnography Intelligent System for Sleep Monitoring",2017,"IEEE Access",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032435870&doi=10.1109%2fACCESS.2017.2765702&partnerID=40&md5=fa7c24f3d21a99fceb1a691db8a067fa","Polysomnography (PSG) is considered the gold standard in the diagnosis of obstructive sleep apnea (OSA). The diagnosis of OSA requires an overnight sleep experiment in a laboratory. However, due to limitations in relation to the number of labs and beds available, patients often need to wait a long time before being diagnosed and eventually treated. In addition, the unfamiliar environment and restricted mobility when a patient is being tested with a polysomnogram (PSG) may disturb their sleep, resulting in an incomplete or corrupted test. Therefore, it is posed that a PSG conducted in the patient&#x2019;s home would be more reliable and convenient. The Internet of Things (IoT) plays a vital role in the e-Health system. In this paper, we implement an IoT-based wireless polysomnography system for sleep monitoring, which utilizes a battery-powered, miniature, wireless, portable, and multipurpose recorder. A Java-based PSG recording program in the personal computer is designed to save several bio-signals and transfer them into the European Data Format. These PSG records can be used to determine a patient&#x2019;s sleep stages and diagnose OSA. This system is portable, lightweight, and has low power-consumption. To demonstrate the feasibility of the proposed PSG system, a comparison was made between the standard PSG-Alice 5&#x00AE; Diagnostic Sleep System and the proposed system. Several healthy volunteer patients participated in the PSG experiment and were monitored by both the standard PSG-Alice 5&#x00AE; Diagnostic Sleep System and the proposed system simultaneously, under the supervision of specialists at the Sleep Laboratory in Taipei Veteran General Hospital. A comparison of the results of the time-domain waveform and sleep stage of the two systems shows that the proposed system is reliable and can be applied in practice. The proposed system can facilitate the long-term tracing and research of personal sleep monitoring at home. OAPA","Biomedical monitoring; Internet of Things; JAVA; Monitoring; Polysomnography (PSG); Sleep apnea; sleep monitoring; Software; Standards; wireless; Wireless communication","Computer software; Diagnosis; Intelligent systems; Internet of things; Java programming language; Monitoring; Patient treatment; Personal computers; Radio; Standards; Wireless telecommunication systems; Biomedical monitoring; JAVA; Polysomnography; Sleep apnea; Sleep monitoring; Wireless communications; Sleep research",2-s2.0-85032435870
"Palmer C., Usman Z., Canciglieri Junior O., Malucelli A., Young R.I.M.","Interoperable manufacturing knowledge systems",2017,"International Journal of Production Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032027056&doi=10.1080%2f00207543.2017.1391416&partnerID=40&md5=bdbe5f77ad01f8e032ba7ec87bdc878f","For many years now, the importance of semantic technologies, that provide a formal, logic-based route to sharing meaning, has been recognised as offering the potential to support interoperability across multiple-related applications and hence, drive manufacturing competitiveness in the digital manufacturing age. However, progress in support of manufacturing enterprise interoperability has tended to be limited to fairly narrow domains of applicability. This paper presents a progression of research and understanding, culminating in the work undertaken in the recent EU FLEXINET project, to develop a comprehensive manufacturing reference ontology that can (a) support the clarification of understanding across domains, (b) support the ability to flexibly share information across interacting software systems and (c) provide the ability to readily configure company knowledge bases to support interoperable manufacturing systems. © 2017 Informa UK Limited, trading as Taylor & Francis Group","decision support; interoperability; knowledge sharing; manufacturing systems; reference ontologies","C (programming language); Decision support systems; Industrial research; Manufacture; Ontology; Semantics; Decision supports; Digital manufacturing; Drive manufacturing; Interacting softwares; Knowledge-sharing; Manufacturing enterprise; Manufacturing knowledge; Semantic technologies; Interoperability",2-s2.0-85032027056
"Brucato M., Abouzied A., Meliou A.","Package queries: efficient and scalable computation of high-order constraints",2017,"VLDB Journal",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032029590&doi=10.1007%2fs00778-017-0483-4&partnerID=40&md5=2f80410ba79d387a426b1237ad86f85a","Traditional database queries follow a simple model: they define constraints that each tuple in the result must satisfy. This model is computationally efficient, as the database system can evaluate the query conditions on each tuple individually. However, many practical, real-world problems require a collection of result tuples to satisfy constraints collectively, rather than individually. In this paper, we present package queries, a new query model that extends traditional database queries to handle complex constraints and preferences over answer sets. We develop a full-fledged package query system, implemented on top of a traditional database engine. Our work makes several contributions. (1) We design PaQL, a SQL-based query language that supports the declarative specification of package queries. We prove that PaQL is at least as expressive as integer linear programming, and therefore, evaluation of package queries is NP-hard. (2) We present a fundamental evaluation strategy that combines the capabilities of databases and constraint optimization solvers to derive solutions to package queries. The core of our approach is a set of translation rules that transform a package query to an integer linear program. (3) We introduce an offline data partitioning strategy allowing query evaluation to scale to large data sizes. (4) We introduce SketchRefine, a scalable algorithm for package evaluation, with strong approximation guarantees [(Formula presented.)-factor approximation]. (5) We present a method for parallelizing the Refine phase of SketchRefine. (6) We present an empirical study of the efficiency gains of providing integer solvers with starting solutions. (7) We present extensive experiments over real-world and benchmark data. The results demonstrate that our methods are effective at deriving high-quality package results and achieve runtime performance that is an order of magnitude faster than directly using ILP solvers over large datasets. © 2017 Springer-Verlag GmbH Germany","Approximation algorithm; Integer linear programming; Package queries; PaQL; SketchRefine","Approximation algorithms; Constrained optimization; Integer programming; Mathematical transformations; Optimization; Program translators; Query languages; Computationally efficient; Constraint optimizations; Evaluation strategies; Integer Linear Programming; Integer linear programs; PaQL; SketchRefine; Strong approximation; Query processing",2-s2.0-85032029590
"Orsini F., Frasconi P., de Raedt L.","kProbLog: an algebraic Prolog for machine learning",2017,"Machine Learning",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031919664&doi=10.1007%2fs10994-017-5668-y&partnerID=40&md5=a9ffc5472db86f93d2ccf0a731dcfd8e","We introduce kProbLog as a declarative logical language for machine learning. kProbLog is a simple algebraic extension of Prolog with facts and rules annotated by semi-ring labels. It allows to elegantly combine algebraic expressions with logic programs. We introduce the semantics of kProbLog, its inference algorithm, its implementation and provide convergence guarantees. We provide several code examples to illustrate its potential for a wide range of machine learning techniques. In particular, we show the encodings of state-of-the-art graph kernels such as Weisfeiler-Lehman graph kernels, propagation kernels and an instance of graph invariant kernels, a recent framework for graph kernels with continuous attributes. However, kProbLog is not limited to kernel methods and it can concisely express declarative formulations of tensor-based algorithms such as matrix factorization and energy-based models, and it can exploit semirings of dual numbers to perform algorithmic differentiation. Furthermore, experiments show that kProbLog is not only of theoretical interest, but can also be applied to real-world datasets. At the technical level, kProbLog extends aProbLog (an algebraic Prolog) by allowing multiple semirings to coexist in a single program and by introducing meta-functions for manipulating algebraic values. © 2017 The Author(s)","Algebraic Prolog; Graph kernels; Kernel programming; Machine learning","Algebra; Artificial intelligence; Factorization; Inference engines; Learning systems; Logic programming; Semantics; Algebraic expression; Algebraic Prolog; Algorithmic differentiations; Continuous attribute; Graph kernels; Machine learning techniques; Matrix factorizations; Real-world datasets; PROLOG (programming language)",2-s2.0-85031919664
"Margheri A., Masi M., Pugliese R., Tiezzi F.","A Rigorous Framework for Specification, Analysis and Enforcement of Access Control Policies",2017,"IEEE Transactions on Software Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032443846&doi=10.1109%2fTSE.2017.2765640&partnerID=40&md5=4cb03c685668af80a95088b3c9a507a9","Access control systems are widely used means for the protection of computing systems. They are defined in terms of access control policies regulating the access to system resources. In this paper, we introduce a formally-defined, fully-implemented framework for specification, analysis and enforcement of attribute-based access control policies. The framework rests on FACPL, a language with a compact, yet expressive, syntax for specification of real-world access control policies and with a rigorously defined denotational semantics. The framework enables the automated verification of properties regarding both the authorisations enforced by single policies and the relationships among multiple policies. Effectiveness and performance of the analysis rely on a semantic-preserving representation of FACPL policies in terms of SMT formulae and on the use of efficient SMT solvers. Our analysis approach explicitly addresses some crucial aspects of policy evaluation, such as missing attributes, erroneous values and obligations, which are instead overlooked in other proposals. The framework is supported by Java-based tools, among which an Eclipse-based IDE offering a tailored development and analysis environment for FACPL policies and a Java library for policy enforcement. We illustrate the framework and its formal ingredients by means of an e-Health case study, while its effectiveness is assessed by means of performance stress tests and experiments on a well-established benchmark. IEEE","Attribute-based Access Control; Authorization; Java; Policy Analysis; Policy Languages; Proposals; Semantics; SMT; Syntactics; Tools","Benchmarking; Distributed computer systems; Java programming language; Network function virtualization; Semantics; Specifications; Surface mount technology; Syntactics; Tools; Attribute based access control; Authorization; Java; Policy analysis; Policy language; Proposals; Access control",2-s2.0-85032443846
"Tavakkoli A., Thomas D.B.","A High-Level Design Framework for the Automatic Generation of High-Throughput Systolic Binomial-Tree Solvers",2017,"IEEE Transactions on Very Large Scale Integration (VLSI) Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032451995&doi=10.1109%2fTVLSI.2017.2761554&partnerID=40&md5=084cf263054c7a473cfc06c4017a27dc","The binomial-tree model is a numerical method widely used in finance with a computational complexity which is quadratic with respect to the solution accuracy. The existing research has employed reconfigurable computing to provide faster solutions compared with general-purpose processors, but they require low-level manual design by a hardware engineer, and can only solve American options. This paper presents a formal mathematical framework that captures a large class of binomial-tree problems, and provides a systolic data-movement template that maps the framework into digital hardware. This paper also presents a fully automated design flow, which takes C-level user descriptions of binomial trees, with custom data types and tree operations, and automatically generates fully pipelined reconfigurable hardware solutions in field-programmable gate array (FPGA) bit-stream files. On a Xilinx Virtex-7 xc7vx980t FPGA at a 100-MHz clock frequency, we require 54-&#x03BC;s latency to solve three 876-step 32-bit fixed-point American option binomial trees, with a pricing rate of 114k trees/s. From the same device and in comparison to the existing solutions with equivalent FPGA technology, we always achieve better throughput. This ranges from 1.4$x$ throughput compared with a hand-tuned register-transfer level systolic design, to 9.1$x$ and 5.6$x$ improvement with respect to scalar and vector architectures, respectively. IEEE","Binomial-tree numerical method; Computational modeling; Field programmable gate arrays; field-programmable gate arrays (FPGAs); Hardware; hardware design automation; high-level synthesis (HLS); Mathematical model; Numerical models; option pricing; Parallel processing; Pricing; reconfigurable hardware accelerators; systolic arrays.","Bins; C (programming language); Computer aided design; Computer hardware; Computer hardware description languages; Costs; Economics; Electronic trading; Field programmable gate arrays (FPGA); Forestry; General purpose computers; Hardware; High level synthesis; Integrated circuit design; Logic gates; Mathematical models; Multiprocessing systems; Numerical methods; Numerical models; Reconfigurable architectures; Signal receivers; Systolic arrays; Throughput; Trees (mathematics); Binomial tree; Computational model; Hardware design; Option pricing; Parallel processing; Reconfigurable hardware",2-s2.0-85032451995
"Jiang C., Jin X.","Quick Way to Port Existing C/C++ Chemoinformatics Toolkits to the Web Using Emscripten",2017,"Journal of Chemical Information and Modeling",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032018540&doi=10.1021%2facs.jcim.7b00434&partnerID=40&md5=882ce64e29824a86495aaf16638da4dd","Emscripten is a special open source compiler that compiles C and C++ code into JavaScript. By utilizing this compiler, some typical C/C++ chemoinformatics toolkits and libraries are quickly ported to to web. The compiled JavaScript files have sizes similar to native programs, and from a series of constructed benchmarks, the performance of the compiled JavaScript codes is also close to that of the native codes and is better than the handwritten JavaScript codes. Therefore, we believe that Emscripten is a feasible and practical tool for reusing existing C/C++ codes on the web, and many other chemoinformatics or molecular calculation software tools can also be easily ported by Emscripten. © 2017 American Chemical Society.",,"Benchmarking; Codes (symbols); High level languages; Open source software; Open systems; Program compilers; C++ codes; Chemoinformatics; Javascript; Molecular calculations; Native code; Open sources; C++ (programming language)",2-s2.0-85032018540
"Gong Y., Chung C., Mall R.S.","Power System Operational Adequacy Evaluation with Wind Power Ramp Limits",2017,"IEEE Transactions on Power Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032453771&doi=10.1109%2fTPWRS.2017.2764420&partnerID=40&md5=d840c3b3effdb5fcad7bc3087a679b4d","Uncertainties associated with wind power integration challenge the operational adequacy of conventional power systems. A set of wind power ramp limits (WPRLs) is proposed in this paper to evaluate the operational adequacy of power systems and to provide operating references to wind farms in the form of a ramp power limit (RPL) and ramp rate limit (RRL). The RPL is used to evaluate the minimum and maximum allowable generation of a wind farm by considering the power reserve capacities of generators and power flow constraints. A robust second-order cone programing (SOCP) RPLs formulation with AC power flow constraints and a column-and-constraint generation (C&amp;CG) based solution method are proposed to maximize the total operating range of all wind farms. Meanwhile, a Pareto optimality-based RPLs evaluation approach is proposed to handle the coupled relationship among the operating ranges of the wind farms to achieve a balanced RPLs solution for each wind farm. The RRL is used to evaluate the most rapid wind power ramp behavior that can be handled by system frequency regulation without exceeding the designated frequency range. A comprehensive criterion is proposed to evaluate the RRLs by considering primary and secondary frequency regulation. Finally, the effectiveness of the proposed evaluation approach is verified through case studies IEEE","Adequacy evaluation; Frequency control; Generators; Load flow; Pareto optimality; ramp power limit (RPL); ramp rate limit (RRL); Robustness; Wind farms; Wind power generation; wind power ramp limits (WPRLs)","C (programming language); Electric frequency control; Electric load flow; Electric power generation; Electric utilities; Gas generators; Pareto principle; Ramp generators; Robustness (control systems); Wind power; Adequacy evaluation; Load flow; Pareto-optimality; Power limit; Ramp rate limits; Wind farm; Electric power system interconnection",2-s2.0-85032453771
"Zhang P., Wang Y., Liu W.","The HSC machining mechanism for TC17 under multimedia mixed minimum quantity lubrication",2017,"International Journal of Advanced Manufacturing Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031932343&doi=10.1007%2fs00170-017-1084-5&partnerID=40&md5=1946d9ea84ac4cc51ee3424c86ebf6fc","This study is intended to fill up the deficiency of the high-speed cutting (HSC) machining mechanism for TC17 Ti alloy. In this study, as the study object, TC17 Ti alloy is placed in room temperature (20 °C), ultra-low temperature (− 60 °C), and ultra-high temperature (350 °C) for HSC experiment, respectively, both through single-medium minimum quantity lubrication (SMMQL) and oil-water minimum quantity lubrication (OWMQL). The experimental results show that the main cutting force decreases by 33% during oil-medium MQL to 50% during water-medium MQL as compared to machining during dry cutting at room temperature; the cutting force decreases by 25% at the low temperature to 55% at the high temperature as compared to machining during OWMQL at room temperature; the cutting roughness decreases by 27% at the low temperature to 43% at the high temperature as compared to machining during OWMQL at room temperature. In the temperature of − 60 °C, the abrasion of the cutter mainly shows thermal cracking and adhesive wear during dry cutting. The cutter mainly shows crater wear during SMMQL of water; the abrasion mainly shows boundary and notching wear during SMMQL of oil, and the cutter also presents self-repairing function. In the temperature of − 60 °C, cutting layer TC17 titanium alloy produced a large dislocation, chip form appears collapse broken chip during OWMQL. In room temperature, there are more coarse second-phase precipitated in the cutting layer metal, the chip form is cracked during OWMQL. In the temperature of 350 °C, the material properties of the TC17 titanium alloy of the cutting layer will be restored to the state after the solution treatment in a short time. A large amount of the diffuse phase disappears. At the same time, grain boundaries show excellent continuity, and the Guinier-Preston enrichment area formed in the grain boundary, and the chip form exhibits a crumb during OWMQL. © 2017 Springer-Verlag London Ltd.","Cutting force; Extreme environment; Minimum quantity lubrication (MQL); TC17 Ti alloy; Tool wear","Abrasion; C (programming language); Cracking (chemical); Cracks; Cutting; Grain boundaries; Lubrication; Metal cutting; Temperature; Titanium; Cutting forces; Extreme environment; Minimum quantity lubrication; Ti alloys; Tool wear; Cutting tools",2-s2.0-85031932343
"Cianfrini M., Corcione M., Quintino A., Ricci E.","A Demonstrative Study on the Two-phase vs. Single-phase Modeling of Buoyancy-driven Flows of Enclosed Nanofluids",2017,"Heat Transfer Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031994852&doi=10.1080%2f01457632.2017.1388900&partnerID=40&md5=1c558c9539df92853dd760cc0596b86c","A demonstrative numerical study on natural convection of water-based nanofluids in square enclosures with different boundary conditions imposed at the walls, and different orientations with respect to the gravity vector, is performed using both the single-phase and the two-phase approaches, with the main scope to evaluate in what measure the single-phase approach fails in describing the basic heat and fluid flow features, as well as in determining the thermal performance of nanofluids. The system of the mass, momentum and energy transfer governing equations is solved by way of a computational code based on the SIMPLE-C algorithm. Empirical correlations are used for the calculation of the effective thermal conductivity, the effective dynamic viscosity, and the thermophoretic diffusion coefficient. The following configurations are investigated: a tilted cavity differentially-heated at two opposite walls; a vertical cavity partially-heated at the bottom wall and cooled at both sides; and a vertical cavity differentially-heated at the vertical and horizontal walls. It is found that the non-uniform distribution of the suspended solid phase throughout the enclosure gives rise to a solutal buoyancy force, whose competition with the thermal buoyancy force results in a periodic flow detectable only if the two-phase approach is applied. Moreover, the impact of the dispersion of the nanoparticles into the base liquid, which turns out to be notably higher at higher average temperatures, is found to be systematically underestimated by the single-phase approach. © 2017 Taylor & Francis Group, LLC",,"Buoyancy; C (programming language); Enclosures; Energy transfer; Flow of fluids; Natural convection; Thermal conductivity; Buoyancy driven flows; Computational codes; Different boundary condition; Effective thermal conductivity; Empirical correlations; Governing equations; Non-uniform distribution; Thermal buoyancy force; Nanofluidics",2-s2.0-85031994852
"Xia C., Wang H., Zhang A., Zhang W.","A high-performance cellular automata model for urban simulation based on vectorization and parallel computing technology",2017,"International Journal of Geographical Information Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031790595&doi=10.1080%2f13658816.2017.1390118&partnerID=40&md5=eee7fd0594ed5dec57f48fadfe37d4fc","Cellular automata (CA) models can simulate complex urban systems through simple rules and have become important tools for studying the spatio-temporal evolution of urban land use. However, the multiple and large-volume data layers, massive geospatial processing and complicated algorithms for automatic calibration in the urban CA models require a high level of computational capability. Unfortunately, the limited performance of sequential computation on a single computing unit (i.e. a central processing unit (CPU) or a graphics processing unit (GPU)) and the high cost of parallel design and programming make it difficult to establish a high-performance urban CA model. As a result of its powerful computational ability and scalability, the vectorization paradigm is becoming increasingly important and has received wide attention with regard to this kind of computational problem. This paper presents a high-performance CA model using vectorization and parallel computing technology for the computation-intensive and data-intensive geospatial processing in urban simulation. To transfer the original algorithm to a vectorized algorithm, we define the neighborhood set of the cell space and improve the operation paradigm of neighborhood computation, transition probability calculation, and cell state transition. The experiments undertaken in this study demonstrate that the vectorized algorithm can greatly reduce the computation time, especially in the environment of a vector programming language, and it is possible to parallelize the algorithm as the data volume increases. The execution time for the simulation of 5-m resolution and 3 × 3 neighborhood decreased from 38,220.43 s to 803.36 s with the vectorized algorithm and was further shortened to 476.54 s by dividing the domain into four computing units. The experiments also indicated that the computational efficiency of the vectorized algorithm is closely related to the neighborhood size and configuration, as well as the shape of the research domain. We can conclude that the combination of vectorization and parallel computing technology can provide scalable solutions to significantly improve the applicability of urban CA. © 2017 Informa UK Limited, trading as Taylor & Francis Group","geographic simulation; parallel computing; Urban cellular automata; vectorization",,2-s2.0-85031790595
"Adeniyi D.A., Wei Z., Yang Y.","Personalised news filtering and recommendation system using Chi-square statistics-based K-nearest neighbour (χ2SB-KNN) model",2017,"Enterprise Information Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987927752&doi=10.1080%2f17517575.2016.1229500&partnerID=40&md5=3323efb2908261c569ec49807ef26a2f","Recommendation problem has been extensively studied by researchers in the field of data mining, database and information retrieval. This study presents the design and realisation of an automated, personalised news recommendations system based on Chi-square statistics-based K-nearest neighbour (χ2SB-KNN) model. The proposed χ2SB-KNN model has the potential to overcome computational complexity and information overloading problems, reduces runtime and speeds up execution process through the use of critical value of χ2 distribution. The proposed recommendation engine can alleviate scalability challenges through combined online pattern discovery and pattern matching for real-time recommendations. This work also showcases the development of a novel method of feature selection referred to as Data Discretisation-Based feature selection method. This is used for selecting the best features for the proposed χ2SB-KNN algorithm at the preprocessing stage of the classification procedures. The implementation of the proposed χ2SB-KNN model is achieved through the use of a developed in-house Java program on an experimental website called OUC newsreaders’ website. Finally, we compared the performance of our system with two baseline methods which are traditional Euclidean distance K-nearest neighbour and Naive Bayesian techniques. The result shows a significant improvement of our method over the baseline methods studied. © 2016 Informa UK Limited, trading as Taylor & Francis Group.","Chi square; data discretisation; in-house java program; online; real-time; recommendation","Computer software; Data mining; Java programming language; Nearest neighbor search; Pattern matching; Websites; Chi square; Data discretisation; Java program; online; Real time; recommendation; Recommender systems",2-s2.0-84987927752
"Nikpaik A., Masnadi Shirazi A.H., Nabavi A., Mirabbasi S., Shekhar S.","A 219-to-231GHz Frequency-Multiplier-Based VCO With ~ 3&#x0025; Peak DC-to-RF Efficiency in 65-nm CMOS",2017,"IEEE Journal of Solid-State Circuits",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032458649&doi=10.1109%2fJSSC.2017.2759116&partnerID=40&md5=04567fb8daf85dfc06377a9d682b482b","Signal sources at mm-wave and (sub-)terahertz frequencies in CMOS can be classified into two broad categories: harmonic oscillators and oscillators that are based on the frequency multiplication of fundamental sources. This paper shows that frequency-multiplier-based sources potentially have a higher dc-to-radio frequency (RF) efficiency than do the popular harmonic oscillators in 65-nm CMOS. To improve the power efficiency of CMOS signal sources that operate near or above the cutoff frequency of the device, design factors including the harmonic current efficiency, the effective output conductance, and the passive losses should be carefully tailored. An architecture is proposed in which: 1) the core voltage-controlled oscillator is optimized to efficiently generate a strong fundamental harmonic; 2) separate class-C frequency doublers are utilized to decouple fundamental signal generation and harmonic extraction and to reduce conductance loss; and 3) doubler circuits are separately optimized to simplify the output matching and power combining network, and hence avoid long and lossy transmission lines. A circuit prototype shows a measured peak output power and dc-to-RF efficiency of 3 dBm and 2.95&#x0025;, respectively. IEEE","Coupled oscillators; frequency multiplier; Harmonic analysis; harmonic extraction; harmonic oscillator; Logic gates; mm-wave; Optimized production technology; Oscillators; Power generation; Power system harmonics; terahertz.; Transistors","C (programming language); Circuit oscillations; CMOS integrated circuits; Cutoff frequency; Efficiency; Extraction; Harmonic analysis; Logic gates; Millimeter waves; Oscillators (electronic); Oscillators (mechanical); Oscillistors; Power generation; Terahertz waves; Transistors; Variable frequency oscillators; Coupled oscillators; Frequency multiplier; Harmonic extraction; Harmonic oscillators; Mm waves; Optimized production technology; Power system harmonics; Tera Hertz; Frequency multiplying circuits",2-s2.0-85032458649
"Razavi S.M.A., Alghooneh A., Behrouzian F.","Influence of temperature on sage seed gum (Salvia macrosiphon) rheology in dilute and concentrated regimes",2017,"Journal of Dispersion Science and Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031905541&doi=10.1080%2f01932691.2017.1379020&partnerID=40&md5=35d6a2985fd76adacc4c7f184b82ecaa","Herein, the influence of temperature (10°C, 30°C, 50°C, 70°C, and 90°C) on the dynamic (using amplitude sweep, frequency sweep, and temperature sweep tests), steady-shear, thixotropy (using hysteresis loop, single shear decay, and in-shear structural recovery tests), yield stress (static and dynamic yield stresses), and dilute solution (intrinsic viscosity ([η]), voluminosity (vs), shape factor (v), Berry number (C[η]), and chain flexibility) properties of sage seed gum (SSG) have been studied. In this way, the effect of type of thermal procedure (iso-thermal and non-isothermal), temperature program (temperature gradient and temperature profile sweeps), and the rate of thermal program (1, 5, and 10°C/min) on the structural changes during heating and cooling stages were also investigated. Furthermore, the time–temperature superposition and Cox–Merz rules were tested on dynamic and steady shear rheological data. © 2017 Taylor & Francis","Biopolymer; rheology; thermal properties; thixotropy; viscoelasticity","Biopolymers; Colloids; Elasticity; Rheology; Thermodynamic properties; Viscoelasticity; Yield stress; Chain flexibility; Concentrated regime; Heating and cooling; Intrinsic viscosity; Temperature profiles; Temperature superposition; Temperature sweeps; thixotropy; C (programming language)",2-s2.0-85031905541
"Pandey P., Kashyap S., Tiwary C.S., Chattopadhyay K.","Development of High-Strength High-Temperature Cast Al-Ni-Cr Alloys Through Evolution of a Novel Composite Eutectic Structure",2017,"Metallurgical and Materials Transactions A: Physical Metallurgy and Materials Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031944937&doi=10.1007%2fs11661-017-4369-2&partnerID=40&md5=dd21c42815e55cc585d9871225b70afd","Aiming to develop high-strength Al-based alloys with high material index (strength/density) for structural application, this article reports a new class of multiphase Al alloys in the Al-Ni-Cr system that possess impressive room temperature and elevated temperature (≥ 200 °C) mechanical properties. The ternary eutectic and near eutectic alloys display a complex microstructure containing intermetallic phases displaying hierarchically arranged plate and rod morphologies that exhibit extraordinary mechanical properties. The yield strengths achieved at room temperatures are in excess of 350 MPa with compressive plastic strains of more than 30 pct (without fracturing) for these alloys. The stability of the complex microstructure also leads to a yield stress of 191 ± 8 to 232 ± 5 MPa at 250 °C. It is argued that the alloys derive their high strength and impressive plasticity through synergic effects of refined nanoeutectics of two different morphologies forming a core shell type of architecture. © 2017 The Minerals, Metals & Materials Society and ASM International",,"Alloys; Aluminum; Aluminum alloys; C (programming language); Eutectics; High strength alloys; Mechanical properties; Microstructure; Nickel; Nickel alloys; Ternary alloys; Yield stress; Complex microstructures; Compressive plastic strain; Elevated temperature; Eutectic structures; Intermetallic phasis; Structural applications; Synergic effects; Ternary eutectics; Chromium alloys",2-s2.0-85031944937
"Li M., Liang M., Du B., Chen J.","A construction for optimal c-splitting authentication and secrecy codes",2017,"Designs, Codes, and Cryptography",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031812945&doi=10.1007%2fs10623-017-0421-x&partnerID=40&md5=0db85f1331ae241577a3e4bbccd4e0a0","Authentication and secrecy codes which provide both secrecy and authentication have been intensively studied in the case where there is no splitting; however the results concerning the case where there is splitting are far fewer. In this paper, we focus on the case with c-splitting, and obtain a bound on the number of encoding rules required in order to obtain maximum levels of security. A c-splitting authentication and secrecy code is called optimal if it obtains maximum levels of security and has the minimum number of encoding rules. We define a new design, called an authentication perpendicular multi-array, and prove that the existence of authentication perpendicular multi-arrays implies the existence of optimal c-splitting authentication and secrecy codes. Further, we study the constructions and existence of authentication perpendicular multi-arrays, and then obtain two new infinite classes of optimal c-splitting authentication and secrecy codes. © 2017 Springer Science+Business Media, LLC","Authentication and secrecy codes; Group divisible splitting t-designs; Splitting authentication codes; Splitting t-designs","Authentication; Codes (symbols); Encoding (symbols); Optimal systems; Signal encoding; Encoding rules; Maximum levels; Multi arrays; Splitting authentication code; T-designs; C (programming language)",2-s2.0-85031812945
"Gonçalves R., Areias M., Rocha R.","On the implementation of a cloud-based computing test bench environment for prolog systems",2017,"Information (Switzerland)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032508286&doi=10.3390%2finfo8040129&partnerID=40&md5=b2d018f63bfb7325733535f98d38de65","Software testing and benchmarking are key components of the software development process. Nowadays, a good practice in large software projects is the continuous integration (CI) software development technique. The key idea of CI is to let developers integrate their work as they produce it, instead of performing the integration at the end of each software module. In this paper, we extend a previous work on a benchmark suite for the YAP Prolog system, and we propose a fully automated test bench environment for Prolog systems, named Yet Another Prolog Test Bench Environment (YAPTBE), aimed to assist developers in the development and CI of Prolog systems. YAPTBE is based on a cloud computing architecture and relies on the Jenkins framework as well as a new Jenkins plugin to manage the underlying infrastructure. We present the key design and implementation aspects of YAPTBE and show its most important features, such as its graphical user interface (GUI) and the automated process that builds and runs Prolog systems and benchmarks. © 2017 by the authors.","Benchmarking; Program correctness; Prolog; Software engineering","Automation; Benchmarking; Computer architecture; Distributed computer systems; Graphical user interfaces; Software design; Software engineering; Software testing; User interfaces; Cloud computing architectures; Continuous integrations; Design and implementations; Graphical user interfaces (GUI); Program correctness; Prolog; Software development process; Software development techniques; PROLOG (programming language)",2-s2.0-85032508286
"Zacharewicz M., Kniaziewicz T.","Modelling of the operating process in a marine diesel engine",2017,"Journal of Marine Engineering and Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031808224&doi=10.1080%2f20464177.2017.1389516&partnerID=40&md5=ba3b536fdfdff329a3e6d5fcf835a283","The paper presents elements of a mathematical model of a marine diesel engine. The purpose of developing the model is to enable diagnostics of fuel supply and charge exchange system in a marine engine (simulation diagnostics). The authors have assumed the option allowing to modify geometric parameters of the crank-piston system, charge exchange, heat exchange and chemical composition of fuel. This option offers simulation of selected defects in an engine. The focus of the paper is both the process of model development and its implementation in an object-oriented programming language. Abbreviations: C: number of working cycles; c: specific heat; D: diameter; d: accuracy of calculations performed; i: iteration; j: value corresponding to subsequent working cycles; k: number of strokes; l: crankshaft length/air demand; m: mass; m: mass stream; n: number of cylinders; p: pressure; (Formula presented.): heat stream; R: individual gas constant; r: length of crank arm; S: cross-section area; T: temperature; W: calorific value; w: flow velocity; V: volume; x: linear dimension; α: rotation angle; ρ: density; κ: adiabatic exponent; λ: air excess factor; μ: inflow/outflow factor; τ: time; cyl: refers to ‘cylinder’; chł: refers to ‘cooling’; ks: refers ‘combustion chamber’; max: refers to maximum value; o: refers to ‘theoretical air demand’; pal: refers to ‘fuel’; z: refers to ‘cylinder supply’; zaw: refers to ‘valves’; r: refers ‘real air demand’ © 2017 Institute of Marine Engineering, Science & Technology",,"Air; Charge transfer; Combustion chambers; Crankshafts; Engines; Flow velocity; Fuels; Iterative methods; Marine engines; Object oriented programming; Specific heat; Charge exchanges; Chemical compositions; Cross-section area; Linear dimensions; Marine Diesel Engines; Model development; Operating process; Rotation angles; Diesel engines",2-s2.0-85031808224
"Čehovin L.","TraX: The visual Tracking eXchange protocol and library",2017,"Neurocomputing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014040382&doi=10.1016%2fj.neucom.2017.02.036&partnerID=40&md5=2a98f2428f102b73c6e88d288820f41f","In this paper we address the problem of developing on-line visual tracking algorithms. We present a specialized communication protocol that serves as a bridge between a tracker implementation and utilizing application. It decouples development of algorithms and application, encouraging re-usability. The primary use case is algorithm evaluation where the protocol facilitates more complex evaluation scenarios that are used nowadays thus pushing forward the field of visual tracking. We present a reference implementation of the protocol that makes it easy to use in several popular programming languages and discuss where the protocol is already used and some usage scenarios that we envision for the future. © 2017 Elsevier B.V.","Algorithm analysis; Communication protocol; Computer vision; Performance evaluation; Software library; Visual tracking","Computer applications; Computer vision; Network protocols; Neural networks; Algorithm analysis; Algorithm evaluation; Complex evaluations; Performance evaluation; Reference implementation; Software libraries; Visual Tracking; Visual tracking algorithm; Tracking (position); algorithm; Article; communication protocol; computer language; eye tracking; online system; priority journal; visual field",2-s2.0-85014040382
"Hazan H., Ziv N.E.","Closed loop Experiment Manager (CLEM)-An open and inexpensive solution for multichannel electrophysiological recordings and closed loop experiments",2017,"Frontiers in Neuroscience",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032034444&doi=10.3389%2ffnins.2017.00579&partnerID=40&md5=dac5ea524d01242d586d945eb4b9bb06","There is growing need for multichannel electrophysiological systems that record from and interact with neuronal systems in near real-time. Such systems are needed, for example, for closed loop, multichannel electrophysiological/optogenetic experimentation in vivo and in a variety of other neuronal preparations, or for developing and testing neuro-prosthetic devices, to name a few. Furthermore, there is a need for such systems to be inexpensive, reliable, user friendly, easy to set-up, open and expandable, and possess long life cycles in face of rapidly changing computing environments. Finally, they should provide powerful, yet reasonably easy to implement facilities for developing closed-loop protocols for interacting with neuronal systems. Here, we survey commercial and open source systems that address these needs to varying degrees. We then present our own solution, which we refer to as Closed Loop Experiments Manager (CLEM). CLEM is an open source, soft real-time, Microsoft Windows desktop application that is based on a single generic personal computer (PC) and an inexpensive, general-purpose data acquisition board. CLEM provides a fully functional, user-friendly graphical interface, possesses facilities for recording, presenting and logging electrophysiological data from up to 64 analog channels, and facilities for controlling external devices, such as stimulators, through digital and analog interfaces. Importantly, it includes facilities for running closed-loop protocols written in any programming language that can generate dynamic link libraries (DLLs). We describe the application, its architecture and facilities. We then demonstrate, using networks of cortical neurons growing on multielectrode arrays (MEA) that despite its reliance on generic hardware, its performance is appropriate for flexible, closed-loop experimentation at the neuronal network level. © 2017 Hazan and Ziv.","Closed-loop system; Electrophysiology; Multielectrode array; Network dynamics; Software","animal cell; animal tissue; Article; automation; brain cell; brain cortex; cell growth; Closed Loop Experiment Manager; computer language; controlled study; database management system; electrophysiological procedures; electrophysiology; nerve cell network; nonhuman; rat",2-s2.0-85032034444
"OETSCH J., PÜHRER J., TOMPITS H.","Stepwise debugging of answer-set programs*",2017,"Theory and Practice of Logic Programming",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032199819&doi=10.1017%2fS1471068417000217&partnerID=40&md5=5dd7d37f8e77ff8940e65a75b35f9c4b","We introduce a stepping methodology for answer-set programming (ASP) that allows for debugging answer-set programs and is based on the stepwise application of rules. Similar to debugging in imperative languages, where the behaviour of a program is observed during a step-by-step execution, stepping for ASP allows for observing the effects that rule applications have in the computation of an answer set. While the approach is inspired from debugging in imperative programming, it is conceptually different to stepping in other paradigms due to non-determinism and declarativity that are inherent to ASP. In particular, unlike statements in an imperative program that are executed following a strict control flow, there is no predetermined order in which to consider rules in ASP during a computation. In our approach, the user is free to decide which rule to consider active in the next step following his or her intuition. This way, one can focus on interesting parts of the debugging search space. Bugs are detected during stepping by revealing differences between the actual semantics of the program and the expectations of the user. As a solid formal basis for stepping, we develop a framework of computations for answer-set programs. For fully supporting different solver languages, we build our framework on an abstract ASP language that is sufficiently general to capture different solver languages. To this end, we make use of abstract constraints as an established abstraction for popular language constructs such as aggregates. Stepping has been implemented in SeaLion, an integrated development environment for ASP. We illustrate stepping using an example scenario and discuss the stepping plugin of SeaLion. Moreover, we elaborate on methodological aspects and the embedding of stepping in the ASP development process. Copyright © Cambridge University Press 2017","answer-set programming; debugging; program analysis; stepping","Application programs; Computer debugging; Computer programming; Knowledge representation; Logic programming; Semantics; Answer set programming; Imperative languages; Imperative programming; Integrated development environment; Language constructs; Methodological aspects; Program analysis; stepping; Program debugging",2-s2.0-85032199819
"Chen S., Wang D., Du R., Feng D.","Elastic multilayered pavement under an elliptical vertical load: analytical solutions and program verification",2017,"Road Materials and Pavement Design",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031492214&doi=10.1080%2f14680629.2017.1385513&partnerID=40&md5=a9c19a3c9b7a252de78ff20b627a36f2","Since the linear elastic solution for multilayered systems was developed in the 1940s, it has been widely used to evaluate the soundness of pavement structure. The primary assumption in the analysis is that the load applied to the pavement structure is simplified as a cylindrical load. Hence application of the cylindrical load to the evaluation of pavement structure, which is well known to involve asymmetrical loading, has been limited. Therefore, the analytical solutions and program verification for an elastic multilayered system subjected to an elliptical vertical load (asymmetrical vertical load) are presented in this paper. A coefficient recursion method was obtained to derive the coefficients A, B, C, D, E, and F based on the general solutions of the asymmetrical class. The results show that coefficients E and F of an arbitrary layer are equal to zero for pavement structure under an asymmetrical vertical load. Then the asymmetrical vertical load was modelled as an elliptical vertical load by simulating the tyre ground pressure distribution. The analytical solutions were derived by substituting the Hankel-transformed load function into general solutions of the asymmetrical system. A C++ program (ASLAYER) was developed on the basis of the analytical solutions and verified by comparing the results with those of BISAR with the definitions (Formula presented.) and (Formula presented.). The results show that ASLAYER can be used to make reliable estimations for the response of pavement structure under an elliptical vertical load. The results of mechanical responses for pavement structure under an elliptical vertical load, compared with those subjected to cylindrical load, show that the asymmetrical vertical load causes more damage to the pavement structure and should be given greater attention. © 2017 Informa UK Limited, trading as Taylor & Francis Group","analytical solution; elasticity; elliptical vertical load; layered system","C++ (programming language); Computer software; Elasticity; Hankel functions; General solutions; Layered systems; Mechanical response; Multi-layered systems; Pavement structures; Program Verification; Recursion methods; Vertical load; Pavements",2-s2.0-85031492214
"Henry M.C., Mostafa M.A.B., Sutherland A.","Recent Advances in Transition-Metal-Catalyzed, Directed Aryl C-H/N-H Cross-Coupling Reactions",2017,"Synthesis (Germany)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028568283&doi=10.1055%2fs-0036-1588536&partnerID=40&md5=6456e33b680ece27499261a2b673333d","Amination and amidation of aryl compounds using a transition-metal-catalyzed cross-coupling reaction typically involves prefunctionalization or preoxidation of either partner. In recent years, a new class of transition-metal-catalyzed cross-dehydrogenative coupling reaction has been developed for the direct formation of aryl C-N bonds. This short review highlights the substantial progress made for ortho -C-N bond formation via transition-metal-catalyzed chelation-directed aryl C-H activation and gives an overview of the challenges that remain for directed meta - and para -selective reactions. 1 Introduction 2 Intramolecular C-N Cross-Dehydrogenative Coupling 2.1 Nitrogen Functionality as Both Coupling Partner and Directing Group 2.2 Chelating-Group-Directed Intramolecular C-N Bond Formation 3 Intermolecular C-N Cross-Dehydrogenative Coupling 3.1 ortho -C-N Bond Formation 3.1.1 Copper-Catalyzed Reactions 3.1.2 Other Transition-Metal-Catalyzed Reactions 3.2 meta - and para -C-N Bond Formation 4 C-N Cross-Dehydrogenative Coupling of Acidic C-H Bonds 5 Conclusions.","amides; amination; amines; cross-coupling; dehydrogenation; transition metals","Amides; Amination; Amines; Catalysis; Chelation; Chemical reactions; Dehydrogenation; Metals; Transition metals; Copper-catalyzed reactions; Cross coupling reactions; Cross dehydrogenative couplings; Cross-couplings; Metal-catalyzed cross-coupling reactions; Nitrogen functionalities; Prefunctionalization; Transition metal catalyzed reaction; C (programming language); acid; carbon; hydrogen; nitrogen; transition element; amination; catalysis; chelation; chemical bond; chemical reaction; cross coupling reaction; dehydrogenation; Review",2-s2.0-85028568283
"HoseinDoost S., Adamzadeh T., Zamani B., Fatemi A.","A model-driven framework for developing multi-agent systems in emergency response environments",2017,"Software and Systems Modeling",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031489970&doi=10.1007%2fs10270-017-0627-4&partnerID=40&md5=443c1cafd658af497641eec10908552b","In emergency response environments, variant entities with specific behaviors and interaction between them form a complex system that can be well modeled by multi-agent systems. To build such complex systems, instead of writing the code from scratch, one can follow the model-driven development approach, which aims to generate software from design models automatically. To achieve this goal, two important prerequisites are: a domain-specific modeling language for designing an emergency response environment model, and transformation programs for automatic code generation from a model. In addition, for modeling with the language, a modeling tool is required, and for executing the generated code there is a need to a platform. In this paper, a model-driven framework for developing multi-agent systems in emergency response environments is provided which includes several items. A domain-specific modeling language as well as a modeling tool is developed for this domain. The language and the tool are called ERE-ML and ERE-ML Tool, respectively. Using the ERE-ML Tool, a designer can model an emergency response situation and then validate the model against the predefined constraints. Furthermore, several model to code transformations are defined for automatic multi-agent system code generation from an emergency response environment model. For executing the generated code, an extension of JAMDER platform is also provided. To evaluate our framework, several case studies including the Victorian bushfire disaster are modeled to show the ability of the framework in modeling real-world situations and automatic transformation of the model into the code. © 2017 Springer-Verlag GmbH Germany","Domain-specific modeling language; Emergency response environment; ERE-ML; Model to code transformation; Model-driven development; Multi-agent system","Automatic programming; Codes (symbols); Computer simulation languages; Cosine transforms; Embedded systems; Emergency services; Large scale systems; Modeling languages; Network function virtualization; Specification languages; Systems analysis; Code transformation; Domain specific modeling languages; Emergency response; ERE-ML; Model driven development; Multi agent systems",2-s2.0-85031489970
"Siano G.G., Montemurro M., Alcaráz M.R., Goicoechea H.C.","Open-Source Assisted Laboratory Automation through Graphical User Interfaces and 3D Printers: Application to Equipment Hyphenation for Higher-Order Data Generation",2017,"Analytical Chemistry",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031397957&doi=10.1021%2facs.analchem.7b02758&partnerID=40&md5=0bfa714d5066be8725ad090e32de670a","Higher-order data generation implies some automation challenges, which are mainly related to the hidden programming languages and electronic details of the equipment. When techniques and/or equipment hyphenation are the key to obtaining higher-order data, the required simultaneous control of them demands funds for new hardware, software, and licenses, in addition to very skilled operators. In this work, we present Design of Inputs-Outputs with Sikuli (DIOS), a free and open-source code program that provides a general framework for the design of automated experimental procedures without prior knowledge of programming or electronics. Basically, instruments and devices are considered as nodes in a network, and every node is associated both with physical and virtual inputs and outputs. Virtual components, such as graphical user interfaces (GUIs) of equipment, are handled by means of image recognition tools provided by Sikuli scripting language, while handling of their physical counterparts is achieved using an adapted open-source three-dimensional (3D) printer. Two previously reported experiments of our research group, related to fluorescence matrices derived from kinetics and high-performance liquid chromatography, were adapted to be carried out in a more automated fashion. Satisfactory results, in terms of analytical performance, were obtained. Similarly, advantages derived from open-source tools assistance could be appreciated, mainly in terms of lesser intervention of operators and cost savings. (Figure Presented). © 2017 American Chemical Society.",,"3D printers; Automation; Computer programming; Equipment; Graphical user interfaces; High performance liquid chromatography; Image recognition; Liquid chromatography; Open systems; Printing machinery; Printing presses; User interfaces; Analytical performance; Experimental procedure; Graphical user interface (GUIs); Laboratory automation; Scripting languages; Simultaneous control; Threedimensional (3-d); Virtual components; Open source software",2-s2.0-85031397957
"CHAPMAN J., UUSTALU T., VELTRI N.","Quotienting the delay monad by weak bisimilarity",2017,"Mathematical Structures in Computer Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032199059&doi=10.1017%2fS0960129517000184&partnerID=40&md5=47a95257ed6c4c331e015c4f1ef7c26f","The delay datatype was introduced by Capretta (Logical Methods in Computer Science, 1(2), article 1, 2005) as a means to deal with partial functions (as in computability theory) in Martin-Löf type theory. The delay datatype is a monad. It is often desirable to consider two delayed computations equal, if they terminate with equal values, whenever one of them terminates. The equivalence relation underlying this identification is called weak bisimilarity. In type theory, one commonly replaces quotients with setoids. In this approach, the delay datatype quotiented by weak bisimilarity is still a monad–a constructive alternative to the maybe monad. In this paper, we consider the alternative approach of Hofmann (Extensional Constructs in Intensional Type Theory, Springer, London, 1997) of extending type theory with inductive-like quotient types. In this setting, it is difficult to define the intended monad multiplication for the quotiented datatype. We give a solution where we postulate some principles, crucially proposition extensionality and the (semi-classical) axiom of countable choice. With the aid of these principles, we also prove that the quotiented delay datatype delivers free ω-complete pointed partial orders (ωcppos). Altenkirch et al. (Lecture Notes in Computer Science, vol. 10203, Springer, Heidelberg, 534–549, 2017) demonstrated that, in homotopy type theory, a certain higher inductive–inductive type is the free ωcppo on a type X essentially by definition; this allowed them to obtain a monad of free ωcppos without recourse to a choice principle. We notice that, by a similar construction, a simpler ordinary higher inductive type gives the free countably complete join semilattice on the unit type 1. This type suffices for constructing a monad, which is isomorphic to the one of Altenkirch et al. We have fully formalized our results in the Agda dependently typed programming language. Copyright © Cambridge University Press 2017",,"Computer applications; Mathematical techniques; Computability theory; Dependently typed programming; Equivalence relations; Homotopy types; Intensional type theory; Logical methods; Partial functions; Weak bisimilarity; Formal languages",2-s2.0-85032199059
"Atzeni P., Bellomarini L., Bugiotti F., de Leonardis M.","Executable schema mappings for statistical data processing",2017,"Distributed and Parallel Databases",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031946647&doi=10.1007%2fs10619-017-7212-2&partnerID=40&md5=382c292bf17357ae426f214d57d99a28","Data processing is the core of any statistical information system. Statisticians are interested in specifying transformations and manipulations of data at a high level, in terms of entities of statistical models. We illustrate here a proposal where a high-level language, EXL, is used for the declarative specification of statistical programs, and a translation into executable form in various target systems is available. The language is based on the theory of schema mappings, in particular those defined by a specific class of tgds, which we actually use to optimize user programs and facilitate the translation towards several target systems. The characteristics of such class guarantee good tractability properties and the applicability in Big Data settings. A concrete implementation, EXLEngine, has been carried out and is currently used at the Bank of Italy. © 2017 Springer Science+Business Media, LLC","ETL; Scalable data processing; Schema mappings; Statistical data","Computer programming languages; Data handling; High level languages; Program translators; Statistics; Translation (languages); Data settings; Schema mappings; Specific class; Statistical data processing; Statistical datas; Statistical information; Target systems; User programs; Big data",2-s2.0-85031946647
"Abid R., Salaün G., De Palma N.","Asynchronous synthesis techniques for coordinating autonomic managers in the cloud",2017,"Science of Computer Programming",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020289887&doi=10.1016%2fj.scico.2017.05.005&partnerID=40&md5=9bc34379ddbd1ef31f6f56413ee1a6d2","Cloud computing allows the delivery of on-demand computing resources over the Internet on a pay-for-use basis. From a technical point of view, cloud applications usually consist of several software components deployed on remote virtual machines. Managing such applications is a challenging problem because manual administration is no longer realistic for these complex distributed systems. Thus, autonomic computing is a promising solution for monitoring and updating these applications automatically. This is achieved through the automation of administration functions and the use of control loops called autonomic managers. An autonomic manager observes the environment, detects changes, and reconfigures dynamically the application. Multiple autonomic managers can be deployed in the same system and must make consistent decisions. Using them without coordination may lead to inconsistencies and error-prone situations. In this article, we first present a simple language for expressing coordination constraints given a set of autonomic managers. Second, given a coordination expression written with that language, we propose new synthesis techniques for automatically generating an asynchronous controller. These synthesis techniques work in two steps by successively generating a model of the controller and a Java object corresponding to this model. This Java code is finally used for deploying the generated controller. As far as evaluation is concerned, we validated our approach by using it for coordinating real-world cloud applications. © 2017 Elsevier B.V.","Asynchronous coordination; Autonomic managers; Distributed cloud applications; Synthesis techniques","Application programs; Controllers; Java programming language; Managers; Asynchronous controllers; Asynchronous coordination; Autonomic Computing; Autonomic managers; Complex distributed system; Coordination constraints; Distributed clouds; Synthesis techniques; Coordination reactions",2-s2.0-85020289887
"Huang J., Li C., Tao L., Zhu H., Hu G.","Synthesis, characterization and heterogeneous base catalysis of amino functionalized lanthanide metal-organic frameworks",2017,"Journal of Molecular Structure",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021081471&doi=10.1016%2fj.molstruc.2017.06.045&partnerID=40&md5=08b1d7c382bd476d8682c9bf64c36f7f","Lanthanide metal-organic frameworks (Ln-MOFs) are featured by their tolerance to water and dense structure. In this work, an amine-functionalized Ln-MOF was facilely synthesized by coordination of terbium with 2-aminoterephthalic acid under the condition of microwave irradiation. The crystal structure was characterized by single crystal X-ray diffraction, FT-IR, Raman, TG-DTA and XPS analysis. The basic catalytic activity of the NH2-Tb-MOF was evaluated for Knoevenagel condensation and Henry reactions. Apart from the high activity and 100% selectivity to the condensation product, the NH2-Tb-MOF catalyst could be easily recycled and reused owing to the high stability of the MOF framework formed by coordination of Tb3+ with carboxylic groups. Remarkably, the NH2-Tb-MOF exhibited size-selective catalysis to substrates. For the small-sized reactants, it displayed comparable activity to the homogeneous catalyst of aniline owing to the high dispersion of NH2− active sites and the low diffusion limits. However, in the same reaction system, extremely poor activity in Knoevenagel condensation and Henry reaction for the bulky substrate 4-(tert-butyl) benzaldehyde was observed due to the both effects of substitute and inhibition of diffusion into the micropores. Crystal structure analysis provided a mechanistic evidence that the heterogeneous base catalysis arose from the amino groups densely distributed inside the micropores. © 2017 Elsevier B.V.","Amine group; Characterization; Heterogeneous catalysis; NH2-Tb-MOF; Synthesis","Catalysis; Catalyst activity; Catalyst selectivity; Catalysts; Characterization; Condensation; Condensation reactions; Crystalline materials; Java programming language; Microporosity; Microwave irradiation; Rare earth elements; Substrates; Synthesis (chemical); X ray diffraction; 2-aminoterephthalic acids; Amine groups; Crystal structure analysis; Heterogeneous base catalysis; Knoevenagel condensation; Metal organic framework; NH<sub>2</sub>-Tb-MOF; Single crystal x-ray diffraction; Crystal structure",2-s2.0-85021081471
"Sadati S., Khayat K.H.","Rheological and hardened properties of mortar incorporating high-volume ground glass fiber",2017,"Construction and Building Materials",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023647070&doi=10.1016%2fj.conbuildmat.2017.07.065&partnerID=40&md5=140924f8e8d67542f40751a1038bf421","The present research investigates the performance of mortar prepared with high-volume ground glass fiber (GGF) incorporated as partial replacement of Portland cement. Several binary and ternary mixtures with up to 50% cement substitution were investigated to evaluate rheological properties, heat of hydration, strength development, drying shrinkage, electrical resistivity, and carbonation. The incorporation of up to 50% GGF was found to reduce yield stress by up to 50% compared to control mortar without any GGF. On the other hand, this resulted in up to 100% increase of plastic viscosity of mortar in comparison with the Reference mortar cast with 100% Portland cement. The rate of structural build-up at rest of the tested mortars, that reflects the thixotropic nature of the mortar, decreased from 7.1 to 0.8 Pa/min with cement substitution by 50% of GGF. Reduction in 91-day compressive strength from 34 to 28 MPa was observed with 50% cement substitution by GGF. The coefficient of pozzolanic activity of mortar cast with 10% to 50% GGF ranged from 0.18 to 0.71 at 91 days, compared to mixtures containing 50% cement substitution with Class F fly ash (FA-F), Class C fly ash (FA-C), or blast furnace slag (SL) where the 91-day coefficient of pozzolanic activities were 1.80, 1.46, and 1.21, respectively. The incorporation of 10% to 50% GGF reduced the 91-day drying shrinkage by 0–20%. At 50% GGF replacement, the electrical resistivity was enhanced from 10 to 88 kΩ.cm at 91 days, while the carbonation coefficient increased by about 100%. The incorporation of 15% or 25% GGF in ternary systems containing either FA-C, FA-F, or SL was effective in enhancing compressive strength, with values ranging between 34 and 49 MPa. The best performance was observed in the case of the GGF/FA-C ternary binders, followed by the GGF/SL, and GGF/FA-F systems where 91-day compressive strength gains of up to 45%, 28%, and 10%, respectively, were observed compared to the Reference mixture with 100% Portland cement. © 2017 Elsevier Ltd","Calorimetry; Durability; Hydration; Pozzolanic activity; Rheological properties; Shrinkage; Sustainable infrastructure; Thixotropy","Binary mixtures; Bins; Blast furnaces; C (programming language); Calorimetry; Cements; Compressive strength; Durability; Electric conductivity; Fly ash; Glass; Glass fibers; Hydration; Mixtures; Mortar; Portland cement; Rheology; Shrinkage; Slags; Yield stress; Binary and ternary mixtures; Carbonation coefficients; Hardened properties; Pozzolanic activity; Rheological property; Strength development; Sustainable infrastructure; Thixotropy; Strength of materials",2-s2.0-85023647070
"Westman J., Nyberg M., Gustavsson J., Gurov D.","Formal architecture modeling of sequential non-recursive C programs",2017,"Science of Computer Programming",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017154649&doi=10.1016%2fj.scico.2017.03.007&partnerID=40&md5=bcfc1b5c9f55d9e5957117a30afba10e","To manage the complexity of C programs, architecture models are used as high-level descriptions, allowing developers to understand, assess, and manage the C programs without having to understand the intricate complexity of the code implementations. However, for the architecture models to serve their purpose, they must be accurate representations of the C programs. In order to support creating accurate architecture models, the present paper presents a mapping from the domain of sequential non-recursive C programs to a domain of formal architecture models, each being a hierarchy of components with well-defined interfaces. The hierarchically organized components and their interfaces, which capture both data and function call dependencies, are shown to both enable high-level assessment and analysis of the C program and provide a foundation for organizing and expressing specifications for compositional verification. © 2017 Elsevier B.V.","Architecture; C program; Component; Interfaces; Modeling","Architecture; Interfaces (materials); Models; Architecture modeling; Architecture models; C programs; Component; Compositional verification; Function calls; High level description; C (programming language)",2-s2.0-85017154649
"Ren H., Xie T., Dang M., Jiang S., Lin H., Luo L.","Sintering mechanism and microwave dielectric properties of BaTi4O9-BBZ composite for LTCC technology",2017,"Ceramics International",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023750576&doi=10.1016%2fj.ceramint.2017.06.178&partnerID=40&md5=55508362a2c57b2ed4494f80aeb1a6f4","A low temperature co-fired ceramic (LTCC) material was fabricated by mixing BaTi4O9 ceramic with BaO-B2O3-ZnO (BBZ) glass. The sintering mechanism was further analyzed through the wetting behavior, activation energy, phase evolution, microstructure and microwave dielectric properties of the BaTi4O9-BBZ composite. The results show that the sintering temperature of the BaTi4O9 ceramics can be significantly lowered from 1300 to 925 °C by the BBZ glass. This is due to the three-stage partially reactive liquid assisted sintering process which consists of glass redistribution and local grains rearrangement, solution-reprecipitaion including glass crystallization and reactions between the glass and ceramic, and global grain rearrangement, closure of pores and viscous flow. XRD patterns exhibit that BaTi4O9 reacts with the crystallization phase of BBZ glass obviously during sintering to form two new phases BaTi(BO3)2 and Ba4Ti13O30. The activation energy of BaTi4O9 ceramic is calculated to be 520.9 ± 40.46 kJ/mol, while that of BaTi4O9-BBZ composite is reduced to 330.98 ± 47.34 kJ/mol. With increasing sintering temperature, the dielectric constant (εr) and the quality factor (Q×f) value increases firstly and then decreases, and the temperature coefficient of resonant frequency (τf) value slightly decreases. Typically, the BaTi4O9 -BBZ composite sintered at 925 °C for 2 h displays excellent microwave dielectric properties of εr = 26.4, Q×f = 27300 GHz and τf = + 0.3 ppm/°C. In addition, the good chemical compatibility of this material with Ag electrode makes it as a potential candidate for LTCC technology. © 2017 Elsevier Ltd and Techna Group S.r.l.","BaO-B2O3-ZnO glass; BaTi4O9 ceramic; Dielectric properties; Sintering mechanism","Activation energy; Barium alloys; Barium compounds; Binary alloys; C (programming language); Ceramic materials; Chemical activation; Dielectric properties; Dielectric properties of solids; Glass; Microelectronics; Natural frequencies; Temperature; Titanium alloys; Zinc oxide; BaTi<sub>4</sub>O<sub>9</sub> ceramic; Chemical compatibility; Liquid-assisted sintering; Low-temperature co-fired ceramic materials; Microwave dielectric properties; Sintering mechanism; Sintering temperatures; Temperature coefficient of resonant frequency; Sintering",2-s2.0-85023750576
"Bani-Fwaz M.Z., Fazary A.E., Becker G.","Synthesis, crystal structures, and quantum chemical calculations of trialkyl-substituted 1λ3,3λ3,5λ3-triphospha dewarbenzenes",2017,"Journal of Molecular Structure",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020422755&doi=10.1016%2fj.molstruc.2017.05.144&partnerID=40&md5=2b48c9f9eb0e000f2688f47d9da10e67","This work has involved the reaction of kinetically stable 2-tert-buty-lλ3-phospha-alkyne, tBu–C[tbnd]P, with dichloro(dialkylamino)arsines, in which the isolated products were characterized by spectroscopic methods; additionally, the results of X-ray structure analyses were confirmed by quantum chemical calculations using Gaussian 98 molecular modeling software. The arsenic component of the starting material is completely lost, probably as a precipitate of insoluble “arsenic(I) chloride,” and unusual oligocycle 2,4,6-tri-tert-butyl-3-chloro-1-dialkylamino-1λ5σ4,3λ3σ3,5λ3σ2-triphosphabicyclo[2.2.0]hexa-1,5-diene (1) – an ylide with an unusually long P–Cl bond (245.5 p.m.) – could be isolated. From these reactions, compounds 1a to 1d differing by their substituents at nitrogen were isolated as deep red, cuboid-shaped single crystals. X-ray structure analyses reveal molecules which are characterized by an ylidic and a regular P–C double bond of almost equal length [P1⊕–C2⊖ av.172.2 p.m., P5–C6av.169.6 p.m.]. In addition to these two characteristic features the average bond length P3–C2 is found to be considerably shortened to a value of 172.7 p.m., whereas the adjacent phosphorus–chlorine bond P3–Cl1 is strongly elongated to 245.5 p.m. © 2017 Elsevier B.V.","Crystal structure; Dichloro(dialkylamino)arsines; Phospha-alkyne; Quantum chemical calculations; Triphospha-dewarbenzenes","Arsenic; Bond length; C (programming language); Chemical analysis; Chemical bonds; Quantum chemistry; Single crystals; Spectroscopic analysis; Dichloro(dialkylamino)arsines; Molecular modeling software; Phospha-alkyne; Quantum chemical calculations; Shaped single crystal; Spectroscopic method; Triphospha-dewarbenzenes; X ray structure analysis; Crystal structure",2-s2.0-85020422755
"Orofino A.B., Galante M.J., Oyanguren P.A.","Analyses of surface relief gratings inscription in epoxy-azo linear and crosslinked polymers",2017,"Journal of Polymer Science, Part B: Polymer Physics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026452141&doi=10.1002%2fpolb.24411&partnerID=40&md5=ce883993815e0b4363775d8b059a2e7a","This work evaluates the inscription of surface relief gratings (SRG) in a series of epoxy-azo prepolymers and networks, both based on the same azo chromophore. Variables such as matrix structure (thermoplastic/thermoset), film thickness, exposure time, power of the incident laser beam, and content of azobenzene were analyzed on the final modulation depth of the gratings. The main goal of the article is to achieve the efficient formation of SRGs on crosslinked azopolymer films in a single step, in a reasonable time, and to a significant extent. The progressive erasure of the obtained structures with increasing temperature showed that part of the photoinduced information remained encoded in the material: as the relief partially relaxed above the glass transition temperature of the bulk material (116 °C) and up to 200 °C, its modulation remained in about one third of the initial height, and did not completely disappear. © 2017 Wiley Periodicals, Inc. J. Polym. Sci., Part B: Polym. Phys. 2017, 55, 1542–1552. © 2017 Wiley Periodicals, Inc.","azo polymers; crosslinking; epoxy networks; surface relief gratings; templates","Chromophores; Crosslinking; Glass transition; Laser beams; Modulation; Polymers; Temperature; Azo polymers; Azo-polymer films; Cross-linked polymers; Epoxy network; Increasing temperatures; Matrix structure; Surface relief gratings; Templates; C (programming language)",2-s2.0-85026452141
"Jongmans S.-S.T.Q., Kappé T., Arbab F.","Constraint automata with memory cells and their composition",2017,"Science of Computer Programming",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017111575&doi=10.1016%2fj.scico.2017.03.006&partnerID=40&md5=f74395e9566e06944708888a41d207ea","Over the past decades, coordination languages emerged for modeling and implementing concurrency protocols among components in component-based systems. Coordination languages allow programmers to express concurrency protocols at a higher and more appropriate level of abstraction than what traditional programming and scripting languages offer. In this paper, we extend a significant coordination model—constraint automata—with a mechanism to finitely and compactly deal with infinite data domains, including foundational notions as behavior and equivalence (based on languages), weak and strong congruence (based on bisimulation), and composition. We also address the act of composing a number of simple primitive constraint automata into a complex composite one, by discussing two alternative composition approaches and by analyzing their performance in a number of experiments. © 2017 Elsevier B.V.","Composition; Constraint automata; Coordination; Performance; Reo","Automata theory; Chemical analysis; Software engineering; Complex composites; Component based systems; Constraint automata; Coordination; Coordination language; Level of abstraction; Performance; Scripting languages; Modeling languages",2-s2.0-85017111575
"Yao L., Wang H., Song Y., Sui G.","BioQueue: A novel pipeline framework to accelerate bioinformatics analysis",2017,"Bioinformatics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031773930&doi=10.1093%2fbioinformatics%2fbtx403&partnerID=40&md5=acc477534dd1e4c768c8c2256da0bb5d","Motivation With the rapid development of Next-Generation Sequencing, a large amount of data is now available for bioinformatics research. Meanwhile, the presence of many pipeline frameworks makes it possible to analyse these data. However, these tools concentrate mainly on their syntax and design paradigms, and dispatch jobs based on users' experience about the resources needed by the execution of a certain step in a protocol. As a result, it is difficult for these tools to maximize the potential of computing resources, and avoid errors caused by overload, such as memory overflow. Results Here, we have developed BioQueue, a web-based framework that contains a checkpoint before each step to automatically estimate the system resources (CPU, memory and disk) needed by the step and then dispatch jobs accordingly. BioQueue possesses a shell command-like syntax instead of implementing a new script language, which means most biologists without computer programming background can access the efficient queue system with ease. Availability and implementation BioQueue is freely available at https://github.com/liyao001/BioQueue. The extensive documentation can be found at http://bioqueue.readthedocs.io. Contact li-yao@outlook.com or gcsui@nefu.edu.cn Supplementary informationSupplementary dataare available at Bioinformatics online. © The Author 2017. Published by Oxford University Press. All rights reserved.",,,2-s2.0-85031773930
"Ratiu D., Voelter M., Pavletic D.","Automated testing of DSL implementations—experiences from building mbeddr",2017,"Software Quality Journal",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031933140&doi=10.1007%2fs11219-017-9390-6&partnerID=40&md5=626a32377316d2b43ff9057c089be5f6","Domain-specific languages promise to improve productivity and quality of software development by providing problem-adequate abstractions to developers. Projectional language workbenches, in turn, allow the definition of modular and extensible domain specific languages, generators, and development environments. While recent advances in language engineering have enabled the definition of DSLs and tooling in a modular and cost-effective way, the quality assurance of their implementation is still challenging. In this paper, we discuss our work on testing different aspects of the implementation of domain specific languages and associated tools, and present several approaches to increase the automation of language testing. We illustrate these approaches with the Jetbrains MPS language workbench and our experience with testing mbeddr, a set of domain specific languages and tools on top of C tailored to embedded software development. Based on the experience gained from the mbeddr project, we extract generic lessons for practitioners as well as challenges which need more research. © 2017 Springer Science+Business Media, LLC","Automation; Domain specific languages; Quality assurance; Testing","Automation; Computer programming languages; Cost effectiveness; Cost engineering; Digital subscriber lines; Problem oriented languages; Productivity; Quality assurance; Software design; Software engineering; Software testing; Testing; Associated tool; Automated testing; Development environment; Domain specific languages; Language engineering; Language testing; Language workbenches; Quality of softwares; C (programming language)",2-s2.0-85031933140
"BENDKOWSKI M., GRYGIEL K., TARAU P.","Random generation of closed simply typed λ-terms: A synergy between logic programming and Boltzmann samplers*",2017,"Theory and Practice of Logic Programming",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032228015&doi=10.1017%2fS147106841700045X&partnerID=40&md5=ca336a5a96713b61074e2f25306db55c","A natural approach to software quality assurance consists in writing unit tests securing programmer-declared code invariants. Throughout the literature, a great body of work has been devoted to tools and techniques automating this labour-intensive process. A prominent example is the successful use of randomness, in particular, random typable λ-terms, in testing functional programming compilers such as the Glasgow Haskell Compiler. Unfortunately, due to the intrinsically difficult combinatorial structure of typable λ-terms, no effective uniform sampling method is known, setting it as a fundamental open problem in the random software testing approach. In this paper, we combine the framework of Boltzmann samplers, a powerful technique of random combinatorial structure generation, with today's Prolog systems offering a synergy between logic variables, unification with occurs check and efficient backtracking. This allows us to develop a novel sampling mechanism able to construct uniformly random closed simply typed λ-terms of up size 120. We apply our techniques to the generation of uniformly random closed simply typed normal forms and design a parallel execution mechanism pushing forward the achievable term size to 140. Copyright © Cambridge University Press 2017","Boltzmann samplers; combinatorics of λ-terms; parallel implementation of Boltzmann samplers; random generation of simply typed normal forms; random generation of simply typed λ-terms; type inference","Computer circuits; Computer software selection and evaluation; Functional programming; Logic programming; PROLOG (programming language); Quality assurance; Software testing; Boltzmann; Combinatorics; Normal form; Random generation; Type inferences; Program compilers",2-s2.0-85032228015
"Hunt W.A., Jr., Kaufmann M., Moore J.S., Slobodova A.","Industrial hardware and software verification with ACL2",2017,"Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028937641&doi=10.1098%2frsta.2015.0399&partnerID=40&md5=ce789d82ac2c0e4b04f20506eed7e8d2","The ACL2 theorem prover has seen sustained industrial use since the mid-1990s. Companies that have used ACL2 regularly include AMD, Centaur Technology, IBM, Intel, Kestrel Institute, Motorola/Freescale, Oracle and Rockwell Collins. This paper introduces ACL2 and focuses on how and why ACL2 is used in industry. ACL2 is wellsuited to its industrial application to numerous software and hardware systems, because it is an integrated programming/proof environment supporting a subset of the ANSI standard Common Lisp programming language. As a programming language ACL2 permits the coding of efficient and robust programs; as a prover ACL2 can be fully automatic but provides many features permittingdomain-specific human-supplied guidance at various levels of abstraction. ACL2 specifications and models often serve as efficient execution engines for the modelled artefacts while permitting formal analysis and proof of properties. Crucially, ACL2 also provides support for the development and verification of other formal analysis tools. However, ACL2 did not find its way into industrial use merely because of its technical features. The core ACL2 user/development community has a shared vision of making mechanized verification routine when appropriate and has been committed to this vision for the quarter century since the Computational Logic, Inc., Verified Stack. The community has focused on demonstrating the viability of the tool by taking on industrial projects (often at the expense of not being able to publish much). This article is part of the themed issue ‘Verified trustworthy software systems © 2017 The Author(s) Published by the Royal Society. All rights reserved.","ACL2; Formal methods; Lisp; Models; Theorem prover; Verification","Application programs; Computation theory; Computer programming languages; Computer systems programming; Formal methods; Formal verification; Hardware; LISP (programming language); Logic programming; Models; Theorem proving; ACL2; Formal analysis tools; Integrated programming; Lisp; Mechanized verifications; Software and hardwares; Theorem provers; Trustworthy software systems; Verification",2-s2.0-85028937641
"Appel A.W., Beringer L., Chlipala A., Pierce B.C., Shao Z., Weirich S., Zdancewic S.","Position paper: the science of deep specification",2017,"Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028945294&doi=10.1098%2frsta.2016.0331&partnerID=40&md5=90a651530f8d27b73f1cc97c805369d7","We introduce our efforts within the project ‘The science of deep specification’ to work out the key formal underpinnings of industrial-scale formal specifications of software and hardware components, anticipating a world where large verified systems are routinely built out of smaller verified components that are also used by many other projects. We identify an important class of specification that has already been used in a few experiments that connect strong component-correctness theorems across the work of different teams. To help popularize the unique advantages of that style, we dub it deep specification, and we say that it encompasses specifications that are rich, two-sided, formal and live (terms that we define in the article). Our core team is developing a proof-of-concept system (based on the Coq proof assistant) whose specification and verification work is divided across largely decoupled subteams at our four institutions, encompassing hardware microarchitecture, compilers, operating systems and applications, along with cross-cutting principles and tools for effective specification. We also aim to catalyse interest in the approach, not just by basic researchers but also by users in industry. This article is part of the themed issue ‘Verified trustworthy software systems’. © 2017 The Author(s) Published by the Royal Society. All rights reserved.","Formal methods; Programming languages; Proof assistants","Computer programming languages; Cutting tools; Formal methods; Hardware; Specifications; Theorem proving; Coq proof assistant; Correctness theorem; Industrial scale; Micro architectures; Proof assistant; Software and hardwares; Specification and verification; Trustworthy software systems; Formal specification",2-s2.0-85028945294
"Sawant A.A., Robbes R., Bacchelli A.","On the reaction to deprecation of clients of 4 + 1 popular Java APIs and the JDK",2017,"Empirical Software Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031416657&doi=10.1007%2fs10664-017-9554-9&partnerID=40&md5=00e478fbaaf19937c9e60b62e5bd0d5d","Application Programming Interfaces (APIs) are a tremendous resource—that is, when they are stable. Several studies have shown that this is unfortunately not the case. Of those, a large-scale study of API changes in the Pharo Smalltalk ecosystem documented several findings about API deprecations and their impact on API clients. We extend this study, by analyzing clients of both popular third-party Java APIs and the JDK API. This results in a dataset consisting of more than 25,000 clients of five popular Java APIs on GitHub, and 60 clients of the JDK API from Maven Central. This work addresses several shortcomings of the previous study, namely: a study of several distinct API clients in a popular, statically-typed language, with more accurate version information. We compare and contrast our findings with the previous study and highlight new ones, particularly on the API client update practices and the startling similarities between reaction behavior in Smalltalk and Java. We make a comparison between reaction behavior for third-party APIs and JDK APIs, given that language APIs are a peculiar case in terms of wide-spread usage, documentation, and support from IDEs. Furthermore, we investigate the connection between reaction patterns of a client and the deprecation policy adopted by the API used. © 2017 The Author(s)","API popularity; API usage; Application programming interface; Dataset","Java programming language; Api popularity; API usage; Dataset; Large-scale studies; Reaction behavior; Reaction patterns; Third parties; Version information; Application programming interfaces (API)",2-s2.0-85031416657
"Fisher K., Launchbury J., Richards R.","The HACMS program: Using formal methods to eliminate exploitable bugs",2017,"Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028935782&doi=10.1098%2frsta.2015.0401&partnerID=40&md5=e87c6228b6ad1b9ee17a0f6249b8d5ee","For decades, formal methods have offered the promise of verified software that does not have exploitable bugs. Until recently, however, it has not been possible to verify software of sufficient complexity to be useful. Recently, that situation has changed. SeL4 is an open-source operating system microkernel efficient enough to be used in a wide range of practical applications. Its designers proved it to be fully functionally correct, ensuring the absence of buffer overflows, null pointer exceptions, use-after-free errors, etc., and guaranteeing integrity and confidentiality. The CompCert Verifying C Compiler maps source C programs to provably equivalent assembly language, ensuring the absence of exploitable bugs in the compiler. A number of factors have enabled this revolution, including faster processors, increased automation, more extensive infrastructure, specialized logics and the decision to co-develop code and correctness proofs rather than verify existing artefacts. In this paper, we explore the promise and limitations of current formal-methods techniques. We discuss these issues in the context of DARPA’s HACMS program, which had as its goal © 2017 The Authors.","Cybersecurity; Formal methods; High-assurance software","C (programming language); Open source software; Open systems; Program compilers; Program debugging; Assembly language; Buffer overflows; C compilers; Correctness proofs; Cyber security; High assurance; Number of factors; Open source operating systems; Formal methods",2-s2.0-85028935782
"Wiedensohler A., Wiesner A., Weinhold K., Birmili W., Hermann M., Merkel M., Müller T., Pfeifer S., Schmidt A., Tuch T., Velarde F., Quincey P., Seeger S., Nowak A.","Mobility particle size spectrometers: Calibration procedures and measurement uncertainties",2017,"Aerosol Science and Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032339584&doi=10.1080%2f02786826.2017.1387229&partnerID=40&md5=8922affb4dce42165329d483456baa47","Mobility particle size spectrometers (MPSS) belong to the essential instruments in aerosol science that determine the particle number size distribution (PNSD) in the submicrometer size range. Following calibration procedures and target uncertainties against standards and reference instruments are suggested for a complete MPSS quality assurance program: (a) calibration of the CPC counting efficiency curve (within 5% for the plateau counting efficiency; within 1 nm for the 50% detection efficiency diameter), (b) sizing calibration of the MPSS, using a certified polystyrene latex (PSL) particle size standard at 203 nm (within 3%), (c) intercomparison of the PNSD of the MPSS (within 10% and 20% of the dN/dlogDP concentration for the particle size range 20–200 and 200–800 nm, respectively), and (d) intercomparison of the integral PNC of the MPSS (within 10%). Furthermore, following measurement uncertainties have been investigated: (a) PSL particle size standards in the range from 100 to 500 nm match within 1% after sizing calibration at 203 nm. (b) Bipolar diffusion chargers based on the radioactive nuclides Kr85, Am241, and Ni63 and a new ionizer based on corona discharge follow the recommended bipolar charge distribution, while soft X-ray-based charges may alter faster than expected. (c) The use of a positive high voltage supply show a 10% better performance than a negative one. (d) The intercomparison of the integral PNC of an MPSS against the total number concentration is still within the target uncertainty at an ambient pressure of approximately 500 hPa. © 2017 The Author(s). Published with license by Taylor & Francis",,"Americium; C (programming language); Calibration; Efficiency; Electric corona; Quality assurance; Spectrometers; Uncertainty analysis; Bipolar diffusion charger; Calibration procedure; Detection efficiency; Measurement uncertainty; Particle number size distribution; Particle size standards; Reference instruments; Total number concentrations; Particle size",2-s2.0-85032339584
"Pazouki A., Kwarta M., Williams K., Likos W., Serban R., Jayakumar P., Negrut D.","Compliant contact versus rigid contact: A comparison in the context of granular dynamics",2017,"Physical Review E",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032855778&doi=10.1103%2fPhysRevE.96.042905&partnerID=40&md5=6fcd0fad4a799b8233425c9ff1116c84","We summarize and numerically compare two approaches for modeling and simulating the dynamics of dry granular matter. The first one, the discrete-element method via penalty (DEM-P), is commonly used in the soft matter physics and geomechanics communities; it can be traced back to the work of Cundall and Strack [P. Cundall, Proc. Symp. ISRM, Nancy, France 1, 129 (1971); P. Cundall and O. Strack, Geotechnique 29, 47 (1979)GTNQA80016-850510.1680/geot.1979.29.1.47]. The second approach, the discrete-element method via complementarity (DEM-C), considers the grains perfectly rigid and enforces nonpenetration via complementarity conditions; it is commonly used in robotics and computer graphics applications and had two strong promoters in Moreau and Jean [J. J. Moreau, in Nonsmooth Mechanics and Applications, edited by J. J. Moreau and P. D. Panagiotopoulos (Springer, Berlin, 1988), pp. 1-82; J. J. Moreau and M. Jean, Proceedings of the Third Biennial Joint Conference on Engineering Systems and Analysis, Montpellier, France, 1996, pp. 201-208]. The DEM-P and DEM-C are manifestly unlike each other: They use different (i) approaches to model the frictional contact problem, (ii) sets of model parameters to capture the physics of interest, and (iii) classes of numerical methods to solve the differential equations that govern the dynamics of the granular material. Herein, we report numerical results for five experiments: shock wave propagation, cone penetration, direct shear, triaxial loading, and hopper flow, which we use to compare the DEM-P and DEM-C solutions. This exercise helps us reach two conclusions. First, both the DEM-P and DEM-C are predictive, i.e., they predict well the macroscale emergent behavior by capturing the dynamics at the microscale. Second, there are classes of problems for which one of the methods has an advantage. Unlike the DEM-P, the DEM-C cannot capture shock-wave propagation through granular media. However, the DEM-C is proficient at handling arbitrary grain geometries and solves, at large integration step sizes, smaller problems, i.e., containing thousands of elements, very effectively. The DEM-P vs DEM-C comparison is carried out using a public-domain, open-source software package; the models used are available online. © 2017 American Physical Society.",,"Computer graphics; Differential equations; Dynamics; Granular materials; Numerical methods; Open source software; Open systems; Shear flow; Shock waves; Software engineering; Wave propagation; Compliant contacts; Computer graphics applications; Emergent behaviors; Engineering systems; Frictional contact problems; Modeling and simulating; Non-smooth mechanics; Soft-matter physics; C (programming language)",2-s2.0-85032855778
"Batty M.","Compositional relaxed concurrency",2017,"Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028918975&doi=10.1098%2frsta.2015.0406&partnerID=40&md5=340ee4014501e97d4af51198dae29a3a","There is a broad design space for concurrent computer processors: they can be optimized for low power, low latency or high throughput. This freedom to tune each processor design to its niche has led to an increasing diversity of machines, from powerful pocketable devices to those responsible for complex and critical tasks, such as car guidance systems. Given this context, academic concurrency research sounds notes of both caution and optimism. Caution because recent work has uncovered flaws in the way we explain the subtle memory behaviour of concurrent systems: specifications have been shown to be incorrect, leading to bugs throughout the many layers of the system. And optimism because our tools and methods for verifying the correctness of concurrent code—although built above an idealized model of concurrency—are becoming more mature. This paper looks at the way we specify the memory behaviour of concurrent systems and suggests a new direction. Currently, there is a siloed approach, with each processor and programming language specified separately in an incomparable way. But this does not match the structure of our programs, which may use multiple processors and languages together. Instead we propose a compositional approach, where program components carry with them a description of the sort of concurrency they rely on, and there is a mechanism for composing these. This will support not only components written for the multiple varied processors found in a modern system but also those that use idealized models of concurrency, providing a sound footing for mature verification techniques. This article is part of the themed issue ‘Verified trustworthy software systems’. © 2017 The Author(s) Published by the Royal Society. All rights reserved.","Concurrency; Graphics processors; Heterogeneous systems; Relaxed memory; Semantics; Verification","Integrated circuit design; Semantics; Verification; Concurrency; Concurrent computers; Graphics processor; Heterogeneous systems; Multiple processors; Program components; Trustworthy software systems; Verification techniques; Program debugging",2-s2.0-85028918975
"Hosseini K., Sigloch K.","ObspyDMT: A Python toolbox for retrieving and processing large seismological data sets",2017,"Solid Earth",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031330860&doi=10.5194%2fse-8-1047-2017&partnerID=40&md5=867c6e3e86a80ccfb907730b06c5c492","We present obspyDMT, a free, open-source software toolbox for the query, retrieval, processing and management of seismological data sets, including very large, heterogeneous and/or dynamically growing ones. ObspyDMT simplifies and speeds up user interaction with data centers, in more versatile ways than existing tools. The user is shielded from the complexities of interacting with different data centers and data exchange protocols and is provided with powerful diagnostic and plotting tools to check the retrieved data and metadata. While primarily a productivity tool for research seismologists and observatories, easy-to-use syntax and plotting functionality also make obspyDMT an effective teaching aid. Written in the Python programming language, it can be used as a stand-alone command-line tool (requiring no knowledge of Python) or can be integrated as a module with other Python codes. It facilitates data archiving, preprocessing, instrument correction and quality control-routine but nontrivial tasks that can consume much user time. We describe obspyDMT's functionality, design and technical implementation, accompanied by an overview of its use cases. As an example of a typical problem encountered in seismogram preprocessing, we show how to check for inconsistencies in response files of two example stations. We also demonstrate the fully automated request, remote computation and retrieval of synthetic seismograms from the Synthetics Engine (Syngine) web service of the Data Management Center (DMC) at the Incorporated Research Institutions for Seismology (IRIS).",,"Computer programming; Computer software; Data handling; Electronic data interchange; High level languages; Information management; Open source software; Open systems; Seismology; Societies and institutions; Software engineering; Web services; Data exchange protocols; Productivity tools; Python programming language; Remote computations; Research institutions; Seismological data; Synthetic seismogram; Technical implementation; Search engines; data management; data processing; data set; seismic data; seismogram; seismology; software",2-s2.0-85031330860
"Li Y., Klippenstein S.J., Zhou C.-W., Curran H.J.","Theoretical Kinetics Analysis for H Atom Addition to 1,3-Butadiene and Related Reactions on the C̀4H7 Potential Energy Surface",2017,"Journal of Physical Chemistry A",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031317080&doi=10.1021%2facs.jpca.7b05996&partnerID=40&md5=43d3ad1141d4fc49725374552cdb9304","The oxidation chemistry of the simplest conjugated hydrocarbon, 1,3-butadiene, can provide a first step in understanding the role of polyunsaturated hydrocarbons in combustion and, in particular, an understanding of their contribution toward soot formation. On the basis of our previous work on propene and the butene isomers (1-, 2-, and isobutene), it was found that the reaction kinetics of H-atom addition to the C=C double bond plays a significant role in fuel consumption kinetics and influences the predictions of high-temperature ignition delay times, product species concentrations, and flame speed measurements. In this study, the rate constants and thermodynamic properties for H-atom addition to 1,3-butadiene and related reactions on the C̀4H7 potential energy surface have been calculated using two different series of quantum chemical methods and two different kinetic codes. Excellent agreement is obtained between the two different kinetics codes. The calculated results including zero-point energies, single-point energies, rate constants, barrier heights, and thermochemistry are systematically compared among the two quantum chemical methods. 1-Methylallyl (C̀4H71-3) and 3-buten-1-yl (C̀4H71-4) radicals and C2H4 + C̀2H3 are found to be the most important channels and reactivity-promoting products, respectively. We calculated that terminal addition is dominant (&gt;80%) compared to internal H-atom addition at all temperatures in the range 298-2000 K. However, this dominance decreases with increasing temperature. The calculated rate constants for the bimolecular reaction C4H6 + H → products and C2H4 + C̀2H3 → products are in excellent agreement with both experimental and theoretical results from the literature. For selected C4 species, the calculated thermochemical values are also in good agreement with literature data. In addition, the rate constants for H atom abstraction by H atoms have also been calculated, and it is found that abstraction from the central carbon atoms is the dominant channel (&gt;70%) at temperatures in the range of 298-2000 K. Finally, by incorporating our calculated rate constants for both H atom addition and abstraction into our recently developed 1,3-butadiene model, we show that laminar flame speed predictions are significantly improved, emphasizing the value of this study. © 2017 American Chemical Society.",,"Abstracting; Addition reactions; Atoms; Butenes; Carbon; Chemical bonds; Ethylene; Free radical reactions; Hydrocarbons; Isomers; Kinetics; Molecular physics; Potential energy; Potential energy surfaces; Quantum chemistry; Rate constants; Reaction kinetics; Temperature; Bimolecular reaction; Ignition delay time; Increasing temperatures; Quantum-chemical methods; Single-point energy; Species concentration; Thermochemical values; Zero-point energies; C (programming language)",2-s2.0-85031317080
"Furferi R., Governi L., Uccheddu F., Volpe Y.","Computer-aided design tool for GT ventilation system ductworks",2017,"Computer-Aided Design and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031491002&doi=10.1080%2f16864360.2017.1375666&partnerID=40&md5=066f16ef555ecae1ba586627d4ab3381","The design of gas turbine ventilation systems (VSs) is a lengthy and tedious process, often requiring weeks to refine a single design concept and by additional time to manufacture it. This is particularly true when dealing with structural design since the typical approach followed by main worldwide manufacturing companies is to outsource finite elements analysis and, often, the 3d modelling phase itself. Moreover, the structural design process is iterative: the modeling and finite elements analysis steps are repeated several times whenever a new VS has to be produced. Accordingly, speeding-up the structural design phase is today a crucial issue for gas turbine sector. Keeping the above objective in mind, the present paper proposes a CAD-based tool, implemented in a commercial 3D CAD software package (SolidWorks), supporting and partly automating the complex structural VS design process. The solution suggested in this work consists of the design and implementation of a SolidWorks add-in, called DuctWorks, developed by using C# programming language. Differently from commercially available solutions, the proposed tool is specifically thought keeping in mind the necessity of performing a final structural assessment, which is of utmost importance given the considerable dimensions and stresses this kind of VS are subject to in the specific field of GT and energy production industry. Tested against a set of case studies, DuctWorks proved to be effective in allowing designers to accelerate the ventilation systems design process with excellent results when compared with the traditional design process. © 2017 CAD Solutions, LLC","CAD tools; FEA; ventilation system","Finite element method; Gas turbines; Manufacture; Structural design; Ventilation; CAD tool; Computer aided design tools; Design and implementations; Energy productions; Finite elements analysis; Manufacturing companies; Structural assessments; Ventilation systems; Computer aided design",2-s2.0-85031491002
"Youker A.J., Brown M.A., Heltemes T.A., Vandegrift G.F.","Controlling Pu behavior on Titania: Implications for LEU Fission-Based Mo-99 Production",2017,"Industrial and Engineering Chemistry Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031327053&doi=10.1021%2facs.iecr.7b02967&partnerID=40&md5=4cc936627baeabc9815f1238e5585374","Molybdenum-99 is the parent isotope of the most widely used isotope, technetium-99m, in all diagnostic nuclear medicine procedures. Due to proliferation concerns associated with the use of highly enriched uranium (HEU), the preferred method of fission-based Mo-99 production uses low enriched uranium (LEU) targets. Using LEU versus HEU for Mo-99 production produces ∼30 times more Pu-239, due to neutron capture on U-238 to produce Np-239, which ultimately decays to Pu-239 (t1/2 = 24,110 yr). Argonne National Laboratory is supporting a potential US Mo-99 producer in their efforts to produce Mo-99 from an LEU solution. In order to mitigate the generation of large volumes of greater-than-class-C (GTCC) low level waste (Pu-239 concentrations greater than 1 nCi/g), we have focused our efforts on the separation chemistry of Pu and Mo with a titania sorbent in sulfate media. Results from batch and column experiments show that temperature and acid wash concentration can be used to control Pu behavior on titania. © 2017 American Chemical Society.",,"C (programming language); Diagnosis; Isotopes; Nuclear medicine; Plutonium; Titanium dioxide; Uranium; Argonne National Laboratory; Column experiments; Highly enriched uranium; Low-enriched uranium; Low-level waste; Mo-99 productions; Neutron capture; Proliferation concern; Molybdenum",2-s2.0-85031327053
"Jo J.-W., Kim Y.-H., Park J., Heo J.S., Hwang S., Lee W.-J., Yoon M.-H., Kim M.-G., Park S.K.","Ultralow-Temperature Solution-Processed Aluminum Oxide Dielectrics via Local Structure Control of Nanoclusters",2017,"ACS Applied Materials and Interfaces",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031301538&doi=10.1021%2facsami.7b09523&partnerID=40&md5=513b11734a08ef636137d330e559f7e5","Oxide dielectric materials play a key role in a wide range of high-performance solid-state electronics from semiconductor devices to emerging wearable and soft bioelectronic devices. Although several previous advances are noteworthy, their typical processing temperature still far exceeds the thermal limitations of soft materials, impeding their wide utilization in these emerging fields. Here, we report an innovative route to form highly reliable aluminum oxide dielectric films using an ultralow-Temperature (&lt;60 °C) solution process with a class of oxide nanocluster precursors. The extremely low-Temperature synthesis of oxide dielectric films was achieved by using low-impurity, bulky metal-oxo-hydroxy nanoclusters combined with a spatially controllable and highly energetic light activation process. It was noteworthy that the room-Temperature light activation process was highly effective in dissociating the metal-oxo-hydroxy clusters, enabling the formation of a dense atomic network at low temperature. The ultralow-Temperature solution-processed oxide dielectrics demonstrated high breakdown field (&gt;6 MV cm-1), low leakage (â1 × 10-8 A cm-2 at 2 MV cm-1), and excellent electrical stability comparable to those of vacuum-deposited and high-Temperature-processed dielectric films. For potential applications of the oxide dielectrics, transparent metal oxides and carbon nanotube active devices as well as integrated circuits were implemented directly on both ultrathin polymeric and highly stretchable substrates. © 2017 American Chemical Society.","aluminum-oxo cluster; flexible electronics; light activation; low-Temperature metal oxide; stretchable electronics","Aluminum; C (programming language); Carbon; Carbon nanotubes; Chemical activation; Dielectric films; Flexible electronics; Ionic liquids; Low temperature effects; Metals; Nanoclusters; Oxide films; Oxides; Processing; Semiconductor devices; Substrates; Temperature; Yarn; Light activation; Low temperature synthesis; Metal oxides; Oxo clusters; Processing temperature; Solid state electronics; Stretchable electronics; Ultra low temperatures; Dielectric materials",2-s2.0-85031301538
"He B., Dong L., Xu T., Fei S., Zhang H., Wang W.","Research on network programming language and policy conflicts for SDN",2017,"Concurrency Computation ",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021146475&doi=10.1002%2fcpe.4218&partnerID=40&md5=2c9cd3da356a3bbe6d6baf6489d5080a","Through network programmability, software defined network can simplify network control and management. Since the current software defined network southbound interface level is low and programming situation is complex, it requires a high-level abstract programming language to simplify programming. First, this paper improves the NetCore programming language to generate NetCore-M language, so that it can support deployment of multipolicies combination including packet drop action. This paper describes in detail the syntax, semanteme, and implementation of NetCore-M language forwarding policy service. Secondly, this paper describes the network policy conflict systematically. Finally, this paper shows that the modified multipolicies combination algorithm can effectively detect policies conflicts based on the implementation of the Pyretic project. Copyright © 2017 John Wiley & Sons, Ltd.","conflict detection; policy combination; Pyretic; SDN","Ada (programming language); Complex networks; Computer programming languages; High level languages; Conflict detection; Interface level; Network control; Network programming language; Policies conflict; Policy combination; Programmability; Pyretic; Computer programming",2-s2.0-85021146475
"Pierce M.E., Warnke T., Krumme U., Helms T., Hammer C., Uhrmacher A.M.","Developing and validating a multi-level ecological model of eastern Baltic cod (Gadus morhua) in the Bornholm Basin – A case for domain-specific languages",2017,"Ecological Modelling",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026817591&doi=10.1016%2fj.ecolmodel.2017.07.012&partnerID=40&md5=888a7447b30c2695419314e2cd32292a","Recent changes in environmental and ecological conditions are a major reason that established stock assessment macro-models no longer provide reliable estimates on the stock status of eastern Baltic cod (Gadus morhua). To account for a complex ecological system, an individual-based modelling approach is needed that turns the attention from the overall population to the individual fish, its metabolic processes, behaviour, and interaction with environmental conditions. The multi-level rule-based modelling language ML-Rules was used to develop the first iteration of an individual-based model. The different stratification layers of the estuarine environment are modelled as explicit entities with varying properties and are populated by individual cod and its prey. The cod model focuses on growth and mortality dependent on abiotic factors and behaviour within the stratified environment of the Bornholm Basin. Despite the complexity of the formalised interactions, the resulting model specification is succinct and compact. Its structure and declarative nature facilitates reuse and subsequent extension. To allow easy replication of simulation experiments, we used the simulation experiment specification language SESSL for calibration and validation. The extendibility of the model and replicability of simulation experiments, as provided by the domain specific languages ML-Rules and SESSL respectively, will be key assets in future research, as the model provides a first, but essential, step toward studying the impact of specific environmental changes and certain behaviour pattern on the cod population in the Bornholm Basin. © 2017 Elsevier B.V.","Eastern Baltic cod; Ecological modelling; Hypoxia; Individual-based; ML-Rules; Rule-based","Computer programming languages; Ecology; Modeling languages; Problem oriented languages; Specification languages; Specifications; XML; Eastern Baltic cod; Ecological modelling; Hypoxia; Individual-based; ML-Rules; Rule based; Computer simulation languages; abiotic factor; anoxic conditions; complexity; ecological modeling; environmental change; environmental conditions; estuarine environment; gadoid; growth; mortality; stock assessment; stratification; Atlantic Ocean; Baltic Sea; Bornholm Basin; Gadus callarias; Gadus morhua",2-s2.0-85026817591
"Orponen P.","Design methods for 3D wireframe DNA nanostructures",2017,"Natural Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030845318&doi=10.1007%2fs11047-017-9647-9&partnerID=40&md5=ca88c22c3402b7bc2d1e51475646f29c","The field of structural DNA nanotechnology aims at the systematic development of self-assembling nanostructures using DNA as the construction material. Research in this area is progressing rapidly, and the controlled, computer-aided design of increasingly complex structures is becoming feasible. One thread of this endeavour is the design and characterisation of self-assembling 3D nanostructures based on wireframe polyhedral models. This article aims to illustrate some of the key developments in this direction, in sufficient detail so that the reader can achieve a general understanding of the main concepts and approaches. The emphasis is on the design principles rather than experimental methodology, and the role of computer science and computational tools is set forth. © 2017 Springer Science+Business Media B.V.","3D nanostructures; DNA nanotechnology; DNA origami; Self-assembly; Wireframe models","Computer aided design; FORTH (programming language); Nanostructures; Nanotechnology; Self assembly; 3-D nanostructures; Computational tools; DNA nanostructures; DNA nanotechnology; Dna origamis; Experimental methodology; Self-assembling nanostructures; Wireframe model; DNA",2-s2.0-85030845318
"Ravi Shankar A., Vetrivendan E., Shukla P.K., Das S.K., Hemanth Rao E., Murthy S.S., Lydia G., Nashine B.K., Mallika C., Selvaraj P., Kamachi Mudali U.","Characterisation of Ceramic-Coated 316LN Stainless Steel Exposed to High-Temperature Thermite Melt and Molten Sodium",2017,"Journal of Materials Engineering and Performance",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030853860&doi=10.1007%2fs11665-017-2933-y&partnerID=40&md5=2b76532bef4505ed5719ea4cea96c7f4","Currently, stainless steel grade 316LN is the material of construction widely used for core catcher of sodium-cooled fast reactors. Design philosophy for core catcher demands its capability to withstand corium loading from whole core melt accidents. Towards this, two ceramic coatings were investigated for its application as a layer of sacrificial material on the top of core catcher to enhance its capability. Plasma-sprayed thermal barrier layer of alumina and partially stabilised zirconia (PSZ) with an intermediate bond coat of NiCrAlY are selected as candidate material and deposited over 316LN SS substrates and were tested for their suitability as thermal barrier layer for core catcher. Coated specimens were exposed to high-temperature thermite melt to simulate impingement of molten corium. Sodium compatibility of alumina and PSZ coatings were also investigated by exposing samples to molten sodium at 400 °C for 500 h. The surface morphology of high-temperature thermite melt-exposed samples and sodium-exposed samples was examined using scanning electron microscope. Phase identification of the exposed samples was carried out by x-ray diffraction technique. Observation from sodium exposure tests indicated that alumina coating offers better protection compared to PSZ coating. However, PSZ coating provided better protection against high-temperature melt exposure, as confirmed during thermite melt exposure test. © 2017 ASM International","316LN stainless steel; alumina coatings; molten sodium; PSZ coatings; thermite melt","Alumina; Aluminum alloys; C (programming language); Ceramic coatings; Ceramic materials; Characterization; Chromium alloys; Fast reactors; Inorganic coatings; Nickel alloys; Plasma spraying; Reactor cores; Scanning electron microscopy; Sodium; X ray diffraction; Yttrium alloys; Zirconia; 316ln stainless steels; Alumina coating; High temperature melts; Molten sodium; Sodium cooled fast reactor; Stainless steel grades; Thermites; X-ray diffraction techniques; Stainless steel",2-s2.0-85030853860
"Li Y., Li R., Lu Y., Chen X., Zhang S., Bu L., Wang Z.","Intelligent monitoring system design for circuit breaker operating circuit",2017,"Dianli Zidonghua Shebei/Electric Power Automation Equipment",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032725464&doi=10.16081%2fj.issn.1006-6047.2017.10.032&partnerID=40&md5=cc38c91e100a156f6ee46082051041d7","In order to monitor the state of tripping/closing circuit, platen and protection outlet contact in circuit breaker operating circuit, and give early fault warning circuit weak links to avoid improper operation of circuit breaker, an intelligent monitoring system for circuit breaker operating circuit is designed. The existing tripping/closing circuit is improved and the principles of component selection and parameter setting are given, so that the system can monitor and protect the whole working conditions of tripping/closing circuit. In order to monitor the state of platen and protection outlet contact of circuit breaker operating circuit in real time and alarm for misoperation of platen and faults of protection outlet contact, the inductive proximity switch and Hall voltage sensor are interacted and the specific installation positions of Hall voltage sensors are given. The MCU is used to process and upload the field information collected by sensors. LabVIEW is applied to write the background software interface to realize the functions of real-time status display, human-computer interaction, historical data storage, and fault warning. © 2017, Electric Power Automation Equipment Press. All right reserved.","Electric circuit breakers; Intelligent monitoring; Operating circuit; Platen; Protection outlet contact; Whole working condition","Computer programming languages; Digital storage; Human computer interaction; Inductive sensors; Monitoring; Timing circuits; Component selection; Inductive proximity switches; Installation position; Intelligent monitoring; Intelligent monitoring systems; Platen; Software interfaces; Whole working condition; Electric circuit breakers",2-s2.0-85032725464
"Farahani H.K., Ketabchi M., Zangeneh S.","Determination of Johnson–Cook Plasticity Model Parameters for Inconel718",2017,"Journal of Materials Engineering and Performance",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030845994&doi=10.1007%2fs11665-017-2990-2&partnerID=40&md5=01a425c84da394f4efedbbcf20d2b8cb","In order to simulate foreign object damage (FOD) phenomenon in aircraft high-pressure compressor blades made of a nickel-based super-alloy, Johnson–Cook (J–C) plasticity model was used. For prediction of material’s plastic behavior at temperature of 400 °C (working temperature of the blades) in the range of strain rates associated with the FOD phenomenon (in order of 106 s−1), material parameters of A, B, C, n and m for the J–C plasticity model had to be determined experimentally. Parameters of A, B and n with values of 1108, 699 MPa and 0.5189, respectively, were obtained from quasi-static tensile tests. Moreover, m was determined to be 1.2861, also through quasi-static tensile tests with a strain rate of 1 s−1 at three temperatures of 475, 550 and 625 °C. However, in order to determine C, firstly a steel ball was impacted on the surface of a flat specimen made of a precipitation-hardening alloy, and then, the impact site was 3D scanned to obtain the induced crater profile. Finally, the impact test (ballistic) was simulated using Abaqus, and a C value of 0.0085 was determined by comparing the actual crater profile with the one obtained from the simulation through a trial-and-error approach. © 2017 ASM International","foreign object damage; impact (ballistic); Inconel718; Johnson–Cook plasticity model","Age hardening; Alloy steel; Ballistics; Fighter aircraft; Nickel alloys; Plasticity; Precipitation (chemical); Strain rate; Tensile testing; Foreign object damage(FOD); Foreign-object damage; impact (ballistic); Inconel-718; Nickel- based superalloys; Plasticity model; Quasi-static tensile test; Trial-and-error approach; C (programming language)",2-s2.0-85030845994
"Deng J., Li Q.-W., Xiao Y., Shu C.-M., Zhang Y.-N.","Predictive models for thermal diffusivity and specific heat capacity of coals in Huainan mining area, China",2017,"Thermochimica Acta",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029455710&doi=10.1016%2fj.tca.2017.09.005&partnerID=40&md5=c323d6942127d2faed3580fc8e07008b","Thermal properties of coal govern the thermal transfer in coal mass. Taking coal samples from Huainan mining area as the objects, thermophysical parameters (thermal diffusivity, specific heat capacity, and thermal conductivity) were measured from 30 to 300 °C by LFA457 laser-flash apparatus. Predictive models for thermal diffusivity and specific heat capacity were then established. The results indicate that the thermal diffusivity of coal samples in Huainan mining area decreases with increased temperature, whereas specific heat capacity and thermal conductivity rise. The predictive models could accurately forecast the values and variations of thermophysical parameters for coal samples in Huainan mining area below 300 °C. Furthermore, the modeling method is suitable for the establishment of models for coal samples in other areas. These will be beneficial for the understanding of thermal transfer in coal mass and shorten the testing time in the laboratory. © 2017 Elsevier B.V.","Flash method; Predictive models; Temperature; Thermophysical parameters","C (programming language); Coal; Diffusion; Temperature; Thermal conductivity; Thermal diffusivity; Thermodynamic properties; Flash method; Huainan mining area; Increased temperature; Model method; Predictive models; Testing time; Thermal transfer; Thermo-physical parameters; Specific heat",2-s2.0-85029455710
"Dilshener T., Wermelinger M., Yu Y.","Locating bugs without looking back",2017,"Automated Software Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030839644&doi=10.1007%2fs10515-017-0226-1&partnerID=40&md5=1b5ceadecfc7a14021932c2109fdf1c5","Bug localisation is a core program comprehension task in software maintenance: given the observation of a bug, e.g. via a bug report, where is it located in the source code? Information retrieval (IR) approaches see the bug report as the query, and the source code files as the documents to be retrieved, ranked by relevance. Such approaches have the advantage of not requiring expensive static or dynamic analysis of the code. However, current state-of-the-art IR approaches rely on project history, in particular previously fixed bugs or previous versions of the source code. We present a novel approach that directly scores each current file against the given report, thus not requiring past code and reports. The scoring method is based on heuristics identified through manual inspection of a small sample of bug reports. We compare our approach to eight others, using their own five metrics on their own six open source projects. Out of 30 performance indicators, we improve 27 and equal 2. Over the projects analysed, on average we find one or more affected files in the top 10 ranked files for 76% of the bug reports. These results show the applicability of our approach to software projects without history. © 2017 The Author(s)","Bug localisation; Empirical study; Information retrieval","Codes (symbols); Computer programming languages; Heuristic methods; Information retrieval; Empirical studies; Localisation; Manual inspection; Open source projects; Performance indicators; Program comprehension; Software project; State of the art; Open source software",2-s2.0-85030839644
"Fan H., Zhu H., Liu Q., Shi Y., Sun C.","A Novel DAL Scheme with Shared-Locking for Semantic Conflict Prevention in Unconstrained Real-Time Collaborative Programming",2017,"IEEE Access",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031782539&doi=10.1109%2fACCESS.2017.2760914&partnerID=40&md5=a7f8b00bcaa3114d4b63004f33eb587c","Real-time collaborative programming allows a team of programmers to concurrently edit the shared source code document at the same time. To support semantic conflict prevention in real-time collaborative programming, a dependency-based automatic locking (DAL) approach was proposed in prior work, which automatically grants locks on source code regions with dependency relationships. The prior DAL scheme was devised under two assumptions that are not realistic, and together with other restrictions, they become serious problems in applying the DAL approach and techniques in real-world programming scenarios. To address the issues under the prior DAL scheme, this paper presents a novel DAL scheme with a shared-locking approach, which ensures the responsiveness, effectiveness and consistency of semantic conflict prevention in unconstrained real-time collaborative programming. Under the novel DAL scheme, programmers can perform concurrent editing operations with overlapping locking scopes and perform editing operations that may dynamically change the source code structure, while three types of shared-locking are allowed under well-defined circumstances with reasonable design rationales. In addition, we have presented major technical issues and solutions in realizing the scheme, which has been implemented in a research prototype. Experimental evaluations have confirmed the good performance of the novel DAL scheme and its supporting techniques. OAPA","dependency-based automatic locking (DAL); locking state update; real-time collaborative programming; responsiveness; semantic conflict prevention; shared-locking","Codes (symbols); Computer programming; Computer programming languages; Semantics; dependency-based automatic locking (DAL); locking state update; Real-time collaborative; responsiveness; Semantic conflict; shared-locking; Locks (fasteners)",2-s2.0-85031782539
"Hong S., Jeon Y., Lee N.","Distributed Uplink Reception in Cloud Radio Access Networks: A Linear Coding Approach",2017,"IEEE Transactions on Vehicular Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031802554&doi=10.1109%2fTVT.2017.2761398&partnerID=40&md5=9bfd79c747c7994a8328e723ad92761d","This paper considers an uplink cloud radio access network (C-RAN), in which K user terminals (UTs) send information messages to a cloud unit that consists of L antenna terminals (ATs) and a central processor, which are connected via digital error-free backhaul links with a finite-capacity. In this net- work, novel low-complexity detection methods are proposed by incorporating a lattice-quantize-and-forward (LQF) framework, which converts the C-RAN into an equivalent finite-field multiple- input-multiple-output (FF-MIMO) channel. In particular, under this equivalent FF single-input-multiple-output (FF-SIMO) channel, an optimal receive combining method is present by using a simple repetition code. In addition, using linear block codes, a low-complexity detection method is presented for the equivalent FF-MIMO channel. Finally, by simulations, it is demonstrated that the proposed detection method combined with the LQF framework provides high achievable sum rates for uplink C- RANs especially when a lot of low-cost ATs are deployed. IEEE","Cloud radio access network (C-RAN); finite-field multiple-input-multiple-output (FF-MIMO); lattice codes","Channel estimation; Codes (symbols); Complex networks; Digital radio; Feedback control; MIMO systems; Network coding; Optimal systems; Radio; Radio links; Telecommunication repeaters; Achievable sum rates; Finite fields; Information messages; Lattice codes; Low-complexity detections; Quantize and forwards; Radio access networks; Single input multiple outputs; C (programming language)",2-s2.0-85031802554
"Chen B., Xia S., Hao J., Fu F.","Constructions of Optimal Cyclic (r,&#x03B4;) Locally Repairable Codes",2017,"IEEE Transactions on Information Theory",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031814994&doi=10.1109%2fTIT.2017.2761120&partnerID=40&md5=e77feda9cc649cb31ed1db7cce4812ef","A code is said to be an r-local locally repairable code (LRC) if each of its coordinates can be repaired by accessing at most r other coordinates. When some of the r coordinates are also erased, the r-local LRC can not accomplish the local repair, which leads to the concept of (r,&#x03B4;)-locality. A q-ary &#x005B;n,k&#x005D; linear code C is said to have (r,&#x03B4;)-locality (&#x03B4;&#x2265;2) if for each coordinate i, there exists a punctured subcode of C with support containing i, whose length is at most r&#x002B;&#x03B4;&#x2013;1, and whose minimum distance is at least &#x03B4;. The (r,&#x03B4;)-LRC can tolerate &#x03B4;&#x2013;1 erasures in every local code (i.e., punctured subcode), which degenerates to an r-local LRC when &#x03B4;&#x0003D;2. A q-ary (r,&#x03B4;) LRC is called optimal if it meets the Singleton-like bound for (r,&#x03B4;)-LRCs. A class of optimal q-ary cyclic r-local LRCs with lengths n &#x2502; q &#x2013; 1 were constructed by Tamo, Barg, Goparaju and Calderbank based on the q-ary Reed-Solomon codes. In this paper, we construct a class of optimal q-ary cyclic (r,&#x03B4;)-LRCs (&#x03B4;&#x2265;2) with length n &#x2502; q &#x2013; 1, which generalizes the results of Tamo et al. Moreover, we construct a new class of optimal q-ary cyclic r-local LRCs with lengths n &#x2502; q &#x002B; 1 and a new class of optimal q-ary cyclic (r,&#x03B4;)-LRCs (&#x03B4;&#x2265;2) with lengths n &#x2502; q &#x002B; 1. The constructed optimal LRCs with length n &#x0003D; q&#x002B;1 have the best-known length for a given finite field with size q when the minimum distance is larger than 4. IEEE","Distributed storage; locally repairable codes; maximum distance separable (MDS) codes; optimal cyclic LRCs; Singleton-like bounds","Codes (symbols); Reed-Solomon codes; Distributed storage; locally repairable codes; Maximum distance separable code; optimal cyclic LRCs; Singleton-like bounds; C (programming language)",2-s2.0-85031814994
"Pastore V.P., Godjoski A., Martinoia S., Massobrio P.","SpiCoDyn: A Toolbox for the Analysis of Neuronal Network Dynamics and Connectivity from Multi-Site Spike Signal Recordings",2017,"Neuroinformatics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030692874&doi=10.1007%2fs12021-017-9343-z&partnerID=40&md5=3d0b79693c574dd8fadfede58e514239","We implemented an automated and efficient open-source software for the analysis of multi-site neuronal spike signals. The software package, named SpiCoDyn, has been developed as a standalone windows GUI application, using C# programming language with Microsoft Visual Studio based on .NET framework 4.5 development environment. Accepted input data formats are HDF5, level 5 MAT and text files, containing recorded or generated time series spike signals data. SpiCoDyn processes such electrophysiological signals focusing on: spiking and bursting dynamics and functional-effective connectivity analysis. In particular, for inferring network connectivity, a new implementation of the transfer entropy method is presented dealing with multiple time delays (temporal extension) and with multiple binary patterns (high order extension). SpiCoDyn is specifically tailored to process data coming from different Multi-Electrode Arrays setups, guarantying, in those specific cases, automated processing. The optimized implementation of the Delayed Transfer Entropy and the High-Order Transfer Entropy algorithms, allows performing accurate and rapid analysis on multiple spike trains from thousands of electrodes. © 2017 Springer Science+Business Media, LLC","Connectivity; Multi-electrode arrays; Multi-threading; Neuronal networks; Spiking and bursting activity; Transfer entropy",,2-s2.0-85030692874
"Miura H., Ozawa S., Matsuura T., Yamada K., Nagata Y.","Proposed patient motion monitoring system using feature point tracking with a web camera",2017,"Australasian Physical and Engineering Sciences in Medicine",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030694296&doi=10.1007%2fs13246-017-0589-4&partnerID=40&md5=5de0caccfa8915d744a0e36cf8cccee2","Patient motion monitoring systems play an important role in providing accurate treatment dose delivery. We propose a system that utilizes a web camera (frame rate up to 30 fps, maximum resolution of 640 × 480 pixels) and an in-house image processing software (developed using Microsoft Visual C++ and OpenCV). This system is simple to use and convenient to set up. The pyramidal Lucas–Kanade method was applied to calculate motions for each feature point by analysing two consecutive frames. The image processing software employs a color scheme where the defined feature points are blue under stable (no movement) conditions and turn red along with a warning message and an audio signal (beeping alarm) for large patient movements. The initial position of the marker was used by the program to determine the marker positions in all the frames. The software generates a text file that contains the calculated motion for each frame and saves it as a compressed audio video interleave (AVI) file. We proposed a patient motion monitoring system using a web camera, which is simple and convenient to set up, to increase the safety of treatment delivery. © 2017 Australasian College of Physical Scientists and Engineers in Medicine","Feature point tracking; Image processing; Patient motion management; Web camera","Audio signal processing; C++ (programming language); Cameras; Computer software; Image processing; Patient treatment; Feature point tracking; Image-processing software; Maximum resolution; Micro-soft visual c++; Monitoring system; Patient motions; Warning messages; Web camera; Monitoring",2-s2.0-85030694296
"Strüber D., Acreţoaie V., Plöger J.","Model clone detection for rule-based model transformation languages",2017,"Software and Systems Modeling",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030688144&doi=10.1007%2fs10270-017-0625-6&partnerID=40&md5=b5bbeb1a1976f0786487a31e29a5050f","Cloning is a convenient mechanism to enable reuse across and within software artifacts. On the downside, it is also a practice related to severe long-term maintainability impediments, thus generating a need to identify clones in affected artifacts. A large variety of clone detection techniques have been proposed for programming and modeling languages; yet no specific ones have emerged for model transformation languages. In this paper, we explore clone detection for rule-based model transformation languages, including graph-based ones, such as Henshin, and hybrid ones, such as ATL. We introduce use cases for such techniques in the context of constructive and analytical quality assurance, and a set of key requirements we derived from these use cases. To address these requirements, we describe our customization of existing model clone detection techniques: We consider eScan, an a-priori-based technique, ConQAT, a heuristic technique, and a hybrid technique based on a combination of eScan and ConQAT. We compare these techniques in a comprehensive experimental evaluation, based on three realistic Henshin rule sets, and a comprehensive body of examples from the ATL transformation zoo. Our results indicate that our customization of ConQAT enables the efficient detection of the considered clones, without sacrificing accuracy. With our contributions, we present the first evidence on the usefulness of model clone detection for the quality assurance of model transformations and pave the way for future research efforts at the intersection of model clone detection and model transformation. © 2017 Springer-Verlag GmbH Germany","ATL; Henshin; Model clone detection; Model transformation; Quality assurance","Computer software reusability; Graphic methods; Heuristic methods; Modeling languages; Quality assurance; Clone detection; Clone detection techniques; Experimental evaluation; Henshin; Heuristic techniques; Model transformation; Model transformation languages; Usefulness of models; Cloning",2-s2.0-85030688144
"Umenne P., Lam S., du J., Srinivasu V.V.","Josephson Effect in the Micron and Submicron YBCO Constrictions Fabricated Using the Femtosecond Laser Technique",2017,"Journal of Superconductivity and Novel Magnetism",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030681380&doi=10.1007%2fs10948-017-4371-3&partnerID=40&md5=19c5cfc3a7418efafff7a123c0509c8c","A femtosecond laser was used successfully to fabricate planar micron and submicron-sized constrictiontype Josephson junctions on YBa2Cu3O7−x thin films. A simple program using G-code (control systems) programming language was written to control the movement of the sample stage during the etching process. The constriction’s geometry was investigated using both atomic force microscopy (AFM) and scanning electron microscopy (SEM). Electrical transport measurements were performed at different temperatures. Shapiro steps were observed and analyzed. The micron-sized constriction shows a linear relationship for the measured critical current against the temperature which is consistent with the behavior of an S–s’–Stype Josephson junction where “S” stands for a bulk superconductive material that is untouched by the laser and “s”’ is superconducting material whose critical temperature is lower than the value of “S” In the case of the narrower submicronsized constriction, the measured critical current dependence with temperature shows an exponential decay, which is consistent with the behavior of the long S–N–Stype Josephson junction where “N” stands for a normal material. A model is proposed to describe the observed behavior by considering the effect of sample heating during the constriction’s fabrication. © 2017 Springer Science+Business Media, LLC","Femtosecond laser; Josephson junction; Micron constriction; Submicron constriction; YBa2Cu3O7−x thin films","Atomic force microscopy; Fabrication; Quantum optics; Scanning electron microscopy; Superconducting films; Thin films; Ultrashort pulses; Yttrium barium copper oxides; Critical temperatures; Current dependence; Electrical transport measurements; Josephson-junction; Linear relationships; Micron constriction; Submicron; YBa2Cu3O7; Josephson junction devices",2-s2.0-85030681380
"Claude F., Becherif M., Ramadan H.S.","Experimental validation for Li-ion battery modeling using Extended Kalman Filters",2017,"International Journal of Hydrogen Energy",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017592081&doi=10.1016%2fj.ijhydene.2017.01.123&partnerID=40&md5=111cb920c2a5f7f4fd9306a22ec43af9","The battery management systems (BMS) is an essential emerging component of both electric and hybrid electric vehicles (HEV) alongside with modern power systems. With the BMS integration, safe and reliable battery operation can be guaranteed through the accurate determination of the battery state of charge (SOC), its state of health (SOH) and the instantaneous available power. Therefore, undesired power fade and capacity loss problems can be avoided. Because of the electrochemical actions inside the battery, such emerging storage energy technology acts differently with operating and environment condition variations. Consequently, the SOC estimation mechanism should cope with the probable changes and uncertainties in the battery characteristics to ensure a permanent precise SOC determination over the battery lifetime. This paper aims to study and design the BMS for the Li-ion batteries. For this purpose, the system mathematical equations are presented. Then, the battery electrical model is developed. By imposing known charge/discharge current signals, all the parameters of such electrical model are identified using voltage drop measurements. Then, the extended kalman filter (EKF) methodology is employed to this nonlinear system to determine the most convenient battery SOC. This methodology is experimentally implemented using C language through micro-controller. The proposed BMS technique based on EKF is experimentally validated to determine the battery SOC values correlated to those reached by the Coulomb counting method with acceptable small errors. © 2017 Hydrogen Energy Publications LLC","Battery management system; Extended Kalman Filter; Hybrid electric vehicle; Li-ion battery; SOC","Bandpass filters; C (programming language); Charging (batteries); Electric batteries; Extended Kalman filters; Hybrid vehicles; Ions; Kalman filters; Lithium; Lithium-ion batteries; Secondary batteries; System-on-chip; Battery operation; Battery state of charge; Charge/discharge; Coulomb counting method; Electrical modeling; Environment conditions; Experimental validations; Mathematical equations; Battery management systems",2-s2.0-85017592081
"Evenbly G.","Hyperinvariant Tensor Networks and Holography",2017,"Physical Review Letters",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030768981&doi=10.1103%2fPhysRevLett.119.141602&partnerID=40&md5=c02399a167f265008ccd1aa32b088e19","We propose a new class of tensor network state as a model for the AdS/CFT correspondence and holography. This class is demonstrated to retain key features of the multiscale entanglement renormalization ansatz (MERA), in that they describe quantum states with algebraic correlation functions, have free variational parameters, and are efficiently contractible. Yet, unlike the MERA, they are built according to a uniform tiling of hyperbolic space, without inherent directionality or preferred locations in the holographic bulk, and thus circumvent key arguments made against the MERA as a model for AdS/CFT. Novel holographic features of this tensor network class are examined, such as an equivalence between the causal cones C(R) and the entanglement wedges E(R) of connected boundary regions R. © 2017 American Physical Society.",,"C (programming language); Equivalence classes; Holography; Quantum theory; Tensors; Algebraic correlations; Boundary regions; Hyperbolic spaces; Key feature; Network state; Quantum state; Renormalization; Variational parameters; Quantum entanglement",2-s2.0-85030768981
"Zhu Z., Lei Y., Zhu Y., Sarjoughian H.","Cognitive Behaviors Modeling Using UML Profile: Design and Experience",2017,"IEEE Access",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030777898&doi=10.1109%2fACCESS.2017.2760060&partnerID=40&md5=85976a3dd53f390e3787707b6114832a","To achieve model reuse in combat effectiveness simulation systems development, cognitive decision behaviors are usually implemented using a scripting language which is separate from the programming language used to implement simulation models. Therefore, it is desirable to establish a much better grounding for cognitive behaviors modeling. In the context of domain specific modeling, metamodeling from scratch for designing such a scripting language poses some limitations, among which is the issue of integrating various models that are represented by various customized languages with different syntax and semantics, together with a large expenditure of designing, implementing, and maintaining these languages and their supporting resources. Instead, UML Profile-based metamodeling is adopted, as a lightweight extension to capture the cognitive domain specific concepts, relationships, and constraints. Moreover, a unifying framework is proposed to guide the cognitive domain specific profiles design. Upon this framework, the development process is shown through constructing an anti-submarine tactical profile in combat effectiveness simulation systems domain and the feasibility of the domain specific language is illustrated with an armed escort scenario. OAPA","Computer languages; DSL; metamodeling; UML profile","Brain; Cognitive systems; Computer aided software engineering; Computer programming languages; Computer simulation languages; DSL; Problem oriented languages; Semantics; Combat effectiveness; Development process; Domain specific languages; Domain specific modeling; Metamodeling; Scripting languages; Supporting resources; Uml profiles; Modeling languages",2-s2.0-85030777898
"Šustek M., Marcaník M., Tomášek P., Úředníček Z.","DC motors and servo-motors controlled by Raspberry Pi 2B",2017,"MATEC Web of Conferences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032868307&doi=10.1051%2fmatecconf%2f201712502025&partnerID=40&md5=adee31876575dee30e2c8feb7246f5b6","The expanding capabilities of today's microcontrollers and other devices lead to an increased utilization of these technologies in diverse fields. The automation and issue of remote control of moving objects belong to these fields. In this project, a microcontroller Raspberry Pi 2B was chosen for controlling DC motors and servo-motors. This paper provides basic insight into issue of controlling DC motors and servo-motors, connection between Raspberry and other components on breadboard and programming syntaxes for controlling motors in Python programming language. © The Authors, published by EDP Sciences, 2017.",,"Computer circuits; Controllers; Electric machine control; Microcontrollers; Remote control; Diverse fields; Moving objects; Python programming language; DC motors",2-s2.0-85032868307
"Li C., Bi Y., Benezeth Y., Ginhac D., Yang F.","High-level synthesis for FPGAs: code optimization strategies for real-time image processing",2017,"Journal of Real-Time Image Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030537663&doi=10.1007%2fs11554-017-0722-3&partnerID=40&md5=d1328aec053a1c0edac9c905a73e0ade","High-level synthesis (HLS) is a potential solution to increase the productivity of FPGA-based real-time image processing development. It allows designers to reap the benefits of hardware implementation directly from the algorithm behaviors specified using C-like languages with high abstraction level. In order to close the performance gap between the manual and HLS-based FPGA designs, various code optimization forms are made available in today’s HLS tools. This paper proposes a HLS source code and directive manipulation strategy for real-time image processing by taking into account the applying order of different optimization forms. Experiment results demonstrate that our approach can improve more effectively the test implementations comparing to the other optimization strategies. © 2017 Springer-Verlag GmbH Germany","Code optimization; FPGA; High-level synthesis; Real-time image processing","C (programming language); Codes (symbols); Field programmable gate arrays (FPGA); Hardware; High level languages; High level synthesis; Abstraction level; Code optimization; Hardware implementations; Manipulation strategy; Optimization strategy; Performance gaps; Real-time image processing; Source codes; Image processing",2-s2.0-85030537663
"Qian Y., Khan I.A., Zhao D.","Electrocatalysts Derived from Metal–Organic Frameworks for Oxygen Reduction and Evolution Reactions in Aqueous Media",2017,"Small",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026430161&doi=10.1002%2fsmll.201701143&partnerID=40&md5=1f7e047a4b8880b5730ef6c7faab7f07","Electrochemical energy conversion and storage devices such as fuel cells and metal–air batteries have been extensively studied in recent decades for their excellent conversion efficiency, high energy capacity, and low environmental impact. However, sluggish kinetics of the oxygen-related reactions at air cathodes, i.e., oxygen reduction reaction (ORR) and oxygen evolution reaction (OER), are still worth improving. Noble metals such as platinum (Pt), iridium (Ir), ruthenium (Ru) and their oxides are considered as the benchmark ORR and OER electrocatalysts, but they are expensive and prone to be poisoned due to the fuel crossover effect, and may suffer from agglomeration and leaching after long-term usage. To mitigate these limits, it is highly desirable to design alternative ORR/OER electrocatalysts with prominent performance. Metal–organic frameworks (MOFs) are a class of porous crystalline materials consisting metal ions/clusters coordinated by organic ligands. Their crystalline structure, tunable pore size and high surface area afford them wide opportunities as catalytic materials. This Review covers MOF-derived ORR/OER catalysts in electrochemical energy conversion, with a focus on the different strategies of material design and preparation, such as composition control and nanostructure fabrication, to improve the activity and durability of MOF-derived electrocatalysts. © 2017 WILEY-VCH Verlag GmbH & Co. KGaA, Weinheim","electrocatalysts; fuel cells; metal–air batteries; metal–organic frameworks; oxygen reduction and evolution reactions","Crystalline materials; Electrocatalysts; Electrolysis; Electrolytic reduction; Energy conversion; Environmental impact; Fuel cells; Fuel storage; Iridium; Java programming language; Metals; Oxygen; Platinum; Reaction kinetics; Reduction; Ruthenium; Secondary batteries; Virtual storage; Electrochemical energy conversions; Metal organic framework; Metal-air battery; Metalorganic frameworks (MOFs); Nanostructure fabrication; Oxygen evolution reaction; Oxygen reduction and evolution reactions; Oxygen reduction reaction; Platinum metals",2-s2.0-85026430161
"Ghittorelli M., Kovacs-Vajna Z.M., Torricelli F.","Physical-Based Analytical Model of Amorphous InGaZnO TFTs Including Deep, Tail, and Free States",2017,"IEEE Transactions on Electron Devices",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030778943&doi=10.1109%2fTED.2017.2755098&partnerID=40&md5=825f813651a43cd9857e5edc7c658715","Amorphous InGaZnO (a-IGZO) is a candidate material for thin-film transistors (TFTs) owing to its large electron mobility and good uniformity over large area. a-IGZO TFTs drain current models are essential for further pushing both a-IGZO TFTs technology and circuit design. In this paper, we propose a simple physical-based and analytical model of the drain current of a-IGZO TFTs. The model is valid in both nondegenerate and degenerate conduction and it accounts for deep interface states, tail localized states, and free delocalized band states. The model is validated with the measurements of both coplanar and staggered a-IGZO TFTs. It provides key physical and material parameters of the transistor and, owing to its class C&#x221E; formulation, it can be straightforwardly implemented in circuit simulators. IEEE","Amorphous indium gallium zinc oxide thin-film transistors (a-IGZO TFTs); analytical model; charge transport; physical model; thin-film transistors (TFTs).","Amorphous films; Amorphous semiconductors; Analytical models; C (programming language); Charge transfer; Circuit simulation; Drain current; Indium; Integrated circuit manufacture; Interface states; Semiconducting indium compounds; Thin film circuits; Thin films; Transistors; Amorphousingazno (a-igzo); Candidate materials; Circuit simulators; Drain current models; Igzo tfts; Material parameter; Physical model; Thin-film transistor (TFTs); Thin film transistors",2-s2.0-85030778943
"Case A., Lutz J.H., Stull D.M.","Reachability problems for continuous chemical reaction networks",2017,"Natural Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030548923&doi=10.1007%2fs11047-017-9641-2&partnerID=40&md5=781616a2ca8b43ba0199cba2979eab99","Chemical reaction networks (CRNs) model the behavior of molecules in a well-mixed solution. The emerging field of molecular programming uses CRNs not only as a descriptive tool, but as a programming language for chemical computation. Recently, Chen, Doty and Soloveichik introduced rate-independent continuous CRNs (CCRNs) to study the chemical computation of continuous functions. A fundamental question for any CRN model is reachability, the question whether a given target state is reachable from a given start state via a sequence of reactions (a path) in the network. In this paper, we investigate CCRN-REACH, the reachability problem for rate-independent continuous chemical reaction networks. Our main theorem is that, for CCRNs, deciding reachability—and constructing a path if there is one—is computable in polynomial time. This contrasts sharply with the known exponential space hardness of the reachability problem for discrete CRNs. We also prove that the related problem Sub-CCRN-REACH, which asks about reachability in a CCRN using only a given number of its reactions, is NP-complete. © 2017 Springer Science+Business Media B.V.","Analysis of algorithms; Continuous chemical reaction networks; Reachability","Chemical reactions; Computation theory; Polynomial approximation; Problem oriented languages; Analysis of algorithms; Chemical computation; Chemical reaction networks; Continuous functions; Molecular programming; Rate independents; Reachability; Reachability problem; Chemical analysis; chemical reaction; hardness; human",2-s2.0-85030548923
"Lim C.K., Tan K.L., Yusran H., Suppramaniam V.","Comparison of L-system applications towards plant modelling, music rendering and score generation using visual language programming",2017,"AIP Conference Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031289048&doi=10.1063%2f1.5005419&partnerID=40&md5=48a739145ada5b6559c163d0752be65c","Visual language or visual representation has been used in the past few years in order to express the knowledge in graphic. One of the important graphical elements is fractal and L-Systems is a mathematic-based grammatical model for modelling cell development and plant topology. From the plant model, L-Systems can be interpreted as music sound and score. In this paper, LSound which is a Visual Language Programming (VLP) framework has been developed to model plant to music sound and generate music score and vice versa. The objectives of this research has three folds: (i) To expand the grammar dictionary of L-Systems music based on visual programming, (ii) To design and produce a user-friendly and icon based visual language framework typically for L-Systems musical score generation which helps the basic learners in musical field and (iii) To generate music score from plant models and vice versa using L-Systems method. This research undergoes a four phases methodology where the plant is first modelled, then the music is interpreted, followed by the output of music sound through MIDI and finally score is generated. LSound is technically compared to other existing applications in the aspects of the capability of modelling the plant, rendering the music and generating the sound. It has been found that LSound is a flexible framework in which the plant can be easily altered through arrow-based programming and the music score can be altered through the music symbols and notes. This work encourages non-experts to understand L-Systems and music hand-in-hand. © 2017 Author(s).",,,2-s2.0-85031289048
"Guerrero F.N., Spinelli E.M.","A simple encoding method for Sigma-Delta ADC based biopotential acquisition systems",2017,"Journal of Medical Engineering and Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030159280&doi=10.1080%2f03091902.2017.1366562&partnerID=40&md5=6575c7cbd5a49723734396b2c2f8a016","Sigma Delta analogue-to-digital converters allow acquiring the full dynamic range of biomedical signals at the electrodes, resulting in less complex hardware and increased measurement robustness. However, the increased data size per sample (typically 24 bits) demands the transmission of extremely large volumes of data across the isolation barrier, thus increasing power consumption on the patient side. This problem is accentuated when a large number of channels is used as in current 128–256 electrodes biopotential acquisition systems, that usually opt for an optic fibre link to the computer. An analogous problem occurs for simpler low-power acquisition platforms that transmit data through a wireless link to a computing platform. In this paper, a low-complexity encoding method is presented to decrease sample data size without losses, while preserving the full DC-coupled signal. The method achieved a 2.3 average compression ratio evaluated over an ECG and EMG signal bank acquired with equipment based on Sigma-Delta converters. It demands a very low processing load: a C language implementation is presented that resulted in an 110 clock cycles average execution on an 8-bit microcontroller. © 2017 Informa UK Limited, trading as Taylor & Francis Group.","biomedical signal; biopotential; dynamic range; ECG; EMG; encoding; lossless compression; Sigma Delta converter","Bioelectric phenomena; C (programming language); Electrocardiography; Electrodes; Encoding (symbols); Signal encoding; Biomedical signal; Biopotentials; Dynamic range; Lossless compression; Sigma-delta converters; Analog to digital conversion",2-s2.0-85030159280
"Xiao X., Li Y., Wang X.","Configuration Analysis and Design of a Multidimensional Tele-operator Based on a 3-P(4S) Parallel Mechanism",2017,"Journal of Intelligent and Robotic Systems: Theory and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030326854&doi=10.1007%2fs10846-017-0663-x&partnerID=40&md5=d48c7a2b50c7c052b4b9adad90b6fe2a","Based on configuration analysis, different types of 3-P(4S) parallel mechanisms are designed and introduced in this paper. Application issues of parallel mechanisms are discussed and a double 3-P(4S) mechanism-based tele-operator is illustrated. Inverse and forward kinematics of the single 3-P(4S) parallel mechanism are derived and solved via MATLAB software; based on it, the workspace of the 3-P(4S) parallel mechanism is investigated. The relationship between the distribution angle of kinematic chain and volume of the workspace is derived, and the shapes of the workspace of single and double 3-P(4S) parallel mechanisms are plotted. A prototype is developed and an interactive simulation system is established based on SolidWorks and LabVIEW software. Testing results indicate that the proposed tele-operator can well perform tele-operation tasks. This research work lays a good basis for performances evaluation and parameter optimization of 3-P(4S) mechanisms. Besides, it provides new ideas for the applications of parallel mechanisms. © 2017 Springer Science+Business Media B.V.","Configuration analysis; Interactive control; Parallel mechanism; Tele-operator","Computer programming languages; Computer software; Kinematics; MATLAB; Software prototyping; Configuration analysis; Interactive control; Interactive simulation systems; Lab-view softwares; Parallel mechanisms; Parameter optimization; Performances evaluation; Tele-operator; Mechanisms",2-s2.0-85030326854
"Lim D.-W., Yoon J., Eoh J., Lee H.-Y., Jeong J.-Y.","Design methodology for insulating and cooling of a small modular reactor head by high temperature structural-thermal-fluid analysis",2017,"Journal of Nuclear Science and Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021817371&doi=10.1080%2f00223131.2017.1344581&partnerID=40&md5=5c57b3c1d57ee7a6ccf39d6fd2bfc03a","The design of a sodium-cooled fast reactor (SFR) head can be complicated due to its shape and functions. The head is a component placed in the pressure boundary to shield nuclear radioactive radiation. At the same time, it needs to seal the reactor vessel, support penetrating components, and minimize heat losses. This paper presents a new insulating and cooling design concept of a small SFR head. For a new design, this study shows a comprehensive design approach considering fluid-thermal-structural computations. The interactive design approach refers to dependent simulation steps of three-dimensional (3D) thermal-structural, one-dimensional (1D) heat-transfer, and 3D computational fluid dynamics (CFD) analysis. This multi-domain approach was applied to the head of the large sodium integral effect test facility called sodium test loop for safety simulation and assessment (STELLA-2). And the STELLA-2 head design was proposed as a thick plate with a sandwich type of insulation, cooling the perimeter annulus of the round head-top surface. For the structural design, the ASME design code was utilized, and the head temperature of 346 °C was calculated as its initial design temperature target. In an axial heat-transfer mode from the in-vessel to the head, a 1D finite element model gave 57 and 75 mm insulation thicknesses with a thermal conductivity of 0.07 W/m/K. The cooling effectiveness of the proposed head design was shown through a commercial CFD package. © 2017 Atomic Energy Society of Japan. All rights reserved.","design by analysis; fluid-thermal-structural coupled analysis; large sodium test facility; small modular reactor; Small reactor head design; sodium-cooled fast reactor; top shield","C (programming language); Computational fluid dynamics; Cooling; Fast reactors; Heat transfer; Insulation; Nuclear reactors; Small nuclear reactors; Sodium; Structural analysis; Structural design; Test facilities; Thermal conductivity; Thermal insulation; Coupled analysis; Design by analysis; Small modular reactors; Small reactor; Sodium cooled fast reactor; Top shields; Finite element method",2-s2.0-85021817371
"Lutz A., Schick B., Holzmann H., Kochem M., Meyer-Tuve H., Lange O., Mao Y., Tosolin G.","Simulation methods supporting homologation of Electronic Stability Control in vehicle variants",2017,"Vehicle System Dynamics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020224356&doi=10.1080%2f00423114.2017.1322705&partnerID=40&md5=d03591f4450776d2552e32f46e5ed2f8","Vehicle simulation has a long tradition in the automotive industry as a powerful supplement to physical vehicle testing. In the field of Electronic Stability Control (ESC) system, the simulation process has been well established to support the ESC development and application by suppliers and Original Equipment Manufacturers (OEMs). The latest regulation of the United Nations Economic Commission for Europe UN/ECE-R 13 allows also for simulation-based homologation. This extends the usage of simulation from ESC development to homologation. This paper gives an overview of simulation methods, as well as processes and tools used for the homologation of ESC in vehicle variants. The paper first describes the generic homologation process according to the European Regulation (UN/ECE-R 13H, UN/ECE-R 13/11) and U.S. Federal Motor Vehicle Safety Standard (FMVSS 126). Subsequently the ESC system is explained as well as the generic application and release process at the supplier and OEM side. Coming up with the simulation methods, the ESC development and application process needs to be adapted for the virtual vehicles. The simulation environment, consisting of vehicle model, ESC model and simulation platform, is explained in detail with some exemplary use-cases. In the final section, examples of simulation-based ESC homologation in vehicle variants are shown for passenger cars, light trucks, heavy trucks and trailers. This paper is targeted to give a state-of-the-art account of the simulation methods supporting the homologation of ESC systems in vehicle variants. However, the described approach and the lessons learned can be used as reference in future for an extended usage of simulation-supported releases of the ESC system up to the development and release of driver assistance systems. Abbreviations: ABS: Anti-lock braking system; ADR: Australian design rules; ALB: Automatic load-dependent brake force controller; AMEVSC: Alternative method to assess the electronic vehicle stability control system; APP: Application; BSC: Brake slip controller; CAE: Computer-aided engineering; CAN: Controller area network; CAT: Category; CoG: Centre of gravity; DIN: Deutsches Institut für Normung (German Institute for Standards); EB+: Trademark of Haldex; EBD: Electronic brake force distribution; EBS: Electronic brake system; ECU: Electronic control unit; ESC: Electronic stability control; ECVWTA: European Community Whole Vehicle Type Approval; FMVSS: Federal motor vehicle safety standards; GPS: Global positioning system; GRRF: Groupe de travail en matiere de roulement et de freinage (Working Party on Braking and Running Gear); HiL: Hardware-in-the-Loop; HSRI: Highway Safety Research Institute; K&C: Kinematic and compliant (KnC); MBS: Multibody systems; MPV: Multipurpose vehicle; NHTSA: National Highway Traffic Safety Administration; OEM: Original equipment manufacturer; SiL: Software-in-the-Loop; ST: Summer tyres; STM: Single track model; StVO: Straßenverkehrsordnung (Government Highway Regulations); SUV: Sports utility vehicle; SW: Software; SwD: Sine with dwell manoeuvre; TC: Threshold consumption value; TCS: Traction control system; TRIAS: Test Requirements and Instructions for Automobile Standards; UN/ECE: United Nations Economic Commission for Europe; VAF: Value-added function; VDC: Vehicle dynamics controller; VTC: Vehicle test catalogue; WT: Winter tyres. © 2017 Informa UK Limited, trading as Taylor & Francis Group.","Electronic Stability Control; ESC; FMVSS126; Homologation; simulation; sine with dwell; UN/ECE-R 13; vehicle dynamics","Anti-lock braking systems; Application programs; Automobile drivers; Automobile electronic equipment; Automobile hardware; Automobile manufacture; Automobiles; Automotive industry; Braking; C (programming language); Computer aided engineering; Computer aided software engineering; Computer control systems; Computer hardware; Control system stability; Control system synthesis; Control systems; Global positioning system; Highway accidents; Highway engineering; Highway traffic control; Light trailers; Manufacture; Pumping plants; Safety engineering; Software testing; Stability; Standards; System stability; Traction control; Transportation; Trucks; Vehicles; Electronic stability control; FMVSS126; Homologation; simulation; sine with dwell; UN/ECE-R 13; Vehicle dynamics; Controllers",2-s2.0-85020224356
"Dai W., du Y., Jin H., Qiang W., Zou D., Xu S., Liu Z.","RollSec: Automatically Secure Software States Against General Rollback",2017,"International Journal of Parallel Programming",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030313942&doi=10.1007%2fs10766-017-0523-0&partnerID=40&md5=1cd278dd39d7e7524b8d872193e2b08a","The rollback mechanism is critical in crash recovery and debugging, but its security problems have not been adequately addressed. This is justified by the fact that existing solutions always require modifications on target software or only work for specific scenarios. As a consequence, rollback is either neglected or restricted or prohibited in existing systems. In this paper, we systematically characterize security threats of rollback as abnormal states of non-deterministic variables and resumed program points caused by rollback. Based on this, we propose RollSec (for Rollback Security), which provides general measurements including state extracting, recording, and compensating, to maintain correctness of these abnormal states for eliminating rollback threats. RollSec can automatically extract these states based on language-independent information of software as protection targets, which will be monitored during run-time, and compensated to correct states on each rollback without requiring extra modifications or supports of specific architectures. At last, we implement a prototype of RollSec to verify its effectiveness, and conduct performance evaluations which demonstrate that only acceptable overhead is introduced. © 2017 Springer Science+Business Media, LLC","Automated protection; General rollback problem; Non-deterministic state; Rollback security","Software engineering; Automated protection; Crash recoveries; General rollback problem; Language independents; Non-deterministic state; Rollback security; Security problems; Security threats; Parallel programming",2-s2.0-85030313942
"Huang K., Hu B., Chen L., Knoll A., Wang Z.","ADAS on COTS with OpenCL: A Case Study with Lane Detection",2017,"IEEE Transactions on Computers",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030750537&doi=10.1109%2fTC.2017.2759203&partnerID=40&md5=789bb35c570d633220632b0edc9b2edc","The concept of autonomous cars is driving a boost for car electronics and the size of automotive electronics market is foreseen to double by 2025. How to benefit from this boost is an interesting question. This article presents a case study to test the feasibility of using OpenCL as the programming language and COTS components as the underlying computing platforms for ADAS development. For representative ADAS applications, a scalable lane detection is developed that can tune the trade-off between detection accuracy and speed. Our OpenCL implementation is tested on 14 video streams from different data-sets with different road scenarios on 5 COTS platforms. We demonstrate that the COTS platforms can provide more than sufficient computing power for the lane detection in the meanwhile our OpenCL implementation can exploit the massive parallelism provided by the COTS platforms. IEEE","Advanced Driver Assistance Systems (ADAS); Automobiles; Automotive engineering; Commercial of the shelf (COTS); Field programmable gate arrays; FPGA; GPU; Graphics processing units; Hardware; OpenCL; Safety; Standards","Accident prevention; Automobile drivers; Automobile hardware; Automobiles; Automotive engineering; Computer graphics; Computer hardware; Economic and social effects; Field programmable gate arrays (FPGA); Graphics processing unit; Program processors; Software packages; Standards; Car electronics; Commercial of the shelves; Computing platform; Computing power; COTS component; Detection accuracy; Massive parallelism; OpenCL; Advanced driver assistance systems",2-s2.0-85030750537
"Rahman N.H.A., Abdullah N.A., Hamid I.R.A., Wen C.C., Jelani M.S.R.M.","A CCTV system with SMS alert (CMDSA): An implementation of pixel processing algorithm for motion detection",2017,"AIP Conference Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031301790&doi=10.1063%2f1.5005346&partnerID=40&md5=c400f1270123c58e2e8cd5d468d9d60d","Closed-Circuit TV (CCTV) system is one of the technologies in surveillance field to solve the problem of detection and monitoring by providing extra features such as email alert or motion detection. However, detecting and alerting the admin on CCTV system may complicate due to the complexity to integrate the main program with an external Application Programming Interface (API). In this study, pixel processing algorithm is applied due to its efficiency and SMS alert is added as an alternative solution for users who opted out email alert system or have no Internet connection. A CCTV system with SMS alert (CMDSA) was developed using evolutionary prototyping methodology. The system interface was implemented using Microsoft Visual Studio while the backend components, which are database and coding, were implemented on SQLite database and C# programming language, respectively. The main modules of CMDSA are motion detection, capturing and saving video, image processing and Short Message Service (SMS) alert functions. Subsequently, the system is able to reduce the processing time making the detection process become faster, reduce the space and memory used to run the program and alerting the system admin instantly. © 2017 Author(s).",,,2-s2.0-85031301790
"An S., Feng X., Dai Y., Bo H., Wang X., Li M., Woo J.Z., Liang X., Guo C., Liu C.X., Wei L.","Development and evaluation of a speech-generating AAC mobile app for minimally verbal children with autism spectrum disorder in Mainland China",2017,"Molecular Autism",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030323450&doi=10.1186%2fs13229-017-0165-5&partnerID=40&md5=bbd5946c4f8962ca497167ec9c5f439b","Background: Mobile touchscreen devices are currently being used as speech-generating devices (SGDs) and have been shown to promote the communication skills, particularly the requesting skills of children with autism spectrum disorders (ASD) who have limited spoken language. However, no augmentative and alternative communication (AAC) mobile app has been developed and evaluated in the Chinese language in Mainland China. Methods: We developed an AAC mobile app, which is the first in Mainland China, to our knowledge, named Yuudee (Chinese name é (xiaoyudi)). Yuudee was developed using the Objective-C and Java programming languages. A five-phase training protocol for making requests using Yuudee was developed based on the Picture Exchange Communication System. We trained ten minimally verbal children with ASD to make requests using Yuudee and evaluated the effectiveness of the training. Results: Yuudee has a built-in library of over 400 pictures with corresponding spoken phrases that are divided into 39 categories ranging from making simple requests to expressing emotions. An additional important feature of Yuudee is its customization functions that allow a parent or trainer to easily select pictures and phrases to display, create new pictures and phrases, and change the layouts and orders of the pictures to fit the personal needs of each child. Yuudee is freely available in an iOS version from the iTunes App Store (https://itunes.apple.com/cn/app/xiao-yu-di/id794832934?mt=8) and in an Android version from Google Play (https://play.google.com/store/apps/details?id=com.supersuperstar.yuudee.vue) and domestic Chinese Android App stores. Three consecutive unprompted successful responses, which were defined as an initial training success, were achieved in at least three of the five phases for all ten of the evaluated children. The accuracy rate of a given phase was calculated for each child who achieved three consecutive unprompted successful responses in the phase. Seven children achieved at least 50% accuracy in at least two of the five phases. The other three children achieved at least 50% accuracy in only one phase. Two children achieved at least 50% accuracy in all of the phases in which they were trained. Conclusions: Our data suggest that Yuudee is a useful tool for helping minimally verbal children with ASD make requests. © 2017 The Author(s).","App; Augmentative and alternative communication; Development; Mainland China; Training effectiveness",,2-s2.0-85030323450
"Catalan T., Horita V.","C1-Genericity of symplectic diffeomorphisms and lower bounds for topological entropy",2017,"Dynamical Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010661859&doi=10.1080%2f14689367.2017.1278744&partnerID=40&md5=ece58dda8c5b8cdf3d2d2406a7778335","There is a C1-residual (Baire second class) subset R of symplectic diffeomorphisms on 2d-dimensional manifold, d ≥ 1, such that for every non-Anosov f in R, its topological entropy is lower bounded by the supremum of the Lyapunov exponents of their hyperbolic periodic points in the unbreakable central sub-bundle (i.e. central direction with no dominated splitting) of f. The previous result deals with the fact that for f in a C1-residual set R of symplectic diffeomorphisms (containing R) satisfies a trichotomy: or f is Anosov or f is robustly transitive partially hyperbolic with unbreakable centre of dimension 2m, 0 &lt; m &lt; d, or f has totally elliptic periodic points dense on M. In the second case, we also show the existence of a sequence of m-elliptic periodic points converging to M. Indeed, R contains an C1 open and dense subset of symplectic diffeomorphisms. © 2017 Informa UK Limited, trading as Taylor & Francis Group.","elliptic periodic points; generic properties; homoclinic tangency; Partially hyperbolic symplectic systems; topological entropy","Entropy; Lyapunov methods; Topology; Generic properties; Homoclinic tangencies; Periodic points; Symplectic; Topological entropy; C (programming language)",2-s2.0-85010661859
"Yue B., Han F., Wu J., Wang Y., Zhang C., Fang X., Qi X., Bai Y., Chen H.","Combined Haplotypes of CaSR Gene Sequence Variants and Their Associations with Growth Traits in Cattle",2017,"Animal Biotechnology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014524394&doi=10.1080%2f10495398.2016.1271805&partnerID=40&md5=b97ef8708bc5670e348cb72dbbf138d1","The calcium-sensing receptor (CaSR) is a Class C G-protein coupled receptor that regulates food intake and assimilation. However, studies on the relationship between CaSR gene and growth traits in cattle are deficient. The aim of this study was to examine the association of the CaSR polymorphism with growth traits in cattle breeds. Four novel single nucleotide polymorphisms (SNPs) and one previously reported SNP (NC_007299.5: g.67630865T>C, 67638409G>C, 67660395G>C, 67661546C>G, and 67661892A>C) were identified in the bovine CaSR gene using DNA sequencing and PCR-SSCP methods in 520 individuals from three representative breeds. The three SNP P4_2, P7_1, and P7_4 in LX, QC, and JX cattle populations belonged to intermediate genetic diversity (0.25 < PIC < 0.5). In addition, we evaluated the haplotype frequency and linkage disequilibrium coefficient of five sequence variants in the three cattle breeds. LD and haplotype structure of CaSR were different between breeds. LD analysis showed that the P4_2 and P7_4 loci were in complete LD in JX cattle population (r2 = 0.99 and D′ = 1). Only 11 haplotypes were listed except for those with a frequency of <0.03. Hap1 (-TGGGC-) had the highest haplotype frequencies in LX (27.30%), Hap6(-TGGCC-) had the highest haplotype frequencies in QC (21.70%) and JX (32.30%). Association analysis indicated that P2, P4_2, and P7_4 loci were all significantly associated with growth traits and combined genotype TTGCGC was highly significantly associated with Chest circumference and body weight than the other genotype in JX cattle population. The results of this study suggest that the CaSR gene possibly is a strong candidate gene that affects growth traits in the Chinese cattle breeding program. © 2017 Taylor & Francis.","CaSR gene; cattle; combined haplotype; growth traits; sequence variants","DNA sequences; Gene encoding; Genes; Polymerase chain reaction; Population statistics; Calcium-sensing receptors; cattle; G protein coupled receptors; Growth traits; Haplotypes; Linkage disequilibrium; Sequence variants; Single nucleotide polymorphisms; C (programming language)",2-s2.0-85014524394
"Liu X., Jia W., Xu G., Zhang Y., Fu Y.","Selective Hydrodeoxygenation of Lignin-Derived Phenols to Cyclohexanols over Co-Based Catalysts",2017,"ACS Sustainable Chemistry and Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030482843&doi=10.1021%2facssuschemeng.7b01047&partnerID=40&md5=2c3e002cc0d6c468b4ad63c66a9843b1","Cyclohexanols are important feedstock for polymers, spices, and medicines production in industry. In this work, a series of cobalt-based catalysts with different supports were prepared and used to catalyze lignin-derived phenols to cyclohexanols. Among the catalysts, Co/TiO2 showed the best hydrodeoxygenation (HDO) activity. An equivalent of propylcyclohexanol (&gt;99.9%) was achieved under 1 MPa H2, 200 °C for 2 h. According to the characterization results of transmission electron microscopy (TEM), Brunauer-Emmett-Teller (BET) surface area analysis, powder X-ray diffraction (XRD), X-ray photoelectron spectroscopy (XPS), hydrogen temperature-programmed reduction (H2-TPR), hydrogen temperature-programmed desorption (H2-TPD) and NH3-TPD, the particle size and dispersion of Co could have important influence on catalytic activity. For Co/TiO2, the SMSI effect may significantly affect the catalytic activity. The influences of different temperature, H2 pressure and reaction time on the eugenol conversion by Co/TiO2 were explored. 99% yield of propylcyclohexanol could even be obtained under 0.4 MPa H2, 180 °C for 8 h. This should be the mildest condition that has been reported for HDO of eugenol to propylcyclohexanol catalyzed by non-noble metal catalyst. On the basis the mechanism and substrates extension studies, all the Co-based catalysts selected in this study showed high activity to cleave the Caryl-OCH3 bond before the hydrogenation of the aromatic ring when the -OCH3 group substituted at ortho-position. © 2017 American Chemical Society.","Biomass; Cobalt; Cyclohexanols; Hydrodeoxygenation; Phenols","Biomass; C (programming language); Catalyst activity; Catalysts; Cobalt; High resolution transmission electron microscopy; Lignin; Particle size; Particle size analysis; Phenols; Precious metals; Temperature programmed desorption; Transmission electron microscopy; X ray diffraction; Brunauer-emmett-teller surface areas; Cobalt-based catalysts; Cyclohexanols; Hydrodeoxygenation; Hydrogen temperature programmed desorption; Hydrogen temperature programmed reduction; Non-noble metal catalysts; Powder X ray diffraction; X ray photoelectron spectroscopy; Catalysts; Deoxygenation; Lignins; Phenols; Transmission Electron Microscopy; X Ray Diffraction",2-s2.0-85030482843
"Brown N.F., Pradeep S.A., Agnihotri S., Pilla S.","The Power of Processing: Creating High Strength Foams from Epoxidized Pine Oil",2017,"ACS Sustainable Chemistry and Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030450961&doi=10.1021%2facssuschemeng.7b01253&partnerID=40&md5=42da906263d9c7fddd3be9995c51791d","The present work reports on the synthesis of foams from epoxidized pine oil (EPO) with polymethylhydrosiloxane (PMHS) used as a foaming agent. The effect of two different processing methods involving modifications of curing agent and foaming agent addition timings was also analyzed. Resultant foams were characterized via density, mechanical and thermal testing, and microstructure. Foams produced using a modified processing method displayed properties that deviate from the Ashby-Gibson models, resulting in superior compressive strengths over many synthetic and biobased epoxy foams, ranging from 6.1 to 11.3 MPa. The impact of the method on cellular microstructure was also significant, with 20- and 30-fold increase in cell density from the original processing method for the same levels of foaming agent in both the methods. Glass transition temperatures of the foams ranged from 61.8 to 97 °C, higher than those of many foams in their class. © 2017 American Chemical Society.","Ashby-Gibson; Biobased; Epoxy; Foams; Pine oil; PMHS; Polymethylhydrosiloxane","C (programming language); Compressive strength; Foams; Glass transition; Microstructure; Ashby-Gibson; Bio-based; Epoxy; Pine oil; PMHS; Polymethylhydrosiloxanes; Processing",2-s2.0-85030450961
"Bjørner N., Canini M., Sultana N.","Report on networking and programming languages 2017",2017,"Computer Communication Review",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032746113&doi=10.1145%2f3155055.3155061&partnerID=40&md5=5a357147d05c132ef81ec9490e0e8764","The third workshop on Networking and Programming Lan-guages, NetPL 2017, was held in conjunction with SIG-COMM 2017. The workshop series attracts invited speakers from academia and industry and a selection of contributed abstracts for short presentations. NetPL brings together re-searchers from the networking community and researchers from the programming languages and verification communities. The workshop series is a timely forum for exciting trends, technological and scientific advances in the intersection of these communities. We describe some of the high-lights from the invited talks through the lens of three trends: Advances in network machine architectures, network programming abstractions, and network verification. NetPL included five invited speakers, four from academia, and one from industry. The program contained six contributed talks out of eight submitted for presentation. The workshop organizers reviewed the abstracts for quality and scope. A total of 42 registrations were received and the attendance occupied the lecture room to the brink. Slides and abstracts from all talks are available from the workshop home page.1 Videos of the presentations are available in the NetPL YouTube channel.2.","Network verification; Programming languages; Software defined networking","Abstracting; Computer programming languages; Network architecture; Software defined networking; Verification; High lights; In networks; Invited talk; Network programming; Networking community; Scientific advances; Through the lens; YouTube; Computer programming",2-s2.0-85032746113
"Swacha J.","Exercise solution check specification language for interactive programming learning environments",2017,"OpenAccess Series in Informatics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032644357&doi=10.4230%2fOASIcs.SLATE.2017.6&partnerID=40&md5=88aca9bc812d1ebee482c10424517c8c","Automatic checking of the correctness of students’ solutions of programming exercises for generating appropriate feedback is a necessary component of interactive programming learning environments. Although there are multiple ways of specifying such a check, ranging from mere string patterns to code written in general-purpose programming language, they all have their deficiencies, with the check specification being too verbose, too complicated, di cult to reuse, or very limited in its expressive capabilities. In this paper, a new language designed especially for this purpose is described. It provides both extension and replacement for RegEx-based pattern specification so that checks typical for programming exercise verification can be expressed in a concise and highly-readable manner. © Jakub Swacha","Automatic programming exercise solution verification; RegEx alternative; RegEx extension; Source code pattern specification","Automatic programming; Computer aided instruction; Pattern matching; Slate; Specification languages; Specifications; General-purpose programming language; Pattern specifications; Programming exercise; Programming learning; RegEx alternative; RegEx extension; Solution verification; Source codes; Education",2-s2.0-85032644357
"Ray B., Posnett D., Devanbu P., Filkov V.","A large-scale study of programming languages and code quality in GitHub",2017,"Communications of the ACM",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030219489&doi=10.1145%2f3126905&partnerID=40&md5=73b3cd7027988099aeb13670d4edfbc9","What is the effect of programming languages on software quality? This question has been a topic of much debate for a very long time. In this study, we gather a very large data set from GitHub (728 projects, 63 million SLOC, 29,000 authors,1.5 million commits, in 17 languages) in an attempt to shed some empirical light on this question. This reasonably large sample size allows us to use a mixed-methods approach,combining multiple regression modeling with visualization and text analytics, to study the effect of language features such as static versus dynamic typing and allowing versus disallowing type confusion on software quality. By triangulating findings from different methods, and controlling for confounding effects such as team size, project size, and project history, we report that language design does have a significant,but modest effect on software quality. Most notably,it does appear that disallowing type confusion is modestly better than allowing it, and among functional languages, static typing is also somewhat better than dynamic typing. We also find that functional languages are somewhat better than procedural languages. It is worth noting that these modest effects arising from language design are overwhelmingly dominated by the process factors such as project size,team size, and commit size. However, we caution the reader that even these modest effects might quite possibly be due to other, intangible process factors, for example, the preference of certain personality types for functional, static languages that disallow type confusion.",,"Computer software selection and evaluation; Functional languages; Language features; Large-scale studies; Multiple regression model; Personality types; Procedural languages; Software Quality; Very large datum; Modeling languages",2-s2.0-85030219489
"Valverde S.","Visualizing the evolution of programming languages",2017,"Leonardo",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030558484&doi=10.1162%2fLEON_a_01280&partnerID=40&md5=bafcbe7e23d806c4dfe91f485aa21cee","The study of cultural evolutionary patterns, particularly when dealing with artifacts, is constrained by a lack of powerful quantitative methods. In this work, the project team shows that a simple network approach can reconstruct phylogenetic trees from existing databases of recorded artifact influences. They created novel network tools to visualize the large-scale evolution of programming languages. The simple idea of trees of influence can be extended to many other fields beyond the study of programming languages, offering a new theoretical framework to rigorously quantify cultural and technological evolution. © 2017 ISAST.",,,2-s2.0-85030558484
"Wang X., Tian C., Duan Z., Zhao L.","MSVL: a typed language for temporal logic programming",2017,"Frontiers of Computer Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019726907&doi=10.1007%2fs11704-016-6059-4&partnerID=40&md5=07d7fd4745faa8c70046cc830f8cd49e","The development of types is an important but challenging issue in temporal logic programming. In this paper, we investigate how to formalize and implement types in the temporal logic programming language MSVL, which is an executable subset of projection temporal logic (PTL). Specifically, we extendMSVL with a few groups of types including basic data types, pointer types and struct types. On each type, we specify the domain of values and define some standard operations in terms of logic functions and predicates. Then, it is feasible to formalize statements of type declaration of program variables and statements of struct definitions as logic formulas. As the implementation of the theory, we extend theMSV toolkit with the support of modeling, simulation and verification of typedMSVL programs. Applications to the construction of AVL tree and ordered list show the practicality of the language. © 2017, Higher Education Press and Springer-Verlag Berlin Heidelberg.","MSVL; struct definition; temporal logic programming; type; type declaration","Logic programming; Temporal logic; Data type; Logic formulas; Logic functions; MSVL; Program variables; struct definition; type; type declaration; Computer circuits",2-s2.0-85019726907
"Riener H., Haedicke F., Frehse S., Soeken M., Große D., Drechsler R., Fey G.","metaSMT: focus on your application and not on solver integration",2017,"International Journal on Software Tools for Technology Transfer",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84975143358&doi=10.1007%2fs10009-016-0426-1&partnerID=40&md5=6df21379417c235c39895b9804cfb67b","Many applications from artificial intelligence and formal methods use decision procedures as their core solving engines. In this context, automated reasoning based on Satisfiability (SAT) or Satisfiability Modulo Theories (SMT) is very effective. For a given application, however, selecting the best reasoning engine is a daunting task requiring first-hand experience and insight into engine-specific implementation details. Developers have to decide which concrete engine to use and how to integrate the engine into an application. Although file formats, e.g., DIMACS CNF or SMT-LIB, standardize the input of SAT and SMT solvers, not all engines provide input interfaces compliant with these standards. When following the standard, advanced (and not standardized) features of the solvers remain unused and their integration is left to the users. This work presents metaSMT, a framework that eases the integration of existing reasoning engines into applications. Inspired by SMT-LIB, metaSMT provides a domain-specific language that allows for engine-independent programming and offers a generic interface to advanced features as an extra abstraction layer. State-of-the-art solvers for satisfiability and other theories are available via metaSMT with little programming effort. Language bindings for C++ and Python are provided. We show how metaSMT can be used as a portfolio consistency checker for SMT-LIB2 instances. The benchmark set of the category quantifier-free bit-vector theory from SMT-LIB (1.6 GB) is used for these experiments. © 2016, Springer-Verlag Berlin Heidelberg.","EDSL; Formal methods; Logic; SAT; SMT","Abstracting; Artificial intelligence; C++ (programming language); Computational linguistics; Computer programming; Computer programming languages; Formal logic; Formal methods; Problem oriented languages; Surface mount technology; Automated reasoning; Decision procedure; Domain specific languages; EDSL; Generic interfaces; Language bindings; Logic; Satisfiability modulo Theories; Engines",2-s2.0-84975143358
"Abe T., Maeda T.","A general model checking framework for various memory consistency models",2017,"International Journal on Software Tools for Technology Transfer",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978654511&doi=10.1007%2fs10009-016-0429-y&partnerID=40&md5=37c79200be44e26d6317e607c20c560b","Relaxed memory consistency models are common and essential when multiple processes share a single global address space, such as when using multicore CPUs, distributed shared-memory programming languages, and so forth. Programming within these models is difficult and error prone, because of non-intuitive behaviors that could not occur in a strict consistency model. In addition, because the memory consistency models vary from language to language, and CPU to CPU, a program that may work correctly on one system may not work on another. To address the problem, this paper describes a model checking framework in which users are able to check their programs under various memory consistency models. More specifically, our framework provides a base model that exhibits very relaxed behaviors, and users are able to define various consistency models by adding constraints to the base model. This paper also describes McSPIN, a prototype implementation of a model checker based on the proposed framework. McSPIN can take a memory consistency model as an input, as well as a program and a property to be checked. We have specified the necessary constraints for three practical existing memory consistency models (Unified Parallel C, Coarray Fortran, and Itanium). McSPIN verified some example programs correctly, and confirmed the expected differences among the three models. © 2016, Springer-Verlag Berlin Heidelberg.","Coarray Fortran; Itanium; Memory consistency model; Model checking; Unified Parallel C","Computational linguistics; FORTH (programming language); FORTRAN (programming language); Memory architecture; Multicore programming; Program processors; Co-array Fortran; Consistency model; Distributed shared memory; Global address spaces; Itanium; Memory consistency models; Prototype implementations; Unified parallel C; Model checking",2-s2.0-84978654511
"Frust T., Wagner M., Stephan J., Juckeland G., Bieberle A.","Rapid data processing for ultrafast X-ray computed tomography using scalable and modular CUDA based pipelines",2017,"Computer Physics Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021691375&doi=10.1016%2fj.cpc.2017.05.025&partnerID=40&md5=0b6cc05e8e9fd89d841d1f6ff1213a27","Ultrafast X-ray tomography is an advanced imaging technique for the study of dynamic processes basing on the principles of electron beam scanning. A typical application case for this technique is e.g. the study of multiphase flows, that is, flows of mixtures of substances such as gas–liquidflows in pipelines or chemical reactors. At Helmholtz-Zentrum Dresden-Rossendorf (HZDR) a number of such tomography scanners are operated. Currently, there are two main points limiting their application in some fields. First, after each CT scan sequence the data of the radiation detector must be downloaded from the scanner to a data processing machine. Second, the current data processing is comparably time-consuming compared to the CT scan sequence interval. To enable online observations or use this technique to control actuators in real-time, a modular and scalable data processing tool has been developed, consisting of user-definable stages working independently together in a so called data processing pipeline, that keeps up with the CT scanner's maximal frame rate of up to 8  kHz. The newly developed data processing stages are freely programmable and combinable. In order to achieve the highest processing performance all relevant data processing steps, which are required for a standard slice image reconstruction, were individually implemented in separate stages using Graphics Processing Units (GPUs) and NVIDIA's CUDA programming language. Data processing performance tests on different high-end GPUs (Tesla K20c, GeForce GTX 1080, Tesla P100) showed excellent performance. Program summary/new version program summary Program Title: GLADOS/RISA Program Files doi: http://dx.doi.org/10.17632/65sx747rvm.1 Licensing provisions: LGPLv3 Programming language: C++/CUDA Supplementary material: Test data set, used for the performance analysis. Nature of problem: Ultrafast computed tomography is performed with a scan rate of up to 8 kHz. To obtain cross-sectional images from projection data computer-based image reconstruction algorithms must be applied. The objective of the presented program is to reconstruct a data stream of around 1.3  GB  s−1 in a minimum time period. Thus, the program allows to go into new fields of application and to use in the future even more compute-intensive algorithms, especially for data post-processing, to improve the quality of data analysis. Solution method: The program solves the given problem using a two-step process: first, by a generic, expandable and widely applicable template library implementing the streaming paradigm (GLADOS); second, by optimized processing stages for ultrafast computed tomography implementing the required algorithms in a performance-oriented way using CUDA (RISA). Thereby, task-parallelism between the processing stages as well as data parallelism within one processing stage is realized. © 2017 Elsevier B.V.","Computed tomography; Image reconstruction; Multithreading; Parallel algorithms; Pipeline processing; Real-time systems","Application programs; C++ (programming language); Computer graphics; Computer programming languages; Computerized tomography; Data handling; Graphics processing unit; Image processing; Image reconstruction; Imaging techniques; Multitasking; Parallel algorithms; Parallel processing systems; Pipelines; Problem oriented languages; Program processors; Quality control; Real time systems; Scanning; Statistical tests; Tomography; Cross sectional image; Data processing pipelines; Image reconstruction algorithm; Multi-threading; Pipeline processing; Processing performance; Ultrafast computed tomographies; X-ray computed tomography; Pipeline processing systems",2-s2.0-85021691375
"Harada T., Takadama K.","Machine-code program evolution by genetic programming using asynchronous reference-based evaluation through single-event upset in on-board computer",2017,"Journal of Robotics and Mechatronics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031900306&doi=10.20965%2fjrm.2017.p0808&partnerID=40&md5=905d710cb2f16c610419985e96b89d54","This study proposes a novel genetic programming method using asynchronous reference-based evaluation (called AREGP) to evolve computer programs through single-event upsets (SEUs) in the on-board computer in space missions. AREGP is an extension of Tierra-based asynchronous genetic programming (TAGP), which was proposed in our previous study. It is based on the idea of the biological simulator, Tierra, where digital creatures are evolved through bit inversions in a program. AREGP not only inherits the advantages of TAGP but also overcomes its limitation, i.e., TAGP cannot select good programs for evolution without an appropriate threshold. Specifically, AREGP introduces an archive mechanism to maintain good programs and a reference-based evaluation by using the archive for appropriate threshold selection and removal. To investigate the effectiveness of the proposed AREGP, simulation experiments are performed to evolve the assembly language program in the SEU environment. In these experiments, the PIC instruction set, which is carried on many types of spacecraft, is used as the evolved assembly program. The experimental results revealed that AREGP cannot only maintain the correct program through SEU with high occurrence rate, but is also better at reducing the size of programs in comparison with TAGP. Additionally, AREGP can achieve a shorter execution step and smaller size of programs, which cannot be achieved by TAGP. © 2017, Fuji Technology Press. All rights reserved.","Genetic programming; Machine-code program evolution; On-board computer; Single-event upset","Biology; Computer programming; Computer simulation languages; Digital storage; Flash memory; Genetic algorithms; Radiation hardening; Space flight; Assembly language; Bit inversion; Instruction set; Machine code programs; Onboard computers; Single event upsets; Space missions; Threshold selection; Genetic programming",2-s2.0-85031900306
"Abdelzad V., Lethbridge T.C.","Promoting traits into model-driven development",2017,"Software and Systems Modeling",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946781578&doi=10.1007%2fs10270-015-0505-x&partnerID=40&md5=a2c8ab24705cf3e08de028dbedbf684a","Traits, as sets of behaviors, can provide a good mechanism for reusability. However, they are limited in important ways and are not present in widely used programming and modeling languages and hence are not readily available for use by mainstream developers. In this paper, we add UML associations and other modeling concepts to traits and apply them to Java and C++ through model-driven development. We also extend traits with required interfaces so dependencies at the semantics level become part of their usage, rather than simple syntactic capture. All this is accomplished in Umple, a textual modeling language based upon UML that allows adding programming constructs to the model. We applied the work to two case studies. The results show that we can promote traits to the modeling level along with the improvement in flexibility and reusability. © 2015, Springer-Verlag Berlin Heidelberg.","Modeling; Reusability; Traits; UML; Umple","C++ (programming language); Computational linguistics; Java programming language; Models; Reusability; Semantics; Case-studies; Model driven development; Modeling concepts; Required interfaces; Traits; UML; Umple; Modeling languages",2-s2.0-84946781578
"Janetschek M., Prodan R., Benedict S.","A workflow runtime environment for manycore parallel architectures",2017,"Future Generation Computer Systems",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014111392&doi=10.1016%2fj.future.2017.02.029&partnerID=40&md5=57995e05df4844b674d1e93d93796792","We introduce a new Manycore Workflow Runtime Environment (MWRE) to efficiently enact traditional scientific workflows on modern manycore computing architectures. MWRE is compiler-based and translates workflows specified in the XML-based Interoperable Workflow Intermediate Representation (IWIR) into an equivalent C++-based program. This program efficiently enacts the workflow as a stand-alone executable by means of a new callback mechanism that resolves dependencies, transfers data, and handles composite activities. Furthermore, a core feature of MWRE is explicit support for full-ahead scheduling and enactment. Experimental results on a number of real-world workflows demonstrate that MWRE clearly outperforms existing Java-based workflow engines designed for distributed (Grid or Cloud) computing infrastructures in terms of enactment time, is generally better than an existing script-based engine for manycore architectures (Swift), and sometimes gets even close to an artificial baseline implementation of the workflows in the standard OpenMP language for shared memory systems. Experimental results also show that full-ahead scheduling with MWRE using a state-of-the-art heuristic can improve the workflow performance up to 40%. © 2017","Full-ahead scheduling; Manycores; Scientific workflows; Workflow execution plan","Application programming interfaces (API); C++ (programming language); Computer architecture; Computer software; Distributed computer systems; Engines; Java programming language; Memory architecture; Program compilers; Real time systems; Scheduling; Computing infrastructures; Full-ahead scheduling; Intermediate representations; Many-core architecture; Manycores; Scientific workflows; Shared memory system; Workflow execution; Parallel architectures",2-s2.0-85014111392
"Allanach B.C., Martin S.P., Robertson D.G., Ruiz de Austri R.","The inclusion of two-loop SUSYQCD corrections to gluino and squark pole masses in the minimal and next-to-minimal supersymmetric standard model: SOFTSUSY3.7",2017,"Computer Physics Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020928592&doi=10.1016%2fj.cpc.2017.05.006&partnerID=40&md5=d989f19def19e80872c56636c21edac6","We describe an extension of the SOFTSUSY spectrum calculator to include two-loop supersymmetric QCD (SUSYQCD) corrections of order O(αs 2) to gluino and squark pole masses, either in the minimal supersymmetric standard model (MSSM) or the next-to-minimal supersymmetric standard model (NMSSM). This document provides an overview of the program and acts as a manual for the new version of SOFTSUSY, which includes the increase in accuracy in squark and gluino pole mass predictions. Program summary Program title: SOFTSUSY Program Files doi: http://dx.doi.org/10.17632/sh77x9j7hs.1 Licensing provisions: GNU GPLv3 Programming language: C++, fortran, C Nature of problem: Calculating supersymmetric particle spectrum, mixing parameters and couplings in the MSSM or the NMSSM. The solution to the renormalization group equations must be consistent with theoretical boundary conditions on supersymmetry breaking parameters, as well as a weak-scale boundary condition on gauge couplings, Yukawa couplings and the Higgs potential parameters. Solution method: Nested fixed point iteration. Restrictions: SOFTSUSY will provide a solution only in the perturbative regime and it assumes that all couplings of the model are real (i.e. CP−conserving). If the parameter point under investigation is non-physical for some reason (for example because the electroweak potential does not have an acceptable minimum), SOFTSUSY returns an error message. The higher order corrections included are for the MSSM (R-parity conserving or violating) or the real R-parity conserving NMSSM only. Journal reference of previous version: Comput. Phys. Comm. 189 (2015) 192. Does the new version supersede the previous version?: Yes. Reasons for the new version: It is desirable to improve the accuracy of the squark and gluinos mass predictions, since they strongly affect supersymmetric particle production cross-sections at colliders. Summary of revisions: The calculation of the squark and gluino pole masses is extended to be of next-to-next-to leading order in SUSYQCD, i.e. including terms up to O(gs 4∕(16π2)2). Additional comments: Program obtainable from http://softsusy.hepforge.org/ © 2017 Elsevier B.V.","Gluino; MSSM; NMSSM; Squark","Boundary conditions; C++ (programming language); Couplings; FORTRAN (programming language); Fractals; Iterative methods; Open source software; Poles; Statistical mechanics; Gluino; Minimal supersymmetric standard models; MSSM; Next to next to leading orders; Next-to-minimal supersymmetric standard models; NMSSM; Renormalization group equations; Squark; Supersymmetry",2-s2.0-85020928592
"López-Martín C., Ulloa-Cazarez R.L., García-Floriano A.","Support vector regression for predicting the productivity of higher education graduate students from individually developed software projects",2017,"IET Software",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029783744&doi=10.1049%2fiet-sen.2016.0304&partnerID=40&md5=db4baa2e880b3121f16b2d6dea137853","Productivity prediction of a software engineer is necessary to determine whether corrective actions are needed and to identify improvement options to produce better results. It can be performed from abstraction levels such as organisation, team project, individual project, or task Software engineering education and training has approached its efforts at individual level. In this study, the authors propose the application of a data mining technique named support vector regression (SVR) to predict the productivity of individuals (i.e. graduate students). Its prediction accuracy was compared with that of a statistical regression model, and with those of two neural networks. After applying a Wilcoxon statistical test, results suggest that an SVR with linear kernel using new and changed lines of code, and programming language experience as independent variables, could be used for predicting the individual productivity of a higher education graduate student, when software projects coded in either Java or C++ programming languages, have been developed by following a disciplined process specifically proposed for academic environments. © The Institution of Engineering and Technology 2017.",,"C++ (programming language); Computer programming; Computer software; Data mining; Education; Education computing; Forecasting; Object oriented programming; Productivity; Regression analysis; Software engineering; Software testing; Academic environment; Corrective actions; Independent variables; Individual levels; Individual productivity; Prediction accuracy; Statistical regression model; Support vector regression (SVR); Students",2-s2.0-85029783744
"Kolb S., Paramonov S., Guns T., De Raedt L.","Learning constraints in spreadsheets and tabular data",2017,"Machine Learning",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020207644&doi=10.1007%2fs10994-017-5640-x&partnerID=40&md5=c9bbe6830d2d265fd79962b5a25177e8","Spreadsheets, comma separated value files and other tabular data representations are in wide use today. However, writing, maintaining and identifying good formulas for tabular data and spreadsheets can be time-consuming and error-prone. We investigate the automatic learning of constraints (formulas and relations) in raw tabular data in an unsupervised way. We represent common spreadsheet formulas and relations through predicates and expressions whose arguments must satisfy the inherent properties of the constraint. The challenge is to automatically infer the set of constraints present in the data, without labeled examples or user feedback. We propose a two-stage generate and test method where the first stage uses constraint solving techniques to efficiently reduce the number of candidates, based on the predicate signatures. Our approach takes inspiration from inductive logic programming, constraint learning and constraint satisfaction. We show that we are able to accurately discover constraints in spreadsheets from various sources. © 2017, The Author(s).","Constraint discovery; Constraint learning; Constraint programming; Excel; Machine learning; Spreadsheets; Tabular constraint learning","Computer programming; Constraint theory; Inductive logic programming (ILP); Learning systems; Network security; Spreadsheets; Testing; Constraint discovery; Constraint learning; Constraint programming; Excel; Tabular constraint learning; Computer programming languages",2-s2.0-85020207644
"Huo X., Sun T., Song Y.","A geometric algebra approach to determine motion/constraint, mobility and singularity of parallel mechanism",2017,"Mechanism and Machine Theory",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020931351&doi=10.1016%2fj.mechmachtheory.2017.06.005&partnerID=40&md5=1f47c5f2960ead77f1cc9e093a5c5484","The crucial procedure of mobility and singularity identification of parallel mechanisms is widely recognized as how to determine their motions (constraints) concisely and visually. In this paper, we propose a geometric algebra (GA) based approach to determine the motions/constraints, mobility and singularity of parallel mechanisms mainly utilizing the geometric and algebraic relations. Firstly, the motions, constraints and their relations are represented by conformal geometric algebra (CGA) formulas in a concise form by employing the characterized geometric elements with G4,1. Secondly, the mobility of parallel mechanism, including its number and property and the axes of motions, not only at origin configuration but also in the prescribed workspace, is obtained by the procedure proposed in this paper. Thirdly, the singularity of parallel mechanism is identified by the two indices proposed in this paper with shuffle and outer products. Finally, a typical example is given to illustrate the motions/constraints, mobility and singularity analysis. This approach is beneficial to kinematic analysis and optimal design of parallel mechanisms, especially for which would be carried out in automatic and visual manner using computer programming languages. © 2017 Elsevier Ltd","Constraint; Geometric algebra; Kinematics; Mobility; Parallel mechanism; Singularity","Algebra; Carrier mobility; Computer programming; Computer programming languages; Geometry; Kinematics; Visual languages; Algebraic relations; Conformal Geometric Algebra; Constraint; Geometric Algebra; Kinematic Analysis; Parallel mechanisms; Singularity; Singularity analysis; Mechanisms",2-s2.0-85020931351
"Damiani F., Faitelson D., Gladisch C., Tyszberowicz S.","A novel model-based testing approach for software product lines",2017,"Software and Systems Modeling",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957939894&doi=10.1007%2fs10270-016-0516-2&partnerID=40&md5=a3c96a439d2ec91e4d45728dd9e16686","Model-based testing relies on a model of the system under test. FineFit is a framework for model-based testing of Java programs. In the FineFit approach, the model is expressed by a set of tables based on Parnas tables. A software product line is a family of programs (the products) with well-defined commonalities and variabilities that are developed by (re)using common artifacts. In this paper, we address the issue of using the FineFit approach to support the development of correct software product lines. We specify a software product line as a specification product line where each product is a FineFit specification of the corresponding software product. The main challenge is to concisely specify the software product line while retaining the readability of the specification of a single system. To address this, we used delta-oriented programming, a recently proposed flexible approach for implementing software product lines, and developed: (1) delta tables as a means to apply the delta-oriented programming idea to the specification of software product lines; and (2) DeltaFineFit as a novel model-based testing approach for software product lines. © 2016, Springer-Verlag Berlin Heidelberg.","Alloy; Delta-oriented programming; Java; Model-based testing; Refinement; Software product line","Alloying; Java programming language; Model checking; Software design; Software testing; Specifications; Java; Model based testing; Model-based testing approaches; Programming ideas; Refinement; Software Product Line; Software products; System under test; Computer software",2-s2.0-84957939894
"Soller D., Jaumann T., Kilian G., Robert J., Heuberger A.","DFC++ Processing Framework Concept: A Novel Framework Approach for Flexible Signal Processing on Embedded Systems",2017,"Journal of Signal Processing Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982281238&doi=10.1007%2fs11265-016-1174-x&partnerID=40&md5=739cd1460c6c34e830717f30c74c4e4d","Development of modern Software Defined Radio (SDR) based communication systems can be accelerated significantly by the use of processing frameworks. The evolution of SDR and the involved departure from digital representations of classical radio architecture towards more abstract software systems raises new requirements of increased flexibility and versatility. The proposed Data Flow Control for C++ (DFC++) processing framework concept addresses those requirements by employing modern programming techniques and flow control mechanisms to allow for variable data rates, dynamic paths, and flexible component designs. Another important trend is the integration of various embedded platforms in the software radio domain. The rapidly increasing performance and efficiency of embedded processors enables the deployment of SDR systems in more space and power constrained environments. Therefore covering a heterogeneous hardware selection becomes increasingly important for processing frameworks. By relying exclusively on C++ and minimizing external dependencies, DFC++ is specifically aiming for excellent portability and adaptability to support a wide range of current and future software radio projects while maintaining high performance and ease of use. This paper introduces the key aspects of the DFC++ concept and implementation with focus on the reference pointer based data transport mechanisms responsible for the propagation of user data between different processing components. © 2016, Springer Science+Business Media New York.","Embedded systems; Processing framework; Software defined radio","Analog circuits; C++ (programming language); Computer programming; Computer software; Computer software portability; Data handling; Digital radio; Embedded systems; Flow control; Radio; Radio receivers; Signal processing; Digital representations; Embedded processors; Flexible components; Heterogeneous hardware; Increased flexibility; Programming technique; Software-defined radios; Variable data rates; Software radio",2-s2.0-84982281238
"Rodrigues T., Delicato F.C., Batista T., Pires P.F., Pirmez L.","An approach based on the domain perspective to develop WSAN applications",2017,"Software and Systems Modeling",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944631210&doi=10.1007%2fs10270-015-0498-5&partnerID=40&md5=f3bedc0f67a6168c8596695b9877289f","As wireless sensor and actuator networks (WSANs) can be used in many different domains, WSAN applications have to be built from two viewpoints: domain and network. These different viewpoints create a gap between the abstractions handled by the application developers, namely the domain and network experts. Furthermore, there is a coupling between the application logic and the underlying sensor platform, which results in platform-dependent projects and source codes difficult to maintain, modify, and reuse. Consequently, the process of developing an application becomes cumbersome. In this paper, we propose a model-driven architecture (MDA) approach for WSAN application development. Our approach aims to facilitate the task of the developers by: (1) enabling application design through high abstraction level models; (2) providing a specific methodology for developing WSAN applications; and (3) offering an MDA infrastructure composed of PIM, PSM, and transformation programs to support this process. Our approach allows the direct contribution of domain experts in the development of WSAN applications, without requiring specific knowledge of programming WSAN platforms. In addition, it allows network experts to focus on the specific characteristics of their area of expertise without the need of knowing each specific application domain. © 2015, Springer-Verlag Berlin Heidelberg.","Abstraction; Architecture; Code generation; Domain-specific language; Model-driven architecture; UML profile; WSAN applications","Abstracting; Application programs; Architecture; Computer programming languages; Natural language processing systems; Network architecture; Problem oriented languages; Software design; Wireless sensor networks; Abstraction; Code Generation; Domain specific languages; Model driven architectures; Uml profiles; Software architecture",2-s2.0-84944631210
"Eilert T., Beckers M., Drechsler F., Michaelis J.","Fast-NPS—A Markov Chain Monte Carlo-based analysis tool to obtain structural information from single-molecule FRET measurements",2017,"Computer Physics Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021283147&doi=10.1016%2fj.cpc.2017.05.027&partnerID=40&md5=93be0cb991a148b392ac67139aee2ed3","The analysis tool and software package Fast-NPS can be used to analyse smFRET data to obtain quantitative structural information about macromolecules in their natural environment. In the algorithm a Bayesian model gives rise to a multivariate probability distribution describing the uncertainty of the structure determination. Since Fast-NPS aims to be an easy-to-use general-purpose analysis tool for a large variety of smFRET networks, we established an MCMC based sampling engine that approximates the target distribution and requires no parameter specification by the user at all. For an efficient local exploration we automatically adapt the multivariate proposal kernel according to the shape of the target distribution. In order to handle multimodality, the sampler is equipped with a parallel tempering scheme that is fully adaptive with respect to temperature spacing and number of chains. Since the molecular surrounding of a dye molecule affects its spatial mobility and thus the smFRET efficiency, we introduce dye models which can be selected for every dye molecule individually. These models allow the user to represent the smFRET network in great detail leading to an increased localisation precision. Finally, a tool to validate the chosen model combination is provided. Programme summary Programme Title: Fast-NPS Programme Files doi: http://dx.doi.org/10.17632/7ztzj63r68.1 Licencing provisions: Apache-2.0 Programming language: GUI in MATLAB (The MathWorks) and the core sampling engine in C++ Nature of problem: Sampling of highly diverse multivariate probability distributions in order to solve for macromolecular structures from smFRET data. Solution method: MCMC algorithm with fully adaptive proposal kernel and parallel tempering scheme. © 2017 Elsevier B.V.","Bayesian inference; Dye model; Nano-Positioning system; smFRET; Structural biology","Bayesian networks; C++ (programming language); Chains; Computer programming; Engines; Inference engines; Macromolecules; Markov processes; MATLAB; Molecules; Structural analysis; Tempering; Bayesian inference; Macromolecular structures; Markov Chain Monte-Carlo; Multivariate probability distributions; Nano-positioning; SmFRET; Structural biology; Structure determination; Probability distributions",2-s2.0-85021283147
"Kovarik V.J., Muralidharan R.","Model-Based Systems Engineering: Lessons Learned from the Joint Tactical Radio System",2017,"Journal of Signal Processing Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008227620&doi=10.1007%2fs11265-016-1218-2&partnerID=40&md5=ddb0fd2fb6e7c048bc914804e2da1f9a","The Joint Tactical Radio System was the first major program that sought to develop a new family of radio systems using a software-based architecture. A new software-oriented architecture, the Software Communications Architecture was developed as a common, interoperable foundation for this new family of tactical radios. The fundamental objective was to enable radio systems to support multiple waveforms, allow for software-only upgrades of operational capabilities and ultimately reduce the tail-end logistics, maintenance and upgrade costs. However, within the first few years the program experienced difficulties and setbacks resulting in cost and schedule overruns. Several program reviews and analyses were performed to assess the reasons for the problems encountered. Although multiple causes were cited for the failures, this paper puts forth the assertion that a key aspect of the engineering process, systems engineering, was not planned into the program and a fundamental cause for many of the issues encountered. © 2017, Springer Science+Business Media New York.","ICSM; Integrated communication system model; MBE; Model based engineering; SCA; SDR; Software communications architecture; Software defined radio; SysML; Systems modeling language; UML; Unified modeling language","Computer architecture; FORTH (programming language); Modeling languages; Molecular beam epitaxy; Radio systems; Systems engineering; Unified Modeling Language; ICSM; Model-based engineering; Software communications architectures; Software-defined radios; SysML; Systems modeling languages; Software radio",2-s2.0-85008227620
"Barros P.A., Pereira M.J.V., Henriques P.R.","Applying attribute grammars to teach linguistic rules",2017,"OpenAccess Series in Informatics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032641076&doi=10.4230%2fOASIcs.SLATE.2017.1&partnerID=40&md5=95b927111cdbe29a5fad72c467b63d1b","An attribute grammar is a very well known formalism to describe computer languages but it can also be successfully used to describe linguistic phenomena. Since natural languages can also be expressed in grammars it is natural to describe rules using the same formalism. Linguistic teachers of the University Complutense of Madrid started using attribute grammars but they lack a tool that helps them to specify linguistic rules in a friendly and natural way. Therefore we propose a domain specific language (NLSdsl) carefully designed for non-programmers that will be implemented on an AnTLR based system. © Patrícia Amorim Barros, Maria João Varanda Pereira, and Pedro Rangel Henriques","Attribute Grammars; DSL; Linguistics","Computer programming languages; Context sensitive grammars; DSL; Problem oriented languages; Slate; Teaching; Attribute grammars; Domain specific languages; Linguistic phenomena; Linguistic rules; Natural languages; Linguistics",2-s2.0-85032641076
"Papadakis S., Kalogiannakis M., Orfanakis V., Zaranis N.","The appropriateness of scratch and app inventor as educational environments for teaching introductory programming in primary and secondary education",2017,"International Journal of Web-Based Learning and Teaching Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028002878&doi=10.4018%2fIJWLTT.2017100106&partnerID=40&md5=d2e3523b414c7919e83c1a6df67283e5","Teaching programming is a complex task. The task is even more challenging for introductory modules. There is an ongoing debate in the teaching community over the best approach to teaching introductory programming. Visual block-based programming environments allow school students to create their own programs in ways that are more accessible than in textual programming environments. These environments designed for education allow students to program without the obstacle of syntax errors (errors in typing commands) found in traditional text-based languages. In this paper, the authors focus on the use of App Inventor and Scratch as blocks-based programming environments designed explicitly with novices in mind. In the authors' analysis, both Novice Programming Environments (NPEs) seemed to be attractive platforms for introducing fundamental concepts in computer programming and both look appealing for both majors and non-majors. © 2017, IGI Global.","-Novice Programmers; -Novice Programming Environments (NPEs); -Primary Education; -Scratch; -Secondary Education; App Inventor for Android (AIA)",,2-s2.0-85028002878
"Prausa M.","epsilon: A tool to find a canonical basis of master integrals",2017,"Computer Physics Communications",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021273518&doi=10.1016%2fj.cpc.2017.05.026&partnerID=40&md5=34c9a004c703c337a8e152f1deb4885d","In 2013, Henn proposed a special basis for a certain class of master integrals, which are expressible in terms of iterated integrals. In this basis, the master integrals obey a differential equation, where the right hand side is proportional to ϵ in d=4−2ϵ space–time dimensions. An algorithmic approach to find such a basis was found by Lee. We present the tool epsilon, an efficient implementation of Lee's algorithm based on the Fermat computer algebra system as computational back end. Program summary Program Title: epsilon Program Files doi: http://dx.doi.org/10.17632/j59sy5n729.1 Licensing provisions: GPLv3 Programming language: C++ Nature of problem: For a certain class of master integrals, a canonical basis can be found in which they fulfill a differential equation with the right hand side proportional to ϵ. In such a basis the solution of the master integrals in an ϵ-expansion becomes trivial. Unfortunately, the problem of finding a canonical basis is challenging. Solution method: Algorithm by Lee [1] Restrictions: The normalization step of Lee's algorithm will fail if the eigenvalues of the matrix residues are not of the form a+bϵ with a,b∈Z. Multi-scale problems are not supported. [1] R.N. Lee, JHEP 1504 (2015) 108 [arXiv:1411.0911 [hep-ph]]. © 2017 Elsevier B.V.","Canonical basis; Differential equation; Feynman integral; Fuchsian form","Algebra; Computational efficiency; Differential equations; Eigenvalues and eigenfunctions; Problem oriented languages; Algorithmic approach; Canonical basis; Computer algebra systems; Efficient implementation; Feynman integrals; Iterated integrals; Multiscale problem; Right-hand sides; C++ (programming language)",2-s2.0-85021273518
"Wu W., Lin W., Peng Z.","An intelligent power consumption model for virtual machines under CPU-intensive workload in cloud environment",2017,"Soft Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964545734&doi=10.1007%2fs00500-016-2154-6&partnerID=40&md5=1db876ab923977a7a5bd9b5bad54c7bf","Cloud computing has gained enormous popularity by providing high availability and scalability as well as on-demand services. However, with the continuous rise of energy consumption cost, the virtualized environment of cloud data centers poses a challenge to today’s power monitoring system. Software-based power monitoring is gaining prevalence since power models can work precisely by exploiting soft computing methodologies like genetic programming and swarm intelligence for model optimization. However, traditional power models barely consider virtualization and have drawbacks like high error rate, low feasibility as well as insufficient scalability. In this paper, we first analyze the power signatures of virtual machines in different configurations through experiments. Then we propose a virtual machine (VM) power model, named CAM, which is able to adapt to the reconfiguration of VMs and provide accurate power estimating under CPU-intensive workload. We also propose two training methodologies corresponding to two typical situations for model training. CAM can estimate the power of a single VM as well as a physical server hosting several heterogeneous VMs. We exploited public Linux benchmarks to evaluate CAM.The experimental results show that CAM produced very small errors in power estimating for both VMs (4.26 % on average) and the host server (0.88 % on average). © 2016, Springer-Verlag Berlin Heidelberg.","Cloud computing; Power consumption; Power model; vCPU; Virtual machine","Artificial intelligence; Cams; Computer operating systems; Electric power utilization; Energy utilization; Genetic algorithms; Genetic programming; Java programming language; Scalability; Soft computing; Telecommunication networks; Virtual reality; Cloud data centers; Cloud environments; Power model; Soft computing methodologies; Swarm Intelligence; vCPU; Virtual machines; Virtualized environment; Cloud computing",2-s2.0-84964545734
"Gupta R., Muttoo S.K., Pal S.K.","Fuzzy C-Means Clustering and Particle Swarm Optimization based scheme for Common Service Center location allocation",2017,"Applied Intelligence",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017439985&doi=10.1007%2fs10489-017-0917-0&partnerID=40&md5=25278228f7fe73357a2d6b5939996ca8","Common Service Centers (CSCs), which are also known as Tele-centers and Rural Kiosks, are important infrastructural options for any country aiming to provide E-Governance services in rural regions. Their main objective is to provide adequate information and services to a country’s rural areas, thereby increasing government-citizen connectivity. Within developing nations, such as India, many CSC allocations are being planned. This study proposes a solution for allocating a CSC for villages in a country according to their E-Governance plan. The Fuzzy C-Means (FCM) algorithm was used for clustering the village dataset and finding a cluster center for CSC allocation, and the Particle Swarm Optimization (PSO) algorithm was used for further optimizing the results obtained from the FCM algorithm based on population. In the context of other studies addressing similar issues, this study highlights the practical implementation of location modeling and analysis. An extensive analysis of the results obtained using a village dataset from India including four prominent states shows that the proposed solution reduces the average traveling costs of villagers by an average of 33 % compared with those of allocating these CSCs randomly in a sorted order and by an average of 11 % relative to centroid allocation using the FCM-based approach only. As compared to traditional approaches like P-Center and P-Median, the proposed scheme is better by 31 % and 14 %, respectively. Therefore, the proposed algorithm yields better results than classical FCM and other types of computing techniques, such as random search & linear programming. This scheme could be useful for government departments managing the allocation of CSCs in various regions. This work should also be useful for researchers optimizing the location allocation schemes used for various applications worldwide. © 2017, Springer Science+Business Media New York.","Common service centers; E-Governance; Fuzzy C-Means clustering; Linear programming; Location allocation; P-center; P-median; Particle swarm optimization; Rural kiosks; Tele-centers","C (programming language); Fuzzy systems; Government data processing; Linear programming; Location; Location based services; Optimization; Particle swarm optimization (PSO); Rural areas; E-governance; Fuzzy C means clustering; Location allocation; P-center; P-median; Service center; Tele-centers; Clustering algorithms",2-s2.0-85017439985
"Tournier P.-H., Bonazzoli M., Dolean V., Rapetti F., Hecht F., Nataf F., Aliferis I., El Kanfoud I., Migliaccio C., De Buhan M., Darbas M., Semenov S., Pichot C.","Numerical modeling and high-speed parallel computing: New perspectives on tomographic microwave imaging for brain stroke detection and monitoring",2017,"IEEE Antennas and Propagation Magazine",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028515210&doi=10.1109%2fMAP.2017.2731199&partnerID=40&md5=e98e95fab144eda3a7552381383db18c","This article deals with microwave tomography for brain stroke imaging using state-of-the-art numerical modeling and massively parallel computing. Iterative microwave tomographic imaging requires the solution of an inverse problem based on a minimization algorithm (e.g., gradient based) with successive solutions of a direct problem such as the accurate modeling of a whole-microwave measurement system. Moreover, a sufficiently high number of unknowns is required to accurately represent the solution. As the system will be used for detecting a brain stroke (ischemic or hemorrhagic) as well as for monitoring during the treatment, the running times for the reconstructions should be reasonable. The method used is based on high-order finite elements, parallel preconditioners from the domain decomposition method and domain-specific language with the opensource FreeFEM-solver. © 2017 IEEE.",,"Computer programming languages; Domain decomposition methods; Finite element method; Iterative methods; Microwaves; Numerical models; Problem oriented languages; Tomography; Domain specific languages; High-order finite elements; Massively parallel computing; Microwave measurement systems; Microwave tomography; Minimization algorithms; Parallel preconditioners; Tomographic imaging; Inverse problems",2-s2.0-85028515210
"Panda A.R., Mishra D., Ratha H.K.","FPGA Implementation of a Tone-Based Flight Termination System in a Software-Defined Radio Platform",2017,"IEEE Transactions on Industrial Informatics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031733780&doi=10.1109%2fTII.2017.2709344&partnerID=40&md5=cc07df84cd729b7b0ef5bb53d745f4a3","This paper outlines the design and implementation of a tone-based flight termination system (FTS) in a software-defined radio (SDR) platform. It is completely a novel implementation of an analog FTS in an SDR platform of NI Flex-RIO system. This single platform based design appears as a substitute for the previously used multiple platforms based complex system. Ruggedization and relevance design methods are required for the FTS design. Hence, the blueprint of the FTS is carried out in a field-programmable gate array. It ensures reconfigurable, interoperable operations with precise, reliable, and future upgradable implementation. Efficient optimization methods have been adopted to minimize the use of hardware resources. LabVIEW, a graphical programming language, is used for rapid prototyping. The validation of the system was done both in subsystem level as well as the integrated level at real-time mission scenario. © 2005-2012 IEEE.","Field-programmable gate array (FPGA); flight termination system (FTS); real-time system; software-defined radio (SDR)","Analog circuits; Computer graphics; Field programmable gate arrays (FPGA); Integrated circuit design; Interactive computer systems; Logic gates; Radio; Radio receivers; Real time systems; Design and implementations; flight termination system (FTS); FPGA implementations; Graphical programming language; Hardware resources; Multiple platforms; Optimization method; Software-defined radios; Software radio",2-s2.0-85031733780
"Zhang S., Huang Z., Wang W., Tian R., He J.","HACO-F: An accelerating hls-based floating-point ant colony optimization algorithm on FPGA",2017,"International Journal of Performability Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031946867&doi=10.23940%2fijpe.17.06.p7.854863&partnerID=40&md5=58a2a6641a3613709b42616647d6892b","In this paper, a novel accelerating Ant Colony Optimization (ACO) algorithm based on High-Level Synthesis (HLS) on FPGA (Field Programmable Gate Array) is proposed. The proposed algorithm (HACO-F) is implemented by C/C++ programming language and calculated by floating-point. For the sake of accelerating, the algorithm mainly employs the data optimization strategy to redefine the variables precision in HACO-F to reduce resource utilization and energy consumption. Then, we explore a loop optimization strategy including pipeline and unroll to parallelize loops in HACO-F to decrease computation time. The experimental results show that the HACO-F algorithm can achieve more than 6 times accelerating performance than that of the AS (Ant System) at the same search ability. The resource utilization in HACO-F is 1% FF, 4% LUT, and 9% BRAM decrease. The total on-chip energy consumption of HACO-F is reduced by 23.9%. © 2017 Totem Publisher, Inc. All rights reserved.","Algorithm acceleration; Ant colony optimization; Embedded system; FPGA; High-level synthesis","Artificial intelligence; C (programming language); Digital arithmetic; Embedded systems; Energy utilization; Field programmable gate arrays (FPGA); High level synthesis; Optimization; Ant Colony Optimization algorithms; Ant systems; Computation time; Data optimization; Floating points; Fpga(field programmable gate array); Loop optimizations; Resource utilizations; Ant colony optimization",2-s2.0-85031946867
"McNelles P., Zeng Z.C., Renganathan G., Chirila M., Lu L.","Failure mode taxonomy for assessing the reliability of Field Programmable Gate Array based Instrumentation and Control systems",2017,"Annals of Nuclear Energy",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019130356&doi=10.1016%2fj.anucene.2017.04.033&partnerID=40&md5=4b95356850b7b157299c9d070dcaf64c","Field Programmable Gate Arrays (FPGAs) are a form of programmable digital hardware configured to perform digital logic functions. This configuration (programming) is performed using Hardware Description Language (HDL), making FPGAs a form of HDL Programmed Device (HPD). In the nuclear field, FPGAs have seen use in upgrades and replacements of obsolete Instrumentation and Control (I&C) systems. This paper expands upon previous work that resulted in extensive FPGA failure mode data, to allow for the application of the OECD-NEA failure modes taxonomy. The OECD-NEA taxonomy presented a method to model digital (software-based) I&C systems, based on the hardware and software failure modes, failure uncovering effects and levels of abstraction, using a Reactor Trip System/Engineering Safety Feature Actuation System (RTS/ESFAS) as an example system. To create the FPGA taxonomy, this paper presents an additional “sub-component” level of abstraction, to demonstrate the effect of the FPGA failure modes and failure categories on an FPGA-based system. The proposed FPGA taxonomy is based on the FPGA failure modes, failure categories, failure effects and uncovering situations. The FPGA taxonomy is applied to the RTS/ESFAS test system, to demonstrate the effects of the anticipated FPGA failure modes on a digital I&C system, and to provide a modelling example for this proposed taxonomy. © 2017 Elsevier Ltd","Digital I&C; Failure modes; FPGA; Nuclear Power Plant; Taxonomy","Abstracting; C (programming language); Computer hardware description languages; Failure (mechanical); Failure modes; Hardware; Logic gates; Nuclear fuels; Nuclear power plants; Outages; Signal receivers; Taxonomies; Actuation systems; Digital hardware; Failure category; Hardware and software; Instrumentation and control; Instrumentation and control system; Level of abstraction; Levels of abstraction; Field programmable gate arrays (FPGA)",2-s2.0-85019130356
"Cyrol A.K., Mitter M., Strodthoff N.","FormTracer. A mathematica tracing package using FORM",2017,"Computer Physics Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020926884&doi=10.1016%2fj.cpc.2017.05.024&partnerID=40&md5=ac0578fa701e5b4a1bf2eac022ce277c","We present FormTracer, a high-performance, general purpose, easy-to-use Mathematica tracing package which uses FORM. It supports arbitrary space and spinor dimensions as well as an arbitrary number of simple compact Lie groups. While keeping the usability of the Mathematica interface, it relies on the efficiency of FORM. An additional performance gain is achieved by a decomposition algorithm that avoids redundant traces in the product tensors spaces. FormTracer supports a wide range of syntaxes which endows it with a high flexibility. Mathematica notebooks that automatically install the package and guide the user through performing standard traces in space–time, spinor and gauge-group spaces are provided. Program summary Program Title: FormTracer Program Files doi: http://dx.doi.org/10.17632/7rd29h4p3m.1 Licensing provisions: GPLv3 Programming language: Mathematica and FORM Nature of problem: Efficiently compute traces of large expressions Solution method: The expression to be traced is decomposed into its subspaces by a recursive Mathematica expansion algorithm. The result is subsequently translated to a FORM script that takes the traces. After FORM is executed, the final result is either imported into Mathematica or exported as optimized C/C++/Fortran code. Unusual features: The outstanding features of FormTracer are the simple interface, the capability to efficiently handle an arbitrary number of Lie groups in addition to Dirac and Lorentz tensors, and a customizable input-syntax. © 2017 Elsevier B.V.","Feynman diagrams; FORM; Mathematica; Trace","Forming; Lie groups; Quantum theory; Syntactics; Tensors; Arbitrary number; Arbitrary spaces; Compact lie groups; Decomposition algorithm; Feynman diagrams; Mathematica; Performance Gain; Trace; C++ (programming language)",2-s2.0-85020926884
"Costa Lucena Filho W., Carvalho Cordeiro L., Sabino Da Silva Junior W., Barbosa Carvalho C.","A Power Control and Anticolision Mechanism for RFID Systems",2017,"IEEE Latin America Transactions",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032647024&doi=10.1109%2fTLA.2017.8071238&partnerID=40&md5=8abf304b226bde1e01c486148b3f7325","RFID (Radio Frequency IDentification) applications require identification of large number of tags, which results in increased collisions and degradation in the performance of traditional DFSA (Dynamic Frame slot ALOHA) algorithms. This paper proposes a power control mechanism to estimate the amount of tags in RFID networks. The mechanism is based on the division of the interrogation zone in sub-areas called clusters. This division is used to interrogate in a single slot all tags of a cluster, perform measurements of RSSI and, with it, estimate the amount of tags per cluster. The mechanism is simulated and evaluated using our own simulator developed in C/C ++ programming language. We compared the results of number of slots, identification time and energy consumption with that obtained from the use of the optimal DFSA algorithm and Q algorithm of the EPCglobal standard. From the simulation results, one can see that the proposed mechanism provides performance 99% close to the ideal DFSA in dense networks, where there are large amount of tags. © 2017 IEEE.","Anticolision Mechanism; Clustering; Power Control; Radio Frequency Identification; RFID","C (programming language); Energy utilization; Identification (control systems); Power control; Radio waves; Clustering; Dense network; Dynamic frame; Large amounts; Measurements of; Q algorithms; RFID networks; RFID systems; Radio frequency identification (RFID)",2-s2.0-85032647024
"Fortnow L., Santhanam R.","Robust simulations and significant separations",2017,"Information and Computation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026786360&doi=10.1016%2fj.ic.2017.07.002&partnerID=40&md5=a2fc818e7043f79c1a368db71926f06e","We define a new notion of “robust simulations” between complexity classes which is intermediate between the traditional notions of infinitely-often and almost-everywhere, as well as a corresponding notion of “significant separations”. A language L has a robust simulation in a complexity class C if there is a language in C which agrees with L on arbitrarily large polynomial stretches of input lengths. We show that various implications in complexity theory such as the collapse of PH if NP=P and the Karp–Lipton theorem have analogues for robust simulations. We then use these results to prove that most known separations in complexity theory can be strengthened to significant separations, though in each case, an almost everywhere separation is unknown. Proving our results requires several new ideas, including a completely different proof of the hierarchy theorem for non-deterministic polynomial time than the ones previously known. © 2017 Elsevier Inc.",,"Computational complexity; Computer simulation languages; Polynomial approximation; Separation; Complexity class; Complexity theory; Karp-Lipton theorem; Polynomial-time; Robust simulations; C (programming language)",2-s2.0-85026786360
"Kutepov A.L., Oudovenko V.S., Kotliar G.","Linearized self-consistent quasiparticle GW method: Application to semiconductors and simple metals",2017,"Computer Physics Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021894213&doi=10.1016%2fj.cpc.2017.06.012&partnerID=40&md5=ad9a9cad7f8905b50d121762bcb24239","We present a code implementing the linearized quasiparticle self-consistent GW method (LQSGW) in the LAPW basis. Our approach is based on the linearization of the self-energy around zero frequency which differs it from the existing implementations of the QSGW method. The linearization allows us to use Matsubara frequencies instead of working on the real axis. This results in efficiency gains by switching to the imaginary time representation in the same way as in the space time method. The all electron LAPW basis set eliminates the need for pseudopotentials. We discuss the advantages of our approach, such as its N3 scaling with the system size N, as well as its shortcomings. We apply our approach to study the electronic properties of selected semiconductors, insulators, and simple metals and show that our code produces the results very close to the previously published QSGW data. Our implementation is a good platform for further many body diagrammatic resummations such as the vertex-corrected GW approach and the GW+DMFT method. Program summary Program Title: LqsgwFlapw Program Files doi: http://dx.doi.org/10.17632/cpchkfty4w.1 Licensing provisions: GNU General Public License Programming language: Fortran 90 External routines/libraries: BLAS, LAPACK, MPI (optional) Nature of problem: Direct implementation of the GW method scales as N4 with the system size, which quickly becomes prohibitively time consuming even in the modern computers. Solution method: We implemented the GW approach using a method that switches between real space and momentum space representations. Some operations are faster in real space, whereas others are more computationally efficient in the reciprocal space. This makes our approach scale as N3. Restrictions: The limiting factor is usually the memory available in a computer. Using 10 GB/core of memory allows us to study the systems up to 15 atoms per unit cell. © 2017",,"Electronic properties; Linearization; Open source software; Computationally efficient; Efficiency gain; GNU general public license; Matsubara frequency; Momentum spaces; Pseudopotentials; Reciprocal space; Solution methods; FORTRAN (programming language)",2-s2.0-85021894213
"Drnasin I., Grgić M., Gogić G.","JavaScript Access to DICOM Network and Objects in Web Browser",2017,"Journal of Digital Imaging",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010977220&doi=10.1007%2fs10278-017-9956-7&partnerID=40&md5=f97e8a4dc6036f5464ed3f61b899aef3","Digital imaging and communications in medicine (DICOM) 3.0 standard provides the baseline for the picture archiving and communication systems (PACS). The development of Internet and various communication media initiated demand for non-DICOM access to PACS systems. Ever-increasing utilization of the web browsers, laptops and handheld devices, as opposed to desktop applications and static organizational computers, lead to development of different web technologies. The DICOM standard officials accepted those subsequently as tools of alternative access. This paper provides an overview of the current state of development of the web access technology to the DICOM repositories. It presents a different approach of using HTML5 features of the web browsers through the JavaScript language and the WebSocket protocol by enabling real-time communication with DICOM repositories. JavaScript DICOM network library, DICOM to WebSocket proxy and a proof-of-concept web application that qualifies as a DICOM 3.0 device were developed. © 2017, Society for Imaging Informatics in Medicine.","DICOM; HTML5; HTTP; Internet; JavaScript; PACS; Teleradiology; WebSocket","Computer aided diagnosis; Digital Imaging and Communications in Medicine (DICOM); High level languages; HTML; HTTP; Internet; Java programming language; Picture archiving and communication systems; DICOM; HTML5; Javascript; Teleradiology; Websocket; Web browsers",2-s2.0-85010977220
"Cardellini V., Fanfarillo A., Filippone S.","Coarray-based load balancing on heterogeneous and many-core architectures",2017,"Parallel Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020457520&doi=10.1016%2fj.parco.2017.06.001&partnerID=40&md5=75f958e03eba035b8a62095979869da0","In order to reach challenging performance goals, computer architecture is expected to change significantly in the near future. Heterogeneous chips, equipped with different types of cores and memory, will force application developers to deal with irregular communication patterns, high levels of parallelism, and unexpected behavior. Load balancing among the heterogeneous compute units will be a critical task in order to achieve an effective usage of the computational power provided by such new architectures. In this highly dynamic scenario, Partitioned Global Address Space (PGAS) languages, like Coarray Fortran, appear a promising alternative to standard MPI programming that uses two-sided communications, in particular because of PGAS one-sided semantic and ease of programmability. In this paper, we show how Coarray Fortran can be used for implementing dynamic load balancing algorithms on an exascale compute node and how these algorithms can produce performance benefits for an Asian option pricing problem, running in symmetric mode on Intel Xeon Phi Knights Corner and Knights Landing architectures. © 2017 Elsevier B.V.","Coarray fortran; Many-core; Partitioned global address space","Economics; Electronic trading; FORTRAN (programming language); Memory architecture; Semantics; Co-array Fortran; Communication pattern; Computational power; Dynamic load balancing algorithms; Many core; Many-core architecture; Partitioned Global Address Space; Performance benefits; Computer architecture",2-s2.0-85020457520
"Poshtkohi A., Ghaznavi-Ghoushchi M.B., Saghafi K.","The Parvicursor infrastructure to facilitate the design of Grid and Cloud computing systems",2017,"Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013436241&doi=10.1007%2fs00607-017-0541-1&partnerID=40&md5=f51bb23d67a13099a3870cebf76ec983","During the past decades, different variants of technology solutions have emerged to eliminate the restrictions on the processing power of computers in solving various problems. Grid and Cloud computing patterns are among the most important of them. In this paper, we introduce a new infrastructure referred to as Parvicursor based on the distributed objects paradigm that can facilitate the construction of scalable and high-performance parallel distributed systems. It proposes several peer-to-peer services to construct scalable distributed system paradigms such as HPC, Grid and Cloud computing. Also, Parvicursor realizes a partial, native, cross-platform, high-performance and C++-based implementation of the.NET ECMA standards. To the best of our knowledge, Parvicursor.NET Framework is the first attempt that allows developers to implement.NET ECMA programs directly in native code. Parvicursor makes use of combining the thread-level parallelism and distributed memory programming models to exploit the strengths of both models in many-core era. © 2017, Springer-Verlag Wien.",".NET Framework; Cloud computing; Distributed systems; Distributed thread-level parallelism; Grid computing; Scalable Internet services; Secure high-throughput data transfer","C++ (programming language); Cloud computing; Data transfer; Grid computing; Peer to peer networks; Distributed systems; Distributed thread; High-throughput data; Internet services; NET framework; Distributed computer systems",2-s2.0-85013436241
"Deng D., Feng S., Shi M., Huang C.","In situ preparation of silver nanoparticles decorated graphene conductive ink for inkjet printing",2017,"Journal of Materials Science: Materials in Electronics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022178571&doi=10.1007%2fs10854-017-7427-z&partnerID=40&md5=cc51eb685d85be772a158b2082130e98","Conductive ink can be widely applied in printed electronics to print high conductivity and flexible electrodes, especially for large-area formats with low cost considerations. In this article, we demonstrated that the in situ prepared silver nanoparticles decorated graphene conductive ink was suitable for flexible electronics. By using liquid phase exfolication method and reducing the silver salt to nano silver at the same system which addressed the heterogeneous issue of silver decorated graphene. The inkjet-printed graphene features attained low resistivity of 20 ± 1Ω/□ after a thermal anneal at 400 °C for 30 min while showed uniform morphology, compatibility with flexible substrates. © 2017, Springer Science+Business Media, LLC.",,"C (programming language); Flexible electronics; Ink; Metal nanoparticles; Nanoparticles; Silver; Flexible electrodes; Flexible substrate; High conductivity; In-situ preparations; Low resistivity; Printed electronics; Silver nanoparticles; Thermal anneals; Graphene",2-s2.0-85022178571
"Krebs I., Jardin S.C., Günter S., Lackner K., Hoelzl M., Strumberger E., Ferraro N.","Magnetic flux pumping in 3D nonlinear magnetohydrodynamic simulations",2017,"Physics of Plasmas",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030177296&doi=10.1063%2f1.4990704&partnerID=40&md5=eb027a5e87d07b8400e7871407eb8977","A self-regulating magnetic flux pumping mechanism in tokamaks that maintains the core safety factor at q-1, thus preventing sawteeth, is analyzed in nonlinear 3D magnetohydrodynamic simulations using the M3D-C1 code. In these simulations, the most important mechanism responsible for the flux pumping is that a saturated (m=1,n=1) quasi-interchange instability generates an effective negative loop voltage in the plasma center via a dynamo effect. It is shown that sawtoothing is prevented in the simulations if β is sufficiently high to provide the necessary drive for the (m=1,n=1) instability that generates the dynamo loop voltage. The necessary amount of dynamo loop voltage is determined by the tendency of the current density profile to centrally peak which, in our simulations, is controlled by the peakedness of the applied heat source profile. © 2017 Author(s).",,"C (programming language); Interactive devices; Magnetic flux; Magnetohydrodynamics; Plasma diagnostics; Plasma stability; Pumps; Safety factor; Current density profiles; Dynamo effect; Heat sources; Loop voltages; Magnetohydrodynamic simulations; Pumping mechanism; Quasi-interchange instability; Sawteeth; Magnetoplasma",2-s2.0-85030177296
"Lu H., Liu Y., Yang Y., Li L.","Preparation of poly (vinyl alcohol)/gelatin composites via in-situ thermal/mechanochemical degradation of collagen fibers during melt extrusion: effect of extrusion temperature",2017,"Journal of Polymer Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032747751&doi=10.1007%2fs10965-017-1377-2&partnerID=40&md5=397808cb3b6aa0b49b79a30d3f9e24ca","By in-situ degradation of collagen fibers into gelatin under the thermal/mechanochemical effects of the extruder, PVA/gelatin composites were successfully prepared using PVA and collagen fibers derived from cattle hide limed split wastes as raw materials. The effect of extrusion temperature on the degradation of collagen fibers and the thermal processability and mechanical properties of the composites were studied. The results showed that the controllable degradation of collagen fibers in extruder could be realized by adjusting the extrusion temperature. Particularly, high extrusion temperature promoted the generation of low-molecular-weight gelatin and the esterification between the hydroxyl of PVA and the carboxyl of gelatin, as well as the hydrogen bonding between O-H, C = O, N-H in gelatin and water or O-H in PVA, thus endowing gelatin with the good compatibility with PVA, and significantly increasing the content of non-freezable bound water in system. Ascribing to the plasticization of the gelatin with lower molecular weight and more non-freezable bound water, PVA/gelatin composites exhibited the improved thermal processability and the decreased mechanical properties with the increase of extrusion temperature. Even so, the tensile strength and Young’s modulus of the composite obtained at 175 °C still above 40 MPa and 1.0 GPa respectively, satisfying some practical applications. © 2017, Springer Science+Business Media B.V.","Collagen fibers; Extrusion temperature; In-situ degradation; Poly (vinyl alcohol); Thermal processability","C (programming language); Collagen; Extrusion; Fibers; Hydrogen bonds; Mechanical properties; Melt spinning; Molecular weight; Polyvinyl alcohols; Collagen fiber; Controllable degradation; Extrusion temperatures; Freezable bound water; Good compatibility; Low molecular weight; Processability; Situ degradation; Tensile strength",2-s2.0-85032747751
"Shi X., Chen Y., Lai Y., Zhang K., Li J., Zhang Z.","Metal organic frameworks templated sulfur-doped mesoporous carbons as anode materials for advanced sodium ion batteries",2017,"Carbon",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025152666&doi=10.1016%2fj.carbon.2017.07.056&partnerID=40&md5=3615e88ef0c81889aef34276dd590af1","In this paper, we focus on an innovative sulfur doping method with MOF-5 and inorganic sulfur powders as templated carbon precursor and sulfur source, in which sulfur powders were firstly encapsulated into the abundant pore structure of MOF-5 and then sulfur doping process could be realized through further pyrolysis treatment. Based on the results of material characterization, sulfur-doped mesoporous carbon (SPC) holds an amorphous structure with an enlarged interlayer distance of 0.386 nm and a mesoporous size distribution of 3–6 nm, while sulfur atoms existing in SPC (2.5 at.%) are mainly in the form of thiophene-type bonds (C–S–C and C[dbnd]S). Benefitting from the structural advantages, SPC electrode could display a long-term cycling stability with a reversible capacity of 173.7 mAh g−1 at 200 mA g−1 after 500 cycles and an outstanding rate capability of 104.9 and 90 mAh g−1 even the current raised up to 1.6 and 3.2 A g−1, respectively. The enhanced electrochemical performances could be mainly attributed to the introduction of S atoms into carbon structure, which can effectively enlarge the interlayer distance, improve the electronic conductivity and promote the insertion/extraction process of sodium storage. © 2017 Elsevier Ltd",,"Amorphous carbon; Anodes; Characterization; Electric batteries; Electrodes; Java programming language; Metal ions; Organometallics; Powder metals; Powders; Secondary batteries; Sulfur; Amorphous structures; Electrochemical performance; Electronic conductivity; Interlayer distance; Material characterizations; Metal organic framework; Sodium ion batteries; Structural advantage; Mesoporous materials",2-s2.0-85025152666
"Müller M.","Effect of surface treatment of adhesive bonded sheet of aluminium alloy EN AW 2024 T3 on adhesive bond strength created by means of structural two-component adhesive",2017,"Manufacturing Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030546160&partnerID=40&md5=ac9a4079021a6d0511caf8455e28dac5","When constructing traffic means, agricultural machines etc. it is necessary to create a bond, namely from thin semi-products, i.e. sheets of metal. Namely light and strong materials such as e.g. aluminium alloys EN AW 2024 T3 (AlCu4Mgl) are used in the constructions. A research namely on the adhesive bonded surface treatment is necessary at a rise of the quality adhesive bond. The aim of the research is an evaluation of the adhesive bonded surface treatment of the aluminium alloy EN AW 2024 T3 (AlCu4Mg1) by means of mechanical tests and a surface analysis by means of SEM. A cyclic degradation loading of the adhesive bond after exposing the adhesive bonds to increased and decreased temperatures, i.e. in the interval -40 to 70 °C in a programmable climatic chamber MKF240 and connected adhesive bonded surface treatments were evaluated within the research. The adhesive bonded surface treatment was of the positive influence on the strength and the elongation of the adhesive bond and it increased the resistance to the cyclic acting of the degradation environment at the same time. © 2017. Published by Manufacturing Technology.","Adhesive bond strength; Chemical treatment; Mechanical treatment; SEM; Surface roughness","Agricultural machinery; Aluminum; Aluminum alloys; Bond (masonry); Bond strength (chemical); Bond strength (materials); C (programming language); Scanning electron microscopy; Surface analysis; Surface roughness; Adhesive bond strengths; Adhesive-bonded; Agricultural machine; Chemical treatments; Climatic chamber; Cyclic degradations; Mechanical treatments; Two-component adhesives; Surface treatment",2-s2.0-85030546160
"Scheffler G.L., Makonnen Y., Pozebon D., Beauchemin D.","Solid sampling analysis of a Mg alloy using electrothermal vaporization inductively coupled plasma optical emission spectrometry",2017,"Journal of Analytical Atomic Spectrometry",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030725066&doi=10.1039%2fc7ja00203c&partnerID=40&md5=1f989a29b95b7900eb06735b0a5da1fc","Electrothermal vaporization hyphenated with inductively coupled plasma optical emission spectrometry (ETV-ICPOES) was applied to the analysis of the AZ31 Mg alloy in an attempt to quantify Al, Cu, Mn, Ni and Zn. Small pieces of the alloy were simply placed in graphite boats for automated insertion into the ETV graphite furnace. The optimized ETV conditions included a carrier gas flow rate of 0.15 L min-1 and an argon by-pass flow rate of 0.50 L min-1, along with 8 mL min-1 Freon 23 (CHF3, trifluoromethane) as the reaction gas. The heating program included pyrolysis (400 °C for 20 s), cooling (20 °C for 15 s), atomization (2200 °C for 30 s) and cooling (20 °C for 20 s) steps. The peak area of each transient signal was integrated (over 50 s) after point-by-point internal standardization with Ar emission (at 415.859 nm) to compensate for loading effects. To build calibration curves, 1 to 6 mg of certified reference material NIST 1648a (Urban Particulate Matter) was weighed into graphite boats. The limits of quantification based on 10 times the standard deviation of the blank (using empty graphite boats and based on 3 mg sample) ranged from 0.2 mg kg-1 (Cu) to 400 mg kg-1 (Ca). The analytes' concentrations obtained were in reasonable agreement with both the reported values and those found after digestion by ICPOES or ICP mass spectrometry. Hence, ETV-ICPOES shows great potential for fast screening of minor and trace elements in Mg alloys. © 2017 The Royal Society of Chemistry.",,"Argon; Boats; Flow of gases; Graphite; Inductively coupled plasma; Light emission; Magnesium; Magnesium alloys; Manganese; Mass spectrometry; Optical emission spectroscopy; Plasma torches; Spectrometry; Trace elements; Vaporization; Carrier gas flow rates; Certified reference materials; Electrothermal vaporization; Inductively coupled plasma-optical emission spectrometry; Internal standardization; Minor and trace elements; Solid sampling analysis; Urban particulate matters; C (programming language)",2-s2.0-85030725066
"Induja I.J., Varma M.R., Sebastian M.T.","Preparation, characterization and properties of alumina-lithium aluminium borosilicate glass based LTCC tapes",2017,"Journal of Materials Science: Materials in Electronics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021123906&doi=10.1007%2fs10854-017-7330-7&partnerID=40&md5=b7ffa67a2dded6717aead3205403646d","A new low temperature cofired ceramic (LTCC) tape based on 40 wt% Al2O3–60 wt% LABS glass (40Li2CO3:10Al2O3:30B2O3:20SiO2) has been developed. The dielectric properties of the LABS glass are studied. The structural, dielectric, thermal as well as the chemical compatibility with Ag electrode of the bulk Al2O3–LABS sintered at 800 °C are investigated.The room temperature thermal conductivity and CTE of the bulk are 3.80 Wm−1 K−1 and 5.1 ppm/°C respectively. The Al2O3–LABS slurry which has a pseudoplastic nature is made into thin sheets using tape casting technique. The green tape has a surface roughness of 293 nm and tensile strength 0.2 MPa. The Al2O3–LABS based LTCC tapes are sintered at 775 °C has εr of 4.70 with tanδ 0.005 and τε of +412 ppm/°C at 5 GHz. The results suggest that the Al2O3–LABS based LTCC tapes is a possible candidate for LTCC device applications. © 2017, Springer Science+Business Media, LLC.",,"Alumina; C (programming language); Dielectric properties; Laboratories; Sintering; Surface roughness; Tensile strength; Thermal conductivity; Ag electrode; Chemical compatibility; Device application; Green tape; Low-temperature co-fired ceramics; Pseudoplastic; Tape-casting technique; Thin sheet; Borosilicate glass",2-s2.0-85021123906
"Pietra F.D., Gavitone N., Kovařík H.","Optimizing the first eigenvalue of some quasilinear operators with respect to boundary conditions",2017,"ESAIM - Control, Optimisation and Calculus of Variations",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032193686&doi=10.1051%2fcocv%2f2016058&partnerID=40&md5=29680823f1b995a0b5ce1c4323b5a210","We consider a class of quasilinear operators on a bounded domain Ω C Rn and address the question of optimizing the first eigenvalue with respect to the boundary conditions, which are of the Robin-type. We describe the optimizing boundary conditions and establish upper and lower bounds on the respective maximal and minimal eigenvalue. © 2017 EDP Sciences, SMAI.","Optimization problem; P-Laplacian; Robin boundary conditions","Boundary conditions; C (programming language); Optimization; Bounded domain; Eigen-value; Optimization problems; P-Laplacian; Quasilinear operators; Robin boundary conditions; Upper and lower bounds; Eigenvalues and eigenfunctions",2-s2.0-85032193686
"Zhu X., Pedrycz W., Li Z.","Granular Encoders and Decoders: A Study in Processing Information Granules",2017,"IEEE Transactions on Fuzzy Systems",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014677246&doi=10.1109%2fTFUZZ.2016.2598366&partnerID=40&md5=5ba147ed52773695db7abc3341e27b46","Information granules are generic building blocks supporting the processing realized in granular computing and facilitating communication with the environment. In this paper, we are concerned with a fundamental problem of encoding-decoding of information granules. The essence of the problem is outlined as follows: Given a finite collection of granular data X1, X2,...,XN (sets, fuzzy sets, etc.), construct an optimal codebook composed of information granules A1, A2,..., Ac, where typically c &lt;&lt; N, so that any Xk represented in terms of Ai's and then decoded (reconstructed) with the help of this codebook leads to the lowest decoding error. A fundamental result is established, which states that in the proposed encoders and decoders, when encoding-decoding error is present, the information granule coming as a result of decoding is of a higher type than the original information granules (say, if Xk is information granule of type-1, then its decoded version becomes information granule of type-2). It would be beneficial to note that as the encoding-decoding process is not lossless (in general, with an exception of a few special cases), the lossy nature of the method is emphasized by the emergence of information granules of higher type (in comparison with the original data being processed). For instance, when realizing encoding-decoding of numeric data (viz., information granules of type-0), the losses occur and they are quantified in terms of intervals, fuzzy sets, probabilities, rough sets, etc., where, in fact, the result becomes an information granule of type-1. In light of the nature of the constructed result when Xk is an interval or a fuzzy set, an optimized performance index engages a distance between the bounds of the interval-valued membership function. We develop decoding and encoding mechanisms by engaging the theory of possibility and fuzzy relational calculus and show that the decoded information granule is either a granular interval or interval-valued fuzzy set. The optimization mechanism is realized with the aid of the particle swarm optimization (PSO). A series of experiments are reported with intent to illustrate the details of the encoding-decoding mechanisms and show that the PSO algorithm can efficiently optimize the granular codebook. © 2017 IEEE.","Encoding and decoding; granular computing; higher type information granules; information granule; particle swarm optimization (PSO); reconstruction error; representation and reconstruction","C (programming language); Calculations; Computation theory; Decoding; Encoding (symbols); Errors; Fuzzy sets; Granular computing; Granulation; Membership functions; Particle swarm optimization (PSO); Particles (particulate matter); Signal encoding; Encoders and decoders; Encoding and decoding; Encoding mechanism; Encoding-decoding; Interval-valued fuzzy sets; Optimized performance; Reconstruction error; Relational calculus; Information granules",2-s2.0-85014677246
"Feng H., Zhang W., Dong C., Cao J., Li D.","Verification of linear resistive tearing instability with gyrokinetic particle code VirtEx",2017,"Physics of Plasmas",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032031320&doi=10.1063%2f1.4999166&partnerID=40&md5=615d6647c1d48db6c7ec84318d530a96","Current-driven resistive tearing instability is verified using the newly developed global first-principles particle-in-cell code called VirtEx, which was coded from scratch in conformity with the C++'11 specifications. The tearing instability is first verified in the fluid limit in a cylinder geometry by ignoring the gyrokinetic effect of ions, and the numerical results agree well with the analytical predictions of the resistive tearing theory. Then, the effect of toroidicity on resistive tearing instability is investigated. © 2017 Author(s).",,"Plasma theory; Stability; Analytical predictions; Current-driven; Effect of ions; First principles; Gyrokinetics; Numerical results; Particle in cell codes; Tearing instability; C++ (programming language)",2-s2.0-85032031320
"Mikhailov O.V., Chachkov D.V.","Molecular structures of (575)macrotricyclic 3d-metal chelates in M(II)–N-methylthiocarbohydrazide–hexanedione-2,5 according to density functional theory calculations",2017,"Russian Journal of Inorganic Chemistry",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032035900&doi=10.1134%2fS0036023617100138&partnerID=40&md5=f6ff07326dc1516a5e44d8e744fd8f28","The geometric parameters of the molecular structures and thermodynamic parameters of macrotricyclic M(II) (M = Mn, Fe, Co, Ni, Cu, Zn) complexes with an MN2S2 chelate core formed by the template reactions of the M(II) with N-methylthiocarbohydrazide H3C–HN–HN–C(=S)–NH–NH2 and hexanedione- 2,5 H3C–C(=O)–CH2–CH2–C(=O)–CH3 have been calculated by the DFT method with the Gaussian09 program package. The bond lengths, bond angles, and some nonbonded angles in these complexes have been determined. In all the complexes, the M(II) central ion is pseudotetrahedrally coordinated by the donor atoms of an inner-sphere tetradentate ligand; the (N2S2) group of the donor atoms is not planar. The additional seven-membered chelate rings show significant deviations from coplanarity (&gt;60°). The noncoplanatiry of the five-membered rings is less pronounced. © 2017, Pleiades Publishing, Ltd.",,"C (programming language); Chelation; Coordination reactions; Manganese; Molecular structure; Software packages; Chelate ring; Coplanarity; Five-membered rings; Inner spheres; Program packages; Template reactions; Tetradentate ligands; Thermodynamic parameter; Density functional theory",2-s2.0-85032035900
"S. Alves E.H.D., Cordeiro L.C., L. Filho E.B.D.","A method to localize faults in concurrent C programs",2017,"Journal of Systems and Software",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015765249&doi=10.1016%2fj.jss.2017.03.010&partnerID=40&md5=9fd371ba2ca66285baa4c274af5f039e","We describe a new approach to localize faults in concurrent programs, which is based on bounded model checking and sequentialization techniques. The main novelty is the idea of reproducing a faulty behavior, in a sequential version of a concurrent program. In order to pinpoint faulty lines, we analyze counterexamples generated by a model checker, to the new instrumented sequential program, and search for a diagnostic value, which corresponds to actual lines in a program. This approach is useful to improve debugging processes for concurrent programs, since it tells which line should be corrected and what values lead to a successful execution. We implemented this approach as a code-to-code transformation from concurrent into non-deterministic sequential programs, which are used as inputs to existing verification tools. Experimental results show that our approach is effective and capable of identifying faults in our benchmark set, which was extracted from the SV-COMP 2016 suite. © 2017 Elsevier Inc.","Bounded model checking; Concurrent software; Fault localization; Non-determinism; Sequentialization","Cosine transforms; Model checking; Program debugging; Program diagnostics; Bounded model checking; Concurrent software; Fault localization; Non Determinism; Sequentialization; C (programming language)",2-s2.0-85015765249
"Kalhor S., Ghanaatshoar M., Kashiwagi T., Kadowaki K., Kelly M.J., Delfanazari K.","Thermal Tuning of High-Tc Superconducting Bi2Sr2CaCu2O8+δ Terahertz Metamaterial",2017,"IEEE Photonics Journal",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030716046&doi=10.1109%2fJPHOT.2017.2754465&partnerID=40&md5=c05f2c80739bcdab63ed40ef444543e5","We introduce a class of low-loss subwavelength resonators and report the first demonstration of a high-temperature ( Tc) superconducting Bi2Sr2 CaCu2O8+δ (BSCCO) terahertz (THz) metamaterial. The numerical simulations and analytical calculations are performed to study the electromagnetic response of the subwavelength BSCCO split-ring resonators (SRRs) to the incident photons with energies below the superconducting gap energy. A transition of resonance strength is observed as a dip in resonance frequency for temperatures below BSCCO Tc. To interpret the transmission spectra, resonance switching, and frequency tuning of SRRs, we calculate the temperature dependent complex permittivity and surface impedance of a 200 nm thick unpatterned slightly underdoped BSCCO thin film. We compare the resonance tunability of SRRs made of the extremely disorder superconductor (BSCCO) with metamaterials made of a weakly disorder superconductor YBa2Cu3O7 (YBCO) and show that the resonance quality and frequency tuning are comparable for these two metamaterials. Our results may be useful for THz emitters and detectors developments, for instance, by integration of SRRs with BSCCO THz emitters and microstrip antennas, the device functionalities such as polarization, emission pattern directivity, and output power could be controlled and improved. © 2009-2012 IEEE.","Antennas and split-ring resonators; BSCCO THz emitters and detectors; superconducting metamaterials.","Antennas; C (programming language); Electric impedance; Metamaterials; Microstrip antennas; Optical resonators; Resonance; Resonators; Superconducting materials; Superconducting resonators; Tuning; Yttrium barium copper oxides; Analytical calculation; AND splits; Electromagnetic response; Resonance frequencies; Sub-wavelength resonators; Temperature dependent; THz emitters; Transmission spectrums; Ring gages",2-s2.0-85030716046
"Liu W., Yao X., Chen X.","A local stress approach to predict the fatigue life of the U-notched PMMA plate at different temperatures",2017,"International Journal of Fatigue",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021376156&doi=10.1016%2fj.ijfatigue.2017.06.031&partnerID=40&md5=70c3d30d57162a339ff1907aa436a872","In this paper, the fatigue lives of U-notched polymethyl methacrylate (PMMA) plate at different temperatures are numerically investigated on the basis of local stress approach. First, a local stress approach for fatigue damage at the U-notch is presented based on the principle of equivalent damage life. Second, the strength and stiffness degeneration criterions during the fatigue process are established to take account of the nonlinear cumulative fatigue damage. Finally, the commercial software ABAQUS is employed to predict the fatigue S-N curves of the U-notched PMMA plate at various constant temperatures of −55 °C, 23 °C and 60 °C using a user-defined material (UMAT) subroutine. The numerical results of the fatigue life are in good agreements with the experimental data, which verify the effectiveness of the local stress approach. © 2017 Elsevier Ltd","Different temperatures; Equivalent damage life; Fatigue life; Local stress approach; U-notched plate","ABAQUS; C (programming language); Fatigue of materials; Polymethyl methacrylates; Subroutines; Commercial software; Constant temperature; Cumulative fatigue damage; Equivalent damage; Fatigue process; Local stress; Numerical results; Strength and stiffness; Fatigue damage",2-s2.0-85021376156
"Henríquez-Vargas L., Villaroel E., Gutierrez J., Donoso-García P.","Implementation of a parallel ADI algorithm on a finite volume GPU-based elementary porous media flow computation",2017,"Journal of the Brazilian Society of Mechanical Sciences and Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029759923&doi=10.1007%2fs40430-017-0882-x&partnerID=40&md5=eb3d369deef1c45f3e19d6f4411622aa","In this work we present flow simulations in laminar and turbulent regime within a representative elementary volume of a simplified porous media by solving the Navier–Stokes equations and a Low-Re turbulence k- ϵ model. Numerical solution was achieved with an implementation of the SIMPLE algorithm for pressure velocity coupling of variables, and the solution of the tridiagonal systems of algebraic equations was accomplished by a parallelized ADI scheme based on the Thomas algorithm. Implementation of the numerical solution was done with an in-house C code which combined OMP and CUDA technologies for computations based on CPU and GPU, respectively. Exponential structured grids were employed in the wall vicinity to capture the turbulence behavior. Results indicate that similar profiles for velocity, pressure, turbulent kinetic energy and its dissipation were found. Several CUDA grids were tested and their performances measured over two GPUs: GTX 680 and GTX TITAN. Considerable speedup was achieved by the GPUs over the CPU schemes even without the use of the device shared memory which was not explored due to the nature of the algorithm. © 2017, The Brazilian Society of Mechanical Sciences and Engineering.","CUDA; Low-Re; Parallel ADI; Porous media; SIMPLE","C (programming language); Graphics processing unit; Kinetic energy; Kinetics; Navier Stokes equations; Program processors; Turbulence; CUDA; Numerical solution; Parallel ADI; Pressure-velocity coupling; Representative elementary volume; SIMPLE; Tridiagonal systems; Turbulent kinetic energy; Porous materials",2-s2.0-85029759923
"Xiang H., Fang L., Tang Y., Li C.","Effects of Zn non-stoichiometry on the phase evolution and microwave dielectric properties of Li2Zn1−xGe3O8 (0 ≤ x ≤ 0.2) spinels",2017,"Journal of Materials Science: Materials in Electronics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021971635&doi=10.1007%2fs10854-017-7447-8&partnerID=40&md5=17e98cc9c53ce4208cbdd251724d7402","A series of Li2Zn1−xGe3O8 (0 ≤ x ≤ 0.2) spinels were prepared by the conventional solid-state reaction. The phase composition and microstructure were investigated using X-ray diffraction, Raman spectroscopy and scanning electron microscope. The microwave dielectric properties of samples were observed strongly dependent on the sintering temperature and composition. Li2Zn1−xGe3O8 (0 ≤ x ≤ 0.2) ceramics were well densified at 950 °C for 4 h and the best microwave dielectric properties were achieved at x = 0.15 with εr = 8.7, Q × f = 99,600 GHz (at 15.0 GHz), and τf = −60.1 ppm/°C. Furthermore, the chemical compatibility with the silver electrode were confirmed for Li2Zn1−xGe3O8 ceramics. These ceramics could be possible candidates as LTCC materials. © 2017, Springer Science+Business Media, LLC.",,"C (programming language); Ceramic materials; Scanning electron microscopy; Sintering; Solid state reactions; X ray diffraction; Chemical compatibility; Microwave dielectric properties; Non stoichiometry; Phase evolutions; Silver electrode; Sintering temperatures; Dielectric properties",2-s2.0-85021971635
"Díez-Ramírez J., Sánchez P., Kyriakou V., Zafeiratos S., Marnellos G.E., Konsolakis M., Dorado F.","Effect of support nature on the cobalt-catalyzed CO2 hydrogenation",2017,"Journal of CO2 Utilization",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029150123&doi=10.1016%2fj.jcou.2017.08.019&partnerID=40&md5=d73034c96ba5ec54e0cd348fad4f09f9","CO2 hydrogenation to value added chemicals/fuels has gained considerable interest, in terms of sustainable energy and environmental mitigation. In this regard, the present work aims to investigate the CO2 methanation performance of cobalt-based catalysts supported on different metal oxides (MxOy: CeO2, ZrO2, Gd2O3, ZnO) at low temperatures (200-300 °C) and under atmospheric pressure. Various characterization methods, such as N2 adsorption-desorption at -196 °C, X-ray diffraction (XRD), X-ray photoelectron spectroscopy (XPS) and temperature-programmed reduction (TPR), were employed to correlate the structural and surface properties of the materials with their catalytic activity. The results revealed a significant impact of support nature on the CO2 hydrogenation performance. The following order, in terms of CH4 yield (YCH4), was recorded at 300 °C: Co/CeO2 (∼96%) &gt; Co/ZnO (∼54%) &gt; Co/G2O3 (∼53%) ∼ Co/ZrO2 (∼53%). On the basis of the characterization results, the superiority of Co/CeO2 catalyst can be mainly ascribed to its enhanced reducibility linked to Co-Ceria interactions. Moreover, Co/CeO2 demonstrated a stable conversion/selectivity performance under subsequent reaction cycles, in contrast to Co/ZnO, which progressively activated under reaction conditions. The latter is related with the modifications induced in elemental chemical states and surface composition of Co/ZnO upon pretreatment in reaction conditions, in contrast to Co/CeO2 sample where a stable surface performance was observed. © 2017 Elsevier Ltd. All rights reserved.","Co-based catalysts; CO2 hydrogenation; Methanation","Atmospheric pressure; C (programming language); Carbon dioxide; Catalyst activity; Catalysts; Chemical modification; Cobalt; Hydrogenation; Methanation; Temperature programmed desorption; X ray diffraction; Characterization methods; Co-based catalysts; CO2 hydrogenation; Cobalt-based catalysts; Environmental mitigation; Reaction conditions; Temperature-programmed reduction; Value-added chemicals; X ray photoelectron spectroscopy",2-s2.0-85029150123
"GAO Z., ZHANG S., MA H., LI Z.","Surface composition change of chlorine-doped catalyst Ni(Clx)/CeO2 in methanation reaction",2017,"Journal of Rare Earths",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030173649&doi=10.1016%2fS1002-0721%2817%2961002-0&partnerID=40&md5=8233356f06205a7f22b5f73209469b0b","The oxide sample NiO/CeO2 with feed atomic ratio of Ni/Ce at 40%, prepared by co-precipitation method and calcination at 500 °C for 2 h, was impregnated by aqueous solution of NH4Cl to dope chlorine ions. After the impregnated samples were dried and calcined at 400 °C for 2 h, the calcined samples NiO(Clx)/CeO2 (x=0.1–0.5) were characterized by means of X-ray diffraction (XRD) and temperature programmed reduction (TPR) techniques. It was comfirmed that the doped chlorine ions hindered reduction of Ni2+ ions in the calcined samples, and suppressed adsorption of CO2 and CO on the reduced sample Ni(Cl0.3)/CeO2. The reduced samples Ni(Clx)/CeO2 (x=0.0–0.5) were used as catalysts for selective methanation of CO in H2-rich gas. When chlorine ions were doped at the feed atomic ratio of Cl/Ce(x) equal to 0.3–0.5, CO in the H2-rich gas could be removed to below 10 ppm with a high selectivity more than 50% in a wide reaction temperature range of 220–280 °C. However, the selectivity of CO methanation decreased with reaction time in the durability tests over the catalyst Ni(Cl0.3)/CeO2 at the reaction temperature of 260 °C and even at 220 °C. The lowering of the selectivity was found to be related with the surface composition change of the catalyst in the catalytic reaction. © 2017 The Chinese Society of Rare Earths","compositional analysis; hydrogen purification; rare earths; selective methanation; XPS; XRF","C (programming language); Calcination; Catalysis; Catalysts; Chlorine; Doping (additives); Durability; Hydrogenation; Ions; Methanation; Nickel; Precipitation (chemical); Rare earths; Solutions; X ray diffraction; X ray photoelectron spectroscopy; Catalytic reactions; Compositional analysis; Coprecipitation method; Hydrogen purification; Reaction temperature; Selective methanation; Selective methanation of CO; Temperature-programmed reduction; Catalyst selectivity",2-s2.0-85030173649
"Guidi M., Fregolent A., Ruta G.","Curvature effects on the eigenproperties of axisymmetric thin shells",2017,"Thin-Walled Structures",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020727743&doi=10.1016%2fj.tws.2017.06.007&partnerID=40&md5=a588d35d20e020326f0eeb5210314079","A set of linear elastic homogeneous isotropic axisymmetric thin shells of revolution with plane projection of radius R varying with the height c of the pole, to keep constant mass, is introduced. Their curvature and dynamical properties depend on the ratio c/R, and their linear dynamics is investigated by standard modal analysis, adopting a commercial code, and accounting for curvature. Natural frequencies for a given mode are linear with c/R, decrease for membrane modes, and increase for transverse modes. Thus, membrane and transverse modes may shift as curvature grows; graphical and numerical results are reported. © 2017 Elsevier Ltd","Axisymmetric shells; Curvature; Eigenfrequencies","Modal analysis; Axisymmetric shells; Commercial codes; Curvature; Curvature effect; Dynamical properties; Eigen frequencies; Linear dynamics; Numerical results; C (programming language)",2-s2.0-85020727743
"Zhang C., Hu Y.","CuFusion: Accurate real-time camera tracking and volumetric scene reconstruction with a cuboid",2017,"Sensors (Switzerland)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030719832&doi=10.3390%2fs17102260&partnerID=40&md5=82f4f17166ad3df38e99db24d548b434","Given a stream of depth images with a known cuboid reference object present in the scene, we propose a novel approach for accurate camera tracking and volumetric surface reconstruction in real-time. Our contribution in this paper is threefold: (a) utilizing a priori knowledge of the precisely manufactured cuboid reference object, we keep drift-free camera tracking without explicit global optimization; (b) we improve the fineness of the volumetric surface representation by proposing a prediction-corrected data fusion strategy rather than a simple moving average, which enables accurate reconstruction of high-frequency details such as the sharp edges of objects and geometries of high curvature; (c) we introduce a benchmark dataset CU3D that contains both synthetic and real-world scanning sequences with ground-truth camera trajectories and surface models for the quantitative evaluation of 3D reconstruction algorithms. We test our algorithm on our dataset and demonstrate its accuracy compared with other state-of-the-art algorithms. We release both our dataset and code as open-source (https://github.com/zhangxaochen/CuFusion) for other researchers to reproduce and verify our results. © 2017 by the authors. Licensee MDPI, Basel, Switzerland.","Depth cameras; Kinect sensors; Open source; Real-time reconstruction; SLAM","C (programming language); Cameras; Curve fitting; Data fusion; Global optimization; Image reconstruction; Open systems; Optimization; Statistical tests; Surface reconstruction; Depth camera; Kinect sensors; Open sources; Real-time reconstruction; SLAM; Three dimensional computer graphics",2-s2.0-85030719832
"Emam H.E., Abdelhameed R.M.","In-situ modification of natural fabrics by Cu-BTC MOF for effective release of insect repellent (N,N-diethyl-3-methylbenzamide)",2017,"Journal of Porous Materials",5,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009280984&doi=10.1007%2fs10934-016-0357-y&partnerID=40&md5=8cb50fffcecbfacee24cd7c2546f439a","Insect repellent fabrics are now of interest to secure human beings from the harmful effects of insects, but control the release of insect repellent from such fabrics is much important. The present study showed a good strategy to release effectively of N,N-diethyl-3-methylbenzamide (DEET) as insect repellent, from natural fabrics. Copper-benzene-1,3,5-tricarboxylic acid (Cu-BTC) as metal organic framework (MOF) material was in-situ incorporated into the matrix of natural fabrics including Cotton, Linen and Silk. DEET was then loaded onto the modified fabrics and the release of DEET from fabrics was studied. The successfulness of Cu-BTC incorporation was confirmed by scanning electron microscope, energy dispersive X-ray, X-ray diffraction and attenuated total reflectance—fourier transform infrared spectroscopy. The measured contents of Cu and Cu-BTC in fabrics were ranged in 35.9–38.9 and 115.4–130.3 mg/g fabrics, respectively. After loading the DEET into fabrics, the measured content of DEET was followed the order of Silk < Linen < Cotton and the modified fabrics exhibited much higher DEET by percent of 65–110%. Due to MOF modification, the released amount of DEET from fabrics was considerably increased by value of 205–220 mg/g and the release time became as long as 24–36 h. The release rate was fitted well to zero order model as the rate is independent of the reactant concentration. The so-obtained product can be applicable as disposable insect repellent materials for controllable and effective release of DEET for such a long residence time exceeded 9 days. © 2017, Springer Science+Business Media New York.","Cotton; Cu-BTC; DEET; Insect repellent; Linen; Release; Silk","Cotton; Crystalline materials; Flax; Fourier transform infrared spectroscopy; Linen; Organometallics; Scanning electron microscopy; Silk; X ray diffraction; Attenuated total reflectance; DEET; Energy dispersive x-ray; Insect repellent; Metal organic framework materials; Reactant concentrations; Release; Zero-order models; Java programming language",2-s2.0-85009280984
"Goparaju S., Fazeli A., Vardy A.","Minimum storage regenerating codes for All parameters",2017,"IEEE Transactions on Information Theory",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030116013&doi=10.1109%2fTIT.2017.2690662&partnerID=40&md5=753cfde142ccdf17c665f39f655fd576","RRegenerating codes for distributed storage have attracted much research interest in the past decade. Such codes trade the bandwidth needed to repair a failed node with the overall amount of data stored in the network. Minimum storage regenerating (MSR) codes are an important class of optimal regenerating codes that minimize (first) the amount of data stored per node and (then) the repair bandwidth. Specifically, an [n, k, d]-(a) MSR code C over Fq stores a file F consisting of ak symbols over Fq among n nodes, each storing a symbols, in such a way that: 1) the file F can be recovered by downloading the content of any k of the n nodes and 2) the content of any failed node can be reconstructed by accessing any d of the remaining n - 1 nodes and downloading a/(d-k+1) symbols from each of these nodes. In practice, the file F is typically available in uncoded form on some k of the n nodes, known as systematic nodes, and the defining node-repair condition above can be relaxed to requiring the optimal repair bandwidth for systematic nodes only. Such codes are called systematic-repair MSR codes. Unfortunately, finite-a constructions of [n, k, d] MSR codes are known only for certain special cases: either low rate, namely k/n 0.5, or high repair connectivity, namely d = n - 1. Our main result in this paper is a finite-a construction of systematicrepair [n, k, d] MSR codes for all possible values of parameters n, k, d. We also introduce a generalized construction for [n, k] MSR codes to achieve the optimal repair bandwidth for all values of d simultaneously. © 1963-2012 IEEE.","Distributed storage systems; interference alignment; regenerating codes","Bandwidth; Codes (symbols); Digital storage; Multiprocessing systems; Repair; Distributed storage; Distributed storage system; Failed nodes; Interference alignment; Low rates; Regenerating codes; Research interests; UNCODED; C (programming language)",2-s2.0-85030116013
"Yang L., Zhu Y., Jiao Y., Yang D., Chen Y., Wu J., Lu Z., Zhao S., Pu X., Huang Y.","The influence of intramolecular noncovalent interactions in unsymmetrical squaraines on material properties, film morphology and photovoltaic performance",2017,"Dyes and Pigments",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020481990&doi=10.1016%2fj.dyepig.2017.04.021&partnerID=40&md5=269933f9a8e166ff16abc5caefca85e4","Three unsymmetrical squaraines (USQs) with different number of hydroxyl groups (BIISQ bearing two hydroxyl substituents, BIISQ-MOH bearing mono-one, and BIISQ-NOH bearing none) have been synthesized to understand of the insightful molecular structure-property relationship of photovoltaic materials. Our research shows that the introduction of strong intramolecular hydrogen bonding (HB) interactions between donor (D) and acceptor (A) units of squaraines can affect the whole π-conjugated properties, such as deepening the highest occupied molecular orbital (HOMO) energy level and thus enhancing the open-circuit voltage (Voc), increasing the dipole moment and improving hole mobility, weakening the electron-withdrawing ability of centric four-membered rings (as A unit in squaraines) and then improving the compatibility between USQ and [6,6]-phenyl-C71butyric acid methyl ester (PC71BM). Eventually, the bulk-heterojunction organic photovoltaic device (BHJ-OPV) based on BIISQ has obtained the best performance, which is approximately three times higher than that of BIISQ-NOH-based one. Interestingly, our research also finds that thin layer chromatography (TLC) analysis might be a simple, cheap, and rapid way to preliminarily forecast the compatibility between donor materials and PC71BM when the molecular skeletons of donor materials are relatively similar. © 2017 Elsevier Ltd","Hydroxyl group; Noncovalent interaction; Organic photovoltaic; Phase separation; Unsymmetrical squaraines","Butyric acid; Chromatography; Heterojunctions; Hole mobility; Hydrogen bonds; Ions; Molecular orbitals; Open circuit voltage; Phase separation; Steel beams and girders; Thin layer chromatography; Electron-withdrawing ability; Highest occupied molecular orbital energy levels; Hydroxyl groups; Intramolecular hydrogen bonding; Non-covalent interaction; Organic photovoltaics; Squaraines; Structure property relationships; C (programming language)",2-s2.0-85020481990
"Vivaldo I., Moreno M., Torres A., Ambrosio R., Rosales P., Carlos N., Calleja W., Monfil K., Benítez A.","A comparative study of amorphous silicon carbide and silicon rich oxide for light emission applications",2017,"Journal of Luminescence",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019926160&doi=10.1016%2fj.jlumin.2017.05.048&partnerID=40&md5=9c356595087596d206445f723161073f","In this work we performed a comparative study of the structural, optical and photoluminescent properties of amorphous Silicon Carbide (a-Si1−xCx:H) and Silicon Rich Oxide (SRO). We have optimized the deposition conditions of a-Si1−xCx:H in order to improve the photoluminescence (PL) intensity and we have been able to produce films with similar PL intensity than that of SRO, which has been extensively studied due to its high level of PL and its compatibility with the silicon technology. The a-Si1−xCx:H films have been deposited at low temperature (150 °C), while thermal treatments at high temperatures were not necessary as is done for SRO in order to improve its PL intensity. The above makes a-Si1−xCx:H an alternative material for low temperature optoelectronic silicon based devices and also for flexible device applications. © 2017 Elsevier B.V.","Photoluminescence; Silicon carbide; Silicon rich oxide","C (programming language); Photoluminescence; Silicon; Silicon carbide; Temperature; Alternative materials; Deposition conditions; Flexible device applications; Photo-luminescent properties; Photoluminescence intensities; Silicon rich oxides; Silicon Technologies; Silicon-based devices; Amorphous silicon",2-s2.0-85019926160
"Singh J., Manam J., Singh F.","Synthesis and thermoluminescence studies of γ-irradiated Dy3+ doped SrGd2O4 phosphor",2017,"Materials Research Bulletin",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019989652&doi=10.1016%2fj.materresbull.2017.05.052&partnerID=40&md5=3e69f9dec710d0cd947ac78556df9bb5","Dy3+ doped SrGd2O4 phosphors were synthesized via homogeneous precipitation cum auto-combustion method for the first time. Orthorhombic phase formation and granular morphology of SrGd2O4: Dy3+ samples were investigated through X-ray diffraction (XRD) and microscopic studies. Thermoluminescence (TL) characteristics of SrGd2O4: Dy3+ phosphors were taken after exposure of 60Co γ-rays. The TL glow curve of as-prepared phosphors was well-resolved into five peaks 114 °C, 161 °C, 198 °C, 248 °C, and 293 °C by using computerized glow curve deconvolution program. The effect of impurity (Dy3+) contents and heating rates for the TL glow curves were also studied. The linear behaviour of as-formed SrGd2O4: Dy3+ samples are observed within a wide range of dose of 80 Gy–2 kGy. Fading characteristics of SrGd2O4: Dy3+ phosphor was studied over the duration of 30 days. A comparative study was done to estimate different trapping parameters by employing Chen's peak shape method and CGCD simulation of TL glow curves. © 2017 Elsevier Ltd","A. Oxides; B. Luminescence; D. Defects; D. Phosphors","Gamma rays; Light emission; Phosphors; Thermoluminescence; X ray diffraction; Auto-combustion methods; Comparative studies; Fading characteristics; Glow curve deconvolution; Granular morphology; Homogeneous Precipitation; Orthorhombic phase; Trapping parameter; C (programming language)",2-s2.0-85019989652
"Pohrelyuk I.M., Lavrys S.M., Sakharuk O.M., Stasyshyn I.V., Penkovyi O.V.","Pretreatment Influence on Titanium Surface Properties After Gas Nitriding",2017,"Journal of Materials Engineering and Performance",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029595323&doi=10.1007%2fs11665-017-2934-x&partnerID=40&md5=af76acec6e52c79929e2e0b396ed3170","Influence of an initial mechanical treatment (grinding, polishing) on geometry and physical–mechanical parameters of a commercially pure titanium (Grade 2) surface after thermodiffusive saturation by nitrogen was studied. Microstructure analysis has shown that mechanism of formation and growth of a nitride film depends on the initial mechanical treatment. Nitriding under temperature of 750 °C does not influence practically the quality of ground surfaces and decreases it on one class for polished one. For higher saturation temperatures, surface quality has little dependence from the initial treatment. The best set of geometry and physical–mechanical characteristics belongs to the surface, which was initially polished and nitrided subsequently under 750 °C temperature, which provides its high wear resistance. © 2017, ASM International.","mechanical treatment; nitriding; roughness; structural-phase state; surface topography; titanium","C (programming language); Film growth; Nitriding; Surface roughness; Titanium; Wear resistance; Commercially Pure titaniums; Mechanical characteristics; Mechanical parameters; Mechanical treatments; Mechanism of formation; Microstructure analysis; Saturation temperature; Structural-phase state; Surface topography",2-s2.0-85029595323
"Gonçalves R., Areias M., Rocha R.","Towards an automated test bench environment for prolog systems",2017,"OpenAccess Series in Informatics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032636532&doi=10.4230%2fOASIcs.SLATE.2017.2&partnerID=40&md5=47e7c69f95f1ec7e015d20d31c5e63b7","Software testing and benchmarking is a key component of the software development process. Nowadays, a good practice in big software projects is the Continuous Integration (CI) software development technique. The key idea of CI is to let developers integrate their work as they produce it, instead of doing the integration at the end of each software module. In this paper, we extend a previous work on a benchmark suite for the Yap Prolog system and we propose a fully automated test bench environment for Prolog systems, named Yet Another Prolog Test Bench Environment (YAPTBE), aimed to assist developers in the development and CI of Prolog systems. YAPTBE is based on a cloud computing architecture and relies on the Jenkins framework and in a set of new Jenkins plugins to manage the underneath infrastructure. We present the key design and implementation aspects of YAPTBE and show its most important features, such as its graphical user interface and the automated process that builds and runs Prolog systems and benchmarks. © Ricardo Gonçalves, Miguel Areias, and Ricardo Rocha","Benchmarking; Program Correctness; Prolog; Software Engineering","Automation; Benchmarking; Computer architecture; Graphical user interfaces; Slate; Software design; Software engineering; Software testing; User interfaces; Cloud computing architectures; Continuous integrations; Design and implementations; Important features; Program correctness; Prolog; Software development process; Software development techniques; PROLOG (programming language)",2-s2.0-85032636532
"Liu J., Gao X., Xu J.-L., Ruotolo A., Wang S.-D.","Flexible low-power organic complementary inverter based on low-${k}$ polymer dielectric",2017,"IEEE Electron Device Letters",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028953672&doi=10.1109%2fLED.2017.2737548&partnerID=40&md5=3046185486d8ff1e12cf0965cf0d9e9b","Organic complementary inverters that have high performance, low-power operation, and flexible compatibility are achieved using a simple and low-cost method to prepare a thin low-${k}$polymer dielectric on sputtered C nanoparticles. The operation voltage of the flexible inverter can be as low as 3 V, and the gain is close to 200, which is superior to most reported organic-based inverters. The flexible inverter also exhibits outstanding switching stability in multiple signal processing. The present organic inverters may be of value in portable and wearable electronics. © 1980-2012 IEEE.","Complementary inverter; Flexible; Low-k dielectric; Organic field-effect transistors","C (programming language); Dielectric devices; Dielectric materials; Electric inverters; Field effect transistors; Gates (transistor); Logic gates; Organic field effect transistors; Organic polymers; Polymers; Signal processing; Silicon; Substrates; Complementary inverters; Flexible; Low-power operation; Operation voltage; Organic complementary inverters; Organic inverters; Polymer dielectrics; Switching stability; Low-k dielectric",2-s2.0-85028953672
"Yu H., Yin J., Soleimanbeigi A., Likos W.J.","Effects of curing time and fly ash content on properties of stabilized dredged material",2017,"Journal of Materials in Civil Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026483129&doi=10.1061%2f%28ASCE%29MT.1943-5533.0002032&partnerID=40&md5=9181e1a52865ecda8ca4291466f8c0fe","Properties of raw dredged material (RDM) stabilized with self-cementing Class C fly ash (FA) were evaluated for beneficial use in geotechnical construction applications. Emphasis was placed on evaluating effects of curing time and fly ash content on index and engineering properties relevant to pavement construction. RDM samples were blended with 10, 20, and 30% FA and cured for 2 h, 7 days, and 28 days. Fly ash stabilization reduced plasticity and improved the engineering properties of the stabilized dredged material (SDM). Increasing FA content increased maximum dry unit weight and reduced optimum water content for compaction. Unconfined compressive strength (qu) increased with FA content and curing time. The effect of curing time on qu was more significant at higher FA content. Freeze-thaw cycles only reduced the strength of SDM specimens by 5% on average, indicating that SDM was durable to freeze-thaw. Analytical relationships were developed to predict Atterberg limits and qu of SDM at different fly ash contents and curing times. The California bearing ratio (CBR) for the SDMranged from 10 to 20, which is comparable to compacted silty sand or sand and rates as fair to good for pavement subgrade. The resilient modulus (MR) increased significantly with FA content and varied between 35 and 83 MPa, which is comparable to gravel or crushed stone and rates as good to excellent for subgrade. Results indicate that low-strength dredged materials stabilized with Class C fly ash are viable for beneficial use as pavement subgrade material. © 2017 American Society of Civil Engineers.","Curing time; Dredged materials; Engineering properties; Fly ash; Pavement","C (programming language); Compressive strength; Curing; Dredges; Dredging; Freezing; Pavements; Soil testing; Strength of materials; Thawing; California bearing ratio; Construction applications; Curing time; Dredged materials; Engineering properties; Pavement construction; Stabilized dredged materials; Unconfined compressive strength; Fly ash; compressive strength; dredging; fly ash; freeze-thaw cycle; pavement; California; United States",2-s2.0-85026483129
"Kasprzyk M., Zalewska A., Niedzicki L., Bitner A., Marcinek M., Wieczorek W.","Non-crystallizing solvent mixtures and lithium electrolytes for low temperatures",2017,"Solid State Ionics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019876011&doi=10.1016%2fj.ssi.2017.05.014&partnerID=40&md5=42917bd323913678cd7af56fdb43b03d","A new class of solvent mixture and new liquid electrolytes are reported. New non-crystallizing materials may improve the performance of lithium-ion batteries at extremely low temperatures. Solvents were prepared by mixing EC (ethylene carbonate) with PEG250 (poly(ethylene glycol) dimethyl ether with an average molar mass of 250 g mol− 1). Some of these mixtures show only a glass transition, which takes place at temperatures below − 70 °C. It is possible to prepare such non-crystallizing electrolytes with both the novel imidazolide lithium salt LiTDI (lithium 4,5-dicyano-2-(trifluoromethyl)imidazolide) and the benchmark commercial salt LiPF6 (lithium hexafluorophosphate). Most state-of-the-art electrolytes crystallize at temperatures above − 40 °C. Thus, below this temperature a rapid decrease in conductivity is observed. New solutions show very good thermal and electrochemical properties (for instance: high conductivity, wide range of electrochemical stability window). This type of electrolyte may also reach high conductivity values of around 0.014 mS cm− 1 at − 60 °C. This new class of electrolyte may be the answer to the numerous present issues with applications below 0 °C, and also gives the possibility of battery storage at low temperature without cell damage. © 2017","Conductivity; Electrolyte; Lithium; Low temperature; Non-crystallizing","C (programming language); Electric batteries; Electric conductivity; Ethylene; Fuels; Glass transition; Lithium; Lithium alloys; Lithium compounds; Lithium-ion batteries; Mixtures; Organic solvents; Polyethylene glycols; Solvents; Temperature; Average molar mass; Electrochemical stabilities; Ethylene carbonate; High conductivity; Liquid electrolytes; Lithium hexafluorophosphate; Low temperatures; Non-crystallizing; Electrolytes",2-s2.0-85019876011
"Yan J.-B., Xie J.","Experimental studies on mechanical properties of steel reinforcements under cryogenic temperatures",2017,"Construction and Building Materials",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021270005&doi=10.1016%2fj.conbuildmat.2017.06.123&partnerID=40&md5=c862ef6e8e383e9f0b697e92a9daceff","The increasing demands of the liquid natural gas (LNG) container and engineering constructions in the cold regions require the reinforcing steels could work under the cryogenic temperatures. This paper reported the experimental studies on the mechanical properties of HRB335, HRB400, and SLTS type of reinforcing steels that were used in the reinforced concrete structures and LNG containers. A test program consisted of 63 steel coupons was performed under different cryogenic temperatures ranging from −165 °C to 20 °C. The test results revealed the influences of the cryogenic temperatures on the mechanical properties of the different reinforcing steels that included stress-strain behaviours, elastic Young's modulus, yield and ultimate strength, fracture strain, and percentage of reduction in the cross sectional area. Discussions were also made on the differences of the influences of the cryogenic temperatures on the mechanical properties among different types of reinforcing steels. Based on the test results, empirical design equations were developed through the regression analysis on the reported test results. The accuracies of these developed equations were checked through validations of the predictions against the test results. Conclusions and design recommendations were made based on these experimental and analytical studies. © 2017 Elsevier Ltd","Cold regions; Cryogenic temperature; LNG container; Materials design; Mechanical properties; Reinforcing steel","C (programming language); Containers; Cryogenics; Elastic moduli; Fracture; Mechanical properties; Regression analysis; Reinforced concrete; Reinforcement; Software testing; Cold regions; Cross sectional area; Cryogenic temperatures; Design recommendations; Engineering constructions; Materials design; Reinforcing steels; Stress strain behaviours; Strain",2-s2.0-85021270005
"Geng W., Han H., Liu F., Liu X., Xiao L., Wu W.","N,P,S-codoped C@nano-Mo2C as an efficient catalyst for high selective synthesis of methanol from CO2 hydrogenation",2017,"Journal of CO2 Utilization",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021873694&doi=10.1016%2fj.jcou.2017.06.016&partnerID=40&md5=2798ba8b479433c3bd397236c01988c6","With the protic ionic liquid consisting of N-butylimidazolium molybdophosphate and N-butylimidazolium p-toluenesulfonate as carbon source, molybdenum source and N,P,S-doping source, the catalysts of N,P,S-codoped C@nano-Mo2C (N,P,S-dC@Mo2C) were prepared by temperature-programmed carbonization method in a N2/H2 atmosphere. The results of X-ray diffraction (XRD) and X-ray photoelectron spectroscopy (XPS) demonstrated that N,P,S-dC@Mo2C was successfully synthesized and the morphology of N,P,S-dC@Mo2C was characterized by transmission electron microscopy (TEM). In the hydrogenation of CO2 to form methanol, N,P,S-dC@Mo2C showed highly catalytic activity and selectivity. When the N,P,S-dC@Mo2C-1073K was employed as a catalyst, the methanol selectivity of 91% was achieved with CO2 conversion of 19%. Moreover, the N,P,S-dC@Mo2C-1073K catalyst showed the excellent stability and its catalytic activity and selectivity was not decreased when the catalytic reaction was run continuously for 100 h in the fixed bed reactor. © 2017 Elsevier Ltd. All rights reserved.","Carbon dioxide; Methanol; N,P,S-codoped C@nano-Mo2C; Protic ionic liquid","C (programming language); Carbon dioxide; Carbonization; Catalysis; Catalyst selectivity; Catalysts; High resolution transmission electron microscopy; Hydrogenation; Ionic liquids; Methanol; Transmission electron microscopy; X ray diffraction; X ray photoelectron spectroscopy; Carbonization methods; Catalytic reactions; Co-doped; Methanol selectivity; P-toluenesulfonates; Protic ionic liquids; Selective synthesis; Temperature programmed; Catalyst activity",2-s2.0-85021873694
"Sarvghad M., Steinberg T.A., Will G.","Corrosion of steel alloys in eutectic NaCl+Na2CO3 at 700 °C and Li2CO3 + K2CO3 + Na2CO3 at 450 °C for thermal energy storage",2017,"Solar Energy Materials and Solar Cells",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020253634&doi=10.1016%2fj.solmat.2017.05.063&partnerID=40&md5=754a0db74ae707f9f6fb137db0819fe4","Stainless steel 316, duplex steel 2205 and carbon steel 1008 were examined for compatibility with the eutectic mixtures of NaCl+Na2CO3 at 700 °C and Li2CO3 + K2CO3 + Na2CO3 at 450 °C in air for thermal energy storage. Electrochemical measurements combined with advanced microscopy and microanalysis techniques were employed. Oxidation was found as the primary attack in both molten salt environments. However, the availability of O2 controlled the degree of oxidation. Alloy 316 showed the lowest corrosion current densities in each molten salt owing to the formation of films on the surface. The attack morphology on the surface of all materials was uniform corrosion with no localized degradation at 450 °C. Microscopy observations showed grain boundary oxidative attack as the primary corrosion mechanism for all studied alloys at 700 °C with depletion of alloying elements from grain boundaries in alloys 316 and 2205. The protective nature of austenite phase reduced selective oxidation of the underlying ferrite layers of alloy 2205 in chloride carbonate at 700 °C. © 2017 Elsevier B.V.","Corrosion; Impedance spectroscopy; Microscopy; Molten Salt; Polarization; Steel","Alloy steel; Alloying elements; Alloys; Carbon; Carbon steel; Corrosion; Energy storage; Eutectics; Fused salts; Grain boundaries; Heat storage; Microscopic examination; Oxidation; Polarization; Stainless steel; Steel; Thermal energy; Corrosion current densities; Corrosion mechanisms; Degree of oxidations; Electrochemical measurements; Impedance spectroscopy; Microscopy and microanalysis techniques; Molten salt; Stainless steel 316; C (programming language)",2-s2.0-85020253634
"Bagchi A., Paul J.A.","Espionage and the optimal standard of the Customs-Trade Partnership against Terrorism (C-TPAT) program in maritime security",2017,"European Journal of Operational Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016410262&doi=10.1016%2fj.ejor.2017.03.014&partnerID=40&md5=cb961bacb29d78834b47ab433add042a","We examine the design of a trusted trader program in the U.S. known as C-TPAT (Customs-Trade Partnership against Terrorism). For this, we consider a game between the government, an importer and a terrorist group. The government provides maritime security using three policies: (i) Standard of the C-TPAT program, that is, the degree of security of the supply chain that is required of a member, (ii) Quality of intelligence about the terrorist group, and (iii) Inspection of Cargo. In equilibrium, the government sets the standard of the program at a level that minimizes congestion. However, the optimal espionage expenditure is less than the level that minimizes congestion. We also endogenously determine the membership size of the program and show that it depends non-monotonically on policies such as the standard of the program or the quality of intelligence. Finally, we examine the impact of parametric changes on these policies. © 2017 Elsevier B.V.","Homeland security; OR in defense; Planning: government; Public policy; Terrorism","Commerce; Mergers and acquisitions; National security; Public policy; Supply chains; Terrorism; Customs-trade partnership against terrorisms; Maritime security; OR in defense; Parametric changes; Terrorist groups; C (programming language)",2-s2.0-85016410262
"Razgon I.","On Oblivious Branching Programs with Bounded Repetition that Cannot Efficiently Compute CNFs of Bounded Treewidth",2017,"Theory of Computing Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991703731&doi=10.1007%2fs00224-016-9714-0&partnerID=40&md5=c720cfb72fea0d9294ea87eadd5268ed","In this paper we study complexity of an extension of ordered binary decision diagrams (OBDDs) called c-OBDDs on CNFs of bounded (primal graph) treewidth. In particular, we show that for each k ≥ 3 there is a class of CNFs of treewidth k for which the equivalent c-OBDDs are of size Ω(nk/(8c−4)). Moreover, this lower bound holds if c-OBDDs are non-deterministic and semantic. Our second result uses the above lower bound to separate the above model from sentential decision diagrams (SDDs). In order to obtain the lower bound, we use a structural graph parameter called matching width. Our third result shows that matching width and pathwidth are linearly related. © 2016, Springer Science+Business Media New York.",,"Binary decision diagrams; Binary trees; Equivalence classes; Semantics; Bounded treewidth; Branching programs; Decision diagram; Lower bounds; Ordered binary decision diagrams; Pathwidth; Structural graph; Tree-width; C (programming language)",2-s2.0-84991703731
"Dhimish M., Holmes V., Mehrdadi B., Dales M.","Diagnostic method for photovoltaic systems based on six layer detection algorithm",2017,"Electric Power Systems Research",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019881842&doi=10.1016%2fj.epsr.2017.05.024&partnerID=40&md5=64ce75c69b67d600d1b7f465fe103278","This work proposes a fault detection algorithm based on the analysis of the theoretical curves which describe the behaviour of an existing grid-connected photovoltaic (GCPV) plant. For a given set of working conditions, solar irradiance and PV modules’ temperature, a number of attributes such as voltage ratio (VR) and power ratio (PR) are simulated using virtual instrumentation (VI) LabVIEW software. Furthermore, a third order polynomial function is used to generate two detection limits (high and low limit) for the VR and PR ratios obtained using LabVIEW simulation tool. The high and low detection limits are compared with real-time long-term data measurements from a 1.1 kWp and 0.52 kWp GCPV systems installed at the University of Huddersfield, United Kingdom. Furthermore, samples that lies out of the detecting limits are processed by a fuzzy logic classification system which consists of two inputs (VR and PR) and one output membership function. The obtained results show that the fault detection algorithm can accurately detect different faults occurring in the PV system. The maximum detection accuracy of the algorithm before considering the fuzzy logic system is equal to 95.27%, however, the fault detection accuracy is increased up to a minimum value of 98.8% after considering the fuzzy logic system. © 2017 Elsevier B.V.","Fault detection; Fuzzy logic; LabVIEW; Photovoltaic faults; Photovoltaic system","Computer circuits; Computer programming languages; Fuzzy logic; Membership functions; Photovoltaic cells; Photovoltaic effects; Real time systems; Signal detection; Detection algorithm; Fault detection algorithm; Grid connected photovoltaic (GCPV); LabViEW; Low detection limit; Photovoltaic; Photovoltaic systems; Virtual Instrumentation; Fault detection",2-s2.0-85019881842
"Du S., Zhao H., Ge Y., Yang Z., Shi X.","Laboratory investigation into the modification of transport properties of high-volume fly ash mortar by chemical admixtures",2017,"Journal of Materials in Civil Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024388268&doi=10.1061%2f%28ASCE%29MT.1943-5533.0002025&partnerID=40&md5=6aa1fc33615fe19dc4762ea4ffcd751f","This work aims to optimize the transport properties of high-volume fly ash (HVFA) mortars that replace Portland cement with a Class C fly ash at 60% by weight. Ten chemical admixtures (five nonpolymers and five polymers) previously reported to improve the early-age strength or water resistance of concrete were investigated for their effects on the HVFA mortars. A total of 26 mortar mixtures were designed and tested, based on a statistical design to explore the potential synergistic effects among the polymeric admixtures and the nonpolymeric admixtures, respectively. At the age of 28 days, the compressive strength, splitting tensile strength, and water sorptivity of all mortar mixtures and the gas permeability of six selected mixtures from each group were tested. In addition, the surface free energy and pore size distribution of the selected mortars were obtained in the effort to correlate with water sorptivity and gas permeability, respectively. The predictive models built on the results of designed experiments suggest that if used individually, tributyl phosphate, hydroxypropyl methyl cellulose, and hydroxyl terminated polysiloxane are the three admixtures that can effectively reduce the water sorptivity of HVFA mortars. For the six selected HVFA mortars, those containing polymeric admixtures exhibited a significantly lower gas permeability coefficient than those containing nonpolymeric admixtures. The water sorptivity of HVFA mortars was mainly affected by the microstructure of mixtures rather than their surface free energy. The nonpolymeric admixtures worked better in refining the pore structure in the HVFA mortars and reducing the critical radius than the polymeric admixtures. © 2017 American Society of Civil Engineers.","Critical radius; High-volume fly ash; Pore size distribution; Surface free energy; Transport properties","C (programming language); Chemical modification; Compressive strength; Concrete additives; Electron transport properties; Fly ash; Free energy; Gas permeability; Mixtures; Polymers; Pore size; Portland cement; Silicones; Size distribution; Tensile strength; Transport properties; Critical radius; Designed experiments; High volume fly ash; Hydroxypropyl methyl cellulose; Laboratory investigations; Splitting tensile strength; Surface free energy; Tri-butyl phosphate; Mortar; cement; concrete; fly ash; mortar; polymer; porosity; size distribution; surface energy",2-s2.0-85024388268
"Savoldi L., Bonifetto R., Brighenti A., Corato V., Muzzi L., Turtu S., Zanino R., Zappatore A.","Quench propagation in a TF coil of the EU DEMO",2017,"Fusion Science and Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029958436&doi=10.1080%2f15361055.2017.1333866&partnerID=40&md5=036fb1fef0dc23bcc0cf6a46f2c3fded","The design of a suitable quench protection system is fundamental for the safe operation of superconducting magnets and in turn requires the accurate simulation of the quench transient. The quench propagation in a toroidal field (TF) coil for the future European fusion reactor (EU DEMO) is analyzed here considering the latest, layer-wound winding pack (WP) design proposed by ENEA. The thermal-hydraulic model of a TF coil implemented in the 4C code is updated by including the external cryogenic circuits of the WP and of the casing cooling channels and proposing a preliminary layout of the quench lines. Three different locations are considered for the quench initiation: maximum temperature margin in the WP, and minimum and maximum temperature margin on the same turn of the innermost layer. The evolution of the main electrical and thermal-hydraulic parameters is simulated, such as voltage along each layer, quench front propagation both along and across the layers, hot spot temperature, pressurization of the coil and coolant mass flow rate at the coil boundaries, so that the 4C code provides a reliable (in view of its validation) and detailed virtual monitor of what happens inside the coil during the quench transient. In all cases considered, the ENEA design is predicted to satisfy the present (i.e., ITER) design criteria concerning the maximum allowed hot spot temperature. © American Nuclear Society.","DEMO; Quench; Superconducting magnets","C (programming language); Hydraulic models; Magnets; Nuclear reactors; Quenching; Superconducting magnets; DEMO; Front propagation; Hotspot temperature; Maximum temperature; Quench propagation; Thermal hydraulic modeling; Thermal hydraulic parameters; Toroidal Field coils; Superconducting coils",2-s2.0-85029958436
"Mohammadi E., Dehkhoda P., Tavakoli A., Honarbakhsh B.","Shielding effectiveness analysis of large enclosures by domain decomposition mesh-free method",2017,"IEEE Transactions on Electromagnetic Compatibility",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017479561&doi=10.1109%2fTEMC.2017.2679196&partnerID=40&md5=19403726417041b759b8b5722153dad9","In this paper, an efficient domain decomposition mesh-free method (DD-MFM) is introduced to analyze the shielding effectiveness of a perforated metallic structure. First, a DD scheme is developed for a two-dimensional Fredholm integral equation of the second kind. Then, it is applied to a MFM-based method in a shielding enclosure problem. To this end, N number of nodes are considered on each aperture surface representing an individual domain. The MFM formulation through the DD scheme leads to M coupled equations, where M is the number of apertures (domains). In each equation, coefficient matrices have only 2N × 2N dimension, while the conventional MFM (C-MFM) would produce 2MN × 2 MN coefficient matrices. Thus, DD-MFM technique will overcome the ill-conditioning problem of matrices and results in much more efficiency, especially for problems with large matrix condition number, albeit at the cost of generating M coupled equations. Coupled equations are treated in an iterative process. To show the efficiency and accuracy of the proposed method, several enclosures with different size and multiple apertures are studied. The results are validated with the C-MFM and two well-known commercial software, FEKO and Computer Simulation Technology. The important output of the proposed DD-MFM method is that it makes the analysis of large enclosure with numerous apertures efficiently possible. © 1964-2012 IEEE.","Domain-decomposition; mesh-free method (MFM); perforated metallic enclosure; shielding effectiveness (SE)","C (programming language); Computational mechanics; Computer software; Domain decomposition methods; Efficiency; Enclosures; Integral equations; Iterative methods; Magnetic shielding; Mesh generation; Number theory; Shielding; Commercial software; Computer simulation technology; Fredholm integral equations; Matrix condition numbers; Metallic structures; Multiple apertures; Shielding effectiveness; Shielding enclosure; Matrix algebra",2-s2.0-85017479561
"Zhou Y., Li J., Wang S., Zhang J., Kang Z.","From MOF membrane to 3D electrode: a new approach toward an electrochemical non-enzymatic glucose biosensor",2017,"Journal of Materials Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023177964&doi=10.1007%2fs10853-017-1349-2&partnerID=40&md5=5a35cc60caa571edf528de9b88b23e77","A three-dimensional (3D) nickel oxide (NiO) catalytic electrode was fabricated by annealing Ni2(L-asp)2bipy MOF membrane and was subsequently applied for electrochemical glucose sensor. This 3D self-supported MOF membrane precursor provided uniform and porous architecture, and it was used for fabricating 3D NiO electrode in the first time. The SEM and XRD data showed that the NiO was evenly distributed on Ni mesh and complete transformation from Ni2(L-asp)2bipy to NiO. This catalytic electrode, using a chronoamperometric approach, demonstrated linear range up to 400 μM with high sensitivity of 478.9 μA mM−1 cm−2 and low limit of detection of 4.34 μM. Uric acid, urea and ascorbic acid showed negligible interferences to the detection of glucose. The excellent performance of this electrode was attributed to the uniformly distributed NiO on the Ni substrate, direct electron transformation from Ni substrate to electrochemical active NiO and the porosity of such electrode design. © 2017, Springer Science+Business Media, LLC.",,"Ascorbic acid; Electrodes; Glucose; Glucose sensors; Java programming language; Metadata; Nickel; Nickel oxide; Organic acids; Urea; Catalytic electrodes; Electrochemical glucose sensors; Electrode design; Glucose biosensor; Limit of detection; Nickel oxides (NiO); Porous architectures; Threedimensional (3-d); Electrochemical electrodes",2-s2.0-85023177964
"Díaz-Ramirez J., Giraldo-Peralta N., Flórez-Ceron D., Rangel V., Mejía-Argueta C., Huertas J.I., Bernal M.","Eco-driving key factors that influence fuel consumption in heavy-truck fleets: A Colombian case",2017,"Transportation Research Part D: Transport and Environment",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028510541&doi=10.1016%2fj.trd.2017.08.012&partnerID=40&md5=01be4d758ff776afec9de2220519e3b9","This research identifies key variables that influence fuel consumption that might be improved through eco-driving training programs under three circumstances that have been scarcely studied before: (a) heavy- and medium-duty truck fleets, (b) long-distance freight transport, and (c) the Latin American region. Based on statistical analyses that include multivariate regression of operational variables on fuel consumption, the impacts of an eco-driving training campaign were measured by comparing ex ante and ex post data. Operational variables are grouped into driving errors, trip conditions, driver behavior, driver profile, and vehicle attributes. The methodology is applied in a freight fleet with nationwide transport operations located in Colombia, where the steepness of its roads plays an important role in fuel consumption. The fleet, composed of 18 trucks, is equipped with state-of-the-art real-time data logger systems. During four months, 517 trips traveling a total distance of 292,512 km and carrying a total of 10,034 tons were analyzed. The results show a baseline average fuel consumption (FC) of 1.716 liters per 100 km. A different logistics performance indicator, which measures FC in liters per ton transported each 100 km, shows an average of 3.115. After the eco-driving campaign, reductions of 6.8% and 5.5% were obtained. Drivers’ experience, driving errors, average speed, and weight-capacity ratio, among others, were found to be highly relevant to FC. In particular, driving errors such as acceleration, braking and speed excesses are the most sensitive to eco-driving training, showing reductions of up to 96% on the average number of events per trip. © 2017","Driver behavior; Driving errors; Eco-driving training; Freight transportation; Fuel consumption; Statistical analyses","C (programming language); Errors; Fleet operations; Fuel consumption; Fuels; Real time systems; Regression analysis; Statistical methods; Transportation; Truck transportation; Trucks; Driver behavior; Driving errors; Eco-driving; Freight transport; Multivariate regression; Operational variables; Performance indicators; Transport operations; Freight transportation; freight transport; fuel consumption; statistical analysis; training; trucking; Colombia",2-s2.0-85028510541
"Martínez J., Padilla A., Rodríguez E., Jiménez A., Orozco H.","Design of teaching tools focused on control systems with virtual instruments [Diseño de Herramientas Didácticas Enfocadas al Aprendizaje de Sistemas de Control Utilizando Instrumentación Virtual]",2017,"RIAI - Revista Iberoamericana de Automatica e Informatica Industrial",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031737748&doi=10.1016%2fj.riai.2017.03.003&partnerID=40&md5=53070750bbde1dfcab5593142db2e2d1","This paper describes the design of three didactic tools focused on learning of control systems implemented in LabVIEW virtual instruments software. These tools are dedicated to stability analysis in control systems, compensator design using root locus approach and Bode diagrams in the frequency domain. Each of them has a friendly interface with the user. The advantage of these didactic tools is the several options to simulate some characteristics referent to control in contrast with others teaching tools. © 2016 CEA.","Educación en Control; Laboratorio Virtual; Palabras clave Estabilidad; Simulación de Sistemas","Bode diagrams; Computer programming languages; Control system analysis; Control systems; Digital instruments; Frequency domain analysis; Root loci; Compensator design; Frequency domains; Laboratorio Virtual; LabVIEW virtual instrument; Palabras clave Estabilidad; Stability analysis; Teaching tools; Virtual instrument; E-learning",2-s2.0-85031737748
"Foucaud F., Harutyunyan A., Hell P., Legay S., Manoussakis Y., Naserasr R.","The complexity of tropical graph homomorphisms",2017,"Discrete Applied Mathematics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023753420&doi=10.1016%2fj.dam.2017.04.027&partnerID=40&md5=d452288866e38f5a8d778382152a6d20","A tropical graph (H,c) consists of a graph H and a (not necessarily proper) vertex-colouring c of H. Given two tropical graphs (G,c1) and (H,c), a homomorphism of (G,c1) to (H,c) is a standard graph homomorphism of G to H that also preserves the vertex-colours. We initiate the study of the computational complexity of tropical graph homomorphism problems. We consider two settings. First, when the tropical graph (H,c) is fixed; this is a problem called (H,c)-COLOURING. Second, when the colouring of H is part of the input; the associated decision problem is called H-TROPICAL-COLOURING. Each (H,c)-COLOURING problem is a constraint satisfaction problem (CSP), and we show that a complexity dichotomy for the class of (H,c)-COLOURING problems holds if and only if the Feder–Vardi Dichotomy Conjecture for CSPs is true. This implies that (H,c)-COLOURING problems form a rich class of decision problems. On the other hand, we were successful in classifying the complexity of at least certain classes of H-TROPICAL-COLOURING problems. © 2017 Elsevier B.V.","Dichotomy; Graph homomorphisms; Tropical graphs","Algebra; C (programming language); Tropics; Complexity dichotomies; Decision problems; Dichotomy; Graph homomorphisms; Tropical graphs; Vertex-colouring; Constraint satisfaction problems",2-s2.0-85023753420
"Dhimish M., Holmes V., Dales M., Mehrdadi B.","Effect of micro cracks on photovoltaic output power: Case study based on real time long term data measurements",2017,"Micro and Nano Letters",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030686531&doi=10.1049%2fmnl.2017.0205&partnerID=40&md5=5a0e6c264d600dbfc2154d638ab2bbff","This study analyses the impact of micro cracks on photovoltaic (PV) module output power performance and energy production. Electroluminescence imaging technique was used to detect micro cracks affecting PV modules. The experiment was carried out on ten different PV modules installed at the University of Huddersfield, United Kingdom. The examined PV modules which contain micro cracks shows large loss in the output power comparing with the theoretical output power predictions, where the maximum power loss is equal to 80.73%. LabVIEW software was used to simulate the theoretical output power of the examined PV modules under real time long term data measurements. © The Institution of Engineering and Technology 2017.",,"Computer programming languages; Cracks; Imaging techniques; Photovoltaic cells; Photovoltaic effects; Data measurements; Electroluminescence imaging; Energy productions; Lab-view softwares; Maximum power; Photovoltaic; Photovoltaic modules; United kingdom; Crack detection; energy yield; luminescence; prediction; software; theoretical study; United Kingdom",2-s2.0-85030686531
"Sulír M., Porubän J.","Generating method documentation using concrete values from executions",2017,"OpenAccess Series in Informatics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032632180&doi=10.4230%2fOASIcs.SLATE.2017.3&partnerID=40&md5=c24c10022222aaead2a746d811471bdd","There exist multiple automated approaches of source code documentation generation. They often describe methods in abstract terms, using the words contained in the static source code or code excerpts from repositories. In this paper, we introduce DynamiDoc – a simple yet e ective automated documentation approach based on dynamic analysis. It traces the program being executed and records string representations of concrete argument values, a return value, and a target object state before and after each method execution. Then for every concerned method, it generates documentation sentences containing examples, such as “When called on [3, 1.2] with element = 3, the object changed to [1.2]”. A qualitative evaluation is performed, listing advantages and shortcomings of the approach. © Matúš Sulír and Jaroslav Porubän","Documentation generation; Dynamic analysis; Examples; Methods; Source code summarization","Computer programming languages; Concretes; Dynamic analysis; Slate; Automated approach; Examples; Generating methods; Methods; Qualitative evaluations; Source codes; Static sources; Target object; Codes (symbols)",2-s2.0-85032632180
"Lee C.-S., Wang M.-H., Yang S.-C., Hung P.-H., Lin S.-W., Shuo N., Kubota N., Chou C.-H., Chou P.-C., Kao C.-H.","FML-based Dynamic Assessment Agent for Human-Machine Cooperative System on Game of Go",2017,"International Journal of Uncertainty, Fuzziness and Knowlege-Based Systems",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028932070&doi=10.1142%2fS0218488517500295&partnerID=40&md5=c2903237f5eacf29e607f9df266dc19e","In this paper, we demonstrate the application of Fuzzy Markup Language (FML) to construct an FML-based Dynamic Assessment Agent (FDAA), and we present an FML-based Human-Machine Cooperative System (FHMCS) for the game of Go. The proposed FDAA comprises an intelligent decision-making and learning mechanism, an intelligent game bot, a proximal development agent, and an intelligent agent. The intelligent game bot is based on the open-source code of Facebook's Darkforest, and it features a representational state transfer application programming interface mechanism. The proximal development agent contains a dynamic assessment mechanism, a GoSocket mechanism, and an FML engine with a fuzzy knowledge base and rule base. The intelligent agent contains a GoSocket engine and a summarization agent that is based on the estimated win rate, real-time simulation number, and matching degree of predicted moves. Additionally, the FML for player performance evaluation and linguistic descriptions for game results commentary are presented. We experimentally verify and validate the performance of the FDAA and variants of the FHMCS by testing five games in 2016 and 60 games of Google's Master Go, a new version of the AlphaGo program, in January 2017. The experimental results demonstrate that the proposed FDAA can work effectively for Go applications. © 2017 World Scientific Publishing Company.","decision support engine; FAIR darkforest Go engine; Fuzzy markup language; prediction agent; robot engine","Application programming interfaces (API); Decision making; Decision support systems; Engines; Intelligent agents; Interface states; Knowledge based systems; Markup languages; Open source software; Open systems; Software testing; Decision supports; Fuzzy markup languages; Fuzzy markup languages (FML); Human-machine cooperative system; Intelligent decision making; Linguistic descriptions; Prediction agent; Representational state transfer; Dynamics",2-s2.0-85028932070
"Cortés H., Navarro A.","Enterprise WAE: A Lightweight UML Extension for the Characterization of the Presentation Tier of Enterprise Applications with MDD-Based Mockup Generation",2017,"International Journal of Software Engineering and Knowledge Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032036441&doi=10.1142%2fS0218194017500486&partnerID=40&md5=253c36f05003b9860bbc0b2f5dc41732","Nowadays, the Unified Modeling Language (UML) is the most successful notation for the design of object-oriented applications. However, plain UML is not enough to characterize the web presentation tier of enterprise applications, including the navigational, structural and role-based access control (RBAC) features present in these applications. In this paper, we present Enterprise Web Application Extension (E-WAE), a lightweight UML extension for the modeling of these elements, which permits the inclusion of multitier, Service-Oriented Architecture (SOA) and security design-level patterns in the models. Our approach follows a Model-Driven Development (MDD) approach, which enables the automatic generation of intermediate platform-specific models and automatic code generation for JavaServer Faces (JSF) and Active Server Pages.NET Model-View-Controller (ASP.NET MVC) frameworks. In addition, this generated code can be used as a low-cost mockup for early client validation of the navigational, structural and RBAC features of enterprise applications. E-WAE has been used with different applications. In this paper, we refer to the checkout process in the Amazon website, the delete resources use case in OdAJ2EE, an educational application developed by us, and the US Library of Congress Online Catalog search facility as examples of its applicability. © 2017 World Scientific Publishing Company.","enterprise applications; MDA; MDD; mockup; multitier architecture; UML","Access control; Automatic programming; Information services; Mockups; Modeling languages; Service oriented architecture (SOA); Software architecture; Systems analysis; Automatic code generations; Educational Applications; Enterprise applications; Model-driven development; Multi tier architecture; Object oriented application; Platform specific model; Role-based Access Control; Unified Modeling Language",2-s2.0-85032036441
"Ganty P., Iosif R., Konečný F.","Underapproximation of procedure summaries for integer programs",2017,"International Journal on Software Tools for Technology Transfer",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964344183&doi=10.1007%2fs10009-016-0420-7&partnerID=40&md5=6245ad107930c982baaaec211208ac70","We show how to underapproximate the procedure summaries of recursive programs over the integers using off-the-shelf analyzers for non-recursive programs. The novelty of our approach is that the non-recursive program we compute may capture unboundedly many behaviors of the original recursive program for which stack usage cannot be bounded. Moreover, we identify a class of recursive programs on which our method terminates and returns the precise summary relations without underapproximation. Doing so, we generalize a similar result for non-recursive programs to the recursive case. Finally, we present experimental results of an implementation of our method applied on a number of examples. © 2016, Springer-Verlag Berlin Heidelberg.","Bounded context-free languages; Flat counter systems; Procedure summaries; Program analysis","Context free languages; Counter systems; Integer program; Procedure summaries; Program analysis; Recursive programs; Under-approximation; Integer programming",2-s2.0-84964344183
"Zhang Q., Zhang Y., Yao L., Fan F., Shen S.","Finite element analysis of the static properties and stability of a 800 m Kiewitt type mega-latticed structure",2017,"Journal of Constructional Steel Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021422429&doi=10.1016%2fj.jcsr.2017.06.024&partnerID=40&md5=35d172d68b79c7aaa44b59d525ebdd16","A comparison was made of the static behavior of a double-layer reticulated shell, a local triple-layered reticulated shell, a ribbed type mega-latticed structure and a Kiewitt type mega-latticed structure with the same geometrical parameters and loads. The results show that the Kiewitt type mega-latticed structure has the best structural performance. Then a complex structural configuration was analyzed in detail, using CAD 3D modeling, and a command-flow was developed to create the new structure automatically by ANSYS Parameter Design Language as an innovative structural-programming method. The static analysis and comprehensive stability analysis were conducted. The reasonable values of parameters for the overall buckling mode were summarized and the ultimate bearing capacity was accurately obtained by considering geometrical nonlinear, material nonlinear and initial curvature of the members. The nonlinear equilibrium paths were traced using the Arc-length method. Results indicate that the 800 m Kiewitt type mega-latticed structure has a very low sensitivity to geometrical nonlinear and a low sensitivity to initial curvature of members, but a high sensitivity to material nonlinear. Therefore, the Kiewitt type mega-latticed structure could be regarded as a reasonable super-large span structure with several advantages, including reasonable stresses, clear force transmission lines, economic steel consumption, high stiffness and good bearing capacity. © 2017 Elsevier Ltd","Automatic configuration; Kiewitt type mega-latticed structure; Stability analysis; Structure system; Super-large span","Bearing capacity; Computer aided design; Finite element method; Geometry; Modeling languages; Static analysis; Structural analysis; Struts; Automatic configuration; Large span; Stability analysis; Structural configurations; Structural performance; Structural programming; Structure systems; Ultimate bearing capacity; Nonlinear analysis",2-s2.0-85021422429
"Whitington J., Ridge T.","Visualizing the evaluation of functional programs for debugging",2017,"OpenAccess Series in Informatics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032645352&doi=10.4230%2fOASIcs.SLATE.2017.7&partnerID=40&md5=f9c8433f815829e8b53397358c472fe4","In this position paper, we present a prototype of a visualizer for functional programs. Such programs, whose evaluation model is the reduction of an expression to a value through repeated application of rewriting rules, and which tend to make little or no use of mutable state, are amenable to visualization in the same fashion as simple mathematical expressions, with which every schoolchild is familiar. We show how such visualizations may be produced for the strict functional language OCaml, by direct interpretation of the abstract syntax tree and appropriate pretty-printing. We describe (and begin to address) the challenges of presenting such program traces in limited space and of identifying their essential elements, so that our methods will one day be practical for more than toy programs. We consider the problems posed by the parts of modern functional programming which are not purely functional such as mutable state, input/output and exceptions. We describe initial work on the use of such visualizations to address the problem of program debugging, which is our ultimate aim. © John Whitington and Tom Ridge","Debugging; Functional; OCaml; Visualization","Application programs; Computer debugging; Flow visualization; Functional programming; Slate; Trees (mathematics); Visualization; Abstract Syntax Trees; Evaluation modeling; Functional; Functional languages; Functional programs; Mathematical expressions; OCaml; Repeated application; Program debugging",2-s2.0-85032645352
"Cao D., Kang L., Zhan H., Mei H.","Towards application-level elasticity on shared cluster: an actor-based approach",2017,"Frontiers of Computer Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992381827&doi=10.1007%2fs11704-016-5386-9&partnerID=40&md5=57a529014cc8d3b342f3462725d6d6ad","In current cluster computing, several distributed frameworks are designed to support elasticity for business services adapting to environment fluctuation. However, most existing works support elasticity mainly at the resource level, leaving application level elasticity support problem to domain-specific frameworks and applications. This paper proposes an actor-based general approach to support application-level elasticity for multiple cluster computing frameworks. The actor model offers scalability and decouples language-level concurrency from the runtime environment. By extending actors, a new middle layer called Unisupervisor is designed to “sit” between the resource management layer and application framework layer. Actors in Unisupervisor can automatically distribute and execute tasks over clusters and dynamically scale in/out. Based on Unisupervisor, high-level profiles (MasterSlave, MapReduce, Streaming, Graph, and Pipeline) for diverse cluster computing requirements can be supported. The entire approach is implemented in a prototype system called UniAS. In the evaluation, both benchmarks and real applications are tested and analyzed in a small scale cluster. Results show that UniAS is expressive and efficiently elastic. © 2016, Higher Education Press and Springer-Verlag Berlin Heidelberg.","actor programming model; cluster computing; concurrent and parallel processing; elastic scaling; elasticity","Benchmarking; Computer architecture; Distributed computer systems; Elasticity; Application frameworks; Distributed framework; Domain-specific frameworks; elastic scaling; Environment fluctuation; Parallel processing; Programming models; Small-scale clusters; Cluster computing",2-s2.0-84992381827
"Unat D., Dubey A., Hoefler T., Shalf J.B., Abraham M., Bianco M., Chamberlain B.L., Cledat R., Edwards H.C., Finkel H., Fuerlinger K., Hannig F., Jeannot E., Kamil A., Keasler J., Kelly P.H.J., Leung V., Ltaief H., Maruyama N., Newburn C.J., Pericas M.","Trends in Data Locality Abstractions for HPC Systems",2017,"IEEE Transactions on Parallel and Distributed Systems",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030168276&doi=10.1109%2fTPDS.2017.2703149&partnerID=40&md5=ee1f373069d24315de470f3e0add02d4","The cost of data movement has always been an important concern in high performance computing (HPC) systems. It has now become the dominant factor in terms of both energy consumption and performance. Support for expression of data locality has been explored in the past, but those efforts have had only modest success in being adopted in HPC applications for various reasons. them However, with the increasing complexity of the memory hierarchy and higher parallelism in emerging HPC systems, locality management has acquired a new urgency. Developers can no longer limit themselves to low-level solutions and ignore the potential for productivity and performance portability obtained by using locality abstractions. Fortunately, the trend emerging in recent literature on the topic alleviates many of the concerns that got in the way of their adoption by application developers. Data locality abstractions are available in the forms of libraries, data structures, languages and runtime systems; a common theme is increasing productivity without sacrificing performance. This paper examines these trends and identifies commonalities that can combine various locality concepts to develop a comprehensive approach to expressing and managing data locality on future large-scale high-performance computing systems. © 1990-2012 IEEE.","data layout; Data locality; high-performance computing; locality-aware runtimes; programming abstractions","Computer programming; Energy utilization; Productivity; Data layouts; Data locality; High performance computing; Programming abstractions; Runtimes; Abstracting",2-s2.0-85030168276
"Hsiao S.-W., Lee C.-H., Yang M.-H., Chen R.-Q.","User interface based on natural interaction design for seniors",2017,"Computers in Human Behavior",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019268376&doi=10.1016%2fj.chb.2017.05.011&partnerID=40&md5=00f7933dc18dadedc5419e732abf6820","With world population ageing, how to help seniors to adapt to technology life is an important issue. Technology is becoming life rather than resistance, because many of the technology applications are often accompanied by a lot of information to process. This makes the user interface to become an important bridge between human computer interactions. Especially the inconvenience caused by human ageing, these related issues from the cognitive and operational of products are derived. This study proposes a study of user interface design based on natural interaction to increase seniors’ usage intention. In the proposed contents, the Kinect sensor is used to retrieve seniors’ in-depth information in movements, thus the user interface of system can be operated by the gesture intuitively. In the framework of the system, in the first all, the morphology is applied to identify the features of a hand from depth values obtained from the sensor. Gesture is used to recognize operating behavior of users to implement the interactive action, and collision detection is applied to confirm effectiveness of operation. On the other hand, through interpretive structural model (ISM), each design element of interactive interface can be decomposed and realized, and the solution for target and direction of design problem is also proposed. At the meanwhile, the concept of affordance is conducted to the development of interface for graphic users that proposed in this study, and the design achievement contains operation and usability of intuition can further be acquired. Finally, based on the proposed methodology, an intuitive user interface of digital devices is constructed by Java programming language that allows for verifying the feasibility of user interface for seniors. Besides, the proposed method can be widely used to develop the user interface for various products. © 2017 Elsevier Ltd","Affordance; Gesture recognition; Interpretive structural model; Natural interaction; Natural user interface","Computer programming; Digital devices; Gesture recognition; Human computer interaction; Affordances; Interactive interfaces; Interpretive structural modeling; Intuitive user interface; Natural interactions; Natural user interfaces; Technology application; User interface designs; User interfaces",2-s2.0-85019268376
"Queirós R.","A survey on CSS preprocessors",2017,"OpenAccess Series in Informatics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032623233&doi=10.4230%2fOASIcs.SLATE.2017.8&partnerID=40&md5=9f957fc5cca74949537f1d3e711de981","In the Web realm, the adoption of Cascading Style Sheets (CSS) is unanimous, being widely used for styling web documents. Despite their intensive use, this W3C specification was written for web designers with limit programming background. Thus, it lack several programming constructs, such as variables, conditional and repetitive blocks, and functions. This absence a ects negatively code reuse, and consequently, the maintenance of the styling code. In the last decade, several languages (e.g. Sass, Less) appeared to extend CSS, defined as CSS preprocessors, with the ultimate goal to bring those missing constructs and to foster stylesheets structured programming. The paper provides an introductory survey on CSS Preprocessors. It gathers information on a specific set of preprocessors, categorizes them and compares their features regarding a set of predefined criteria such as: maturity, coverage and performance. © Ricardo Queirós",,"Slate; Surveys; Cascading style sheets; Code reuse; Web designers; Web document; Structured programming",2-s2.0-85032623233
"Zhang H., Stangner T., Wiklund K., Rodriguez A., Andersson M.","UmUTracker: A versatile MATLAB program for automated particle tracking of 2D light microscopy or 3D digital holography data",2017,"Computer Physics Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021276217&doi=10.1016%2fj.cpc.2017.05.029&partnerID=40&md5=48caa0dae6f98a9aa543147e94468342","We present a versatile and fast MATLAB program (UmUTracker) that automatically detects and tracks particles by analyzing video sequences acquired by either light microscopy or digital in-line holographic microscopy. Our program detects the 2D lateral positions of particles with an algorithm based on the isosceles triangle transform, and reconstructs their 3D axial positions by a fast implementation of the Rayleigh–Sommerfeld model using a radial intensity profile. To validate the accuracy and performance of our program, we first track the 2D position of polystyrene particles using bright field and digital holographic microscopy. Second, we determine the 3D particle position by analyzing synthetic and experimentally acquired holograms. Finally, to highlight the full program features, we profile the microfluidic flow in a 100μm high flow chamber. This result agrees with computational fluid dynamic simulations. On a regular desktop computer UmUTracker can detect, analyze, and track multiple particles at 5 frames per second for a template size of 201 ×201 in a 1024 × 1024 image. To enhance usability and to make it easy to implement new functions we used object-oriented programming. UmUTracker is suitable for studies related to: particle dynamics, cell localization, colloids and microfluidic flow measurement. Program summary Program title: UmUTracker Program Files doi: http://dx.doi.org/10.17632/fkprs4s6xp.1 Licensing provisions: Creative Commons by 4.0 (CC by 4.0) Programming language: MATLAB Nature of problem: 3D multi-particle tracking is a common technique in physics, chemistry and biology. However, in terms of accuracy, reliable particle tracking is a challenging task since results depend on sample illumination, particle overlap, motion blur and noise from recording sensors. Additionally, the computational performance is also an issue if, for example, a computationally expensive process is executed, such as axial particle position reconstruction from digital holographic microscopy data. Versatile robust tracking programs handling these concerns and providing a powerful post-processing option are significantly limited. Solution method: UmUTracker is a multi-functional tool to extract particle positions from long video sequences acquired with either light microscopy or digital holographic microscopy. The program provides an easy-to-use graphical user interface (GUI) for both tracking and post-processing that does not require any programming skills to analyze data from particle tracking experiments. UmUTracker first conduct automatic 2D particle detection even under noisy conditions using a novel circle detector based on the isosceles triangle sampling technique with a multi-scale strategy. To reduce the computational load for 3D tracking, it uses an efficient implementation of the Rayleigh–Sommerfeld light propagation model. To analyze and visualize the data, an efficient data analysis step, which can for example show 4D flow visualization using 3D trajectories, is included. Additionally, UmUTracker is easy to modify with user-customized modules due to the object-oriented programming style Additional comments: Program obtainable from https://sourceforge.net/projects/umutracker/ © 2017 Elsevier B.V.","Digital holographic microscopy; Image processing; Microfluidics; Particle tracking velocimetry","Computational fluid dynamics; Computer graphics; Data visualization; Digital microfluidics; Graphical user interfaces; Holograms; Holography; Image processing; MATLAB; Microfluidics; Microscopic examination; Particle size analysis; Phase measurement; Three dimensional computer graphics; Video recording; Computational loads; Computational performance; Digital holographic microscopy; Efficient implementation; Graphical user interfaces (GUI); Holographic microscopy; Particle tracking velocimetry; Polystyrene particle; Object oriented programming",2-s2.0-85021276217
"Gituliar O., Magerya V.","Fuchsia: A tool for reducing differential equations for Feynman master integrals to epsilon form",2017,"Computer Physics Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019739569&doi=10.1016%2fj.cpc.2017.05.004&partnerID=40&md5=026e2f730a3e735f0361ef10c9a81552","We present Fuchsia — an implementation of the Lee algorithm, which for a given system of ordinary differential equations with rational coefficients ∂xJ(x,ϵ)=A(x,ϵ)J(x,ϵ) finds a basis transformation T(x,ϵ), i.e., J(x,ϵ)=T(x,ϵ)J′(x,ϵ), such that the system turns into the epsilon form: ∂xJ′(x,ϵ)=ϵS(x)J′(x,ϵ), where S(x) is a Fuchsian matrix. A system of this form can be trivially solved in terms of polylogarithms as a Laurent series in the dimensional regulator ϵ. That makes the construction of the transformation T(x,ϵ) crucial for obtaining solutions of the initial system. In principle, Fuchsia can deal with any regular systems, however its primary task is to reduce differential equations for Feynman master integrals. It ensures that solutions contain only regular singularities due to the properties of Feynman integrals. Program summary Program Title:Fuchsia Program Files doi: http://dx.doi.org/10.17632/zj6zn9vfkh.1 Licensing provisions: MIT Programming language: Python 2.7 Nature of problem: Feynman master integrals may be calculated from solutions of a linear system of differential equations with rational coefficients. Such a system can be easily solved as an ϵ-series when its epsilon form is known. Hence, a tool which is able to find the epsilon form transformations can be used to evaluate Feynman master integrals. Solution method: The solution method is based on the Lee algorithm (Lee, 2015) which consists of three main steps: fuchsification, normalization, and factorization. During the fuchsification step a given system of differential equations is transformed into the Fuchsian form with the help of the Moser method (Moser, 1959). Next, during the normalization step the system is transformed to the form where eigenvalues of all residues are proportional to the dimensional regulator ϵ. Finally, the system is factorized to the epsilon form by finding an unknown transformation which satisfies a system of linear equations. Additional comments including Restrictions and Unusual features: Systems of single-variable differential equations are considered. A system needs to be reducible to Fuchsian form and eigenvalues of its residues must be of the form n+mϵ, where n is integer. Performance depends upon the input matrix, its size, number of singular points and their degrees. It takes around an hour to reduce an example 74 × 74 matrix with 20 singular points on a PC with a 1.7 GHz Intel Core i5 CPU. An additional slowdown is to be expected for matrices with complex and/or irrational singular point locations, as these are particularly difficult for symbolic algebra software to handle. © 2017 Elsevier B.V.","Differential equations; Epsilon form; Feynman integrals; Fuchsian form; Moser reduction","Computer programming; Differential equations; Eigenvalues and eigenfunctions; Linear systems; Linear transformations; Mathematical transformations; Matrix algebra; Feynman integrals; Rational coefficients; Single variable; Solution methods; Symbolic algebra; System of differential equations; System of linear equations; System of ordinary differential equations; Ordinary differential equations",2-s2.0-85019739569
"Paliyawan P., Thawonmas R.","UKI: universal Kinect-type controller by ICE Lab",2017,"Software - Practice and Experience",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028697547&doi=10.1002%2fspe.2474&partnerID=40&md5=b5f89421922cc5bf4a5f83c77d85150d","Universal Kinect-type-controller by ICE Lab (UKI, pronounced as ‘You-key’) was developed to allow users to control any existing application by using body motions as inputs. The middleware works by converting detected motions into keyboard and/or mouse-click events and sending them to a target application. This paper presents the structure and design of core modules, along with examples from real cases to illustrate how the middleware can be configured to fit a variety of applications. We present our designs for interfaces that decode all configuration details into a human-interpretable language, and these interfaces significantly promote user experience and eliminate the need for programming skill. The performance of the middleware is evaluated on fighting-game motion data, and we make the data publicly available so that they can be used in other researches. UKI welcomes its use by everyone without any restrictions on use; for instance, it can be used to promote healthy life through a means of gaming and/or used to conduct serious research on motion systems. The middleware serves as a shortcut in the development of motion applications—coding of an application to detect motions can be replaced with simple clicks on UKI. Copyright © 2017 John Wiley & Sons, Ltd. Copyright © 2017 John Wiley & Sons, Ltd.","Kinect; middleware; motion controller; user interfaces; video games","Controllers; Copyrights; Ice control; User interfaces; Body motions; Kinect; Motion controller; Motion system; Programming skills; Target application; User experience; Video game; Middleware",2-s2.0-85028697547
"Jayavelu S., Rajkumar C., Rameshkumar R., Surryaprakash D.","Design and analysis of vibration and harshness control for automotive structures using finite element analysis",2017,"International Journal of Civil Engineering and Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032575804&partnerID=40&md5=c0aefa542c9161ba316122d827e10ca9","Many machines and machine mechanisms run under dynamic working conditions. The vibrations produced under dynamic conditions affect many important designs Parameters such as strength, production costs, productivity. Computer aided engineering (CAE) procedures are used to analyses the dynamic Response of the vibration controls. The finite element methods used in the analysis are Applied by a computer aided design and analysis software ANSYS. The aim of this paper is to study existing design automotive structures can operate safely environment to reduced vibration resonances. An ANSYS APDL code is developed to obtain the time-histories to frequency range of model and transient analysis APDL stands for ANSYS Parametric Design Language.","APDL Programming; Modal Transient Analysis; Natural Frequency; Noise and Harshness",,2-s2.0-85032575804
"Abadi M., Blanchet B., Fournet C.","The applied Pi calculus: Mobile values, new names, and secure communication",2017,"Journal of the ACM",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032817560&doi=10.1145%2f3127586&partnerID=40&md5=fe19c014a08210a8767bf821ebe0397d","We study the interaction of the programming construct ""new, "" which generates statically scoped names, with communication via messages on channels. This interaction is crucial in security protocols, which are the main motivating examples for our work; it also appears in other programming-language contexts. We define the applied pi calculus, a simple, general extension of the pi calculus in which values can be formed from names via the application of built-in functions, subject to equations, and be sent as messages. (In contrast, the pure pi calculus lacks built-in functions; its only messages are atomic names.)We develop semantics and proof techniques for this extended language and apply them in reasoning about security protocols. This article essentially subsumes the conference paper that introduced the applied pi calculus in 2001. It fills gaps, incorporates improvements, and further explains and studies the applied pi calculus. Since 2001, the applied pi calculus has been the basis for much further work, described in many research publications and sometimes embodied in useful software, such as the tool ProVerif, which relies on the applied pi calculus to support the specification and automatic analysis of security protocols. Although this article does not aim to be a complete review of the subject, it benefits from that further work and provides better foundations for some of it. In particular, the applied pi calculus has evolved through its implementation in ProVerif, and the present definition reflects that evolution.","Security protocols","Network security; Semantics; Applied pi calculus; Automatic analysis; Built-in functions; Conference papers; Extended languages; Further works; Mobile values; Security protocols; Calculations",2-s2.0-85032817560
"Kieslich P.J., Henninger F.","Mousetrap: An integrated, open-source mouse-tracking package",2017,"Behavior Research Methods",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021199412&doi=10.3758%2fs13428-017-0900-z&partnerID=40&md5=76295690613d59b69d7c47f906c23e8b","Mouse-tracking – the analysis of mouse movements in computerized experiments – is becoming increasingly popular in the cognitive sciences. Mouse movements are taken as an indicator of commitment to or conflict between choice options during the decision process. Using mouse-tracking, researchers have gained insight into the temporal development of cognitive processes across a growing number of psychological domains. In the current article, we present software that offers easy and convenient means of recording and analyzing mouse movements in computerized laboratory experiments. In particular, we introduce and demonstrate the mousetrap plugin that adds mouse-tracking to OpenSesame, a popular general-purpose graphical experiment builder. By integrating with this existing experimental software, mousetrap allows for the creation of mouse-tracking studies through a graphical interface, without requiring programming skills. Thus, researchers can benefit from the core features of a validated software package and the many extensions available for it (e.g., the integration with auxiliary hardware such as eye-tracking, or the support of interactive experiments). In addition, the recorded data can be imported directly into the statistical programming language R using the mousetrap package, which greatly facilitates analysis. Mousetrap is cross-platform, open-source and available free of charge from https://github.com/pascalkieslich/mousetrap-os. © 2017, Psychonomic Society, Inc.","Experimental design; Mouse-tracking; OpenSesame; Process tracing; Python; Response dynamics; Software","computer language; experimental design; eye tracking; human; human experiment; scientist; skill; software",2-s2.0-85021199412
"Dzwiniel P., Gola M., Wójcik-Gryciuk A., Waleszczyk W.J.","Specvis: Free and open-source software for visual field examination",2017,"PLoS ONE",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031276783&doi=10.1371%2fjournal.pone.0186224&partnerID=40&md5=ab73c94eb9fd4c7eb5df0d52daab0bd7","Visual field impairment affects more than 100 million people globally. However, due to the lack of the access to appropriate ophthalmic healthcare in undeveloped regions as a result of associated costs and expertise this number may be an underestimate. Improved access to affordable diagnostic software designed for visual field examination could slow the progression of diseases, such as glaucoma, allowing for early diagnosis and intervention. We have developed Specvis, a free and open-source application written in Java programming language that can run on any personal computer to meet this requirement (http://www.specvis.pl/). Specvis was tested on glaucomatous, retinitis pigmentosa and stroke patients and the results were compared to results using the Medmont M700 Automated Static Perimeter. The application was also tested for inter-test intrapersonal variability. The results from both validation studies indicated low inter-test intrapersonal variability, and suitable reliability for a fast and simple assessment of visual field impairment. Specvis easily identifies visual field areas of zero sensitivity and allows for evaluation of its levels throughout the visual field. Thus, Specvis is a new, reliable application that can be successfully used for visual field examination and can fill the gap between confrontation and perimetry tests. The main advantages of Specvis over existing methods are its availability (free), affordability (runs on any personal computer), and reliability (comparable to high-cost solutions). © 2017 Dzwiniel et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",,"adult; aged; Article; brain ischemia; clinical article; computer language; controlled study; eye fixation; female; glaucoma; human; male; middle aged; perimetry; retinitis pigmentosa; software; test retest reliability; visual field; visual field defect; visual stimulation; economics; Eye Diseases; pathophysiology; perimetry; procedures; Adult; Aged; Eye Diseases; Female; Humans; Male; Middle Aged; Software; Visual Field Tests",2-s2.0-85031276783
"Jalal H., Pechlivanoglou P., Krijkamp E., Alarid-Escudero F., Enns E., Myriam Hunink M.G.","An Overview of R in Health Decision Sciences",2017,"Medical Decision Making",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027071420&doi=10.1177%2f0272989X16686559&partnerID=40&md5=b14dcc61651d8c513e402e709edc3217","As the complexity of health decision science applications increases, high-level programming languages are increasingly adopted for statistical analyses and numerical computations. These programming languages facilitate sophisticated modeling, model documentation, and analysis reproducibility. Among the high-level programming languages, the statistical programming framework R is gaining increased recognition. R is freely available, cross-platform compatible, and open source. A large community of users who have generated an extensive collection of well-documented packages and functions supports it. These functions facilitate applications of health decision science methodology as well as the visualization and communication of results. Although R's popularity is increasing among health decision scientists, methodological extensions of R in the field of decision analysis remain isolated. The purpose of this article is to provide an overview of existing R functionality that is applicable to the various stages of decision analysis, including model design, input parameter estimation, and analysis of model outputs. © 2017 Author(s).","cost-effectiveness analysis; economic evaluation; literature review; R project","cost effectiveness analysis; human; scientist",2-s2.0-85027071420
"Perez-Riverol Y., Ternent T., Koch M., Barsnes H., Vrousgou O., Jupp S., Vizcaíno J.A.","OLS Client and OLS Dialog: Open Source Tools to Annotate Public Omics Datasets",2017,"Proteomics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030696452&doi=10.1002%2fpmic.201700244&partnerID=40&md5=379e61409e2dd266032bb7cc87f553d7","The availability of user-friendly software to annotate biological datasets and experimental details is becoming essential in data management practices, both in local storage systems and in public databases. The Ontology Lookup Service (OLS, http://www.ebi.ac.uk/ols) is a popular centralized service to query, browse and navigate biomedical ontologies and controlled vocabularies. Recently, the OLS framework has been completely redeveloped (version 3.0), including enhancements in the data model, like the added support for Web Ontology Language based ontologies, among many other improvements. However, the new OLS is not backwards compatible and new software tools are needed to enable access to this widely used framework now that the previous version is no longer available. We here present the OLS Client as a free, open-source Java library to retrieve information from the new version of the OLS. It enables rapid tool creation by providing a robust, pluggable programming interface and common data model to programmatically access the OLS. The library has already been integrated and is routinely used by several bioinformatics resources and related data annotation tools. Secondly, we also introduce an updated version of the OLS Dialog (version 2.0), a Java graphical user interface that can be easily plugged into Java desktop applications to access the OLS. The software and related documentation are freely available at https://github.com/PRIDE-Utilities/ols-client and https://github.com/PRIDE-Toolsuite/ols-dialog. © 2017 WILEY-VCH Verlag GmbH & Co. KGaA, Weinheim","data annotation; omics datasets; ontologies; open source software","Article; bioinformatics; computer interface; data base; documentation; information processing; medical ontology; priority journal; software; systems biology; web browser; web ontology language",2-s2.0-85030696452
"Taube-Schiff M., Ruhig M., Mehak A., Deathe van Dyk M., Cassin S.E., Ungar T., Koczerginski D., Sockalingam S.","Staff perspectives: What is the function of adult mental health day hospital programs?",2017,"Journal of Psychiatric and Mental Health Nursing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028770850&doi=10.1111%2fjpm.12405&partnerID=40&md5=ff2d648ecc6a0c55439da7ebce390a65","What Is Known on the Subject?: Psychiatric day hospital (DH) treatment has been offered since the 1930s and is appropriate for individuals experiencing intense psychiatric symptoms without requiring 24-hour inpatient care. No empirical research has examined the specific purpose of DH treatment from the perspectives of healthcare providers within these programs. What This Paper Adds To Existing Knowledge?: This study was the first to address the question of the purpose and function of DH treatment from the outlook of frontline workers within this setting, and confirmed anecdotal observations that DH treatment provides an alternative to intensive psychiatric care, and also operates as “bridge” between these intensive services and purely outpatient treatment. Additional information emerged, such as the importance of the name of DH programs avoiding connotations of illness, the benefits and skills that draw patients to these programs, and challenges that staff and patients experience within DH programs (e.g. short length of treatment, barriers to treatment access). What Are the Implications for Practice?: This information can enhance curriculum development within these settings. For example, given the importance of skill building, it is essential to integrate the provision of skill building and coping strategies within these settings. In addition, given that the name of the setting can impact staff (and perhaps service users as well), ensuring that the name of such program highlight wellness and recovery may enable a different type of therapeutic community to develop within these settings. Abstract: Introduction Despite the benefits of psychiatric day hospitals (DH), research has not addressed staff perspectives of these programs’ effectiveness and barriers. Aim To elucidate staff perceptions of Adult Mental Health DH programs at two hospitals in Canada, allowing for improved programming, enhanced structure and increased understanding of DH settings within the continuum of care. Method Twenty-five DH staff members completed semi-structured qualitative interviews. Two independent coders applied content analysis to achieve data saturation. Results Four major themes emerged: (1) program purpose and function, (2) what is in a name, (3) perceived patient motivation, and (4) room for improvement. Discussion Findings highlighted the importance of a multidisciplinary team delivering education and skill-focused interventions. Services were cited as “bridging” different mental health settings. Challenges included barriers to treatment access and inadequate length of treatment. Implications for Practice Understanding the function and purpose of this treatment service may enhance service delivery by enabling programs to integrate identified key ingredients. Providers can also note treatment duration and consider how to best use that time. Finally, language used within a DH setting appears to impact staff delivering services, and may also alter patients’ understanding of the services they will receive and purpose of the program. © 2017 John Wiley & Sons Ltd","content analysis; day hospital programs; partial hospitalization programs; psychiatric treatment; qualitative methodology; staff experiences","adult; Canada; content analysis; coping behavior; curriculum development; female; health care delivery; hospitalization; human; interview; language; male; mental day hospital; mental health care; motivation; multicenter study; outpatient department; perception; skill; staff; therapeutic community; treatment duration; worker",2-s2.0-85028770850
"Golay J., Leuenberger M., Kanevski M.","Feature selection for regression problems based on the Morisita estimator of intrinsic dimension",2017,"Pattern Recognition",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020014509&doi=10.1016%2fj.patcog.2017.05.008&partnerID=40&md5=3e991ca954a78af3b34e8280f2f30436","Data acquisition, storage and management have been improved, while the key factors of many phenomena are not well known. Consequently, irrelevant and redundant features artificially increase the size of datasets, which complicates learning tasks, such as regression. To address this problem, feature selection methods have been proposed. This paper introduces a new supervised filter based on the Morisita estimator of intrinsic dimension. It can identify relevant features and distinguish between redundant and irrelevant information. Besides, it offers a clear graphical representation of the results, and it can be easily implemented in different programming languages. Comprehensive numerical experiments are conducted using simulated datasets characterized by different levels of complexity, sample size and noise. The suggested algorithm is also successfully tested on a selection of real world applications and compared with RReliefF using extreme learning machine. In addition, a new measure of feature relevance is presented and discussed. © 2017 Elsevier Ltd","Data mining; Feature selection; Intrinsic dimension; Measure of relevance; Morisita index","Data acquisition; Data mining; Digital storage; Filtration; Information management; Learning systems; Extreme learning machine; Feature selection methods; Graphical representations; Intrinsic dimensions; Measure of relevance; Morisita index; Numerical experiments; Redundant features; Feature extraction",2-s2.0-85020014509
"Scharett E., Madathil K.C., Lopes S., Rogers H., Agnisarman S., Narasimha S., Ashok A., Dye C.","An Investigation of the Information Sought by Caregivers of Alzheimer's Patients on Online Peer Support Groups",2017,"Cyberpsychology, Behavior, and Social Networking",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031738374&doi=10.1089%2fcyber.2017.0274&partnerID=40&md5=22764584a24da1247f2c4a0aeb0f86a5","Caregivers of Alzheimer's patients find respite in online communities for solutions and emotional support. This study aims to understand the characteristics of information caregivers of Alzheimer's patients are searching for and the kind of support they receive through Internet-based peer support communities. Using a Web crawler written in Python Web programming language, we retrieved publicly available 2,500 random posts and their respective solutions from April 2012 to October 2016 on the solutions category of the Caregiver's Forum on ALZConnected.org. A content analysis was conducted on these randomly selected posts and 4,219 responses to those posts based on a classification system were derived from initial analyses of 750 posts and related responses. The results showed most posts (26%) related to queries about Alzheimer's symptoms, and the highest percentage of responses (45.56%) pertained to caregiver well-being. The LIWC analyses generated an average tone rating of 27.27 for the posts, implying a negative tone and 65.17 for their responses, implying a slightly positive tone. The ALZConnected.org Web site has the potential of being an emotionally supportive tool for caregivers; however, a more user-friendly interface is required to accommodate the needs of most caregivers and their technological skills. Solutions offered on the peer support groups are often subjective opinions of other caregivers and should not be considered professional or comprehensive; further research on educating caregivers using online forums is necessary. © Copyright 2017, Mary Ann Liebert, Inc. 2017.","Alzheimer's disease; caregiver needs analysis; content analysis; dementia; online peer support groups",,2-s2.0-85031738374
"Abdelaziz A., Tan Fong A., Gani A., Khan S., Alotaibi F., Khurram Khan M.","On Software-Defined Wireless Network (SDWN) Network Virtualization: Challenges and Open Issues",2017,"Computer Journal",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031826868&doi=10.1093%2fcomjnl%2fbxx063&partnerID=40&md5=d986c07258fbde0171e2d8313f28c7e4","Software-defined networking (SDN) is new network architecture that emerges as to implement network virtualization (NV) with vast features, especially when it is applied it in multi-tenant scenarios. The rapid growth of wireless network applications and services, let to adopt NVs into software-defined wireless network (SDWN). This is because wireless networks require specific features that can be hindered of implementing NVs such as updated location information, dynamic channel configuration, and rapid client re-association. This paper presents state-of-the-art NV methods for SDWN with the aim of highlighting issues and challenges of applying NVs techniques of SDN into SDWN. We discuss three SDN techniques that facilitate NV in the cloud, namely proxy-based virtualization, layer two prefixes-based virtualizations and programing language-based virtualization. Moreover, the paper points out the possibility of providing effective VNs in the SDWN architecture. We also taxonomies the SDWN proposed virtualization methods based on hypervisor controller in the different networks. Finally, the potential requirements and challenges and open issues of SDWN NVs are also identified and presented as the future directions in SDWN research. © The British Computer Society 2017. All rights reserved.","network virtualization; OpenFlow; software-defined network; software-defined wireless network","Application programs; Software defined networking; Virtual reality; Virtualization; Wireless networks; Dynamic channels; Issues and challenges; Location information; Network applications; Network virtualization; Openflow; Software defined networking (SDN); State of the art; Network architecture",2-s2.0-85031826868
"Sussman D.M.","cellGPU: Massively parallel simulations of dynamic vertex models",2017,"Computer Physics Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021089203&doi=10.1016%2fj.cpc.2017.06.001&partnerID=40&md5=924a0490fc0f128854e1a197e3ca9cdc","Vertex models represent confluent tissue by polygonal or polyhedral tilings of space, with the individual cells interacting via force laws that depend on both the geometry of the cells and the topology of the tessellation. This dependence on the connectivity of the cellular network introduces several complications to performing molecular-dynamics-like simulations of vertex models, and in particular makes parallelizing the simulations difficult. cellGPU addresses this difficulty and lays the foundation for massively parallelized, GPU-based simulations of these models. This article discusses its implementation for a pair of two-dimensional models, and compares the typical performance that can be expected between running cellGPU entirely on the CPU versus its performance when running on a range of commercial and server-grade graphics cards. By implementing the calculation of topological changes and forces on cells in a highly parallelizable fashion, cellGPU enables researchers to simulate time- and length-scales previously inaccessible via existing single-threaded CPU implementations. Program summary Program Title: cellGPU Program Files doi: http://dx.doi.org/10.17632/6j2cj29t3r.1 Licensing provisions: MIT Programming language: CUDA/C++ Nature of problem: Simulations of off-lattice “vertex models” of cells, in which the interaction forces depend on both the geometry and the topology of the cellular aggregate. Solution method: Highly parallelized GPU-accelerated dynamical simulations in which the force calculations and the topological features can be handled on either the CPU or GPU. Additional comments: The code is hosted at https://gitlab.com/dmsussman/cellGPU, with documentation additionally maintained at http://dmsussman.gitlab.io/cellGPUdocumentation © 2017 Elsevier B.V.","Dynamical vertex model; GPU; Molecular dynamics","Cells; Cytology; Molecular dynamics; Topology; Cellular aggregates; Dynamical simulation; Interaction forces; Massively parallels; Topological changes; Topological features; Two dimensional model; Vertex model; Graphics processing unit",2-s2.0-85021089203
[No author name available],"OpenAccess Series in Informatics",2017,"OpenAccess Series in Informatics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032618735&partnerID=40&md5=fcad5cf7ca2e33ec880b410cb8f6595c","The proceedings contain 23 papers. The topics discussed include: applying attribute grammars to teach linguistic rules; towards an automated test bench environment for prolog systems; generating method documentation using concrete values from executions; towards employing informal sketches and diagrams in software development; modelling Contiki-based IoT systems; exercise solution check specification language for interactive programming learning environments; visualizing the evaluation of functional programs for debugging; a survey on CSS preprocessors; indexing XML documents using tree paths automation; enhancing feedback to students in automated diagram assessment; a REST service for poetry generation; SOS – simple orchestration of services; visualization of ontology evolution using OntoDiffGraph; comparing and combining Portuguese lexical-semantic knowledge bases; an emotional word analyzer for Portuguese; information extraction for event ranking; natural transmission of information extraction results to end-users – a proof-of-concept using data-to-text; and adapting speech recognition in augmented reality for mobile devices in outdoor environments.",,,2-s2.0-85032618735
"Kiefer M., Klebanov V., Ulbrich M.","Relational Program Reasoning Using Compiler IR: Combining Static Verification and Dynamic Analysis",2017,"Journal of Automated Reasoning",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030170380&doi=10.1007%2fs10817-017-9433-5&partnerID=40&md5=74a0b9ab4c0fe3b1ccd2f58cab15fb81","Relational program reasoning is concerned with formally comparing pairs of executions of programs. Prominent examples of relational reasoning are program equivalence checking (which considers executions from different programs) and detecting illicit information flow (which considers two executions of the same program). The abstract logical foundations of relational reasoning are, by now, sufficiently well understood. In this paper, we address some of the challenges that remain to make the reasoning practicable. Two major ones are dealing with the feature richness of programming languages such as C and with the weakly structured control flow that many real-world programs exhibit. A popular approach to control this complexity is to define the analyses on the level of an intermediate program representation (IR) such as one generated by modern compilers. In this paper we describe the ideas and insights behind IR-based relational verification. We present a program equivalence checker for C programs that operates on LLVM IR. To extend the reach of the approach and to make it more efficient, we show how dynamic analyses can be employed to support and strengthen the static verification. The effectiveness of the approach is demonstrated by automatically verifying equivalence of functions from different implementations of the standard C library. © 2017 Springer Science+Business Media B.V.",,"C (programming language); Dynamic analysis; Functions; Control flows; Information flows; Logical foundations; Program equivalence; Program representations; Real world projects; Relational reasoning; Static verification; Program compilers",2-s2.0-85030170380
"Khaliq W., Waheed F.","Mechanical response and spalling sensitivity of air entrained high-strength concrete at elevated temperatures",2017,"Construction and Building Materials",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020938433&doi=10.1016%2fj.conbuildmat.2017.06.039&partnerID=40&md5=d0d801300d8ca2f24ab74329ec8d8335","Polypropylene fibers are commonly used to increase the porosity in high-strength concrete (HSC) in high-temperature environments, to release the vapor pressure in the micropores. However, air entrained HSC can provide suitable alternative to polypropylene fiber reinforced HSC in structures under fire conditions, essentially due to intrinsic porosity. An experimental program was designed to obtain higher strength in air entrained concrete and study its performance at elevated temperatures in 23–800 °C range. In this study, mechanical and material properties of air entrained HSC at varying air volume of 4% and 8% were investigated and compared with conventional HSC in unstressed (hot) state. Compressive strength, splitting tensile strength, stress-strain response, elastic modulus, and spalling along with mass loss and cracking behavior under a higher heating rate of 10 °C per minute were studied. Results show better retention of mechanical properties in air entrained HSC at elevated temperature with improved spalling mitigation and physical properties. © 2017 Elsevier Ltd","Air entrainment; Compressive strength; High-strength concrete; Mass loss; Porosity; Spalling mitigation; Stress-strain; Unstressed conditions","Air entrainment; C (programming language); Concretes; High performance concrete; Polypropylenes; Porosity; Reinforced concrete; Reinforced plastics; Spalling; Tensile strength; High strength concretes; High-temperature environment; Mass loss; Mechanical and material properties; Splitting tensile strength; Stress strain; Stress-strain response; Unstressed conditions; Compressive strength",2-s2.0-85020938433
"Giabbanelli P.J., Tawfik A.A.","Overcoming the PBL Assessment Challenge: Design and Development of the Incremental Thesaurus for Assessing Causal Maps (ITACM)",2017,"Technology, Knowledge and Learning",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030164070&doi=10.1007%2fs10758-017-9338-8&partnerID=40&md5=9a5df97265cd2999f162cd1c9d2d1cdf","Because of the lack of tools available to assess problem-solving skills, teachers often revert to more traditional instructional approaches (e.g. lecture-based, memorization) that fail to prepare learners for the complexity of dynamic work environments. To overcome this challenge, technology solutions are needed that accurately and efficiently assess complex problem-solving skills such as causal reasoning. Moreover, these tools must be valid and reliable so instructors can accurately assess student learning. This emergent report details the design and development of Incremental Thesaurus for Assessing Causal Maps. As will be described, the software offers three unique features: (a) analysis of causal map with little or no manipulation of the original file; (b) a growing repository of terms that supports efficient assessment and (c) ability to codify the level of concept complexity using the structure–behavior–function framework. © 2017 Springer Science+Business Media B.V.","Assessment; Causal reasoning; Ill-structured problem solving; Problem-based learning","C (programming language); Education; Teaching; Thesauri; Assessment; Causal reasoning; Complex problem solving; Design and Development; Ill-structured problem solving; Problem based learning; Problem solving skills; Technology solutions; Problem solving",2-s2.0-85030164070
"Kim S.-W., Lee Y.","A study of educational method using app inventor for elementary computing education",2017,"Journal of Theoretical and Applied Information Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030317768&partnerID=40&md5=9e9b07cf6a3c62d295553cb20e8883d6","With the fourth industrial revolution, software education has become much more important. In South Korea, Informatics will be taught as mandatory to middle school students; education program development and applications with block based programming languages are vivaciously conducted. Although App Inventor has various educational effects, it has not been studied enough. Based on advanced research, an education program was developed, it was applied to 12 elementary school students who were living in Cheongju. As a result of applying the 20th App Inventor education program, there was no significant difference in the creative problem-solving ability and self-efficacy of elementary school students. Those students thought that the App Inventor program was interesting and it is needed to allocate proper class hours by their grade level. Through this result, in the 2015 revised national curriculum, an educational method was conducted to take advantage of App Inventor effectively. This study shows how App Inventor educational programs should be developed and to energize software education. © 2005 - Ongoing JATIT & LLS.","App inventor; Educational method; Elementary school; Programming education; Software education",,2-s2.0-85030317768
"Kim H., Byun J., Byun S., Woo G.","An approach to improving the scalability of parallel haskell programs",2017,"Journal of Theoretical and Applied Information Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030312148&partnerID=40&md5=186c7606bf19477864548cfc5e6c8f40","Though the performance of computer hardware is increasing owing to the many-core architectures, the software counterpart is lack of the proportional throughput. In this situation, functional languages can be one of the alternatives to promote the performance of parallel programs since those languages have an inherent parallelism in evaluating pure expressions without side-effects. Specifically, Haskell is notably popular in parallel programming because it provides easy-to-use parallel constructs based on monads. However, the scalability of parallel programs in Haskell tends to fluctuate as the number of cores is getting increased. The garbage collector is suspected to be the source of this fluctuation because it affects on both the space and the time for the execution of programs. This paper justifies this conjecture using the specific tuning tool, namely GC-Tune. We have tuned the behavior of the garbage collector in the executions of three large-scale parallel programs: the K-means, a maximal independent set, and plagiarism detection programs. As a result, the scalabilities of the programs have been improved by 38%, 21%, and 7%, respectively; the fluctuation ranges are also narrowed down by 45%, 30%, and 58%, respectively, compared to the original execution of the programs without any tuning. This result implies that GC-tuning can be an effective method to promote the scalability of parallel Haskell programs. In results, the execution time of parallel programs can also be much accurately estimated. © 2005 - Ongoing JATIT & LLS.","Garbage collection; GC-Tune; Haskell; K-means; Maximal independent set; Parallel programming; Plagiarism detection",,2-s2.0-85030312148
"Molnos S., Baumbach C., Wahl S., Müller-Nurasyid M., Strauch K., Wang-Sattler R., Waldenberger M., Meitinger T., Adamski J., Kastenmüller G., Suhre K., Peters A., Grallert H., Theis F.J., Gieger C.","pulver: An R package for parallel ultra-rapid p-value computation for linear regression interaction terms",2017,"BMC Bioinformatics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030241332&doi=10.1186%2fs12859-017-1838-y&partnerID=40&md5=3e6d91337a1613b1af8b83487c0ece49","Background: Genome-wide association studies allow us to understand the genetics of complex diseases. Human metabolism provides information about the disease-causing mechanisms, so it is usual to investigate the associations between genetic variants and metabolite levels. However, only considering genetic variants and their effects on one trait ignores the possible interplay between different ""omics"" layers. Existing tools only consider single-nucleotide polymorphism (SNP)-SNP interactions, and no practical tool is available for large-scale investigations of the interactions between pairs of arbitrary quantitative variables. Results: We developed an R package called pulver to compute p-values for the interaction term in a very large number of linear regression models. Comparisons based on simulated data showed that pulver is much faster than the existing tools. This is achieved by using the correlation coefficient to test the null-hypothesis, which avoids the costly computation of inversions. Additional tricks are a rearrangement of the order, when iterating through the different ""omics"" layers, and implementing this algorithm in the fast programming language C++. Furthermore, we applied our algorithm to data from the German KORA study to investigate a real-world problem involving the interplay among DNA methylation, genetic variants, and metabolite levels. Conclusions: The pulver package is a convenient and rapid tool for screening huge numbers of linear regression models for significant interaction terms in arbitrary pairs of quantitative variables. pulver is written in R and C++, and can be downloaded freely from CRAN at https://cran.r-project.org/web/packages/pulver/. © 2017 The Author(s).","Algorithm; Linear regression interaction term; SNP-CpG interaction; Software","Algorithms; Alkylation; Bioinformatics; C++ (programming language); Computer programming; Computer software; Diagnosis; Genetic programming; High level languages; Linear regression; Metabolites; Statistical tests; Correlation coefficient; Genome-wide association studies; Interaction term; Linear regression models; Quantitative variables; Real-world problem; Single-nucleotide polymorphisms; SNP-CpG interaction; Regression analysis",2-s2.0-85030241332
"Martins J.A., Mazayev A., Correia N.","Hypermedia APIs for the Web of Things",2017,"IEEE Access",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030784500&doi=10.1109%2fACCESS.2017.2755259&partnerID=40&md5=3afb3cec0983692b532050dfe469beae","The Web of Things is a new and emerging concept that defines how the Internet of Things can be connected using common Web technologies, by standardising device interactions on upper-layer protocols. Even for devices that can only communicate using proprietary vendor technologies, upper-layer protocols can generally provide the necessary contact points for a high degree of interoperability. One of the major development issues for this new concept is creating efficient Hypermediaenriched Application Programming Interfaces (APIs) that can map physical Things into virtual ones, exposing their properties and functionality to others. This article does an in-depth comparison of the following six Hypermedia APIs: (a) the JSON Hypertext Application Language from IETF, (b) the Media Types for Hypertext Sensor Markup from IETF, (c) the Constrained RESTful Application Language from IETF, (d) the Web Thing Model from Evrythng, (e) the Web of Things Specification from W3C, and (f) the Web Thing API from Mozilla. CCBY","API; Brightness; CoRAL; HAL; HSML; Hypertext; Internet of Things; Internet of Things; Interoperability; Interoperability; Media; Model; Payloads; Proposals; Protocols; Standard; Web of Things; Web Thing","Application programming interfaces (API); C (programming language); Hypermedia systems; Hypertext systems; Internet of things; Interoperability; Luminance; Models; Network protocols; Standards; CoRAL; HSML; Hypertext; Media; Payloads; Proposals; Web Thing; Internet protocols",2-s2.0-85030784500
"Tebbe H.","Data-Informed Collection Decisions Using R",2017,"Serials Review",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030530240&doi=10.1080%2f00987913.2017.1368842&partnerID=40&md5=4985f2f2103828c780eda5ad83e32180","Collection decisions can seem daunting to a librarian who is new to the job. In charge of many new-to-her subject fund codes, the author wanted to understand what had been previously purchased using these funds and how to effectively manage a custom ebook collection. The author used the R programming language to clean and merge purchase and usage data. This article will provide an overview of tasks in R that can be leveraged for making data-informed collection decisions and for sharing information with colleagues. 2017 Published with license by Taylor & Francis © Heidi Tebbe","collection management; programming; R",,2-s2.0-85030530240
"Isenberg T., Jakobs M., Pauck F., Wehrheim H.","Validity of Software Verification Results on Approximate Hardware",2017,"IEEE Embedded Systems Letters",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030758760&doi=10.1109%2fLES.2017.2758200&partnerID=40&md5=dc008067c47326563a174c271e566b33","Approximate computing (AC) is an emerging paradigm for energy-efficient computation. The basic idea of AC is to sacrifice high precision for low energy by allowing hardware to carry out ""approximately correct"" calculations. This provides a major challenge for software quality assurance: Programs successfully verified to be correct might be erroneous on approximate hardware. In this paper, we present a novel approach for determining under what conditions a software verification result is valid for approximate hardware. To this end, we compute the allowed tolerances for AC hardware from successful verification runs. More precisely, we derive a set of constraints which &#x2013; when met by the AC hardware &#x2013; guarantees the verification result to carry over to AC. On the practical side, we furthermore (1) show how to extract tolerances from verification runs employing predicate abstraction as verification technology, and (2) show how to check such constraints on hardware designs. We have implemented all techniques, and exemplify them on example C programs and a number of recently proposed approximate adders. IEEE","Abstract Interpretation; Adders; Approximate Computing; Hardware; Hardware design languages; Hardware Model Checking; Pre/Postconditions.; Safety; Semantics; Software; Tools","Abstracting; Accident prevention; Adders; C (programming language); Computer hardware; Computer software; Computer software selection and evaluation; Energy efficiency; Model checking; Quality assurance; Semantics; Tools; Verification; Abstract interpretations; Approximate Computing; Hardware design language; Hardware models; Pre/Postconditions; Hardware",2-s2.0-85030758760
"Nurhayati D.M., Herman T., Suhendra S.","Analysis of Secondary School Students' Algebraic Thinking and Math-Talk Learning Community to Help Students Learn",2017,"Journal of Physics: Conference Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032385523&doi=10.1088%2f1742-6596%2f895%2f1%2f012054&partnerID=40&md5=38f578ebeafcfb4cbcde6f2884b9ffcf","This study aims to determine the difficulties of algebraic thinking ability of students in one of secondary school on quadrilateral subject and to describe Math-Talk Learning Community as the alternative way that can be done to overcome the difficulties of the students' algebraic thinking ability. Research conducted by using quantitative approach with descriptive method. The population in this research was all students of that school and twenty three students as the sample that was chosen by purposive sampling technique. Data of algebraic thinking were collected through essay test. The results showed the percentage of achievement of students' algebraic thinking's indicators on three aspects: a) algebra as generalized arithmetic with the indicators (conceptually based computational strategies and estimation); b) algebra as the language of mathematics (meaning of variables, variable expressions and meaning of solution); c) algebra as a tool for functions and mathematical modelling (representing mathematical ideas using equations, tables, or words and generalizing patterns and rules in real-world contexts) is still low. It is predicted that because the secondary school students was not familiar with the abstract problem and they are still at a semi-concrete stage where the stage of cognitive development is between concrete and abstract. Based on the percentage achievement of each indicators, it can be concluded that the level of achievement of student's mathematical communication using conventional learning is still low, so students' algebraic thinking ability need to be improved. © Published under licence by IOP Publishing Ltd.",,"Algebra; C (programming language); Concretes; Functions; Modeling languages; Students; Cognitive development; Computational strategy; Learning community; Mathematical communication; Quantitative approach; Real-world; Sampling technique; Secondary schools; Education",2-s2.0-85032385523
"Enayati J., Moravej Z.","Real-time harmonics estimation in power systems using a novel hybrid algorithm",2017,"IET Generation, Transmission and Distribution",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031495581&doi=10.1049%2fiet-gtd.2017.0044&partnerID=40&md5=c74fc4fda8a85000c0efcf7650e6fb93","This study presents a new hybrid algorithm to estimate the harmonic parameters of a distorted signal in power systems. The parameters to be estimated are amplitudes and phases of harmonic components according to the voltage/currents samples. The proposed algorithm is based on combination of the recursive least squares (RLS) and iterated extended Kalman filter (IEKF) techniques. The RLS-IEKF algorithm decomposes the problem into linear amplitude estimation and non-linear phase estimation leading to extracting the intended state vector in online mode and intensive noise presence. As well, RLS-IEKF estimates dynamic parameters using tuning factor which controls the impact of measurement on estimation process. Simulation results obtained by MATLAB show the accuracy and speed of convergence in comparison with that of conventional discrete Fourier transform and ensemble Kalman filter. For further validation, the proposed algorithm is implemented by C++ code and is applied to real switching current data. The real-time implementation of RLS-IEKF in a simple laboratory setup using PC/104 computer set and dedicated hardware shows its satisfactory performance for practical power quality and protection cases. © 2017. The Institution of Engineering and Technology.",,"C++ (programming language); Computer hardware; Discrete Fourier transforms; Harmonic analysis; Kalman filters; MATLAB; Real time control; Real time systems; Ensemble Kalman Filter; Estimation process; Harmonic components; Harmonic parameters; Iterated extended Kalman filter; Real-time implementations; Recursive least square (RLS); Speed of convergence; Parameter estimation",2-s2.0-85031495581
"Cicek P.-V., Elsayed M., Nabki F., El-Gamal M.","A novel multi-level IC-compatible surface microfabrication technology for MEMS with independently controlled lateral and vertical submicron transduction gaps",2017,"Journal of Micromechanics and Microengineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032749309&doi=10.1088%2f1361-6439%2faa874b&partnerID=40&md5=4c782894d804547b7eab18f477aa8587","An above-IC compatible multi-level MEMS surface microfabrication technology based on a silicon carbide structural layer is presented. The fabrication process flow provides optimal electrostatic transduction by allowing the creation of independently controlled submicron vertical and lateral gaps without the need for high resolution lithography. Adopting silicon carbide as the structural material, the technology ensures material, chemical and thermal compatibility with modern semiconductor nodes, reporting the lowest peak processing temperature (i.e. 200°C) of all comparable works. This makes this process ideally suited for integrating capacitive-based MEMS directly above standard CMOS substrates. Process flow design and optimization are presented in the context of bulk-mode disk resonators, devices that are shown to exhibit improved performance with respect to previous generation flexural beam resonators, and that represent relatively complex MEMS structures. The impact of impending improvements to the fabrication technology is discussed. © 2017 IOP Publishing Ltd.","above-IC integration; MEMS; microfabrication; platform technology; silicon carbide","Bacteriophages; C (programming language); Integrated circuits; MEMS; Microanalysis; Processing; Resonators; Semiconducting silicon; Silicon; Silicon carbide; Timing circuits; Above IC; Design and optimization; Fabrication Technologies; High resolution lithography; Platform technology; Processing temperature; Surface microfabrication; Thermal compatibility; Microfabrication",2-s2.0-85032749309
"Reynolds M.S.","A 2.4-GHz, Hybrid 10-Mb/s BPSK Backscatter and 1-Mb/s FSK Bluetooth TX With Hardware Reuse",2017,"IEEE Microwave and Wireless Components Letters",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030770484&doi=10.1109%2fLMWC.2017.2751299&partnerID=40&md5=f5d01bfb406ce2f33e70b2625a7a8717","This letter presents a hybrid architecture for wireless transmitters that reuses the same hardware and antenna to selectively operate in either backscatter or conventional modes, with a minimum of added complexity. A single FET stage is used as both a Class-C power amplifier for a conventional 2.4-GHz, 1-Mb/s frequency shift keying Bluetooth low energy (BLE) transmitter with peak efficiency &#x03B7; &#x2248; 78&#x0025;, as well as a 10-Mb/s BPSK modulator in an ultralow power backscatter mode. A transmitter energy consumption of 81 nJ/b at an output power level of +14 dBm is achieved in the 1-Mb/s conventional mode, while only 32 pJ/b is required in the 10-Mb/s BPSK backscatter mode. It is shown that the data rate of the backscatter mode can be decoupled from the conventional mode, such that the backscatter link can operate at ten times the rate of the conventional link, while achieving over three orders of magnitude power savings. This approach is equally applicable to other communication standards, such as Wi-Fi (IEEE 802.11b), Zigbee (IEEE 802.15.4), and so on. IEEE","Backscatter; backscatter; Backscatter communication; Binary phase shift keying; Bluetooth; Bluetooth low energy (BLE); Field effect transistors; Frequency shift keying; hardware reuse.; Logic gates; Wireless communication","Binary phase shift keying; Bluetooth; C (programming language); Energy utilization; Field effect transistors; Frequency shift keying; Gates (transistor); Hardware; Logic gates; Power amplifiers; Standards; Transmitters; Wireless telecommunication systems; Bluetooth low energies (BLE); Class-c power amplifiers; Communication standards; Hardware reuse; Hybrid architectures; Three orders of magnitude; Wireless communications; ZigBee (IEEE 802.15.4); Backscattering",2-s2.0-85030770484
"Visser W., Păsăreanu C.S.","Probabilistic programming for Java using symbolic execution and model counting",2017,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032619187&doi=10.1145%2f3129416.3129433&partnerID=40&md5=18daa667c2237e090d2eaf8c065e835a","In this paper we describe a probabilistic programming environment for Java that is based on symbolic execution and model counting. The novelty of the framework is that the probability distributions in the program can themselves be symbolic, which allows parametric probabilistic programming. The framework handles typical probabilistic programming features, such as observe statements, and can be used for the encoding and analysis of Discrete Time Markov Chains (DTMC), Bayesian Networks, etc. We show two examples of using the system: (1) analysis of bubble sort when using an unreliable comparison operation, and, (2) analysis of a simulation model of autonomous aircraft towing vehicles, to show whether plans generated for these vehicles are robust when probability distributions are changed from the ones used to generate the plans. © 2017 Association for Computing Machinery.","Model Counting; Probabilistic Programming; Symbolic Execution","Bayesian networks; Engineers; Java programming language; Markov processes; Model checking; Autonomous aircraft; Bubble sort; Discrete time Markov chains; Model Counting; Probabilistic programming; Simulation model; Symbolic execution; Towing vehicles; Probability distributions",2-s2.0-85032619187
"Ade-Ibijola A., Obaido G.","S-NAR: Generating narrations of SQL queries using regular expressions",2017,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032644769&doi=10.1145%2f3129416.3129454&partnerID=40&md5=9a3e08bdb7c74163ff7fe527f819de3e","Structured Query Language (SQL) is popular with relational databases. Despite the simple and highly structured nature of SQL, end users often find it difficult to comprehend written queries and/or write new queries. Hence, a number of tools have been proposed to aid the comprehension of SQL queries via visualisation. In this paper, we present a different comprehension aid called narrations. Narrations are non-technical, textual descriptions of SQL queries. Using a representation of regular languages, regular expressions, we have designed a tool, called S-NAR (or Sql-NARrator), that reads queries and generates a narration of these queries using pre-defined templates. S-NAR was tested with 5,000 queries and narrated 96% of the queries. The generated narrations should find applications in aiding comprehension in the teaching of database courses at higher institutions of learning, and assisting the comprehension of legacy queries in data-centered industries. © 2017 Association for Computing Machinery.","Learning via abstraction; Query comprehension; Regular expression application; SQL query narration","Computer programming languages; Education; Engineers; Pattern matching; Query processing; Teaching; Database course; Learning via abstraction; Query comprehension; Regular expressions; Relational Database; SQL query; Structured query languages; Textual description; Query languages",2-s2.0-85032644769
"Ho T.-Y., Liu F.-T., Ho G.-W., Lin Y.-R.","The implementation of a measurement system for brushless DC motor parameters",2017,"International Journal of Green Energy",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029461505&doi=10.1080%2f15435075.2017.1350184&partnerID=40&md5=6aa137c7e8d0f68fbe012c1062383de1","Most of the energy conversion in industrial devices and equipment is completed by the motor. The acquirement of motor parameters becomes very important for designing the motor drives. The aim of this paper is to design and implement a motor measurement system. Through the processing of an Advanced RISC Machines (ARM) microcontroller, the various parameters of motors such as input voltage, input current, input power, motor speed, and motor torque can be obtained. Consequently, the torque constant, load torque, viscous friction, and the inertia of the motor are calculated and achieved. The motor parameters can be commanded and displayed in the designed human interface of a PC via USB communication. The hardware system designed in this system includes an ARM microcontroller, an inverter, a voltage sensor, a current sensor, a torque sensor, and power supply. The software programming is developed under the Visual Studio 2012 environment development platform using the C language. Finally, the prototype of the motor measurement system is completed and verified. The experimental results for the motor parameters and torque/speed characteristic are demonstrated and show the feasibility of the complete designed system. © 2017 Taylor & Francis Group, LLC.","ARM microcontroller; human interface; motor drives; motor measurement system; motor parameters","AC motors; C (programming language); Controllers; DC motors; Electric drives; Electric motors; Energy conversion; Microcontrollers; Parameter estimation; Torque; Visual languages; ARM microcontrollers; Human Interface; Measurement system; Motor drive; Motor parameters; Brushless DC motors; communication; computer; electricity supply; engine; experimental study; measurement method",2-s2.0-85029461505
"He M., Vafeiadis V., Qin S., Ferreira J.F.","GPS+: Reasoning About Fences and Relaxed Atomics",2017,"International Journal of Parallel Programming",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029906820&doi=10.1007%2fs10766-017-0518-x&partnerID=40&md5=9e7be5896b0ce4f113a1168b932d3b4b","In order to support efficient compilation to modern architectures, mainstream programming languages, such as C/C(Formula presented.) and Java, have adopted weak (or relaxed) memory models. According to these weak memory models, multithreaded programs are allowed to exhibit behaviours that would have been inconsistent under the traditional strong (i.e., sequentially consistent) memory model. This makes the task of reasoning about concurrent programs even more challenging. The GPS framework, developed by Turon et al. (ACM OOPSLA, pp 691–707, 2014), has made a step forward towards tackling this challenge for the release–acquire fragment of the C11 memory model. By integrating ghost states, per-location protocols and separation logic, GPS can successfully verify programs with release–acquire atomics. In this paper, we introduced GPS(Formula presented.) to support a larger class of C11 programs, that is, programs with release–acquire atomics, relaxed atomics and release–acquire fences. Key elements of our proposed logic include two new types of assertions, a more expressive resource model and a set of new verification rules. © 2017 Springer Science+Business Media, LLC","Atomic; C11; Concurrent; Fence; GPS; Hoare logic; Multi-threads; Relaxed memory model; Separation logic; Weak memory model","Computer circuits; Fences; Formal logic; Global positioning system; Multitasking; Atomic; Concurrent; Hoare Logic; Multi-thread; Relaxed memory models; Separation logic; Weak memory models; C (programming language)",2-s2.0-85029906820
"Frieslaar I., Irwin B.","Investigating the effects various compilers have on the electromagnetic signature of a cryptographic executable",2017,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032623990&doi=10.1145%2f3129416.3129436&partnerID=40&md5=b14d1d7489d1b3404eef7de221d7abc0","This research investigates changes in the electromagnetic (EM) signatures of a cryptographic binary executable based on compile-time parameters to the GNU and clang compilers. The source code was compiled and executed on a Raspberry Pi 2, which utilizes the ARMv7 CPU. Various optimization flags are enabled at compile-time and the output of the binary executable’s EM signatures are captured at run-time. It is demonstrated that GNU and clang compilers produced different EM signature on program execution. The results indicated while utilizing the O3 optimization flag, the EM signature of the program changes. Additionally, the g++ compiler demonstrated fewer instructions were required to run the executable; this related to fewer EM emissions leaked. The EM data from the various compilers under different optimization levels was used as input data for a correlation power analysis attack. The results indicated that partial AES-128 encryption keys was possible. In addition, the fewest subkeys recovered was when the clang compiler was used with level O2 optimization. Finally, the research was able to recover 15 of 16 AES-128 cryptographic algorithm’s subkeys, from the the Pi. © 2017 Copyright held by the owner/author(s). Publication rights licensed to Association for Computing Machinery.","C/C++; Compilers; CPA; Electromagnetic; Raspberry Pi","Bins; C (programming language); Engineers; Open source software; Program compilers; Side channel attack; Compile-time parameters; Correlation power analysis; Cryptographic algorithms; Electromagnetic; Electromagnetic signatures; Encryption key; Optimization levels; Program execution; Cryptography",2-s2.0-85032623990
"Cai J., Batshon H.G., Mazurczyk M.V., Sinkin O.V., Wang D., Paskov M., Patterson W., Davidson C.R., Corbett P.C., Wolter G.M., Hammon T.E., Bolshtyansky M.A., Foursa D.G., Pilipetskii A.N.","70.46 Tb/s over 7,600 km and 71.65 Tb/s over 6,970 km Transmission in C+L Band Using Coded Modulation with Hybrid Constellation Shaping and Nonlinearity Compensation",2017,"Journal of Lightwave Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030780284&doi=10.1109%2fJLT.2017.2757281&partnerID=40&md5=5cab0511364d28c4ca07d7cadba9e1dd","We demonstrate 70.46 Tb/s transmission over 7,600 km and 71.65 Tb/s transmission over 6,970 km with C+L band EDFAs using a multi-dimensional coded modulation format with hybrid probabilistic and geometric constellation shaping. The proposed format (4D-PS-9/12-56APSK) is designed to approach Shannon limit and to improve the performance of nonlinearity compensation over conventional and probabilistically shaped 2D formats. The receiver DSP uses multi-stage nonlinearity compensation that includes fast least-mean-square equalizer and generalized filter in addition to digital back propagation. The adaptive linear filters are aided by coded modulation decisions. We study the contribution of each algorithm and show an average total nonlinearity compensation benefit of 1.4 dBQ at the designed amplifier power. IEEE","amplitude phase shift keying (APSK); coherent communication; coherent detection; constellation shaping; Digital signal processing; Forward error correction; Maximum likelihood detection; Modulation; Nonlinear filters; nonlinearity compensation (NLC); optical fiber communication; Receivers; Signal to noise ratio; wavelength-division multiplexing (WDM)","Adaptive optics; Amplitude shift keying; Backpropagation; C (programming language); Digital signal processing; Error compensation; Error correction; Forward error correction; Maximum likelihood; Nonlinear filtering; Nonlinear optics; Optical communication; Optical fiber communication; Optical fibers; Passive filters; Phase shift keying; Receivers (containers); Signal processing; Signal receivers; Signal to noise ratio; Turbo codes; Wavelength division multiplexing; Amplitude-phase-shift keying; Coherent communication; Coherent detection; Constellation shaping; Maximum likelihood detection; Non-linearity compensation; Modulation",2-s2.0-85030780284
"Yahaya N.A.N., Rajapaksha R.D.A.A., Uda M.N.A., Hashim U.","Ultra-low current biosensor output detection using portable electronic reader",2017,"AIP Conference Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030717120&doi=10.1063%2f1.5002430&partnerID=40&md5=bdc67c0055a1133d7f96c6cb5dccafcd","Generally, the electrical biosensor usually shows extremely low current signal output around pico ampere to microampere range. In this research, electronic reader with amplifier has been demonstrated to detect ultra low current via the biosensor. The operational amplifier Burr-Brown OPA 128 and Arduino Uno board were used to construct the portable electronic reader. There are two cascaded inverting amplifier were used to detect ultra low current through the biosensor from pico amperes (pA) to nano amperes ranges (nA). A small known input current was form by applying variable voltage between 0.1V to 5.0V across a 5GΩ high resistor to check the amplifier circuit. The amplifier operation was measured with the high impedance current source and has been compared with the theoretical measurement. The Arduino Uno was used to convert the analog signal to digital signal and process the data to display on reader screen. In this project, Proteus software was used to design and test the circuit. Then it was implemented together with Arduino Uno board. Arduino board was programmed using C programming language to make whole circuit communicate each order. The current was measured then it shows a small difference values compared to theoretical values, which is approximately 14pA. © 2017 Author(s).",,,2-s2.0-85030717120
"Dawson B.P., Infantolino J.K., Vindiola M.M., Monaco J.V.","Tightly integrated deep learning and symbolic programming on a single neuromorphic chip",2017,"Proceedings - IEEE International Symposium on Circuits and Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032669673&doi=10.1109%2fISCAS.2017.8050340&partnerID=40&md5=7f407dd6d4602fb5b3b491f13d449f9f","This work integrates deep learning and symbolic programming paradigms into a unified method for deploying applications to a neuromorphic system. The approach removes the need for coordination among disjoint co-processors by embedding both types entirely on a neuromorphic processor. This integration provides a flexible approach for using each technique where it performs best. A single neuromorphic solution can seamlessly deploy neural networks for classifying sensor-driven noisy data obtained from the environment alongside programmed symbolic logic to processes the input from the networks. We present a concrete implementation of the proposed framework using the TrueNorth neuromorphic processor to play blackjack using a pre-programmed optimal strategy algorithm combined with a neural network trained to classify card images as input. Future extensions of this approach will develop a symbolic neuromorphic compiler for automatically creating networks from a symbolic programming language. © 2017 IEEE.",,"Deep learning; Program compilers; Neuromorphic; Neuromorphic chips; Neuromorphic systems; Optimal strategies; Symbolic logic; Symbolic programming; Symbolic programming language; Unified method; Computer systems programming",2-s2.0-85032669673
"Tolvanen J.-P.","Applying domain-specific languages in metaedit+ for product line development",2017,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032276113&doi=10.1145%2f3109729.3109755&partnerID=40&md5=52e18c58fc1d03ac696d94de0c4b8754","is demonstration shows how domain-specific languages are applied with MetaEdit+ tool in various kinds of product lines, ranging from industry automation to consumer electronics. In the demonstration practical examples are illustrated and executed covering both domain engineering and application engineering. In particular evolution and versioning of domain knowledge and application knowledge is detailed and demonstrated. © 2017 ACM.","Domain-specific language; Domain-specific modeling; Metaedit+; Software product line","Computer programming languages; Computer software; Electronics industry; Graphical user interfaces; Problem oriented languages; Application engineering; Domain engineering; Domain specific languages; Domain specific modeling; Industry automation; Metaedit; Product line development; Software Product Line; Modeling languages",2-s2.0-85032276113
"Troya J., Tolvanen J.-P., Segura S.","Domain-specific languages and model transformations for software product line",2017,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032300022&doi=10.1145%2f3106195.3106227&partnerID=40&md5=4806bc19eb6d281a0b77ae2cdf195705","This tutorial introduces and demonstrates the use of Model-Driven Engineering in Software Product Lines. In particular, it teaches participants about domain-specific languages, metamodeling and modeling, and where these techniques can be best used (and where not). Along with modeling, tutorial teaches various model transformation approaches and how they can be effectively used to bring software product lines to a different domain and to optimize them. .e use of models for handling product variation is demonstrated with real-life examples from various industries and product lines. © 2017 ACM.","ATL; Domain-specific language; Feature model; Model transformation; Software product line; Tutorial","Computer programming languages; Computer software; Graphical user interfaces; Modeling languages; Problem oriented languages; Teaching; Domain specific languages; Feature modeling; Model transformation; Software Product Line; Tutorial; Software design",2-s2.0-85032300022
"Kim J., Batory D., Dig D.","Refactoring Java software product lines",2017,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032262776&doi=10.1145%2f3106195.3106201&partnerID=40&md5=30fae71d6e71ab563060faa2dc294ed1","Refactoring is a staple of Object-Oriented (OO) program development. It should be a staple of OO Software Product Line (SPL) development too. X15 is the first tool to support the refactoring of Java SPL codebases. X15 (1) uses Java custom annotations to encode variability in feature-based Java SPLs, (2) projects a view of an SPL product (a program that corresponds to a legal SPL configuration), and (3) allows programmers to edit and refactor the product, propagating changes back to the SPL codebase. Case studies apply 2316 refactorings in 8 public Java SPLs and show that X15 is as efficient, expressive, and scalable as a state-of-the-art feature-unaware Java refactoring engine. © 2017 ACM.","Refactoring; Software product lines","Java programming language; Object oriented programming; Software design; Java software; Object oriented; Program development; Refactoring engines; Refactorings; Software Product Line; Software product lines; State of the art; Computer software",2-s2.0-85032262776
"Kim J., Batory D., Dig D.","X15: A tool for refactoring Java software product lines",2017,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032298161&doi=10.1145%2f3109729.3109750&partnerID=40&md5=53b3ba4800330e6a04b4295ecb8e1d7c","X15 is the first tool that can apply common object-oriented refactorings to Java Software Product Lines (SPLs). X15 is also the first tool that programmers can write custom scripts (to call refactorings programmatically) to retrofit design patterns into Java SPLs. We motivate and illustrate X15's unique capabilities in this paper. © 2017 ACM.","Refactoring; Software product lines","Computer software; Java programming language; Software design; Java software; Object oriented; Refactorings; Retrofit design; Software Product Line; Object oriented programming",2-s2.0-85032298161
"Garibotti R., Reagen B., Shao Y.S., Wei G.-Y., Brooks D.","Using dynamic dependence analysis to improve the quality of high-level synthesis designs",2017,"Proceedings - IEEE International Symposium on Circuits and Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032662399&doi=10.1109%2fISCAS.2017.8050748&partnerID=40&md5=3062cd36c3d331b781629dc8a24a96d8","High-Level Synthesis (HLS) tools that compile algorithms written in high-level languages into register-transfer level implementations can significantly improve design productivity and lower engineering cost. However, HLS-generated designs still lag handwritten implementations in a number of areas, particularly in the efficient allocation of hardware resources. In this work, we propose the use of dynamic dependence analysis to generate higher quality designs using existing HLS tools. We focus on resource sharing for compute-intensive workloads, a major limitation of relying only on static analysis. We demonstrate that with dynamic dependence analysis, the synthesized designs can achieve an order of magnitude resource reduction without performance loss over the state-of-the-art HLS solutions. © 2017 IEEE.",,"Computer programming languages; Cost engineering; High level languages; Quality control; Dependence analysis; Design productivity; Efficient allocations; Engineering costs; Hardware resources; Performance loss; Register transfer level; Resource sharing; High level synthesis",2-s2.0-85032662399
"Singh A., Pandey Y., Kumar A., Singh M.K., Kumar A., Mukhopadhyay S.C.","Ventilation Monitoring and Control System for High Rise Historical Buildings",2017,"IEEE Sensors Journal",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030790080&doi=10.1109%2fJSEN.2017.2756978&partnerID=40&md5=37b01ca5b0ccd6db91184517da0bd1d9","Adequate ventilation system and difficulty in operating/maintain ventilators at higher levels in temples and high rise historical buildings is a major problem. In this regard a wireless sensor actuator network based ventilation monitoring and control system is developed for temples and high rise historical buildings. Sensor array modules are implemented successfully. ZigBee communication module for transmitting real-time data to the control room is being used. Machine-to-machine communication of the exhaust fans and the control Apps with PC (personal computer) was successfully carried out. Developed system is capable of online monitoring of exhaust fans running information parameters such as air flow, vibration, rpm (revolutions per minute), and load. The system is also capable of ventilation control for good indoor air quality based on real-time monitoring of environmental parameters like as CO2, temperature and relative humidity. A graphical user interface (GUI) for monitoring and control ventilation with the exhaust system was developed. Exhaust fans real-time information and environmental parameters values are displayed on the GUI developed using Visual Studio C&#x0023; language. Calibration of the sensor module and exhaust system has been implemented successfully and they assure that the desired accuracy is sustained after a time interval. Developed system is of low cost, energy efficient, easy to operate with high accuracy. IEEE","Buildings; buildings; environment monitoring; Fans; Monitoring; sensor system application; Temperature sensors; wireless sensor network","Air quality; Buildings; C (programming language); Calibration; Control systems; Energy efficiency; Fans; Graphical user interfaces; Humidity control; Indoor air pollution; Machine-to-machine communication; Personal computers; Quality control; Temperature sensors; User interfaces; Ventilation; Ventilation exhausts; Visual languages; Wireless sensor networks; Zigbee; Environment monitoring; Environmental parameter; Graphical user interfaces (GUI); Monitoring and control systems; Revolutions per minutes; Sensor systems; Temperature and relative humidity; ZigBee communication modules; Monitoring",2-s2.0-85030790080
"Lu W.-S., Hinamoto T.","Design of composite filters with equiripple passbands and least-squares stopbands",2017,"Proceedings - IEEE International Symposium on Circuits and Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032683573&doi=10.1109%2fISCAS.2017.8050766&partnerID=40&md5=b473ae8448cb552fc930a40087bd8c6b","We study a class of composite filters (C-filters), each is composed of a prototype filter and a shaping filter in cascade, where the shaping filter is constructed by cascading several complementary comb filters. In particular, the problem of designing a C-filter with equiripple passband and least-squares stopband subject to peak stopband gain is formulated and an algorithm for designing such a class of linear-phase FIR C-filters is proposed. The algorithm is based on an alternating convex optimization strategy in that the prototype and shaping filters are optimized in separate steps which are coupled and carried out in a sequential manner to yield a satisfactory design. Design example is presented to illustrate the algorithm and demonstrate the performance of the C-filter relative to its conventional FIR counterparts. © 2017 IEEE.",,"Bandpass filters; C (programming language); Convex optimization; Optimization; Composite filter; Design of composites; Least Square; Linear phase; Optimization strategy; Prototype filters; Sequential manners; Shaping filters; FIR filters",2-s2.0-85032683573
"Viitamaki V., Sjovall P., Vanne J., Hamalainen T.D.","High-level synthesized 2-D IDCT/IDST implementation for HEVC codecs on FPGA",2017,"Proceedings - IEEE International Symposium on Circuits and Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032680397&doi=10.1109%2fISCAS.2017.8050323&partnerID=40&md5=895c9190b676c3a7f6d6f6b65fb7aa98","This paper presents efficient inverse discrete cosine transform (IDCT) and inverse discrete sine transform (IDST) implementations for High Efficiency Video Coding (HEVC). The proposal makes use of high-level synthesis (HLS) to implement a complete HEVC 2-D IDCT/IDST architecture directly from the C code of a well-known Even-Odd decomposition algorithm. The final architecture includes a 4-point IDCT/IDST unit for the smallest transform blocks (TB), an 8/16/32-point IDCT unit for the other TBs, and a transpose memory for intermediate results. On Arria II FPGA, it supports real-time (60 fps) HEVC decoding of up to 2160p format with 12.4 kALUTs and 344 DSP blocks. Compared with the other existing HLS approach, the proposed solution is almost 5 times faster and is able to utilize available FPGA resources better. © 2017 IEEE.","Field-programmable gate array (FPGA); High Efficiency Video Coding (HEVC); High-level synthesis (HLS); Inverse discrete cosine transform (DCT); Inverse discrete sine transform (DST)","C (programming language); Codes (symbols); Discrete cosine transforms; Efficiency; Field programmable gate arrays (FPGA); High level synthesis; Image coding; Video signal processing; Decomposition algorithm; Discrete sine transforms; High-efficiency video coding; Intermediate results; Inverse discrete cosine transforms; It supports; Real time; Transpose memory; Inverse transforms",2-s2.0-85032680397
"Jayaraman R., Raja G.","Channel assignment based coding mechanism for reliable transmission for smart cities",2017,"Cluster Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029809811&doi=10.1007%2fs10586-017-1193-9&partnerID=40&md5=1bb26d8e1d8058fb05abfd01f59a9b0b","The broadband wireless network provides an efficient solution for both data reliability and network congestion to meet the demand of the increasing number of mobile users. However, due to dense deployment of nodes, interference and data dissemination problems occur which result in unreliable packet delivery during data transmission in smart cities. All this creates problem in efficient data transmission. In order to solve this problem, in this work, we propose a novel Code-Encoding and Decoding (C-ED) mechanism for IEEE 802.16 networks that helps to mitigate the problem of data dissemination by using minimal number of channels. The proposed C-ED mechanism provides a reliable packet delivery during multicast transmission. As the smart cities are connected with complex networks, our scheme utilizes the existing channel assignment strategies to assign a minimal number of channels to the network and transmit the data using the proposed C-ED mechanism. To illustrate the effectiveness of the proposed C-ED mechanism, it is evaluated by combining it with the existing channel assignment strategies i.e., clique partitioning and random. The simulation results show that the C-ED mechanism with clique partitioning provides improved quality of service than random channel assignment. The C-ED mechanism is compared with Luby Transform (LT) codes which result in reduced transmission delay and improved throughput for a complex network. © 2017 Springer Science+Business Media, LLC","Channel assignment and scheduling; Group based wireless network; Multicast; Network coding; Unicast","Codes (symbols); Complex networks; Data communication systems; Data transfer; Mobile telecommunication systems; Multicasting; Network coding; Problem solving; Quality of service; Smart city; Wireless networks; Broadband wireless network; Channel Assignment; Encoding and decoding; Group-based; Multicast transmissions; Reliable packet deliveries; Reliable transmission; Unicast; C (programming language)",2-s2.0-85029809811
"Horcas J.-M., Pinto M., Fuentes L.","Extending the common variability language (CVL) engine: A practical tool",2017,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032303244&doi=10.1145%2f3109729.3109749&partnerID=40&md5=9c1fb4d36a1df1738ea7f0f28111ec5d","The Common Variability Language (CVL) has become a reference in the specification and resolution of variability in the last few years. Despite the multiple advantages of CVL (orthogonal variability, architecture variability resolution, MOF-compliant, standard proposed,. . . ), several approaches require extending and/or modifying the CVL approach in different ways in order to fulfill the industrial needs for variability modeling in Software Product Lines. However, the community lacks a tool that would enable proposed extensions and the integration of novel approaches to be put into practice. Existing tools that provide support for CVL are incomplete or are mainly focused on the variability model's editor, instead of executing the resolution of the variability over the base models. Moreover, there is no API that allows direct interaction with the CVL engine to extend or use it in an independent application. In this paper, we identify the extension points of the CVL approach with the goal of making the CVL engine more flexible, and to help software architects in the task of resolving the variability of their products. The practical tool presented here is a working implementation of the CVL engine, that can be extended through a proposed API. © 2017 ACM.","CVL; Software product line; Variability","Application programming interfaces (API); Computer software; Software architecture; Software design; Base models; Direct interactions; Extension points; Software architects; Software Product Line; Variability; Variability model; Engines",2-s2.0-85032303244
"Wang E.-H., Zhou L., Chen S.-H.K., Hill K., Parmanto B.","Development and evaluation of a mobile AAC: a virtual therapist and speech assistant for people with communication disabilities",2017,"Disability and Rehabilitation: Assistive Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029902213&doi=10.1080%2f17483107.2017.1369592&partnerID=40&md5=55b27cbb4d203b14e3e9303a4bcb0e78","Purpose: The currently existing Augmentative and Alternative Communication (AAC) technologies have limitations to produce the best communication rehabilitation outcomes and therefore a better solution is needed. Method: In this work, a mobile AAC app was developed based on results from research studies. Sophisticated AAC language programming, embedded training materials, and real-time communication performance reporting were integrated into the app. Two groups of study participants were recruited to participate a usability study and a preliminary feasibility study for the purpose of evaluating this mobile AAC app, respectively. Results: A tablet-based AAC app was developed to support communication rehabilitation. User studies of the app were conducted and included able-bodied individuals and people with verbal communication disabilities. All study participants agreed that the app establishes a usable alternative treatment protocol for communication rehabilitation. Conclusions: The app’s integrated features have great potential to maximize users’ communication effectiveness, enhance language skills, and ultimately improve users’ quality of life.Implications for rehabilitationWe have developed and evaluated an integrated mobile AAC language-based app.This tablet-based app integrated AAC with embedded trainings and real-time performance report. © 2017 Informa UK Limited, trading as Taylor & Francis Group","augmentative and alternative communication; communication disabilities; mHealth; telehealth; usability study",,2-s2.0-85029902213
"Rosenfeld V., Mueller R., Tözün P., Özcan F.","Processing Java UDFs in a C++ environment",2017,"SoCC 2017 - Proceedings of the 2017 Symposium on Cloud Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032453846&doi=10.1145%2f3127479.3132022&partnerID=40&md5=413e67d7ec82251f924605ef9c4427ca","Many popular big data analytics systems today make liberal use of user-defined functions (UDFs) in their programming interface and are written in languages based on the Java Virtual Machine (JVM). This combination creates a barrier when we want to integrate processing engines written in a language that compiles down to machine code with a JVM-based big data analytics ecosystem. In this paper, we investigate efficient ways of executing UDFs written in Java inside a data processing engine written in C++. While it is possible to call Java code from machine code via the Java Native Interface (JNI), a naive implementation that applies the UDF one row at a time incurs a significant overhead, up to an order of magnitude. Instead, we can significantly reduce the costs of JNI calls and data copies between Java and machine code, if we execute UDFs on batches of rows, and reuse input/output buffers when possible. Our evaluation of these techniques using different scalar UDFs, in a prototype system that combines Spark and a columnar data processing engine written in C++, shows that such a combination does not slow down the execution of SparkSQL queries containing such UDFs. In fact, we find that the execution of Java UDFs inside an embedded JVM in our C++ engine is 1.12× to 1.53× faster than executing in Spark alone. Our analysis also shows that compiling Java UDFs directly into machine code is not always beneficial over strided execution in the JVM. © 2017 Association for Computing Machinery.","Data management systems; User-defined functions","C++ (programming language); Cloud computing; Codes (symbols); Data handling; Engines; Information management; Java programming language; Data analytics; Data management system; Java Native Interfaces; Java virtual machines; Processing engine; Programming interface; Prototype system; User Defined Functions; Big data",2-s2.0-85032453846
"Dai T., Dean D., Wang P., Gu X., Lu S.","Hytrace: A hybrid approach to performance bug diagnosis in production cloud infrastructures",2017,"SoCC 2017 - Proceedings of the 2017 Symposium on Cloud Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032447028&doi=10.1145%2f3127479.3132562&partnerID=40&md5=f0111e75ddf5d3e1e9ec83af391212aa","Server applications running inside production cloud infrastructures are prone to various performance problems (e.g., software hang, performance slow down). When those problems occur, developers often have little clue to diagnose those problems. We present Hy-Trace, a novel hybrid approach to diagnosing performance problems in production cloud infrastructures. HyTrace combines rulebased static analysis and runtime inference techniques to achieve higher bug localization accuracy than pure-static and pure-dynamic approaches for performance bugs.HyTrace does not require source code and can be applied to both compiled and interpreted programs such as C/C++ and Java. We conduct experiments using real performance bugs from seven commonly used server applications. The results show that our approach can significantly improve the performance bug diagnosis accuracy compared to existing diagnosis techniques.","Hybrid analysis; Performance bug diagnosis","Application programs; Cloud computing; Computer software; Platform as a Service (PaaS); Program debugging; Static analysis; Bug localizations; Cloud infrastructures; Diagnosis techniques; Dynamic approaches; Hybrid analysis; Inference techniques; Performance problems; Server applications; C (programming language)",2-s2.0-85032447028
"Sadykov V.A., Sadovskaya E.M., Pikalova E.Y., Kolchugin A.A., Filonova E.A., Pikalov S.M., Eremeev N.F., Ishchenko A.V., Lukashevich A.I., Bassat J.M.","Transport features in layered nickelates: correlation between structure, oxygen diffusion, electrical and electrochemical properties",2017,"Ionics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029769640&doi=10.1007%2fs11581-017-2279-3&partnerID=40&md5=461182f6e268ef3eb41b7df2b0455ae0","Oxygen migration is increasingly acknowledged as playing an important role in the ionic transport in mixed conductors and influencing the electrode electrochemical performance. The aim of this work was to establish correlations between the structural and electrical properties of undoped (Ln2NiO4 + δ, Ln = La, Pr) and doped (La1.7M0.3NiO4 + δ, M = Ca, Sr, Ba, La0.85Pr0.85Ca0.3NiO4 + δ, Pr1.7Ca0.3NiO4 + δ) layered nickelates and the oxygen diffusion in these materials to determine what influences their electrochemical response. A new technique for temperature programmed isotope exchange of oxides with C18O2 in a flow reactor was applied to investigate oxygen mobility and surface reactivity in the polycrystalline powder samples which provided the means to experimentally demonstrate the appearance of two channels of oxygen migration in the doped materials via cooperative mechanism and via near-dopant position. The electrochemical performance of the electrodes based on the developed materials was found to exhibit a strong dependence on their oxygen transport characteristics. © 2017 Springer-Verlag GmbH Germany","Electrochemical performance; Isotope exchange; Ln2NiO4 + δ; Ruddlesden–Popper phase; SOFC cathode","C (programming language); Diffusion in gases; Doping (additives); Electrodes; Isotopes; Oxygen; Polycrystalline materials; Solid oxide fuel cells (SOFC); Cooperative mechanisms; Electrochemical performance; Electrochemical response; Isotope exchange; Polycrystalline powders; Ruddlesden; Sofc cathodes; Structural and electrical properties; Electrochemical electrodes",2-s2.0-85029769640
"Sikdar S., Teymourian K., Jermaine C.","An experimental comparison of complex object implementations for big data systems",2017,"SoCC 2017 - Proceedings of the 2017 Symposium on Cloud Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032436105&doi=10.1145%2f3127479.3129248&partnerID=40&md5=ec58446726c041ff746a9ce1a47617e2","Many cloud-based data management and analytics systems support complex objects. Dataflow platforms such as Spark and Flink allow programmers to manipulate sets consisting of objects from a host programming language (often Java). Document databases such as MongoDB make use of hierarchical interchange formats - most popularly JSON - which embody a data model where individual records can themselves contain sets of records. Systems such as Dremel and AsterixDB allow complex nesting of data structures. Clearly, no system designer would expect a system that stores JSON objects as text to perform at the same level as a system based upon a custom-built physical data model. The question we ask is: How significant is the performance hit associated with choosing a particular physical implementation? Is the choice going to result in a negligible performance cost, or one that is debilitating? Unfortunately, there does not exist a scientific study of the effect of physical complex model implementation on system performance in the literature. Hence it is difficult for a system designer to fully understand performance implications of such choices. This paper is an attempt to remedy that. © 2017 Association for Computing Machinery.","Big data management; Complex objects implementation; Data serialization; Experimental comparison","Big data; Cloud computing; Systems analysis; Analytics systems; Complex objects; Data serialization; Document database; Experimental comparison; Interchange formats; Performance costs; Scientific studies; Information management",2-s2.0-85032436105
"Bai X., Wang Y., Liu H., Guo S.","Symmetry Information Based Fuzzy Clustering for Infrared Pedestrian Segmentation",2017,"IEEE Transactions on Fuzzy Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030775220&doi=10.1109%2fTFUZZ.2017.2756827&partnerID=40&md5=4e91957996d0a1affa85730ba8ffb955","Pedestrian detection in infrared images is always a challenging task. Segmentation is an important step of pedestrian detection. An accurate segmentation could provide more information for further analysis. In this paper, an improved Fuzzy C-Means clustering method, which incorporates geometric symmetry information, is proposed for infrared pedestrian segmentation. In the proposed method, symmetry information is introduced by Markov Random Field (MRF) theory. Moreover, a new metric is utilized to handle the weak symmetry of pedestrian. In addition, a whole procedure is proposed to extract infrared pedestrians. The experimental results indicate that our method performs better for infrared pedestrian segmentation and obtains better segmentation results compared with other state-of-art methods. IEEE","Clustering methods; Fuzzy C-Means; Image segmentation; Infrared images; Linear programming; Markov random fields; Mirrors; Pedestrian segmentation; Resistance; Robustness; Symmetry","C (programming language); Cluster analysis; Crystal symmetry; Electric resistance; Fuzzy clustering; Fuzzy systems; Infrared imaging; Linear programming; Markov processes; Mirrors; Robustness (control systems); Clustering methods; Fuzzy C mean; Improved fuzzy c-means clustering; Markov Random Fields; Pedestrian detection; Pedestrian segmentations; Segmentation results; State-of-art methods; Image segmentation",2-s2.0-85030775220
"Cheng Y., Wang M., Xiong Y., Wu Z., Wu Y., Zhang L.","Un-preprocessing: Extended CPP that works with your tools",2017,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032476427&doi=10.1145%2f3131704.3131715&partnerID=40&md5=c9bb2271b1c04cfe29418d887381051c","Many tools directly change programs, such as bug-fixing tools, program migration tools, etc. We call them program-modification tools. On the other hand, many programming languages use the C preprocessor, such as C, C++, and Objective-C. Because of the complexity of preprocessors, many program-modification tools either fail to produce sound results under the presence of preprocessor directives, or give up completely and deal only with preprocessed code. In this paper we propose a lightweight approach that enables program-modification tools to work with the C preprocessor for free. The idea is that program-modification tools now simply target the preprocessed code, and our system, acting as a bidirectional C preprocessor, automatically propagates the changes on the preprocessed code back to the un-preprocessed code. The resulting source code is guaranteed to be correct and is kept similar to the original source as much as possible. We have evaluated our approach on Linux kernel with a set of generated changes. The evaluation results show the feasibility and effectiveness of our approach. © 2017 Association for Computing Machinery.",,"Codes (symbols); Computer operating systems; Program processors; Bug-fixing; C preprocessor; Change programs; Evaluation results; Linux kernel; Program modifications; Source codes; C++ (programming language)",2-s2.0-85032476427
"Cao Y., Zou Y., Luo Y., Xie B., Zhao J.","Refining traceability links between code and software documents",2017,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032476627&doi=10.1145%2f3131704.3131716&partnerID=40&md5=48bceb75984ae7293d2dcb347b4075fd","Recovering traceability links between source code and software document can be very helpful for Software Maintenance and Software Reuse. Existing work has already achieved good results in extracting code elements (classes, methods, etc.) from software documents. However, it will lead to a lot of noise links if we link a document to all the code elements existing in it. In this paper, we propose an approach to identify the contextual code elements and the salient code elements in a software document, then we can weight the traceability links between source code and software document so that those noise traceability links can be filtered effectively. We measure the saliency of each code element in a document with four kinds of document-related features and three kinds of code-related features, and we adopt TransR-based code embedding technology to evaluate the distance between code elements. In the experiments, we get a precision of 70.7% in recognizing salient code elements of StackOverflow answer documents, which is more than 12% improvement compared with Rigby's work. At the same time, we can filter about 56.5%~69.3% noise traceability links compared with the RecoDoc approach. It will improve the quality of traceability links between source code and related software documents. © 2017 Association for Computing Machinery.","Code element; Contextual code element; Salient code element; Software document; Traceability link","Computer programming languages; Computer software reusability; Code element; Contextual code element; Salient code element; Source codes; Traceability links; Codes (symbols)",2-s2.0-85032476627
"Lillack M., Kastner C., Bodden E.","Tracking Load-time Configuration Options",2017,"IEEE Transactions on Software Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030719563&doi=10.1109%2fTSE.2017.2756048&partnerID=40&md5=dd60d1eae493e35dcb4a832cb4f4f864","Many software systems are highly configurable, despite the fact that configuration options and their interactions make those systems significantly harder to understand and maintain. In this work we consider load-time configuration options, such as parameters from the command-line or from configuration files. They are particularly hard to reason about: tracking configuration options from the point at which they are loaded to the point at which they influence control-flow decisions is tedious and error-prone if done manually. We design and implement Lotrack, an extended static taint analysis to track configuration options automatically. Lotrack derives a configuration map that explains for each code fragment under which configurations it may be executed. An evaluation on Android apps and Java applications from different domains shows that Lotrack yields high accuracy with reasonable performance. We use Lotrack to empirically characterize how much of the implementation of Android apps depends on the platform's configuration options or interactions of these options. IEEE","Androids; Bluetooth; Configuration options; Humanoid robots; Java; Software; Static analysis; Tools; Variability mining","Android (operating system); Anthropomorphic robots; Bluetooth; Computer software; Static analysis; Tools; Androids; Configuration files; Configuration options; Design and implements; Humanoid robot; Influence controls; Java; Time configuration; Java programming language",2-s2.0-85030719563
"Palyart M., Murphy G.C., Masrani V.","A Study of Social Interactions in Open Source Component Use",2017,"IEEE Transactions on Software Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030707914&doi=10.1109%2fTSE.2017.2756043&partnerID=40&md5=faa5cd46470a9f009f878714912d4f37","All kinds of software projects, whether open or closed source, rely on open source components. Repositories that serve open source components to organizations, such as the Central Repository and npmjs.org, report billions of requests per year. Despite the widespread reliance of projects on open source components, little is known about the social interactions that occur between developers of a project using a component and developers of the component itself. In this paper, we investigate the social interactions that occur for 5,133 pairs of projects, from two different communities (Java and Ruby) representing user projects that depend on a component project. We consider such questions as how often are there social interactions when a component is used? When do the social interactions occur? And, why do social interactions occur? Our results provide insight into how socio-technical interactions occur beyond the level of an individual or small group of projects previously studied by others and identify the need for a new model of socio-technical congruence for dependencies between, instead of within, projects. IEEE","collaboration; Companies; Computer bugs; Java; Libraries; OSS components; social interactions; Software; Software reuse","Computer software; Computer software reusability; Industry; Java programming language; Libraries; Open systems; Program debugging; Social sciences; collaboration; Computer bugs; Java; OSS components; Social interactions; Open source software",2-s2.0-85030707914
"Zhu Z., Hua C., Zou Y., Xie B., Zhao J.","Automatically generating task-oriented API learning guide",2017,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032484430&doi=10.1145%2f3131704.3131714&partnerID=40&md5=9f43519bc45bf6218d14556737b48f14","Learning and reusing open source API libraries remain a time consuming process due to the documentation quality and the knowledge gap between API providers and users. Some researchers and API providers have found that the development tasks would narrow the knowledge gap and meet the needs of busy developers. To our knowledge, there is no existing work to generating task oriented API documents. In this paper, we propose an automatic approach to generating task oriented API learning guide. The guide is organized by a hierarchical task list. We integrate the natural language processing techniques with an evidence-based filtering pipeline in our approach. We also employ a graph-based clustering procedure to generate a three-layer task list. Furthermore, we define the normal form of the task phrases as the metadata in our approach. The approach has been implemented as a tool, APITasks. We used it to generate the API documents for four libraries. In an empirical study, we evaluate the accuracy and completeness of our approach with the manually created benchmarks. The results affirm the capability of our approach. © 2017 ACM.","API Documentation; Development Tasks; Natural Language Processing; Software Reuse; Stack Overflow","Application programming interfaces (API); Computer software reusability; Graphic methods; Libraries; Open source software; Pipeline processing systems; Automatic approaches; Development tasks; Empirical studies; Evidence-based; Graph-based clustering; Knowledge gaps; Natural languages; Stack overflow; Natural language processing systems",2-s2.0-85032484430
"Rajashekharaiah K.M.M., Pawar M., Patil M.S., Kulenavar N., Joshi G.H.","Design thinking framework to enhance object oriented design and problem analysis skill in Java programming laboratory: An experience",2017,"Proceedings - 2016 IEEE 4th International Conference on MOOCs, Innovation and Technology in Education, MITE 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032802100&doi=10.1109%2fMITE.2016.23&partnerID=40&md5=b6bcfcf9009bb45dcea5a1334b95eb38","After being used to a procedural style of programming, programming in an object-oriented style seems to be difficult. The problem analysis skill is also important where it leads to designing solution for complex problems. In the process of problem analysis, it is big challenge for the students to identify classes, attributes, methods and association between the classes from a given problem statement/Scenario and then mapping to program code. The problem analysis is part of design thinking, where it consists of five phases Empathy (Emphasize), Define, Ideate, Prototype and Test. In this course we implemented a modified standard ""Design Thinking Framework"" through structured enquiry assessment, in our framework few phases are overlapping and it is defined using following phases - 1. Define, 2. Ideate & Prototype, 3. Test. This framework is add-on to our previous practice where a comprehensive tutorial for ""Object Oriented Thinking"" is conducted first to minimize students difficulties. Also it includes ""laboratory experiment categorization"" to help students in improving problem analysis and design skills. By using the above said approaches, it is observed that the students are able to use object oriented concepts efficiently to solve problems, design solutions and performed better in semester end examination. © 2016 IEEE.","Analysis; Categorization; Design thinking; Object oriented paradigm","Computer programming; Curricula; Education; Educational technology; Engineering research; Java programming language; Network function virtualization; Problem solving; Students; Teaching; Analysis; Categorization; Design thinking; Laboratory experiments; Object oriented design; Object oriented paradigm; Object-oriented concepts; Problem statement; Object oriented programming",2-s2.0-85032802100
"Cheramangalath U., Nasre R., Srikant Y.N.","DH-Falcon: A Language for Large-Scale Graph Processing on Distributed Heterogeneous Systems",2017,"Proceedings - IEEE International Conference on Cluster Computing, ICCC",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032630119&doi=10.1109%2fCLUSTER.2017.72&partnerID=40&md5=df9f31d6c833935aadfc1c8ca6f19249","Graph models of social information systems typically contain trillions of edges. Such big graphs cannot beprocessed on a single machine. The graph object must bepartitioned and distributed among machines and processedin parallel on a computer cluster. Programming such systemsis very challenging. In this work, we present DH-Falcon, a graph DSL (domain-specific language) which can be usedto implement parallel algorithms for large-scale graphs, tar-geting Distributed Heterogeneous (CPU and GPU) clusters. DH-Falcon compiler is built on top of the Falcon compiler, which targets single node devices with CPU and multipleGPUs. An important facility provided by DH-Falcon is that itsupports mutation of graph objects, which allows programmerto write dynamic graph algorithms. Experimental evaluationshows that DH-Falcon matches or outperforms state-of-The-Art frameworks and gains a speedup of up to 13×. © 2017 IEEE.","CUDA; Distribute systems; Distributed graph processing; Domain-specific languages; Dynamic graph algorithms; Falcon; MPI; OpenMP","Application programming interfaces (API); Cluster computing; Clustering algorithms; Computer architecture; Computer programming languages; Graphical user interfaces; Problem oriented languages; Program compilers; CUDA; Distribute systems; Domain specific languages; Dynamic graph algorithms; Falcon; Graph processing; OpenMP; Distributed computer systems",2-s2.0-85032630119
"Johnson M., Playne D.","Halide vectorization for android photography applications-a case study",2017,"Proceedings - IEEE International Conference on Cluster Computing, ICCC",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032621922&doi=10.1109%2fCLUSTER.2017.40&partnerID=40&md5=45d3635be0f925a3fab579af42937fc2","We evaluate the vector performance of the Halide domain-specific language for a computational photography application targeted at Android devices. Our application has existing implementations in C++ and ARM NEON and these are used as a baseline for performance comparisons with Halide. We give a very brief introduction to Halide concepts and describe the structure of our application. We describe how each stage of the algorithm is implemented and measure the performance of our Halide implementation on 3 popular vector architectures, x86-64 AVX2, ARMv7 NEON and ARMv8. © 2017 IEEE.","Android; Computational Photography; Halide; Image Processing; Vectorization","Android (operating system); ARM processors; C++ (programming language); Color photography; Computer architecture; Computer programming languages; Image processing; Photography; Problem oriented languages; Android; Computational photography; Domain specific languages; Halide; Performance comparison; Vector architectures; Vectorization; Cluster computing",2-s2.0-85032621922
"Patil S., Supriya K., Uma M., Shettar R.B., Kumar P.","Open ended approach to empirical learning of IOT with Raspberry Pi in modeling and simulation lab",2017,"Proceedings - 2016 IEEE 4th International Conference on MOOCs, Innovation and Technology in Education, MITE 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032795619&doi=10.1109%2fMITE.2016.76&partnerID=40&md5=405fa9b7684800ed45e45663b695b15a","A concept centered open ended experiments motivates the students to think in multidimensional view. In modeling and simulation lab for the second year undergraduate students, the open ended experiment is designed to expose the students to Internet of things (IOT) applications. Python language is one of the freeware and can be used to implement IOT applications using Raspberry Pi. In most of the industries python programming language is widely used for various test automation. Initially the python language is introduced to implement numerical computation algorithms, so that the students are familiar with the basic libraries. Then the open ended experiment is carried out using Raspberry Pi for IOT applications. In this experiment the students are sensing and retrieving data from the cloud. With this approach the students are exposed to python programming and IOT concepts which is most widely used in industry. It also helps the students to carry out higher semester projects in IOT based applications in a better way. © 2016 IEEE.","IOT applications; Modeling and simulation lab; Raspberry Pi-2","Education; Educational technology; Engineering research; High level languages; Internet of Things (IOT); IOT applications; Model and simulation; Numerical computations; Open-Ended Experiments; Python programming language; Raspberry Pi-2; Undergraduate students; Students",2-s2.0-85032795619
"Sub T., Nagel L., Vef M.-A., Brinkmann A., Feld D., Soddemann T.","Pure Functions in C: A Small Keyword for Automatic Parallelization",2017,"Proceedings - IEEE International Conference on Cluster Computing, ICCC",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032621016&doi=10.1109%2fCLUSTER.2017.32&partnerID=40&md5=a4233e267cb420a8e48ab556ac90122d","The need for parallel task execution has been steadily growing in recent years since manufacturers mainly improve processor performance by scaling the number of installed cores instead of the frequency of processors. To make use of this potential, an essential technique to increase the parallelism of a program is to parallelize loops. However, a main restriction of available tools for automatic loop parallelization is that the loops often have to be 'polyhedral' and that it is, e.g., not allowed to call functions from within the loops.In this paper, we present a seemingly simple extension to the C programming language which marks functions without side-effects. These functions can then basically be ignored when checking the parallelization opportunities for polyhedral loops. We extended the GCC compiler toolchain accordingly and evaluated several real-world applications showing that our extension helps to identify additional parallelization chances and, thus, to significantly enhance the performance of applications. © 2017 IEEE.",,"Cluster computing; Computer architecture; Parallel processing systems; Automatic Parallelization; Loop parallelization; Parallel task; Parallelizations; Processor performance; Real-world; Side effect; C (programming language)",2-s2.0-85032621016
"Nakao M., Murai H., Iwashita H., Tabuchi A., Boku T., Sato M.","Implementing Lattice QCD Application with XcalableACC Language on Accelerated Cluster",2017,"Proceedings - IEEE International Conference on Cluster Computing, ICCC",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032646369&doi=10.1109%2fCLUSTER.2017.58&partnerID=40&md5=6b6df73e4dd9e6472bd901c56ee49626","Accelerated clusters, which are distributed memory systems equipped with accelerators, have been used in various fields. For accelerated clusters, programmers often implement their applications by a combination of MPI and CUDA (MPI+CUDA). However, the approach faces programming complexity issues. This paper introduces the XcalableACC (XACC) language, which is a hybrid model of XcalableMP (XMP) and OpenACC. While XMP is a directive-based language for distributed memory systems, OpenACC is also a directive-based language for accelerators. XACC enables programmers to develop applications on accelerated clusters with ease. To evaluate XACC performance and productivity levels, we implemented a lattice quantum chromodynamics (Lattice QCD) application using XACC on 64 compute nodes and 256 GPUS and found its performance was almost the same as that of MPI+CUDA. Moreover, we found that XACC requires much less change from the serial Lattice QCD code than MPI+CUDA to implement the parallel Lattice QCD code. © 2017 IEEE.","Accelerated cluster; Compiler; Parallel language","Computer architecture; Memory architecture; Quantum theory; Accelerated cluster; Compiler; Distributed memory systems; Hybrid model; Lattice QCD; Lattice quantum chromodynamics; Parallel languages; Programming complexity; Cluster computing",2-s2.0-85032646369
"Martinez Ayala D.F., Balasingam B., McComb S., Pattipati K.R.","Markov Modeling and Analysis of Team Communication",2017,"IEEE Transactions on Systems, Man, and Cybernetics: Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030704595&doi=10.1109%2fTSMC.2017.2748985&partnerID=40&md5=ffa93b2c8147725ddbfa17d520d5287e","This paper presents a predictive data analytics process for examining the relationship between team communication and performance in planning tasks. Team performance is measured in terms of the time each team spends in completing the planning task and the cost of the concomitant work schedule. The predictive data analytics process encompasses three data abstraction techniques for data preparation, three probabilistic models that represent the temporal features of data abstracted from team communication interactions, and a validation process that selects the best pair of data abstraction and model for subsequent insight analysis. Experimental data obtained from 32 teams of three members each, tasked to solve a personnel scheduling problem, is used for validating the proposed methodology. IEEE","Analytical models; Data models; Hidden Markov models; Hidden Markov models (HMMs); Markov chains (MCs); Markov processes; Planning; Predictive models; probability mass functions (PMFs); team communication; team performance","Abstracting; Analytical models; Computer programming languages; Data structures; Markov processes; Planning; Predictive analytics; Scheduling; Hidden markov models (HMMs); Predictive models; Probability mass function; Team communication; Team performance; Hidden Markov models",2-s2.0-85030704595
"Kim Y., Dennis J.M., Kerr C.","Assessing representativeness of kernels using descriptive statistics",2017,"Proceedings - IEEE International Conference on Cluster Computing, ICCC",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032627752&doi=10.1109%2fCLUSTER.2017.117&partnerID=40&md5=76ed8c6dd38482657958f606115cd929","A kernel or mini-App is a self-contained small application that retains certain characteristics of the original application [7]. Working on a kernel or mini-App in the place of the original application can dramatically reduce the resources and effort required for performing software tasks such as performance optimization and porting to new platforms. However, using kernel as a proxy is based on the assumption that it represents the original application in the context of how it is being used. In this paper, we introduce an extension to the Fortran Kernel Generator (KGen) which is an automated kernel extraction tool [1]. The extension allows comparison of the execution characteristics between the original application and the generated kernel using descriptive statistics. From the comparison, the user is provided with statistics that provide information on the degree and context of representativeness of the kernel. KGen also utilizes the information generated to help it to automatically improve representativeness of the kernels whilst reducing the size of the workload generated. We applied this extension to three kernels. One is generated from a Fortran scientific library and the remaining two are generated from an earth system model. We have demonstrated that the descriptive statistics provided in the enhancement provide not only quantitative metrics and context of representativeness but also a way to improve the quality of representativeness of the kernels generated. © 2017 IEEE.","Automated kernel extraction; Codesign; Descriptive statistics; Kernel; Python; Representativeness","Cluster computing; Computer architecture; Extraction; FORTRAN (programming language); Statistics; Co-designs; Descriptive statistics; Kernel; Python; Representativeness; Application programs",2-s2.0-85032627752
"McNally J.R., O’Brien P.J.","Kinetic analyses of single-stranded break repair by human DNA ligase III isoforms reveal biochemical differences from DNA ligase I",2017,"Journal of Biological Chemistry",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029737434&doi=10.1074%2fjbc.M117.804625&partnerID=40&md5=2a7f61ef25ee09349fa03bbb6a836061","Humans have three genes encoding DNA ligases with conserved structural features and activities, but they also have notable differences. The LIG3 gene encodes a ubiquitous isoform in all tissues (LIG3α) and a germ line–specific splicing isoform (LIG3β) that differs in the C-terminal domain. Both isoforms are found in the nucleus and the mitochondria. Here, we determined the kinetics and thermodynamics of single-stranded break ligation by LIG3α and LIG3β and compared this framework to that of LIG1, the nuclear replicative ligase. The kinetic parameters of the LIG3 isoforms are nearly identical under all tested conditions, indicating that the BRCA1 C terminal (BRCT) domain specific to LIG3α does not alter ligation kinetics. Although LIG3 is only 22% identical to LIG1 across their conserved domains, the two enzymes had very similar maximal ligation rates. Comparison of the rate and equilibrium constants for LIG3 and LIG1 nevertheless revealed important differences. The LIG3 isoforms were seven times more efficient than LIG1 at ligating nicked DNA under optimal conditions, mainly because of their lower Km value for the DNA substrate. This could explain why LIG3 is less prone to abortive ligation than LIG1. Surprisingly, the affinity of LIG3 for Mg2+ was ten times weaker than that of LIG1, suggesting that Mg2+ availability regulates DNA ligation in vivo, because Mg2+ levels are higher in the mitochondria than in the nucleus. The biochemical differences between the LIG3 isoforms and LIG1 identified here will guide the understanding of both unique and overlapping biological roles of these critical enzymes. © 2017 by The American Society for Biochemistry and Molecular Biology, Inc.",,"C (programming language); Encoding (symbols); Enzymes; Equilibrium constants; Genes; Kinetics; Rate constants; Surgical equipment; Thermodynamics; Brca1 c-terminal domains; C-terminal domains; Critical enzymes; Kinetic analysis; Kinetics and thermodynamics; Optimal conditions; Single-stranded breaks; Structural feature; DNA; adenosine triphosphate; BRCA1 protein; DNA ligase; DNA ligase I; DNA ligase III alpha; DNA ligase III beta; magnesium ion; unclassified drug; adenosine phosphate; ATP dependent DNA ligase; isoenzyme; magnesium; adenylation; Article; binding affinity; carboxy terminal sequence; catalytic efficiency; comparative study; conserved sequence; controlled study; DNA nick translation; DNA purification; DNA repair; equilibrium constant; kinetic parameters; molecular stability; molecular weight; priority journal; rate constant; single stranded DNA break; substrate concentration; thermodynamics; chemistry; dose response; enzyme specificity; enzyme stability; human; kinetics; metabolism; molecular model; protein conformation; protein processing; Adenosine Monophosphate; Conserved Sequence; DNA Breaks, Single-Stranded; DNA Ligase ATP; DNA Repair; Dose-Response Relationship, Drug; Enzyme Stability; Humans; Isoenzymes; Kinetics; Magnesium; Models, Molecular; Protein Conformation; Protein Processing, Post-Translational; Substrate Specificity",2-s2.0-85029737434
"Haupt F., Leymann F., Vukojevic-Haupt K.","API governance support through the structural analysis of REST APIs",2017,"Computer Science - Research and Development",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029752764&doi=10.1007%2fs00450-017-0384-1&partnerID=40&md5=50761769efded124fd33064ba75577c6","Today, REST APIs have established as a means for realizing distributed systems and are supposed to gain even more importance in the context of Cloud Computing, Internet of Things, and Microservices. Nevertheless, many existing REST APIs are known to be not well designed, resulting in the absence of desirable non-functional properties that truly RESTful systems entail. Although existing analysis show, that many REST APIs are not fully REST compliant, it is still an open issue how to improve this deficit and where to start. In this work, we apply structural analysis of REST APIs in order to support API governance, resulting in a set of basic and aggregated metrics that characterize an API set and also guide further governance tasks. We apply the structural analysis on a set of 286 real world APIs and then demonstrate how to derive suitable metrics that represent the perceived complexity of an API, complemented and validated by a survey of developers following the AHP process. As a result, we provide effective support for API governance, helping to identify and remedy problems in APIs. © 2017 Springer-Verlag GmbH Germany","Analysis; API governance; Interface description language; REST","Distributed computer systems; Structural analysis; Analysis; API governance; Distributed systems; Interface description languages; Non functional properties; Real-world; REST; Application programming interfaces (API)",2-s2.0-85029752764
"Zhu X., Zhang Q., Ho E.D., Yu K.H.-O., Liu C., Huang T.H., Cheng A.S.-L., Kao B., Lo E., Yip K.Y.","START: A system for flexible analysis of hundreds of genomic signal tracks in few lines of SQL-like queries",2017,"BMC Genomics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029878806&doi=10.1186%2fs12864-017-4071-1&partnerID=40&md5=e224b554d69d93925d8a0f395c051bff","Background: A genomic signal track is a set of genomic intervals associated with values of various types, such as measurements from high-throughput experiments. Analysis of signal tracks requires complex computational methods, which often make the analysts focus too much on the detailed computational steps rather than on their biological questions. Results: Here we propose Signal Track Query Language (STQL) for simple analysis of signal tracks. It is a Structured Query Language (SQL)-like declarative language, which means one only specifies what computations need to be done but not how these computations are to be carried out. STQL provides a rich set of constructs for manipulating genomic intervals and their values. To run STQL queries, we have developed the Signal Track Analytical Research Tool (START, http://yiplab.cse.cuhk.edu.hk/start/ ), a system that includes a Web-based user interface and a back-end execution system. The user interface helps users select data from our database of around 10,000 commonly-used public signal tracks, manage their own tracks, and construct, store and share STQL queries. The back-end system automatically translates STQL queries into optimized low-level programs and runs them on a computer cluster in parallel. We use STQL to perform 14 representative analytical tasks. By repeating these analyses using bedtools, Galaxy and custom Python scripts, we show that the STQL solution is usually the simplest, and the parallel execution achieves significant speed-up with large data files. Finally, we describe how a biologist with minimal formal training in computer programming self-learned STQL to analyze DNA methylation data we produced from 60 pairs of hepatocellular carcinoma (HCC) samples. Conclusions: Overall, STQL and START provide a generic way for analyzing a large number of genomic signal tracks in parallel easily. © 2017 The Author(s).","Data analysis; Human genomics; Signal tracks","Article; computer interface; data analysis software; data processing; DNA methylation; genomic signal track; genomics; human; Internet; liver cell carcinoma; promoter region; signal track analytical research tool; signal track query language; structured query language",2-s2.0-85029878806
"Bungart M., Fohry C.","A malleable and fault-tolerant task pool framework for X10",2017,"Proceedings - IEEE International Conference on Cluster Computing, ICCC",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032620687&doi=10.1109%2fCLUSTER.2017.27&partnerID=40&md5=9a030a964b31f1f9dc0d4f1eef137472","Current HPC environments require parallel programs that are both malleable and fault-Tolerant. Malleability denotes the ability to embrace system-initiated resource changes, and fault tolerance denotes the ability to cope with, e.g., permanent node failures.This paper considers the task pool pattern, specifically its lifeline-based variant. It builds on a previous fault-Tolerant realization, and integrates the ability to add resources. We suggest a growth protocol that is able to cope with failures of old and new resources during its execution. New resources replace failed ones in one data structure, while getting a new role in another.The algorithm was implemented in a framework for the programming language X10. Correctness tests and performance measurements used the Unbalanced Tree Search (UTS) benchmark. We compared the performance on a constant vs. varying number of workers with same average, and observed negligible differences in execution time and task throughput. © 2017 IEEE.","Fault Tolerance; Malleability; Resilience; Task Pool; X10","Benchmarking; Cluster computing; Computer architecture; Lakes; Fault-tolerant; Malleability; Parallel program; Performance measurements; Resilience; Task Pool; Tree search; Fault tolerance",2-s2.0-85032620687
"Totterdell J.A., Nur D., Mengersen K.L.","Bayesian hidden Markov models in DNA sequence segmentation using R: the case of Simian Vacuolating virus (SV40)",2017,"Journal of Statistical Computation and Simulation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021636865&doi=10.1080%2f00949655.2017.1344666&partnerID=40&md5=747cda3ca052996b067b57b94412fb09","Segmentation models aim to partition compositionally heterogeneous domains into homogeneous segments which may be reflective of biological function. Due to the latent nature of the segments a natural approach to segmentation that has gained favour recently uses Bayesian hidden Markov models (HMMs). Concomitantly in the last few decades, the free R programming language has become a dominant tool for computational statistics, visualization and data science. Therefore, this paper aims to fully exploit R to fit a Bayesian HMM for DNA segmentation. The joint posterior distribution of parameters in the model to be considered is derived followed by the algorithms that can be used for estimation. Functions following these algorithms (Gibbs Sampling, Data Augmentation and Label Switching) are then fully implemented in R. The methodology is assessed through extensive simulation studies and then being applied to analyse Simian Vacuolating virus (SV40). It is concluded that: (1) the algorithms and functions in R can correctly estimate sequence segmentation if the HMM structure is assumed; (2) the performance of the model improves with sequence length; (3) R is reasonably fast for short to medium sequence lengths and number of segments and (4) the segmentation of SV40 appears to correspond with the two major transcripts, early and late, that regulate the expression of SV40 genes. © 2017 Informa UK Limited, trading as Taylor & Francis Group.","Bayesian modelling; data augmentation; DNA sequence; Gibbs sampler algorithm; hidden Markov models; label switching algorithm; R statistical software; segmentation modelling; Simian Vacuolating virus (SV40)",,2-s2.0-85021636865
"Couto M., Pereira R., Ribeiro F., Rua R., Saraiva J.","Towards a green ranking for programming languages",2017,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032193517&doi=10.1145%2f3125374.3125382&partnerID=40&md5=5e850e6167255e65ed8d047f694cca81","While in the past the primary goal to optimize software was the run time optimization, nowadays there is a growing awareness of the need to reduce energy consumption. Additionally, a growing number of developers wish to become more energy-aware when programming and feel a lack of tools and the knowledge to do so. In this paper we define a ranking of energy efficiency in programming languages. We consider a set of computing problems implemented in ten well-known programming languages, and monitored the energy consumed when executing each language. Our preliminary results show that although the fastest languages tend to be the lowest consuming ones, there are other interesting cases where slower languages are more energy efficient than faster ones. © 2017 Association for Computing Machinery.","Energy efficiency; Green software; Language benchmarking; Programming languages","Computer programming languages; Energy utilization; Power management; Energy aware; Energy efficient; Reduce energy consumption; Runtime optimization; Energy efficiency",2-s2.0-85032193517
"Rebêlo H., Leavens G.T.","Aspect-oriented programming reloaded",2017,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032212109&doi=10.1145%2f3125374.3125383&partnerID=40&md5=6768cdc3426541c7727fc9e442830159","Many programs have crosscutting concerns for which neither procedural nor object-oriented programming adequately modularize, which has led to the idea of aspect-oriented programming (AOP). However, AOP has not found favor with the programming languages community due to a belief that AOP breaks classical modularity and modular reasoning. We propose a new AOP programming model that enables both crosscutting modularity and modular reasoning. This model is implemented by AspectJML, a general-purpose aspect-oriented extension to Java. It supports modular crosscutting concerns using key object-oriented mechanisms, such as hierarchical structure, and allows reasoning that scales to ever-larger programs. © 2017 ACM.","Aspect-oriented programming; AspectJ; AspectJML; Modularity","Aspect oriented programming; Aspect-J; Aspect-Oriented Programming (AOP); AspectJML; Cross-cutting concerns; Hierarchical structures; Modular reasoning; Modularity; Programming models; Object oriented programming",2-s2.0-85032212109
"Grossschmidt G., Harf M.","Model-based simulation of hydraulic hoses in an intelligent environment",2017,"International Journal of Fluid Power",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029678685&doi=10.1080%2f14399776.2017.1374140&partnerID=40&md5=09d60899a40dcf957519e1a9c1d0643f","In this paper, comprehensive mathematical models of hydraulic hoses for fluid power systems and a modelling and simulation technology based on using multi-pole models and intelligent simulation environment are proposed. Principles of composing multi-pole mathematical models for hydraulic hoses with lumped parameters having various causalities are discussed. Computing transient and frequency responses of hydraulic hoses in a visual simulation tool CoCoViLa are considered. The CoCoViLa environment is a visual programming tool, which supports declarative programming in a high-level language and automatic program synthesis. The proposed technology enables to find optimal solutions for hydraulic hoses in design and development of various fluid power systems. © 2017 Informa UK Limited, trading as Taylor & Francis Group","automatic program synthesis; CoCoViLa simulation environment; Hydraulic hose; multi-pole mathematical model; visual task description","Computer aided software engineering; Computer programming; Computer programming languages; Frequency response; High level languages; Hose; Hydraulic servomechanisms; Poles; Automatic programs; Declarative Programming; Hydraulic hose; Intelligent environment; Model-based simulations; Modelling and simulation technologies; Simulation environment; Visual tasks; Visual languages",2-s2.0-85029678685
"Viana D.L., De Medeiros Santos A.L.","A domain-specific language for the specification of gesture-based applications",2017,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032174153&doi=10.1145%2f3125374.3125376&partnerID=40&md5=19b85cfb08ef683ebb0e44420e9acf0d","Gesture-based systems are becoming an alternative to the development of intuitive applications for users because they enable them to interact more naturally. In general, such systems use tracking devices together with code to recognize the gestures, which often involves complex implementations. Furthermore, due to the nature of Software Development Kits provided by hardware vendors, the code becomes dependent on the tracking device. Hence, significant portions of the application need to be rewritten in order to run on another device. In this work, we propose the use of a Domain Specific Language to reduce the complexity of specification and recognition of gestures. We also provide a hardware abstraction layer that standardizes the capture of the sensorsfi raw data. This allows any gesture definition to become independent from the device. We conclude by presenting an experiment that evaluates the usage of the language to specify and recognize a large variety of gestures. The results show a reduction in the complexity for specifying and recognizing gestures. © 2017 ACM.","Domain-specific language; Gesture recognition; Natural user interface","Abstracting; Computer programming languages; Hardware; Problem oriented languages; Software design; Specifications; User interfaces; Domain specific languages; Gesture based system; Hardware Abstraction Layers; Natural user interfaces; Nature of software; Tracking devices; Gesture recognition",2-s2.0-85032174153
"Gadea A., Gunther E., Pagano M.","The importance of being Extrinsic: Coherence and adequacy for a call-by-value language",2017,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032209311&doi=10.1145%2f3125374.3125378&partnerID=40&md5=7370ebaeaa41c29c21c92f375a170761","In this paper we mechanize in Coq a typed, call-by-value language by specifying its operational semantics and giving intrinsic and extrinsic denotational semantics, both using domain theory. We also prove that the denotational semantics are equivalent; this is interesting because it leads to a direct proof of coherence for the intrinsic semantics. Finally, we prove the adequacy of the operational semantics with respect to the denotational semantics. As far as we know, this is the first mechanization of Reynolds' bracketing theorem and also the use of biorthogonality with extrinsic semantics instead of intrinsic semantics. © 2017 ACM.","Coherence; Computational adequacy; Mechanization","Coherent light; Computation theory; Computer programming languages; Machinery; Mechanization; Theorem proving; Biorthogonality; Computational adequacy; Denotational semantics; Domain theory; Operational semantics; Reynolds; Semantics",2-s2.0-85032209311
"Ribeiro R., Du Bois A.","Certified bit-coded regular expression parsing",2017,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032179408&doi=10.1145%2f3125374.3125381&partnerID=40&md5=bbae9a842e31e4ae09120903b15a1662","We describe the formalization of a regular expression (RE) parsing algorithm that produces a bit representation of its parse tree in the dependently typed language Agda. The algorithm computes bit-codes using Brzozowski derivatives and we prove that produced codes are equivalent to parse trees ensuring soundness and completeness w.r.t an inductive RE semantics. We include the certified algorithm in a tool developed by us, named verigrep, for regular expression based search in the style of the well known GNU grep. Practical experiments conducted with this tool are reported. © 2017 ACM.","Bit-codes; Certified algorithms; Dependent types; Regular expressions","Codes (symbols); Forestry; Object oriented programming; Open source software; Pattern matching; Semantics; Trees (mathematics); Bit codes; Certified algorithms; Dependent types; Parse trees; Parsing algorithm; Regular expressions; Soundness and completeness; Computer programming languages",2-s2.0-85032179408
"Galindo C., Geil O., Hernando F., Ruano D.","Improved constructions of nested code pairs",2017,"IEEE Transactions on Information Theory",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030757976&doi=10.1109%2fTIT.2017.2755682&partnerID=40&md5=0d23bb0480489e88967e69203469db2c","Two new constructions of linear code pairs C2 &#x2282; C1 are given for which the codimension and the relative minimum distances M1(C1,C2), M1(C&#x2534;2 , C&#x2534;1) are good. By this we mean that for any two out of the three parameters the third parameter of the constructed code pair is large. Such pairs of nested codes are indispensable for the determination of good linear ramp secret sharing schemes [40]. They can also be used to ensure reliable communication over asymmetric quantum channels [54]. The new constructions result from carefully applying the Feng-Rao bounds [21], [31] to a family of codes defined from multivariate polynomials and Cartesian product point sets. IEEE","asymmetric quantum code; Cascading style sheets; Cryptography; CSS construction; Feng-Rao bound; Hamming weight; Linear codes; nested codes; Privacy; Quantum mechanics; ramp secret sharing; relative generalized Hamming weight; relative minimum distance; wiretap channel of type II","Codes (symbols); Communication channels (information theory); Cryptography; Data privacy; Hamming distance; Quantum computers; Quantum theory; Asymmetric quantum codes; Cascading style sheets; Feng-Rao bound; Hamming weights; Linear codes; Minimum distance; Nested codes; Relative generalized Hamming weight; Secret sharing; Wiretap channel of type II; C (programming language)",2-s2.0-85030757976
"Torrens P., Vasconcellos C., Gonçalves J.","A hybrid intermediate language between SSA and CPS: Short Paper",2017,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032183824&doi=10.1145%2f3125374.3125377&partnerID=40&md5=8444fae89f6508a9c3b63d6cba2c63cb","Compiler theory is usually studied individually according to the paradigms of the programming language being compiled. As noted by Kelsey, though the static single assignment (SSA) form has been used as intermediate language for imperative language compilers, and some variant of a continuation passing style (CPS) lambda calculus has been used as intermediate language for functional language compilers, they are (almost) equivalent and it is possible to draw syntactic translations between them. This short paper aims to present an untyped intermediate language which may be interpreted as both SSA and CPS, in order to provide a common language for both imperative and functional compilers, as well to take advantage of optimizations designed for either one of the approaches. Finally, potential variants and research opportunities are discussed. © 2017 ACM.","Continuation passing style; Intermediate languages; Static single assignment","Calculations; Differentiation (calculus); Common languages; Compiler theory; Continuation-passing style; Functional languages; Imperative languages; Intermediate languages; Research opportunities; Static single assignments; Program compilers",2-s2.0-85032183824
"Waszczuk G., Pardo A., Viera M.","Extensible records in Idris",2017,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032201218&doi=10.1145%2f3125374.3125384&partnerID=40&md5=e384422ed2352e306542ee77821b0047","Extensible records are records structures that can be dynamically extended with new fields. In some languages, extensible records are supported as a primitive, in others they are implemented as a user library, each alternative with its benefits and drawbacks. This paper presents a library to strongly-typed extensible records in Idris, a functional programming language with dependent types. Like HList, a Haskell library for extensible records, we use heterogeneous lists to represent our records, but nowexploiting the power of dependent types. We show the benefits of our solution by means of examples. © 2017 ACM.","Extensible records; Heterogeneous lists; Programming with dependent types","Computer applications; Computer programming; Dependent types; Extensible records; Haskell; Heterogeneous lists; Functional programming",2-s2.0-85032201218
"Lazzarini V.","Supporting an object-oriented approach to unit generator development: The csound plugin opcode framework",2017,"Applied Sciences (Switzerland)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029847756&doi=10.3390%2fapp7100970&partnerID=40&md5=a97b91403aff2dccf100a4b3213dd92e","This article presents a new framework for unit generator development for Csound, supporting a full object-oriented programming approach. It introduces the concept of unit generators and opcodes, and its centrality with regards to music programming languages in general, and Csound in specific. The layout of an opcode from the perspective of the Csound C-language API is presented, with some outline code examples. This is followed by a discussion which places the unit generator within the object-oriented paradigm and the motivation for a full C++ programming support, which is provided by the Csound Plugin Opcode Framework (CPOF). The design of CPOF is then explored in detail, supported by several opcode examples. The article concludes by discussing two key applications of object-orientation and their respective instances in the Csound code base. © 2017 by the author. Licensee MDPI, Basel, Switzerland.","C++; Code re-use; Computer music languages; Csound; Musical signal processing; Object-oriented programming; Opcodes; Sound synthesis; Unit generators",,2-s2.0-85029847756
"Ugliara F.A., Dias Vieira G.M., Guimaraes J.D.O.","Transparent replication using metaprogramming in Cyan",2017,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032206300&doi=10.1145%2f3125374.3125375&partnerID=40&md5=f7b1d5dbfcdc49cc50f6e5026e5d8413","Replication can be used to increase the availability of a service by creating many operational copies of its data called replicas. Active replication is a form of replication that has strong consistency semantics, easier to reason about and program. However, creating replicated services using active replication still demands from the programmer the knowledge of subtleties of the replication mechanism. In this paper we show how to use the metaprogramming infrastructure of the Cyan language to shield the application programmer from these details, allowing easier creation of fault-tolerant replicated applications through simple annotations. © 2017 ACM.","Code generation; Metaprogramming; Replication","Computer applications; Computer programming; Active replication; Application programmers; Code Generation; Meta Programming; Replicated services; Replication; Replication mechanism; Strong consistency; Semantics",2-s2.0-85032206300
"Figueroa I.","A preliminary assessment of how monads are used in Haskell",2017,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032195356&doi=10.1145%2f3125374.3125385&partnerID=40&md5=0c9d1c86ba082e6446a5b6a70b79fc5a","Monads are a denotational approach to embed and reason about notions of computation such as mutable state, I/O, exceptions, and many others. Even though monads are technically languageagnostic, they are mostly associated to the Haskell language. Indeed, one could argue that the use of monads is one of the defining characteristic of the Haskell language. In practical terms, monadic programming in Haskell relies on the standard mtl package library, which provides 8 notions of computation: identity, error, list, state, reader, writer, RWS, and continuations. Despite their widespread use, we are not aware of any empirical investigations regarding how developers use monads. In this paper we present preliminary results of an empirical study that quantitatively describe how monads are used in a sample of the Hackage repository. Our results show that around 25% of sampled modules depend on the mtl package, whereas only 1% depend on alternative, yet compatible implementations. Nevertheless, usage patterns for each specific monad remain similar both for mtl and alternatives. Regarding usage, the state monad is by far the most used one, although all of them are used. We also report on the distribution of packages that use mtl, regarding their category and stability level. © 2017 ACM.","Empirical study; Hackage; Haskell; Mining software repositories; Monads; Use of monads","Computer programming; Empirical studies; Hackage; Haskell; Mining software repositories; Monads; Use of monads; Computer applications",2-s2.0-85032195356
[No author name available],"ACM International Conference Proceeding Series",2017,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032192506&partnerID=40&md5=dd3850dc0e2d9e056e7a2c53a6b67fd5","The proceedings contain 11 papers. The topics discussed include: a hybrid intermediate language between SSA and CPS; demand driven less-than analysis; register allocation and instruction scheduling challenge; certified bit-coded regular expression parsing; extensible records in Idris; the importance of being extrinsic: coherence and adequacy for a call-by-value language; towards a green ranking for programming languages; a preliminary assessment of how monads are used in Haskell; transparent replication using meta-programming in cyan; aspect-oriented programming reloaded; and domain-specific language for the specification of gesture-based applications.",,,2-s2.0-85032192506
"Zou Y., Liu H., Xie W., Wan Q.","Semidefinite Programming Methods for Alleviating Sensor Position Error in TDOA Localization",2017,"IEEE Access",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030628303&doi=10.1109%2fACCESS.2017.2752206&partnerID=40&md5=011881817d24993f526768171c9d9dcb","This paper develops a unified solution for time-difference-of-arrival (TDOA) localization in the presence of sensor position errors. This technique starts with maximum likelihood estimation (MLE), which is known to be nonconvex. A semidefinite programming (SDP) technique to effectively transform the MLE problem into a convex optimization is proposed, together with a unified solution for four scenarios: (a) without a calibration emitter; (b) with a single calibration emitter whose position is subject to measurement errors; (c) with a single calibration emitter whose position is perfectly known, and (d) with a single calibration emitter, whose position is completely unknown. The results are finally extended to the case of multiple calibration emitters whose positions are also subject to errors. Similar to existing schemes that are known to have good performances, the proposed solution also reaches the Cram&#x00E9;r-Rao lower bound (CRLB) when sensor position errors and TDOA measurement noise are sufficiently small. However, as TDOA measurement noise or sensor position errors increase, comparison with existing state-of-the-art methods for each scenario shows that the proposed solution performs significantly better. OAPA","semidefinite programming (SDP); sensor position error; Source localization; time-difference-of-arrival (TDOA)","C (programming language); Calibration; Convex optimization; Errors; Maximum likelihood; Maximum likelihood estimation; Spurious signal noise; Time difference of arrival; Time of arrival; Lower bounds; Measurement Noise; Multiple calibration; Semi-definite programming; Sensor position errors; Source localization; State-of-the-art methods; Unified solutions; Solution mining",2-s2.0-85030628303
"Liao S.-W., Kuang S.-Y., Kao C.-L., Tu C.-H.","A Halide-based Synergistic Computing Framework for Heterogeneous Systems",2017,"Journal of Signal Processing Systems",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029574848&doi=10.1007%2fs11265-017-1283-1&partnerID=40&md5=02dadcd34344af9616b6ce9551f43d05","New programming models have been developed to embrace contemporary heterogeneous machines, each of which may contain several types of processors, e.g., CPUs, GPUs, FPGAs and ASICs. Unlike the conventional ones, which use separate programming schemes for different processors of the machine, e.g., OpenMP for the CPU and CUDA for the GPU, the new ones tend to offer a unified programming model to abstract details of heterogeneous computing engines. One such programming model is Halide that is designed for high performance image processing. Halide programmers are allowed to map data and computation to either the CPUs or GPUs through high-level C++ functions, which are converted to various code targets, including x86, ARM, CUDA, and OpenCL, by the Halide compiler. Nevertheless, it becomes complex when the programmers attempt to write a Halide program for cooperative computation on both the CPU and GPU. In this work, we propose the synergistic computing framework that extends Halide to improve program execution performance. Several key issues are tackled, including data coherence, workload partitioning, job dispatching and communication/synchronization, so that the Halide programmers are allowed to take advantage of the heterogeneous computing engines with the two developed C++ classes, one is for static workload partitioning/dispatching and the other is the dynamic counterpart. Furthermore, optimizations are developed to improve performance by generating adequate the CPU code, and eliminating extra memory copies. We characterize and discuss the performance of two image processing programs and our framework on the heterogeneous platforms, i.e., Android Nexus 7 smartphone and x86-based computers. Our results show that significant performance gain can be achieved while the CPU and GPU execute a program synergistically with the proposed framework. © 2017 Springer Science+Business Media, LLC","Graphic processing units; Halide; Heterogeneous computing; Runtime system; Synergistic computing","Application programming interfaces (API); Engines; Graphics processing unit; Image processing; Network function virtualization; Program compilers; Program processors; Graphic processing units; Halide; Heterogeneous computing; Runtime systems; Synergistic computing; C++ (programming language)",2-s2.0-85029574848
"Braga A.M., Silvestre J.D., de Brito J.","Compared environmental and economic impact from cradle to gate of concrete with natural and recycled coarse aggregates",2017,"Journal of Cleaner Production",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024089463&doi=10.1016%2fj.jclepro.2017.06.057&partnerID=40&md5=46e73585ee37f806e19cb256d662283f","The construction sector, a representative activity in Europe, generates high Environmental Impacts: extraction of large quantities of raw materials, high energy consumption and significant production of pollutants and waste. Thereby, this study is intended to be a contribution to the research on the best concrete solutions from an environmental and economy point of view, presenting the comparison, in environmental and economic terms, of the life cycle of concrete with coarse natural and recycled concrete aggregates. A life cycle assessment of concrete (cradle to gate) was performed including all stages except application, maintenance and demolition stages. In the activities where collection of data from companies was not possible, generic databases (Ecoinvent 3 and European Life Cycle Database) were used as reference. Using CML baseline method and Cumulative Energy Demand, the Environmental Impacts of 216 concrete mixes from 24 references were analysed. The results were analysed by strength class and taking into account the influence of the cement content, superplasticizer incorporation and w/c ratio. The results show that the use of coarse aggregates recycled from concrete can significantly reduce the Environmental Impacts and costs, proving that cement is the main contributor to both impacts. The concrete mixes with best mechanical results use coarse aggregates recycled from concrete with better characteristics (low water absorption and porosity, higher density and specific mass), usually corresponding to lower Environmental Impacts and costs. © 2017 Elsevier Ltd","Environmental impact; Life cycle assessment; Life cycle costs; Recycled coarse aggregates; Recycled concrete; SimaPro","Aggregates; C (programming language); Cements; Concrete aggregates; Concrete mixers; Concretes; Construction industry; Costs; Energy utilization; Life cycle; Recycling; Water absorption; Life Cycle Assessment (LCA); Lifecycle costs; Recycled coarse aggregate; Recycled concretes; Simapro; Environmental impact",2-s2.0-85024089463
"Gladstone L., Biare D., Cappelli L., Cushman J.S., Del Corso F., Fujikawa B.K., Hickerson K.P., Moggi N., Pagliarone C.E., Schmidt B., Wagaarachchi S.L., Welliver B., Winslow L.A.","The CUORE slow monitoring systems",2017,"Journal of Physics: Conference Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032437351&doi=10.1088%2f1742-6596%2f888%2f1%2f012234&partnerID=40&md5=18966949c6b7b9818855ce961550701b","CUORE is a cryogenic experiment searching primarily for neutrinoless double decay in 130Te. It will begin data-taking operations in 2016. To monitor the cryostat and detector during commissioning and data taking, we have designed and developed Slow Monitoring systems. In addition to real-time systems using LabVIEW, we have an alarm, analysis, and archiving website that uses MongoDB, AngularJS, and Bootstrap software. These modern, state of the art software packages make the monitoring system transparent, easily maintainable, and accessible on many platforms including mobile devices. © Published under licence by IOP Publishing Ltd.",,"Alarm systems; Astrophysics; Atomic physics; Computer programming languages; Elementary particles; Interactive computer systems; Neutrons; Real time systems; Double decay; LabViEW; MongoDB; Monitoring system; State of the art; Monitoring",2-s2.0-85032437351
"Mladenović M., Mitrović J., Stanković R.","Using lexical resources for irony and sarcasm classification",2017,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032480226&doi=10.1145%2f3136273.3136298&partnerID=40&md5=f6467b64cdc16f9655721474ec834e48","The paper presents a language dependent model for classification of statements into ironic and non-ironic. The model uses various language resources: morphological dictionaries, sentiment lexicon, lexicon of markers and a WordNet based ontology. This approach uses various features: Antonymous pairs obtained using the reasoning rules over the Serbian WordNet ontology (R), antonymous pairs in which one member has positive sentiment polarity (PPR), polarity of positive sentiment words (PSP), ordered sequence of sentiment tags (OSA), Part-of-Speech tags of words (POS) and irony markers (M). The evaluation was performed on two collections of tweets that had been manually annotated according to irony. These collections of tweets as well as the used language resources are in the Serbian language (or one of closely related languages - Bosnian/Croatian/Montenegrin). The best accuracy of the developed classifier was achieved for irony with a set of 5 features - (PPR, PSP, POS, OSA, M) - acc = 86.1%, while for sarcasm the best results were achieved with the set (R, PSP, POS, OSA, M) - acc = 72.8.","Computational irony; Verbal irony; Verbal Sarcasm; WordNet","Computer applications; Computer programming; Computational irony; Language resources; Lexical resources; Part-of-speech tags; Sentiment lexicons; Verbal irony; Verbal Sarcasm; Wordnet; Ontology",2-s2.0-85032480226
"Polikarpova N., Tschannen J., Furia C.A.","A fully verified container library",2017,"Formal Aspects of Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029579284&doi=10.1007%2fs00165-017-0435-1&partnerID=40&md5=373218866fa8e5162feba43ca032eaf1","The comprehensive functionality and nontrivial design of realistic general-purpose container libraries pose challenges to formal verification that go beyond those of individual benchmark problems mainly targeted by the state of the art. We present our experience verifying the full functional correctness of EiffelBase2: a container library offering all the features customary in modern language frameworks, such as external iterators, and hash tables with generic mutable keys and load balancing. Verification uses the automated deductive verifier AutoProof, which we extended as part of the present work. Our results indicate that verification of a realistic container library (135 public methods, 8400 LOC) is possible with moderate annotation overhead (1.4 lines of specification per LOC) and good performance (0.2 s per method on average). © 2017 The Author(s)","AutoProof; Containers; Deductive verification; Object-oriented software; SMT","Containers; Formal verification; Surface mount technology; Verification; AutoProof; Bench-mark problems; Container libraries; Deductive verification; Functional correctness; Modern languages; Object oriented software; State of the art; Object oriented programming",2-s2.0-85029579284
"Ming L., Liu J.-X.","Prediction of the amount of vessels arriving at inland port based on time series analysis",2017,"2017 4th International Conference on Transportation Information and Safety, ICTIS 2017 - Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032798987&doi=10.1109%2fICTIS.2017.8047864&partnerID=40&md5=e91c50a91c8cdf6bead9db9cef5c1521","This paper focused on the prediction of the amount of vessels arriving at the inland port. Based on the statistical data, this paper analyzed the process of time series modeling and model test, set up prediction model of the amount of vessels by using time series analysis method, R programming language, and SAS statistical software. The whole process was described in detail based on an example. It proved that the amount of vessels arriving at the inland port was predicted very well. It lays the foundation for inland port planning. © 2017 IEEE.","inland port; Prediction; the amount of vessels; time series","Forecasting; Harmonic analysis; Modeling languages; Ports and harbors; Software testing; Time series; inland port; Port planning; Prediction model; Statistical datas; Statistical software; the amount of vessels; Time series modeling; Whole process; Time series analysis",2-s2.0-85032798987
"Chen R., Luo Y., Li R., Zhang X., Ying L.","Analysis of the automatic test generation tool: CREST",2017,"Proceedings - 2016 International Conference on Intelligent Transportation, Big Data and Smart City, ICITBS 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032836651&doi=10.1109%2fICITBS.2016.86&partnerID=40&md5=8fa98cb60840c9d8809449b12e68d211","The CREST is an open source automatic test generation tool for C which based on Common Intermediate Language and Yices. One of its major advantages is that several heuristic search strategies are proposed to test larger programs. The success of CREST should be attributed to static instrumentation, concolic execution, and heuristic search. Thus, it's meaningful for software testing and vulnerability exploitation to analyze this software testing platform. The concolic execution is introduced briefly in the first. Then, the work flow of CREST, instrumentation and the solver is explained. In addition, the key structures used to store symbolic expression and heuristic search strategies are given. By giving examples of executing the single-file and multiple-files program, the execution performance of three common utilities from Busybox is analyzed at last. Through this project, we have learned limitations of CREST. Conclusion and future work provide a sense of direction of concolic execution in software testing. © 2016 IEEE.","Concolic execution; Heuristic search strategies; Performance analysis; Software testing; Test generation","Big data; C (programming language); Heuristic algorithms; Heuristic programming; Modular robots; Open source software; Smart city; Automatic test generation; Concolic execution; Execution performance; Heuristic search strategy; Intermediate languages; Performance analysis; Symbolic expression; Test generations; Software testing",2-s2.0-85032836651
"Spek F., Weehuizen M., Achterberg I.","Using Concurrent Modeling of Thermodynamics and Controller in Developing ECS Control Functionality",2017,"SAE Technical Papers",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028996197&doi=10.4271%2f2017-01-2160&partnerID=40&md5=0dd4532b0de30e68b5c7f0d1745f7970","In new aircraft programs, systems' functionality is increasingly becoming integrated into modular avionics. Controllers may not be delivered by the systems supplier so this trend creates a new interface between systems and controllers. A functional software specification is therefore needed to facilitate the building of the software by the controller supplier. In the case of an ECS system controller, the hardware was obtained from different suppliers and a software functional specification was needed for the controller supplier. To be able to design and verify the system functionality, an integrated ECS simulation model was created which coupled the thermodynamics of the aircraft and ECS system to the controller actions. The model also included functionality to simulate sensor noise and component failures. The thermodynamic model was created in Matlab/Simulink and consisted of a combination of direct programming as well as data on a Flowmaster model for the bleed system. The vapor cycle cooling system model was simulated within Matlab/Simulink using the Thermosys package. The controller side was modelled using compiled C++ controllers, thereby allowing rapid updates to functionality and configuration control. Component controllers were tested on a bleed air test rig where stable component control was shown. The integrated model allowed the integration of different level controllers in order to achieve the required functionality. Several flight profiles were created in order to be able to simulate both normal and abnormal conditions. After several iterations of the system functionality, a stable system response was obtained and the functionality was correctly specified. Some interesting observations were made regarding component behavior which were quickly addressed with the hardware suppliers thereby allowing further functionality optimization. Generally, the tool facilitated rapid development of the ECS control functionality. © 2017 SAE International.",,"C++ (programming language); Computer programming; Concurrency control; Fighter aircraft; Hardware; MATLAB; Specifications; Thermodynamics; Configuration control; Control functionality; Functional specification; Integrated modeling; Required functionalities; Software Specification; System functionality; Thermodynamic model; Controllers",2-s2.0-85028996197
"Lu N.","Design and implementation of fetal education music management system",2017,"Proceedings - 2016 International Conference on Intelligent Transportation, Big Data and Smart City, ICITBS 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032819127&doi=10.1109%2fICITBS.2016.113&partnerID=40&md5=be81f3031e21dd10ae9f8b3c1fdd4709","In order to allow gave birth to the fetus in the mother's body has a good atmosphere for the development, it is imperative to the implementation of prenatal music, so in this paper, the design and R & D the this music prenatal education management system. Prenatal music management system construction of the overall goal is to develop an application oriented, safe and reliable, flexible operation, convenient, standardized and unified system. This system combined with the developing thought of the information management system, the reference to the online music management software, according to the ideas of software engineering design based on C / S structure of the music prenatal education management system. This paper describes in detail the whole process of the development of fetal education music management system. Introduced the basic concept of music prenatal education and development trend, in the demand analysis to clarify the feasibility and necessity of music prenatal education management information system, system development process, fully in accordance with the idea of software engineering to complete. This system has realized the backstage data management, maintenance and foreground for users to use the platform, in the background maintenance in the music resource maintenance upload management, reasonable standard classification of prenatal music. Let there be need in the shortest time find the most suitable music, in front of the play, to realize the function of fast forward, slow down, a song, a song, memory playback, and set up the special recording function, makes the user more convenient use. The various functions of the management information system of fetal education music have achieved initial expectations, and achieved favorable effect. © 2016 IEEE.","C/S architecture; Database technology; Fetal education management; Music system; UML language","Big data; C (programming language); Maintenance; Management information systems; Smart city; Software engineering; Background maintenance; Database technology; Design and implementations; Education management; Information management systems; Music system; System development process; UML language; Information management",2-s2.0-85032819127
"Cui J., Sheng W., Wu Q., Yu C., Hao E., Bobadova-Parvanova P., Storer M., Asiri A.M., Marwani H.M., Jiao L.","Synthesis, Structure, and Properties of Near-Infrared [b]Phenanthrene-Fused BF2 Azadipyrromethenes",2017,"Chemistry - An Asian Journal",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028007042&doi=10.1002%2fasia.201700876&partnerID=40&md5=5e82d57f9977b60c935085651f5ad9b2","A new class of phenanthrene-fused BF2 azadipyrromethene (azaBODIPY) dyes have been synthesized through a tandem Suzuki reaction and oxidative ring-fusion reaction, or a palladium-catalyzed intramolecular C−H activation reaction. These phenanthrene-fused azaBODIPY dyes are highly photostable and display markedly redshifted absorption (up to λ=771 nm) and emission bands (λ≈800 nm) in the near-infrared region. DFT calculations and cyclic voltammetry studies indicate that, upon annulation, more pronounced stabilization of the LUMO is the origin of the bathochromic shift of the absorption and high photostability. © 2017 Wiley-VCH Verlag GmbH & Co. KGaA, Weinheim","density functional calculations; dyes/pigments; fused-ring systems; photochemistry; synthesis design","Activation analysis; Anthracene; C (programming language); Chemical reactions; Cyclic voltammetry; Density functional theory; Design for testability; Fusion reactions; Photochemical reactions; Bathochromic shift; Dyes/pigments; Fused-ring system; Intramolecular C-H activation; Near infrared region; Palladium-catalyzed; Redshifted absorption; Synthesis design; Infrared devices",2-s2.0-85028007042
"Haitao Y., Yu W., Xinxi L., Ruochen F., Yong D.","Research of RBFNN-based traffic energy-consumption model",2017,"Proceedings - 2016 International Conference on Intelligent Transportation, Big Data and Smart City, ICITBS 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032823702&doi=10.1109%2fICITBS.2016.34&partnerID=40&md5=0a33b851dd28981ff59dae91adaed88f","Energy saving and emission reduction are of great importance for the development of transportation. Therefore, researchers should conduct precise measurements on energy consumption caused by vehicles to support the applications of green navigation. In most cases, energy consumption are resulted by vehicles driving on the roads, of which are numerous and great mobility and hard to be directly collected and monitored through energy-consumption sensing devices. So a lot of scholars used a model of vehicles' energy consumption based on computer technology and established a historical database through analyzing historic data to support the measurements of energy consumption. On hand, previous studies on energy-consumption models would collect a large amount of samples despite of the accuracy of data. And on the other hand, different structures of different road conditions which may influence the generation of energy consumption and result in the secondary loss of accurate data were neglected as well. Aimed at the problems mentioned above, I would like to set forth and conduct a measurement of energy consumption based on computer technologies and combined with a real-Time measurement of city roads of RBFNN, which would measure different road sections. The traffic network of Beijing city would be chose as an example to establish an energy-consumption model of transportation and to offer support for the government to monitor and assess a traffic management strategy which is oriented at saving energy and reducing emission, as well as offer technical support for the application of intelligent traffic system of energy saving and emission reduction. © 2016 IEEE.","Energy Consumption Model; RBFNN; Traffic Network","Big data; Emission control; Energy conservation; Energy utilization; FORTH (programming language); Mobile devices; Roads and streets; Smart city; Traffic control; Transportation; Vehicles; Energy consumption model; Energy saving and emission reductions; Intelligent traffic systems; Precise measurements; RBFNN; Real time measurements; Traffic management strategies; Traffic networks; Green computing",2-s2.0-85032823702
"Jha A.K., Choudhary P.","Adopting Model-Based Software Design and Verification for Aerospace Systems",2017,"SAE Technical Papers",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028960709&doi=10.4271%2f2017-01-2110&partnerID=40&md5=28540afb8e6a4e3538b81b53663a7593","The complexity of software development is increasing unprecedentedly with every next generation of aircraft systems. This requires to adopt new techniques of software design and verification that could optimize the time and cost of software development. At the same time these techniques need to ensure high quality of software design and safety compliance to regulatory guidelines like DO-178C [1] and its supplements DO-330[2] and DO-331[3]. To arrive at new technologies one has to evaluate the alternate methods available for software design by developing models, integration of models, auto-code generation, auto test generation and also the performance parameters like time, effort, reuse and presentation needs to be evaluated. We have made an attempt to present summary of alternate design concept study, and edge of MBD over other design techniques. The new techniques have challenges in managing the software development processes through conventional means and showing their compliance to stringent industry standards and guidelines. We have present process compliance to aerospace software development guideline DO-178C. This paper has discussed requirements of DO-178C and its associated supplement DO-331 for model based software development and demonstrated means of compliance for models. It has also presented requirements of DO-330 for tool qualification and its applicability to model-based software development and verification. © 2017 SAE International.",,"C (programming language); Computer software reusability; Fighter aircraft; Regulatory compliance; Software engineering; Software testing; Verification; Aerospace systems; Auto-code generations; Industry standards; Performance parameters; Regulatory guidelines; Safety compliances; Software development process; Tool qualifications; Software design",2-s2.0-85028960709
"Ghanim F., Vishkin U., Barua R.","Easy PRAM-based high-performance parallel programming with ICE",2017,"IEEE Transactions on Parallel and Distributed Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030624180&doi=10.1109%2fTPDS.2017.2754376&partnerID=40&md5=e17ff3f929951344ad40e32d789bcbb7","Parallel machines have become more widely used. Unfortunately parallel programming technologies have advanced at a much slower pace for irregular-programs. This advancement is inhibited by synchronization costs, non-loop parallelism, non-array data structures, recursively expressed parallelism and parallelism, too fine-grained to be exploitable. We present ICE, a new parallel programming language that is easy-to-program, since: (i)ICE is a synchronous, lock-step language thus no need for programmer-specified synchronization, (ii)the ICE program for a PRAM algorithm amounts to directly transcribing it, and (iii)the PRAM algorithmic theory offers unique wealth of parallel algorithms and techniques. We propose ICE as a component of an ecosystem, along side (i)the XMT architecture, which was developed at UMD, and can exploit fine-grained parallelism in irregular-programs; and (ii)the PRAM algorithmic model. This ecosystem delivers on the goals of easy-programming and efficient parallelization of irregular-programs. We have built the ICE compiler which translates the ICE language into the multithreaded XMTC language; significant due to that multithreading is a feature shared by practically all current scalable parallel programming languages thus providing a method to compile ICE code. As one indication of ease-of-programming, we observed a reduction in code size in 11 out of 16 benchmarks as compared to hand-optimized XMTC. For these programs, the average reduction in number of program lines is 35.5\%. Our main result is perhaps surprising: The run-time was comparable to XMTC with a 0.45\% average gain for ICE across all benchmarks. IEEE","Ease of programming; fine-grained parallelism; Ice; ICE; Instruction sets; irregular programs; Nested ICE; Nested parallelism; Parallel processing; Parallel programming; Phase change random access memory; PRAM; Synchronization; XMT","Algorithmic languages; Ecology; Ecosystems; Multitasking; Parallel programming; Phase change memory; Program compilers; Random access storage; Synchronization; Fine-grained parallelism; Instruction set; Irregular programs; Nested Parallelism; Parallel processing; Phase change random access memory; PRAM; Ice",2-s2.0-85030624180
"Magalhães N.M., De Souza Campos H., Jr., Araújo M.A.P., De Oliveira Neves V.","An automated refactoring approach to remove unnecessary complexity in source code",2017,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030472654&doi=10.1145%2f3128473.3128476&partnerID=40&md5=e10e5bea7d6a890b4a4776be512ef19b","Programming apprentices may choose to prioritize the correct functioning of a source code without focusing on their quality, making them difficult to maintain and test. Based on that, a phenomenon called unnecessary structural complexity may occur, in which a program has a cyclomatic complexity value that can be reduced without affecting its external behavior. In a previous work, we developed an approach and tool to address this problem. The approach is able to identify the presence of unnecessary cyclomatic complexity and to show the developer a suggestion to restructure the source code, through a control flow graph. The goal of this paper is to automate the source code refactoring process to support the elimination of unnecessary cyclomatic complexity. We performed two experimental studies to evaluate the approach in the academic context. The evidences provided by these studies suggest that the approach is able to support unnecessary cyclomatic complexity removal. We could not find, however, evidences about the implications of such approach on unit tests development. © 2017 Association for Computing Machinery.","Control Flow Graph; Cyclomatic Complexity; Software Quality; Software Testing; Source Code Refactoring","Automation; Codes (symbols); Computer programming languages; Computer software selection and evaluation; Data flow analysis; Flow graphs; Graphic methods; Quality control; Control flow graphs; Cyclomatic complexity; External behavior; Refactorings; Software Quality; Source codes; Structural complexity; Unit tests; Software testing",2-s2.0-85030472654
"Araújo J., Araújo J., Magalhães C., Andrade J., Mota A.","Feasibility of using source code changes on the selection of text-based regression test cases",2017,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030464460&doi=10.1145%2f3128473.3128481&partnerID=40&md5=a75fe0bcb0df99ebf4dabcedbb9ce120","This paper investigates the relationship between recently modified source code and the selection of text-based regression test cases. The main reason is that our industrial partner uses release notes documents to perform such a selection, but these documents are not so well-written as the text-based test cases. Therefore, we intend to extract useful text from source code to see whether they can serve as a source of keywords in the selection process. We present an experiment that shows promising results about this hypothesis. © 2017 Association for Computing Machinery.","Information retrieval; Regression campaign.; Source code; Test case selection","Codes (symbols); Computer programming languages; Information retrieval; Regression analysis; Industrial partners; Regression campaign; Regression tests; Source code changes; Source codes; Test case; Test case selection; Software testing",2-s2.0-85030464460
"Botelho J., Durelli V.H.S., Borges S.S., Endo A.T., Eler M.M., Delamaro M.E., Durelli R.S.","On the costs of applying logic-based criteria to mobile applications: An empirical analysis of predicates in real-world Objective-C and Swift applications",2017,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030455796&doi=10.1145%2f3128473.3128477&partnerID=40&md5=1eb22c6d895d94796176e71e52ed9fd0","The proliferation of mobile devices has given rise to an increasing demand for software that is well-suited to this particular environment. However, ensuring the quality of mobile applications is challenging. Much of the overall complexity of mobile applications stems from logic expressions, i.e., predicates, which appear in control-flow statements (e.g., if, if-else, while, and do-while) and define much of the behavior of software. Thus, testing predicates is key to ensuring the quality of mobile applications. We argue that an apt way to test predicates is by leveraging well-established logic-based criteria. Many logic-based criteria have been devised, e.g., the active clause coverage (ACC) and modified condition/decision coverage (MCDC). Given that ACC/MCDC are considered expensive, we set out to examine the cost of applying these criteria to mobile applications. We probed into a basic, but relevant, proxy for cost: The complexity of predicates, i.e., number of clauses in predicates. We examined 35 open-source mobile applications implemented in Objective-C and Swift ranging from 129 to 58,140 lines of code with a total of 19,345 predicates. We looked at the frequency and percentage of predicates. We also analyzed the relationship between overall measures of size and the frequency of predicates. We found that, although about 99% of the predicates in mobile application have at most three clauses, there is a significant positive linear correlation between overall measures of size and the number of predicates with four or more clauses. We conclude that mobile applications do not have many multi-clause predicates and hence sophisticated logic-based criteria are needed on only a small portion of the predicates. © 2017 Association for Computing Machinery.","Active clause coverage (ACC) criteria; Logic-based test criteria; Modified condition-decision coverage; Replication study","Application programs; Computer circuits; Cost benefit analysis; Costs; Mobile computing; Mobile devices; Mobile telecommunication systems; Open source software; Open systems; Software testing; Active clause coverage (ACC) criteria; Empirical analysis; Linear correlation; Mobile applications; Modified condition decision coverage; Modified condition/decision coverages; Replication study; Test criteria; C (programming language)",2-s2.0-85030455796
"Ropp P., Friedman A., Durrant J.D.","Scoria: A Python module for manipulating 3D molecular data",2017,"Journal of Cheminformatics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029578213&doi=10.1186%2fs13321-017-0237-8&partnerID=40&md5=9f25c2eff6688734e5e6163466e8c895","Third-party packages have transformed the Python programming language into a powerful computational-biology tool. Package installation is easy for experienced users, but novices sometimes struggle with dependencies and compilers. This presents a barrier that can hinder the otherwise broad adoption of new tools. We present Scoria, a Python package for manipulating three-dimensional molecular data. Unlike similar packages, Scoria requires no dependencies, compilation, or system-wide installation. One can incorporate the Scoria source code directly into their own programs. But Scoria is not designed to compete with other similar packages. Rather, it complements them. Our package leverages others (e.g. NumPy, SciPy), if present, to speed and extend its own functionality. To show its utility, we use Scoria to analyze a molecular dynamics trajectory. Our FootPrint script colors the atoms of one chain by the frequency of their contacts with a second chain. We are hopeful that Scoria will be a useful tool for the computational-biology community. A copy is available for download free of charge (Apache License 2.0) at http://durrantlab.com/scoria/.[Figure not available: see fulltext.] © 2017 The Author(s).","Computational biology; Molecular modeling; Python; Structural biology",,2-s2.0-85029578213
"Hellman R.B., Tekin C., Schaar M.V.D., Santos V.J.","Functional Contour-following via Haptic Perception and Reinforcement Learning",2017,"IEEE Transactions on Haptics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030765827&doi=10.1109%2fTOH.2017.2753233&partnerID=40&md5=0c4ea3b510414bc0193f5605d7dc3061","Many tasks involve the fine manipulation of objects despite limited visual feedback. In such scenarios, tactile and proprioceptive feedback can be leveraged for task completion. We present an approach for real-time haptic perception and decision-making for a haptics-driven, functional contour-following task: the closure of a ziplock bag. This task is challenging for robots because the bag is deformable, transparent, and visually occluded by artificial fingertip sensors that are also compliant. A deep neural net classifier was trained to estimate the state of a zipper within a robot&#x0027;s pinch grasp. A Contextual Multi-Armed Bandit (C-MAB) reinforcement learning algorithm was implemented to maximize cumulative rewards by balancing exploration versus exploitation of the state-action space. The C-MAB learner outperformed a benchmark Q-learner by more efficiently exploring the state-action space while learning a hard-to-code task. The learned C-MAB policy was tested with novel ziplock bag scenarios and contours (wire, rope). Importantly, this work contributes to the development of reinforcement learning approaches that account for limited resources such as hardware life and researcher time. As robots are used to perform complex, physically interactive tasks in unstructured or unmodeled environments, it becomes important to develop methods that enable efficient and effective learning with physical testbeds. IEEE","Active touch; contour-following; decision making; Haptic interfaces; haptic perception; Learning (artificial intelligence); manipulation; Manipulators; Planning; Real-time systems; reinforcement learning; Robot sensing systems","C (programming language); Decision making; Deep learning; Deep neural networks; Feedback; Haptic interfaces; Intelligent robots; Interactive computer systems; Learning algorithms; Manipulators; Planning; Real time systems; Robot programming; Robots; Sensory perception; Visual communication; Visual servoing; Active touch; Contour following; Haptic perception; Learning (artificial intelligence); manipulation; Robot sensing system; Reinforcement learning",2-s2.0-85030765827
"Huang Y., Liu Z., Chen X., Luo X.","Automatic Matching Release Notes and Source Code by Generating Summary for Software Change",2017,"Proceedings - 2016 International Conference on Digital Home, ICDH 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032356483&doi=10.1109%2fICDH.2016.031&partnerID=40&md5=3ac70424c76720196f3396f44fc98a10","To quickly locate the source code that maps to a specific change described in change history, establishing traceability links between release notes and source code is a necessary task. Current works on the traceability link recovery can be used to find out source code changes which are of higher textual similarities with the release note. However, these approaches rely on consistency of the text used in artifacts at various abstraction levels, and the completeness of text descriptions. In this paper, we propose to leverage source code change information for improving the accuracy of release note to source code traceability recovery tasks. In order to reduce the complexity of link recovery, our approach first performs change impact analysis to cluster the source code changes for the same purpose as a virtual class. After that, our approach employs a natural language generation algorithm to generate readable summary sentence for each virtual class. The traceability links are built between release notes and clusters of program entities by computing the linguistic similarity of sentences. We conduct case studies on 26 releases of 3 popular softwares to evaluate the approach, and the results indicate that our proposed method can improve the accuracy of traceability link recovery compared to other IR-based techniques. © 2016 IEEE.","Summary Generation; Syntactic and Semantic Similarity; Traceability Link Recovery","Codes (symbols); Digital devices; Natural language processing systems; Recovery; Semantics; Change impact analysis; Linguistic similarities; Natural language generation; Semantic similarity; Source code changes; Summary generation; Textual similarities; Traceability links; Computer programming languages",2-s2.0-85032356483
"Bai S., Zhang J., Chen Z., Wang Y., Hong M., Karaki T.","Near-room-temperature synthesis of niobate hydrate particles with hexagonal-platelike morphologies",2017,"Materials Chemistry and Physics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026907644&doi=10.1016%2fj.matchemphys.2017.06.048&partnerID=40&md5=6f5f376a5a8f17457ebb8181ee518911","Platelike alkaline niobates, which are an important class of templates for growing lead-free textured piezoceramic materials, are usually synthesized at temperatures greater than 900 °C from a melting process. We previously developed a hydrothermal route to niobate hydrate at temperatures above 100 °C and combined it with heat treatment to yield platelike niobate perovskite. In this contribution, we present the first report on near-room-temperature wet-chemical preparation of platelike potassium niobate (KN) and potassium sodium niobate (KNN) hydrate particles. Hexagonal-platelike KN-hydrate particles that were 1.5–4.0 μm wide and 0.1–0.35 μm thick were prepared via low temperature synthesis at 60 °C over a period of 24 h in a 9 mol/L KOH solution. Similarly, KNN hydrate particles with a hexagonal-platelike shape were prepared at 40 °C over a period of 48 h in 6 mol/L [OH−]. Sodium dodecyl benzene sulfonate (SDBS) surfactant was added as a shape modulator. Calcining the KN hydrate particles at 500 °C for 2 h transformed the crystals to a stable perovskite phase while maintaining the platelike morphology. The low-temperature wet-chemical route to alkaline niobates is expected to lead to a low-cost scalable method for the mass production of platelike template particles in the field of high-performance lead-free piezoceramics. © 2017 Elsevier B.V.","Lead-free piezoelectrics; Niobate; Platelike; Wet-chemical synthesis","Alkalinity; Hydrates; Hydration; Low temperature effects; Low temperature production; Niobium compounds; Perovskite; Piezoelectric ceramics; Potassium; Scalability; Single crystals; Sodium; Temperature; Lead-free piezoelectrics; Low temperature synthesis; Niobates; Platelike; Potassium sodium niobate; Sodium dodecylbenzene sulfonate; Wet chemical preparation; Wet chemical synthesis; C (programming language)",2-s2.0-85026907644
"Corcione M., Grignaffini S., Quintino A., Ricci E., Vallati A.","Buoyancy-Induced Convection of Alumina-Water Nanofluids in Laterally Heated Vertical Slender Cavities",2017,"Heat Transfer Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029586565&doi=10.1080%2f01457632.2017.1363609&partnerID=40&md5=998bc38a6df13a278add26a6363cce5e","A two-phase model based on the double-diffusive approach is used to perform a numerical study of natural convection of alumina-water nanofluids in differentially heated vertical slender cavities. In the mathematical formulation, Brownian diffusion and thermophoresis are assumed to be the only slip mechanisms by which the solid phase can develop a significant relative velocity with respect to the liquid phase. The system of the governing equations of continuity, momentum and energy for the nanofluid, and continuity for the nanoparticles is solved through a computational code relying on the SIMPLE-C algorithm for the pressure-velocity coupling. The effective thermal conductivity and dynamic viscosity of the nanofluid, and the coefficient of thermophoretic diffusion of the suspended solid phase, are evaluated using three empirical correlations based on a high number of experimental data available from diverse sources, and validated by way of literature data different from those used in generating them. Numerical simulations are executed for different height-to-width aspect ratios of the enclosure, as well as different average temperatures of the nanofluid. The heat transfer performance of the nanoparticle suspension relative to that of the base fluid is found to increase as the nanofluid average temperature is increased and, at low to moderate temperatures, the aspect ratio of the enclosure is decreased. Moreover, at temperatures higher than room temperature, a peak at an optimal particle loading is found to exist for any investigated configuration. © 2017 Taylor & Francis Group, LLC",,"Alumina; Aspect ratio; C (programming language); Enclosures; Heat transfer; Nanoparticles; Natural convection; Thermal conductivity; Effective thermal conductivity; Empirical correlations; Heat transfer performance; Mathematical formulation; Moderate temperature; Nanoparticle suspension; Optimal particle loadings; Pressure-velocity coupling; Nanofluidics",2-s2.0-85029586565
"Mohanraj V., Ponnuswamy S.","Design, synthesis, characterisation, conformation and biological investigation of N-acyl r-2,c-6-bis (4-methoxyphenyl)-c-3,t-3-dimethylpiperidin-4-ones",2017,"Journal of Molecular Structure",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019850802&doi=10.1016%2fj.molstruc.2017.05.036&partnerID=40&md5=263a1000aa4570fdef2df476b17ae053","In a wide research programme towards the study of piperidin-4-ones with efficient pharmacological effect, a new series of N-acyl r-2,c-6-bis(4-methoxyphenyl)-c-3,t-3-dimethylpiperidin-4-ones 2–5 are synthesized and characterized by IR spectra, 1H, 13C, DEPT - 135 and 2D (COSY and HSQC) NMR and mass spectra. The parent compound 1 prefers to exist in a chair conformation whereas the extracted coupling constant, chemical shifts and estimated dihedral angles show that the N-acyl piperdine-4-ones 2–5 prefer to exist in a distorted boat conformation B1 (with C2 and C5 in prow and stern positions) with coplanar orientation of N[sbnd]C[dbnd]O moiety. The existence of a fast N[sbnd]CO rotational equilibrium between the boat conformations B (I) and B (II) has also been observed. Anti bacterial activity of the above test compounds 1–5 is determined against pseudomonas sp. and salmonella sp. The antioxidant activities are determined by the ABTS, DPPH and superoxide assays. Furthermore, molecular docking studies have been carried out for the compounds 1–5 with target protein CHK1. © 2017 Elsevier B.V.","Antibacterial activity; Antioxidant activity; Distorted boat conformation; Molecular docking study; N-acylpiperidin-4-ones; NMR spectra","Antioxidants; Boats; Conformations; Dihedral angle; Mass spectrometry; Molecular modeling; Nuclear magnetic resonance spectroscopy; Oxygen; Anti-bacterial activity; Anti-oxidant activities; Boat conformations; Molecular docking; NMR spectrum; C (programming language)",2-s2.0-85019850802
"Dayioglu M., Cetin B., Nam S.","Stabilization of expansive Belle Fourche shale clay with different chemical additives",2017,"Applied Clay Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019769603&doi=10.1016%2fj.clay.2017.05.033&partnerID=40&md5=fb980cd5cf9c42e643125cfc8c7bd878","Improving the engineering properties of expansive soils is very important in northern plains, Texas and mid-west regions of the United States. In this study, expansive Belle Fourche clay (B) from South Dakota, was mixed with the class C fly ash (FC), class F fly ash (FF) and lime. Swelling pressure (SWP) and unconfined compressive strength (UCS) tests were conducted on samples that were cured at different periods (0, 7 and 28 days). Furthermore, freeze and thaw (F-T) effects on the swelling and strength properties of the clay and selected mixtures were investigated. Results showed that the SWP of the Belle Fourche clay (B) decreased significantly with addition of lime 4% by dry weight of soil from 235 kPa to almost 0 kPa. Mixing fly ashes also reduced the SWP to 47 kPa and 100 kPa with class C and class F fly ashes, respectively. Increase in F-T cycles reduced the SWP, whereas the SWP increased with 2 and 4 F-T cycles for the mixtures with the fly ashes. However, after 4 cycles, the pressure of the same mixtures decreased. On the contrary, to the clay-fly ash mixtures, F-T did not affect the SWP of the clay-lime mixtures. In terms of strength, chemical treatment increased UCS. The overall effectiveness of the treatment under the curing and F-T was in the order of FC, lime, and FF. The UCSs of the clays treated with these additives were 3.58, 1.82, and 1.63 times higher than the non-treated clay. F-T reduced the UCS of the clay and the clay treated with FF. Although the UCS of the FC and lime mixtures increased within 2 cycles of F-T, they did not show the same strength improving performance with more F-T cycles. It was observed that mixtures with higher liquid limit and plasticity index (PI) tended to have higher SWP and lower UCS. This study claimed that chemically stabilized soils with high CaO content, CaO/SiO2, CaO/Al2O3, and CaO/(SiO2 + Al2O3) ratios had higher potential to decrease SWP of expansive soils and increase UCS of weak soils. © 2017 Elsevier B.V.","Expansive clay soil; Fly ash; Freeze-thaw cycles; Lime; Swelling pressure; Unconfined compressive strength","C (programming language); Compressive strength; Curing; Fly ash; Lime; Mixtures; Soil testing; Soils; Stabilization; Thawing; Chemical treatments; Engineering properties; Expansive clays; Freeze-thaw cycles; Improving performance; Overall effectiveness; Swelling pressures; Unconfined compressive strength; Clay; additive; clay soil; compressive strength; expansive soil; freeze-thaw cycle; lime; plasticity; pressure; soil mechanics; Australia; Midwest; Northern Plains; South Dakota; Texas; United States; Victoria [Australia]",2-s2.0-85019769603
"Wang S.","On extremal cacti with respect to the Szeged index",2017,"Applied Mathematics and Computation",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017503816&doi=10.1016%2fj.amc.2017.03.036&partnerID=40&md5=8eab32e8696e16601bb8ad2571fd5ec9","The Szeged index of a graph G is defined as Sz(G)=∑e=uv∈Enu(e)nv(e), where nu(e) and nv(e) are, respectively, the number of vertices of G lying closer to vertex u than to vertex v and the number of vertices of G lying closer to vertex v than to vertex u. A cactus is a graph in which any two cycles have at most one common vertex. Let C(n,k) denote the class of all cacti with order n and k cycles, and Cn t denote the class of all cacti with order n and t pendant vertices. In this paper, a lower bound of the Szeged index for cacti of order n with k cycles is determined, and all the graphs that achieve the lower bound are identified. As well, the unique graph in Cn t with minimum Szeged index is characterized. © 2017 Elsevier Inc.","Cactus; Pendent vertex; Szeged index","C (programming language); Cactus; Extremal; Graph G; K -cycle; Lower bounds; Pendant vertices; Pendent vertex; Szeged index; Graph theory",2-s2.0-85017503816
"Büscher N., Franz M., Holzer A., Veith H., Katzenbeisser S.","On compiling Boolean circuits optimized for secure multi-party computation",2017,"Formal Methods in System Design",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029532991&doi=10.1007%2fs10703-017-0300-0&partnerID=40&md5=23ba8502efcec4f5be21c8538b81877f","Secure multi-party computation (MPC) allows two or more distrusting parties to jointly evaluate a function over private inputs. For a long time considered to be a purely theoretical concept, MPC transitioned into a practical and powerful tool to build privacy-enhancing technologies. However, the practicality of MPC is hindered by the difficulty to implement applications on top of the underlying cryptographic protocols. This is because the manual construction of efficient applications, which need to be represented as Boolean or arithmetic circuits, is a complex, error-prone, and time-consuming task. To facilitate the development of further privacy-enhancing technology, multiple compilers have been proposed that create circuits for MPC. Yet, almost all presented compilers only support domain specific languages or provide very limited optimization methods. In this work (this is an extended and revised version of the paper ‘Secure Two-party Computations in ANSI C’ (Holzer et al., in: ACM CCS, 2012) that reflects the progress in secure computation and describes the current optimization tool chain of CBMC-GC) we describe our compiler CBMC-GC that implements a complete tool chain from ANSI C to circuit. Moreover, we give a comprehensive overview of circuit minimization techniques, which we have identified and adapted for the creation of efficient circuits for MPC. With the help of these techniques, our compilation approach allows for a high level of abstraction from the cryptographic primitives used in MPC protocols, as well as the complex design of digital circuits. By using the model checker CBMC as a compiler frontend, we illustrate the link between MPC, formal methods, and digital logic design. Our experimental results illustrate the effectiveness of the implemented optimizations techniques for various example applications. In particular, compared with other state-of-the-art compilers, we show that CBMC-GC compiles circuits from the same source code that are up to four times smaller. © 2017 Springer Science+Business Media, LLC","Compiler; Logic synthesis; Secure multi-party computation","Chains; Computation theory; Computer circuits; Computer programming languages; Cryptography; Data privacy; Formal methods; Graphical user interfaces; Logic circuits; Logic Synthesis; Model checking; Problem oriented languages; Program compilers; Timing circuits; Compiler; Cryptographic primitives; Cryptographic protocols; Domain specific languages; High level of abstraction; Privacy enhancing technologies; Secure multi-party computation; Secure two-party computations; C (programming language)",2-s2.0-85029532991
"Zhang C., Bi J., Zhou Y., Dogar A.B., Wu J.","HyperV: A high performance hypervisor for virtualization of the programmable data plane",2017,"2017 26th International Conference on Computer Communications and Networks, ICCCN 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032259944&doi=10.1109%2fICCCN.2017.8038396&partnerID=40&md5=eca2fa0d717e765a373ce6527eb2fc7e","P4 is a domain specific language designed to define the behavior of a programmable data plane. It facilitates offloading hardware-suitable Network Functions (NFs) to a data plane. Consequently, NFs can maximally benefit from high performance of hardware devices, meanwhile more CPU power can be reserved for user applications. However, since the programmable data plane provides an NF with an exclusive network context, different NFs cannot operate on the same data plane simultaneously. Besides, it is hardly possible to dynamically reconfigure programmable network devices without interrupting the operation of a data plane. Therefore, we propose HyperV, a high performance hypervisor for virtualization of a P4 specific data plane, to provide both non-exclusive and uninterrupted features.We implemented HyperV based on a P4-BMv2 target and a DPDK target respectively. Then we evaluated BMv2-target HyperV by comparing with Hyper4, a recently proposed hypervisor, and evaluated DPDK- target HyperV by comparing with PISCES and Open vSwitch. Results show that BMv2- target HyperV averagely prevails over Hyper4 2.5x in performance while reducing resource usage by 4x. DPDK-target HyperV performs comparably to Open vSwitch and PISCES, with the worst case of a throughput penalty in less than 7%, while providing a powerful capability of virtualization which neither of them provides. © 2017 IEEE.",,"Computer hardware; Computer programming languages; Hardware; Problem oriented languages; Virtual reality; Virtualization; Data planes; Domain specific languages; Hardware devices; Network contexts; Network functions; Open vswitch; Programmable network devices; Resource usage; Computer networks",2-s2.0-85032259944
"Okano K., Harauchi S., Sekizawa T., Ogata S., Nakashima S.","Equivalence checking of Java methods: Toward ensuring IoT dependability",2017,"2017 26th International Conference on Computer Communications and Networks, ICCCN 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032297308&doi=10.1109%2fICCCN.2017.8038505&partnerID=40&md5=ee8900d540acc45ce73b344c6df4a60e","IoT devices are software-rich and Java is sometimes chosen as the developing programming language. Although Java is highly productive in constructing large advanced programs, application or user-defined Java classes must be responsible for safety and security issues. In particular, two fundamental methods hashCode and equals play key roles in safety and security assurance. Some existing studies for ensuring the correctness of these two methods rely on static analysis, which are limited to loop-free programs only. This paper proposes a new solution to this important problem, based on equivalence checking of methods or functions. The proposed approach makes use of software analysis workbench (SAW), an open source tool. The approach is also useful in reducing the cost of regression testing when program refactoring is conducted. © 2017 IEEE.","And equivalence; Hash code; Java; Software verification","Application programs; Computer networks; Computer software; Functions; Hash functions; Internet of things; Open source software; Open systems; Software testing; Static analysis; Verification; And equivalence; Equivalence checking; Hash code; Java; Regression testing; Safety and securities; Software analysis; Software verification; Java programming language",2-s2.0-85032297308
"Fu J., Bernard F., Kamali-Bernard S.","Assessment of the elastic properties of amorphous calcium silicates hydrates (I) and (II) structures by molecular dynamics simulation",2017,"Molecular Simulation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029471351&doi=10.1080%2f08927022.2017.1373191&partnerID=40&md5=45c5cf90829ee33db82aab9f57f5ba4b","Based on Hamid model of 11Å tobermorite, amorphous calcium silicates hydrates (or C-S-H) structures (Ca4Si6O14(OH)4•2H2O as the C-S-H(I) and (CaO)1.67(SiO2)(H2O)1.75 as the C-S-H(II)) with the Ca/Si ratio of 0.67 and 1.7 are concerned. Then, as the representative ‘globule’ C-S-H, two amorphous C-S-H structures with the size of 5.352 × 4.434 × 4.556 nm3 during the stretch process are simulated at a certain strain rate of 10−3 ps−1 by LAMMPS program for molecular dynamics simulation, using ClayFF force field. The tensile stress–strain curves are obtained and analysed. Besides, elastic modulus of the ‘globule’ C-S-H is calculated to assess the elastic modulus of C-S-H phases (the low-density C-S-H – LD C-S-H – and the high-density C-S-H – HD C-S-H), where the porosity is a critical factor for explaining the relationship between ‘globule’ C-S-H at nanoscale and C-S-H phases at microscale. Results show that: (1) The C-S-H(I) structure has transformed from crystalline to amorphous during the annealing process, Young’s moduli in x, y and z directions are almost the same. Besides, the extent of aggregation and aggregation path for water molecules in the structure is different in three directions. (2) Young’s modulus of both amorphous C-S-H(I) and C-S-H(II) structures with a size of about 5 nm under strain rate of 10−3 ps−1 at 300 K in three directions is averaged to be equal, of which C-S-H(II) structure is about 60.95 GPa thus can be seen as the elastic modulus of the ‘globule’ C-S-H. (3) Based on the ‘globule’ C-S-H, the LD C-S-H and HD C-S-H can be assessed by using the Self-Consistent Scheme (separately 18.11 and 31.45 GPa) and using the Mori–Tanaka scheme (29.78 and 37.71 GPa), which are close to the nanoindentation experiments by Constantinides et al. (21.7 and 29.4 GPa). © 2017 Informa UK Limited, trading as Taylor & Francis Group","amorphous C-S-H structure; molecular dynamics; Nanoscale; tensional deformation; Young’s modulus","Calcium; Calcium silicate; Elastic moduli; Hydrates; Hydration; Molecular dynamics; Molecules; Nanotechnology; Silicates; Strain rate; Amorphous calcium silicates; Annealing process; Crystalline-to-amorphous; Elastic properties; Molecular dynamics simulations; Nano scale; Nanoindentation experiments; Self-consistent scheme; C (programming language)",2-s2.0-85029471351
"Upton K.T., Schilling K.A., Beauchamp J.L.","Easily fabricated ion source for characterizing mixtures of organic compounds by direct analysis in real time mass spectrometry",2017,"Analytical Methods",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028691902&doi=10.1039%2fc7ay00971b&partnerID=40&md5=03f8ee29a24d80be5a95e0e2f032b0d7","The increasing use of atmospheric pressure mass spectrometry has led to the development of many ambient ionization sources, for which sampling versatility and low cost are desired features. One such recent ambient ionization method is direct analysis in real time mass spectrometry (DART-MS), which has proven to be well suited to the analysis of native samples of both simple and complex natures. We describe a home-built DART source (EZ-DART) with versatile sampling capabilities, low power requirements, and low assembly cost which can be easily interfaced to mass spectrometers equipped with an atmospheric pressure inlet. The operating temperature range (22-250 °C) enables the acquisition of both temperature programmed desorption-based DART mass spectra and the collection of multistep collision-induced dissociation (CID) mass spectra. We present here the validation of the EZ-DART source and a demonstration of its performance in a number of relevant applications. Additionally, we introduce the new DART application of reagent assisted desorption ionization (RADI) for the targeting of specific chemical functionality in complex organic mixtures through a host-guest chemical system. © 2017 The Royal Society of Chemistry.",,"Atmospheric chemistry; Atmospheric ionization; Atmospheric pressure; C (programming language); Desorption; Ion sources; Ionization; Mass spectrometers; Mass spectrometry; Mixtures; Spectrometry; Temperature programmed desorption; Ambient ionizations; Atmospheric pressure mass spectrometries; Chemical functionality; Collision induced dissociation; Complex organic mixtures; Desorption ionization; Direct analysis in real time; Operating temperature ranges; Chemical analysis",2-s2.0-85028691902
"Covián E., Puente V., Casero M.","Uncertainties estimation in surveying measurands: Application to lengths, perimeters and areas",2017,"Measurement Science and Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029902762&doi=10.1088%2f1361-6501%2faa7b9d&partnerID=40&md5=216f4aed23ba17e2f94ccb68c8e1dd1a","The present paper develops a series of methods for the estimation of uncertainty when measuring certain measurands of interest in surveying practice, such as points elevation given a planimetric position within a triangle mesh, 2D and 3D lengths (including perimeters enclosures), 2D areas (horizontal surfaces) and 3D areas (natural surfaces). The basis for the proposed methodology is the law of propagation of variance-covariance, which, applied to the corresponding model for each measurand, allows calculating the resulting uncertainty from known measurement errors. The methods are tested first in a small example, with a limited number of measurement points, and then in two real-life measurements. In addition, the proposed methods have been incorporated to commercial software used in the field of surveying engineering and focused on the creation of digital terrain models. The aim of this evolution is, firstly, to comply with the guidelines of the BIPM (Bureau International des Poids et Mesures), as the international reference agency in the field of metrology, in relation to the determination and expression of uncertainty; and secondly, to improve the quality of the measurement by indicating the uncertainty associated with a given level of confidence. The conceptual and mathematical developments for the uncertainty estimation in the aforementioned cases were conducted by researchers from the AssIST group at the University of Oviedo, eventually resulting in several different mathematical algorithms implemented in the form of MATLAB code. Based on these prototypes, technicians incorporated the referred functionality to commercial software, developed in C++. As a result of this collaboration, in early 2016 a new version of this commercial software was made available, which will be the first, as far as the authors are aware, that incorporates the possibility of estimating the uncertainty for a given level of confidence when computing the aforementioned surveying measurands. © 2017 IOP Publishing Ltd.","digital terrain model (DTM) software; elevation; perimeters and areas; surveying engineering; uncertainty","C++ (programming language); Computer software; Estimation; Geometry; MATLAB; Software prototyping; Surveying; Surveys; Bureau international des poids et mesures; Digital terrain model; elevation; Expression of uncertainty; Mathematical algorithms; perimeters and areas; uncertainty; Uncertainty estimation; Uncertainty analysis",2-s2.0-85029902762
"Baraka R.S., Breem S.N.A.","Automatic Arabic Text Summarization for Large Scale Multiple Documents Using Genetic Algorithm and MapReduce",2017,"Proceedings - 2017 Palestinian International Conference on Information and Communication Technology, PICICT 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032293366&doi=10.1109%2fPICICT.2017.32&partnerID=40&md5=146aecda08700dc5db08080a4a4dd8ab","Multi document summarization focuses on extracting the most significant information from a collection of textual documents. Most summarization techniques require the data to be centralized, which may not be feasible in many cases due to computational and storage limitations. The huge increase of data emerging by the progress of technology and the various sources makes automatic text summarization of large scale of data a challenging task. We propose an approach for automatic text summarization of large scale Arabic multiple documents using Genetic algorithm and MapReduce parallel programming model. The approach insures scalability, speed and accuracy in summary generation. It eliminates sentence redundancy and increases readability and cohesion factors between the sentences of summaries. The experiments resulted in acceptable precision and recall scores. This indicates that the system successfully identifies the most important sentences. In Addition to all to that, the approach provided up to 10x speedup score, which is faster than on a single machine. Therefore, it can deal with large-scale datasets successfully. Finally, the efficiency score of the proposed approach indicates that the large data set utilizes the available resources up to 62%. © 2017 IEEE.","Hadoop; MapReduce; Parallel Genetic Algorithm; Text Mining; Text Summarization","Data mining; Digital storage; Genetic algorithms; Natural language processing systems; Parallel programming; Hadoop; Map-reduce; Parallel genetic algorithms; Text mining; Text summarization; Text processing",2-s2.0-85032293366
"Yongliang W., Jianping C., Wei W., Bin W.","Optimization research of stiffened shells based on kriging model and explicit FEM",2017,"2017 8th International Conference on Mechanical and Aerospace Engineering, ICMAE 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032369098&doi=10.1109%2fICMAE.2017.8038661&partnerID=40&md5=481bd444d8ba9c59349440af4fc1804c","A novel parametric model of the stiifened shell is developed by Python language with Abaqus in this paper. As an effective analysis method in the optimal design, explicit finite element method (FEM) is used to design and optimize the skin thickness and stiffener size of Stiffened Shells. The optimization objectives and constraints are mainly the minimum mass subject to the structural performance and the high structural performance subject to the mass. In order to avoid the enormous computational cost of complex simulations in design optimization process, a surrogate kriging model is built based on the experimental design. The surrogate model method and the multi-island genetic algorithm are used to achieve a preliminary design based on the approximate model, and the sequential linear programming algorithm is employed to optimize continuous variables. So the computing time of optimization analysis is reduced greatly. The simulation results show that a reasonable and useful design can be realized with the optimization methods. © 2017 IEEE.","explicit FEM; kriging surrogate model; optimization; stiffened shells","Aerospace engineering; Genetic algorithms; Interpolation; Linear programming; Optimization; Shells (structures); Explicit FEM; Explicit finite element method; Kriging surrogate model; Multi island genetic algorithms; Optimization researches; Sequential linear programming; Stiffened shells; Structural performance; Finite element method",2-s2.0-85032369098
"Chong F.T., Franklin D., Martonosi M.","Programming languages and compiler design for realistic quantum hardware",2017,"Nature",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030755671&doi=10.1038%2fnature23459&partnerID=40&md5=e367830f28741b9da381ab290e657b96","Quantum computing sits at an important inflection point. For years, high-level algorithms for quantum computers have shown considerable promise, and recent advances in quantum device fabrication offer hope of utility. A gap still exists, however, between the hardware size and reliability requirements of quantum computing algorithms and the physical machines foreseen within the next ten years. To bridge this gap, quantum computers require appropriate software to translate and optimize applications (toolflows) and abstraction layers. Given the stringent resource constraints in quantum computing, information passed between layers of software and implementations will differ markedly from in classical computing. Quantum toolflows must expose more physical details between layers, so the challenge is to find abstractions that expose key details while hiding enough complexity. © 2017 Macmillan Publishers Limited, part of Springer Nature. All rights reserved.",,"algorithm; experimental design; hardware; linear programing; optimization; quantum mechanics; software; algorithm; computer; computer analysis; computer language; mathematical computing; priority journal; quantum mechanics; Review; software design",2-s2.0-85030755671
"Franceschini L., Ancona D., Komendantskaya E.","Structural resolution for abstract compilation of object-oriented languages",2017,"Electronic Proceedings in Theoretical Computer Science, EPTCS",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030148812&doi=10.4204%2fEPTCS.258.2&partnerID=40&md5=66b50ad70191658ee6c570fb26adcaeb","We propose abstract compilation for precise static type analysis of object-oriented languages based on coinductive logic programming. Source code is translated to a logic program, then type-checking and inference problems amount to queries to be solved with respect to the resulting logic program. We exploit a coinductive semantics to deal with infinite terms and proofs produced by recursive types and methods. Thanks to the recent notion of structural resolution for coinductive logic programming, we are able to infer very precise type information, including a class of irrational recursive types causing non-Termination for previously considered coinductive semantics. We also show how to transform logic programs to make them satisfy the preconditions for the operational semantics of structural resolution, and we prove this step does not affect the semantics of the logic program. © Ancona, Dagnino & Zucca.",,"Computer circuits; Computer programming languages; Logic programming; Semantics; Inference problem; Logic programs; Non terminations; Operational semantics; Recursive types; Source codes; Static type analysis; Type information; Object oriented programming",2-s2.0-85030148812
"Razik L., Mirz M., Knibbe D., Lankes S., Monti A.","Automated deserializer generation from CIM ontologies: CIM++—an easy-to-use and automated adaptable open-source library for object deserialization in C++ from documents based on user-specified UML models following the Common Information Model (CIM) standards for the energy sector",2017,"Computer Science - Research and Development",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029428410&doi=10.1007%2fs00450-017-0350-y&partnerID=40&md5=4af0e9ef135ee30eec28b74ff0688081","The increasing complexity of ICT systems in smart grids requires that all actors improve their interoperability. To this aim, IEC 61970/61968 specify the Common Information Model (CIM) which describes terms in the energy sector and relations between them. One of the key features of CIM is its object-oriented design based on the Unified Modeling Language (UML). This makes CIM easy to maintain and extensible by visual UML editors leading to a continuous standardization process keeping up with new developments. But this means that CIM based software must be kept up-to-date as well. Therefore, this paper presents our Model-Driven Architecture (MDA) based approach with which CIM, as specified by a visual UML editor, can be mapped to a compilable C(Formula presented.) codebase. Moreover, it shows how this codebase can be used for an automated generation of a C(Formula presented.) objects deserializer from CIM based documents following the UML specification. All presented approaches are implemented in an open-source project called CIM(Formula presented.) and evaluated on a real-world use case. © 2017 Springer-Verlag GmbH Germany","CIM; Deserialization; Energy; MDA; Ontology; Smart grids","Automation; Electric power transmission networks; Information theory; Interoperability; Modeling languages; Object oriented programming; Ontology; Open source software; Smart power grids; Software architecture; Software design; Systems analysis; Unified Modeling Language; Common information model; Deserialization; Energy; Model driven architectures; Object oriented design; Open-source libraries; Smart grid; Standardization process; C++ (programming language)",2-s2.0-85029428410
"Sowpati D.T., Srivastava S., Dhawan J., Mishra R.K.","C-State: An interactive web app for simultaneous multi-gene visualization and comparative epigenetic pattern search",2017,"BMC Bioinformatics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029432056&doi=10.1186%2fs12859-017-1786-6&partnerID=40&md5=205d6d26b3ef7b7f98df754baad199cb","Background: Comparative epigenomic analysis across multiple genes presents a bottleneck for bench biologists working with NGS data. Despite the development of standardized peak analysis algorithms, the identification of novel epigenetic patterns and their visualization across gene subsets remains a challenge. Results: We developed a fast and interactive web app, C-State (Chromatin-State), to query and plot chromatin landscapes across multiple loci and cell types. C-State has an interactive, JavaScript-based graphical user interface and runs locally in modern web browsers that are pre-installed on all computers, thus eliminating the need for cumbersome data transfer, pre-processing and prior programming knowledge. Conclusions: C-State is unique in its ability to extract and analyze multi-gene epigenetic information. It allows for powerful GUI-based pattern searching and visualization. We include a case study to demonstrate its potential for identifying user-defined epigenetic trends in context of gene expression profiles. © 2017 The Author(s).","ChIP-seq; Chromatin state; Epigenetic patterns; Genome browser; JavaScript; RNA-seq; Visualization; Web app","Chromosomes; Computer programming; Data transfer; Flow visualization; Gene expression; Genes; Graphical user interfaces; High level languages; Interface states; User interfaces; Visualization; Web browsers; ChIP-seq; Chromatin state; Epigenetic patterns; Genome browsers; Javascript; Web App; C (programming language)",2-s2.0-85029432056
"Guerra R., Martel E., Khan J., Lopez S., Athanas P., Sarmiento R.","On the Evaluation of Different High-Performance Computing Platforms for Hyperspectral Imaging: An OpenCL-Based Approach",2017,"IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030217520&doi=10.1109%2fJSTARS.2017.2737958&partnerID=40&md5=fb64671d4489728b2878dcb3210ed672","Hyperspectral imaging systems are a powerful tool for obtaining surface information in many different spectral channels that can be used in many different applications. Nevertheless, the huge amount of information provided by hyperspectral images also has a downside, since it has to be processed and analyzed. For such purpose, parallel hardware devices, such as field-programmable gate arrays (FPGAs) and graphic processing units (GPUs), are typically used, especially for hyperspectral imaging applications under real-time constraints. However, developing hardware applications typically requires expertise in the specific targeted device, as well as in the tools and methodologies that can be used to perform the implementation of the desired algorithms in that device. In this scenario, the Open Computing Language (OpenCL) emerges as a very interesting solution in which a single high-level language can be used to efficiently develop applications in multiple and different hardware devices. In this work, the parallel Fast Algorithm for Linearly Unmixing Hyperspectral Images (pFUN) has been implemented in two different NVIDIA GPUs, the GeForce GTX 980 and the Tesla K40c, using OpenCL. The obtained results are compared with the results provided by the previously developed NVIDIA CUDA implementation of the pFUN algorithm for the same GPU devices for comparing the efficiency of OpenCL against a more specific synthesis design language for the targeted hardware devices, such as CUDA is for NVIDIA GPUs. Moreover, the FUN algorithm has also been implemented into a Bitware Stratix V Altera FPGA, using OpenCL, for comparing the results that can be obtained using OpenCL when targeting different devices and architectures. The obtained results demonstrate the suitability of the followed methodology in the sense that it allows the achievement of efficient FPGA and GPU implementations able to cope with the stringent requirements imposed by hyperspectral imaging systems. IEEE","&#x00A0;high-performance&#x00A0;&#x00A0;&#x2009;computing; CUDA; field-programmable gate array (FPGA); graphic&#x00A0;&#x00A0;processing&#x00A0;&#x00A0;unit&#x00A0;&#x00A0;(GPU); hyperspectral imaging; hyperspectral unmixing; open computing language (openCL); parallel programing","Computer graphics equipment; Computer hardware; Computer programming languages; Field programmable gate arrays (FPGA); Graphics processing unit; Hardware; High level languages; Image processing; Imaging systems; Logic gates; Program processors; Signal receivers; Spectroscopy; Amount of information; CUDA; Graphic processing units (GPUs); High performance computing; Hyperspectral unmixing; open computing language (openCL); parallel programing; Real time constraints; Hyperspectral imaging",2-s2.0-85030217520
"Neufeld B.H., Neufeld M.J., Lutzke A., Schweickart S.M., Reynolds M.M.","Metal–Organic Framework Material Inhibits Biofilm Formation of Pseudomonas aeruginosa",2017,"Advanced Functional Materials",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025445119&doi=10.1002%2fadfm.201702255&partnerID=40&md5=3c7a4510cec87e81cc2a7e0281836c2e","An 85% reduction in the bacterial attachment of Pseudomonas aeruginosa is achieved using a water-stable metal–organic framework (MOF) blended with chitosan. These materials demonstrate this reduction in bacterial adhesion in the first 6 h and maintain it over the full 24 h exposure period, a remarkable impediment of biofilm formation to achieve, given the strength of this bacteria strain. The films elicit the same inhibitory effect after a second round of experiments, suggesting reusability of the materials. Characterization of the films by powder X-ray diffraction, attenuated total reflectance-IR, and scanning electron microscopy supports retention of the MOF structure within the chitosan matrix. The extensive control experiments employed in this study isolate the observed biological effects to the synthesized films, and not to possible leachates from the films. This presents the first account of using a water-stable MOF within a polymer as a means to achieve an antibacterial surface by demonstrating an 85% reduction in bacterial attachment of Pseudomonas aeruginosa. © 2017 WILEY-VCH Verlag GmbH & Co. KGaA, Weinheim","antibacterial surfaces; bacteria attachment; biofilm formation; biomedical applications; metal–organic frameworks","Bacteria; Biofilms; Characterization; Chitin; Chitosan; Crystalline materials; Java programming language; Medical applications; Reusability; Scanning electron microscopy; X ray diffraction; Antibacterial surfaces; Bacteria attachments; Biofilm formation; Biomedical applications; Metal organic framework; Films",2-s2.0-85025445119
"Liu P., Wu X., Ge Z., Li S., Wu H., Wen L., Wang W., Zhang H.","Progress on China nuclear data processing code system",2017,"EPJ Web of Conferences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030468972&doi=10.1051%2fepjconf%2f201714602004&partnerID=40&md5=260487a90077ac027eba9cb7f00ee4ee","China is developing the nuclear data processing code Ruler, which can be used for producing multi-group cross sections and related quantities from evaluated nuclear data in the ENDF format [1]. The Ruler includes modules for reconstructing cross sections in all energy range, generating Doppler-broadened cross sections for given temperature, producing effective self-shielded cross sections in unresolved energy range, calculating scattering cross sections in thermal energy range, generating group cross sections and matrices, preparing WIMS-D format data files for the reactor physics code WIMS-D [2]. Programming language of the Ruler is Fortran-90. The Ruler is tested for 32-bit computers with Windows-XP and Linux operating systems. The verification of Ruler has been performed by comparison with calculation results obtained by the NJOY99 [3] processing code. The validation of Ruler has been performed by using WIMSD5B code. © The Authors, published by EDP Sciences, 2017.",,,2-s2.0-85030468972
[No author name available],"Electronic Proceedings in Theoretical Computer Science, EPTCS",2017,"Electronic Proceedings in Theoretical Computer Science, EPTCS",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030175909&partnerID=40&md5=5b4b99aa1b629586cdf9f2afbc510241","The proceedings contain 4 papers. The topics discussed include: extending coinductive logic programming with co-facts; structural resolution for abstract compilation of object-oriented languages; trace and stable failures semantics for CSP-Agda; structural resolution with co-inductive loop detection; an executable specification of typing rules for extensible records based on row polymorphism; abstract compilation for type analysis of object-oriented languages; refinement types and higher-order constrained horn clauses; and category theoretic semantics for logic programming: laxness and saturation.",,,2-s2.0-85030175909
"Ganguly D., Jones G.J.F., Ramírez-de-la-Cruz A., Ramírez-de-la-Rosa G., Villatoro-Tello E.","Retrieving and classifying instances of source code plagiarism",2017,"Information Retrieval Journal",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029455072&doi=10.1007%2fs10791-017-9313-y&partnerID=40&md5=22c02abb596c3155cfb28c1cc6585437","Automatic detection of source code plagiarism is an important research field for both the commercial software industry and within the research community. Existing methods of plagiarism detection primarily involve exhaustive pairwise document comparison, which does not scale well for large software collections. To achieve scalability, we approach the problem from an information retrieval (IR) perspective. We retrieve a ranked list of candidate documents in response to a pseudo-query representation constructed from each source code document in the collection. The challenge in source code document retrieval is that the standard bag-of-words (BoW) representation model for such documents is likely to result in many false positives being retrieved, because of the use of identical programming language specific constructs and keywords. To address this problem, we make use of an abstract syntax tree (AST) representation of the source code documents. While the IR approach is efficient, it is essentially unsupervised in nature. To further improve its effectiveness, we apply a supervised classifier (pre-trained with features extracted from sample plagiarized source code pairs) on the top ranked retrieved documents. We report experiments on the SOCO-2014 dataset comprising 12K Java source files with almost 1M lines of code. Our experiments confirm that the AST based approach produces significantly better retrieval effectiveness than a standard BoW representation, i.e., the AST based approach is able to identify a higher number of plagiarized source code documents at top ranks in response to a query source code document. The supervised classifier, trained on features extracted from sample plagiarized source code pairs, is shown to effectively filter and thus further improve the ranked list of retrieved candidate plagiarized documents. © 2017 Springer Science+Business Media, LLC","Document representation; Field based indexing and retrieval; Lexical, Structural and stylistic features; Source code plagiarism detection",,2-s2.0-85029455072
"Peccerillo B., Bartolini S.","Phast library - Enabling single-source and high performance code for GPUs and multi-cores",2017,"Proceedings - 2017 International Conference on High Performance Computing and Simulation, HPCS 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032361825&doi=10.1109%2fHPCS.2017.109&partnerID=40&md5=261bba981949752bc92a36c6a53f2211","The simulation of parallel heterogeneous architectures such as multi-cores and GPUs sets new challenges in the programming language/framework domain. Applications for simulators need to be expressed in a way that can be easily adapted for the specific architectures, effectively tuned for on each of them while preventing from introducing biases due to non-uniform hand-made optimizations. The most common heterogeneous programming frameworks are too low-level, so we propose PHAST, a high-level heterogeneous C++ library targetable on multi-cores and Nvidia GPUs. It permits to write code at a high level of abstraction, to reach good performance while allowing for fine parameter tuning and not shielding code from low-level optimizations. We evaluate PHAST in the case of DCT8x8 on both supported architectures. On multi-cores, we found that PHAST implementation is around ten times faster than OpenCL (AMD vendor) implementation, but up to about 4x slower than OpenCL (Intel vendor) one, which effectively leverages auto-vectorization. On Nvidia GPUs, PHAST code performs up to 55.14% better than CUDA SDK reference version. © 2017 IEEE.",,"C++ (programming language); Codes (symbols); Computer simulation languages; Program processors; C++ libraries; Heterogeneous architectures; Heterogeneous programming; High level of abstraction; High performance codes; Parameter-tuning; Single source; Vectorization; Multicore programming",2-s2.0-85032361825
"Kocina F., Kunovsky J.","Advanced VLSI circuits simulation",2017,"Proceedings - 2017 International Conference on High Performance Computing and Simulation, HPCS 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032382530&doi=10.1109%2fHPCS.2017.84&partnerID=40&md5=5479a3f831e5b1813e7d955bafd87199","The paper deals with very accurate and effective simulation of Complementary Metal-Oxide-Semiconductor (CMOS) transistors which are used to construct basic logic gates (inverter, NAND and NOR) and their composites (XOR, AND, OR). The transistors are substituted by a resistor-capacitor (RC) circuit and the circuit is described by a system of differential algebraic equations (DAEs). These equations are numerically solved by the variable-step, variable-order Modern Taylor Series Method (MTSM). The same approach can be used for VLSI simulation - it was implemented by the corresponding author in a general purpose programming language. This approach is faster than the state of the art (SPICE) and uses less memory. © 2017 IEEE.",,"CMOS integrated circuits; Computation theory; Computer simulation languages; Differential equations; Metals; MOS devices; Oxide semiconductors; Timing circuits; Transistors; VLSI circuits; Basic logic gates; Complementary metal oxide semiconductors; Differential algebraic equations; General-purpose programming language; Resistor capacitors; State of the art; Taylor series methods; Variable order; Circuit simulation",2-s2.0-85032382530
"Sandobalin J., Insfran E., Abrahao S.","An Infrastructure Modelling Tool for Cloud Provisioning",2017,"Proceedings - 2017 IEEE 14th International Conference on Services Computing, SCC 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032348388&doi=10.1109%2fSCC.2017.52&partnerID=40&md5=67a463cb30e032838b476d9df520294a","Cloud computing offers computing, network, and storage capabilities through services that abstract the capabilities of the underlying hardware. Currently, a variety of tools exist that manage the infrastructure provisioning and use scripts to define the final state of the hardware to be deployed in the cloud. However, there are major challenges that need to be addressed to automate the infrastructure management so that they are effectively used in initiatives such as DevOps. In particular, the management of Infrastructure as a Code (IaC) is one of the most important technical challenges to support activities such as the integration, deployment, and continuous delivery of applications. To address this problem, we present a support for the management of DevOps tools, through the definition of a Domain Specific Language (DSL) based on the concept of Infrastructure as a Code, and a tool that supports this language allowing to model the final state of a provisioning infrastructure in the cloud and generating the provisioning scripts for the Amazon Web Services (AWS) platform. The proposed tool reduces the work for development and operations personnel and facilitates their communication. © 2017 IEEE.","Cloud Services; DevOps; Infrastructure as Code; Infrastructure Provisioning; Model Driven Development","Codes (symbols); Computer programming languages; Hardware; Problem oriented languages; Web services; Cloud services; DevOps; Infrastructure as Code; Infrastructure Provisioning; Model driven development; Distributed computer systems",2-s2.0-85032348388
"Stoica L., Ghandi R., Chen C.-P., Solomko V.","A 200°C general purpose rail-To-rail complementary input class-AB operational amplifier for high temperature applications",2017,"ISSCS 2017 - International Symposium on Signals, Circuits and Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032280842&doi=10.1109%2fISSCS.2017.8034901&partnerID=40&md5=6246a9da0fca8c9c1d78ec2d6c6d53b3","This paper covers the design and testing of an operational amplifier (opamp) used in a high temperature signal conditioning unit for integration with temperature and strain gauge sensors. The opamp was designed and fabricated in a 1 μm CMOS Silicon-on-Insulator (SOI) process and has been characterized up to 300°C. The measurement results at 200°C are showing a DC open-loop gain of 100dB, an offset voltage of 1mV, an input bias current of ±15pA, a common mode input range (CMIR) of [0-5]V and a unity gain frequency of 3.2MHz. The opamp has a size of 687μm × 218μm and draws a current of 550μA from a 5V supply. The opamp was used to design an instrumentation amplifier (IA) with a gain of 225 at 200°C. © 2017 IEEE.",,"Amplifiers (electronic); C (programming language); High temperature applications; Integration testing; Power amplifiers; Silicon on insulator technology; Strain gages; Conditioning units; High temperature; Input-bias current; Instrumentation amplifier; Operational amplifier (opamp); Silicon-on-insulator process; Strain gauge sensors; Unity-gain frequencies; Operational amplifiers",2-s2.0-85032280842
"Shin W.-G., Testa M., Kim H.S., Jeong J.H., Lee S.B., Kim Y.-J., Min C.H.","Independent dose verification system with Monte Carlo simulations using TOPAS for passive scattering proton therapy at the National Cancer Center in Korea",2017,"Physics in Medicine and Biology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029909960&doi=10.1088%2f1361-6560%2faa8663&partnerID=40&md5=ee642e68aa640ef29704c1032a788b38","For the independent validation of treatment plans, we developed a fully automated Monte Carlo (MC)-based patient dose calculation system with the tool for particle simulation (TOPAS) and proton therapy machine installed at the National Cancer Center in Korea to enable routine and automatic dose recalculation for each patient. The proton beam nozzle was modeled with TOPAS to simulate the therapeutic beam, and MC commissioning was performed by comparing percent depth dose with the measurement. The beam set-up based on the prescribed beam range and modulation width was automated by modifying the vendor-specific method. The CT phantom was modeled based on the DICOM CT files with TOPAS-built-in function, and an in-house-developed C++ code directly imports the CT files for positioning the CT phantom, RT-plan file for simulating the treatment plan, and RT-structure file for applying the Hounsfield unit (HU) assignment, respectively. The developed system was validated by comparing the dose distributions with those calculated by the treatment planning system (TPS) for a lung phantom and two patient cases of abdomen and internal mammary node. The results of the beam commissioning were in good agreement of up to 0.8 mm2 for B8 option in both of the beam range and the modulation width of the spread-out Bragg peaks. The beam set-up technique can predict the range and modulation width with an accuracy of 0.06% and 0.51%, respectively, with respect to the prescribed range and modulation in arbitrary points of B5 option (128.3, 132.0, and 141.2 mm2 of range). The dose distributions showed higher than 99% passing rate for the 3D gamma index (3 mm distance to agreement and 3% dose difference) between the MC simulations and the clinical TPS in the target volume. However, in the normal tissues, less favorable agreements were obtained for the radiation treatment planning with the lung phantom and internal mammary node cases. The discrepancies might come from the limitations of the clinical TPS, which is the inaccurate dose calculation algorithm for the scattering effect, in the range compensator and inhomogeneous material. Moreover, the steep slope of the compensator, conversion of the HU values to the human phantom, and the dose calculation algorithm for the HU assignment also could be reasons of the discrepancies. The current study could be used for the independent dose validation of treatment plans including high inhomogeneities, the steep compensator, and riskiness such as lung, head &amp; neck cases. According to the treatment policy, the dose discrepancies predicted with MC could be used for the acceptance decision of the original treatment plan. © 2017 Institute of Physics and Engineering in Medicine.","determination of nozzle parameters; independent dose verification system; Monte Carlo simulation; national cancer center in Korea; passive scattering proton therapy; Proton therapy; TOPAS","Biological organs; C++ (programming language); Computer software; Diseases; Intelligent systems; Modulation; Nozzles; Patient treatment; Proton beams; Radiotherapy; Dose verification; National cancer centers; Nozzle parameters; Proton therapy; TOPAS; Monte Carlo methods",2-s2.0-85029909960
"Ye S., Ren X., Tang Y., Xu L., Li H., Li C., Lin Y.","A hybrid parallel algorithm for solving eeuler equation using explicit rkdg method based on openfoam",2017,"Proceedings - 2017 International Conference on High Performance Computing and Simulation, HPCS 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032371408&doi=10.1109%2fHPCS.2017.99&partnerID=40&md5=635aa64ddb1a16674fea7d2593325e66","OpenFOAM is a framework of the open source C CFD toolbox for flexible engineering simulation, which uses finite volume method (FVM) in the discretization of partial differential equations (PDEs). The problem solving procedure in OpenFOAM consists in equations dicretization stage, equations solving stage and field limiting stage. The best parallelism is limited by the equation solving stage, which contains communications. Compared to FVM, discontinuous Galerkin (DG) method is a high-order discretization method, which can accelerate the convergence of the residuals over same mesh scale and has higher resolution of the flow. Based on OpenFOAM with DG method, the ratio of overhead in equations discretization stage increases, especially when solving Euler equations using an explicit method. The equations discretization stage has a better potential parallelism than the other two stages due to no existence of communication. In this paper, we will analysis the difference of time cost in these three stages between original OpenFOAM and OpenFOAM with DG method. By decoupling these three stages, a hybrid parallel algorithm for solving PDEs is proposed and implemented based on OpenFOAM with DG method. The experimental results show that the simulation time is reduced by 16%, and the relative speedup of the hybrid parallel algorithm is up to 2.88 compared to the original parallel algorithm with the same degree of parallelism. © 2017 IEEE.","CFD; DG; Hybrid parallel algorithm; Open-FOAM","C (programming language); Computational fluid dynamics; Discrete event simulation; Finite volume method; Parallel algorithms; Problem solving; Algorithm for solving; Degree of parallelism; Discontinuous Galerkin methods; Discretization method; Engineering simulation; Equations solving; Partial Differential Equations (PDEs); Problem-solving procedures; Galerkin methods",2-s2.0-85032371408
"Xu J., Wang Y., Chen P., Wang P.","Lightweight and Adaptive Service API Performance Monitoring in Highly Dynamic Cloud Environment",2017,"Proceedings - 2017 IEEE 14th International Conference on Services Computing, SCC 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032368809&doi=10.1109%2fSCC.2017.80&partnerID=40&md5=f09d88182444cf4906ed06684410517a","Cloud platforms and services usually provide an APIlayer as decoupled, language agnostic interface for both front-endclient integration and back-end data and/or function access. Theavailability and performance of the APIs have significant impact onthe quality of end user or client experiences due to its nature ofinteraction endpoints. However, the extreme dynamics, complexityand scale of the current cloud platforms challenge the applicabilityof the existing performance monitoring and anomaly detection approachesfrom timeliness, accuracy, and scalability perspectives. Thispaper presents a novel approach to API performance monitoring,which recognizes performance problems by response time deviationfrom a baseline response time / throughput model that are createdand continuously updated through online learning. In the postdetectionphase, an MIC (Maximal Information Criteria) basedcorrelation algorithm is used to group alerts into a higher leveland more informative hyper-Alerts for end user notification. Weprototyped our solution for a large-scale commercial cloud platform,evaluated it using three months' API performance metrics data,and compared with a couple of existing representative algorithmsand tools. The results show our approach is able to detect APIperformance anomalies with a high F1-score. Compared to existingGranger based approach, our approach has achieved nearly onetime increase in F1-score. Moreover, the alert reduction ratio of ourapproach outperforms several state-of-The-Art approaches. © 2017 IEEE.","Alert reduction; Anomaly detection; API; Service","Computer programming; Computer science; Alert reduction; Anomaly detection; Maximal information; Performance metrics; Performance monitoring; Performance problems; Service; State-of-the-art approach; Application programming interfaces (API)",2-s2.0-85032368809
"Kuckuk S., Haase G., Vasco D.A., Köstler H.","Towards generating efficient flow solvers with the ExaStencils approach",2017,"Concurrency Computation ",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019904940&doi=10.1002%2fcpe.4062&partnerID=40&md5=0bd099555b5956c78a6b4baa7f2099eb","ExaStencils aims at providing intuitive interfaces for the specification of numerical problems and resulting solvers, particularly those from the class of (geometric) multigrid methods. It envisions a multi-layered domain-specific language and a sophisticated code generation framework ultimately emitting source code in a chosen target language. We present our recent advances in fully generating solvers applied to 3D fluid mechanics for nonisothermal/non-Newtonian flows. In detail, a system of time-dependent, nonlinear partial differential equations is discretized on a cubic, nonuniform, and staggered grid using finite volumes. We examine the contained problem of coupled Navier-Stokes and temperature equations, which are linearized and solved using the SIMPLE algorithm and geometric multigrid solvers, as well as the incorporation of non-Newtonian properties. Furthermore, we provide details on necessary extensions to our domain-specific language and code generation framework, in particular, those concerning the handling of boundary conditions, support for nonequidistant staggered grids, and supplying specialized functions to express operations reoccurring in the scope of finite volume discretizations. Many of these enhancements are generalizable and thus suitable for utilization in similar projects. Lastly, we demonstrate the applicability of our code generation approach by providing convincing performance results for fully generated and automatically parallelized solvers. Copyright © 2017 John Wiley & Sons, Ltd.","code generation; computational fluid dynamics; domain-specific languages; high-performance computing; multigrid methods","Boundary conditions; Codes (symbols); Computational fluid dynamics; Computer programming languages; Finite volume method; Fluid mechanics; Graphical user interfaces; Non Newtonian flow; Nonlinear equations; Numerical methods; Partial differential equations; Problem oriented languages; Code Generation; Domain specific languages; Finite volume discretizations; High performance computing; Intuitive interfaces; Multigrid methods; Non-Newtonian property; Nonlinear partial differential equations; Navier Stokes equations",2-s2.0-85019904940
"Takafuji D., Nakano K., Ito Y., Bordim J.","C2CU: a CUDA C program generator for bulk execution of a sequential algorithm",2017,"Concurrency Computation ",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007028405&doi=10.1002%2fcpe.4022&partnerID=40&md5=7ba89b56541a283d579f70a5b5046e0e","Several important tasks, including matrix computation, signal processing, sorting, dynamic programming, encryption, and decryption, can be performed by oblivious sequential algorithms. A sequential algorithm is oblivious if an address accessed at each time does not depend on the input data. A bulk execution of a sequential algorithm is to execute it for many independent inputs in turn or in parallel. A number of works have been devoted to design and implement parallel algorithms for a single input. However, none of these works evaluated the bulk execution performance of these algorithms. The first contribution of this paper is to present a time-optimal implementation for bulk execution of an oblivious sequential algorithm. Our second contribution is to develop a tool, named C2CU, which automatically generates a CUDA C program for a bulk execution of an oblivious sequential algorithm. The C2CU has been used to generate CUDA C programs for the bulk execution of the bitonic sorting, Floyd-Warshall, and Montgomery modulo multiplication algorithms. Compared to a sequential implementation on a single CPU, the generated CUDA C programs for the above algorithms run, respectively, 199, 54, and 78 times faster. Copyright © 2016 John Wiley & Sons, Ltd.","bulk execution; CUDA; GPGPU; oblivious algorithms","Cryptography; Dynamic programming; Matrix algebra; Program processors; Sequential switching; Signal processing; Sorting; Bulk execution; CUDA; Design and implements; Execution performance; GPGPU; Multiplication algorithms; Oblivious algorithms; Sequential implementation; C (programming language)",2-s2.0-85007028405
"Kunecki P., Panek R., Wdowin M., Franus W.","Synthesis of faujasite (FAU) and tschernichite (LTA) type zeolites as a potential direction of the development of lime Class C fly ash",2017,"International Journal of Mineral Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025458171&doi=10.1016%2fj.minpro.2017.07.007&partnerID=40&md5=fcadad4f731c854c81001766ab210db8","The study presents an evaluation of the possibility of using Class C fly ash for the synthesis of faujasite (Type X) and tschernichite (Type A) type zeolite materials. In order to obtain the well-formed zeolites, syntheses were carried out. The variables were: the ratio of NaOH to fly ash, water, the filtrate (post-reaction solutions obtained during the hydrothermal synthesis of zeolites rich in Si), and the amount of added aluminium foil. The analysis showed that three of the most effective reactions (from which Samples 21–23 were derived) occurred under the following conditions: the ratio of NaOH/fly ash was 1.6, 2.0 and 1.25, respectively, with a fusion temperature of 550 °C (for each of the three reactions), fusion time of 1 h and reaction time of 4 h (for each of the three reactions); the amount of H2O was 100, 100 and 50 ml; the amount of filtrate was 0, 0 and 50 ml; the amount of added aluminium foil was 0.5 g (for each of the three reactions); and the reaction temperature was 80 °C (for each of the three reactions). The three best zeolite materials (Samples 21–23) that were derived were subjected to mineralogical (X-ray powder diffraction [XRD], scanning electron microscopy-energy-dispersive X-ray spectroscopy [SEM-EDS]) and chemical (X-ray fluorescence [XRF]) characterization, with the addition of textural analysis (Brunauer-Emmett-Teller [BET] specific surface area and pore volume and size). Studies have shown that the obtained zeolites have a Type A (Samples 21–22) and Type X (Sample 23) structure, including well-formed grains with isometric and cubic characteristics. The calculated unit cell parameters of the obtained zeolites indicate a cubic crystal system and are very close to the reference values for structures of X and A type zeolites. The ratio of SiO2/Al2O3 in each of the three tested zeolite materials was as follows: 2.16, 1.98 and 2.41. The specific surface area amounted to 106, 104 and 256 m2/g for Samples 21–23, respectively. Obtained results were similar to the type of zeolite structures obtained from Class F fly ash. Therefore, we can conclude that the analysed Class C fly ash may also be a productive substrate for the synthesis of zeolite materials of Type X and A. © 2017 Elsevier B.V.","Fly ash Class C; Fusion; Hydrothermal synthesis; Lignite coal; Zeolite A; Zeolite X","Aluminum; Aluminum foil; C (programming language); Characterization; Chemical analysis; Coal ash; Energy dispersive spectroscopy; Filtration; Fly ash; Fusion reactions; Scanning electron microscopy; Specific surface area; X ray powder diffraction; X ray spectroscopy; Zeolites; Brunauer emmett tellers; Cubic crystal system; Energy dispersive X ray spectroscopy; Lignite coal; Reaction temperature; Unit cell parameters; Zeolite X; Zeolite-A; Hydrothermal synthesis",2-s2.0-85025458171
"Archipoff S., Janin D.","Unified media programming: An algebraic approach",2017,"FARM 2017 - Proceedings of the 5th ACM SIGPLAN International Workshop on Functional Art, Music, Modeling, and Design, co-located with ICFP 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031010431&doi=10.1145%2f3122938.3122943&partnerID=40&md5=35383b510f7b896ea2363ed4052783d8","In this paper, we aim at defining a simple and sound mathematical framework for describing temporal media programming language semantics. It occurs that semigroup theory offers various concepts that are especially well suited for this purpose. As a result, a fairly general programming scheme can be defined in order to specify, compose and render both spatial media objects (e.g. 3D drawings) and timed media objects (e.g. Animation or Music). Each of these constructs is specified in Haskell via an adequate type class definition and an associated uniform data type construct. A simple monoid based semantics model of the turtle command language of Logo is detailed and extended throughout the paper. This allows for providing step by step introductions and usage examples of the algebraic concepts and constructs our proposal is based on. © 2017 Association for Computing Machinery.","3D programming; Model based programming language; Temporal animation",,2-s2.0-85031010431
"Tan G., Morrisett G.","Bidirectional Grammars for Machine-Code Decoding and Encoding",2017,"Journal of Automated Reasoning",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028970859&doi=10.1007%2fs10817-017-9429-1&partnerID=40&md5=912e07833c79c4af689cb4ed64b84410","Binary analysis, which analyzes machine code, requires a decoder for converting bits into abstract syntax of machine instructions. Binary rewriting requires an encoder for converting instructions to bits. We propose a domain-specific language that enables the specification of both decoding and encoding in a single bidirectional grammar. With dependent types, a bigrammar enables the extraction of an executable decoder and encoder as well as a correctness proof showing their consistency. The bigrammar DSL is embedded in Coq with machine-checked proofs. We have used the bigrammar DSL to specify the decoding and encoding of subsets of the x86-32 and MIPS instruction sets. We have also extracted an executable decoder and encoder from the x86 bigrammar with competitive performance. © 2017 Springer Science+Business Media B.V.","Certified programs; Domain-specific languages; Grammars; Parsing","Bins; Computer programming languages; Decoding; Digital subscriber lines; Encoding (symbols); Graphical user interfaces; Problem oriented languages; Syntactics; Theorem proving; Competitive performance; Correctness proofs; Dependent types; Domain specific languages; Grammars; Machine instructions; Machine-checked proofs; Parsing; Signal encoding",2-s2.0-85028970859
"Young H.","A categorial grammar for music and its use in automatic melody generation",2017,"FARM 2017 - Proceedings of the 5th ACM SIGPLAN International Workshop on Functional Art, Music, Modeling, and Design, co-located with ICFP 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031010864&doi=10.1145%2f3122938.3122939&partnerID=40&md5=b7ec43d9092bbb858af728154581614b","Like natural language, music can be described as being composed of various parts, which combine together to form a set-theoretic or logical entity. The conceptualized parts are more basic than the music seen on a page; they are the musical objects subject to music-theoretic analysis, and can be described using the language of functional programming and lambda calculus. This paper introduces the types of musical objects seen in tonal and modern music, as well as the combinators that allow them to combine to create other musical objects. We propose a method for automatically generating melodies by searching for combinations of musical objects which together produce a valid program corresponding to a melody or set of melodies. © 2017 Association for Computing Machinery.","Automated music; Categorial grammar; Music generation","Calculations; Differentiation (calculus); Functional programming; Automated music; Categorial grammar; Combinators; Lambda calculus; Melody generation; Music generation; Natural languages; Theoretic analysis; Computer music",2-s2.0-85031010864
"Perez I.","GALE: A functional graphic adventure library and engine",2017,"FARM 2017 - Proceedings of the 5th ACM SIGPLAN International Workshop on Functional Art, Music, Modeling, and Design, co-located with ICFP 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031026282&doi=10.1145%2f3122938.3122944&partnerID=40&md5=4676c38a496e46c6cf6ff08751506442","Functional Programming promises highly-declarative code, efficient, parallelisable execution, modularity and reusability. In spite of these advantages, the use of pure Functional Languages in commercial games is still rare. This is, in part, due to the lack of backends for multimedia, production tools, and demonstrations that functional abstractions work well for other than non-trivial examples. In this paper we present GALE, a Graphic Adventure Library and Engine implemented in Haskell. Our engine implements the basic common features available in similar commercial engines for graphic adventures. We show a high-level abstract definition of game descriptions that allows us not only to run them, but also to analyse them in compile time. We also demonstrate how this description allows us to provide features not available in traditional engines. Our system works on iOS, Android and desktop, and is accompanied by a development environment to compose the games with no prior programming skills. © 2017 Association for Computing Machinery.","Functional programming; Game programming; Graphic adventure; Haskell; Static analysis",,2-s2.0-85031026282
"Orlarey Y., Letz S., Fober D., Michon R.","FAUST tutorial for functional programmers",2017,"FARM 2017 - Proceedings of the 5th ACM SIGPLAN International Workshop on Functional Art, Music, Modeling, and Design, co-located with ICFP 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030990173&doi=10.1145%2f3122938.3122941&partnerID=40&md5=2a49390102eacfa9a11f0d2b48d19443","This paper is an introduction to FAUST, a functional programming language for sound synthesis and audio processing. We assume that the reader has some familiarity with functional programming, but no previous knowledge in signal processing. The text describes several examples that the reader will be able to try online using a web browser. These examples are preceded by two more technical sections presenting some aspects of the language. © 2017 Association for Computing Machinery.","Faust; Signal processing",,2-s2.0-85030990173
"Lukács D., Tóth M.","Structuring Erlang BEAM control flow",2017,"Erlang 2017 - Proceedings of the 16th ACM SIGPLAN International Workshop on Erlang, co-located with ICFP 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031012966&doi=10.1145%2f3123569.3123572&partnerID=40&md5=9942a70c7cf4e5c9a5c9b969f5f145f3","As source code dependencies are usually stored in some precompiled executable representation like bytecode, static analysis frameworks for high-level languages have to be specifically adapted so they can meaningfully analyse these libraries too. This adaptation is not trivial, since compilation is in general not injective, the semantics of low-level instruction sets are often not specified adequately, and the structure of the high-level sources and the low-level target is considerably different. This is also true for the functional Erlang programming language and its assembly-like BEAM bytecode. In this paper, we present a structuring algorithm capable of recovering the Erlang syntax tree of functional branching expressions compiled to BEAM. The implementation of the presented algorithm is part of the RefactorErl static analyser framework. Therefore, the tool is able to represent the semantics of the BEAM programs with an Erlang syntax tree and perform further semantic analysis on it to discover the source dependencies. © 2017 Association for Computing Machinery.","BEAM; Decompilation; Static analysis","Computer programming languages; Functional programming; Semantics; Static analysis; Syntactics; Trees (mathematics); Analysis frameworks; BEAM; Decompilation; Erlang programming language; Instruction set; Low-level targets; Semantic analysis; Source dependency; High level languages",2-s2.0-85031012966
"Palesandro A., Lacoste M., Bennani N., Ghedira-Guegan C., Bourge D.","Mantus: Putting Aspects to Work for Flexible Multi-Cloud Deployment",2017,"IEEE International Conference on Cloud Computing, CLOUD",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032183104&doi=10.1109%2fCLOUD.2017.88&partnerID=40&md5=eaa47817ace7340fdce8027389613ff9","Cloud provider barriers still stand. After a decade of cloud computing, customers struggle to overcome the challenge of crossing multi-provider clouds to benefit from fine-grained resource distribution, business independence from CSPs and cost savings. Although increasingly popular, most adopted IaaS intercloud solutions are generally limited to specific public cloud providers or present maintainability issues. Remaining hurdles include complexity of management and operations of such infrastructures, in presence of per-customer customizations and provider configurations. The Infrastructure as Code (IaC) paradigm is emerging as key enabler for IaaS multi-clouds, to develop and manage infrastructure configurations. However, due to complexity of the infrastructure life-cycle, to heterogeneity of composing resources and to user-customizations, this approach is far from being viable. In this paper, we explore an aspect-oriented approach to IaC deployment and management. We propose Mantus, a IaC-based multi-cloud builder composed of an aspect-oriented Domain-Specific Language called TML, or TOSCA Manipulation Language, and a corresponding aspect weaver to inject flexibly non-functional services in TOSCA infrastructure templates. We show the practical feasibility of our approach, with also good results in terms of performance and scalability. © 2017 IEEE.","aspect-oriented programming; infrastructure-as-code; multi-cloud; TOSCA; weaving","Aspect oriented programming; Cloud computing; Computer programming languages; Life cycle; Problem oriented languages; Weaving; Aspect-oriented; Cloud providers; infrastructure-as-code; Multi-clouds; Performance and scalabilities; Resource distribution; TOSCA; User customizations; Infrastructure as a service (IaaS)",2-s2.0-85032183104
"Cassar I., Francalanza A., Aceto L., Ingólfsdóttir A.","EAOP: An aspect oriented programming framework for Erlang",2017,"Erlang 2017 - Proceedings of the 16th ACM SIGPLAN International Workshop on Erlang, co-located with ICFP 2017",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030098892&doi=10.1145%2f3123569.3123570&partnerID=40&md5=e2b9c421aab48fbbab5f88578cee1e8d","Aspect oriented programming (AOP) is a paradigm ideal for defining cross-cutting concerns within an existing application. Although several AOP frameworks exist for more renowned languages such as Java and C#, little to no frameworks have been developed for actor oriented languages such as Erlang. We thus present eAOP, a new AOP framework specifically designed to instrument actororiented constructs in Erlang such as message sends and receives, along with other traditional constructs such as function calls. © 2017 Association for Computing Machinery.","Actor Systems; Aspect Oriented Programming; Code instrumentation; Concurrency; Erlang","Actor systems; Aspect-Oriented Programming (AOP); Code instrumentation; Concurrency; Cross-cutting concerns; Erlang; Function calls; Aspect oriented programming",2-s2.0-85030098892
"Zhao S., Zhang X., Sun S., Wang X.","Research on control law accelerator of digital signal process chip TMS320F28035 for real-time data acquisition and processing",2017,"Journal of Physics: Conference Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030625449&doi=10.1088%2f1742-6596%2f887%2f1%2f012092&partnerID=40&md5=65a2f04831225de909367dbf6093d907","TI C2000 series digital signal process (DSP) chip has been widely used in electrical engineering, measurement and control, communications and other professional fields, DSP TMS320F28035 is one of the most representative of a kind. When using the DSP program, need data acquisition and data processing, and if the use of common mode C or assembly language programming, the program sequence, analogue-to-digital (AD) converter cannot be real-time acquisition, often missing a lot of data. The control low accelerator (CLA) processor can run in parallel with the main central processing unit (CPU), and the frequency is consistent with the main CPU, and has the function of floating point operations. Therefore, the CLA coprocessor is used in the program, and the CLA kernel is responsible for data processing. The main CPU is responsible for the AD conversion. The advantage of this method is to reduce the time of data processing and realize the real-time performance of data acquisition. © Published under licence by IOP Publishing Ltd.",,"Analog to digital conversion; Artificial intelligence; C (programming language); Data acquisition; Digital arithmetic; Digital signal processing; Information systems; Program processors; Signal processing; Analogue to digitals; Assembly language programming; Floating point operations; Measurement and control; Professional fields; Real time acquisition; Real time performance; Real-time data acquisition and processing; Data handling",2-s2.0-85030625449
"Lan Z., Yuan H.","Development of CBR system for embedded purpose",2017,"2017 2nd International Conference on Reliability Systems Engineering, ICRSE 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032288478&doi=10.1109%2fICRSE.2017.8030785&partnerID=40&md5=877d28f39899e31d31d163aeaf0a4f5c","As the complexity of the launching vehicle increases, using fault diagnosis method to improve reliability becomes more and more important. CBR (case-based reasoning) method is frequently used in prognostic and health management systems. The launching vehicle system has many subsystems. In order to apply CBR method to these various subsystems, a CBR system based on Java and MySQL database is designed in this paper. The principle and process of modular structure is discussed, and case base database based on MySQL is designed. The system is developed in the Java language according to three layer model. It can be used for embedded application. Two data sets from UCI database are used to test module function. Test result shows validation of the system. © 2017 IEEE.","case-based reasoning; fault diagnosis; Java; MySQL database","Database systems; Failure analysis; Fault detection; Java programming language; Reliability; Systems engineering; CBR (case based reasoning); Embedded application; Fault diagnosis method; Java; Launching vehicles; MySQL database; Prognostic and health management; Three-layer models; Case based reasoning",2-s2.0-85032288478
"Lee H., Fox G.C.","Efficient Software Defined Systems Using Common Core Components",2017,"IEEE International Conference on Cloud Computing, CLOUD",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032230689&doi=10.1109%2fCLOUD.2017.59&partnerID=40&md5=e78699f1d3ab3d8b1bb067a0fbf581d0","With advent of Docker containers, an application deployment using container images gains popularity over scientific communities and major cloud providers to ease building reproducible environments. While a single base image can be imported multiple times from different containers to reduce storage consumption by a sharing technique, copy-on-write, duplicates of package dependencies are often observed over containers. In this paper, we propose new approaches to the container image management for eliminating duplicated dependencies. We create Common Core Components (3C) to share package dependencies by version control system commands, submodules and merge. 3C with submodules provides a collection of required libraries and tools in a separate branch, while keeping their base image same. 3C with merge offers a new base image including domain specific components thereby reducing duplicates in similar base images. Container images built with 3C enable efficient and compact software defined systems and disclose security information for tracking Common Vulnerability and Exposure (CVE). As a result, building application environments with 3C-enabled container images consumes less storage compared to existing Docker images. Dependency information for vulnerability is provided in detail for further developments. © 2017 IEEE.","Common Core Components; Containers; Dependencies; DevOps; Software Defined Systems","Cloud computing; Containers; Application deployment; Building applications; Core components; Dependencies; Dependency informations; DevOps; Scientific community; Version control system; C (programming language)",2-s2.0-85032230689
"Zhang W.","Efficient detection of dangling pointer error for C/C++ programs",2017,"Journal of Physics: Conference Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030650289&doi=10.1088%2f1742-6596%2f887%2f1%2f012053&partnerID=40&md5=b2960295ca58ddc9c77a0626808dddf2","Dangling pointer error is pervasive in C/C++ programs and it is very hard to detect. This paper introduces an efficient detector to detect dangling pointer error in C/C++ programs. By selectively leave some memory accesses unmonitored, our method could reduce the memory monitoring overhead and thus achieves better performance over previous methods. Experiments show that our method could achieve an average speed up of 9% over previous compiler instrumentation based method and more than 50% over previous page protection based method. © Published under licence by IOP Publishing Ltd.",,"Artificial intelligence; Errors; Information systems; Average speed; C/C++ programs; Dangling pointers; Efficient detection; Memory access; C (programming language)",2-s2.0-85030650289
"Hu B., Kim W.-G., Sulmonetti T.P., Sarazen M.L., Tan S., So J., Liu Y., Dixit R.S., Nair S., Jones C.W.","A Mesoporous Cobalt Aluminate Spinel Catalyst for Nonoxidative Propane Dehydrogenation",2017,"ChemCatChem",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029000846&doi=10.1002%2fcctc.201700647&partnerID=40&md5=6c98e33c61ef20ea28758da0eabdd65d","A mesoporous CoAl2O4 spinel (Co-Al) is synthesized by a one-step evaporation-induced self-assembly (EISA) method. N2 physisorption and TEM are used to demonstrate the presence of mesopores within the Co-Al material. The spinel crystal structure of Co-Al, in which Co occupies tetrahedral (Td) sites, is confirmed by using XRD and UV/Vis spectroscopy. In nonoxidative propane dehydrogenation at 550 °C, a propane conversion of approximately 8 % is observed for Co-Al with a &gt;80 % propylene selectivity, which corresponds to a turnover frequency of 5.1 h−1 based on an estimation of the number of active Co sites by using NH3 temperature-programmed desorption. A much higher propane conversion rate and a circa 80 % propylene selectivity is observed upon reaction at 600 °C. Continuous deactivation of the catalyst is observed for Co-Al at this elevated temperature. In situ X-ray absorption spectroscopy results suggest that Co remains as a Td Co2+ species under the reaction conditions. The Td Co2+ sites within the Co-Al material are thus proposed to act as Lewis acidic active sites; this acidity is verified using IR spectroscopy with pyridine as a probe molecule. © 2017 Wiley-VCH Verlag GmbH & Co. KGaA, Weinheim","cobalt; dehydrogenation; mesoporous materials; self-assembly; spinel phases","Aluminum; C (programming language); Catalysts; Crystal structure; Dehydrogenation; Frequency estimation; Mesoporous materials; Propane; Propylene; Self assembly; Temperature programmed desorption; Ultraviolet visible spectroscopy; X ray absorption spectroscopy; Elevated temperature; Evaporation induced self assemblies; In-situ X-ray absorption spectroscopy; Propane dehydrogenation; Propylene selectivity; Reaction conditions; Spinel phasis; UV/ Vis spectroscopy; Cobalt",2-s2.0-85029000846
"Tyuryumina E.Y., Neznanov A.A.","On Consolidated Predictive Model of the Natural History of Breast Cancer Considering Primary Tumor and Primary Distant Metastases Growth",2017,"Proceedings - 2017 IEEE International Conference on Healthcare Informatics, ICHI 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032372731&doi=10.1109%2fICHI.2017.14&partnerID=40&md5=8aabf8b2dc8e289eee0662b0eea4cb72","We propose a new mathematical growth model of primary tumor and primary metastases which may help to improve predicting accuracy of breast cancer process using an original mathematical model referred to CoM-IV and corresponding software. The CoM-IV model and predictive software: a) detect different growth periods of primary tumor and primary metastases; b) make forecast of patient survival; c) have higher average prediction accuracy than the other tools; d) can improve forecasts on survival of BC and facilitate optimisation of diagnostic tests. The CoM-IV enables us, for the first time, to predict the whole natural history of primary tumor and primary metastases growth on each stage (pT1, pT2, pT3, pT4) relying only on primary tumor sizes. Summarising: CoM-IV a) describes correctly primary tumor and primary distant metastases growth of IV (T1-4N0-3M1) stage with (N1-3) or without regional metastases in lymph nodes (N0); b) facilitates the understanding of the appearance period and manifestation of primary metastases. © 2017 IEEE.","Breast cancer; Exponential growth model; Mathematical model; Primary metastases; Primary tumor; Survival","C (programming language); Cobalt compounds; Diagnosis; Diseases; Forecasting; Health care; Mathematical models; Software testing; Tumors; Breast Cancer; Distant metastasis; Exponential growth; Patient survivals; Prediction accuracy; Predictive modeling; Primary metastases; Survival; Pathology",2-s2.0-85032372731
"Chen L., Peng B., Zhang B., Liu T., Zou Y., Jiang L., Henschel R., Stewart C., Zhang Z., McCallum E., Tom Z., Jon O., Qiu J.","Benchmarking Harp-DAAL: High Performance Hadoop on KNL Clusters",2017,"IEEE International Conference on Cloud Computing, CLOUD",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032200797&doi=10.1109%2fCLOUD.2017.19&partnerID=40&md5=a6f90e8bb14cb69579972bc5940f825d","Data analytics is undergoing a revolution in many scientific domains, and demands cost-effective parallel data analysis techniques. Traditional Java-based Big Data processing tools like Hadoop MapReduce are designed for commodity CPUs. In contrast, emerging manycore processors like the Xeon Phi have an order of magnitude greater computation power and memory bandwidth. To harness their computing capabilities, we propose the Harp-DAAL framework. We show that enhanced versions of MapReduce can be replaced by Harp, a Hadoop plug-in, that offers useful data abstractions for both high-performance iterative computation and MPI-quality communication, as well as drive Intel's native DAAL library. We select a subset of three machine learning algorithms and implement them within Harp-DAAL. Our scalability benchmarks ran on Knights Landing (KNL) clusters and achieved up to 2.5 times speedup of performance over the HPC solution in NOMAD and 15 to 40 times speedup over Java-based solutions in Spark. We further quantify the workloads on single node KNL with a performance breakdown at the micro-architecture level. © 2017 IEEE.","BigData; HPC; Xeon Phi","Big data; Cloud computing; Computer architecture; Cost effectiveness; Data handling; Digital storage; Iterative methods; Java programming language; Learning algorithms; Learning systems; Program processors; Storage allocation (computer); Computation power; Computing capability; Data abstraction; Iterative computation; Many-core processors; Memory bandwidths; Micro architectures; Xeon Phi; Benchmarking",2-s2.0-85032200797
"Harrison J.R.","Towards an Isabelle/HOL formalisation of core Erlang",2017,"Erlang 2017 - Proceedings of the 16th ACM SIGPLAN International Workshop on Erlang, co-located with ICFP 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031032198&doi=10.1145%2f3123569.3123576&partnerID=40&md5=8d3b055d3900cccf83c9d61db54c9463","As part of broader work to improve the safety of Erlang systems, we are attempting to detect (and prevent) messages which remain forever unreceived in process' mailboxes using a mix of static and runtime analysis. We have formalised the communicating portion of Core Erlang using Isabelle/HOL, an interactive theorem prover. We can use the Isabelle toolchain to prove properties of our model, automatically prepare documents, and generate verified executable code in a variety of functional programming languages. We formally model a communicating fragment of Core Erlang in a language we call CoErl. After defining the evaluation of expressions, we model the process-local and concurrent semantics of the language using a labelled transition system. We also introduce the notion of mailbox traces which capture communication events during process execution. This is followed by some illustrative examples of the concurrent semantics. Although our CoErl model is a solid foundation for a full formalisation of Core Erlang, it currently lacks higher-order and recursive behaviour. Isabelle/HOL has proved practical for formalising and verifying several properties of CoErl and its trace system, while ongoing and future work focuses on bringing the language to feature parity with Core Erlang and Erlang/OTP. © 2017 Association for Computing Machinery.","Asynchronous communication; Core Erlang; Erlang; Isabelle; Labelled transition systems; Pproof assistant","Computer aided analysis; Semantics; Theorem proving; Asynchronous communication; Core Erlang; Erlang; Isabelle; Labelled transition systems; Pproof assistant; Functional programming",2-s2.0-85031032198
"Li Y., Muthiah M., Routh A., Dorai C.","Cognitive Computing in Action to Enhance Invoice Processing with Customized Language Translation",2017,"Proceedings - 2017 IEEE 1st International Conference on Cognitive Computing, ICCC 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032268637&doi=10.1109%2fIEEE.ICCC.2017.25&partnerID=40&md5=58a54a66f80ba9d434d4269dc57e7128","This paper describes our recent effort to develop a cognitive application to transform invoice processing in P2P (Procure to Pay) process in Finance operations. The context of this problem is with service providers who offer invoice processing services to their global clients. Due to the language barrier, the service provider usually maintain both offshore and near-shore teams, where the offshore team handles the main workload and is usually located in English-speaking countries, while the near-shore team helps in resolving language dependent issues which the offshore team is unable to handle. To reduce the dependency on near-shore resources and improve the efficiency of the offshore team, we have developed a web-based translation application which can provide secure and domain-specific language translation service between multiple languages in scope. The application also contain modules for language trainers to rate translations and provide feedback, which is used to train the language models in an incremental fashion. The translation service can also be integrated into the overall ERP (Enterprise Resource Planning) workflow to facilitate process automation. This solution has been deployed in production in an IBM delivery center and is currently used by the offshore team on a daily basis. Our three-month application usage tracking shows that we can achieve up to 85% translation accuracy at sentence-level between English and French/Spanish, and the offshore team is able to handle 40% more workload. © 2017 IEEE.","ERP workflow; Finance; Invoice processing; Language translation; Procure to Pay","Coastal engineering; Computer programming languages; Enterprise resource planning; Finance; Peer to peer networks; Problem oriented languages; Cognitive Computing; Domain specific languages; Language translation; Multiple languages; Process automation; Procure to Pay; Translation services; Web-based translation; Translation (languages)",2-s2.0-85032268637
"Ledur C., Griebler D., Manssour I., Fernandes L.G.","A High-Level DSL for Geospatial Visualizations with Multi-core Parallelism Support",2017,"Proceedings - International Computer Software and Applications Conference",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031930755&doi=10.1109%2fCOMPSAC.2017.18&partnerID=40&md5=373f4992513c3b067cf40d58e25f1017","The amount of data generated worldwide associated with geolocalization has exponentially increased over the last decade due to social networks, population demographics, and the popularization of Global Positioning Systems. Several methods for geovisualization have already been developed, but many of them are focused on a specific application or require learning a variety of tools and programming languages. It becomes even more difficult when users have to manage a large amount of data because state-of-the-art alternatives require the use of third-party pre-processing tools. We present a novel Domain-Specific Language (DSL), which focuses on large data geovisualizations. Through a compiler, we support automatic visualization generations and data pre-processing. The system takes advantage of multi-core parallelism to speed-up data pre-processing abstractly. Our experiments were designated to highlight the programming effort and performance of our DSL. The results have shown a considerable programming effort reduction and efficient parallelism support with respect to the sequential version. © 2017 IEEE.","Big Data; Domain-Specific Language; Geospatial Visualizations; GMaVis; Multi-Core Systems; Parallel Processing; SPar; Stream Parallelism","Application programs; Big data; Computer hardware description languages; Computer programming languages; Computer software; Data handling; Data visualization; Digital subscriber lines; Parallel processing systems; Population statistics; Problem oriented languages; Visualization; Domain specific languages; Geospatial visualization; GMaVis; Multi-core systems; Parallel processing; SPar; Stream Parallelism; Multicore programming",2-s2.0-85031930755
"Yu D., Wang J., Wu Q., Yang J., Wang J., Yang W., Yan W.","Detecting Java Code Clones with Multi-granularities Based on Bytecode",2017,"Proceedings - International Computer Software and Applications Conference",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031925638&doi=10.1109%2fCOMPSAC.2017.104&partnerID=40&md5=92c86822c5bebbb42f32679dbd7530bb","Sequences of duplicate code, either with or without modification, are known as code clones or just clones. Code clones are generally considered undesirable for a number of reasons, although they can offer some convenience to developers. The detection of code clones helps to improve the quality of source code through software re-engineering. Numerous methods have been proposed for code clone detection in Java code. However, the existing methods are mostly based on the Java source code, while only a few focus on its bytecode, in fact, the Java bytecode reflects more of the semantic nature of the source code than the source code itself does. In this paper, we propose a novel code clone detection method based on Java bytecode. Using the block-level code fragments extracted from bytecode, it can simultaneously detect code clones at both method level and block level. In addition, during the process of code clone detection, the similarities of both method call sequences and instruction sequences are calculated in order to improve accuracy. We conduct two extensive experiments to evaluate the performance of our method. The results show that the proposed method can detect code clones more effectively than the state-of-the-art methods. © 2017 IEEE.","Code clone detection; instruction; Java bytecode; method call; multi-granularities","Application programs; Cloning; Computer programming languages; Computer software; Java programming language; Semantics; Code clone detection; instruction; Java byte codes; method call; Multi-granularity; Codes (symbols)",2-s2.0-85031925638
"Santos F., Nunes I., Bazzan A.L.C.","Supporting the Development of Agent-Based Simulations: A DSL for Environment Modeling",2017,"Proceedings - International Computer Software and Applications Conference",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031915897&doi=10.1109%2fCOMPSAC.2017.224&partnerID=40&md5=930a4a13a3aa22d756363375e952182e","Domain-specific languages are a means of speeding up and easing software system development. Agent-based simulations are simulation systems in which autonomous entities, namely agents, are developed in order to reproduce, analyze, or predict a phenomenon under study. Despite its potential, available alternatives for agent-based modeling and simulation benefit from recurrent domain-related concepts, such as domain concerns and standard strategies for creating and initializing entities, in a limited way. Such elements, when represented in models, can potentially ease the modeling and simulation. We propose a domain-specific modeling language that provides ready-to-use concepts for these recurrent agent-based simulation elements with a modularized notation.The language is targeted to the agent-based modeling and simulation domain and is currently focused on modeling the simulated environment. A user study provides evidence that our language decreases the time needed to understand agent-based simulations. © 2017 IEEE.","Agent-based Modeling and Simulation; Domain-specific Language; Environment; User Study","Application programs; Computational methods; Computer aided software engineering; Computer programming languages; Computer simulation languages; Computer software; Digital subscriber lines; Graphical user interfaces; Modeling languages; Problem oriented languages; Software agents; Specification languages; Systems analysis; Agent based simulation; Agent-based modeling and simulation; Domain specific languages; Domain specific modeling languages; Environment; Model and simulation; Simulated environment; User study; Autonomous agents",2-s2.0-85031915897
"Landi A.D.S., Chagas F., Santos B.M., Costa R.S., Durelli R., Terra R., Camargo V.V.D.","Supporting the Specification and Serialization of Planned Architectures in Architecture-Driven Modernization Context",2017,"Proceedings - International Computer Software and Applications Conference",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031931416&doi=10.1109%2fCOMPSAC.2017.225&partnerID=40&md5=0d7b1c62c7143a2d696abf77ff3c963f","Architecture-Driven Modernization (ADM) intends to standardize software reengineering by relying on a family of standard metamodels. Knowledge-Discovery Metamodel (KDM) is the main ADM ISO metamodel aiming at representing all aspects of existing legacy systems. One of the internal KDM metamodels is called Structure, responsible for representing architectural abstractions (Layers, Components and Subsystems) and their relationships. Planned Architecture (PA) is an artifact that involves not only the architectural abstractions of the system but also the access rules that must exist between them and be maintained over time. Although PAs are frequently used in Architecture-Conformance Checking processes, up to this moment, there is no contribution showing how to specify and serialize PAs in ADM-based modernization projects. Therefore, in this paper we present an approach that i) involves a DSL (Domain-Specific Language) for the specification of PAs using the Structure metamodel concepts, and ii) proposes a strategy for the serialization of PAs as a Structure metamodel instance without modifying it. We have conducted a comparison between DCL-KDM and other techniques for specifying and generating PAs. The results showed that DCL-KDM is an efficient alternative to to generate instances of the Structure metamodel as a PA and to serialize it. © 2017 IEEE.","ADM; Architecture-Conformance Checking; Architecture-Driven Modernization; Domain-Specific Language; DSL; KDM; Knowledge-Discovery Metamodel; modernization projects; Planned Architecture","Abstracting; Application programs; Computer programming languages; Delta modulation; Digital subscriber lines; DSL; Legacy systems; Modernization; Problem oriented languages; Reengineering; Software engineering; Specifications; Architecture-driven modernizations; Conformance checking; Domain specific languages; Meta model; Modernization projects; Computer software",2-s2.0-85031931416
"Xu W., Xu D., Deng L.","Measurement of Source Code Readability Using Word Concreteness and Memory Retention of Variable Names",2017,"Proceedings - International Computer Software and Applications Conference",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031918193&doi=10.1109%2fCOMPSAC.2017.166&partnerID=40&md5=addde5a1ec7792203ccf18e9e467f763","Source code readability is critical to software quality assurance and maintenance. In this paper, we present a novel approach to the automated measurement of source code readability based on Word Concreteness and Memory Retention (WCMR) of variable names. The approach considers programming and maintenance as processes of organizing variables and their operations to describe solutions to specific problems. The overall readability of given source code is calculated from the readability of all variables contained in the source code. The readability of each variable is determined by how easily its meaning is memorized (i.e., word concreteness) and how quickly they are forgotten over time (i.e., memory retention). Our empirical study has used 14 open source applications with over a half-million lines of code and 10,000 warning defects. The result shows that the WCMR-based source code readability negatively correlates strongly with overall warning defect rates, and particularly with such warning as bad programming practices, code vulnerability, and correctness bug warning. © 2017 IEEE.","Code Readability; Memory Retention; Variable Definitions and References; Word Concreteness","Application programs; Codes (symbols); Computer programming languages; Computer software; Computer software selection and evaluation; Concretes; Defects; Open source software; Quality assurance; Automated measurement; Code readability; Memory retention; Open source application; Programming practices; Software quality assurance; Variable Definitions and References; Word Concreteness; Open systems",2-s2.0-85031918193
"Marchetto G., Sisto R., Virgilio M., Yusupov J.","A Framework for User-Friendly Verification-Oriented VNF Modeling",2017,"Proceedings - International Computer Software and Applications Conference",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031903382&doi=10.1109%2fCOMPSAC.2017.16&partnerID=40&md5=dfab65eb56082216a68d91ebf3534a2c","Network Function Virtualization (NFV) architectures are emerging to increase networks flexibility. However, this renewed scenario poses new challenges, because virtualized networks, need to be carefully verified before being actually deployed in production environments in order to preserve network coherency (e.g., absence of forwarding loops, preservation of security on network traffic, etc.). Nowadays, model checking tools, SAT solvers, and Theorem Provers are available for formal verification of such properties in virtualized networks. Unfortunately, most of those verification tools accept input descriptions written in specification languages that are difficult to use for people not experienced in formal methods. Also, in order to enable the use of formal verification tools in real scenarios, vendors of Virtual Network Functions (VNFs) should provide abstract mathematical models of their functions, coded in the specific input languages of the verification tools. This process is error-prone, time-consuming, and often outside the VNF developers' expertise. This paper presents a framework that we designed for automatically extracting verification models starting from a Java based representation of a given VNF. It comprises a Java library of classes to define VNFs in a more developer-friendly way, and a tool to translate VNF definitions into formal verification models of different verification tools. © 2017 IEEE.","Formal verification; model extraction; modeling; VNF","Application programs; Computer software; Formal methods; Formal verification; Functions; Java programming language; Model checking; Models; Specification languages; Transfer functions; Formal verification tools; Model checking tools; Model extraction; Network coherency; Production environments; Verification model; Verification tools; Virtual networks; Network function virtualization",2-s2.0-85031903382
"Fernandes L.E.R., Custodio V., Alves G.V., Fisher M.","A rational agent controlling an autonomous vehicle: Implementation and formal verification",2017,"Electronic Proceedings in Theoretical Computer Science, EPTCS",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030101519&doi=10.4204%2fEPTCS.257.5&partnerID=40&md5=afd12f85812acf2a0c4a00b832fc77ad","The development and deployment of Autonomous Vehicles (AVs) on our roads is not only realistic in the near future but can also bring significant benefits. In particular, it can potentially solve several problems relating to vehicles and traffic, for instance: (i) possible reduction of traffic congestion, with the consequence of improved fuel economy and reduced driver inactivity; (ii) possible reduction in the number of accidents, assuming that an AV can minimise the human errors that often cause traffic accidents; and (iii) increased ease of parking, especially when one considers the potential for shared AVs. In order to deploy an AV there are significant steps that must be completed in terms of hardware and software. As expected, software components play a key role in the complex AV system and so, at least for safety, we should assess the correctness of these components. In this paper, we are concerned with the high-level software component(s) responsible for the decisions in an AV. We intend to model an AV capable of navigation; obstacle avoidance; obstacle selection (when a crash is unavoidable) and vehicle recovery, etc, using a rational agent. To achieve this, we have established the following stages. First, the agent plans and actions have been implemented within the GWENDOLEN agent programming language. Second, we have built a simulated automotive environment in the Java language. Third, we have formally specified some of the required agent properties through LTL formulae, which are then formally verified with the AJPF verification tool. Finally, within the MCAPL framework (which comprises all the tools used in previous stages) we have obtained formal verification of our AV agent in terms of its specific behaviours. For example, the agent plans responsible for selecting an obstacle with low potential damage, instead of a higher damage obstacle (when possible) can be formally verified within MCAPL.We must emphasise that the major goal (of our present approach) lies in the formal verification of agent plans, rather than evaluating real-world applications. For this reason we utilised a simple matrix representation concerning the environment used by our agent. © 2017 L. Fernandes, V. Custodio, G. Alves & M. Fisher.",,"Accidents; Computer software; Formal verification; Fuel economy; Traffic congestion; Vehicles; Agent programming languages; Automotive environment; Autonomous Vehicles; Hardware and software; Matrix representation; Software component; Vehicle recoveries; Verification tools; Autonomous agents",2-s2.0-85030101519
"Kumar L., Rath S., Sureka A.","An Empirical Analysis on Effective Fault Prediction Model Developed Using Ensemble Methods",2017,"Proceedings - International Computer Software and Applications Conference",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031942342&doi=10.1109%2fCOMPSAC.2017.53&partnerID=40&md5=7a8289ec9d3baa765ecc26d343d8f326","Software fault prediction models are employed to optimize testing resource allocation by identifying fault-prone classes before testing phases. We apply three different ensemble methods to develop a model for predicting fault proneness. We propose a framework to validate the source code metrics and select the right set of metrics with the objective to improve the performance of the fault prediction model. The fault prediction models are then validated using a cost evaluation framework. We conduct a series of experiments on 45 open source project dataset. Key conclusions from our experiments are: (1) Majority Voting Ensemble (MVE) methods outperformed other methods (2) selected set of source code metrics using the suggested source code metrics using validation framework as the input achieves better results compared to all other metrics (3) fault prediction method is effective for software projects with a percentage of faulty classes lower than the threshold value (low-54.82%, medium-41.04%, high-28.10%). © 2017 IEEE.","Ensemble Methods; Machine Learning; Predictive Modeling; Software Fault Prediction; Source Code Metrics","Application programs; Codes (symbols); Computer programming languages; Computer software; Forecasting; Learning systems; Software testing; Empirical analysis; Ensemble methods; Fault prediction models; Open source projects; Predictive modeling; Software fault prediction; Source code metrics; Testing resources; Open source software",2-s2.0-85031942342
"Chibani A., Bougriou C.","Effect of the tank geometry on the storage and destocking of hydrogen on metal hydride (LaNi5–H2)",2017,"International Journal of Hydrogen Energy",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028028771&doi=10.1016%2fj.ijhydene.2017.07.102&partnerID=40&md5=2f6119e0ff40b0b5f56a1f99773b00e1","The present numerical study aimed at studying the solid-statehydrogen storage and destocking in the Lanthanum–Nickel (LaNi5–H2) in a concentric triple-tube heat exchanger. Moreover, the influence of the thermal-reactor geometry for the storage and destocking hydrogen have been examined by changing the diameters of the heat exchanger. The performance of Lanthanum–Nickel was compared with those of the hydride (MmNi4.6Fe0.4) and activated carbon. The flowing parameters: kinetics of hydrogen absorption/desorption, chemical reactions, enthalpy of fusion, equilibrium pressure, hydrogen concentration and the storage capacity were considered for calculating the terms of mass and energy equations. The hydride thermal and mass behaviour was integrated in the CFD Fluent with software (C++). A good agreement between the presented model and the literature experimental results was obtained. Additionally, the mentioned above parameters have shown a significant impact on the geometry of the reactor. © 2017 Hydrogen Energy Publications LLC","Destocking; Heat exchanger; Hydrogen; Metal hydrides; Storage; Triple tube","Activated carbon; Binary alloys; C++ (programming language); Carbon; Computer software; Energy storage; Geometry; Heat exchangers; Hydrides; Hydrogen; Lanthanum alloys; Nickel alloys; Destocking; Enthalpy of fusion; Equilibrium pressure; Hydrogen absorption; Hydrogen concentration; Metal hydrides; Storage capacity; Triple tube heat exchangers; Hydrogen storage",2-s2.0-85028028771
"Ma S., Yang H., Shi M.","Developing a Creative Travel Management System Based on Software Reuse and Abstraction Techniques",2017,"Proceedings - International Computer Software and Applications Conference",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032864951&doi=10.1109%2fCOMPSAC.2017.107&partnerID=40&md5=234608d213b61a5ec47cdf972ec8304a","Tourism became a common topic while the level of tourist requirements increased dramatically. Generally traditional travel websites provided general information or price list of hotel, transport tickets, etc. These kinds of information cannot satisfy travelers any more. A challenge for travel websites is to present creative and special travel plans to users. In order to achieve this target, relying on software reuse and abstraction techniques, this paper demonstrates a new system, aiming to generate creative travel plans. This system can be divided into three part (Information Abstraction, Information Reuse, Information Formulation). Firstly, the system is to derive the characteristic query into different travel components with a high level of abstraction. Secondly, the system is to reuse different elements from different travel components to comprise a creative travel plan. Finally, the system builds a creativity metrics system to rank the redived plans based on the level of creativity. © 2017 IEEE.","Abstraction Techniques; Creative Computing; Resue; Travel Plas","Abstracting; Application programs; Computer programming languages; Computer software; Websites; Abstraction techniques; Creative Computing; General information; High level of abstraction; Information re use; Management systems; Resue; Travel Plas; Computer software reusability",2-s2.0-85032864951
"Nakayama K., Tano S., Hashiyama T., Sakai E.","Incremental Annotate-Generalize-Search Framework for Interactive Source Code Comprehension",2017,"Proceedings - International Computer Software and Applications Conference",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031925569&doi=10.1109%2fCOMPSAC.2017.147&partnerID=40&md5=513b2c3574392c703f71df7a22fca184","Understanding unfamiliar source code is inherently difficult for a software engineer, despite its importance. Thus, an experienced engineer prefers to guess the intended behavior, rather than to trace it line-by-line, by combining semantic chunks found in the source code. It is, however, still hard for a system to help in this activity, for lack of ways of both representing semantic chunks and of preparing a rich dictionary of chunks. In this paper, an integrated framework for annotating and searching source code is presented. Since the research is still in its early stage, this paper focuses on the framework itself, together with a brief description of our prototype implementation. In the framework, each engineer gathers (annotates) semantic chunks that have the same meaning and interactively generalizes them to get a search pattern. As a result, a dictionary of semantic chunks together with their search patterns is incrementally created through engineer collaboration. To realize this, two representations are used: A tuple of nodes of an abstract syntax tree (AST) for a semantic chunk and a classifier on generative attribute vectors for search patterns. © 2017 IEEE.","abstract syntax tree; Semantic chunk","Application programs; Codes (symbols); Computer programming languages; Computer software; Engineers; Network function virtualization; Semantics; Syntactics; Trees (mathematics); Abstract Syntax Trees; Attribute vectors; Integrated frameworks; Prototype implementations; Search patterns; Semantic chunk; Source code comprehensions; Source codes; Semantic Web",2-s2.0-85031925569
"Alzahrani M., Melton A.","Defining and Validating a Client-Based Cohesion Metric for Object-Oriented Classes",2017,"Proceedings - International Computer Software and Applications Conference",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031899999&doi=10.1109%2fCOMPSAC.2017.99&partnerID=40&md5=41f254a212e09ac4548acba328ef5316","Cohesion of a software module broadly refers to the relatedness of the elements of the module. A highly cohesive module has elements that all contribute to a single common purpose. Such modules are believed to be more understandable and maintainable. Most existing object-oriented class cohesion metrics measure the cohesion of a class based on internal connections between the methods of the class where two methods are internally connected if they both reference common attributes in the class. In this paper, we propose a client-based class cohesion metric which we name CCC and which measures the cohesion of a class based on how its public methods are used by its clients. The required information for CCC to calculate the cohesion of a class can be extracted during the high-level design phase from class and communication diagrams defined by the Unified Modeling Language (UML). We validate the proposed metric theoretically, and we empirically demonstrate its usefulness. Theoretically, we analyze the compliance of CCC with the cohesion metric properties. Empirically, we investigate the relations between fourteen class cohesion metrics, including CCC, to determine if CCC captures an aspect of cohesion that is not addressed by the other class cohesion metrics. Moreover, we analyze the extent to which the fourteen class cohesion metrics, including CCC, can individually and in combination predict class testability in terms of testing effort. Our results show that CCC captures an aspect of class cohesion that has not been addressed by the other metrics and that CCC is a predictor for class testability in terms of testing effort. © 2017 IEEE.","Class cohesion; software metrics; testability","Application programs; Computer software; High level languages; Modeling languages; Object oriented programming; Unified Modeling Language; Class cohesion; High-level design; Internal connections; Metric properties; Object-oriented class; Object-oriented class cohesions; Software metrics; Testability; Adhesion",2-s2.0-85031899999
"Johnson C., Abundez-Arce A.","Toward Blocks-Text Parity",2017,"Proceedings - International Computer Software and Applications Conference",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031897672&doi=10.1109%2fCOMPSAC.2017.244&partnerID=40&md5=550c55b0e41f6fe85715acc04e2032e3","The use of blocks programming languages has skyrocketed in recent years, thanks largely to freely available blocks environments like Scratch, Snap!, and Blockly. These platforms have lowered the barrier to computer science and algorithmic thinking, allowing even very young children to compose programs. Compared to text interfaces, blocks alleviate much of the burden of learning a language's syntax. However, we do not believe the debate between blocks and text is entirely legitimate, as blocks languages tend to be smaller and domain-specific. Would the claims made in this debate still be valid if we compared text and blocks interfaces for the same language? Without a control for the language framing our positions in this debate, blocks interfaces are probably given a lot of credit that is due to the smallness of the language they support. Blocks languages and conventional text languages have fundamental semantic differences that must be aligned before we can fully understand the advantages of blocks over text. In this paper, we identify a number of these differences, with the hope that our analysis will ultimately be used to create languages that support both blocks and text interfaces and maintain syntactic and semantic parity between the two forms. © 2017 IEEE.","blocks programming; text programming","Computer software; Semantics; Syntactics; Algorithmic thinking; Domain specific; Semantic difference; Young children; Application programs",2-s2.0-85031897672
"Huang C., Yao L., Wang X., Benatallah B., Sheng Q.Z.","Expert as a Service: Software Expert Recommendation via Knowledge Domain Embeddings in Stack Overflow",2017,"Proceedings - 2017 IEEE 24th International Conference on Web Services, ICWS 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032369371&doi=10.1109%2fICWS.2017.122&partnerID=40&md5=6de21b249c2bbb685fda38c5cfe78c35","Question answering (Q&A) communities have gained momentum recently as an effective means of knowledge sharing over the crowds, where many users are experts in the real-world and can make quality contributions in certain domains or technologies. Although the massive user-generated Q&A data present a valuable source of human knowledge, a related challenging issue is how to find those expert users effectively. In this paper, we propose a framework for finding such experts in a collaborative network. Accredited with recent works on distributed word representations, we are able to summarize text chunks from the semantics perspective and infer knowledge domains by clustering pre-trained word vectors. In particular, we exploit a graph-based clustering method for knowledge domain extraction and discern the shared latent factors using matrix factorization techniques. The proposed clustering method features requiring no post-processing of clustering indicators and the matrix factorization method is combined with the semantic similarity of the historical answers to conduct expertise ranking of users given a query. We use Stack Overflow, a website with a large group of users and a large number of posts on topics related to computer programming, to evaluate the proposed approach and conduct extensively experiments to show the effectiveness of our approach. © 2017 IEEE.","Expert as a Service; Expertise finding; Knowledge discovery; Question answering; Stack Overflow","Cluster analysis; Computer programming; Data mining; Factorization; Graphic methods; Matrix algebra; Natural language processing systems; Semantics; Websites; Collaborative network; Expert as a Service; Expert recommendations; Expertise finding; Graph-based clustering; Matrix factorizations; Question Answering; Stack overflow; Web services",2-s2.0-85032369371
"Larsen R.W., Henriksen T.","Strategies for regular segmented reductions on GPU",2017,"FHPC 2017 - Proceedings of the 6th ACM SIGPLAN International Workshop on Functional High-Performance Computing, co-located with ICFP 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030990504&doi=10.1145%2f3122948.3122952&partnerID=40&md5=bc5738213ac20976ea4d0325d5c3a2e7","We present and evaluate an implementation technique for regular segmented reductions on GPUs. Existing techniques tend to be either consistent in performance but relatively inefficient in absolute terms, or optimised for specific workloads and thereby exhibiting bad performance for certain input. We propose three different strategies for segmented reduction of regular arrays, each optimised for a particular workload. We demonstrate an implementation in the Futhark compiler that is able to employ all three strategies and automatically select the appropriate one at runtime. While our evaluation is in the context of the Futhark compiler, the implementation technique is applicable to any library or language that has a need for segmented reductions. We evaluate the technique on four microbenchmarks, two of which we also compare to implementations in the CUB library for GPU programming, as well as on two application benchmarks from the Rodinia suite. On the latter, we obtain speedups ranging from 1.3× to 1.7× over a previous implementation based on scans. © 2017 Association for Computing Machinery.","Functional programming; GPGPU; Parallelism","Benchmarking; Graphics processing unit; Program compilers; Program processors; GPGPU; GPU programming; Implementation techniques; Micro-benchmarks; Parallelism; Regular array; Rodinia; Runtimes; Functional programming",2-s2.0-85030990504
"Hao Y., Fan Y., Tan W., Zhang J.","Service Recommendation Based on Targeted Reconstruction of Service Descriptions",2017,"Proceedings - 2017 IEEE 24th International Conference on Web Services, ICWS 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032387180&doi=10.1109%2fICWS.2017.44&partnerID=40&md5=443335e0139a6229d1021af902141d54","With the rapidly increasing number of services, there is an urgent demand for service recommendation algorithms that help to automatically create mashups. However, most traditional recommendation algorithms rely on the original service descriptions given by service providers. It is detrimental to the recommendation performance because original service descriptions often lack comprehensiveness and pertinence in describing possible application scenarios, let alone the possible language gap existing between service providers and mashup developers. To solve the above issues, a novel method of Targeted Reconstructing Service Descriptions (TRSD) for a specific mashup query is proposed, resorting to the valuable information hidden in mashup descriptions. TRSD aims at introducing mashup descriptions into service descriptions by analyzing the similarity between existing mashups and the specific query, while leveraging service system structure information. Benefit from this approach, missing application scenarios in original service descriptions, query-specific application scenario information, mashup developers' language habits, and service system structure information are all integrated into the reconstructed service descriptions. Based on the reconstructed service description by TRSD, a new service recommendation strategy is developed. Comprehensive experiments on the real-world data set from ProgrammableWeb.com show that the overall MAP of the proposed TRSD model is 6.5% better than the state-of-the-art methods. © 2017 IEEE.","LDA topic model; mashup creation; mashup descriptions; service descriptions; service recommendation","Search engines; Structured programming; Websites; Mash-up; Recommendation algorithms; Recommendation performance; Service description; Service recommendation algorithm; Service recommendations; State-of-the-art methods; Topic Modeling; Web services",2-s2.0-85032387180
"Samaniego M., Deters R.","Internet of Smart Things - IoST: Using Blockchain and CLIPS to Make Things Autonomous",2017,"Proceedings - 2017 IEEE 1st International Conference on Cognitive Computing, ICCC 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032271399&doi=10.1109%2fIEEE.ICCC.2017.9&partnerID=40&md5=4b8077d20cd0f0924080be837e0d2c79","Current networking integrates common 'Things' to the Web, creating the Internet of Things (IoT). The considerable number of heterogeneous Things that can be part of an IoT network demands an efficient management of resources. With the advent of Fog computing, some IoT management tasks can be distributed toward the edge of the constrained networks, closer to physical devices. Blockchain protocols hosted on Fog networks can handle IoT management tasks such as communication, storage, and authentication. This research goes beyond the current definition of Things and presents the Internet of 'Smart Things.' Smart Things are provisioned with Artificial Intelligence (AI) features based on CLIPS programming language to become self-inferenceable and self-monitorable. This work uses the permission-based blockchain protocol Multichain to communicate many Smart Things by reading and writing blocks of information. This paper evaluates Smart Things deployed on Edison Arduino boards. Also, this work evaluates Multichain hosted on a Fog network. © 2017 IEEE.","Autonomy; Blockchain; Edge; Fog; IoT; Management; Multichain; Self-inferencing; Self-monitoring; Smart Things","Distributed computer systems; Fog; Management; Autonomy; Block-chain; Edge; Multichain; Self-inferencing; Self-monitoring; Smart Things; Internet of things",2-s2.0-85032271399
"Ding W., Liu X.","Three-motor synchronous control system based on a compound active disturbance rejection controller with RBF",2017,"Chinese Control Conference, CCC",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032179455&doi=10.23919%2fChiCC.2017.8027962&partnerID=40&md5=9fd439c39bef2660a78014e953f93d02","According to problems of complex algorithm, multi-parameter and labor-intensive and time-consuming adjustment in the active disturbance rejection controller(ADRC), on the basis of optimizing the structure of ADRC, this paper designs a compound ADRC based on radical basis function neural network(RBFNN). The controller obtains the online adjustment information of ADRC parameters by using RBFNN to track the controlled object online. The method is applied to a three-motor synchronous control system based on S7-300 PLC to build an experimental platform, and PLC programming language is adopted for algorithm implementation in order to perform the decoupling experiment of the speed and tension. The results show that the method can achieve the self-adjusting function of partial parameters and can decrease the overshoot. It can also improve the dynamic performance and steady state accuracy of the system. The experimental results show that the method has practical application. © 2017 Technical Committee on Control Theory, CAA.","active disturbance rejection controller; neural network; parameters; radical basis function; self-adjusting; synchronous control",,2-s2.0-85032179455
"Martins B., Laranjeiro N., Vieira M.","INTENSE: INteroperability TEstiNg as a SErvice",2017,"Proceedings - 2017 IEEE 24th International Conference on Web Services, ICWS 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032361457&doi=10.1109%2fICWS.2017.95&partnerID=40&md5=2a2b7c3f08f64247b51c97f28beab179","The web services technology has been created to support communication between heterogeneous platforms. Despite its maturity, built upon more than a decade of experience, research and practice show that the technology still fails to connect web service client applications to servers, even when the programming languages involved are the same. This is especially troubling for service providers, as a failure in the inter-operation of web services may lead to disastrous consequences for the services involved, which frequently support businesses. In this paper, we present INTENSE, a service deployed as an on-line web application, designed to test the interoperability of a web service against specific client-side platforms. The tool is able to test the pre-runtime steps involving code generation and the end-to-end runtime communication, present in a web service interaction with a client. We used INTENSE to test a set of web services deployed on Glassfish and WildFly against the well-known Metro JAX-WS, JBossWS, and Axis2 client platforms, which disclosed severe interoperability issues. © 2017 IEEE.","interoperability; SOAP; testing; web services; WSDL","Interoperability; Soaps (detergents); Testing; Websites; WSDL; Client applications; Code Generation; Heterogeneous platforms; Interoperability testing; Service interaction; Service provider; WEB application; Web Services technologies; Web services",2-s2.0-85032361457
"Wesely J.K., Miller J.M.","Justice system bias perceptions of the dually marginalized: Observations from a sample of women ex-offenders",2017,"Victims and Offenders",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029456794&doi=10.1080%2f15564886.2017.1362614&partnerID=40&md5=e8aeee1e8431a6eed8cff0a412483ffc","Social constructions of race, gender, and class are known to shape stereotypes that condition interaction and behavior across various contexts, including the criminal justice system. From an intersectional framework emphasizing dual marginalization, this study relates in-depth interviews with women ex-offenders regarding their justice system experiences to explore perceived race and gender themed discrimination. Findings of reported pejorative language and degrading behavior reaffirm a well-documented generalized assumption by women of color that disparate treatment is normative. Discussion centers on how these views are detrimental to rehabilitation enrollment, related implications for offender programming objectives, and the utility of intersectionality theory for analyzing related justice topics. © 2017 Taylor & Francis Group, LLC","criminal justice system; ex-offenders; gender; Intersectionality; race",,2-s2.0-85029456794
"Monica D.D., Montanari A., Sala P.","Beyond ωBS-regular languages: WT-regular expressions and counter-check automata",2017,"Electronic Proceedings in Theoretical Computer Science, EPTCS",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030095898&doi=10.4204%2fEPTCS.256.16&partnerID=40&md5=9426fa260592647593aabb59e52912a6","In the last years, various extensions of ω-regular languages have been proposed in the literature, including ωB-regular (ω-regular languages extended with boundedness), ωS-regular (ω-regular languages extended with strict unboundedness), and ωBS-regular languages (the combination of ωBand ωS-regular ones). While the first two classes satisfy a generalized closure property, namely, the complement of an ωB-regular (resp., ωS-regular) language is an ωS-regular (resp., ωB-regular) one, the last class is not closed under complementation. The existence of non-ωBS-regular languages that are the complements of some ωBS-regular ones and express fairly natural properties of reactive systems motivates the search for other well-behaved classes of extended ω-regular languages. In this paper, we introduce the class of wT-regular languages, that includes meaningful languages which are not ωBS-regular. We first define it in terms of wT-regular expressions. Then, we introduce a new class of automata (counter-check automata) and we prove that (i) their emptiness problem is decidable in PTIME and (ii) they are expressive enough to capture wT-regular languages (whether or not wT-regular languages are expressively complete with respect to counter-check automata is still an open problem). Finally, we provide an encoding of wT-regular expressions into S1S+U. © D. Della Monica, A. Montanari, and P. Sala This work is licensed under the Creative Commons Attribution License.",,"Automata theory; Formal verification; Pattern matching; Boundedness; Closure property; Complementation; Emptiness problem; Natural properties; Reactive system; Regular expressions; Computer programming languages",2-s2.0-85030095898
"Chen L.-N., Li H.-Q., Yan M.-W., Yuan C.-F., Zhan W.-W., Jiang Y.-Q., Xie Z.-X., Kuang Q., Zheng L.-S.","Ternary Alloys Encapsulated within Different MOFs via a Self-Sacrificing Template Process: A Potential Platform for the Investigation of Size-Selective Catalytic Performances",2017,"Small",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021725216&doi=10.1002%2fsmll.201700683&partnerID=40&md5=3591e74a7ca689d241f33f06cc75ba82","Functional nanoparticles encapsulated within metal–organic frameworks (MOFs) as an emerging class of composite materials attract increasing attention owing to their enhanced or even novel properties caused by the synergistic effect between the two functional materials. However, there is still no ideal composite structure as platform to systematically analyze and evaluate the relation between the enhanced catalytic performance of composites and the structure of MOF shells. In this work, taking RhCoNi ternary alloy nanoflowers, for example, first the RhCoNi@MOF composite catalysts sheathed with different structured MOFs via a facile self-sacrificing template process are successfully fabricated. The structure type of MOF shells is easily adjustable by using different organic molecules as etchant and coordination reagent (e.g., 2,5-dihydroxyterephthalic acid or 2-methylimidazole), which can dissolve out the Co or Ni element in the alloy template in a targeted manner, thereby producing ZIF-67(Co) or MOF-74(Ni) shells accordingly. With the difference between the two MOF shells in the aperture sizes, the as-prepared two RhCoNi@MOF composites preform distinct size selectivity during the alkene hydrogenation. This work would help us to get more comprehensive understanding of the intrinsic role of MOFs behind the enhanced catalytic performance of nanoparticle@MOF composites. © 2017 WILEY-VCH Verlag GmbH & Co. KGaA, Weinheim","composite catalysts; hydrogenation; metal−organic frameworks; self-sacrificial template","Catalyst activity; Catalysts; Cobalt alloys; Crystalline materials; Functional materials; Hydrogenation; Metal nanoparticles; Nanoparticles; Nickel; Nickel alloys; Rhodium alloys; Shells (structures); Ternary alloys; Alkene hydrogenation; Catalytic performance; Composite catalysts; Functional nanoparticles; Metal organic framework; Metalorganic frameworks (MOFs); Sacrificial templates; Synergistic effect; Java programming language",2-s2.0-85021725216
"Jayaramulu K., Masa J., Tomanec O., Peeters D., Ranc V., Schneemann A., Zboril R., Schuhmann W., Fischer R.A.","Nanoporous Nitrogen-Doped Graphene Oxide/Nickel Sulfide Composite Sheets Derived from a Metal-Organic Framework as an Efficient Electrocatalyst for Hydrogen and Oxygen Evolution",2017,"Advanced Functional Materials",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021748309&doi=10.1002%2fadfm.201700451&partnerID=40&md5=fea3bf8206cd0c386dd5557e3226822c","Engineering of controlled hybrid nanocomposites creates one of the most exciting applications in the fields of energy materials and environmental science. The rational design and in situ synthesis of hierarchical porous nanocomposite sheets of nitrogen-doped graphene oxide (NGO) and nickel sulfide (Ni7S6) derived from a hybrid of a well-known nickel-based metal-organic framework (NiMOF-74) using thiourea as a sulfur source are reported here. The nanoporous NGO/MOF composite is prepared through a solvothermal process in which Ni(II) metal centers of the MOF structure are chelated with nitrogen and oxygen functional groups of NGO. NGO/Ni7S6 exhibits bifunctional activity, capable of catalyzing both the hydrogen evolution reaction (HER) and the oxygen evolution reaction (OER) with excellent stability in alkaline electrolytes, due to its high surface area, high pore volume, and tailored reaction interface enabling the availability of active nickel sites, mass transport, and gas release. Depending on the nitrogen doping level, the properties of graphene oxide can be tuned toward, e.g., enhanced stability of the composite compared to commonly used RuO2 under OER conditions. Hence, this work opens the door for the development of effective OER/HER electrocatalysts based on hierarchical porous graphene oxide composites with metal chalcogenides, which may replace expensive commercial catalysts such as RuO2 and IrO2. © 2017 WILEY-VCH Verlag GmbH & Co. KGaA, Weinheim","electrocatalysis; metal-organic framework (MOF); nanosheets; nickel sulfide; nitrogen-doped graphene oxide","Crystalline materials; Doping (additives); Electrocatalysis; Electrocatalysts; Hybrid materials; Inorganic compounds; Ionic liquids; Java programming language; Metals; Nanocomposites; Nanosheets; Nickel; Nitrogen; Oxygen; Phase interfaces; Sulfur compounds; Bifunctional activity; Environmental science; Hydrogen evolution reactions; Metal organic framework; Nickel sulfide; Nitrogen doped graphene; Oxygen evolution reaction; Oxygen functional groups; Graphene",2-s2.0-85021748309
"Gilda S.","Source code classification using Neural Networks",2017,"Proceedings of the 2017 14th International Joint Conference on Computer Science and Software Engineering, JCSSE 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031763448&doi=10.1109%2fJCSSE.2017.8025917&partnerID=40&md5=a63a4df3a490eba44404585da9b5b2d6","Programming languages are the primary tools of the software development industry. As of today, the programming language of the vast majority of the published source code is manually specified or programmatically assigned based solely on the respective file extension. This work shows that the identification of the programming language can be done automatically by utilizing an artificial neural network based on supervised learning and intelligent feature extraction from the source code files. We employ a multi-layer neural network-word embedding layers along with a Convolutional Neural Network-to achieve this goal. Our criteria for an automatic source code identification solution include high accuracy, fast performance, and large programming language coverage. The model achieves a 97% accuracy rate while classifying 60 programming languages. © 2017 IEEE.","Artificial neural network; Feature extraction; Multi-layer neural network; Supervised learning","Ada (programming language); Codes (symbols); Computer programming languages; Computer software; Extraction; Feature extraction; Network coding; Neural networks; Software design; Software engineering; Supervised learning; Accuracy rate; Convolutional neural network; File extension; High-accuracy; Source codes; Network layers",2-s2.0-85031763448
"Chieochan O., Saokaew A., Boonchieng E.","IOT for smart farm: A case study of the Lingzhi mushroom farm at Maejo University",2017,"Proceedings of the 2017 14th International Joint Conference on Computer Science and Software Engineering, JCSSE 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031710239&doi=10.1109%2fJCSSE.2017.8025904&partnerID=40&md5=7890b217e97192835bd4c87e64a11ef3","This research aims to prototype a smart Lingzhi mushroom farm. This research applied the use of IOT with a sensor to measure and monitors the humidity in the Lingzhi mushroom farm. The humidity data processed through NETPIE was developed and provided by NECTEC as a free service for IOT. Humidity data was stored into a NET FEED (a sub service from NETPIE) and displayed on mobile devices and computers through NET FREEBOARD (another sub service of NETPIE). This research also controlled sprinkler and fog pumps automatically and the functional status (switching on and off for periods of time) pushes notifications through LINE API on the LINE Application. The equipment and tools used in this research were NodeMCU, humidity sensor, RTC (real time clock), relay module, sprinkler and fog pumps. C++ and Node.JS were used as programming. The services and protocol used were NETPIE (Network Platform for internet of everything) with subservices such as NETPIE FEED, NETPIE FREEBOARD, and NETPIE REST API. The results of the research showed that using IOT with the sensor enhanced the prototype of smart farming. © 2017 IEEE.","IOT; LINE API; NETPIE","Application programming interfaces (API); C++ (programming language); Computer programming; LINE API; NETPIE; Network platforms; Real time clock; Software engineering",2-s2.0-85031710239
"Yang D., Xie H., Yin J., Liu Y., Yan C.","Supervised deep quantization for efficient image search",2017,"2017 IEEE International Conference on Multimedia and Expo Workshops, ICMEW 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031706739&doi=10.1109%2fICMEW.2017.8026290&partnerID=40&md5=50c3f4c1411e13c3604fa464540cbc46","Due to the efficiency of compact binary codes in approximate nearest neighbor search for large-scale image retrieval, hashing techniques have received increasing attentions. For most existing hash methods, the suboptimal binary codes are generated, as the hand-crafted feature representation is not optimally compatible with the binary codes. In this paper, we propose a one-stage supervised hashing method to learn high-quality binary codes. We implement a deep Convolutional Neural Network and enforce the learned codes to meet the following criterions: (a) similar images should be encoded into similar binary codes, and vice versa; (b) the binary codes should be evenly distributed; (c) the loss of quantization should be minimized. Experimental comparisons between our method and state-of-the-art algorithms are conducted on CIFAR-10 and NUS-WIDE datasets, and the MAP of our method reaches to 87.67% and 77.48% with 48-bit respectively. It shows that our method can obviously improve the search accuracy. © 2017 IEEE.","deep learning; image retrieval; Supervised hashing","Binary codes; Bins; C (programming language); Codes (symbols); Deep learning; Deep neural networks; Nearest neighbor search; Neural networks; Convolutional neural network; Experimental comparison; Feature representation; Hashing method; Hashing techniques; Search accuracy; State-of-the-art algorithms; Supervised hashing; Image retrieval",2-s2.0-85031706739
"Atchariyachanvanich K., Nalintippayawong S., Permpool T.","Development of a MySQL Sandbox for processing SQL statements: Case of DML and DDL statements",2017,"Proceedings of the 2017 14th International Joint Conference on Computer Science and Software Engineering, JCSSE 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031711284&doi=10.1109%2fJCSSE.2017.8025930&partnerID=40&md5=7427b559ec17560930b1dc87d58f3b06","This research developed the MySQL Sandbox, a secured environment for processing SQL queries. It was implemented as a RESTful web service having three services-sandbox database creation, SQL statement processing and sandbox database resetting. It supports the simultaneous processing of multiple SQL statements from multiple users in multiple databases. It uses question identification (ID) and student ID to create separate databases for each student using the MySQL feature to manage the user's privileges of their own database. Every service returns a result in the JSON format, which is easy to understand. This MySQL Sandbox is the first tool to support judging DDL statements and complex DML statements. Existing SQL grading systems have limitations on the number of supported SQL statements because they are concerned about risks from some sensitive SQL statement, such as DDL and DML statements, other than the SELECT statement. This sandbox will help eliminate the security concerns that obstruct the development and improvement of SQL grading systems, while providing a greater freedom of learning query to students, which will help them improve their own skills in three dimensions i.e., database query, database administration and database programming. © 2017 IEEE.","data definition language support; database; grading system; sandbox; security; SQL statement","Database systems; Education; Grading; Software engineering; Students; Web services; Data-definition languages; Grading system; sandbox; security; SQL statements; Query processing",2-s2.0-85031711284
"Yu L.-Y., Wang S.-C., Lee J.-K.","Hierarchical Read/Write Analysis for Pointer-Based OpenCL Programs on RRAM",2017,"Proceedings of the International Conference on Parallel Processing Workshops",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030624372&doi=10.1109%2fICPPW.2017.20&partnerID=40&md5=90319d2e5db391a063ddbc9ee256ee62","Heterogeneous computing platforms containing a wide range of computing resources from CPUs to specialized hardware accelerators is the trend today resulting from the physical limitations on processors speed and the increasing demand for computing performance. Hence many optimization strategies are studied to get better throughput and lower energy consumption in heterogeneous systems. Various memory technologies such as DRAM, STT-RAM, and RRAM are also developed to help reach the goal. Meanwhile OpenCL is an open programming language standard for programmers to write programs on these hardware accelerators in a heterogeneous system. In this paper, a new static analysis technique, based on OpenCL programming languages can determine read/write characteristics of instances within the program is presented. We consider the computing configuration with both DRAM and RRAM. We try to answer the question of which variables stored on RRAM will benefit energy efficiency with compiler analysis. Our compiler scheme based on Memory SSA enables the analysis to cover pointer-based programs. Our evaluation demonstrates that the read/write information obtained from the proposed design has great potential to achieve high energy-savings. The average error distance of our proposed scheme is 0.3548. In addition, compared to the baseline system, the read/write information help gain average 37.06% energy-saving per kernel. © 2017 IEEE.","Compiler; Hierarchical read/write analysis; LLVM; OpenCL; Pointer analysis","Dynamic random access storage; Energy conservation; Energy efficiency; Energy utilization; Hardware; Program processors; Random access storage; RRAM; Static analysis; Compiler; Hierarchical read/write analysis; LLVM; OpenCL; Pointer analysis; Program compilers",2-s2.0-85030624372
"Rodruksa S., Pradubsuwun D.","Formal verification of ABAP by Z specification",2017,"Proceedings of the 2017 14th International Joint Conference on Computer Science and Software Engineering, JCSSE 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031753140&doi=10.1109%2fJCSSE.2017.8025943&partnerID=40&md5=c2affdf0ef08c77d73fa800a75293989","This paper has proposed a formal verification of ABAP by Z specification. An ABAP programming language is used to create a customized program in SAP ERP. The program must satisfy a business requirement. It likely has a defect from the developed program. Since a specification is created as the business requirement and a program should have functioned as in the specification, the formal verification is needed to assure the correctness of the function in the program. Both an ABAP program and its specification are translated into Z specification and they are verified by Isabelle in order to ensure that the ABAP program conforms to its specification. We also give some experimental result to show the effectiveness of our method. © 2017 IEEE.","ABAP; Formal Verification; HOL; Isabelle; SAP ERP; Z Specification","Enterprise resource planning; Software engineering; Specifications; ABAP; Business requirement; Isabelle; Z specifications; Formal verification",2-s2.0-85031753140
"Jayanthi J., Selvakumar J.","A novel framework to facilitate personalized web search in a dual mode",2017,"Cluster Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028813009&doi=10.1007%2fs10586-017-1128-5&partnerID=40&md5=13b8872e1993d7bf0ee1717b21c89b4e","Now days, web search engines provide good services in terms of retrieval and presentation of the information to the user. A foremost difficulty in the modern and ever growing web is the lack of user interest adaption in the process of web search. All users are presented with the same set of search engine result pages (SERPs) for a given input query string, since it follows the keyword based search. The limitation of keyword based search is (i) uncertain user needs and (ii) improper query selection. If the programmer is searching for a query “switch”, it refers to the switch statement of a programming language and for an electrical engineer, the context of search is the physical house hold switch component. In addition to that a user may fall short in choosing the proper query for search that best articulate their information need. Hence, it is evident that keyword searches have tough time to distinguish the user context over the query. A typical approach to focus on this challenge is a personalized web search strategy where the results are retrieved based on the user interest and preferences. The three different major search modules are: (i) building user profiles (ii) re-ranking the SERPs in personal mode and (iii) re-ranking the SERPs in group mode. The proposed work stands for contributing in the field of user profile construction and personalized page ranking. A new method of user model representation termed as Preference Network is constructed. The proposed system can work in both initialization and maintenance mode to build a new or update an existing model. Both the short term and long term interest are utilized to rank the SERPs. The user interest score and group interest score are computed dynamically. © 2017 Springer Science+Business Media, LLC","Group interest score; Preference network; Search engine result page; Search query; User interest score; User profiles","Information retrieval; Websites; Group interest score; Search engine results; Search queries; User interests; User profile; Search engines",2-s2.0-85028813009
"Delorme M., Iori M., Martello S.","BPPLIB: a library for bin packing and cutting stock problems",2017,"Optimization Letters",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028801305&doi=10.1007%2fs11590-017-1192-z&partnerID=40&md5=678274c5574f82c84b2cc4f752cebb31","The bin packing problem (and its variant, the cutting stock problem) is among the most intensively studied combinatorial optimization problems. We present a library of computer codes, benchmark instances, and pointers to relevant articles for these two problems. The library is available at http://or.dei.unibo.it/library/bpplib. The computer code section includes twelve programs: seven are directly downloadable from the library page, while for the remaining five we provide addresses where they can be obtained or downloaded. Some of the codes for which we provide an original C++ implementation need an integer linear programming solver. For such cases, the library provides two versions: one that uses the commercial solver CPLEX, and one that uses the freeware solver SCIP. The benchmark section provides over six thousands instances (partly coming from the literature and partly randomly generated), together with the corresponding solutions. Instances that are difficult to solve to proven optimality are included. The library also includes a BibTeX file of more than 150 references on this topic and an interactive visual tool to manually solve bin packing and cutting stock instances. We conclude this work by reporting the results of new computational experiments on a number of computer codes and benchmark instances. © 2017 Springer-Verlag GmbH Germany","Benchmark instances; Bin packing; Computer codes; Cutting stock; Surveys","Benchmarking; Bins; C++ (programming language); Codes (symbols); Combinatorial optimization; Optimization; Surveying; Trimming; Bin packing; Combinatorial optimization problems; Computational experiment; Computer codes; Corresponding solutions; Cutting stock; Cutting stock problem; Integer Linear Programming; Integer programming",2-s2.0-85028801305
"Chadli M., Kim J.H., Larsen K.G., Legay A., Naujokat S., Steffen B., Traonouez L.-M.","High-level frameworks for the specification and verification of scheduling problems",2017,"International Journal on Software Tools for Technology Transfer",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028865826&doi=10.1007%2fs10009-017-0466-1&partnerID=40&md5=d17532032a55a68420fd99c56506b7ef","Over the years, schedulability of Cyber-Physical Systems (CPS) has mainly been performed by analytical methods. These techniques are known to be effective but limited to a few classes of scheduling policies. In a series of recent work, we have shown that schedulability analysis of CPS could be performed with a model-based approach and extensions of verification tools such as UPPAAL. One of our main contributions has been to show that such models are flexible enough to embed various types of scheduling policies, which goes beyond those in the scope of analytical tools. However, the specification of scheduling problems with model-based approaches requires a substantial modeling effort, and a deep understanding of the techniques employed in order to understand their results. In this paper we propose simplicity-driven high-level specification and verification frameworks for various scheduling problems. These frameworks consist of graphical and user-friendly languages for describing scheduling problems. The high-level specifications are then automatically translated to formal models, and results are transformed back into the comprehensible model view. To construct these frameworks we exploit a meta-modeling approach based on the tool generator Cinco . Additionally we propose in this paper two new techniques for scheduling analysis. The first performs runtime monitoring using the CUSUM algorithm to detect alarming change in the system. The second performs optimization using efficient statistical techniques. We illustrate our frameworks and techniques on two case studies. © 2017 Springer-Verlag GmbH Germany","Energy; Formal methods; Hierarchical scheduling; High-level language; Meta-modeling; Scheduling; Statistical model-checking","Computer programming languages; Embedded systems; Formal methods; Formal specification; Formal verification; High level languages; Modeling languages; Scheduling; Specifications; Cyber-physical systems (CPS); Energy; Hierarchical scheduling; High level specification; Meta model; Schedulability analysis; Specification and verification; Statistical model checking; Model checking",2-s2.0-85028865826
"Van Geest M., Swierstra W.","Generic packet descriptions: Verified parsing and pretty printing of low-level data",2017,"TyDe 2017 - Proceedings of the 2nd ACM SIGPLAN International Workshop on Type-Driven Development, co-located with ICFP 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030547187&doi=10.1145%2f3122975.3122979&partnerID=40&md5=f5efd436c794a0538e59e06e3bccd69e","Complex protocols describing the communication or storage of binary data are difficult to describe precisely. This paper presents a collection of data types for describing a binary data formats; the corresponding parser and pretty printer are generated automatically from a data description. By embedding these data types in a general purpose dependently typed programming language, we can verify once and for all that the parsers and pretty printers generated in this style are correct by construction. To validate our results, we show how to write a verified parser of the IPv4 network protocol.","Data type generic programming; Dependent types; Parsing; Pretty printing","Bins; Computational linguistics; Network protocols; Printing; Printing machinery; Printing presses; Binary data format; Complex protocols; Correct-by-construction; Dependent types; Dependently typed programming; Generic programming; Parsing; Pretty printers; Digital storage",2-s2.0-85030547187
"Leijen D.","Structured asynchrony with algebraic effects",2017,"TyDe 2017 - Proceedings of the 2nd ACM SIGPLAN International Workshop on Type-Driven Development, co-located with ICFP 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030546974&doi=10.1145%2f3122975.3122977&partnerID=40&md5=3ee11fefa70d0d0e899a30f10ad9186d","Algebraic effect handlers generalize many control-flow abstractions that are implemented specially in most languages, like exception handling, iterators, or backtracking. In this article, we show how we can implement full support for asynchronous programming as a library using just algebraic effect handlers. The consistent type driven approach also leads naturally to powerful abstractions like block-scoped interleaving, cancellation, and timeout's that are lacking in other major asynchronous frameworks. We also introduce the concept of ambient state to reason about state that is local to the current strand of asynchronous execution.","Algebraic effects; Asynchronous programming; Effect types; Koka","Abstracting; Algebraic effects; Asynchronous executions; Asynchronous framework; Asynchronous programming; Control flow abstraction; Effect types; Exception handling; Koka; Algebra",2-s2.0-85030546974
"Bhardwaj A., Shree A., Bhargav Reddy V., Bansal S.","A preliminary performance model for optimizing software packet processing pipelines",2017,"Proceedings of the 8th Asia-Pacific Workshop on Systems, APSys 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030553368&doi=10.1145%2f3124680.3124747&partnerID=40&md5=c6b3b44337f585d8e9473a330895c32f","Software packet processing is increasingly commonplace, especially for software-defined networking constructs. Previous work has investigated methods to efficiently map packet processing pipelines to general-purpose processor architectures. Concurrently, novel high-level domain-specific languages (DSLs) for specifying modern packet processing pipeline functionality, are emerging (e.g., P4 [5]). An attractive goal is develop a compiler that can automatically map a high-level pipeline specification (specified in a high-level DSL) to an underlying machine architecture. Ideally, the compiler should automatically exploit the available parallelism, make intelligent scheduling decisions, and adapt to the workload needs in an online fashion, to provide maximum performance. An important pre-requisite for the development of such a compiler is a performance model of the underlying machine architecture, for the applications of interest. We report our experiences with adding an optimizer to the P4C compiler [14], which compiles a high-level P4 program to a lowerlevel C-based implementation that runs with the DPDK infrastructure [1], and gets eventually executed on a multi-socket x86 machine. We make two contributions: (a) we show that significant performance improvements (up to 55%) can be gained by adding scheduling and prefetching optimizations to the P4C compiler; and (b) we develop a preliminary performance model for reasoning about the expected throughput and latency of a packet-processing workload, on a modern machine architecture. Our model can be used by a compiler, to reason about the expected performance of a packet-processing workload for different code configurations, and can thus be used to optimize the generated code accordingly. © 2017 Association for Computing Machinery.","Batching; Prefetching; Programmable networks; Software switch","C (programming language); Computer architecture; Computer programming languages; Digital subscriber lines; General purpose computers; High level languages; Network architecture; Pipelines; Problem oriented languages; Program compilers; Scheduling; Batching; General purpose processors; Intelligent scheduling; Machine architectures; Pipeline specifications; Prefetching; Programmable network; Software switches; Pipeline processing systems",2-s2.0-85030553368
"Borel K., Swaminathan V., Vance C., Roberts G., Srinivasan R., Karthikeyan R.","Modeling the dispersion of E. coli in waterbodies due to urban sources: A spatial approach",2017,"Water (Switzerland)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028829197&doi=10.3390%2fw9090665&partnerID=40&md5=de9308e6ceddb119d10ca44dd9efa005","In the United States, pathogens are the leading cause for rivers and streams to exceed water quality standards. The Spatially Explicit Load Enrichment Calculation Tool (SELECT) was developed to estimate bacterially contaminated water bodies based on spatial factors such as land use, soil, and population density. SELECT was originally automated using Visual Basics for Applications (VBA), which is no longer supported by the current version of ArcGIS. The aim of this research was to develop a new SELECT interface, pySELECT, using the Python programming language and to incorporate a rainfall-runoff E. coli transport module to simulate E. coli loads resulting from urban sources, such as dogs and on-site wastewater treatment systems. The pySELECT tool was applied to Lavon Lake, a semi urban study watershed in Northeast Texas. The highest potential E. coli loads were in the areas closest to the Dallas-Fort Worth metroplex, and the highest transported loads were located downstream from those identified hotspots or where the most runoff was generated. Watershed managers can use pySELECT to develop best management practices on the specific areas and fecal sources that contribute fecal contamination into a waterbody. © 2017 by the authors.","Bacterial contamination; GIS; Non-point sources; On-site wastewater treatment systems","Computer software; Escherichia coli; Geographic information systems; Land use; Population statistics; River pollution; Runoff; Surface waters; Urban growth; Urban transportation; Wastewater treatment; Water quality; Watersheds; Bacterial contamination; Best management practices; Fecal contamination; Non-point source; On-site wastewater treatment systems; Population densities; Python programming language; Water quality standard; Water pollution; automation; bacterium; best management practice; coliform bacterium; GIS; pathogen; pollutant source; river water; runoff; software; spatial analysis; stream; urban area; wastewater treatment; water quality; watershed; Dallas-Fort Worth International Airport; Texas; United States; Bacteria (microorganisms); Canis familiaris",2-s2.0-85028829197
"Priestley M.","AI and the Origins of the Functional Programming Language Style",2017,"Minds and Machines",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018385433&doi=10.1007%2fs11023-017-9432-7&partnerID=40&md5=307f452449a46128c1204899dfcc9301","The Lisp programming language is often described as the first functional programming language and also as an important early AI language. In the history of functional programming, however, it occupies a rather anomalous position, as the circumstances of its development do not fit well with the widely accepted view that functional languages have been developed through a theoretically-inspired project of deriving practical programming languages from the lambda calculus. This paper examines the origins of Lisp in the early AI programming work of the mid-to-late 1950s, and in particular in the work of Allen Newell, Cliff Shaw and Herbert Simon. Their 1956 program, the Logic Theory Machine, introduced new ideas about data and program structures that were articulated in response to perceived limitations in existing programming technique. Later writers, notably John Backus, have described these features as constituting a “programming language style” distinct from the traditional style that preceded it. The paper examines the origins of the earlier style in practices of manual computation, analyses the key technical differences between it and the style first manifested in the Logic Theory Machine, and concludes that programming practice and experience play a large and underappreciated role in the development of programming styles and languages. © 2017, Springer Science+Business Media Dordrecht.","Functional programming; History of AI; IPL; Lambda calculus; Lisp; Logic theory machine","Ada (programming language); Calculations; Computation theory; Computational mechanics; Computer circuits; Computer programming languages; Differentiation (calculus); LISP (programming language); Functional languages; Lambda calculus; Lisp; Logic theory; Program structures; Programming practices; Programming styles; Programming technique; Functional programming",2-s2.0-85018385433
"Guigas B.","SpecPad: device-independent NMR data visualization and processing based on the novel DART programming language and Html5 Web technology",2017,"Magnetic Resonance in Chemistry",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016581919&doi=10.1002%2fmrc.4592&partnerID=40&md5=388d6dfa3edee9ea08e47f281efc5460","SpecPad is a new device-independent software program for the visualization and processing of one-dimensional and two-dimensional nuclear magnetic resonance (NMR) time domain (FID) and frequency domain (spectrum) data. It is the result of a project to investigate whether the novel programming language DART, in combination with Html5 Web technology, forms a suitable base to write an NMR data evaluation software which runs on modern computing devices such as Android, iOS, and Windows tablets as well as on Windows, Linux, and Mac OS X desktop PCs and notebooks. Another topic of interest is whether this technique also effectively supports the required sophisticated graphical and computational algorithms. SpecPad is device-independent because DART's compiled executable code is JavaScript and can, therefore, be run by the browsers of PCs and tablets. Because of Html5 browser cache technology, SpecPad may be operated off-line. Network access is only required during data import or export, e.g. via a Cloud service, or for software updates. A professional and easy to use graphical user interface consistent across all hardware platforms supports touch screen features on mobile devices for zooming and panning and for NMR-related interactive operations such as phasing, integration, peak picking, or atom assignment. Copyright © 2017 John Wiley & Sons, Ltd.","DART; Html5; JavaScript; NMR software; Web application",,2-s2.0-85016581919
"Zheng Y., Fan R.-L., Zhang Y.-H., Qiu C.-L., Liu D.-Y., Tian D.","Control Software for TOF-SIMS Based on LabVIEW Object Oriented Programming",2017,"Journal of Chinese Mass Spectrometry Society",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031918265&doi=10.7538%2fzpxb.youxian.2016.0064&partnerID=40&md5=ad2ca261af5222d554a05f78360e278d","Time of flight secondary ion mass spectrometer (TOF-SIMS) is a powerful surface analysis technique that has been applied in a wide range of scientific fields. The development of TOF-SIMS used for isotope geology is the national major scientific instruments and equipment development projects. The study of the instrument's control software is a part of the project. LabVIEW is a high level graphical programming language used extensively in instrumentation, since the software provides high efficiency, process synchronization and code execution parallelization. However, LabVIEW is a structured programming language. As the applications become more large and complex, the expandability, reusability and maintainability of the software become worse. The components of the TOF-SIMS are numerous. Traditional LabVIEW programming method will lead to confused software's structure. Before LabVIEW introduced the object oriented programming, these problems are solved by improving the structure of the software. However, the effectiveness is limited. In this paper, a control software was developed for TOF-SIMS based on LabVIEW object oriented programming and event-driven communication. TOF-SIMS is composed of many sub-systems including ion optical system, vacuum system, three-dimensional sample stage and ion detection system. The components of these sub-systems include ion lens, ion deflector, ion filter, pulsing ion deflector, Faraday cup motor and so on. All of these components have standard interfaces, including serial port and AD/DA, serial port includes RS485 and RS232. A library of instrument's control class is built based on the I/O interface types to control all components. A hardware and simulation child class are built for all control class of components. The hardware class is used for components control. The simulation class can not communicate with components but respond simulate value, which could be used for software debugging. Producer/consumer design pattern is used to complete the software structure design. A format of event data is standardizing, which can decrease the impact of change of components. Several user interfaces are shown in the paper to illustrate the function and the design of the software's front panel. The experiment of zircon which is an important mineral used for geological dating and tracing in geochronology is implemented using TOF-SIMS controlled by the software. The experiment is successfully completed and the spectra of zircon is obtained to proceed subsequent analysis. The results show that the software meets the requirements of the instrument. In addition, the software structure has the advantages of good scalability, easy to develop and to extend, and it is not easy to be affected by hardware change. The software design approach can be used for similar development of instrument control software. © 2017, Editorial Board of Journal of Chinese Mass Spectrometry Society. All right reserved.","Control software; LabVIEW; Object oriented programming; Time of flight secondary ion mass spectrometer (TOF-SIMS)","Application programs; Computer control; Computer graphics; Computer programming languages; Computer software; Computer software reusability; Geochronology; Geology; Hardware; High level languages; Ions; Mass spectrometers; Optical systems; Program debugging; Reusability; Secondary emission; Secondary ion mass spectrometry; Silicate minerals; Software design; Spacecraft instruments; Spectrometers; Structured programming; Surface analysis; User interfaces; Zircon; Control software; Graphical programming language; Instrument control softwares; LabViEW; Process synchronization; Producer/consumer design patterns; Secondary ion mass spectrometers; Surface analysis techniques; Object oriented programming",2-s2.0-85031918265
"Ortin F., Redondo J.M., Quiroga J.","Design and evaluation of an alternative programming paradigms course",2017,"Telematics and Informatics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85001086023&doi=10.1016%2fj.tele.2016.09.014&partnerID=40&md5=a7699eac9bdbb4216cac50295d309a42","The knowledge of the most common programming paradigms, and the basic abstractions provided by each paradigm, are competencies to be attained by Software Engineering undergraduate students. These abstractions also include the basis of concurrent and parallel programming, present in different programming paradigms. In an existing Software Engineering degree, these competencies were assigned to the Programming Technology and Paradigms course. We present the approach followed in the design of that course to teach object-oriented, functional, concurrent and parallel programming to second year undergraduate students with basic knowledge of Java. The time limitations of the course prevented us from using various programming languages. After analyzing different alternatives, we chose C# to teach the course. We describe the most important challenges faced and how we addressed them. The course success rate is slightly greater than the rest of courses in the same year and degree, while performance rates and average marks are analogous. There is no influence of age and gender on the final mark, but students retaking the course have significantly worse evaluation than those enrolled for the first time. The students’ self-evaluation revealed that the proposed course has a strong influence on the achievement of the expected learning outcomes, and their satisfaction with the course was significantly higher than with the rest of courses in the same degree. © 2016","C#; Concurrency; Dynamic typing; Functional programming; Meta-programming; Object-orientation; Parallelism; Programming paradigms","Abstracting; Cesium; Curricula; Education; Functional programming; Java programming language; Parallel programming; Software engineering; Students; Teaching; Concurrency; Dynamic typing; Meta Programming; Object orientation; Parallelism; Programming paradigms; Object oriented programming",2-s2.0-85001086023
"Gavanelli M., Nonato M., Peano A., Bertozzi D.","Logic programming approaches for routing fault-free and maximally parallel wavelength-routed optical networks-on-chip (Application paper)",2017,"Theory and Practice of Logic Programming",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032584408&doi=10.1017%2fS1471068417000424&partnerID=40&md5=56cd2ab80f1f1c95345580ca62b03c74","One promising trend in digital system integration consists of boosting on-chip communication performance by means of silicon photonics, thus materializing the so-called Optical Networks-on-Chip. Among them, wavelength routing can be used to route a signal to destination by univocally associating a routing path to the wavelength of the optical carrier. Such wavelengths should be chosen so to minimize interferences among optical channels and to avoid routing faults. As a result, physical parameter selection of such networks requires the solution of complex constrained optimization problems. In previous work, published in the proceedings of the International Conference on Computer-Aided Design, we proposed and solved the problem of computing the maximum parallelism obtainable in the communication between any two endpoints while avoiding misrouting of optical signals. The underlying technology, only quickly mentioned in that paper, is Answer Set Programming. In this work, we detail the Answer Set Programming approach we used to solve such problem. Another important design issue is to select the wavelengths of optical carriers such that they are spread across the available spectrum, in order to reduce the likelihood that, due to imperfections in the manufacturing process, unintended routing faults arise. We show how to address such problem in Constraint Logic Programming on Finite Domains. Copyright © Cambridge University Press 2017.","Answer set programming; Constrained optimization; Constraint logic programming on finite domains; Logic programming applications; Optical networks-on-chip","Computation theory; Computer aided design; Computer circuits; Computer programming; Computer programming languages; Constrained optimization; Fiber optic networks; Integrated circuit design; Logic programming; Microprocessor chips; Network-on-chip; Optical communication; Optimization; Photonics; Problem solving; Answer set programming; Constrained optimi-zation problems; Constraint Logic Programming; Finite domains; Manufacturing process; On chip communication; Optical networks on chips; Physical parameters; Computer systems programming",2-s2.0-85032584408
"Nosáľ M., Porubän J., Sulír M.","Customizing host IDE for non-programming users of pure embedded DSLs: A case study",2017,"Computer Languages, Systems and Structures",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018240212&doi=10.1016%2fj.cl.2017.04.003&partnerID=40&md5=0acd32be1d14f566c52a69aa2e2462b0","Pure embedding as an implementation strategy of domain-specific languages (DSLs) benefits from low implementation costs. On the other hand, it introduces undesired syntactic noise that impedes involvement of non-programming domain experts. Due to this, pure embedded DSLs are generally not intended for, nor used by, non-programmers. In this work, we try to challenge this state by experimenting with inexpensive customizations of the host IDE (Integrated Development Environment) to reduce the negative impact of syntactic noise. We present several techniques and recommendations based on standard IDE features (e.g., file templates, code folding, etc.) that aim to reduce syntactic noise and generally improve the user experience with pure embedded DSLs. The techniques are presented using a NetBeans IDE case study. The goal of the proposed techniques is to improve the user experience with pure embedded DSLs with a focus on the involvement of non-programming domain experts (or non-programmers in general). The proposed techniques were evaluated using a controlled experiment. The experiment compared a group using Ruby and non-modified RubyMine IDE versus a group using Java and NetBeans IDE customized to use the proposed techniques. Experiment results indicate that even inexpensive host IDE customizations can significantly alleviate issues caused by the syntactic noise: Java with its inflexible syntax performed better than Ruby with its concise syntax. © 2017 Elsevier Ltd","Controlled experiment; Domain-specific language; Pure embedding; Syntactic noise","Computer programming languages; Digital subscriber lines; Graphical user interfaces; Integrodifferential equations; Problem oriented languages; Ruby; Syntactics; Controlled experiment; Domain experts; Domain specific languages; Implementation cost; Implementation strategies; Integrated development environment; Pure embedding; User experience; Java programming language",2-s2.0-85018240212
"Yalciner I.F., Nouman A., Patoglu V., Erdem E.","Hybrid conditional planning using answer set programming",2017,"Theory and Practice of Logic Programming",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032585922&doi=10.1017%2fS1471068417000321&partnerID=40&md5=58bdaf6317c9f3a1c7a48956ad33a5c6","We introduce a parallel offline algorithm for computing hybrid conditional plans, called HCP-ASP, oriented towards robotics applications. HCP-ASP relies on modeling actuation actions and sensing actions in an expressive nonmonotonic language of answer set programming (ASP), and computation of the branches of a conditional plan in parallel using an ASP solver. In particular, thanks to external atoms, continuous feasibility checks (like collision checks) are embedded into formal representations of actuation actions and sensing actions in ASP; and thus each branch of a hybrid conditional plan describes a feasible execution of actions to reach their goals. Utilizing nonmonotonic constructs and nondeterministic choices, partial knowledge about states and nondeterministic effects of sensing actions can be explicitly formalized in ASP; and thus each branch of a conditional plan can be computed by an ASP solver without necessitating a conformant planner and an ordering of sensing actions in advance. We apply our method in a service robotics domain and report experimental evaluations. Furthermore, we present performance comparisons with other compilation based conditional planners on standardized benchmark domains. Copyright © Cambridge University Press 2017.","answer set programming; cognitive robotics; Conditional planning; hybrid planning","Benchmarking; Computer programming; Computer programming languages; Logic programming; Modeling languages; Robotics; Answer set programming; Cognitive robotics; Conditional planning; Experimental evaluation; Formal representations; Nondeterministic choice; Performance comparison; Robotics applications; Robot programming",2-s2.0-85032585922
"Chavarriaga E., Jurado F., Díez F.","An approach to build XML-based domain specific languages solutions for client-side web applications",2017,"Computer Languages, Systems and Structures",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018920807&doi=10.1016%2fj.cl.2017.04.002&partnerID=40&md5=5504bbd08645e0707a594d2a4d0252fb","Domain-Specific Languages (DSLs) allow for the building of applications that ease the labour of both software engineers and domain experts thanks to the level of abstraction they provide. In cases where the domain is restricted to Client-Side Web Applications (CSWA), XML-based languages, frameworks and widgets are commonly combined in order to provide fast, robust and flexible solutions. This article presents an approach designed to create XML-based DSL solutions for CSWA that includes an evaluation engine, a programming model and a lightweight development environment. The approach is able to evaluate multiple XML-based DSL programs simultaneously to provide solutions to those Domain Specific Problems for CSWAs. To better demonstrate the capabilities and potential of this novel approach, we will employ a couple of case studies, namely Anisha and FeedPsi. © 2017 Elsevier Ltd","Domain-Specific Languages; JavaScript; Web Application; XML interpreter; XML programing language","Application programs; Computer programming languages; Digital subscriber lines; Problem oriented languages; Development environment; Domain specific; Domain specific languages; Javascript; Level of abstraction; Programming models; WEB application; XML-based languages; XML",2-s2.0-85018920807
"Pulido-Prieto O., Juárez-Martínez U.","A survey of naturalistic programming technologies",2017,"ACM Computing Surveys",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030696896&doi=10.1145%2f3109481&partnerID=40&md5=0dbe3cc3c221bc620b33bdb4f6bf4d05","Mainly focused on solving abstraction problems, programming paradigms limit language expressiveness, thus leaving unexplored natural language descriptions that are implicitly expressive. Several authors have developed tools for programming with a natural language subset limited to specific domains to deal with the ambiguity occurring with artificial intelligence technique use. This article presents a review of tools and languages with naturalistic features and highlights the problems that authors have resolved and those they have not addressed, going on to discuss the fact that a ""naturalistic"" language based on a well-defined model is not reported. © 2017 ACM.","Automatic source code generation; Controlled natural English; Expressiveness; Naturalistic programming","Computer science; Surveys; Artificial intelligence techniques; Controlled natural English; Expressiveness; Limit languages; Natural languages; Programming paradigms; Programming technology; Source code generation; Automatic programming",2-s2.0-85030696896
"Gebser M., Maratea M., Ricca F.","The sixth answer set programming competition",2017,"Journal of Artificial Intelligence Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032694703&partnerID=40&md5=01832f18be32c93e51bc839dc074aca8","Answer Set Programming (ASP) is a well-known paradigm of declarative programming with roots in logic programming and non-monotonic reasoning. Similar to other closely related problem-solving technologies, such as SAT/SMT, QBF, Planning and Scheduling, advancements in ASP solving are assessed in competition events. In this paper, we report about the design and results of the Sixth ASP Competition, which was jointly organized by the University of Calabria (Italy), Aalto University (Finland), and the University of Genoa (Italy), in affiliation with the 13th International Conference on Logic Programming and Non-Monotonic Reasoning. This edition maintained some of the design decisions introduced in 2014, e.g., the conception of sub-tracks, the scoring scheme, and the adherence to a fixed modeling language in order to push the adoption of the ASP-Core-2 standard. On the other hand, it featured also some novelties, like a benchmark selection stage classifying instances according to their empirical hardness, and a “Marathon” track where the top-performing systems are given more time for solving hard benchmarks. © 2017 AI Access Foundation. All rights reserved.",,"Computer circuits; Computer programming; Knowledge representation; Modeling languages; Problem solving; Answer set programming; Benchmark selection; Declarative Programming; Design decisions; Non-monotonic reasoning; Planning and scheduling; Scoring schemes; University of Genoa; Logic programming",2-s2.0-85032694703
"Nazir A., Alam M., Malik S.U.R., Akhunzada A., Cheema M.N., Khan M.K., Ziang Y., Khan T., Khan A.","A high-level domain-specific language for SIEM (design, development and formal verification)",2017,"Cluster Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016090100&doi=10.1007%2fs10586-017-0819-2&partnerID=40&md5=44ad6e0dd5e98815c5245cd81b86a42c","Organizations deploy security information and event management (SIEM) systems for centralized management of security events. The real-time security monitoring capability of the SIEM depends on the correlation process where events data are matched against the security rules. Most SIEM systems use general purpose languages to define security rules. Creating new rules in general purpose languages require excellent programming skills in the proprietary language and intimate knowledge of events. This paper introduces a high-level domain-specific language (HDSL) which simplifies rule creation for the SIEM system. We formally specify the HDSL with extended Backus–Naur form grammar in another tool for language recognition according to the model driven engineering approach. In our implementation framework, the rules defined in the HDSL are converted in the standard event processing language. For evaluation purpose, the converted security rules are tested on the service real-time data security analytics. The results indicate that the rules are converted accurately and generate alarms when specific attacks are detected. For checking correctness of the HDSL, formal verification is carried out using satisfiability modulo theory and Z3 solver. The results are evaluated under diverse attack scenarios, which reveal that HDSL is functioning correctly. The HDSL enhances the SIEM correlation capabilities by providing a tranquil approach for writing the correlation rules. © 2017, Springer Science+Business Media New York.","Correlation rules; Domain specific language; Formal methods; General purpose language; Satisfiability modulo theory (SMT); SIEM; Verification; Z3","Computer programming languages; Embedded systems; Formal logic; Formal methods; High level languages; Information management; Problem oriented languages; Verification; Correlation rule; Domain specific languages; General purpose languages; Satisfiability modulo Theories; SIEM; Formal verification",2-s2.0-85016090100
"Yviquel H., Araujo G.","The Cloud as an OpenMP Offloading Device",2017,"Proceedings of the International Conference on Parallel Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030636665&doi=10.1109%2fICPP.2017.44&partnerID=40&md5=d279a4b3c738d1da055e117f2704a6df","Computation offloading is a programming model in which program fragments (e.g. hot loops) are annotated so that their execution is performed in dedicated hardware or accelerator devices. Although offloading has been extensively used to move computation to GPUs, through directive-based annotation standards like OpenMP, offloading computation to very large computer clusters can become a complex and cumbersome task. It typically requires mixing programming models (e.g. OpenMP and MPI) and languages (e.g. C/C++ and Scala), dealing with various access control mechanisms from different clouds (e.g. AWS and Azure), and integrating all this into a single application. This paper introduces the cloud as a computation offloading device. It integrates OpenMP directives, cloud based map-reduce Spark nodes and remote communication management such that the cloud appears to the programmer as yet another device available in its local computer. Experiments using LLVM, OpenMP 4.5 and Amazon EC2 show the viability of the proposed approach and enable a thorough analysis of the performance and costs involved in cloud offloading. The results show that although data transfers can impose overheads, cloud offloading can still achieve promising speedups of up to 86x in 256 cores for the 2MM benchmark using 1GB matrices. © 2017 IEEE.","Cloud computing; Cloud offloading; OpenMP accelerator model; Parallel programming model","Access control; Application programming interfaces (API); Cloud computing; Data transfer; Parallel programming; Program processors; Access control mechanism; Computation offloading; Dedicated hardware; Offloading computations; Parallel programming model; Program fragments; Programming models; Remote communication; C (programming language)",2-s2.0-85030636665
"Gómez-Abajo P., Guerra E., Lara J.D.","A domain-specific language for model mutation and its application to the automated generation of exercises",2017,"Computer Languages, Systems and Structures",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007489615&doi=10.1016%2fj.cl.2016.11.001&partnerID=40&md5=faa684c0f309ee71114454a0cd105e84","Model-Driven Engineering (MDE) is a software engineering paradigm that uses models as main assets in all development phases. While many languages for model manipulation exist (e.g., for model transformation or code generation), there is a lack of frameworks to define and apply model mutations. A model mutant is a variation of an original model, created by the application of specific model mutation operations. Model mutation has many applications, for instance, in the areas of model transformation testing, model-based testing or education. In this paper, we present a domain-specific language called WODEL for the specification and generation of model mutants. WODEL is domain-independent, as it can be used to generate mutants of models conformant to arbitrary meta-models. Its development environment is extensible, permitting the incorporation of post-processors for different applications. In particular, we describe WODEL-EDU, a post-processing extension directed to the automated generation of exercises for particular domains and their automated correction. We show the application of WODEL-EDU to the generation of exercises for deterministic automata, and report on an evaluation of the quality of the generated exercises, obtaining overall good results. © 2016 Elsevier Ltd","Automatic exercise generation and correction; Domain-Specific Languages; Education; Model mutation; Model-Driven Engineering","Automation; Computer programming languages; Education; Model checking; Problem oriented languages; Software engineering; Automated generation; Deterministic automata; Development environment; Domain specific languages; Exercise generations; Model transformation; Model-driven Engineering; Software engineering paradigm; Graphical user interfaces",2-s2.0-85007489615
"Gavran I., Majumdar R., Saha I.","Antlab: A multi-robot task server",2017,"ACM Transactions on Embedded Computing Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030716751&doi=10.1145%2f3126513&partnerID=40&md5=c7111679e8a037e21d918d15501abbff","We present Antlab, an end-to-end system that takes streams of user task requests and executes them using collections of robots. In Antlab, each request is specified declaratively in linear temporal logic extended with quantifiers over robots. The user does not program robots individually, nor know how many robots are available at any time or the precise state of the robots. The Antlab runtime system manages the set of robots, schedules robots to perform tasks, automatically synthesizes robot motion plans from the task specification, and manages the co-ordinated execution of the plan. We provide a constraint-based formulation for simultaneous task assignment and plan generation for multiple robots working together to satisfy a task specification. In order to scalably handle multiple concurrent tasks, we take a separation of concerns view to plan generation. First, we solve each planning problem in isolation, with an ""ideal world"" hypothesis that says there are no unspecified dynamic obstacles or adversarial environment actions. Second, to deal with imprecisions of the real world, we implement the plans in receding horizon fashion on top of a standard robot navigation stack. The motion planner dynamically detects environment actions or dynamic obstacles from the environment or from other robots and locally corrects the ideal planned path. It triggers a re-planning step dynamically if the current path deviates from the planned path or if planner assumptions are violated. We have implemented Antlab as a C++ and Python library on top of robots running on ROS, using SMT-based and AI planning-based implementations for task and path planning. We evaluated Antlab both in simulation as well as on a set of TurtleBot robots. We demonstrate that it can provide a scalable and robust infrastructure for declarative multi-robot programming. © 2017 ACM.","Cyber-physical systems; Multi-robot systems; Planning; Programming abstractions for robotics","C++ (programming language); Computer programming; Cyber Physical System; Embedded systems; Industrial robots; Motion planning; Multipurpose robots; Planning; Robots; Specifications; Technology transfer; Adversarial environments; Dynamic obstacles; End-to-end systems; Linear temporal logic; Multi-robot systems; Programming abstractions; Separation of concerns; Task specifications; Robot programming",2-s2.0-85030716751
"Czarnul P., Kuchta J., Matuszek M., Proficz J., Rościszewski P., Wójcik M., Szymański J.","MERPSYS: An environment for simulation of parallel application execution on large scale HPC systems",2017,"Simulation Modelling Practice and Theory",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020383011&doi=10.1016%2fj.simpat.2017.05.009&partnerID=40&md5=0840a43a3463c6104ca85a7add2d146c","In this paper we present a new environment called MERPSYS that allows simulation of parallel application execution time on cluster-based systems. The environment offers a modeling application using the Java language extended with methods representing message passing type communication routines. It also offers a graphical interface for building a system model that incorporates various hardware components such as CPUs, GPUs, interconnects and easily allows various formulas to model execution and communication times of particular blocks of code. A simulator engine within the MERPSYS environment simulates execution of the application that consists of processes with various codes, to which distinct labels are assigned. The simulator runs one Java thread per label and scales computations and communication times adequately. This approach allows fast coarse-grained simulation of large applications on large-scale systems. We have performed tests and verification of results from the simulator for three real parallel applications implemented with C/MPI and run on real HPC clusters: a master-slave code computing similarity measures of points in a multidimensional space, a geometric single program multiple data parallel application with heat distribution and a divide-and-conquer application performing merge sort. In all cases the simulator gave results very similar to the real ones on configurations tested up to 1000 processes. Furthermore, it allowed us to make predictions of execution times on configurations beyond the hardware resources available to us. © 2017 Elsevier B.V.","Cluster systems; Parallel computing; Performance simulation; Simulation environment","Application programs; C (programming language); Cluster computing; Codes (symbols); Hardware; Java programming language; Large scale systems; Message passing; Modeling languages; Parallel processing systems; Program processors; Simulators; Software testing; Cluster systems; Cluster-based systems; Hardware components; Multi-dimensional space; Parallel application; Performance simulation; Simulation environment; Single program multiple data; Computer software",2-s2.0-85020383011
"Isberner M.-B., Kern-Isberner G.","Plausible reasoning and plausibility monitoring in language comprehension",2017,"International Journal of Approximate Reasoning",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019997589&doi=10.1016%2fj.ijar.2017.05.003&partnerID=40&md5=34f0738ae8936244060f43416b6791cd","In psychological research on language comprehension, so-called epistemic Stroop effects illustrate how implausible information can interfere with human action decisions, i.e., actions with positive goals can be delayed after implausible information, and vice versa. The basic assumption here is that humans reason from suitable situation models that are built upon background beliefs. In this paper, we present formal models that are apt to simulate cognitive processes that are relevant for language comprehension and these epistemic Stroop effects. Since background knowledge is crucial for the situation model, we use the inductive methods of c-representation and c-revision that are capable of processing explicit (conditional) knowledge bases to make plausible reasoning in the experimental tasks transparent. We argue that the delays in response time are partially caused by belief revision processes which are necessary to overcome the mismatch between plausible context (or background resp. world) knowledge and implausible target words. We also present first tentative results that different types of knowledge may induce different processing patterns. © 2017 Elsevier Inc.","Belief revision; c-representations; c-revisions; Language comprehension; Plausible reasoning; Spohn's ranking functions","Artificial intelligence; Software engineering; Back-ground knowledge; Belief revision; Cognitive process; Language comprehensions; Plausible reasoning; Psychological research; Ranking functions; Situation modeling; C (programming language)",2-s2.0-85019997589
"Çabuk E., Baki G., Young C.","A Microprocessor-based VLF Receiver for Exploration",2017,"Journal of Environmental and Engineering Geophysics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030114792&doi=10.2113%2fJEEG22.3.299&partnerID=40&md5=f8201e3434ce847e1db41da7cd83f795","A modern low cost microcomputer and accessories were used to create a very low frequency (VLF) receiver for geophysical prospecting. The signals were detected by induction coils, which were then amplified, digitized by a sound card, and analyzed by a Raspberry Pi computer. The computer used a Linux operating system and the Python programming language. The peripheral devices were ""off-the-shelf""' commercial items except for the preamplifiers and the induction coils, which were designed and constructed by the authors. A test profile showed typical VLF anomalies across a weak conductor..",,"Amplifiers (electronic); Computer programming; Computer systems programming; Geophysical prospecting; Induction coils; LINUX- operating system; Low costs; Peripheral devices; Python programming language; Sound cards; Very low frequency; Computer operating systems; computer simulation; frequency analysis; geophysical method; signal processing; software; Rubus glaucus",2-s2.0-85030114792
"Bastem B., Unat D., Zhang W., Almgren A., Shalf J.","Overlapping Data Transfers with Computation on GPU with Tiles",2017,"Proceedings of the International Conference on Parallel Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030653621&doi=10.1109%2fICPP.2017.26&partnerID=40&md5=0de567fb63491f301998d1deefa72c66","GPUs are employed to accelerate scientific applications however they require much more programming effort from the programmers particularly because of the disjoint address spaces between the host and the device. OpenACC and OpenMP 4.0 provide directive based programming solutions to alleviate the programming burden however synchronous data movement can create a performance bottleneck in fully taking advantage of GPUs. We propose a tiling based programming model and its library that simplifies the development of GPU programs and overlaps the data movement with computation. The programming model decomposes the data and computation into tiles and treats them as the main data transfer and execution units, which enables pipelining the transfers to hide the transfer latency. Moreover, partitioning application data into tiles allows the programmer to still take advantage of GPU even though application data cannot fit into the device memory. The library leverages C++ lambda functions, OpenACC directives, CUDA streams and tiling API from TiDA to support both productivity and performance. We show the performance of the library on a data transfer-intensive and a compute-intensive kernels and compare its speedup against OpenACC and CUDA. The results indicate that the library can hide the transfer latency, handle the cases where there is no sufficient device memory, and achieves reasonable performance. © 2017 IEEE.","CUDA; GPUs; Library; OpenACC; Overlapping communication with computation; Programming Models; Tiles","Application programming interfaces (API); Data transfer; Graphics processing unit; Libraries; Program processors; Tile; Application data; CUDA; GPUs; Openacc; Performance bottlenecks; Programming models; Programming solutions; Scientific applications; C++ (programming language)",2-s2.0-85030653621
"Drusinsky D.","Reverse engineering concurrent UML state machines using black box testing and genetic programming",2017,"Innovations in Systems and Software Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027196513&doi=10.1007%2fs11334-017-0299-9&partnerID=40&md5=3943cc0c87763e12c21cd768f02e955e","This paper presents a technique for reverse engineering, a software system generated from a concurrent unified modeling language state machine implementation. In its first step, a primitive sequential finite-state machine (FSM) is deduced from a sequence of outputs emitted from black box tests applied to the systems’ input interface. Next, we provide an algorithmic technique for decomposing the sequential primitive FSM into a set of concurrent (orthogonal) primitive FSMs. Lastly, we show a genetic programming machine learning technique for discovering local variables, actions performed on local and non-binary output variables, and two types of intra-FSM loops, called counting-loops and while-loops. © 2017, Springer‐Verlag London (outside the USA).","Concurrency decomposition; Concurrent UML state machines; Genetic programming; Machine Learning; Reverse engineering","Artificial intelligence; Genetic algorithms; Genetic programming; Interface states; Learning systems; Modeling languages; Reverse engineering; Unified Modeling Language; Algorithmic techniques; Input interface; Local variables; Machine learning techniques; Output variables; Software systems; State machine; UML state machine; Black-box testing",2-s2.0-85027196513
"Ghosh S., Sathya V., Ramamurthy A., Akilesh B., Tamma B.R.","A Novel Resource Allocation and Power Control Mechanism for Hybrid Access Femtocells",2017,"Computer Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021938531&doi=10.1016%2fj.comcom.2017.05.007&partnerID=40&md5=d4c2d450d92f1e1c45d2a67168d16d53","LTE Small cells like Femto cells are being deployed in enterprises and residential buildings to improve data rates of indoor users who experience low Signal-to-Interference plus Noise Ratio (SINR) from Macro Base Stations (MBSs). Deployment of Femto cells inside a building can lead to signal leakage at the edges/corners of the buildings. This causes cross-tier interference and degrades the performance of users in High Interference Zone (HIZone) around the building area, who are connected to one of the MBSs in LTE Heterogeneous Networks (HetNets). Hybrid Access Femto cells (HAFs) can ensure QoS for paid Subscriber Group (SG) users by giving them preferential access to resource blocks over non-SG (NSG) users and also improve the throughput of LTE HetNet system by serving nearby NSG users. In this work, we address various challenges involved in deployment and operation of HAFs in indoor environments by proposing an Optimal Placement of Femto cell (OPF) model, a dynamic Bandwidth Allocation (BWA) mechanism for splitting resource blocks between SG and NSG users, a dynamic power control mechanism to mitigate co-tier and cross-tier interference in HetNets and an Enhanced Priority (EP) scheduling mechanism to give more priority to SG users over NSG users. During peak traffic load scenarios, HAFs may not be able to guarantee QoS of both indoor and HIZone users connected to them. As HAFs are primarily meant for indoor users, HAFs employ an Optimal Power Control (OPC) mechanism to tune their transmit powers so that HIZone users are offloaded to near-by MBSs. Since the OPC is a Mixed Integer Non-linear Programming (MINLP) problem, we put forth a Sub-Optimal Power Control (SOPC) mechanism. The SOPC mechanism boosts the throughput of MBSs by almost 62% over the traditional 3GPP proposed enhanced Inter-Cell Interference Co-ordination (eICIC) mechanism for 300 users in the HetNet system. Also, the proposed EP scheduling mechanism maintains Jain's fairness index of 0.99 for both SG and NSG users while providing a 40% higher per user throughput than that obtained with the legacy proportional fair and Priority Set schedulers. © 2017 Elsevier B.V.","Hybrid access femtocells; Optimization; Power control and dynamic scheduling; Resource splitting","Cells; Dynamics; Femtocell; FORTH (programming language); Frequency allocation; Heterogeneous networks; Integer programming; Mobile telecommunication systems; Nonlinear programming; Optimization; Scheduling; Signal interference; Spurious signal noise; Throughput; Wireless telecommunication systems; Cross-tier interferences; Dynamic bandwidth allocation; Dynamic scheduling; Femto-cells; LTE heterogeneous networks; Mixed integer non-linear programming problems; Resource splitting; Signal to interference plus noise ratio; Power control",2-s2.0-85021938531
"Brown N.","Type oriented parallel programming for Exascale",2017,"Advances in Engineering Software",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018715819&doi=10.1016%2fj.advengsoft.2017.04.006&partnerID=40&md5=dbb2bc68fe5cfa4a831bebce466053f0","Whilst there have been great advances in HPC hardware and software in recent years, the languages and models that we use to program these machines have remained much more static. This is not from a lack of effort, but instead by virtue of the fact that the foundation that many programming languages are built on is not sufficient for the level of expressivity required for parallel work. The result is an implicit trade-off between programmability and performance which is made worse due to the fact that, whilst many scientific users are experts within their own fields, they are not HPC experts. Type oriented programming looks to address this by encoding the complexity of a language via the type system. Most of the language functionality is contained within a loosely coupled type library that can be flexibly used to control many aspects such as parallelism. Due to the high level nature of this approach there is much information available during compilation which can be used for optimisation and, in the absence of type information, the compiler can apply sensible default options thus supporting both the expert programmer and novice alike. We demonstrate that, at no performance or scalability penalty when running on up to 8196 cores of a Cray XE6 system, codes written in this type oriented manner provide improved programmability. The programmer is able to write simple, implicit parallel, HPC code at a high level and then explicitly tune by adding additional type information if required. © 2017 Elsevier Ltd","Asynchronous Jacobi; Mesham; Parallel programming; PGAS; Type oriented programming; Type systems","Economic and social effects; Parallel programming; Asynchronous Jacobi; Expert programmers; Hardware and software; Mesham; PGAS; Programmability; Type information; Type systems; Program compilers",2-s2.0-85018715819
"Lee J., Loney N., Meng Y.","Representing hybrid automata by action language modulo theories",2017,"Theory and Practice of Logic Programming",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032583301&doi=10.1017%2fS1471068417000412&partnerID=40&md5=947b73a8e2986b5eff78761e8894838a","Both hybrid automata and action languages are formalisms for describing the evolution of dynamic systems. This paper establishes a formal relationship between them. We show how to succinctly represent hybrid automata in an action language which in turn is defined as a high-level notation for answer set programming modulo theories - an extension of answer set programs to the first-order level similar to the way satisfiability modulo theories (SMT) extends propositional satisfiability (SAT). We first show how to represent linear hybrid automata with convex invariants by an action language modulo theories. A further translation into SMT allows for computing them using SMT solvers that support arithmetic over reals. Next, we extend the representation to the general class of non-linear hybrid automata allowing even non-convex invariants. We represent them by an action language modulo ordinary differential equations, which can be compiled into satisfiability modulo ordinary differential equations. We present a prototype system cplus2aspmt based on these translations, which allows for a succinct representation of hybrid transition systems that can be computed effectively by the state-of-the-art SMT solver dReal. Copyright © Cambridge University Press 2017.","Action languages; Answer set programming; Hybrid automata","Automata theory; Computation theory; Computer programming; Differential equations; Formal logic; High level languages; Knowledge representation; Logic programming; Ordinary differential equations; Action language; Answer set programming; Hybrid automatons; Linear hybrid automata; Propositional satisfiability; Satisfiability modulo Theories; Succinct representation; Transition system; Translation (languages)",2-s2.0-85032583301
"Koeman V.J., Hindriks K.V., Jonker C.M.","Designing a source-level debugger for cognitive agent programs",2017,"Autonomous Agents and Multi-Agent Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84990818571&doi=10.1007%2fs10458-016-9346-4&partnerID=40&md5=e33ae1e3e68f0da68a0a568aa29569cb","When an agent program exhibits unexpected behaviour, a developer needs to locate the fault by debugging the agent’s source code. The process of fault localisation requires an understanding of how code relates to the observed agent behaviour. The main aim of this paper is to design a source-level debugger that supports single-step execution of a cognitive agent program. Cognitive agents execute a decision cycle in which they process events and derive a choice of action from their beliefs and goals. Current state-of-the-art debuggers for agent programs provide insight in how agent behaviour originates from this cycle but less so in how it relates to the program code. As relating source code to generated behaviour is an important part of the debugging task, arguably, a developer also needs to be able to suspend an agent program on code locations. We propose a design approach for single-step execution of agent programs that supports both code-based as well as cycle-based suspension of an agent program. This approach results in a concrete stepping diagram ready for implementation and is illustrated by a diagram for both the Goal and Jason agent programming languages, and a corresponding full implementation of a source-level debugger for Goal in the Eclipse development environment. The evaluation that was performed based on this implementation shows that agent programmers prefer a source-level debugger over a purely cycle-based debugger. © 2016, The Author(s).","Agent program; Cognitive agent; Cognitive state; Debugging; Decision cycle; Source-level","Codes (symbols); Computer debugging; Computer programming; Intelligent agents; Object oriented programming; Process design; Agent programming languages; Cognitive agents; Cognitive state; Decision cycle; Design approaches; Development environment; Source level; Source-level debugger; Program debugging",2-s2.0-84990818571
"Midtgaard J., Møller A.","QuickChecking static analysis properties",2017,"Software Testing Verification and Reliability",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028557118&doi=10.1002%2fstvr.1640&partnerID=40&md5=9df4cdc3e1986c3b19a64b208bd2d617","A static analysis can check programs for potential errors. A natural question that arises is therefore: who checks the checker? Researchers have given this question varying attention, ranging from basic testing techniques, informal monotonicity arguments, thorough pen-and-paper soundness proofs, to verified fixed point checking. In this paper, we demonstrate how quickchecking can be useful to test a range of static analysis properties with limited effort. We show how to check a range of algebraic lattice properties, to help ensure that an implementation follows the formal specification of a lattice. Moreover, we offer a number of generic, type-safe combinators to check transfer functions and operators on lattices, to help ensure that these are, eg, monotone, strict, or invariant. We substantiate our claims by quickchecking a type analysis for the Lua programming language. Copyright © 2017 John Wiley & Sons, Ltd.","domain-specific languages; monotonicity; quickchecking; static program analysis","Computer programming languages; Problem oriented languages; Testing; Algebraic lattices; Domain specific languages; Monotonicity; Monotonicity arguments; Potential errors; quickchecking; Static program analysis; Testing technique; Static analysis",2-s2.0-85028557118
"Zolotas A., Clarisó R., Matragkas N., Kolovos D.S., Paige R.F.","Constraint programming for type inference in flexible model-driven engineering",2017,"Computer Languages, Systems and Structures",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009289904&doi=10.1016%2fj.cl.2016.12.002&partnerID=40&md5=286e8c4d562b68f53dcc0f7c498c0aa8","Domain experts typically have detailed knowledge of the concepts that are used in their domain; however they often lack the technical skills needed to translate that knowledge into model-driven engineering (MDE) idioms and technologies. Flexible or bottom-up modelling has been introduced to assist with the involvement of domain experts by promoting the use of simple drawing tools. In traditional MDE the engineering process starts with the definition of a metamodel which is used for the instantiation of models. In bottom-up MDE example models are defined at the beginning, letting the domain experts and language engineers focus on expressing the concepts rather than spending time on technical details of the metamodelling infrastructure. The metamodel is then created manually or inferred automatically. The flexibility that bottom-up MDE offers comes with the cost of having nodes in the example models left untyped. As a result, concepts that might be important for the definition of the domain will be ignored while the example models cannot be adequately re-used in future iterations of the language definition process. In this paper, we propose a novel approach that assists in the inference of the types of untyped model elements using Constraint Programming. We evaluate the proposed approach in a number of example models to identify the performance of the prediction mechanism and the benefits it offers. The reduction in the effort needed to complete the missing types reaches up to 91.45% compared to the scenario where the language engineers had to identify and complete the types without guidance. © 2016 The Authors","Bottom-up modelling; Constraint programming; Example-driven modelling; Flexible modelling; Type inference","Constraint theory; Bottom up; Constraint programming; Engineering process; Model-driven Engineering; Prediction mechanisms; Technical details; Technical skills; Type inferences; Computer programming",2-s2.0-85009289904
"Degueule T., Combemale B., Blouin A., Barais O., Jézéquel J.-M.","Safe model polymorphism for flexible modeling",2017,"Computer Languages, Systems and Structures",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85005975958&doi=10.1016%2fj.cl.2016.09.001&partnerID=40&md5=bcfcf5929f7ddfd96564c3b492789def","Domain-Specific Languages (DSLs) are increasingly used by domain experts to handle various concerns in systems and software development. To support this trend, the Model-Driven Engineering (MDE) community has developed advanced techniques for designing new DSLs. However, the widespread use of independently developed, and constantly evolving DSLs is hampered by the rigidity imposed to the language users by the DSLs and their tooling, e.g., for manipulating a model through various similar DSLs or successive versions of a given DSL. In this paper, we propose a disciplined approach that leverages type groups׳ polymorphism to provide an advanced type system for manipulating models, in a polymorphic way, through different DSL interfaces. A DSL interface, a.k.a. model type, specifies a set of features, or services, available on the model it types, and subtyping relations among these model types define the safe substitutions. This type system complements the Melange language workbench and is seamlessly integrated into the Eclipse Modeling Framework (EMF), hence providing structural interoperability and compatibility of models between EMF-based tools. We illustrate the validity and practicability of our approach by bridging safe interoperability between different semantic and syntactic variation points of a finite-state machine (FSM) language, as well as between successive versions of the Unified Modeling Language (UML). © 2016 Elsevier Ltd","Metamodeling; Model typing; Type groups polymorphism","Computer programming languages; Digital subscriber lines; Embedded systems; Interoperability; Problem oriented languages; Semantics; Software design; Software engineering; Unified Modeling Language; Domain specific languages; Eclipse modeling framework; Language workbenches; Metamodeling; Model typing; Model-driven Engineering; Syntactic variations; Systems and software; Modeling languages",2-s2.0-85005975958
"Shatnawi A., Seriai A.-D., Sahraoui H., Alshara Z.","Reverse engineering reusable software components from object-oriented APIs",2017,"Journal of Systems and Software",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85002957064&doi=10.1016%2fj.jss.2016.06.101&partnerID=40&md5=c1d6513afff820e171aa3013bb284ad6","Object-oriented Application Programing Interfaces (APIs) support software reuse by providing pre-implemented functionalities. Due to the huge number of included classes, reusing and understanding large APIs is a complex task. Otherwise, software components are accepted to be more reusable and understandable entities than object-oriented ones. Thus, in this paper, we propose an approach for reengineering object-oriented APIs into component-based ones. We mine components as a group of classes based on the frequency they are used together and their ability to form a quality-centric component. To validate our approach, we experimented on 100 Java applications that used four APIs. © 2016 Elsevier Inc.","API; Frequent usage pattern; Object-oriented; Reverse engineering; Software component; Software reuse","Application programming interfaces (API); Application programs; Computer software reusability; Java programming language; Reverse engineering; Complex task; Component based; Java applications; Object oriented; Object oriented application; Reusable software components; Software component; Usage patterns; Object oriented programming",2-s2.0-85002957064
"Ţuţu I., Fiadeiro J.L.","From conventional to institution-independent logic programming",2017,"Journal of Logic and Computation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031928266&doi=10.1093%2flogcom%2fexv021&partnerID=40&md5=666b12b18d091a6d0aeef2bd8ddb08e3","We propose a logic-independent approach to logic programming through which the paradigm as we know it for Horn-clause logic can be explored for other formalisms. Our investigation is based on abstractions of notions such as logic program, clause, query, solution and computed answer, which we develop over Goguen and Burstall's theory of institutions. These give rise to a series of concepts that formalize the interplay between the denotational and the operational semantics of logic programming. We examine properties concerning the satisfaction of quantified sentences, discuss a variant of Herbrand's theorem that is not limited in scope to any particular logical system or construction of logic programs, and describe a general resolution-based procedure for computing solutions to queries. We prove that this procedure is sound; moreover, under additional hypotheses that reflect faithfully properties of actual logic-programming languages, we show that it is also complete. © The Author, 2015. Published by Oxford University Press. All rights reserved.","Herbrand's theorem; Institution theory; Logic programming; Resolution; Substitution systems","Computation theory; Logic programming; Number theory; Optical resolving power; Query processing; Semantics; Computing solutions; Herbrand's theorem; Horn clause; Logic programs; Logical system; Operational semantics; Substitution systems; Computer circuits",2-s2.0-85031928266
"Krasnov M.M., Kuchugov P.A., Ladonkina M.E., Tishkin V.F.","Discontinuous Galerkin method on three-dimensional tetrahedral grids: Using the operator programming method",2017,"Mathematical Models and Computer Simulations",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029745632&doi=10.1134%2fS2070048217050064&partnerID=40&md5=77d1c5f5f2fe0f4a7a0697ef7026c990","In the numerical simulation of gas-dynamic flows in domains with a complex geometry, it is necessary to use detailed unstructured grids and highly accurate numerical methods. The Galerkin method with discontinuous base functions (or the discontinuous Galerkin method) works well in dealing with such problems. This technique has several advantages inherent both in finite-element and in finite-difference approximations. At the same time, the discontinuous Galerkin method is computationally complex; therefore, the question arises about the most efficient use of the full potential of computers. In order to speed up the computations, we applied the operator programming method to develop the computational module. It allows presenting mathematical formulas in programs in compact form and helps to port programs to parallel architectures such as NVidia CUDA and Intel Xeon Phi. Earlier the operator programming method was implemented for regular three-dimensional Cartesian grids and three-dimensional locally adaptive grids. In this work, this method is applied to threedimensional tetrahedral grids. This example demonstrates that the method in question can be efficiently implemented on arbitrary three-dimensional grids. Besides, we demonstrate the use of the template metaprogramming methods of the C++ programming language in order to speed up computations. © 2017, Pleiades Publishing, Ltd.","CUDA; discontinuous Galerkin method; operator programming method; template metaprogramming; three-dimensional tetrahedral grids",,2-s2.0-85029745632
"Sahneh F.D., Vajdi A., Shakeri H., Fan F., Scoglio C.","GEMFsim: A stochastic simulator for the generalized epidemic modeling framework",2017,"Journal of Computational Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028328370&doi=10.1016%2fj.jocs.2017.08.014&partnerID=40&md5=b103969bef6e28c869540b5111e9f683","The recently proposed generalized epidemic modeling framework (GEMF) [1] lays the groundwork for systematically constructing a broad spectrum of stochastic spreading processes over complex networks. This article builds an algorithm for exact, continuous-time numerical simulation of GEMF-based processes. Moreover the implementation of this algorithm, GEMFsim, is available in popular scientific programming platforms such as MATLAB, R, Python, and C; GEMFsim facilitates simulating stochastic spreading models that fit in GEMF framework. Using these simulations one can examine the accuracy of mean-field-type approximations that are commonly used for analytical study of spreading processes on complex networks. © 2017 Elsevier B.V.","Complex networks; Epidemic spreading; Markov process; Simulation","C (programming language); Complex networks; Computer software; Continuous time systems; Epidemiology; Markov processes; MATLAB; Stochastic systems; Analytical studies; Broad spectrum; Continuous-time; Epidemic modeling; Epidemic spreading; Scientific programming; Simulation; Stochastic simulators; Stochastic models",2-s2.0-85028328370
"Wang S., Zhong G., Mitra T.","CGPredict: Embedded GPU performance estimation from single-threaded applications",2017,"ACM Transactions on Embedded Computing Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030668929&doi=10.1145%2f3126546&partnerID=40&md5=7222c6b005f59d4e919b78ab65012fe8","Heterogeneous multiprocessor system-on-chip architectures are endowed with accelerators such as embedded GPUs and FPGAs capable of general-purpose computation. The application developers for such platforms need to carefully choose the accelerator with the maximum performance benefit. For a given application, usually, the reference code is specified in a high-level single-threaded programming language such as C. The performance of an application kernel on an accelerator is a complex interplay among the exposed parallelism, the compiler, and the accelerator architecture. Thus, determining the performance of a kernel requires its redevelopment into each accelerator-specific language, causing substantial wastage of time and effort. To aid the developer in this early design decision, we present an analytical framework CGPredict to predict the performance of a computational kernel on an embedded GPU architecture from un-optimized, single-threaded C code. The analytical approach provides insights on application characteristics which suggest further application-specific optimizations. The estimation error is as low as 2.66% (average 9%) compared to the performance of the same kernel written in native CUDA code running on NVIDIA Kepler embedded GPU. This low performance estimation error enables CGPredict to provide an early design recommendation of the accelerator starting from C code. © 2017 ACM.","Analytical model; Cross-platform prediction; GPGPU; Heterogenous platform; Mobile platform; Performance modeling","Acceleration; Analytical models; Codes (symbols); Distributed computer systems; Graphics processing unit; High level languages; Integrated circuit design; Program compilers; Program processors; System-on-chip; Cross-platform; GPGPU; Heterogenous platform; Mobile platform; Performance Model; C (programming language)",2-s2.0-85030668929
"Peterson J., Van Den Akker B., Cumberland R., Miller P., Banerjee K.","UNF-ST&DARDS unified database and the automatic document generator",2017,"Nuclear Technology",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028971676&doi=10.1080%2f00295450.2017.1318595&partnerID=40&md5=e3078ec3fe3e57326561a9d47a311cf1","The U.S. Department of Energy, Office of Nuclear Energy is sponsoring development of a database to store information related to spent nuclear fuel (SNF) in support of its Spent Fuel and Waste Disposition efforts. This database, referred to as the Unified Database (UDB), is part of a larger engineering analysis tool, the Used Nuclear Fuel Storage, Transportation & Disposal Analysis Resource and Data System (UNF-ST&DARDS). The UDB provides a comprehensive, controlled source of SNF information, including dry cask attributes, assembly data, economic attributes, transportation infrastructure attributes, potential future facility attributes, and federal government radioactive waste attributes. There are a number of existing and envisioned data reports that can be expected to use data stored within the UDB; however, previously, there was not a streamlined method to couple the database to such data reports. Therefore, to streamline the creation of these reports, two methods were developed to generate documents from information in the database automatically. The first method used Java and LaTeX for automatically generating the report, and the second method used the Python programming language along with Sphinx, a Python documentation generator. There are some advantages and disadvantages to both approaches, but both methods produced equally high-quality, automatically generated reports that were directly coupled to the database. This paper describes data currently available in the UDB; explains the two different methods for automatically generating reports from these data; and shows examples of inline text, figures, and tables automatically generated using both approaches. © 2017 American Nuclear Society.","Spent Nuclear fuel; UDB; UNF-ST&DARDS","Database systems; Digital storage; Fuel storage; Fuels; High level languages; Radioactive waste transportation; Radioactive wastes; Automatic document generators; Automatically generated; Engineering analysis; Federal governments; Python programming language; Spent nuclear fuels; Transportation infrastructures; U.S. Department of Energy; Radioactive waste disposal",2-s2.0-85028971676
"Beard J.C., Li P., Chamberlain R.D.","RaftLib: A C++ template library for high performance stream parallel processing",2017,"International Journal of High Performance Computing Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028085202&doi=10.1177%2f1094342016672542&partnerID=40&md5=806c30b192bb08d8783d314098a31950","Stream processing is a compute paradigm that has been around for decades, yet until recently has failed to garner the same attention as other mainstream languages and libraries (e.g. C++, OpenMP, MPI). Stream processing has great promise: the ability to safely exploit extreme levels of parallelism to process huge volumes of streaming data. There have been many implementations, both libraries and full languages. The full languages implicitly assume that the streaming paradigm cannot be fully exploited in legacy languages, while library approaches are often preferred for being integrable with the vast expanse of extant legacy code. Libraries, however are often criticized for yielding to the shape of their respective languages. RaftLib aims to fully exploit the stream processing paradigm, enabling a full spectrum of streaming graph optimizations, while providing a platform for the exploration of integrability with legacy C/C++ code. RaftLib is built as a C++ template library, enabling programmers to utilize the robust C++ standard library, and other legacy code, along with RaftLib's parallelization framework. RaftLib supports several online optimization techniques: dynamic queue optimization, automatic parallelization, and real-time low overhead performance monitoring. © 2016 The Author(s).","big-data; C++ template library; high performance computing; parallel processing; performance monitoring; RaftLib; Stream processing","Application programming interfaces (API); Big data; Codes (symbols); Libraries; C++ template library; High performance computing; Parallel processing; Performance monitoring; RaftLib; Stream processing; C++ (programming language)",2-s2.0-85028085202
"Komendantskaya E., Li Y.","Productive corecursion in logic programming",2017,"Theory and Practice of Logic Programming",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030155101&doi=10.1017%2fS147106841700028X&partnerID=40&md5=307023167026dfb82c75d2ac1fa6b7da","Logic Programming is a Turing complete language. As a consequence, designing algorithms that decide termination and non-termination of programs or decide inductive/coinductive soundness of formulae is a challenging task. For example, the existing state-of-the-art algorithms can only semi-decide coinductive soundness of queries in logic programming for regular formulae. Another, less famous, but equally fundamental and important undecidable property is productivity. If a derivation is infinite and coinductively sound, we may ask whether the computed answer it determines actually computes an infinite formula. If it does, the infinite computation is productive. This intuition was first expressed under the name of computations at infinity in the 80s. In modern days of the Internet and stream processing, its importance lies in connection to infinite data structure processing. Recently, an algorithm was presented that semi-decides a weaker property - of productivity of logic programs. A logic program is productive if it can give rise to productive derivations. In this paper, we strengthen these recent results. We propose a method that semi-decides productivity of individual derivations for regular formulae. Thus, we at last give an algorithmic counterpart to the notion of productivity of derivations in logic programming. This is the first algorithmic solution to the problem since it was raised more than 30 years ago. We also present an implementation of this algorithm. Copyright © Cambridge University Press 2017.","(co)induction; (co)recursion; Horn clauses; infinite term trees; productivity","Computation theory; Computer circuits; Data handling; Productivity; (co)induction; Algorithmic solutions; Horn clause; infinite term trees; Non terminations; Recursions; State-of-the-art algorithms; Stream processing; Logic programming",2-s2.0-85030155101
"Knopp S.J., Bones P.J., Weddell S.J., Jones R.D.","A software framework for real-time multi-modal detection of microsleeps",2017,"Australasian Physical and Engineering Sciences in Medicine",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020078859&doi=10.1007%2fs13246-017-0559-x&partnerID=40&md5=448a24654c8628a7d45eca08dd31b4ca","A software framework is described which was designed to process EEG, video of one eye, and head movement in real time, towards achieving early detection of microsleeps for prevention of fatal accidents, particularly in transport sectors. The framework is based around a pipeline structure with user-replaceable signal processing modules. This structure can encapsulate a wide variety of feature extraction and classification techniques and can be applied to detecting a variety of aspects of cognitive state. Users of the framework can implement signal processing plugins in C++ or Python. The framework also provides a graphical user interface and the ability to save and load data to and from arbitrary file formats. Two small studies are reported which demonstrate the capabilities of the framework in typical applications: monitoring eye closure and detecting simulated microsleeps. While specifically designed for microsleep detection/prediction, the software framework can be just as appropriately applied to (i) other measures of cognitive state and (ii) development of biomedical instruments for multi-modal real-time physiological monitoring and event detection in intensive care, anaesthesiology, cardiology, neurosurgery, etc. The software framework has been made freely available for researchers to use and modify under an open source licence. © 2017, Australasian College of Physical Scientists and Engineers in Medicine.","Biosignals; Cognitive monitoring; Multi-modal; Real-time; Software framework","Anesthesiology; Biomedical signal processing; C++ (programming language); Cognitive systems; Eye movements; Feature extraction; Graphical user interfaces; Network function virtualization; Neurosurgery; Open source software; Open systems; Patient monitoring; Pipeline processing systems; Psychophysiology; Signal processing; User interfaces; Biosignals; Cognitive monitoring; Multi-modal; Real time; Software frameworks; Computer programming; anesthesiology; Article; cardiology; classification algorithm; computer interface; electroencephalogram; eyelid closure; human; human experiment; intensive care; male; microsleep; monitoring; neurosurgery; normal human; prediction; sleep; software; videorecording",2-s2.0-85020078859
"Breschi K., Bernard J.","Construction of a minimum energy broadcast backbone with bounded delay in heterogeneous wireless sensor networks",2017,"Proceedings - IEEE Symposium on Computers and Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030529752&doi=10.1109%2fISCC.2017.8024705&partnerID=40&md5=ff61b61c96ff48596ae579e8055f0e5c","Efficient broadcast in wireless sensor networks can exploit backbone structures, in relation to connected dominating sets in graphs. This paper proposes the construction of a backbone for broadcast in heterogeneous wireless sensor networks having minimum energy consumption and a delay bounded by a predefined constant max. For the purpose of the paper, we assume the sensors composing the network have an energy belonging to [Wmin;Wmax] such that Wmax = c ∗ Wmin where c is a predefined constant. To address this problem we propose two different approaches. For small instances, we propose an integer linear program that computes an optimal solution for the problem. Since solving an integer linear program is NP-hard, obtaining solutions for large network instances may be impossible in a reasonable time, thus we propose an approximation algorithm that computes a solution for the problem in polynomial time and whose approximation ratio is c ∗ max. © 2017 IEEE.",,"Approximation algorithms; C (programming language); Energy utilization; Integer programming; Polynomial approximation; Polynomials; Problem solving; Approximation ratios; Backbone structures; Connected Dominating Set; Heterogeneous wireless sensor networks; Integer linear programs; Minimum energy consumption; Optimal solutions; Polynomial-time; Wireless sensor networks",2-s2.0-85030529752
"Qu L., Assi C., Shaban K., Khabbaz M.J.","A Reliability-Aware Network Service Chain Provisioning with Delay Guarantees in NFV-Enabled Enterprise Datacenter Networks",2017,"IEEE Transactions on Network and Service Management",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023198533&doi=10.1109%2fTNSM.2017.2723090&partnerID=40&md5=f38d59a125d553ad9172a6446db6e527","Traditionally, service-specific network functions (NFs) (e.g., Firewall, intrusion detection system, etc.) are executed by installation-and maintenance-costly hardware middleboxes that are deployed within a datacenter network following a strictly ordered chain. NF virtualization (NFV) virtualizes these NFs and transforms them into instances of plain software referred to as virtual NFs (VNFs) and executed by virtual machines, which, in turn, are hosted over one or multiple industry-standard physical machines. The failure (e.g., hardware or software) of any one of a service chain's VNFs leads to breaking down the entire chain and causing significant data losses, delays, and resource wastage. This paper establishes a reliability-aware and delay-constrained (READ) routing optimization framework for NFV-enabled datacenter networks. READ encloses the formulation of a complex mixed integer linear program (MILP) whose resolution yields an optimal network service VNF placement and traffic routing policy that jointly maximizes the achieved respective reliabilities of supported network services and minimizes these services' respective end-to-end delays. A heuristic algorithm dubbed Greedy-k-shortest paths (GSP) is proposed for the purpose of overcoming the MILP's complexity and develop an efficient routing scheme whose results are comparable to those of READ's optimal counterparts. Thorough numerical analyses are conducted to evaluate the network's performance under GSP, and hence, gauge its merit; particularly, when compared to existing schemes, GSP exhibits an improvement of 18.5% in terms of the average end-to-end delay as well as 7.4% to 14.8% in terms of reliability. © 2004-2012 IEEE.","datacenter; delay; network functions; optimization; performance; Reliability; resources; routing","Bandwidth; Chains; Complex networks; Computer hardware; Computer software; Computer system firewalls; Constrained optimization; Hardware; Heuristic algorithms; Integer programming; Intrusion detection; Java programming language; Network routing; Optimization; Reliability; Reliability analysis; Software reliability; Transfer functions; Virtual machine; Datacenter; Delay; Delays; Network functions; Performance; Resources; Routing; Network function virtualization",2-s2.0-85023198533
"Badri M., Badri L., Flageol W., Toure F.","Source code size prediction using use case metrics: an empirical comparison with use case points",2017,"Innovations in Systems and Software Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986260110&doi=10.1007%2fs11334-016-0285-7&partnerID=40&md5=f5d08487c14a51568f373e9fb732cf05","Software source code size, in terms of source lines of code (SLOC), is an important parameter of many parametric software development effort estimation methods. In this paper, we investigate empirically the early prediction of SLOC for object-oriented software using use case metrics. We used different modeling techniques to build the prediction models. We used the univariate logistic regression and the simple linear regression methods to evaluate the individual effect of each use case metric on SLOC, and the multivariate logistic regression and the multiple linear regression methods to explore the combined effect of the use case metrics on SLOC. We also used in the study different machine learning methods (k-NN, naïve Bayes, C4.5, random forest, and multilayer perceptron neural network). The prediction models were evaluated using the receiver operating characteristic analysis, particularly the area under the curve measure, and leave-one-out cross validation. An empirical study, using data collected from five open source Java projects, is reported in the paper. The use case metrics have been compared to the well-known use case points method. Results provide evidence that the use case metrics-based approach gives a more accurate prediction of SLOC than the use case points-based approach. © 2016, Springer-Verlag London.","C4.5; k-NN; Linear regression; Logistic regression; LOO cross validation; Multilayer perceptron neural network; Naïve Bayes; Prediction models; Random forest; ROC and AUC analysis; Source code size; Use case metrics; Use case points; Use cases","Artificial intelligence; Codes (symbols); Computer programming languages; Decision trees; Forecasting; Learning algorithms; Learning systems; Linear regression; Multilayers; Nearest neighbor search; Open source software; Regression analysis; Software design; Statistical methods; C4.5; Cross validation; Logistic regressions; Multi-layer perceptron neural networks; Prediction model; Random forests; ROC and AUC analysis; Source codes; Use case metrics; Use case points; Object oriented programming",2-s2.0-84986260110
"Goncharov S.S.","Conditional terms in semantic programming",2017,"Siberian Mathematical Journal",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032035771&doi=10.1134%2fS0037446617050068&partnerID=40&md5=a561689588ef5f866fd2b3fc38b3cbcb","For constructing an enrichment of the language with restricted quantifiers, we extend the construction of conditional terms. We show that the so-obtained extension of the language of formulas with restricted quantifiers over structures with hereditary finite lists is a conservative enrichment. © 2017, Pleiades Publishing, Ltd.","computability; computability over abstract structures; conditional term; formula; restricted quantifier; semantic programming; term; Δ0-formula; Σ-formula",,2-s2.0-85032035771
"Kittelmann T., Klinkby E., Knudsen E.B., Willendrup P., Cai X.X., Kanaki K.","Monte Carlo Particle Lists: MCPL",2017,"Computer Physics Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019870389&doi=10.1016%2fj.cpc.2017.04.012&partnerID=40&md5=9876d1571dac9d0483f19efa1edcf1ad","A binary format with lists of particle state information, for interchanging particles between various Monte Carlo simulation applications, is presented. Portable C code for file manipulation is made available to the scientific community, along with converters and plugins for several popular simulation packages. Program summary Program Title: MCPL Program Files doi: http://dx.doi.org/10.17632/cby92vsv5g.1 Licensing provisions: CC0 for core MCPL, see LICENSE file for details. Programming language: C and C++ External routines/libraries: Geant4, MCNP, McStas, McXtrace Nature of problem: Saving particle states in Monte Carlo simulations, for interchange between simulation packages or for reuse within a single package. Solution method: Binary interchange format with associated code written in portable C along with tools and interfaces for relevant simulation packages. © 2017 The Authors","File format; Geant4; MCNP; MCPL; McStas; McXtrace; Monte Carlo simulations; Particle storage","Bins; C++ (programming language); Computer software; Intelligent systems; File formats; Geant4; MCNP; MCPL; McStas; McXtrace; Monte Carlo methods",2-s2.0-85019870389
"Bettini L., Damiani F.","XTRAITJ: Traits for the Java platform",2017,"Journal of Systems and Software",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994226132&doi=10.1016%2fj.jss.2016.07.035&partnerID=40&md5=c40e5534e2bbe837a6c9fd9301ec495f","Traits were proposed as a mechanism for fine-grained code reuse to overcome many limitations of class-based inheritance. A trait is a set of methods that is independent from any class hierarchy and can be flexibly used to build other traits or classes by means of a suite of composition operations. In this paper we present the new version of XTRAITJ, a trait-based programming language that features complete compatibility and interoperability with the JAVA platform. XTRAITJ is implemented in XTEXT and XBASE, and it provides a full Eclipse IDE that supports an incremental adoption of traits in existing JAVA projects. The new version of XTRAITJ allows traits to be accessed from any JAVA project or library, even if the original XTRAITJ source code is not available, since traits can be accessed in their byte-code format. This allows developers to create XTRAITJ libraries that can be provided in their binary only format. We detail the technique we used to achieve such an implementation; this technique can be reused in other languages implemented in XTEXT for the JAVA platform. We formalize our traits by means of flattening semantics and we provide some performance benchmarks that show that the runtime overhead introduced by our traits is acceptable. © 2016 Elsevier Inc.","Eclipse; IDE; Implementation; Java; Trait","Benchmarking; Codes (symbols); Integrodifferential equations; Semantics; Class hierarchies; Eclipse; Implementation; Java; Java platforms; Runtime overheads; Source codes; Trait; Java programming language",2-s2.0-84994226132
"Pinheiro A., Desterro F., Santos M.C., Pereira C.M.N.A., Schirru R.","GPU-based implementation of a diagnostic wind field model used in real-time prediction of atmospheric dispersion of radionuclides",2017,"Progress in Nuclear Energy",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020821393&doi=10.1016%2fj.pnucene.2017.05.027&partnerID=40&md5=ca7f410b91c2fd3a7840d419b9ce9467","In order to improve the prediction of atmospheric dispersion of radionuclides (ADR) in vicinity of Central Nuclear Almirante Alvaro Alberto (CNAAA) Brazilian Nuclear Power Plants (NPP), a more refined computational system is under development. To achieve desired refinement, the required computational effort increases in such a way that system's execution by current computers leads to prohibitive processing time. Aiming to accelerate execution of such refined system, allowing its effective use in real-time prediction of ADR, a GPU-based parallel approach has been proposed. Basically, the ADR system used in CNAAA is comprised by 4 main modules (programs): Source Term, Wind Field, Plume Dispersion and Plume Projection modules. This work is focused on the Wind Field module, which uses a mass-consistent approach, based on Winds Extrapolated from Stability and Terrain (WEST) model. Due to the strong sequential nature of the algorithm, domain decomposition by a 3D-Red-Black partitioning was proposed and a new parallel GPU-based algorithm was implemented using the Compute Unified Device Architecture (CUDA) and C programming language. As a result, the execution time of a fine-grained simulation decreased from about 450 s (running on an Intel-I7) to 18 s (running on a GTX-680 GPU). Here, the most important issues of the parallel implementation, as well as comparative results, are presented and discussed. © 2017","Atmospheric dispersion of radionuclides; CUDA; GPU; Parallel computing; Red-Black partitioning; WEST model; Wind field","C (programming language); Domain decomposition methods; Forecasting; Graphics processing unit; Nuclear fuels; Nuclear power plants; Parallel processing systems; Radioisotopes; Weather forecasting; Atmospheric dispersion; Computational effort; Compute Unified Device Architecture(CUDA); CUDA; Parallel implementations; Real-time prediction; Red-black; Wind field; Atmospheric movements",2-s2.0-85020821393
"Lee J., Talsania S., Wang Y.","Computing LP using ASP and MLN solvers",2017,"Theory and Practice of Logic Programming",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032572741&doi=10.1017%2fS1471068417000400&partnerID=40&md5=01d713a1a466e60ad80aa52316f89872","LPMLN is a recent addition to probabilistic logic programming languages. Its main idea is to overcome the rigid nature of the stable model semantics by assigning a weight to each rule in a way similar to Markov Logic is defined. We present two implementations of LPMLN, lpmln2asp and lpmln2mln. System lpmln2asp translates LPMLN programs into the input language of answer set solver clingo, and using weak constraints and stable model enumeration, it can compute most probable stable models as well as exact conditional and marginal probabilities. System lpmln2mln translates LPMLN programs into the input language of Markov Logic solvers, such as alchemy, tuffy, and rockit, and allows for performing approximate probabilistic inference on LPMLN programs. We also demonstrate the usefulness of the LPMLN systems for computing other languages, such as ProbLog and Pearl's Causal Models, that are shown to be translatable into LPMLN. Copyright © Cambridge University Press 2017.","Answer Set Programming; LPMLN; Markov Logic","Computation theory; Computer programming; Computer systems programming; Logic programming; Markov processes; Probabilistic logics; Semantics; Translation (languages); Answer set programming; Causal model; LPMLN; Marginal probability; Markov logic; Probabilistic inference; Stable model; Stable model semantics; Computer circuits",2-s2.0-85032572741
"Bae K.-R., Moon B.","An accurate and cost-effective stereo matching algorithm and processor for real-time embedded multimedia systems",2017,"Multimedia Tools and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954569909&doi=10.1007%2fs11042-016-3248-y&partnerID=40&md5=555a43464d0afffb2346bf4de26f3bcf","Stereo matching is a vision technique for finding three-dimensional (3D) distance information in various multimedia applications by calculating pixel disparities between the matching points of a stereo image pair captured from a stereo camera. The most important considerations in stereo matching are highly accurate results and real-time performance. Thus, this paper proposes an accurate stereo matching algorithm that uses both a census transform algorithm and the sum of absolute differences algorithm in a complementary manner and its real-time hardware architecture. In addition, the proposed algorithm uses a vertical census transform with cost aggregation (VCTCA) to reduce hardware costs while maintaining high matching accuracy. We model the proposed algorithm using C language and verify it in several environments. Using a hardware description language, we implement the proposed hardware architecture and verify it on a field-programmable gate array-based platform to confirm the cost and performance of the hardware. The experimental results show that the proposed algorithm using the VCTCA produces accurate 3D distance information in real environments and reduces the hardware complexity. Thus, the algorithm and its hardware architecture are suitable for real-time embedded multimedia systems. © 2016, Springer Science+Business Media New York.","3D content; Algorithm cross-check; Hardware implementation; Stereo matching; Vertical census transform","Algorithms; C (programming language); Computational linguistics; Computer hardware description languages; Cost effectiveness; Costs; Embedded systems; Field programmable gate arrays (FPGA); Hardware; Image matching; Multimedia systems; Real time systems; Reconfigurable hardware; Stereo vision; Surveys; 3D content; Census transforms; Cross check; Hardware implementations; Stereo matching; Stereo image processing",2-s2.0-84954569909
"Van Es N., Stievenart Q., Nicolay J., D'Hondt T., De Roover C.","Implementing a performant scheme interpreter for the web in asm.js",2017,"Computer Languages, Systems and Structures",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017409118&doi=10.1016%2fj.cl.2017.02.002&partnerID=40&md5=05cf8add24ed2c03f36cbbfaee938991","This paper presents the implementation of an efficient interpreter for a Scheme-like language using manually written asm.js code. The asm.js specification defines an optimizable subset of JavaScript that has already served well as a compilation target for web applications where performance is critical. However, its usage as a human-writable language that can be integrated into existing projects to improve performance has remained largely unexplored. We therefore apply this strategy to optimize the implementation of an interpreter. We also discuss the feasibility of this approach, as writing asm.js by hand is generally not its recommended use-case. We therefore present a macro system to solve the challenges we encounter. The resulting interpreter is compared to the original C implementation and its compiled equivalent in asm.js. This way, we evaluate whether manual integration with asm.js provides the necessary performance to bring larger applications and runtimes to the web. We also refactor our implementation to assess how more JavaScript code can cohabit with asm.js code, improving maintainability of the implementation while preserving near-native performance. In the case of our interpreter, this improved maintainability enables adding more complex optimizations. We investigate the addition of function inlining, for which we validate the performance gain. © 2017 Elsevier Ltd","asm.js; Interpreters; JavaScript; Optimization; Performance","Codes (symbols); High level languages; Maintainability; Optimization; Program interpreters; Web crawler; asm.js; Complex optimization; Improve performance; Javascript; Macro systems; Performance; Performance Gain; WEB application; C (programming language)",2-s2.0-85017409118
"Maier A.J., Cockburn B.F.","Optimization of Low-Density Parity Check decoder performance for OpenCL designs synthesized to FPGAs",2017,"Journal of Parallel and Distributed Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018300371&doi=10.1016%2fj.jpdc.2017.04.001&partnerID=40&md5=535db76ed5989a7082941f6804630b54","Open Computing Language (OpenCL) is a high-level language that allows developers to produce portable software for heterogeneous parallel computing platforms. OpenCL is available for a variety of hardware platforms, with compiler support being recently expanded to include Field-Programmable Gate Arrays (FPGAs). This article investigates flexible OpenCL designs for the iterative min-sum decoding algorithm for (3,6)-regular Low-Density Parity Check (LDPC) codes over a range of codeword lengths. The target FPGA hardware is the Altera Stratix V GX A7 based Nallatech 385n board. The computationally demanding LDPC decoding algorithm offers several forms of parallelism that could be exploited by the Altera Offline Compiler (AOC version 15.1) for OpenCL. Our best decoder design produced a corrected codeword throughput of 68.22 Mbps at the compiler-selected FPGA clock frequency of 163.88 MHz for a length-2048 (3,6)-regular LDPC code. For a length-1024 (3,6)-regular LDPC code, our best design produced a throughput of 54.8 Mbps (32 decoding iterations) which significantly improves on the throughput of around 7 Mbps (30 decoding iterations) produced by an OpenCL based decoder design reported by Falcao et al. for the same size of LDPC code. © 2017 Elsevier Inc.","Altera-Offline Compiler; FPGA; High-level synthesis; LDPC; Low-Density Parity Check; OpenCL; Parallel algorithms","Codes (symbols); Computer programming languages; Convolutional codes; Decoding; Forward error correction; Hardware; High level languages; High level synthesis; Integrated circuit design; Iterative decoding; Iterative methods; Logic Synthesis; Optimization; Parallel algorithms; Program compilers; Satellite communication systems; Throughput; Heterogeneous parallel computing; LDPC; Low density parity check; Low density parity check decoders; Low-density parity-check (LDPC) codes; Min-sum decoding algorithm; Offline; OpenCL; Field programmable gate arrays (FPGA)",2-s2.0-85018300371
"Rubino E.M., Alvares A.J., Prades R.M., Valero P.S.","A Novel Minimum Time Parallel 2-D Discrete Wavelet Transform Algorithm for General Purpose Processors",2017,"Proceedings of the International Conference on Parallel Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030653343&doi=10.1109%2fICPP.2017.64&partnerID=40&md5=cd844683165f2c56df77e994c9fa5fbe","A novel efficient inplace, multithreaded, and cachefriendly parallel 2-D wavelet transform algorithm based on the lifting transform is introduced. In order to maximize the cache utilization and consequently minimize the memory bus bandwidth use, the threads compete to work on a small memory area maximizing the chance of finding it in the cache and their synchronization is done with very low overhead without the use of any locks and relying solely on the basic compare-and-swap (CAS) atomic primitive. An implementation in the C programming language with and without the use of vector (single instruction multiple data - SIMD) instructions is provided for both single (serial) and multi (parallel) threaded single-loop DWT implementations as well as serial and parallel naive implementations using linear (row order) and strided (column order) memory access patterns for comparison. Results show a significant improvement over the single-threaded optimized implementation and a much greater improvement over both the single and multi threaded naive implementations, reaching minimum running time depending on the number of processor cores and the available memory bus bandwidth, i.e., it becomes memory bound using the minimum number of memory accesses. Given the simplicity and high speed of the lifting steps, an analysis based on the number of memory bus operations (read and write) is done for images that are larger than twice the shared cache size which establishes a lower bound for the running time of all linear memory access algorithms and also determines the maximum speed gains to be expected in relation to currently implemented parallel schemes based on the parallel execution of independent lifting steps. It also shows the optimality of the parallel algorithm presented. Finally, a comparison with currently available implementations shows the gains achieved by the proposed algorithm. © 2017 IEEE.","Discrete wavelet transform; DWT; Lifting; Lockless; Memory bound; Memory saturation; Parallel; SIMD","Bandwidth; Buses; C (programming language); Discrete wavelet transforms; General purpose computers; Locks (fasteners); Memory architecture; Parallel processing systems; Signal reconstruction; System buses; Wavelet transforms; Lifting; Lockless; Memory bounds; Memory saturation; Parallel; SIMD; Cache memory",2-s2.0-85030653343
"Muraleedhara Varier K., Sankar V., Gangadathan M.P.","TrackEtching — A Java based code for etched track profile calculations in SSNTDs",2017,"Computer Physics Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019635277&doi=10.1016%2fj.cpc.2017.04.013&partnerID=40&md5=dc64b516ed7dcb4935070827a1f301bd","A java code incorporating a user friendly GUI has been developed to calculate the parameters of chemically etched track profiles of ion-irradiated solid state nuclear track detectors. Huygen's construction of wavefronts based on secondary wavelets has been used to numerically calculate the etched track profile as a function of the etching time. Provision for normal incidence and oblique incidence on the detector surface has been incorporated. Results in typical cases are presented and compared with experimental data. Different expressions for the variation of track etch rate as a function of the ion energy have been utilized. The best set of values of the parameters in the expressions can be obtained by comparing with available experimental data. Critical angle for track development can also be calculated using the present code. Program summary Program Title: TrackEtching Program Files doi: http://dx.doi.org/10.17632/7wb6pvpbgh.1 Licensing provisions: CC0 1.0 Programming language: Java Nature of problem: Calculation of the etched track profiles in ion irradiated SSNTDs is important for the application in the field of nucleopore filters and for their use as templates for nano wire fabrication. Solution method: A numerical approach, based on Huygen's method for optical wavefront calculations has been employed. At any etching time, the etching is assumed to proceed along the normal to the etched surface. Several analytical functions are tried for the variation of the track etch velocity along the ion track as a function of the depth inside the surface and the energy/stopping power of the ion in the medium. Additional comments including Restrictions and Unusual features: The program does not generate three-dimensional profile. Provision for double sided etching will be incorporated in a later version of the code. © 2017 Elsevier B.V.","Chemical etching; Etched track profile; Java code; Track detector","Codes (symbols); Etching; Ions; Nanowires; Numerical methods; Wavefronts; Analytical functions; Chemical etching; Etched tracks; Java codes; Numerical approaches; Solid state nuclear track detectors; Three-dimensional profiles; Track detectors; Java programming language",2-s2.0-85019635277
"Janhunen T., Kaminski R., Ostrowski M., Schellhorn S., Wanko P., Schaub T.","Clingo goes linear constraints over reals and integers",2017,"Theory and Practice of Logic Programming",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032568710&doi=10.1017%2fS1471068417000242&partnerID=40&md5=14cff7c8694912cc24f72c877192be3d","The recent series 5 of the Answer Set Programming (ASP) system clingo provides generic means to enhance basic ASP with theory reasoning capabilities. We instantiate this framework with different forms of linear constraints and elaborate upon its formal properties. Given this, we discuss the respective implementations, and present techniques for using these constraints in a reactive context. More precisely, we introduce extensions to clingo with difference and linear constraints over integers and reals, respectively, and realize them in complementary ways. Finally, we empirically evaluate the resulting clingo derivatives clingo[dl] and clingo[lp] on common language fragments and contrast them to related ASP systems. Copyright © Cambridge University Press 2017.","Answer Set Programming (ASP); Constraint Answer Set Programming (CASP); Constraint Processing (CP); Theory Solving","Logic programming; Answer set programming; Common languages; Constraint processing; Formal properties; Linear constraints; Reasoning capabilities; Theory Solving; Computer programming",2-s2.0-85032568710
"Chaki S., De Niz D.","Formal verification of a timing enforcer implementation",2017,"ACM Transactions on Embedded Computing Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030692775&doi=10.1145%2f3126517&partnerID=40&md5=0924e13a259327b45a09bc97c596d9c1","A timing enforcer is a scheduler that not only allocates CPU cycles to threads, but also uses timers to enforce time budgets. An approach for verifying safety properties of timing enforcers at the source code level is presented. We assume that the enforcer is implemented as a set of ""enforcer"" functions that are executed atomically on critical system-level events, such as the arrival and departure of jobs, and triggering of timers. The key idea is to express the safety property as an invariant, and prove that it is inductive across all the enforcer functions. A formal semantics of timing enforcers is presented, including the semantics of functions used to read the system clock and set timers. Using this semantics, the verification approach is presented, and its soundness proved. Further, the approach also takes into consideration the periodicity of tasks. It is validated by proving the correctness of the enforcement of CPU cycle budgets for tasks by the Zero-Slack Rate Monotonic (zsrm) scheduler, which is implemented in C as a Linux kernel module. The inductiveness of the necessary zsrm invariants is proved by expressing them as function contracts using the acsl specification language, and verifying the contracts using the frama-c tool. © 2017 ACM.","Cyber-physical systems; Real-time scheduler; Software verification","Budget control; Computer operating systems; Cyber Physical System; Embedded systems; Formal methods; Formal verification; Real time systems; Scheduling; Semantics; Specification languages; Timing circuits; Verification; Critical systems; Formal Semantics; Linux kernel; Rate-monotonic; Real-time schedulers; Safety property; Software verification; System clock; C (programming language)",2-s2.0-85030692775
"Angelini G., Bonanni T., Corsini A., Delibra G., Tieghi L., Volponi D.","Optimization of an axial fan for air cooled condensers",2017,"Energy Procedia",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030687644&doi=10.1016%2fj.egypro.2017.08.236&partnerID=40&md5=f24c326f8d3e1cdf84c75331d863d916","We report on the low noise optimization of an axial fan specifically designed for the cooling of CSP power plants. The duty point presents an uncommon combination of a load coefficient of 0.11, a flow coefficient of 0.23 and a static efficiency ηstat &gt; 0.6. Calculated fan Reynolds number is equal to Re = 2.85 × 107. Here we present a process used to optimize and numerically verify the fan performance. The optimization of the blade was carried out with a Python code through a brute-force-search algorithm. Using this approach the chord and pitch distributions of the original blade are varied under geometrical constraints, generating a population of over 200000 different possible individuals. Each individual was then tested using an axisymmetric Python code. The software is based on a blade element axisymmetric principle whereby the rotor blade is divided into a number of streamlines. For each of these streamlines, relationships for velocity and pressure are derived from conservation laws for mass, tangential momentum and energy of incompressible flows. The final geometry was eventually chosen among the individuals with the maximum efficiency. The final design performance was then validated through with a CFD simulation. The simulation was carried out using a RANS approach, with the cubic k-ϵ low Reynolds turbulence closure of Lien et al. The numerical simulation was able to verify the air performance of the fan and was used to derive blade-to-blade distributions of design parameters such as flow deviation, velocity components, specific work and diffusion factor of the optimized blade. All the computations were performed in OpenFOAM, an open source C++- based CFD library. © 2017 The Author(s).","Axial flow fan; low-noise optimization; OpenFOAM; reduced-order simulations","Air; Axial flow; Axial flow turbomachinery; C (programming language); Constraint satisfaction problems; Fans; High level languages; Open source software; Plant shutdowns; Reynolds number; Air-cooled condensers; Axial flow fan; Geometrical constraints; Low noise; OpenFOAM; Reduced order; Tangential momentum; Turbulence closures; Computational fluid dynamics",2-s2.0-85030687644
"Rioualen C., Da Costa Q., Chetrit B., Charafe-Jauffret E., Ginestier C., Bidaut G.","HTS-Net: An integrated regulome-interactome approach for establishing network regulation models in high-throughput screenings",2017,"PLoS ONE",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029898856&doi=10.1371%2fjournal.pone.0185400&partnerID=40&md5=58ef71e0be296f7217f479706e1b454e","High-throughput RNAi screenings (HTS) allow quantifying the impact of the deletion of each gene in any particular function, from virus-host interactions to cell differentiation. However, there has been less development for functional analysis tools dedicated to RNAi analyses. HTS-Net, a network-based analysis program, was developed to identify gene regulatory modules impacted in high-throughput screenings, by integrating transcription factors-target genes interaction data (regulome) and protein-protein interaction networks (interactome) on top of screening z-scores. HTS-Net produces exhaustive HTML reports for results navigation and exploration. HTS-Net is a new pipeline for RNA interference screening analyses that proves better performance than simple gene rankings by z-scores, by re-prioritizing genes and replacing them in their biological context, as shown by the three studies that we reanalyzed. Formatted input data for the three studied datasets, source code and web site for testing the system are available from the companion web site at http://htsnet.marseille.inserm.fr/. We also compared our program with existing algorithms (CARD and hotnet2). © 2017 Rioualen et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",,"algorithm; Article; conceptual framework; controlled study; gene interaction; genetic database; high throughput screening; intermethod comparison; protein protein interaction; RNA analysis; RNA interference; software; web browser; biological model; cell differentiation; computer language; cytology; embryonic stem cell; gene regulatory network; Hepacivirus; high throughput sequencing; human; physiology; procedures; validation study; virus replication; Algorithms; Cell Differentiation; Databases, Genetic; Embryonic Stem Cells; Gene Regulatory Networks; Hepacivirus; High-Throughput Nucleotide Sequencing; Humans; Models, Genetic; Programming Languages; RNA Interference; Virus Replication",2-s2.0-85029898856
"Kannimoola J.M., Jayaraman B., Tambay P., Achuthan K.","Temporal constrained objects: Application and implementation",2017,"Computer Languages, Systems and Structures",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018583483&doi=10.1016%2fj.cl.2017.03.002&partnerID=40&md5=a45cb02451d7e00a14d0c9d764773c3a","We present a novel programming concept called temporal constrained objects for modeling of dynamic systems. It is an extension of the paradigm of constrained objects which provides a principled approach to modeling complex engineering systems based upon two main principles: a compositional specification of the structure of the system, using objects, and a declarative specification of its behavior, using constraints. A novel feature of temporal constrained objects is the series variable, the sequence of whose values is determined by constraints that include metric temporal operators. The emergent behavior of a dynamic system is determined through a process of time-based simulation and constraint satisfaction at each step. Each class definition for a temporal constrained object is translated into a Prolog rule with constraint-solving capability. In order to improve the performance for long simulations, a partial evaluation technique is adopted for optimized code generation. This paper describes the syntax of a language called TCOB along with several examples, our objective being to demonstrate the benefits of the programming paradigm. TCOB has been implemented and all examples presented in this paper were tested using this implementation. An overview of the translation as well as partial execution and its performance improvements are presented in the paper. © 2017 Elsevier Ltd","Compositional modeling; Constrained objects; Constraints; Implementation; Metric temporal operators; Objects; Partial evaluation; Performance; Series variables","Dynamical systems; Specifications; Compositional modeling; Constrained objects; Constraints; Implementation; Objects; Partial evaluation; Performance; Series variables; Temporal operators; PROLOG (programming language)",2-s2.0-85018583483
"Czerwiński W., David C., Losemann K., Martens W.","Deciding definability by deterministic regular expressions",2017,"Journal of Computer and System Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017333617&doi=10.1016%2fj.jcss.2017.03.011&partnerID=40&md5=59469a8c3adb45558786b184bbb2d8f2","We investigate the complexity of deciding whether a given regular language can be expressed by a deterministic regular expression. Our main technical result shows that deciding if the language of a given regular expression (or, non-deterministic finite automaton) can be defined by a deterministic regular expression is PSPACE-complete. The problem becomes EXPSPACE-complete if the input language is represented as a regular expression with counters and NL-hard if the input language is given by a minimal deterministic finite automaton. © 2017 Elsevier Inc.","Complexity; Definability; Determinism; Regular expressions","Pattern matching; Complexity; Definability; Determinism; Deterministic finite automata; Deterministic regular expressions; Nondeterministic finite automaton; PSPACE-complete; Regular expressions; Computer programming languages",2-s2.0-85017333617
"Hanazumi S., de Melo A.C.V.","A Formal Approach to implement java exceptions in cooperative systems",2017,"Journal of Systems and Software",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84981736041&doi=10.1016%2fj.jss.2016.07.033&partnerID=40&md5=ff70044b316a822095688ade600726fc","The increasing number of systems that work on the top of cooperating elements have required new techniques to control cooperation on both normal and abnormal behaviors of systems. The controllability of the normal behaviors has received more attention because they are concerned with the users expectations, while for the abnormal behaviors it is left to designers and programmers. However, for cooperative systems, the abnormal behaviors, mostly represented by exceptions at programming level, become an important issue in software development because they can affect the overall system behavior. If an exception is raised and not handled accordingly, the system may collapse. To avoid such situation, certain concepts and models have been proposed to coordinate propagation and recovering of exceptional behaviors, including the Coordinated Atomic Actions (CAA). Regardless of the effort in creating these conceptual models, an actual implementation of them in real systems is not very straightforward. This article provides a reliable framework for the implementation of Java exceptions propagation and recovery using CAA concepts. To do this, a Java framework (based on a formal specification) is presented, together with a set of properties to be preserved and proved with the Java Pathfinder (JPF) model checker. In practice, to develop new systems based on the given coordination concepts, designers/programmers can instantiate the framework to implement the exceptional behavior and then verify the correctness of the resulting code using JPF. Therefore, by using the framework, designers/programmers can reuse the provided CAA implementation and instantiate fault-tolerant Java systems. © 2016 Elsevier Inc.","concurrent exception handling; Coordinated atomic actions model; java framework; program verification","Computer software; Concurrency control; Model checking; Software design; Abnormal behavior; Atomic actions; Co-operative systems; Coordinate propagation; Exception handling; Java framework; Program Verification; Reliable frameworks; Java programming language",2-s2.0-84981736041
"Sewell T., Kam F., Heiser G.","High-assurance timing analysis for a high-assurance real-time operating system",2017,"Real-Time Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026916437&doi=10.1007%2fs11241-017-9286-3&partnerID=40&md5=eaf910e32ec108a527493c1e0120e82c","Worst-case execution time (WCET) analysis of real-time code needs to be performed on the executable binary code for soundness. Obtaining tight WCET bounds requires determination of loop bounds and elimination of infeasible paths. The binary code, however, lacks information necessary to determine these bounds. This information is usually provided through manual intervention, or preserved in the binary by a specially modified compiler. We propose an alternative approach, using an existing translation-validation framework, to enable high-assurance, automatic determination of loop bounds and infeasible paths. We show that this approach automatically determines all loop bounds and many (possibly all) infeasible paths in the seL4 microkernel, as well as in standard WCET benchmarks which are in the language subset of our C parser. We also design and validate an improvement to the seL4 implementation, which permits a key part of the kernel’s API to be available to users in a mixed-criticality setting. © 2017, Springer Science+Business Media, LLC.","High assurance; OS; Real time; seL4; Static analysis; Timing; Verified; WCET; Worst case","Binary codes; Bins; Codes (symbols); Computer operating systems; Osmium; Program compilers; Static analysis; Timing circuits; High assurance; Real time; seL4; Timing; Verified; WCET; C (programming language)",2-s2.0-85026916437
"Kim Y.-K., Lee Y.-H., Moon B.","A study of partitioned DIMM tree management for multimedia server systems",2017,"Multimedia Tools and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960119985&doi=10.1007%2fs11042-016-3382-6&partnerID=40&md5=8092d08341f99cbb6c4be49ec677726f","In-memory computing systems have been attracting considerable attention as a method for servicing high-quality multimedia contents. In-memory computing was intended to store entire data sets in the main memory of a computer to eliminate the need to access slow mechanical hard discs and increase the ability to process complex and large volumes of data. Prior studies have proposed a dual inline memory module (DIMM) tree architecture (DTA) as a new structure for implementing the in-memory computing system. The DTA can apply a partitioned DIMM tree policy to efficiently manage memory. However, the partitioned DIMM tree has several drawbacks, including hardware overhead resulting from additional fields in both the translation lookaside buffer (TLB) and the page table and the demand for an additional fast partition area for the fast partition page table (FPPT). To overcome these drawbacks, this paper proposes an advanced TLB management policy for the partitioned DIMM tree, DIMM tree TLB and two new partitioned DIMM tree management policies, fast-FPPT and slow-FPPT. We model the proposed policies using C language and verify them by special workloads in experiments employing a large-capacity memory system. The experimental results show how the proposed policies influence system performance and confirm that they overcome problems in the existing DTA. The simulations revealed a similarity between the performance of systems using the proposed policies and that of the existing DTA model. However, as the proposed policies demand a considerably lower hardware cost than the existing DTA model, the proposed policies are more practical. © 2016, Springer Science+Business Media New York.","Big memory server; DIMM tree architecture; In-memory computing; Main memory; Multimedia server system","Buffer storage; C (programming language); Computer architecture; Computer hardware; Forestry; Hardware; Reconfigurable hardware; Hardware overheads; Main memory; Memory servers; Multimedia contents; Multimedia servers; Performance of systems; Translation lookaside buffer; Tree architectures; Memory architecture",2-s2.0-84960119985
"Zhang Y., Kong X., Guo L., Yu X., Dai C., Shao J.","Simulation and experiment of starting transient flow field of the hydrostatic bearing based on dynamic mesh method",2017,"High Technology Letters",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030655790&doi=10.3772%2fj.issn.1006-6748.2017.03.011&partnerID=40&md5=9d374e5c0f01ce58cbe23b456403d747","A new method is developed to assess and analyze the dynamic performance of hydrostatic bearing oil film by using an amulets-layer dynamic mesh technique. It is implemented using C Language to compile the UDF program of a single oil film of the hydrostatic bearing. The effects of key lubrication parameters of the hydrostatic bearing are evaluated and analyzed under various working conditions, i.e. under no-load, a load of 40 t, a full load of 160 t, and the rotation speed of 1 r/min, 2 r/min, 4 r/min, 8 r/min, 16 r/min, 32 r/min. The transient data of oil film bearing capacity under different load and rotation speed are acquired for a total of 18 working conditions during the oil film thickness changing. It allows the effective prediction of dynamic performance of large size hydrostatic bearing. Experiments on hydrostatic bearing oil film have been performed and the results were used to define the boundary conditions for the numerical simulations and validate the developed numerical model. The results showed that the oil film thickness became thinner with the increase of the operating time of the hydrostatic bearing, both the oil film rigidity and the oil cavity pressure increased significantly, and the increase of the bearing capacity was inversely proportional to the cube of the change of the film thickness. Meanwhile, the effect of the load condition on carrying capacity of large size static bearing was more important than the speed condition. The error between the simulation value and the experimental value was 4.25%. Copyright © by HIGH TECHNOLOGY LETTERS PRESS.","Dynamic mesh; Hydrostatic bearing; Oil pad; Transient data; UDF","Bearing capacity; C (programming language); Film thickness; Hydraulics; Lubricating oils; Mesh generation; Numerical models; Rotation; Dynamic mesh; Dynamic mesh technique; Dynamic performance; Experimental values; Oil film thickness; Oil pad; Starting transient; Transient data; Hydrostatic bearings",2-s2.0-85030655790
"Mushore T.D., Odindi J., Dube T., Mutanga O.","Prediction of future urban surface temperatures using medium resolution satellite data in Harare metropolitan city, Zimbabwe",2017,"Building and Environment",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030566441&doi=10.1016%2fj.buildenv.2017.06.033&partnerID=40&md5=77c6a28162dba7753f455156ece99a1c","The objective of the study was to determine the impact of urban growth on future micro-climate of Harare by predicting future distribution of land use and land cover, as well as land surface temperature using Cellular Automata Markov Chain analysis. Landsat series data was used to map Land Use and Land Cover (LULC) and land surface temperature distribution during the month of October for the year 1984, 1993, 2001 and 2015. The Cellular Automata Markov Chain analysis was used to determine long term landscape transformation at 10-year time steps from 2015 to 2045. We further tested the potential of a variety of vegetation and non-vegetation indices to predict land surface temperature. Results show that the Urban Index (UI), non-vegetation index was the best predictor of surface temperature, since it had the highest correlation with retrieved surface temperature (r = 0.9831). When tested against temperature derived from thermal band in October 2015, the mean absolute percentage error of the UI derived temperature was 5.27%. Based on changes which occurred between 1984 and 2015, the Cellular Automata Markov Chain analysis predicted that high density built-up areas will increase monotonically from 470.02 in 2015 to 490.36 km2 in 2045. Green spaces were predicted as decreasing from 57.42 to 27.85 km2, while croplands also decrease from 30.27 to 16.93 km2 between 2015 and 2040. Using UI as predictor of land surface temperature, we predicted that the 18–28 °C class will decrease in coverage between 2015 and 2040, while the 36–45 °C category will increase in proportion covered from 42.5 to 58% of city. We concluded that continued urban growth will increase warming and result in high future temperatures unless mitigation efforts are strengthened. The findings of this study are important in informing future development of cities to consider growth implications on future temperatures and thermal comfort of urban residents. © 2017 Elsevier Ltd","Cellular automata markov; Harare; Land surface temperature; Markov chain analysis; Urban growth; Urban growth; Vegetation indices","C (programming language); Cellular automata; Chains; Forecasting; Land use; Markov processes; Surface measurement; Surface properties; Urban growth; Vegetation; Harare; Land surface temperature; Land use and land cover; Markov chain analysis; Mean absolute percentage error; Surface temperatures; Urban surface temperature; Vegetation index; Atmospheric temperature",2-s2.0-85030566441
"Laugraud B., Piérard S., Van Droogenbroeck M.","LaBGen: A method based on motion detection for generating the background of a scene",2017,"Pattern Recognition Letters",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007554530&doi=10.1016%2fj.patrec.2016.11.022&partnerID=40&md5=ceb32ba164765704a42a5f52dd022901","Given a video sequence acquired with a fixed camera, the generation of the stationary background of the scene is a challenging problem which aims at computing a reference image for a motionless background. For that purpose, we developed our method named LaBGen, which emerged as the best one during the Scene Background Modeling and Initialization (SBMI) workshop organized in 2015, and the IEEE Scene Background Modeling Contest (SBMC) organized in 2016. LaBGen combines a pixel-wise temporal median filter and a patch selection mechanism based on motion detection. To detect motion, a background subtraction algorithm decides, for each frame, which pixels belong to the background. In this paper, we describe the LaBGen method extensively, evaluate it on the SBI 2016 dataset and compare its performance with other background generation methods. We also study its computational complexity, the performance sensitivity with respect to its parameters, and the stability of the predicted background image over time with respect to the chosen background subtraction algorithm. We provide an open source C++ implementation at http://www.telecom.ulg.ac.be/labgen. © 2016 Elsevier B.V.","Background generation; Background subtraction; Median filter; Motion detection; SBI dataset","C++ (programming language); Motion analysis; Motion compensation; Pixels; Background generations; Background image; Background model; Background subtraction; Background subtraction algorithms; Motion detection; Performance sensitivity; SBI dataset; Median filters",2-s2.0-85007554530
"Bowie D., Cruickshank C.A.","Experimental evaluation of a triple-state sorption chiller [Évaluation expérimentale d'un refroidisseur à sorption tri-étagé]",2017,"International Journal of Refrigeration",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021182318&doi=10.1016%2fj.ijrefrig.2017.05.009&partnerID=40&md5=36189da6ebbf8e562d16b070378f4359","This paper presents the experimental testing results of a novel triple-state sorption chiller with integrated cold storage. The performance of the chiller was measured for hot water inlet temperatures between 65 °C and 95 °C, heat rejection inlet temperatures between 15 °C and 35 °C, and chilled water inlet temperatures between 10 °C and 25 °C. An empirical model was developed for implementation in the TRaNsient SYstem Simulation (TRNSYS) software. To validate the model, a five-hour experimental charge test was conducted during which the hot water and heat rejection inlet temperatures were continuously varied. The model was able to predict the total heat input and heat rejection energy to within 0.7% and 1.3% of the experimentally measured values, respectively. © 2017","Experimental testing; Modelling; Simulation; Sorption chiller; TRNSYS","C (programming language); Cold storage; Computer software; Cooling systems; Heat sinks; Models; Water; Empirical model; Experimental evaluation; Experimental testing; Inlet temperature; Measured values; Simulation; Transient systems; TRNSYS; Sorption",2-s2.0-85021182318
"Nadji Y., Perdisci R., Antonakakis M.","Still Beheading Hydras: Botnet Takedowns Then and Now",2017,"IEEE Transactions on Dependable and Secure Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029577840&doi=10.1109%2fTDSC.2015.2496176&partnerID=40&md5=cf49a0669089be26ee61ec2350fc3d7e","Devices infected with malicious software typically form botnet armies under the influence of one or more command and control (C&C) servers. The botnet problem reached such levels where federal law enforcement agencies have to step in and take actions against botnets by disrupting (or 'taking down') their C&Cs, and thus their illicit operations. Lately, more and more private companies have started to independently take action against botnet armies, primarily focusing on their DNS-based C&Cs. While well-intentioned, their C&C takedown methodology is in most cases ad-hoc, and limited by the breadth of knowledge available around the malware that facilitates the botnet. With this paper, we aim to bring order, measure, and reason to the botnet takedown problem. We improve an existing takedown analysis system called rza. Specifically, we examine additional botnet takedowns, enhance the risk calculation to use botnet population counts, and include a detailed discussion of policy improvements that can be made to improve takedowns. As part of our system evaluation, we perform a postmortem analysis of the recent 3322.org, Citadel, and No-IP takedowns. © 2004-2012 IEEE.","K.5.m; K.6.m","C (programming language); Cesium; Computer crime; Malware; Analysis system; Command and control; K.5.m; K.6.m; Postmortem analysis; Private companies; Risk calculation; System evaluation; Botnet",2-s2.0-85029577840
"Mallakpour S., Jarang N.","Exploration of the role of modified titania nanoparticles with citric acid and vitamin C in improvement of thermal stability, optical property, and mechanical behavior of novel poly(vinyl chloride) nanocomposite films",2017,"Journal of Vinyl and Additive Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029349246&doi=10.1002%2fvnl.21526&partnerID=40&md5=d654d868dc984202136ef32ef9af7bfa","In the present work, first the hydrophilic surface of titanium dioxide nanoparticles (TiO2 NPs) was modified with citric acid and then with vitamin C as bilayer surface modification for better compatibility with poly(vinyl chloride) (PVC) matrix. The process was accomplished under ultrasonic method as a fast, low-cost, and green method. The modified TiO2 NPs were incorporated into the PVC matrix using the ultrasonic method. The resulting films (4, 8, and 12 wt%) were characterized by various techniques, including Fourier-transform infrared spectroscopy, X-ray diffraction, thermal gravimetric analysis, ultraviolet-Visible analysis, and mechanical tensile test, and their morphology was investigated by field emission scanning electron microscopy and transmission electron microscopy. The appearance of new peaks (carbonyl group) and also its shift in the Fourier-transform infrared spectrum of modified TiO2 NPs confirmed the presence of citric acid and vitamin C on the surface of the NPs. The resulting data of thermal gravimetric analysis showed improvement in thermal stability of the NC films. Also, strain and elongation of the samples increased in comparison with the pure PVC. J. VINYL ADDIT. TECHNOL., 23:E15–E24, 2017. © 2015 Society of Plastics Engineers. © 2015 Society of Plastics Engineers",,"Chlorine compounds; Citric acid; Electron microscopy; Field emission microscopes; Fourier transform infrared spectroscopy; Gravimetric analysis; High resolution transmission electron microscopy; Nanocomposite films; Nanoparticles; Optical properties; Plastic products; Polyvinyl chlorides; Scanning electron microscopy; Surface treatment; Tensile testing; Thermodynamic stability; Thermogravimetric analysis; Titanium dioxide; Transmission electron microscopy; X ray diffraction; Field emission scanning electron microscopy; Fourier transform infrared spectra; Hydrophilic surfaces; Mechanical behavior; Mechanical tensile tests; Thermal gravimetric analysis; Titanium dioxide nanoparticles; Ultraviolet visible analysis; C (programming language)",2-s2.0-85029349246
"Inoue N.","Analysis of six aromatic amines stability in workplace measurement",2017,"Journal of Analytical Chemistry",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028632518&doi=10.1134%2fS1061934817090076&partnerID=40&md5=23a57ac313e8651582f8f7220733bb4b","For aromatic amine determination in workplaces, stabilities of six types of carcinogenic aromatic amines (2,4-diaminotoluene, 4,4'-diamino-3,3'-dimethyldiphenylmethane, o-tolidine, 3,3'-dichlorobenzidine, 4,4'-methylenebis(2-chloroaniline), and o-dianisidine) were evaluated with air or argon gas bubbling for 45 min in aqueous solution under light irradiation (desk lamp) and heating conditions. Gas chromatography–mass spectrometry (GC–MS) was used to identify and quantify the aromatic amines. The following conditions were selected: temperature program 70°C (1 min), 7 grad/min up to 120°C (1 min), 10 grad/min up to 300°C (5 min), carrier gas flow rate 1.0 mL/min. 3,3'-Dichlorobenzidine concentration decreased by approximately 10% after irradiation with a desk lamp for 45 min in distilled water, and a monochloro compound was detected by GC–MS. The other aromatic amines were rarely different from the 0-min concentration. The shielding prevented the decomposition of 3,3'-dichlorobenzidine in distilled water. © 2017, Pleiades Publishing, Ltd.","3,3'-dichlorobenzidine; aromatic amine; decomposition; shielding; workplace","Argon; Aromatic compounds; Aromatization; Bubble formation; C (programming language); Decomposition; Flow of gases; Gas chromatography; Irradiation; Mass spectrometry; Shielding; Solutions; Aromatic amines; Carcinogenic aromatic amines; Carrier gas flow rates; Dichlorobenzidine; Dimethyldiphenylmethane; Heating conditions; Light irradiations; workplace; Amines",2-s2.0-85028632518
"Song Z., Liu X., Zhao X., Liu Q., Jin Z., Chi B.","A Low-Power NB-IoT Transceiver With Digital-Polar Transmitter in 180-nm CMOS",2017,"IEEE Transactions on Circuits and Systems I: Regular Papers",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021758985&doi=10.1109%2fTCSI.2017.2707412&partnerID=40&md5=af677e41a298f6c40d9021b099f92663","A fully integrated 750960 MHz wireless transceiver (TRX) is presented for single-tone NB-IoT applications. Effective design methodologies and techniques, from the system level to circuit level, are proposed to address various design challenges while achieving low-power consumption. The TRX consists of a low-IF receiver with 180-kHz signal bandwidth, a digital polar transmitter with 3.75-kHz signal bandwidth, and a fractional-N frequency synthesizer. Passive current mixer is employed in the receiver to improve the linearity and avoid the sensitivity degradation due to 1/ {f} noise. Automatic I/Q imbalance calibration is integrated to improve image rejection ratio (IRR) with the aid of external FPGA. The transmitter is implemented in the digital polar architecture to improve the narrow-band spectrum purity, integrated with an inverse Class-D digital power amplifier (DPA) to achieve high output power and efficiency. A Class-C voltage-controlled oscillator with automatic frequency control assisted the dynamic gate biasing technique is used in the fractional-N PLL frequency synthesizer. Two prototypes are implemented in 180-nm CMOS. By optimizing analog baseband configuration in the receiver and utilizing the revised thermometer-coding and binary-coding-based array placement in the DPA, the receiver achieves 4.0-dB noise figure, 48-dB IRR, and 60-dB PGA dynamic range, and the DPA outputs 23.2dBm maximum saturation power with 44.5% PAE. Furthermore, the transmitter system verifications demonstrate 3.87% error-vector magnitude (EVM) for 891 MHz \pi /4-DQPSK signals at 18.87-dBm output power with -40-dBc out-of-band rejection. The transmitter achieves a dynamic range from -35 to 20 dBm when the demodulation EVM threshold of the system is set to 10%. © 2004-2012 IEEE.","CMOS; digital power amplifier; digital transmitter; NB-IoT; polar transmitter; RF; wireless transceiver","Bandwidth; C (programming language); CMOS integrated circuits; Frequency synthesizers; Integrated circuit design; Internet of things; Low power electronics; Oscillistors; Power amplifiers; Programmed control systems; Signal receivers; Transceivers; Transmitters; Automatic frequency control; Digital power amplifiers; Digital transmitters; Error vector magnitude; Fractional-N frequency synthesizers; Image rejection ratios; Polar transmitter; Wireless transceiver; Radio transceivers",2-s2.0-85021758985
"Feng B., Shi Z., Chang Z., Liu H., Zhao Y.","110 °C range athermalization of wavefront coding infrared imaging systems",2017,"Infrared Physics and Technology",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021204572&doi=10.1016%2fj.infrared.2017.05.020&partnerID=40&md5=12f62149b7804ad727fabcd7a5fadda2","110 °C range athermalization is significant but difficult for designing infrared imaging systems. Our wavefront coding athermalized infrared imaging system adopts an optical phase mask with less manufacturing errors and a decoding method based on shrinkage function. The qualitative experiments prove that our wavefront coding athermalized infrared imaging system has three prominent merits: (1) working well over a temperature range of 110 °C; (2) extending the focal depth up to 15.2 times; (3) achieving a decoded image being approximate to its corresponding in-focus infrared image, with a mean structural similarity index (MSSIM) value greater than 0.85. © 2017 Elsevier B.V.","Athermalization; Computational imaging; Infrared imaging; Wavefront coding","C (programming language); Codes (symbols); Coding errors; Decoding; Image coding; Imaging systems; Infrared imaging; Optical design; Wavefronts; Athermalization; Computational imaging; Manufacturing errors; Mean structural similarity indices; Qualitative experiments; Shrinkage functions; Temperature range; Wave-front coding; Thermography (imaging)",2-s2.0-85021204572
"Yao G.-G., Pei C.-J., Liu P., Xing H.-Y., Fu L.-X., Liang B.-C.","Novel temperature stable Ba1−xSrxV2O6 microwave dielectric ceramics with ultra-low sintering temperature",2017,"Journal of Materials Science: Materials in Electronics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019626276&doi=10.1007%2fs10854-017-7163-4&partnerID=40&md5=ee2a7f3598f1b4683546d37cceb1f35d","New temperature stability Ba1−xSrxV2O6 (0.35 ≤ x ≤ 0.55) microwave dielectric ceramics prepared by the conventional solid-state route were investigated. X-ray diffraction confirmed that all the specimens formed a solid solution single phase with orthorhombic structure. The microwave dielectric properties strongly depended on the compositions, densification and microstructure of the specimens. Furthermore, partial Sr ions substitution for Ba ions in Ba1−xSrxV2O6 lattices not only successfully improved the temperature stability of BaV2O6-based ceramic but also promoted the sinterability of SrV2O6-based one. Out of these compositions, Ba0.5Sr0.5V2O6 sintered at 625 °C exhibited a near-zero τf together with a low permittivity εr ~ 11.5 and a quality factor Q × f ~ 14 100 GHz, which also showed good chemical compatibility with Al electrodes. © 2017, Springer Science+Business Media New York.",,"C (programming language); Ceramic materials; Dielectric properties; Sintering; X ray diffraction; Chemical compatibility; Low sintering temperature; Microwave dielectric ceramics; Microwave dielectric properties; Orthorhombic structures; Solid-state routes; Temperature stability; Temperature stable; Barium",2-s2.0-85019626276
"Anwar S.R.M., Vandenberghe W.G., Bersuker G., Veksler D., Verzellesi G., Morassi L., Galatage R.V., Jha S., Buie C., Barton A.T., Vogel E.M., Hinkle C.L.","Comprehensive Capacitance-Voltage Simulation and Extraction Tool Including Quantum Effects for High-k on SixGe1-x and InxGa1-xAs: Part II-Fits and Extraction from Experimental Data",2017,"IEEE Transactions on Electron Devices",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028743550&doi=10.1109%2fTED.2017.2725741&partnerID=40&md5=7cbb005c497cc3cc31ea77db8451f195","Capacitance-voltage (C-V) measurement and analysis is highly useful for determining important information about MOS gate stacks. Parameters such as the equivalent oxide thickness (EOT), substrate doping density, flatband voltage, fixed oxide charge, density of interface traps (Dit), and effective gate work function can all be extracted from experimental C-V curves. However, to extract these gate-stack parameters accurately, the correct models must be utilized. In Part I, we described the modeling and implementation of a C-V code that can be used for alternative channel semiconductors in conjunction with high-k gate dielectrics and metal gates. Importantly, this new code (CV ACE) includes the effects of nonparabolic bands and quantum capacitance, enabling accurate models to be applied to experimental C-V curves. In this paper, we demonstrate the capabilities of this new code to extract accurate parameters, including EOT and Dit profiles from experimental high-k on Ge and In0.53Ga0.47As gate stacks. © 1963-2012 IEEE.","C-V simulation; CV ACE; Dit extraction; III-V semiconductors; quantum mechanical (QM) effects; thin oxides","Capacitance; Codes (symbols); Extraction; Gallium alloys; Gate dielectrics; Germanium; High-k dielectric; III-V semiconductors; Indium alloys; Interfaces (materials); Logic gates; Quantum electronics; Quantum theory; Semiconductor doping; Si-Ge alloys; Silicon alloys; Capacitance voltage; Capacitance voltage measurements; CV ACE; Equivalent oxide thickness; High- k gate dielectrics; Quantum capacitance; Quantum mechanical effects; Thin oxides; C (programming language)",2-s2.0-85028743550
"Luo P., Zou D., Jin H., Du Y., Shen J.","A dynamic predictive race detector for C/C++ programs",2017,"Journal of Supercomputing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020544643&doi=10.1007%2fs11227-017-1996-8&partnerID=40&md5=01fda8fb54b8e8899fce5092a29845d8","Concurrent techniques have been widely adopted in software systems, and data race has become a great threat to stability and security of concurrent systems. Previous precise race detection techniques either may miss many races, or are only suitable for some specific programs, such as the programs executed in a virtual machine rather than in actual hardware. To solves these problems, this paper introduces a dynamic predictive race detector, called LayDetect, which detects predictable races in C/C++ programs. LayDetect applies an innovative layering technique, which can detect more races than other detectors, such as FastTrack. We have implemented and evaluated LayDetect with well-known benchmarks and real-world applications. LayDetect has detected 3.7 M races at run-time which is more than that of FastTrack by two orders of magnitude, while the average slowdown (3.0×) and space overhead (34.1 MB) of LayDetect are similar to that of FastTrack. © 2017, Springer Science+Business Media New York.","C/C++ programs; Concurrent systems; Data race; Race detection","Benchmarking; C/C++ programs; Concurrent systems; Data races; Layering techniques; Orders of magnitude; Race detection; Software systems; Space overhead; C (programming language)",2-s2.0-85020544643
"Aouissi Z., Mahjoub H.F., Aschi A., Othman T.","Temperature study of Ficoll400 aqueous solutions, evidence of bad solvent around 35 °C",2017,"Journal of Molecular Liquids",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020792365&doi=10.1016%2fj.molliq.2017.06.030&partnerID=40&md5=74c97d4b2fbebdfe6a123a74bd9d85c5","In the present work, we have applied Dynamic Light Scattering (DLS) and rheological measurements in order to assess the most important characteristics of Ficoll400 (Mw = 400 kDa). We evaluate the effect of temperature and concentration on rheological proprieties and on the size and shape of Ficoll400 entities. DLS experiments indicated the coexistence of tow closely-spaced diffusive modes in aqueous solution by analyzing the spectra with double exponential fits. Interaction parameters determined from the development of the diffusion coefficients and the dynamic viscosity in function of Ficoll400 concentration showed an unknown behavior when temperature is varied carefully between 15 °C and 60 °C. These results are discussed in the context of two-coexisting Ficoll400 populations feeling bad solvent around 35 °C simultaneously with associative character prevailing among all Ficoll400 objects. © 2017 Elsevier B.V.","Associativity; Dynamic Light Scattering; Ficoll400; Huggins constant; Viscosity","Dynamic light scattering; Light scattering; Solutions; Viscosity; Associativity; Double exponential; Dynamic viscosities; Effect of temperature; Ficoll<sub>400</sub>; Huggins constant; Interaction parameters; Rheological measurements; C (programming language)",2-s2.0-85020792365
"Liu H., Xie J., Zhang Z., Zhang Z., Wang G., Pei Y., Zhao B., Zhang J.","Polymer with conjugated alkylthiophenylthienyl side chains for efficient photovoltaic cells",2017,"Organic Electronics: physics, materials, applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020768997&doi=10.1016%2fj.orgel.2017.06.011&partnerID=40&md5=d491eb551f02e3af08124438cd185dfa","A donor-acceptor (D-A) conjugated copolymer PSBT-FTT, incorporating alkylthiophenylthienyl (SBT) side chains on benzo[1,2-b:4,5-b']dithiophene units (BDT), was designed and synthesized. Compared to the analogical polymer PSB-FTT with alkylthiophenyl (SB) side chains, PSBT-FTT exhibits stronger interchain π-π interaction, more redshifted absorption spectrum, stronger absorption coefficient, better compatibility with (7,7)-phenyl-C71-butyric acid methyl ester (PC71BM), more effective exciton dissociation and higher hole mobility. Therefore, the PSBT-FTT-based bulk heterojunction polymer solar cells (PSCs) achieved a PCE value of 7.06% that is almost 50% higher than 4.83% of the PSB-FTT based PSCs. The result indicates that the introducing SBT side chains is an excellent strategy for designing high performance photovoltaic polymers. © 2017 Elsevier B.V.","Alkylthiophenylthienyl side chains; Benzo[1,2-b:4,5-b']dithiophene; Polymer solar cells; Side-chain engineering; Structure-property relationship","Absorption spectroscopy; Butyric acid; C (programming language); Cell engineering; Chains; Conjugated polymers; Heterojunctions; Hole mobility; Photoelectrochemical cells; Photovoltaic cells; Polymers; Professional aspects; Solar cells; Absorption co-efficient; Benzo[1,2-b:4,5-b']dithiophene; Conjugated copolymers; Exciton dissociation; Polymer solar cell (PSCs); Redshifted absorption; Side-chains; Structure property relationships; Polymer solar cells",2-s2.0-85020768997
"Farooq S.U., Quadri S.M.K., Ahmad N.","A replicated empirical study to evaluate software testing methods",2017,"Journal of Software: Evolution and Process",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028991133&doi=10.1002%2fsmr.1883&partnerID=40&md5=4422b3345f29edaa537ad792907cbf2c","Many empirical studies have been performed to evaluate software testing methods in past decades. However, we are still not able to generalize the results as most studies are not complete and differ significantly from one another. To contribute to the existing knowledge base of software testing methods, we performed an empirical study to evaluate 3 testing methods: (1) code reading by stepwise abstraction, (2) functional testing using equivalence partitioning and boundary value analysis, and (3) structural testing using 100% branch, multiple-condition, loop, and relational-operator coverage using a well-defined and standard schema. A controlled experiment is performed with 18 subjects who applied the 3 defect detection techniques to 3 C programs in a fractional factorial experimental design to observe failures and isolate faults. The experimental results show that (1) the techniques are equally effective in terms of observing failures and finding faults, (2) the effectiveness of the techniques depends on the nature of the program, (3) all the testing techniques are equally efficient in case of failure observation, (4) the techniques are different in their efficiency in terms of fault isolation where code reading performed better than that of structural and functional testing, and (5) with respect to the fault types, all the techniques were equally effective in observing failures and isolating faults except in case of cosmetic faults where functional testing performed better than the other 2 techniques The effectiveness and efficiency of testing techniques were significantly influenced by the type of program. The results presented in this paper contribute to an empirical knowledge base of testing methods and may be helpful for the software engineers to decide the appropriate techniques in improving the software testing process. Copyright © 2017 John Wiley & Sons, Ltd.","code reading; comparison of testing methods; empirical study; functional testing; replication; structural testing","C (programming language); Codes (symbols); Design of experiments; Efficiency; Knowledge based systems; code reading; Empirical studies; Functional testing; replication; Structural testing; Testing method; Software testing",2-s2.0-85028991133
"Bansal R., Bhusan Samal H., Gowri V.S., Sankar Sen S., Ghosh I., Madhubala R.","The cytochrome P450 complement (CYPome) of leishmania leads to the discovery of a plant like cytochrome P450 sub-family CYP710C1 gene",2017,"Proceedings of the Indian National Science Academy",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031318853&doi=10.16943%2fptinsa%2f2017%2f49026&partnerID=40&md5=ae5b79bca9928564e8092a29574dee96","Cytochrome P450 (CYP) is a super-family of heme-containing monooxygenases and is involved in the metabolism of endogenous xenobiotic compounds. A genome-wide analysis of the complete cytochrome P450 complement (CYPome) in Leishmania species is presented here. Genome database search algorithms of 20 strains of Leishmania species and 3 strains of Trypanosoma brucei was employed to describe the complete CYPome. Motif search analysis and phylogenetic studies were carried out to investigate the sequence diversity and distribution of different CYPs in Leishmania in comparison to fungi, humans, plants and prokaryotes. In silico analysis predicted the presence of genes belonging to CYP51 and a plantlike CYP710C gene that encodes a plant-like sterol C-22 desaturase, a key enzyme in stigmasterol biosynthesis. This is the first report for the comparative analysis of stigma sterol biosynthetic pathway genes in Leishmania donovani, Arabidopsis thaliana and Candida albicans. We provide experimental evidence of stigmasterol presence in L. donovani promastigotes. We further demonstrate that amphotericin B-resistant L. donovani accumulated stigmasterol as the major sterol and ergosterol to a lesser extent. In conclusion, this study is presumably the first comprehensive report on CYPome of Leishmania and molecular evidence of a plant-like sterol C-22 desaturase gene in Leishmania.","C-22 Desaturase; CYPome; Cytochrome P450 Complement; Leishmania; Stigmasterol","Alcohols; Biochemistry; Biosynthesis; Genes; Search engines; CYPome; Cytochrome p450; Desaturase; Leishmania; Stigmasterol; C (programming language)",2-s2.0-85031318853
"Boeing G.","OSMnx: New methods for acquiring, constructing, analyzing, and visualizing complex street networks",2017,"Computers, Environment and Urban Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030468447&doi=10.1016%2fj.compenvurbsys.2017.05.004&partnerID=40&md5=a5718d98e57f28d431a2dcdbcc476848","Urban scholars have studied street networks in various ways, but there are data availability and consistency limitations to the current urban planning/street network analysis literature. To address these challenges, this article presents OSMnx, a new tool to make the collection of data and creation and analysis of street networks simple, consistent, automatable and sound from the perspectives of graph theory, transportation, and urban design. OSMnx contributes five significant capabilities for researchers and practitioners: first, the automated downloading of political boundaries and building footprints; second, the tailored and automated downloading and constructing of street network data from OpenStreetMap; third, the algorithmic correction of network topology; fourth, the ability to save street networks to disk as shapefiles, GraphML, or SVG files; and fifth, the ability to analyze street networks, including calculating routes, projecting and visualizing networks, and calculating metric and topological measures. These measures include those common in urban design and transportation studies, as well as advanced measures of the structure and topology of the network. Finally, this article presents a simple case study using OSMnx to construct and analyze street networks in Portland, Oregon. © 2017 Elsevier Ltd","Complex networks; GIS; OpenStreetMap; Python; Resilience; Street network; Transportation; Urban design; Urban form; Visualization","Complex networks; Computer programming languages; Flow visualization; Geographic information systems; Graph theory; Topology; Transportation; Urban planning; OpenStreetMap; Python; Resilience; Street network; Urban design; Urban form; Urban transportation",2-s2.0-85030468447
"Martínez S., Cosentino V., Cabot J.","Model-based analysis of Java EE web security misconfigurations",2017,"Computer Languages, Systems and Structures",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013392323&doi=10.1016%2fj.cl.2017.02.001&partnerID=40&md5=7d0b5c4195f6f626e9bc008d4fdbab18","The Java EE framework, a popular technology of choice for the development of web applications, provides developers with the means to define access-control policies to protect application resources from unauthorized disclosures and manipulations. Unfortunately, the definition and manipulation of such security policies remains a complex and error prone task, requiring expert-level knowledge on the syntax and semantics of the Java EE access-control mechanisms. Thus, misconfigurations that may lead to unintentional security and/or availability problems can be easily introduced. In response to this problem, we present a (model-based) reverse engineering approach that automatically evaluates a set of security properties on reverse engineered Java EE security configurations, helping to detect the presence of anomalies. We evaluate the efficacy and pertinence of our approach by applying our prototype tool on a sample of real Java EE applications extracted from GitHub. © 2017 Elsevier Ltd","Model-driven engineering; Reverse-engineering; Security","Access control; Reverse engineering; Semantics; Access control mechanism; Access control policies; Model-based analysis; Model-driven Engineering; Security; Security configurations; Security properties; Unauthorized disclosures; Java programming language",2-s2.0-85013392323
"El Matarawy A.","New temperature controlling mechanism for thermal metrology regulation at NIS-Egypt",2017,"Journal of Thermal Analysis and Calorimetry",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017107462&doi=10.1007%2fs10973-017-6340-2&partnerID=40&md5=3327a327a5619b86a5d1c47c95f26637","Thermal metrology laboratory at the National Institute of Standards (NIS-Egypt) has been working for the last four years to realize the International Temperature Scale 1990 in low-temperature ranges. It is required to develop a temperature controlling system to regulate the temperature precisely. Two mathematical algorithm techniques are considered to stabilize the temperature of an evacuated copper cylinder that is located inside an isolated calorimeter, and the normal PI and modified fractional PI controls have been designed and developed based on Laboratory Virtual Instrument for Engineering Workbench (LabVIEW®) software. The new improved fractional PI controlling mechanism has showed stability better than 3 ± 1 mK in temperature and 45 ± 1 min in time performances. The estimated uncertainty related to the measurements has been improved up to ±0.32 mK. © 2017, Akadémiai Kiadó, Budapest, Hungary.","Adiabatic calorimeter; Fractional PI; ITS-90; LabVIEW; Regulation; Temperature control; Zone","Calorimeters; Computer programming languages; Temperature; Uncertainty analysis; Units of measurement; Zoning; Adiabatic calorimeters; Engineering workbenches; International temperature scale; ITS-90; LabViEW; National institute of standards; Regulation; Temperature controlling; Temperature control",2-s2.0-85017107462
"Zhen Z., Tang S.-X., Zhou Z.","Stabilization of a Heat-ODE System Cascaded at a Boundary Point and an Intermediate Point",2017,"Asian Journal of Control",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028988308&doi=10.1002%2fasjc.1501&partnerID=40&md5=9f6764648fa6dc5cab31c4b64c3c4528","This paper considers the stabilization of a heat-ODE system cascaded at a boundary point and an intermediate point. The stabilizing feedback control law is designed by the backstepping method. Based on a novel transformation, we prove that all the kernel functions in the forward and inverse transformations are of the class C2. Moreover, the effectiveness of controller design is shown with a numerical simulation. Finally, we show the coherence between the controllability assumption of the main theorem in this paper and the known one for a special case with λ=0. © 2017 Chinese Automatic Control Society and John Wiley & Sons Australia, Ltd","backstepping; Cascaded heat-ODE; intermediate point; stabilization","C (programming language); Controllers; Ordinary differential equations; Stabilization; Back-stepping method; Boundary points; Cascaded heat-ODE; Controller designs; intermediate point; Inverse transformations; Kernel function; Stabilizing feedback controls; Backstepping",2-s2.0-85028988308
"Lin J., He J., Qi F., Zheng B., Wang X., Yu B., Zhou K., Zhang W., Li Y., Chen Y.","In-situ Selenization of Co-based Metal-Organic Frameworks as a Highly Efficient Electrocatalyst for Hydrogen Evolution Reaction",2017,"Electrochimica Acta",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021963374&doi=10.1016%2fj.electacta.2017.06.179&partnerID=40&md5=030ad7d7f3fe2c1ee42732ade856a982","Metal-organic frameworks (MOFs) derived cobalt diselenide (MOF-CoSe2) constructed with CoSe2 nanoparticles anchored into nitrogen-doped (N-doped) graphitic carbon has been synthesized through in-situ selenization of Co-based MOFs. The obtained MOF-CoSe2 exhibits excellent hydrogen evolution reaction (HER) performance: it shows a small Tafel slope of 42 mV dec−1, a low onset potential of 150 mV; it delivers a high current density and excellent long-term stability. Such enhancement can be attributed to the unique N-doped MOFs derived architecture with high conductivity, which can not only provide abundant active reaction sites, but also ensure robust contact between the CoSe2 nanoparticles and N-doped carbon matrix, leading to outstanding electrocatalytic activity for HER. This study provides a route to prepared non-noble-metal catalyst with high efficiency and excellent electrocatalytic activity for HER. © 2017 Elsevier Ltd","cobalt diselenide; hydrogen evolution reaction; metal-organic frameworks","Catalysts; Cobalt; Crystalline materials; Doping (additives); Electrocatalysts; Java programming language; Metals; Nanoparticles; Selenium compounds; Slope stability; Synthesis (chemical); Diselenide; Electrocatalytic activity; High current densities; Hydrogen evolution reactions; Long term stability; Metal organic framework; Metalorganic frameworks (MOFs); Non-noble metal catalysts; Metal nanoparticles",2-s2.0-85021963374
"Jaimes M.A., Niño M.","Cost-benefit analysis to assess seismic mitigation options in Mexican public school buildings",2017,"Bulletin of Earthquake Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015185554&doi=10.1007%2fs10518-017-0119-5&partnerID=40&md5=8552e028637971817563977462cb4e4d","This study presents a methodology to perform a cost-benefit (C/B) analysis to assess possible options such as retrofitting or reconstruction of structures focused on mitigation of direct physical losses due to seismic actions. The case of all public school buildings located in Mexico City is presented as an illustrative example having as measure parameters the expected loss, the expected annual loss (EAL) and the probable maximum loss (PML). For the proposed methodology the following steps are required: (1) To gather technical information of typical school buildings designed according to different past seismic codes of the region, (2) To propose seismic mitigation actions such as retrofitting or stiffening of the structural system in order to comply with the current Mexico City seismic design code (RCDF-2004), (3) To compute vulnerability functions by carrying out non-linear Incremental Dynamic Analyses (IDA) for the original designed structural systems and those modified according to the performed mitigation actions, (4) To carry out a probabilistic seismic risk analysis taking into account all locations of public school buildings in Mexico City, (5) To perform a C/B analysis assuming two different cases: (a) retrofitting and/or stiffening the structural system and (b) demolish and reconstruct a completely new school building. This analysis is carried out at two different levels: (1) vulnerability functions of structures considering the two mitigation actions are obtained and compared, and (b) a combination of the different mitigation alternatives is investigated in order to determine, by obtaining the EAL and PML, the number and location of schools that require mitigation actions assuming that economical resources are limited. The usefulness of carrying out a C/B analysis by computing the seismic risk is shown as an aid to formulate and define mitigation strategies that allow decision-makers to prioritize the use of the economic resources. The advantage of this approach is that the obtained results will be presented in such a way they will be easier to communicate to decision-makers even if they are not familiar with formal risk studies. © 2017, Springer Science+Business Media Dordrecht.","Cost-benefit analysis; Retrofitting; Schools; Seismic risk; Site effects","Buildings; C (programming language); Costs; Decision making; Economic analysis; Retrofitting; Risk analysis; Risk assessment; School buildings; Seismic design; Seismology; Structural analysis; Expected annual loss; Incremental dynamic analysis; Mitigation strategy; Schools; Seismic design code; Seismic risk; Site effects; Technical information; Cost benefit analysis; building; cost-benefit analysis; decision making; reconstruction; risk assessment; seismic design; seismic retrofit; site effect; vulnerability; Federal District [Mexico]; Mexico City; Mexico [North America]",2-s2.0-85015185554
"Wang Y.G., Le Gia Q.T., Sloan I.H., Womersley R.S.","Fully discrete needlet approximation on the sphere",2017,"Applied and Computational Harmonic Analysis",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955323585&doi=10.1016%2fj.acha.2016.01.003&partnerID=40&md5=83743b1336a7a6c0887e5eb618a6b87d","Spherical needlets are highly localized radial polynomials on the sphere Sd⊂Rd+1, d≥2, with centers at the nodes of a suitable cubature rule. The original semidiscrete spherical needlet approximation of Narcowich, Petrushev and Ward is not computable, in that the needlet coefficients depend on inner product integrals. In this work we approximate these integrals by a second quadrature rule with an appropriate degree of precision, to construct a fully discrete needlet approximation. We prove that the resulting approximation is equivalent to filtered hyperinterpolation, that is to a filtered Fourier–Laplace series partial sum with inner products replaced by appropriate cubature sums. It follows that the Lp-error of discrete needlet approximation of order J for 1≤p≤∞ and s&gt;d/p has for a function f in the Sobolev space Wp s(Sd) the optimal rate of convergence in the sense of optimal recovery, namely O(2−Js). Moreover, this is achieved with a filter function that is of smoothness class C⌊[Formula presented]⌋, in contrast to the usually assumed C∞. A numerical experiment for a class of functions in known Sobolev smoothness classes gives L2 errors for the fully discrete needlet approximation that are almost identical to those for the original semidiscrete needlet approximation. Another experiment uses needlets over the whole sphere for the lower levels together with high-level needlets with centers restricted to a local region. The resulting errors are reduced in the local region away from the boundary, indicating that local refinement in special regions is a promising strategy. © 2016 Elsevier Inc.","Filtered hyperinterpolation; Frame; Localization; Needlet; Sphere; Spherical design; Wavelet","C (programming language); Errors; Fourier series; Sobolev spaces; Filtered hyperinterpolation; Frame; Localization; Needlet; Spherical designs; Wavelet; Spheres",2-s2.0-84955323585
"Simić M., Kokolanski Z., Denić D., Dimcev V., Živanović D., Taskovski D.","Design and evaluation of computer-based electrical power quality signal generator",2017,"Measurement: Journal of the International Measurement Confederation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019155202&doi=10.1016%2fj.measurement.2017.05.010&partnerID=40&md5=95b0d6e1698dcbd358362a1e4597a3f8","Electrical power quality signal generator, capable of reproducing the power quality disturbances in accordance with European standard EN50160, is presented in this paper. Signal generator is divided in two parts: LabVIEW based virtual instrumentation software for defining the disturbance parameters and hardware electronics for signal generation (data acquisition card and power amplifier). The paper focus is on the design of power amplifier for scaling the data acquisition card output voltage level to the nominal power line voltage (230 V). The signal generator can be used for generation of reference signals useful for testing the power quality measuring instruments and various algorithms for power quality disturbance detection. In such manner, this PC based signal generator can be used as suitable and cost effective alternative to the instruments for testing the power quality meters and analyzers. According to the relevant document – ISO Guide to the Expression of Uncertainty in Measurement, for detailed metrological assessment of developed signal generator, calculation and presentation of measurement uncertainty budget is performed. © 2017 Elsevier Ltd","Electrical power quality; Measurement uncertainty; Power amplifier; Signal generator; Virtual instrument","Automobile engines; Budget control; Computer programming languages; Cost effectiveness; Data acquisition; Instrument testing; Power amplifiers; Signal generators; Signal processing; Uncertainty analysis; Data acquisition cards; Electrical power quality; Guide to the expression of uncertainty in measurements; Measurement uncertainty; Measurement uncertainty budget; Power quality disturbances; Virtual instrument; Virtual Instrumentation; Power quality",2-s2.0-85019155202
"Vo H.T., Reichardt A., Frazer D., Bailey N., Chou P., Hosemann P.","In situ micro-tensile testing on proton beam-irradiated stainless steel",2017,"Journal of Nuclear Materials",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021412703&doi=10.1016%2fj.jnucmat.2017.06.026&partnerID=40&md5=49b328b2c85bf5378d3b1f1ee0f0d93f","Small-scale mechanical testing techniques are currently being explored and developed for engineering applications. In particular, micro-tensile testing can add tremendous value, since the entire stress-strain curve, including the strain to failure, can be measured directly. In this work, 304 stainless steel specimens irradiated with 2 MeV protons to 10 dpa (full-cascade setting in the Stopping and Range of Ions in Matter, SRIM, software) at 360 °C was evaluated using micro-tensile testing. It was found that even on the micron scale, the measured strain corresponds well with macroscopic expectations. In addition, a new approach to analyzing sudden slip events is presented. © 2017 Elsevier B.V.","Localized deformation; Micro-tensile testing; Radiation damage; Slip band; Stainless steel; Total elongation; Yield strength","C (programming language); Materials testing apparatus; Mechanical testing; Radiation damage; Software testing; Steel research; Steel testing; Stress-strain curves; Tensile testing; Yield stress; 304 stainless steel; Engineering applications; Irradiated stainless steels; Localized deformations; Micro tensile testing; Slip band; Stopping and range of ions in matters; Total elongations; Stainless steel",2-s2.0-85021412703
"Titus G., Sudhakar M.S.","A simple and efficient algorithm operating with linear time for MCEEG data compression",2017,"Australasian Physical and Engineering Sciences in Medicine",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026509946&doi=10.1007%2fs13246-017-0575-x&partnerID=40&md5=29d6b0ca2ee8b2dc1e9a0b64d0a623ed","Popularisation of electroencephalograph (EEG) signals in diversified fields have increased the need for devices capable of operating at lower power and storage requirements. This has led to a great deal of research in data compression, that can address (a) low latency in the coding of the signal, (b) reduced hardware and software dependencies, (c) quantify the system anomalies, and (d) effectively reconstruct the compressed signal. This paper proposes a computationally simple and novel coding scheme named spatial pseudo codec (SPC), to achieve lossy to near lossless compression of multichannel EEG (MCEEG). In the proposed system, MCEEG signals are initially normalized, followed by two parallel processes: one operating on integer part and the other, on fractional part of the normalized data. The redundancies in integer part are exploited using spatial domain encoder, and the fractional part is coded as pseudo integers. The proposed method has been tested on a wide range of databases having variable sampling rates and resolutions. Results indicate that the algorithm has a good recovery performance with an average percentage root mean square deviation (PRD) of 2.72 for an average compression ratio (CR) of 3.16. Furthermore, the algorithm has a complexity of only O(n) with an average encoding and decoding time per sample of 0.3 ms and 0.04 ms respectively. The performance of the algorithm is comparable with recent methods like fast discrete cosine transform (fDCT) and tensor decomposition methods. The results validated the feasibility of the proposed compression scheme for practical MCEEG recording, archiving and brain computer interfacing systems. © 2017, Australasian College of Physical Scientists and Engineers in Medicine.","Integer fraction coder (IFC); Integer fraction decoder (IFD); Inverse logarithmic translation (ILT) transform; Pseudo integer (PI); Translated logarithmic (TL) transform","Computational complexity; Cosine transforms; Data compression; Decoding; Digital storage; Discrete cosine transforms; Electroencephalography; Signal encoding; Tensors; Brain-computer interfacing; Fast discrete cosine transforms (FDCT); Integer fraction; Near lossless compression; Pseudo integer (PI); Root mean square deviations; Simple and efficient algorithms; Variable sampling rates; C (programming language); analytic method; Article; brain computer interface; coding algorithm; electroencephalograph; fast discrete cosine transform; feasibility study; information processing device; intermethod comparison; multichannel electroencephalograph; multichannel recorder; signal processing; tensor decomposition method; time",2-s2.0-85026509946
"Park G.S., Kim W., Jeong S.H., Song H.","Smart Base Station-Assisted Partial-Flow Device-to-Device Offloading System for Video Streaming Services",2017,"IEEE Transactions on Mobile Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029364279&doi=10.1109%2fTMC.2016.2626434&partnerID=40&md5=0836bcaedc84507c6c2a09064a15e5e7","This paper presents a smart base station-assisted partial-flow device-to-device offloading system that provides seamless video streaming services to clients by effectively offloading parts of the video traffic to D2D networks in order to alleviate the cellular network traffic load. In the proposed system, the main functionalities of the content centric networking (CCN) technology are deployed for efficient and fast cached content management at the base stations and in the devices. First, a logical overlay Chord-like network is constructed among the smart base stations for effectively handling significant numbers of the distributed contents. Then, content management protocols over the Chord-like network are implemented for rapidly finding the D2D server that contains the cached content requested by the D2D client. A two-stage PID-based LTE traffic controller is proposed to determine the amount of traffic to be offloaded to the D2D network among the cellular operator, the D2D servers, and the D2D clients. The proposed system is fully implemented using a CCNx open source and C/C++. Experimental results are provided to demonstrate the performance improvement of the proposed system. © 2017 IEEE.","chord-like network; Content centric networking; partial-flow device-to-device offloading; two-stage PID-based LTE traffic controller","Base stations; C (programming language); Knowledge engineering; Mobile telecommunication systems; Network architecture; Open systems; Video streaming; Cellular network traffics; Chord-like networks; Content management; Content-centric networkings; Distributed content; Partial flow; Traffic controllers; Video streaming services; Wireless telecommunication systems",2-s2.0-85029364279
"Qian Z., Jin C., Zhang D.","Multiple frictional impact dynamics of threshing process between flexible tooth and grain kernel",2017,"Computers and Electronics in Agriculture",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028404251&doi=10.1016%2fj.compag.2017.07.022&partnerID=40&md5=010d8270c157b66c5b4c5f764df65a06","The flexible threshing tooth is of interest to researchers in agricultural mechanization, due to the fact that impact, knead force, and rate of damnification decreases obviously compared to the traditional rigid pole-tooth, and it is propitious to increase the synthesis benefit for grain production. The multiple frictional contact dynamics of the flexible threshing tooth against grain kernels is presented by using an addition-deletion constraints approach in this study. The flexible threshing tooth is based on flexible-rigid coupling theory. A correlation matrix and four contact points index metrics are introduced. The system formulations for separation, initial contact, stick, and slip are established respectively by using different Lagrange multipliers. The impulse-momentum method is adopted herein to calculate the jump discontinuities. And the concept of a tangential sliding friction potential is introduced to represent the sliding friction effects. The corresponding computational strategy and numerical simulation C++ software are implemented. Several numerical examples adopted to demonstrate the efficiency of the presented approach and algorithms. The peak collision forces on normal and tangential directions are not synchronized. The occurrence of numerous sub-collisions among one macro-collision arises from the coupling of rigid motion and high-frequency deformation vibration of the flexible tooth. The flexible tooth has a less impactful knead force than the rigid one for cracked grains or seed, so as to reduce rate of grain damnification, and is thus propitious for increasing the synthesis benefit for paddy production. © 2017 Elsevier B.V.","Dynamics; Flexible threshing tooth; Lagrange multipliers method; Multiple frictional impacts; Stick-slip","Agriculture; C++ (programming language); Computation theory; Computer software; Dynamics; Frequency multiplying circuits; Friction; Grain (agricultural product); Machinery; Slip forming; Stick-slip; Agricultural mechanization; Computational strategy; Deformation vibrations; Flexible threshing tooth; Lagrange multipliers method; Multiple frictional contacts; Multiple frictional impacts; Tangential directions; Lagrange multipliers",2-s2.0-85028404251
"Lin Q., Huang H., Chen L., Chen E.","Topographic correction method for steep mountain terrain images",2017,"Yaogan Xuebao/Journal of Remote Sensing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031767533&doi=10.11834%2fjrs.20176384&partnerID=40&md5=2efa74959523b42803161477e4cbbeb4","The radiation quality of images is severely affected by variations in topography especially in complex mountain areas. Thus, topographic correction is a necessary pre-processing step for remote sensing image radiative correction. However, over-correction problems were easily found in the commonly used topographic correction method in steep mountain areas. We proposed a semi-empirical topographic correction method for steep mountain terrain to overcome the over-correction problems; it is the simple topographic correction method using estimation of diffuse light (SCEDIL). The SCEDIL model estimates the diffuse fraction through finding the horizontal sunlight and shadow pixels based on images and Digital Elevation Model (DEM) data. The three radiation components (direct, diffuse, and terrain irradiance) focused on the impact of the solar irradiance, reaching an inclined surface to recover the actual land surface reflectance. We consider that the solar direct radiation is the main source of incident radiation for horizontal sunlight pixels, and the incident radiation of horizontal shadow pixels come from diffuse and terrain irradiance. Therefore, the diffuse radiation can be estimated by the mean reflectance of horizontal sunlit and shadow pixels. The estimation of the surface actual reflectance is achieved using a two-step procedure. First, the atmospheric correction model (such as 6S or MODTRAN model) was used to calculate the diffuse fraction and irradiance components of horizontal surfaces. Second, SCEDIL was used to remove terrain effects. The GF-1 and Landsat ETM+ images were used to evaluate different topographic corrections (SCEDIL, C, and SCS+C models). Four validation methods were employed to assess the performance under different illumination conditions, as below: (a) visual comparison for different terrain correction models, (b) changes in the correlation coefficient between the incidence angle and the spectral bands, (c) changes in the Standard Deviation (SD) and mean of the reflectance of each spectral band, and (d) land cover classification accuracy. The results show that: (1) SCEDIL, C, and SCS+C corrections performed effectively for the slightly rough mountain area (average slopes<26°, average elevation<600 m). However, SCEDIL-correction produced better and smoother corrected images than SCS+C and C methods for the steep mountain area; the average slope is larger than 26°, and the average elevation is more than 700 m; (2) the SCEDIL method produced the lowest correlation coefficient between the incidence angle and the spectral bands for steep mountain, (3)SCEDIL-correction maintained more closer mean and lesser reduction in SD to original image bands than C-correction and SCS+C-correction; (4) SCEDIL-corrected images have the highest overall accuracy of classification and highest homogeneity within each land cover class using the Support Vector Machine classification method. Therefore, SCEDIL-correction was robust in terms of different terrains, and especially the steep region images in this study. © 2017, Science Press. All right reserved.","C-correction; Diffuse fraction; SCEDIL-correction; SCS+C-correction; Topographic correction","Diffusers (optical); Electromagnetic wave attenuation; Incident solar radiation; Landforms; Pixels; Radiation; Reflection; Remote sensing; Surveying; Atmospheric corrections; Correlation coefficient; Diffuse fraction; Digital elevation model; Illumination conditions; Land cover classification; Support vector machine classification; Topographic correction; C (programming language)",2-s2.0-85031767533
"Liu H.-H., Li B.-X., Liao L., Wang J.-H.","Replaceability Measurement and Impact Factor Analysis for Java Classes and Packages",2017,"Tien Tzu Hsueh Pao/Acta Electronica Sinica",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032264361&doi=10.3969%2fj.issn.0372-2112.2017.09.014&partnerID=40&md5=89e38045b71471742908d44b4366abfd","Based on qualitative description of code replaceability in ISO25010 standard, it is difficult to quantitatively measure code replaceability. In order to make this process automatic, we define a replaceability measurement formulation by adequately considering the coupling relationship and intrinsic complexity in classes/packages. Then, an experiment is performed on 100 popular open source projects, and results show that (1) there are significant differences among different classes in terms of replaceability and these differences largely depend on the degree of communication between different classes and (2) there is no significant linear relationship between package replaceability and the total number of classes located in it and (3) the replaceability value of package designed by feature is more than the value of package designed by layer. From perspective of code replaceability, our empirical study also provides some suggestion for developers when they design a class or package. © 2017, Chinese Institute of Electronics. All right reserved.","Class replaceability; Class stereotype; Coupling; Package organized by feature; Package organized by layer; Package replaceability","Codes (symbols); Couplings; Java programming language; Class replaceability; Class stereotype; Coupling relationships; Different class; Empirical studies; Linear relationships; Number of class; Open source projects; Open source software",2-s2.0-85032264361
"Yasa S.R., Cheguru S., Krishnasamy S., Korlipara P.V., Rajak A.K., Penumarthy V.","Synthesis of 10-undecenoic acid based C22-dimer acid esters and their evaluation as potential lubricant basestocks",2017,"Industrial Crops and Products",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017129425&doi=10.1016%2fj.indcrop.2017.04.005&partnerID=40&md5=264bc30fc4746804af6cce14d792dc86","A new class of C22-dimer acid esters was synthesized from 10-undecenoic acid by montmorillonite K10 clay catalyzed polymerization to dimer acid followed by their esterification using straight and branched chain alcohols (C1 to C10). All the newly synthesized products were characterized by IR, 1H NMR, 13C NMR, ESI–MS and HPLC, and evaluated for their physicochemical and lubricant properties such as density, specific gravity, viscosity, pour point, flash point, thermal and oxidation stability, weld load, wear and copper corrosion. Structural features like chain length and branching of alcohols influence the physicochemical and lubricants properties of the C22-dimer acid esters. It was observed that the esters synthesized using branched chain alcohols showed lower pour point and higher oxidation stability than their counterparts synthesized using straight chain alcohols. Overall, the physicochemical and lubricants properties of all the synthesized C22-dimer acid esters indicate that they can be potential base oils for hydraulic, metal working fluids and low-temperature lubricant applications. © 2017 Elsevier B.V.","10-Undecenoic acid; Branched chain alcohols; C22-Dimer acid; Montmorillonite K10; Oxidative stability; Polymerization; Pour point","Chains; Clay minerals; Copper corrosion; Density (specific gravity); Dimers; Esters; Fluids; Lubricants; Metal working; Polymerization; Temperature; 10-undecenoic acids; Chain alcohol; Dimer acids; Montmorillonite K10; Oxidative stability; Pour points; C (programming language); alcohol; carbon; catalysis; ester; lubricant; montmorillonite; organic acid; oxidation; physicochemical property; polymerization",2-s2.0-85017129425
"Morais L.D.C., Magnabosco R.","Experimental investigations and DICTRA® simulation of sigma phase formation in a duplex stainless steel",2017,"Calphad: Computer Coupling of Phase Diagrams and Thermochemistry",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025143729&doi=10.1016%2fj.calphad.2017.07.006&partnerID=40&md5=cc451225c91eaad38ec2681f31c07fbd","Sigma phase formation in an UNS S31803 duplex stainless steel aged at 940 °C was evaluated by computational simulation in DICTRA® software, using MOB2 diffusion database and TCFE8 thermodynamic database. Simulation results were compared to experimental tests. Two models were tested in DICTRA® software: in model 1 sigma phase are placed between ferrite and austenite, and in model 2 sigma is placed at one side of ferrite region, and austenite on the other. The volume fraction of sigma and ferrite phases obtained in model 1 showed adherence to the experimental results up to 7200 s (2 h) of simulation, indicating the ability of the model in the description of early stages of sigma formation. Model 2 showed good agreement with experimental data up to 86,400 s (24 h) of simulation. The composition profile obtained by the simulation of the model 1 represented better the impoverishment in Cr and Mo in ferrite/sigma and austenite/sigma interfaces, while the profiles obtained by the simulation of model 2 described better the partition of the chemical elements between austenite and ferrite during sigma formation. © 2017 Elsevier Ltd","Computational simulation; DICTRA®; Duplex stainless steel; Sigma phase","Austenite; C (programming language); Chemical elements; Computer software; Ferrite; Molybdenum; Software testing; Composition profile; Computational simulation; Duplex stainless steel; Experimental investigations; Sigma phase; Sigma phase formation; Simulation of models; Thermodynamic database; Stainless steel",2-s2.0-85025143729
"Polyakov Y., Rohloff K., Sahu G., Vaikuntanathan V.","Fast proxy re-encryption for publish/subscribe systems",2017,"ACM Transactions on Privacy and Security",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030232215&doi=10.1145%2f3128607&partnerID=40&md5=ac4070e5694eef69c6c661a7eaf7e07c","We develop two IND-CPA-secure multihop unidirectional Proxy Re-Encryption (PRE) schemes by applying the Ring-LWE (RLWE) key switching approach from the homomorphic encryption literature. Unidirectional PRE is ideal for secure publish-subscribe operations where a publisher encrypts information using a public key without knowing upfront who the subscriber will be and what private key will be used for decryption. The proposed PRE schemes provide a multihop capability, meaning that when PRE-encrypted information is published onto a PRE-enabled server, the server can either delegate access to specific clients or enable other servers the right to delegate access. Our first scheme (which we call NTRU-ABD-PRE) is based on a variant of the NTRU-RLWE homomorphic encryption scheme. Our second and main PRE scheme (which we call BV-PRE) is built on top of the Brakerski-Vaikuntanathan (BV) homomorphic encryption scheme and relies solely on the RLWE assumption. We present an open-source C++ implementation of both schemes and discuss several algorithmic and software optimizations. We examine parameter selection tradeoffs in the context of security, runtime/latency, throughput, ciphertext expansion, memory usage, and multihop capabilities. Our experimental analysis demonstrates that BV-PRE outperforms NTRU-ABD-PRE in both single-hop and multihop settings. The BVPRE scheme has a lower time and space complexity than existing IND-CPA-secure lattice-based PRE schemes and requires small concrete parameters, making the scheme computationally efficient for use on low-resource embedded systems while still providing 100 bits of security. We present practical recommendations for applying the PRE schemes to several use cases of ad hoc information sharing for publish-subscribe operations. © 2017 ACM.","Delegating access control; Lattice encryption; Proxy re-encryption; Software engineering","Access control; C++ (programming language); Computer software; Embedded systems; Open source software; Open systems; Publishing; Software engineering; Computationally efficient; Encrypted informations; Ho-momorphic encryptions; Homomorphic Encryption Schemes; Practical recommendation; Proxy re encryptions; Publish/Subscribe system; Time and space complexity; Cryptography",2-s2.0-85030232215
"Jabri A., Zayed T.","Agent-based modeling and simulation of earthmoving operations",2017,"Automation in Construction",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021229280&doi=10.1016%2fj.autcon.2017.06.017&partnerID=40&md5=79178ebbaa2b5bd75a0daa1df55f52a1","Discrete-Event Simulation (DES) models are constructed from sequential duration-based activities. DES is used in modeling several construction operations including earthmoving. Current earthmoving models cannot accommodate equipment units with different specifications performing the same task. In addition, activity durations are calculated based on primitive methods such as interpolating existing durations of similar activities in previous projects. Finally, model elements behave in a predetermined manner, ignoring special operational real-life scenarios that occur due to resource constraints. These limitations often lead to inaccuracies in calculating productivity and equipment utilization. This paper applies Agent-Based Modeling and Simulation (ABMS) as an effective bottom-up tool to modeling earthmoving operations. An Agent-Based (AB) earthmoving model consisting of smart, adaptive agents is developed. Each agent is assigned a state chart and a set of static and dynamic properties (attributes and variables) to direct its interactions with the environment and with other agents. This framework proves how modeling earthmoving from the agent's prospective and basing agents' interactions on their properties allow for modeling equipment units with different specifications performing the same task (e.g. trucks of different capacities), as well as for an accurate representation of activity durations, resource handling and resource constraint scenarios. A Java-based application named Agent-Based Simulator for Earthmoving Operations (ABSEMO) is developed as an implementation of the proposed model. ABSEMO will be helpful to contractors in planning earthmoving operations according to the AB approach. A real-life case study of a riverbed excavation in a dam construction project is simulated using ABSEMO, and the results are compared with those obtained from existing simulation models to verify ABSEMO's logic. A percentage difference of 0.42% from the existing results is obtained, indicating that the model's flow of resources is indeed accurate. © 2017 Elsevier B.V.","Agent-based modeling; Agent-based simulation; Earthmoving planning; Earthmoving productivity; Multi-agent systems","Autonomous agents; Computational methods; Computer software; Discrete event simulation; Earthmoving machinery; Equipment; Java programming language; Multi agent systems; Productivity; Specifications; Agent based simulation; Agent-based model; Agent-based modeling and simulation; Construction operations; Earthmoving; Earthmoving operations; Equipment utilization; Java-based applications; Software agents",2-s2.0-85021229280
"Yuan Y.-H., Fan J.-H., Tao J., Qian B.-C., Costantin D., Xiao H.-B., Pei Z.-Y., Lin C.","Optical monitoring of BL Lac object S5 0716+714 and FSRQ 3C 273 from 2000 to 2014",2017,"Astronomy and Astrophysics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028942607&doi=10.1051%2f0004-6361%2f201630338&partnerID=40&md5=b24f46b78772e5a97d2771339bacbe10","Context. Using the 1.56 m telescope at the Shanghai Observatory (ShAO), China, we monitored two sources, BL Lac object S5 0716+714 and flat spectrum radio quasar (FSRQ) 3C 273. For S5 0716+714, we report 4969 sets of CCD (Charge-coupled Device) photometrical optical observations (1369 for V band, 1861 for R band and 1739 for I band) in the monitoring time from Dec. 4, 2000 to Apr. 5, 2014. For 3C 273, we report 460 observations (138 for V band, 146 for R band and 176 for I band) in the monitoring time from Mar. 28, 2006 to Apr. 9, 2014. Aims. The observations provide us with a large amount of data to analyze the short-Term and long-Term optical variabilities. Based on the variable timescales, we can estimate the central black hole mass and the Doppler factor. An abundance of multi-band observations can help us to analyze the relations between the brightness and spectrum. Methods. We use Gaussian fitting to analyze the intra-day light curves and obtain the intra-day variability (IDV) timescales. We use the discrete correlation function (DCF) method and Jurkevich method to analyze the quasi-periodic variability. Based on the VRI observations, we use the linear fitting to analyze the relations between brightness and spectrum. Results. The two sources both show IDV properties for S5 0716+714. The timescales are in the range from 17.3 min to 4.82 h; for 3C 273, the timescale is ΔT = 35.6 min. Based on the periodic analysis methods, we find the periods PV = 24.24 ± 1.09 days, PR = 24.12 ± 0.76 days, PI = 24.82 ± 0.73 days for S5 0716+714, and P = 12.99 ± 0.72, 21.76 ± 1.45 yr for 3C 273. The two sources displayed the ""bluer-when-brighter"" spectral evolution properties. Conclusions. S5 0716+714 and 3C 273 are frequently studied objects. The violent optical variability and IDV may come from the jet. Gaussian fitting can be used to analyze IDVs. The relations between brightness (flux density) and spectrum are strongly influenced by the frequency. © ESO, 2017.","BL Lacertae objects: individual: S5 0716+714","Charge coupled devices; Curve fitting; Luminance; BL Lacertae objects: individual: S5 0716+714; Correlation function; Gaussian fitting; Optical monitoring; Optical observations; Periodic analysis; Spectral evolution; Spectrum radio quasar; C (programming language)",2-s2.0-85028942607
"Innocenti M.E., Johnson A., Markidis S., Amaya J., Deca J., Olshevsky V., Lapenta G.","Progress towards physics-based space weather forecasting with exascale computing",2017,"Advances in Engineering Software",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979681340&doi=10.1016%2fj.advengsoft.2016.06.011&partnerID=40&md5=e7b461d9975d641c48797bb8bbc29010","Space weather is a rapidly growing field of science which studies processes occurring in the area of space between the Sun and the Earth. The development of space weather forecasting capabilities is a task of great societal relevance: space weather effects may damage a number of technological assets, among which power and communication lines, transformers, pipelines and the telecommunication infrastructure. Exascale computing is a fundamental ingredient for space weather forecasting tools based on physical, rather than statistical, models. We describe here our recent progresses towards a physics-based space weather forecasting tool with exascale computing. We select the semi-implicit, Particle In Cell, Implicit Moment Method implemented in the parallel, object-oriented, C++ iPic3D code as a promising starting point. We analyze the structure and the performances of the current version of the iPic3D code. We describe three algorithmic developments, the fully implicit method, the Multi-Level Multi-Domain method, and the fluid-kinetic method, which can help addressing the multiple spatial and temporal scales present in space weather simulations. We then examine, in a co-design approach, which requirements – vectorization, extreme parallelism and reduced communication – an application has to satisfy to fully exploit architectures such as GPUs and Xeon Phi's. We address how to modify the iPic3D code to better satisfy these requirements. We then describe how to port the iPic3D code to the DEEP architecture currently under construction. The FP7 project DEEP (www.deep-project.eu) aims at building an exascale-ready machine composed of a cluster of Xeon nodes and of a collection of Xeon Phi coprocessors, used as boosters. The aim of the DEEP project is to enable exascale performance for codes, such as iPic3D, composed of parts which exhibit different potential for extreme scalability. Finally, we provide examples of simulations of space weather processes done with the current version of the iPic3D code. © 2017 Elsevier Ltd","Adaptive; Exascale; High Performance Computing; Implicit; Particle-In-Cell; Space weather","C++ (programming language); Codes (symbols); Earth (planet); Forecasting; Method of moments; Program processors; Adaptive; Exascale; High performance computing; Implicit; Particle in cell; Space weather; Weather forecasting",2-s2.0-84979681340
"Jiménez-Gómez C.P., Cecilia J.A., Moreno-Tost R., Maireles-Torres P.","Selective Furfural Hydrogenation to Furfuryl Alcohol Using Cu-Based Catalysts Supported on Clay Minerals",2017,"Topics in Catalysis",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017443648&doi=10.1007%2fs11244-017-0804-2&partnerID=40&md5=6b1c29e8db72d33b8d8dcb7c0d75e19b","Copper supported on clay minerals (bentonite and sepiolite) catalysts, with copper loading between 15 and 60 wt%, have been synthesized by precipitation-deposition, calcination and subsequent reduction. The catalysts were characterized by X-ray diffraction, H2 temperature programmed reduction (H2-TPR), N2 adsorption–desorption at −196 °C and X-ray photoelectron spectroscopy, being detected spherical metal Cu-particles with variable size, mainly located on the surface of clays. The evaluation of their catalytic performance in the furfural (FUR) hydrogenation in gas phase has demonstrated that the use of bentonite as support allows attaining conversion values of 83% for 45Cu-Bent, whereas only a 52% is reached by the 45Cu-Sep catalyst. All catalysts were highly selective towards furfuryl alcohol (FOL), reaching yields of 72% for 45Cu-Bent and 45% for 45Cu-Sep after 5 h of time-on-stream (TOS) at 210 °C, by using a H2:FUR molar ratio of 11.5 and a WHSV of 1.5 h−1. However, all catalysts suffer a progressive deactivation with TOS, by deposition of reactants and product (FOL and FUR), as well as the oxidation of the active phase. © 2017, Springer Science+Business Media New York.","Biomass; Clays; Copper; Furfural; Furfuryl alcohol","Aldehydes; Bentonite; Biomass; C (programming language); Catalysts; Clay; Clay minerals; Copper; Deposition; Furfural; Hydrogenation; Temperature programmed desorption; X ray diffraction; X ray photoelectron spectroscopy; Catalytic performance; Copper loading; Furfuryl alcohol; Precipitation-deposition; Subsequent reduction; Temperature-programmed reduction; Time on streams; Variable sizes; Catalyst supports",2-s2.0-85017443648
"Concas G., Marchesi M., Monni C., Orrù M., Tonelli R.","Software Quality and Community Structure in Java Software Networks",2017,"International Journal of Software Engineering and Knowledge Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029620864&doi=10.1142%2fS0218194017500401&partnerID=40&md5=95505ae10fd51dea44ac4aef6b6b8858","We present a study of 600 Java software networks with the aim of characterizing the relationship among their defectiveness and community metrics. We analyze the community structure of such networks, defined as their topological division into subnetworks of densely connected nodes. A high density of connections represents a higher level of cooperation between classes, so a well-defined division in communities could indicate that the software system has been designed in a modular fashion and all its functionalities are well separated. We show how the community structure can be an indicator of well-written, high quality code by retrieving the communities of the analyzed systems and by ranking their division in communities through the built-in metric called modularity. We found that the software systems with highest modularity possess the majority of bugs, and tested whether this result is related to some confounding effect. We found two power laws relating the maximum defect density with two different metrics: the number of detected communities inside a software network and the clustering coefficient. We finally found a linear correlation between clustering coefficient and number of communities. Our results can be used to make predictive hypotheses about software defectiveness of future releases of the analyzed systems. © 2017 World Scientific Publishing Company.","Community structure; defect prediction; defectiveness; modularity; software quality","Computer networks; Computer software; Computer software selection and evaluation; Defect density; Defects; Program debugging; Social sciences; Software testing; Community structures; Defect prediction; defectiveness; modularity; Software Quality; Java programming language",2-s2.0-85029620864
"Burghardt A., Kurc K., Szybicki D., Muszyńska M., Nawrocki J.","Software for the robot-operated inspection station for engine guide vanes taking into consideration the geometric variability of parts [Softver za robotom upravljanu kontrolnu stanicu za statorske lopatice motora s obzirom na geometrijsku promjenljivost dijelova]",2017,"Tehnicki Vjesnik",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028776107&doi=10.17559%2fTV-20160820142224&partnerID=40&md5=cee3b17ddc656de00cb948cf7fb11b4c","The paper presents a process of designing and building software for a robotic test stand used for inspection of stators. The software was developed for a test stand comprising the ABB IRB 140 robotic manipulator, and a PC workstation that handles two ultrasound sensors and runs the LabVIEW software suite. The control algorithms of the robot include the potential differences in the geometric features of the items inspected on the test stand and the resulting differences in the manipulator tool motion paths. The software was designed for and delivered to Pratt & Whitney Rzeszów Sp. z o.o. © 2017, Strojarski Facultet. All rights reserved.","Industrial robots; Non-destructive testing; Robot software; Robotic cells; Robotic measurement","Computer programming languages; Computer software; Industrial robots; Inspection; Nondestructive examination; Robotics; Robots; Software testing; Ultrasonic applications; Building softwares; Geometric feature; Lab-view softwares; Non destructive testing; Potential difference; Robotic cell; Robotic manipulators; Ultrasound sensors; Manipulators",2-s2.0-85028776107
"Wen T., Wang R., Sotero A., Li Y.","A portable impedance immunosensing system for rapid detection of Salmonella Typhimurium",2017,"Sensors (Switzerland)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028711509&doi=10.3390%2fs17091973&partnerID=40&md5=ea60a4e93dadedb20cc4b332eb092b6e","Salmonella Typhimurium is one of the most dangerous foodborne pathogens and poses a significant threat to human health. The objective of this study was to develop a portable impedance immunosensing system for rapid and sensitive detection of S. Typhimurium in poultry. The developed portable impedance immunosensing system consisted of a gold interdigitated array microelectrode (IDAM), a signal acquisitive interface and a laptop computer with LabVIEW software. The IDAM was first functionalized with 16-Mercaptohexadecanoic acid, and streptavidin was immobilized onto the electrode surface through covalent bonding. Then, biotin-labelled S. Typhimurium-antibody was immobilized onto the IDAM surface. Samples were dropped on the surface of the IDAM and the S. Typhimurium cells in the samples were captured by the antibody on the IDAM. This resulted in impedance changes that were measured and displayed with the LabVIEW software. An equivalent circuit of the immunosensor demonstrated that the largest change in impedance was due to the electron-transfer resistance. The equivalent circuit showed an increase of 35% for the electron-transfer resistance value compared to the negative control. The calibration result indicated that the portable impedance immunosensing system could be used to measure the standard impedance elements, and it had a maximum error of measurement of approximately 13%. For pure culture detection, the system had a linear relationship between the impedance change and the logarithmic value of S. Typhimurium cells ranging from 76 to 7.6 × 106CFU (colony-forming unit) (50 μL)-1. The immunosensor also had a correlation coefficient of 0.98, and a high specificity for detection of S. Typhimurium cells with a limit of detection (LOD) of 102CFU (50 μL)-1. The detection time from the moment a sample was introduced to the display of the results was 1 h. To conclude, the portable impedance immunosensing system for detection of S. Typhimurium achieved an LOD that is comparable with commercial electrochemical impedance instruments. The developed impedance immunosensor has advantages in portability, low cost, rapid detection and label-free features showing a great potential for in-field detection of foodborne pathogens. © 2017 by the authors. Licensee MDPI, Basel, Switzerland.","Immunosensor; Label-free; Portable; Rapid detection; Salmonella typhimurium","Computer programming languages; Electrodes; Electron transitions; Equivalent circuits; Food microbiology; Health risks; Immunosensors; Laptop computers; Microelectrodes; Proteins; Salmonella; 16-mercaptohexadecanoic acid; Correlation coefficient; Electrochemical impedance; Electron-transfer resistance; Label free; Portable; Rapid detection; Salmonella typhimurium; Antibodies",2-s2.0-85028711509
"Carabaş M., Popescu P.G.","Energy-efficient virtualized clusters",2017,"Future Generation Computer Systems",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947555155&doi=10.1016%2fj.future.2015.10.018&partnerID=40&md5=b249928d3b7b0c5ac0b43778206eba75","In this paper we provide the state of the art for the virtualization techniques and means to reduce power consumption using it. Virtualization allows us to answer all the requirements with many-core servers and thus eliminate the one size does not fit all issue. The resulting pool of resources is beneficial from an economic as well as environmental point of view. It brings benefits of scale to all logistic elements of the problem: power supply, cooling, floor space. When talking about virtualization and power consumption, one important aspect to be taken into account is data center's heterogeneity from the hardware architecture point of view (e.g., X86, PowerPC). Mapping virtualized operating systems on hardware nodes in order to minimize power consumption is still an open issue that will be addressed throughout this paper: given a number of physical machines, we try to map on them the available virtual machines (called virtual machine assignment) in order to have an efficient system when relating to power consumption. We expose new general bounds for the power consumption of a virtual machine assignment based on Jensen inequality. The lower bound has been previously obtained and used into literature, so here we only rediscover it in a simplified and more clear manner. The upper bound is new and general. Furthermore we practically evaluate some discrete cases and we proposed some graphics with the power consumption and its bounds for some particular real cases. © 2015 Elsevier B.V.","Bounds; CPU load; Jensen inequality; Power reduction; Scheduling; Virtualization","Computer hardware; Electric power utilization; Hardware; Java programming language; Scheduling; Virtual reality; Bounds; Energy efficient; Hardware architecture; Jensen inequality; Power reductions; Virtual machines; Virtualization Techniques; Virtualizations; Energy efficiency",2-s2.0-84947555155
"Lempart M., Kügele M., Snäll J., Ambolt L., Ceberg S.","Development of a novel radiotherapy motion phantom using a stepper motor driver circuit and evaluation using optical surface scanning",2017,"Australasian Physical and Engineering Sciences in Medicine",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019710193&doi=10.1007%2fs13246-017-0556-0&partnerID=40&md5=1c1ca0f963f1a52e402011a29f85938c","Abstract: Recent developments in radiotherapy have focused on the management of patient motion during treatment. Studies have shown that significant gains in treatment quality can be made by ‘gating’ certain treatments, simultaneously keeping target coverage, and increasing separation to nearby organs at risk (OAR). Motion phantoms can be used to simulate patient breathing motion and provide the means to perform quality control (QC) and quality assurance (QA) of gating functionality as well as to assess the dosimetric impact of motion on individual patient treatments. The aim of this study was to design and build a motion phantom that accurately reproduces the breathing motion of patients to enable end-to-end gating system quality control of various gating systems as well as patient specific quality assurance. A motion phantom based on a stepper motor driver circuit was designed. The phantom can be programmed with both real patient data from an external gating system and with custom signals. The phantom was programmed and evaluated with patient data and with a square wave signal to be tracked with a Sentinel™ (C-Rad, Uppsala, Sweden) motion monitoring system. Results were compared to the original curves with respect to amplitude and phase. The comparison of patient curve data showed a mean error value of −0.09 mm with a standard deviation of 0.24 mm and a mean absolute error of 0.29 mm. The square wave signals could be reproduced with a mean error value of −0.03 mm, a standard deviation of 0.04 mm and a mean absolute error of 0.13 mm. Breathing curve data acquired from an optical scanning system can be reproduced accurately with the help of the in-house built motion phantom. The phantom can also be programmed to follow user designed curve data. This offers the potential for QC of gating systems and various dosimetric quality control applications. © 2017, Australasian College of Physical Scientists and Engineers in Medicine.","Breathing adapted radiotherapy; Linear accelerator; Motion phantom; Respiratory gating","C (programming language); Dosimetry; Errors; Gating and feeding; Hospital data processing; Linear accelerators; Patient monitoring; Patient treatment; Quality assurance; Radiotherapy; Statistics; Stepping motors; Timing circuits; Dosimetric quality controls; Mean absolute error; Motion phantom; Optical scanning systems; Respiratory gatings; Square wave signals; Standard deviation; Stepper motor drivers; Quality control; accuracy; Article; breathing pattern; dosimetry; equipment design; motion analysis system; optical surface scanning system; process development; process model; quality control; radiation equipment; radiology phantom; radiotherapy motion phantom; signal processing; stepper motor driver circuit",2-s2.0-85019710193
"Darbyshire J.E., Jenny B.","Natural-color maps via coloring of bivariate grid data",2017,"Computers and Geosciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020902243&doi=10.1016%2fj.cageo.2017.06.004&partnerID=40&md5=57323094d5accdc6a8a99345aea9a64c","Natural ground color is useful for maps where a representation of the Earth's surface matters. Natural color schemes are less likely to be misinterpreted, as opposed to hypsometric color schemes, and are generally preferred by map readers. The creation of natural-c\olor maps was once limited to manual cartographic techniques, but they can now be created digitally with the aid of raster graphics editing software. However, the creation of natural-color maps still requires many steps, a significant time investment, and fairly detailed digital land cover information, which makes this technique impossible to apply to global web maps at medium and large scales. A particular challenge for natural-color map creation is adjusting colors with location to create smoothly blending transitions. Adjustments with location are required to show land cover transitions between climate zones with a natural appearance. This study takes the first step in automating the process in order to facilitate the creation of medium- and large-scale natural-color maps covering large areas. A coloring method based on two grid inputs is presented. Here, we introduce an algorithmic method and prototype software for creating maps with this technique. The prototype software allows the map author to interactively assign colors to design the appearance of the map. This software can generate web map tiles at a global level for medium and large scales. Example natural-color web maps created with this coloring technique are provided. © 2017 Elsevier Ltd","Bivariate maps; Natural-color maps; Spatially variable map symbolization; Web mapping","Blending; C (programming language); Software prototyping; Algorithmic methods; Bivariate; Land cover informations; Natural appearance; Natural colors; Prototype software; Spatially variable map symbolization; Web mapping; Color; algorithm; cartography; digital map; digital mapping; land cover; raster; software; Olor",2-s2.0-85020902243
"Li S., Ma X.","CO2 gasification characteristics of nascent pyrolyzed particles from coals and oil shale",2017,"International Journal of Energy Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014104342&doi=10.1002%2fer.3737&partnerID=40&md5=c8c0ab7fbac59f7c7c0d961759ce033a","In this work, the co-pyrolysis characteristics of oil shale with two typical coals, bitumite and lignite, and the co-gasification characteristics of the mixture pyrolyzed fuels were studied via thermo-gravimetric analysis. The individual fuels and mixture fuels were first pyrolysis in N2 atmosphere to specified temperature (450, 550, and 620 °C) at the heating rate of 20, 30 and 40 °C/min, respectively, and then maintained at the given temperature for 20 min before converted to CO2 ambient to conduct the CO2 gasification tests. The kinetic behavior and effects of both fuel types and pyrolysis temperature were investigated. The shoulder peak at around 550 °C observed in the derivative of weight loss derivative thermogravimetry analysis (DTG) curve during the pyrolysis of oil shale has confirmed the existence of specific reactions of oil shale at around 550 °C that leads to a sharp trough in the differential curves of co-pyrolysis with coals and the unusual change in activation energies of gasification. In isothermal pyrolysis stage, oil shale lost its vast majority of organic matters at the temperature lower than 550 °C. The escape of pyrolysis gas and liquids in the coals is much harder than that in oil shale. The interaction between oil shale and bitumite was too weak to discriminate both in the pyrolysis and CO2 gasification process. The variation of the particle surface structure caused by the releasing of volatile gases is strongly affected by the reaction rate and temperature. Quick volatile decomposition and gas releasing lead to the increase of surface area, decrease of the average pore diameter as well as the uniformization of the pore structure, while the higher temperature results in the blockade and merging of fine pores. The two factors lead to the greatest mass loss rate in the pyrolyzed particles obtained at 550 °C in temperature programmed CO2 gasification stage. Two model-free methods, Friedman method and Flynn–Wall–Ozawa method, were used to extract kinetic parameters from the experimentally determined pyrolyzed fuel conversions. The volatile contend has a significant influence on the fixed carbon conversion during the partially pyrolyzed particles' CO2 gasification. In this study, significant interactions existed in co-thermal utilization, both pyrolysis and CO2 gasification, of oil shale and lignite. It is therefore surmised that co-gasification of pyrolyzed lignite and oil shale may represent a feasible, practical route to high-efficiency utilization of these fuels. Copyright © 2017 John Wiley &amp; Sons, Ltd. Copyright © 2017 John Wiley & Sons, Ltd.","co-gasification; coal; kinetic analysis; oil shale","Activation analysis; Activation energy; Atmospheric temperature; C (programming language); Carbon; Carbon dioxide; Coal; Fuels; Gasification; Gravimetric analysis; Kinetics; Lignite; Mixtures; Oil shale processing; Pyrolysis; Reaction kinetics; Shale; Shale oil; Thermogravimetric analysis; Co-gasification; Derivative thermogravimetry; Gasification characteristics; Gasification process; Kinetic analysis; Pyrolysis temperature; Temperature programmed; Thermal utilization; Oil shale",2-s2.0-85014104342
"Lv H., Wu X., Zhang J.","Analysis and design considerations for a high power buck derived LED driver with extended output voltage and low total harmonic distortion",2017,"Journal of Power Electronics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029725368&doi=10.6113%2fJPE.2017.17.5.1137&partnerID=40&md5=dc9a05fdbcb8adcf2fcf3575b1a62e69","In order to reduce the cost, improve the efficiency and simplify the complicated control of existing isolated LED drivers, an improved boundary conduction mode (BCM) Buck ac-dc light emitting diode (LED) driver with extended output voltage and low total harmonic distortion is proposed. With a coupled inductor winding and a stacked output, its output voltage can be elevated to a much higher value when compared to that of the conventional Buck ac-dc converter, without sacrificing the input harmonics and power factor. Therefore, the proposed Buck LED driver can meet the IEC61000-3-2 (Class C) limitation and has a low THD. The operating principle of the topology and the design methodology of the ac-dc LED driver are presented. A 150 W ac-dc prototype was built in the laboratory and it shows that the input current harmonics meet the lighting standard. In addition, the THD is less than 16% at a typical ac input. The peak efficiency is higher than 96.5% at a full load and a normal input. © 2017 KIPE.","AC-DC; BCM buck; LED driver; Low THD; Non-isolated","C (programming language); DC-DC converters; Design; Efficiency; Harmonic analysis; Harmonic distortion; Rectifying circuits; Wave filters; BCM buck; Boundary conduction mode; Input current harmonics; LED drivers; Light-emitting diode (LED) drivers; Low THD; Non-isolated; Total harmonic distortion (THD); Light emitting diodes",2-s2.0-85029725368
"Ahrens B., Lumsdaine P.L.","Displayed categories",2017,"Leibniz International Proceedings in Informatics, LIPIcs",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030562031&doi=10.4230%2fLIPIcs.FSCD.2017.5&partnerID=40&md5=2475ec475b2e4504c577379e1bd4dfda","We introduce and develop the notion of displayed categories. A displayed category over a category C is equivalent to 'a category D and functor F : D → C', but instead of having a single collection of 'objects of D' with a map to the objects of C, the objects are given as a family indexed by objects of C, and similarly for the morphisms. This encapsulates a common way of building categories in practice, by starting with an existing category and adding extra data/properties to the objects and morphisms. The interest of this seemingly trivial reformulation is that various properties of functors are more naturally defined as properties of the corresponding displayed categories. Grothendieck fibrations, for example, when defined as certain functors, use equality on objects in their definition. When defined instead as certain displayed categories, erence to equality on objects is required. Moreover, almost all examples of fibrations in nature are, in fact, categories whose standard construction can be seen as going via displayed categories. We therefore propose displayed categories as a basis for the development of fibrations in the type-Theoretic setting, and similarly for various other notions whose classical definitions involve equality on objects. Besides giving a conceptual clarification of such issues, displayed categories also provide a powerful tool in computer formalisation, unifying and abstracting common constructions and proof techniques of category theory, and enabling modular reasoning about categories of multicomponent structures. As such, most of the material of this article has been formalised in Coq over the UniMath library, with the aim of providing a practical library for use in further developments. © Benedikt Ahrens and Peter LeFanu Lumsdaine.","Category theory; Computer proof assistants; Coq; Dependent type theory; Univalent mathematics","Algebra; Computation theory; Conformal mapping; Theorem proving; Building categories; Category theory; Computer proofs; Dependent type theory; Further development; Modular reasoning; Multi-component structures; Standard constructions; C (programming language)",2-s2.0-85030562031
"Harrison A., Lifschitz V., Raju D.","Program completion in the input language of GRINGO",2017,"Theory and Practice of Logic Programming",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032568883&doi=10.1017%2fS1471068417000394&partnerID=40&md5=b70e0bf7f95e74ece109a3b011dca38e","We argue that turning a logic program into a set of completed definitions can be sometimes thought of as the reverse engineering process of generating a set of conditions that could serve as a specification for it. Accordingly, it may be useful to define completion for a large class of Answer Set Programming (ASP) programs and to automate the process of generating and simplifying completion formulas. Examining the output produced by this kind of software may help programmers to see more clearly what their program does, and to what degree its behavior conforms with their expectations. As a step toward this goal, we propose here a definition of program completion for a large class of programs in the input language of the ASP grounder gringo, and study its properties. Copyright © Cambridge University Press 2017.","Answer Set Programming; formal methods; program completion","Computer programming; Formal methods; Reverse engineering; Answer set programming; Logic programs; Program completion; Reverse engineering process; Logic programming",2-s2.0-85032568883
"Beck H., Eiter T., Folie C.","Ticker: A system for incremental ASP-based stream reasoning",2017,"Theory and Practice of Logic Programming",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032589494&doi=10.1017%2fS1471068417000370&partnerID=40&md5=4b509577f69ee6070ed3edb97e2498b9","In complex reasoning tasks, as expressible by Answer Set Programming (ASP), problems often permit for multiple solutions. In dynamic environments, where knowledge is continuously changing, the question arises how a given model can be incrementally adjusted relative to new and outdated information. This paper introduces Ticker, a prototypical engine for well-defined logical reasoning over streaming data. Ticker builds on a practical fragment of the recent rule-based language LARS, which extends ASP for streams by providing flexible expiration control and temporal modalities. We discuss Ticker's reasoning strategies: first, the repeated one-shot solving mode calls Clingo on an ASP encoding. We show how this translation can be incrementally updated when new data is streaming in or time passes by. Based on this, we build on Doyle's classic justification-based truth-maintenance system to update models of non-stratified programs. Finally, we empirically compare the obtained evaluation mechanisms. Copyright © Cambridge University Press 2017.","Answer set programming; Non-monotonic reasoning; Stream reasoning","Computer programming; Knowledge representation; Logic programming; Answer set programming; Dynamic environments; Multiple solutions; Non-monotonic reasoning; Outdated information; Rule-based language; Stream reasonings; Temporal modalities; Computer hardware description languages",2-s2.0-85032589494
"Casey E., Barnum S., Griffith R., Snyder J., van Beek H., Nelson A.","Advancing coordinated cyber-investigations and tool interoperability using a community developed specification language",2017,"Digital Investigation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028386648&doi=10.1016%2fj.diin.2017.08.002&partnerID=40&md5=06a5edaba22961804999be4520804991","Any investigation can have a digital dimension, often involving information from multiple data sources, organizations and jurisdictions. Existing approaches to representing and exchanging cyber-investigation information are inadequate, particularly when combining data sources from numerous organizations or dealing with large amounts of data from various tools. To conduct investigations effectively, there is a pressing need to harmonize how this information is represented and exchanged. This paper addresses this need for information exchange and tool interoperability with an open community-developed specification language called Cyber-investigation Analysis Standard Expression (CASE). To further promote a common structure, CASE aligns with and extends the Unified Cyber Ontology (UCO) construct, which provides a format for representing information in all cyber domains. This ontology abstracts objects and concepts that are not CASE-specific, so that they can be used across other cyber disciplines that may extend UCO. This work is a rational evolution of the Digital Forensic Analysis eXpression (DFAX) for representing digital forensic information and provenance. CASE is more flexible than DFAX and can be utilized in any context, including criminal, corporate and intelligence. CASE also builds on the Hansken data model developed and implemented by the Netherlands Forensic Institute (NFI). CASE enables the fusion of information from different organizations, data sources, and forensic tools to foster more comprehensive and cohesive analysis. This paper includes illustrative examples of how CASE can be implemented and used to capture information in a structured form to advance sharing, interoperability and analysis in cyber-investigations. In addition to capturing technical details and relationships between objects, CASE provides structure for representing and sharing details about how cyber-information was handled, transferred, processed, analyzed, and interpreted. CASE also supports data marking for sharing information at different levels of trust and classification, and for protecting sensitive and private information. Furthermore, CASE supports the sharing of knowledge related to cyber-investigations, including distinctive patterns of activity/behavior that are common across cases. This paper features a proof-of-concept Application Program Interface (API) to facilitate implementation of CASE in tools. Community members are encouraged to participate in the development and implementation of CASE and UCO. © 2017","Cyber-investigation; CybOX; DFAX; DFXML; Digital evidence exchange; Digital forensics; Evidence provenance; Information sharing; Specification language; Standard representation; Unified cyber ontology","Application programming interfaces (API); Application programs; Classification (of information); Computer forensics; Digital forensics; Electronic crime countermeasures; Interoperability; Ontology; Societies and institutions; Specification languages; Specifications; Cyber-investigation; CybOX; DFAX; DFXML; Digital evidence; Evidence provenance; Information sharing; Information dissemination",2-s2.0-85028386648
"Khatavkar P., Mays L.W.","Model for Optimal Operation of Water Distribution Pumps with Uncertain Demand Patterns",2017,"Water Resources Management",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019674660&doi=10.1007%2fs11269-017-1712-8&partnerID=40&md5=99e2547d65b114a035243224137ce8be","An optimization model is presented for pump operation based upon minimizing operation costs and indirectly the maintenance costs of pumps considering uncertainty of specified demand (load) curves. The purpose of this model is to determine pump operation to meet the uncertain demands as well as to satisfy the pressure requirements in the water distribution system. In addition, constraints on the number of pump (‘on-off’) switches are included as a surrogate to indirectly minimizing the maintenance costs. This model is a mixed integer nonlinear programming (MINLP) problem using a chance constraint formulation of the uncertain demand constraint. The optimization model was solved using the LocalSolver option in A Mathematical Programming Language (AMPL). The model was first applied to the operation of an example pumping system for an urban water distribution system (WDS) illustrating a reduction in operation costs using the optimization model. The optimization model with the chance-constraint for demand was applied for a range of demand satisfaction uncertainties. A decrease in the operation costs was observed with an increased uncertainty in demand satisfaction, which shows that the model further optimizes the operations considering the relaxed constraints. Model application could be extended to operations of pumping systems during emergencies and contingencies such as droughts, component failures etc. © 2017, Springer Science+Business Media Dordrecht.","Optimal operation; Pumps; Uncertain demand; Water distribution","Costs; Curve fitting; Integer programming; Maintenance; Mathematical programming; Nonlinear programming; Operating costs; Optimization; Pumping plants; Pumps; Water supply systems; Component failures; Mixed integer non-linear programming problems; Optimal operation; Optimization modeling; Uncertain demand; Uncertainty in demand; Urban water distribution system; Water distributions; Water distribution systems; distribution system; numerical model; optimization; pumping; water demand; water supply",2-s2.0-85019674660
"Santos A.L., Prendi G., Sousa H., Ribeiro R.","Stepwise API usage assistance using n-gram language models",2017,"Journal of Systems and Software",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85003443942&doi=10.1016%2fj.jss.2016.06.063&partnerID=40&md5=f0f5854667243fb0305845e673529321","Reusing software involves learning third-party APIs, a process that is often time-consuming and error-prone. Recommendation systems for API usage assistance based on statistical models built from source code corpora are capable of assisting API users through code completion mechanisms in IDEs. A valid sequence of API calls involving different types may be regarded as a well-formed sentence of tokens from the API vocabulary. In this article we describe an approach for recommending subsequent tokens to complete API sentences using n-gram language models built from source code corpora. The provided system was integrated in the code completion facilities of the Eclipse IDE, providing contextualized completion proposals for Java taking into account the nearest lines of code. The approach was evaluated against existing client code of four widely used APIs, revealing that in more than 90% of the cases the expected subsequent token is within the 10-top-most proposals of our models. The high score provides evidence that the recommendations could help on API learning and exploration, namely through the assistance on writing valid API sentences. © 2016 Elsevier Inc.","API; Code completion; IDE; N-grams; Usability","Codes (symbols); Computational linguistics; Integrodifferential equations; Code completions; Error prones; Lines of code; N-gram language models; N-grams; Source codes; Third parties; Usability; Application programming interfaces (API)",2-s2.0-85003443942
"Casellas R., Vilalta R., Mayoral A., Martinez R., Munoz R., Contreras L.M.","Control plane architectures enabling transport network adaptive and autonomic operation",2017,"International Conference on Transparent Optical Networks",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031007700&doi=10.1109%2fICTON.2017.8025013&partnerID=40&md5=22735a99e1f223c8980ef072f3327886","The maturity and flexibility of Software Defined Networking principles, favouring centralized control deployments, featured application programming interfaces and the development of a related application ecosystem, has paved the way for the design and implementation of advanced and adapted control plane architectures that specially target and enable efficient and massive monitoring and data collection. In this line, the steady increase in the use of open and standard interfaces and data modelling languages, as well as the wide adoption (in a vendor independent way) of model-driven solutions and a unified approach for data collection and processing facilitates shifting the focus to the actual processing of information, towards autonomic networks and self-∗ capabilities. Scoped to the control of a flexi-grid optical transport network, and in line with major industry trends, in this paper we cover our requirements for efficient data collection and processing, and we propose and detail a control and management architecture, building on the concepts of front-end and back-end entities, dynamic instantiation of control plane functions within the ETSI NFV framework and the applicability to use cases such as in-operation network planning, on-demand network optimization and parameter tuning. © 2017 IEEE.","active stateful PCE; front-end/back-end architectures; in operation network planning; on-demand control functions; SDN/NFV control of optical networks; service function placement","Adaptive control systems; Adaptive optics; Application programming interfaces (API); Application programs; Computer systems programming; Data acquisition; Data handling; Fiber optic networks; Information management; Modeling languages; Network function virtualization; Signal systems; Transparent optical networks; Control functions; Front end; Network planning; Service functions; Stateful pce; Network architecture",2-s2.0-85031007700
"Colvin R.J., Hayes I.J., Meinicke L.A.","Designing a semantic model for a wide-spectrum language with concurrency",2017,"Formal Aspects of Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014014408&doi=10.1007%2fs00165-017-0416-4&partnerID=40&md5=3d987d6266042488a4c62f1e34eb9c1f","A wide-spectrum language integrates specification constructs into a programming language in a manner that treats a specification command just like any other command. The primary contribution of this paper is a semantic model for a wide-spectrum language that supports concurrency and a refinement calculus. A distinguishing feature of the language is that steps of the environment are modelled explicitly, alongside steps of the program. From these two types of steps a rich set of specification commands can be constructed, based on operators for nondeterministic choice, and sequential and parallel composition. We also introduce a novel operator, weak conjunction, which is used extensively to conjoin separate aspects of specifications, allowing us to take a separation-of-concerns approach to subsequent reasoning. We provide a denotational semantics for the language based on traces, which may be terminating, aborting, infeasible, or infinite. To demonstrate the generality and unifying strength of the language, we use it to express a range of concepts from the concurrency literature, including: a refinement theory for rely/guarantee reasoning; an abstract specification of local variables in a concurrent context; specification of an abstract, linearisable data structure; a partial encoding of temporal logic; and defining the relationships between notions of nonblocking programs. The novelty of the paper is that these diverse concepts build on the same theory. In particular, the rely concept from Jones’ rely/guarantee framework, and a stronger demand concept that restricts the environment, are reused across the different domains to express assumptions about the environment. The language and model form an instance of an abstract concurrent program algebra, and this facilitates reasoning about properties of the model at a high level of abstraction. © 2017, British Computer Society.","Concurrency; Program algebra; Refinement calculus; Rely-guarantee; Wide-spectrum language","Abstracting; Algebra; Calculations; Concurrency control; Semantics; Specifications; Concurrency; Program algebra; Refinement calculi; Rely guarantees; Wide spectrum language; High level languages",2-s2.0-85014014408
"Luong J., Habich D., Lehner W.","AL: Unified analytics in domain specific terms",2017,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030557622&doi=10.1145%2f3122831.3122835&partnerID=40&md5=6313e67a3948b53c77a7f95e78ae69b7","Data driven organizations gather information on various aspects of their endeavours and analyze that information to gain valuable insights or to increase automatization. Today, these organizations can choose from a wealth of specialized analytical libraries and platforms to meet their functional and non-functional requirements. Indeed, many common application scenarios involve the combination of multiple such libraries and platforms in order to provide a holistic perspective. Due to the scattered landscape of specialized analytical tools, this integration can result in complex and hard to evolve applications. In addition, the necessary movement of data between tools and formats can introduce a serious performance penalty. In this article we present a unified programming environment for analytical applications. The environment includes AL, a programming language that combines concepts of various common analytical domains. Further, the environment also includes a flexible compilation system that uses a language-, domain-, and platform independent program intermediate representation to separate high level application logic and physical organisation. We provide a detailed introduction of AL, establish our program intermediate representation as a generally useful abstraction, and give a detailed explanation of the translation of AL programs into workloads for our experimental shared-memory processing engine. © 2017 Association for Computing Machinery.",,"Aluminum; Application programs; High level languages; Libraries; Analytical applications; High level applications; Holistic perspectives; Intermediate representations; Non-functional requirements; Performance penalties; Platform independent; Programming environment; Program translators",2-s2.0-85030557622
"Veloso M.V.D., Filho J.T.C., Barreto G.A.","SOM4R: a Middleware for Robotic Applications Based on the Resource-Oriented Architecture",2017,"Journal of Intelligent and Robotic Systems: Theory and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013426718&doi=10.1007%2fs10846-017-0504-y&partnerID=40&md5=a37506ae52cf28045a0e2d646e967ef9","This paper relies on the resource-oriented architecture (ROA) to propose a middleware that shares resources (sensors, actuators and services) of one or more robots through the TCP/IP network, providing greater efficiency in the development of software applications for robotics. The proposed middleware consists of a set of web services that provides access to representational state of resources through simple and high-level interfaces to implement a software architecture for autonomous robots. The benefits of the proposed approach are manifold: i) full abstraction of complexity and heterogeneity of robotic devices through web services and uniform interfaces, ii) scalability and independence of the operating system and programming language, iii) secure control of resources for local or remote applications through the TCP/IP network, iv) the adoption of the Resource Description Framework (RDF), XML language and HTTP protocol, and v) dynamic configuration of the connections between services at runtime. The middleware was developed using the Linux operating system (Ubuntu), with some applications built as proofs of concept for the Android operating system. The architecture specification and the open source implementation of the proposed middleware are detailed in this article, as well as applications for robot remote control via wireless networks, voice command functionality, and obstacle detection and avoidance. © 2017, Springer Science+Business Media Dordrecht.","BPMN diagrams; Middleware; Mobile robotics; Resource-oriented architecture; Subsumption architecture","Application programs; Complex networks; Computer operating systems; Computer systems programming; HTTP; Hypertext systems; Identification (control systems); Interface states; Internet protocols; Linux; Middleware; Network security; Obstacle detectors; Open source software; Remote control; Robot programming; Robotics; Robots; Transmission control protocol; Web services; Websites; Architecture specification; BPMN diagrams; LINUX- operating system; Mobile robotic; Open source implementation; Resource description framework; Resource-oriented architectures; Subsumption architecture; Network architecture",2-s2.0-85013426718
"Han S.","Completion comprehension of complex sentences dependent on multiple fuzzy implication",2017,"Boletin Tecnico/Technical Bulletin",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032878667&partnerID=40&md5=92912520598a544fec5c507a696bbd98","The study of English complex sentences comprehension is a hot topic in the field of NLP. In the English complex sentence comprehension, a good answer strategy in the complex problem is not only to extract the answer sentence, but also to merge the answer sentence and to generate the corresponding answer, but most of the current researches focuson the former. In this paper, we study the sentence completion comprehension during complex problems solved, and propose a method for completion comprehension of complex sentences dependent on multiple fuzzy implication. The main ideas of this method are as follows: Firstly, the merging part is selected based on sentence segmentation and word importance degree. Then, the same information is merged based on multiple fuzzy. Finally, it generates sentences based on the dependency relation, binary language model and word importance degree integer linear programming optimization. The results of the test on the college entrance examination English reading comprehension data set over the years show that the method achieved 82.62% F value, but ensured the readability and the amount of information of the results.","Complex problem; English complex sentence comprehension; Sentence completion comprehension","Integer programming; Statistical tests; Amount of information; Complex problems; Complex sentences; Entrance examination; Integer Linear Programming; Reading comprehension; Sentence completions; Sentence segmentation; Fuzzy inference",2-s2.0-85032878667
"Turek W., Cetnarowicz K., Borkowski A.","On human-centric and robot-centric perspective of a building model",2017,"Automation in Construction",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019044949&doi=10.1016%2fj.autcon.2017.03.018&partnerID=40&md5=5224fd01e2b2307c6d5e60e5c5b523dd","The effectiveness of mobile robots operating in buildings depends strongly on their ability to cooperate with people. The cooperation requires a common language for communication. In this paper, the problem of modelling buildings in the context of communication between humans and robots is considered. Significant differences between the perception of building elements by humans and robots are discussed at the onset. This analysis allows us to propose a human-oriented building model, which represents elements, features and relations used by people in communication. This model warrants the unambiguous identification of building elements, which forms a good basis for the communication between humans and robots. Further, the model is implemented by means of a flexible, document-based database. Finally, a mapping between the proposed model and the existing robot-oriented models of buildings is proposed, followed by case studies that demonstrate the usage of the proposed methodology. © 2017 Elsevier B.V.","Human-robot interaction; In-door mobile robots; Localization; Mapping; Navigation; Path-planning","Building components; Buildings; Human robot interaction; Mapping; Mobile robots; Motion planning; Navigation; Robot programming; Building element; Building model; Case-studies; Common languages; Document-based; Human-centric; In-buildings; Localization; Robots",2-s2.0-85019044949
"Rabe F.","How to identify, translate and combine logics?",2017,"Journal of Logic and Computation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031903775&doi=10.1093%2flogcom%2fexu079&partnerID=40&md5=e16c2f3576a342144eb20c632d0c8c5d","We give general definitions of logical frameworks and logics. Examples include the logical frameworks LF and Isabelle and the logics represented in them.We apply this to give general definitions for equivalence of logics, translation between logics and combination of logics.We also establish general criteria for the soundness and completeness of these. Our key messages are that the syntax and proof systems of logics are theories; that both semantics and translations are theory morphisms; and that combinations are colimits. Our approach is based on the Mmt language, which lets us combine formalist declarative representations (and thus the associated tool support) with abstract categorical conceptualizations. © The Author, 2014. Published by Oxford University Press. All rights reserved.","Combination; Completeness; Logical framework; MMT; Semantics; Soundness; Translation; Universal logic","Computer science; Formal logic; Logic programming; Translation (languages); Combination; Completeness; Logical frameworks; Soundness; Universal logic; Semantics",2-s2.0-85031903775
"Andreasen E., Gong L., Møller A., Pradel M., Selakovic M., Sen K., Staicu C.-A.","A survey of dynamic analysis and test generation for JavaScript",2017,"ACM Computing Surveys",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030684310&doi=10.1145%2f3106739&partnerID=40&md5=ab31f54da216d37de49049fb3f01ab99","JavaScript has become one of the most prevalent programming languages. Unfortunately, some of the unique properties that contribute to this popularity also make JavaScript programs prone to errors and difficult for program analyses to reason about. These properties include the highly dynamic nature of the language, a set of unusual language features, a lack of encapsulation mechanisms, and the ""no crash"" philosophy. This article surveys dynamic program analysis and test generation techniques for JavaScript targeted at improving the correctness, reliability, performance, security, and privacy of JavaScript-based software. © 2017 ACM.","Dynamic languages; Program analysis; Test generation","High level languages; Reliability analysis; Software reliability; Surveys; Dynamic languages; Dynamic nature; Dynamic program analysis; Javascript; JavaScript programs; Language features; Program analysis; Test generations; Software testing",2-s2.0-85030684310
"Mathew J.D., Huot S., Katz B.F.G.","Survey and implications for the design of new 3D audio production and authoring tools",2017,"Journal on Multimodal User Interfaces",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018356111&doi=10.1007%2fs12193-017-0245-z&partnerID=40&md5=3e5eb5d43c72ce042fcfbf5cadca1ddf","3D audio production tools vary from low-level programming libraries to higher-level user interfaces that are used across a wide range of applications. However, many of the user interfaces for authoring 3D audio parameters are underdeveloped, forcing users to resort to ad hoc solutions with other tools or programming languages. Identifying these limitations and custom methods are needed to inform the development of new user interfaces. Towards this end, an on-line survey was conducted with current practitioners to gather ethnographic information on their tools, methods, and opinions. Results of the survey revealed specific methods and limitations within authoring techniques and 3D audio production with regards to Audio Rendering and Recording, Visual Feedback, Functionality, and Workflow Integration. These results also shed light on three basic tasks that have to be performed interactively with 3D audio production tools: Defining the Rendering Space, Creation and Manipulation of Audio Objects, and Monitoring with Audio/Visual Feedback. This classification helps identifying the needs for 3D audio tools that address issues within the workflow and low-level functionality of systems. © 2017, SIP.","3D audio; HCI; Survey; User interfaces","Audio systems; Human computer interaction; Surveying; Surveys; Three dimensional computer graphics; Visual communication; 3D audio; Audio rendering; Authoring tool; Low level programming; Online surveys; Production tools; Visual feedback; Workflow integration; User interfaces",2-s2.0-85018356111
"Cox J.H., Clark R., Owen H.","Leveraging SDN and WebRTC for Rogue Access Point Security",2017,"IEEE Transactions on Network and Service Management",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029355000&doi=10.1109%2fTNSM.2017.2710623&partnerID=40&md5=a9cf339956319ff23783f53961366987","Rogue access points (RAPs) are unauthorized devices connected to a network, providing unauthorized wireless access to one or more clients. Such devices pose significant risk to organizations, since they provide a convenient means for hackers and insiders to hide malicious or unsanctioned activities on industry, government, and campus networks. Yet, limitations inherent in traditional networks make detecting and removing such devices expensive, time consuming, and difficult to implement. For software-defined networks (SDNs), the risk of a network compromise due to RAPs is equally concerning, and methods for detecting RAPs within SDN architectures are needed. Hence, this paper leverages the capabilities of an SDN along with a trusted agent to detect and deny RAPs access to networks by using both generic and novel methods with minimal impact to performance. Three other contributions are included in this paper. They include: 1) utilizing an emerging Web architecture to detect hidden subnets; 2) developing the first, security-based, use case for Mininet-WiFi, a software-defined wireless network emulator; and 3) enhancing Ryuretic, a modular programming language for SDN application development. © 2004-2012 IEEE.","intrusion detection prevention system (IDPS); malicious access point; Network address translation (NAT); network security; rogue access point (RAP); Ryu; Ryuretic; software-defined networks (SDN); trusted agent; WebRTC","Application programs; Computer systems programming; Intrusion detection; Network architecture; Personal computing; Software agents; Software defined networking; Wi-Fi; Access points; Network address translations; Prevention systems; Ryuretic; Trusted agents; WebRTC; Network security",2-s2.0-85029355000
"Hillerström D., Lindley S., Atkey R., Sivaramakrishnan K.C.","Continuation passing style for effect handlers",2017,"Leibniz International Proceedings in Informatics, LIPIcs",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030565947&doi=10.4230%2fLIPIcs.FSCD.2017.18&partnerID=40&md5=7ba153b8d24dfebb114612e488c0efaf","We present Continuation Passing Style (CPS) translations for Plotkin and Pretnar's effect handlers with Hillerström and Lindley's row-Typed fine-grain call-by-value calculus of effect handlers as the source language. CPS translations of handlers are interesting theoretically, to explain the semantics of handlers, and also offer a practical implementation technique that does not require special support in the target language's runtime. We begin with a first-order CPS translation into untyped lambda calculus which manages a stack of continuations and handlers as a curried sequence of arguments. We then refine the initial CPS translation first by uncurrying it to yield a properly tail-recursive translation and second by making it higher-order in order to contract administrative redexes at translation time. We prove that the higher-order CPS translation simulates effect handler reduction. We have implemented the higher-order CPS translation as a JavaScript backend for the Links programming language. © Daniel Hillerström, Sam Lindley, Robert Atkey, and K. C. Sivaramakrishnan.","Continuation passing style; Delimited control; Effect handlers","Calculations; Differentiation (calculus); Program translators; Semantics; Continuation-passing style; Effect handlers; Higher-order; Implementation techniques; Source language; Tail recursive; Target language; Untyped lambda calculus; Translation (languages)",2-s2.0-85030565947
"Dufek A.S., Augusto D.A., Dias P.L.S., Barbosa H.J.C.","Application of evolutionary computation on ensemble forecast of quantitative precipitation",2017,"Computers and Geosciences",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020912637&doi=10.1016%2fj.cageo.2017.06.011&partnerID=40&md5=7bcc59ad8a651c2ed010a0f84d807b8f","An evolutionary computation algorithm known as genetic programming (GP) has been explored as an alternative tool for improving the ensemble forecast of 24-h accumulated precipitation. Three GP versions and six ensembles’ languages were applied to several real-world datasets over southern, southeastern and central Brazil during the rainy period from October to February of 2008–2013. According to the results, the GP algorithms performed better than two traditional statistical techniques, with errors 27–57% lower than simple ensemble mean and the MASTER super model ensemble system. In addition, the results revealed that GP algorithms outperformed the best individual forecasts, reaching an improvement of 34–42%. On the other hand, the GP algorithms had a similar performance with respect to each other and to the Bayesian model averaging, but the former are far more versatile techniques. Although the results for the six ensembles’ languages are almost indistinguishable, our most complex linear language turned out to be the best overall proposal. Moreover, some meteorological attributes, including the weather patterns over Brazil, seem to play an important role in the prediction of daily rainfall amount. © 2017 Elsevier Ltd","Ensemble weather forecast; Evolutionary computation; Genetic programming; Quantitative precipitation","Bayesian networks; Calculations; Evolutionary algorithms; Forecasting; Genetic algorithms; Genetic programming; Bayesian model averaging; Daily rainfall amounts; Ensemble forecasts; Ensemble weather forecasts; Model ensembles; Real-world datasets; Statistical techniques; Weather patterns; Weather forecasting; Bayesian analysis; ensemble forecasting; genetic algorithm; precipitation (climatology); quantitative analysis; rainfall; weather forecasting; Brazil",2-s2.0-85020912637
"Brand M., Dowe D.L.","The IMP game: Learnability, approximability and adversarial learning beyond Σ1",2017,"Journal of Logic and Computation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032645393&doi=10.1093%2flogcom%2fexw031&partnerID=40&md5=c187cbcbdca5cec1ce88e5b6cca5b34e","We introduce a problem set-up we call the Iterated Matching Pennies (IMP) game and show that it is a powerful framework for the study of three problems: adversarial learnability, conventional (i.e. non-adversarial) learnability and approximability. Using it, we are able to derive the following theorems. (i) It is possible to learn by example all of σ1 1 as well as some supersets; (ii) in adversarial learning (which we describe as a pursuit-evasion game), the pursuer has a winning strategy (in other words, σ1 can be learned adversarially, but 0 1 not); (iii) some languages in σ1 cannot be approximated by any language in σ1. In particular, we show that some languages that are not computable are nevertheless learnable by example. We show corresponding results also for σi and 0 i for arbitrary i. © 2017 The Author.","adversarial learning; approximability; approximation; decidable; elusive model paradox; halting; halting problem; learnability; matching pennies; Nash equilibrium; recursively enumerable; red herring sequence; Turing machine","Computer science; Formal logic; Logic programming; Adversarial learning; Approximability; approximation; decidable; elusive model paradox; halting; Halting problems; Learnability; matching pennies; Nash equilibria; recursively enumerable; red herring sequence; Turing machines",2-s2.0-85032645393
"Rose F., Toher C., Gossett E., Oses C., Nardelli M.B., Fornari M., Curtarolo S.","AFLUX: The LUX materials search API for the AFLOW data repositories",2017,"Computational Materials Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020924537&doi=10.1016%2fj.commatsci.2017.04.036&partnerID=40&md5=680ee99c4c22ddbb35d1df84711d7155","Automated computational materials science frameworks rapidly generate large quantities of materials data for accelerated materials design. In order to take advantage of these large databases, users should have the ability to efficiently search and extract the desired data. Therefore, we have extended the data-oriented AFLOW-repository Application-Program-Interface (API) (Comput. Mater. Sci. 93, 178 (2014)) to enable programmatic access to search queries. A Uniform Resource Identifier (URI)-based search API is proposed for the construction of complex queries for remote creation and retrieval of customized data sets. It is expected that the new language, AFLUX, from “Automatic Flow of LUX (light)”, will enable remote search operations on the AFLOW set of computational materials science data repositories. In addition, AFLUX facilitates the verification and validation of the data in the AFLOW repositories. © 2017 Elsevier B.V.",,"Application programs; Query processing; Application program interfaces; Complex queries; Computational materials science; Data repositories; Materials design; Search operations; Uniform resource identifiers; Verification-and-validation; Application programming interfaces (API)",2-s2.0-85020924537
"Panarin A., Sklyar V., Kharchenko V., Kovalenko A., Babeshko E.","Modeling of industrial FPGA-based controllers with ForSyDe",2017,"Proceedings of the International Conference on Information and Digital Technologies, IDT 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030088135&doi=10.1109%2fDT.2017.8024290&partnerID=40&md5=ef4067b94023c31c94932a956e8b4065","The paper includes results of the theoretical research and practical application of soft-processors testing, in particular Nios compiler of Altera SoPC Builder core. The model is based on Model-Based Testing concept. ForSyDe programming formal language is used as instrument for the development of soft-processor reference program model. Stages of model development with the follow-up analysis and comparison of performance results are introduced. © 2017 IEEE.","Altera SoPC Builder; ForSyDe; Model-Based Testing; modeling; Nios; soft-processor","Field programmable gate arrays (FPGA); Formal languages; Model checking; Models; Program processors; Altera SoPC Builder; ForSyDe; Model based testing; Nios; Soft processors; Program compilers",2-s2.0-85030088135
"Kadiyala A., Kumar A.","Applications of R to evaluate environmental data science problems",2017,"Environmental Progress and Sustainable Energy",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021270876&doi=10.1002%2fep.12676&partnerID=40&md5=08b106de0212d7d26c24ff910dfea543","Open source programming languages and software platforms play a vital role in the progress of research towards developing new methods for addressing data science problems. R is one such platform that the research community may adapt and make the required changes to the codes in accordance with the requisite needs, specifically when analyzing data in different forms (structured, semistructured, unstructured). This study demonstrated the applications of R for analyzing in-bus carbon dioxide concentrations by: (i) importing the data into RStudio; (ii) performing an exploratory data analysis; (iii) developing statistical regression models; and (iv) developing tree models using machine learning methods. The readers may adopt the methods discussed in this paper to successfully address their own data science problems. © 2017 American Institute of Chemical Engineers Environ Prog, 36: 1358–1364, 2017. © 2017 American Institute of Chemical Engineers Environ Prog","biodiesel; CRAN; data science; in-bus air contaminants; indoor air quality; public transportation buses; R; RStudio","Air quality; Biodiesel; Buses; Carbon; Carbon dioxide; Indoor air pollution; Learning systems; Open source software; Open systems; Problem oriented languages; Regression analysis; Trees (mathematics); Air contaminants; CRAN; Data science; Indoor air quality; Public transportation; RStudio; Data flow analysis",2-s2.0-85021270876
"Zambrano-Serrano E., Muñoz-Pacheco J.M., Campos-Cantón E.","Chaos generation in fractional-order switched systems and its digital implementation",2017,"AEU - International Journal of Electronics and Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028625716&doi=10.1016%2fj.aeue.2017.05.032&partnerID=40&md5=f8f183617aebf8d0d43046aa5ec81f5f","A double-scroll chaotic attractor generated by a fractional-order switched system is presented. Based on unstable dissipative systems (UDS) and a switching law, a fractional-order UDS is proposed. Chaos behavior is found with a fractional order as low as 2.568 by satisfying the stability criterion for fractional order chaotic systems. The fractional-order switched system is transformed to an equivalent switched system with augmented states. Then, the equivalent system is straightforward implemented on an ARM system-on-chip board by using Python high level programming language. Numerical simulations are in good agreement with experimental results, which demonstrates the usefulness of proposed method. Additionally, the test 0–1 and a chaos definition for finite state sets are given to demonstrate chaotic behavior. Finally, a random number generator is also proposed as a possible application. © 2017 Elsevier GmbH","ARM architecture; Chaotic attractor; Embedded hardware; Fractional-order; Switched systems","ARM processors; Chaotic systems; Embedded systems; High level languages; Number theory; Numerical methods; Stability criteria; Switching systems; System-on-chip; ARM architecture; Chaotic attractors; Embedded hardware; Fractional order; Switched system; Random number generation",2-s2.0-85028625716
"Bourke T., Carcenac F., Colaço J.-L., Pagano B., Pasteur C., Pouzet M.","A synchronous look at the Simulink standard library",2017,"ACM Transactions on Embedded Computing Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030661464&doi=10.1145%2f3126516&partnerID=40&md5=2b2717b5efa1167cc40ecdf2fd6a51e9","Hybrid systems modelers like Simulink come with a rich collection of discrete-time and continuous-time blocks. Most blocks are not defined in terms of more elementary ones-and some cannot be-but are instead written in imperative code and explained informally in a reference manual. This raises the question of defining a minimal set of orthogonal programming constructs such that most blocks can be programmed directly and thereby given a specification that is mathematically precise, and whose compiled version performs comparably to handwritten code. In this paper, we showthat a fairly large set of blocks of a standard library like the one provided by Simulink can be programmed in a precise, purely functional language using stream equations, hierarchical automata, Ordinary Differential Equations (ODEs), and deterministic synchronous parallel composition. Some blocks cannot be expressed in our setting as they mix discrete-time and continuous-time signals in unprincipled ways that are statically forbidden by the type checker. The experiment is conducted in Zélus, a synchronous language that conservatively extends Lustre with ODEs to program systems that mix discrete-time and continuous-time signals. © 2017 ACM.","Block diagrams; Hybrid systems; Synchronous languages","Computer hardware description languages; Differential equations; Hybrid systems; Ordinary differential equations; Block diagrams; Continuous-time; Continuous-time signal; Program systems; Purely functional; Standard libraries; Synchronous languages; Synchronous parallel compositions; Continuous time systems",2-s2.0-85030661464
"Lawrie D.S.","Accelerating wright-fisher forward simulations on the graphics processing unit",2017,"G3: Genes, Genomes, Genetics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029035900&doi=10.1534%2fg3.117.300103&partnerID=40&md5=32255f2f0a13ddba677299f66de8cd60","Forward Wright-Fisher simulations are powerful in their ability to model complex demography and selection scenarios, but suffer from slow execution on the Central Processor Unit (CPU), thus limiting their usefulness. However, the single-locus Wright-Fisher forward algorithm is exceedingly parallelizable, with many steps that are so-called ""embarrassingly parallel,"" consisting of a vast number of individual computations that are all independent of each other and thus capable of being performed concurrently. The rise of modern Graphics Processing Units (GPUs) and programming languages designed to leverage the inherent parallel nature of these processors have allowed researchers to dramatically speed up many programs that have such high arithmetic intensity and intrinsic concurrency. The presented GPU Optimized Wright-Fisher simulation, or ""GO Fish"" for short, can be used to simulate arbitrary selection and demographic scenarios while running over 250-fold faster than its serial counterpart on the CPU. Even modest GPU hardware can achieve an impressive speedup of over two orders of magnitude. With simulations so accelerated, one can not only do quick parametric bootstrapping of previously estimated parameters, but also use simulated results to calculate the likelihoods and summary statistics of demographic and selection models against real polymorphism data, all without restricting the demographic and selection scenarios that can be modeled or requiring approximations to the single-locus forward algorithm for efficiency. Further, as many of the parallel programming techniques used in this simulation can be applied to other computationally intensive algorithms important in population genetics, GO Fish serves as an exciting template for future research into accelerating computation in evolution. © 2017 Lawrie.","Genetics; GPU; Population; Simulation; Wright-Fisher model","arithmetic; bootstrapping; computer language; demography; DNA polymorphism; human; population genetics; running; scientist; simulation; statistics; velocity",2-s2.0-85029035900
"Wetzel H.N., Cohen C., Norman A.B., Webster R.P.","A novel Python program for implementation of quality control in the ELISA",2017,"Journal of Immunological Methods",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020225368&doi=10.1016%2fj.jim.2017.05.012&partnerID=40&md5=8182bc90d0cecc5aa0fd6da8f6fc53e4","The use of semi-quantitative assays such as the enzyme-linked immunosorbent assay (ELISA) requires stringent quality control of the data. However, such quality control is often lacking in academic settings due to unavailability of software and knowledge. Therefore, our aim was to develop methods to easily implement Levey-Jennings quality control methods. For this purpose, we created a program written in Python (a programming language with an open-source license) and tested it using a training set of ELISA standard curves quantifying the Fab fragment of an anti-cocaine monoclonal antibody in mouse blood. A colorimetric ELISA was developed using a goat anti-human anti-Fab capture method. Mouse blood samples spiked with the Fab fragment were tested against a standard curve of known concentrations of Fab fragment in buffer over a period of 133 days stored at 4°C to assess stability of the Fab fragment and to generate a test dataset to assess the program. All standard curves were analyzed using our program to batch process the data and to generate Levey-Jennings control charts and statistics regarding the datasets. The program was able to identify values outside of two standard deviations, and this identification of outliers was consistent with the results of a two-way ANOVA. This program is freely available, which will help laboratories implement quality control methods, thus improving reproducibility within and between labs. We report here successful testing of the program with our training set and development of a method for quantification of the Fab fragment in mouse blood. © 2017 Elsevier B.V.","ELISA; Levey-Jennings control charts; Python; Quality control","immunoglobulin F(ab) fragment; monoclonal antibody; cocaine; animal experiment; Article; batch process; blood sampling; colorimetry; computer language; controlled study; enzyme linked immunosorbent assay; mouse; nonhuman; priority journal; quality control; reproducibility; statistics; analysis of variance; animal; blood; calibration; Cocaine-Related Disorders; enzyme linked immunosorbent assay; evaluation study; immunology; laboratory automation; predictive value; procedures; software design; software validation; standard; standards; substance abuse; Analysis of Variance; Animals; Antibodies, Monoclonal; Automation, Laboratory; Calibration; Cocaine; Cocaine-Related Disorders; Enzyme-Linked Immunosorbent Assay; Immunoglobulin Fab Fragments; Mice; Predictive Value of Tests; Quality Control; Reference Standards; Reproducibility of Results; Software Design; Software Validation; Substance Abuse Detection",2-s2.0-85020225368
"Ghosh A., Qin S., Lee J., Wang G.-N.","An output instruction based PLC source code transformation approach for program logic simplification",2017,"Informatica (Slovenia)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031710497&partnerID=40&md5=c97af6dd14aff743de87817b880d7381","Due to the growing size and complexity of the PLC (Programmable Logic Controller) programs used for controlling the industrial processes, there is an increasing need for an approach that can help the users to understand the control logics of the PLC programs easily, and can assist them to analyze the programming errors effectively. In this paper, we propose an approach that takes the source code file of PLC program as the input; and transforms it into a hierarchical-structured XML (extensible markup language) file. The XML file format is based on the PLC output instructions and their corresponding conditions. It helps the users to identify the actual cause of a programming error quickly. In addition, a novel technique is applied that decomposes the PLC program into several smaller and modular sub-logic blocks. This makes the control logic simpler and easier to follow. An additional software application has also been developed for state-based graphical visualization of the XML file.","Instruction list; Ladder logic diagram; Programmable logic controller; Reengineering; XML","Application programs; Controllers; Cosine transforms; Hypertext systems; Programmable logic controllers; Programmed control systems; Reengineering; XML; Graphical visualization; Industrial processs; Instruction lists; Ladder logic diagram; PLC (programmable logic controller); Software applications; Source code transformation; XML (extensible markup language); Computer circuits",2-s2.0-85031710497
"Snowden L.R., Wallace N., Cordell K., Graaf G.","Increased mental health treatment financing, community-based organization's treatment programs, and latino-white children's financing disparities",2017,"Journal of Mental Health Policy and Economics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030184470&partnerID=40&md5=240e9a5fee2ff2b04bba0904a9635e33","Background: Latino child populations are large and growing, and they present considerable unmet need for mental health treatment. Poverty, lack of health insurance, limited English proficiency, stigma, undocumented status, and inhospitable programming are among many factors that contribute to Latino-White mental health treatment disparities. Lower treatment expenditures serve as an important marker of Latino children's low rates of mental health treatment and limited participation once enrolled in services. Aims: We investigated whether total Latino-White expenditure disparities declined when autonomous, county-level mental health plans receive funds free of customary cost-sharing charges, especially when they capitalized on cultural and language-sensitive mental health treatment programs as vehicles to receive and spend treatment funds. Using Whites as benchmark, we considered expenditure pattern disparities favoring Whites over Latinos and, in a smaller number of counties, Latinos over Whites. Methods: Using segmented regression for interrupted time series on county level treatment systems observed over 64 quarters, we analyzed Medi-Cal paid claims for per-user total expenditures for mental health services delivered to children and youth (under 18 years of age) during a study period covering July 1, 1991 through June 30, 2007. Settlement-mandated Medicaid's Early Periodic Screening, Diafnosis and Treatment (EPSDT) expenditure increases began in the third quarter of 1995. Terms were introduced to assess immediate and long term inequality reduction as well as the role of culture and language-sensitive community-based programs. Results: Settlement-mandated increased EPSDT treatment funding was associated with more spending on Whites relative to Latinos unless plans arranged for cultural and language-sensitive mental health treatment programs. However, having programs served more to prevent expenditure disparities from growing than to reduce disparities. Discussion: EPSDT expanded funding increased proportional expenditures for Whites absent cultural and language-sensitive treatment programs. The programs moderate, but do not overcome, entrenched expenditure disparities. These findings use investment in mental health services for Latino populations to indicate treatment access and utilization, but do not explicitly reflect penetration rates or intensity of services for consumers. Implications for Policy: New funding, along with an expectation that Latino children's well documented mental health treatment disparities will be addressed, holds potential for improved mental health access and reducing utilization inequities for this population, especially when specialized, culturally and linguistically sensitive mental health treatment programs are present to serve as recipients of funding. Implications for Research: To further expand knowledge of how federal or state funding for community based mental health services for low income populations can drive down the longstanding and considerable Latino-White mental health treatment disparities, we must develop and test questions targeting policy drivers which can channel funding to programs and organizations aimed at delivering linguistically and culturally sensitive services to Latino children and their families. Copyright © 2017 ICMPE.",,"adult; Caucasian; child; consumer; cost; driver; expectation; female; funding; Hispanic; human; human experiment; investment; juvenile; language; lowest income group; male; medicaid; mental health service; recipient; time series analysis; young adult",2-s2.0-85030184470
"Vasilyev V.","Online complete basis set limit extrapolation calculator",2017,"Computational and Theoretical Chemistry",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020479967&doi=10.1016%2fj.comptc.2017.06.001&partnerID=40&md5=91a8844f75fd4a5b70d162c13e86be80","Calculation of the asymptotic convergence of energies and other properties to their complete basis set (CBS) limit in Quantum Chemistry may be tedious, so a CBS Limit Extrapolation Calculator was developed to perform this task. Currently it implements 9 different extrapolation expressions and it was written in a JavaScript programming language. Calculator is implemented as a Dynamic HTML (DHTML) page, with the JavaScript handling input, its validation, numerical calculations as well as plotting using the Google Chart library. © 2017","CBS limit; DHTML; Extrapolation; Google Chart; JavaScript",,2-s2.0-85020479967
"Alhaddad E.M., Eassa F.E.","High performance and scalable big data manager",2017,"Journal of Computational and Theoretical Nanoscience",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027976817&doi=10.1166%2fjctn.2017.6861&partnerID=40&md5=be3d9d430b5857a28a0e48449b8ada10","Big data management and analysis is a challenge for both research and business communities. Big data comes with huge volume, diverse data structures and rapid change; existing data management systems, such as parallel databases, fail to cope with data with such unique properties. In this work, a framework for big data management and analysis is proposed. It resolves big data challenges and also achieve high performance, scalability, fault-tolerance and usability. Programmers can write their own analysis task using the high level programming language of their choice and the framework handle the low level execution complications and get back with the results. Copyright © 2017 American Scientific Publishers All rights reserved.","Agent; Big data; Cluster computing; Data analysis; Data management; Metadata",,2-s2.0-85027976817
"Veerendra A., Premalatha J., Vengadeshwari R.S.","Optimization of transmission tower using genetic algorithm",2017,"International Journal of Civil Engineering and Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029903285&partnerID=40&md5=03a362578d51be173f08acce625794a1","Optimization is the act of obtaining best results under given situations. In civil engineering optimization is essential for design, construction and maintenance. The ultimate goal of engineers is either to maximize the desired benefits or minimize the efforts required. In any practical situations, desired benefits or required efforts can be expressed as a maximum or minimum function with certain design variables and constraints. New approaches to the structural optimization are supported by the development of mathematical programming techniques. In this study weight optimization was carried out for a transmission tower structure which has 484 members. Analysis of the tower structure was carried out using STAAD Pro V8i by considering IS 802 (part 1/sec 1): 1995 and the design of members was carried out according to IS 800: 2007. Algorithm for optimization was done using Python Programming language. © IAEME Publication.","Genetic algorithm; Genetic operators; Optimization; Transmission tower",,2-s2.0-85029903285
"Grover P., Kar A.K.","Big Data Analytics: A Review on Theoretical Contributions and Tools Used in Literature",2017,"Global Journal of Flexible Systems Management",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022085662&doi=10.1007%2fs40171-017-0159-3&partnerID=40&md5=c7d6773137db1f3352033e038ce86e81","The importance of data science and big data analytics is growing very fast as organizations are gearing up to leverage their information assets to gain competitive advantage. The flexibility offered through big data analytics empowers functional as well as firm-level performance. In the first phase of the study, we attempt to analyze the research on big data published in high-quality business management journals. The analysis was visualized using tools for big data and text mining to understand the dominant themes and how they are connected. Subsequently, an industry-specific categorization of the studies was done to understand the key use cases. It was found that most of the existing research focuses majorly on consumer discretionary, followed by public administration. Methodologically, a major focus in such exploration is in social media analytics, text mining and machine learning applications for meeting objectives in marketing and supply chain management. However, it was found that not much focus was highlighted in these studies to demonstrate the tools used for the analysis. To address this gap, this study also discusses the evolution, types and usage of big data tools. The brief overview of big data technologies grouped by the services they enable and some of their applications are presented. The study categorizes these tools into big data analysis platforms, databases and data warehouses, programming languages, search tools, and data aggregation and transfer tools. Finally, based on the review, future directions for exploration in big data has been provided for academic and practice. © 2017, Global Institute of Flexible Systems Management.","Big data; Big data technologies; Data science; Information management; Systematic literature review",,2-s2.0-85022085662
"Bozorg-Haddad O., Garousi-Nejad I., Loáiciga H.A.","Extended multi-objective firefly algorithm for hydropower energy generation",2017,"Journal of Hydroinformatics",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029384178&doi=10.2166%2fhydro.2017.114&partnerID=40&md5=c9502d4efa4620cbd8c381bf84cdfd0b","Classical methods have severe limitations (such as being trapped in local optima, and the curse of dimensionality) to solve optimization problems. Evolutionary or meta-heuristic algorithms are currently favored as the tools of choice for tackling such complex non-linear reservoir operations. This paper evaluates the performance of an extended multi-objective developed firefly algorithm (MODFA). The MODFA script code was developed using the MATLAB programming language and was applied in MATLAB to optimize hydropower generation by a three-reservoir system in Iran. The two objectives used in the present study are the maximization of the reliability of hydropower generation and the minimization of the vulnerability to generation deficits of the three-reservoir system. Optimal Paretos (OPs) obtained with the MODFA are compared with those obtained with the multi-objective genetic algorithm (MOGA) and the multi-objective firefly algorithm (MOFA) for different levels of performance thresholds (50%, 75%, and 100%). The case study results demonstrate that the MODFA is superior to the MOGA and MOFA for calculating proper OPs with distinct solutions and a wide distribution of solutions. This study's results show that the MODFA solves multi-objective multireservoir operation system with the purpose of hydropower generation that are highly nonlinear that classical methods cannot solve.","Firefly algorithm; Hydropower generation; Multi-objective optimization; Multi-reservoir operation",,2-s2.0-85029384178
"Cseppentő L., Micskei Z.","Evaluating code-based test input generator tools",2017,"Software Testing Verification and Reliability",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012876215&doi=10.1002%2fstvr.1627&partnerID=40&md5=7de8f8e39c2de355c4c027a88d49eebc","In recent years, several tools have been developed to automatically select test inputs from the code of the system under test. However, each of these tools has different advantages, and there is a little detailed feedback available on the actual capabilities of the various tools. To evaluate test input generators, this paper collects a set of programming language concepts that should be handled by the tools and maps these core concepts and challenging features like handling the environment or multi-threading to 363 code snippets, respectively. These snippets would serve as inputs for the tools. Next, the paper presents SETTE, an automated framework to execute and evaluate these snippets. Using SETTE, multiple experiments were performed on five Java and one.NET-based tools using symbolic execution, search-based, and random techniques. The test suites' coverage, size, generation time, and mutation score were compared. The results highlight the strengths and weaknesses of each tool and approach and identify hard code parts that are difficult to tackle for most of the tools. We hope that this research could serve as actionable feedback to tool developers and help practitioners assess the readiness of test input generation. Copyright © 2017 John Wiley & Sons, Ltd.","software testing; test data; test generation; white-box testings","Codes (symbols); Testing; Detailed feedbacks; Generation time; Multi-threading; Symbolic execution; System under test; Test data; Test generations; White box; Software testing",2-s2.0-85012876215
"Ahmed M., Shoaib M.","A metrics driven design approach for real time environment application",2017,"International Arab Journal of Information Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028326123&partnerID=40&md5=eb5dd0f2e31cb166022d469f77fb49ad","Design of real time environment application is the most exigent task for the designers comparing to non Real Time Application (RTA) design. The stringent timing requirement for task completion is the problem to handle at design time. The design complexity is increased manifolds when object oriented design methods are used and task deadlines are introduced at design stage. There are many design methodologies available for the real time systems but as far as the researcher is concerned none addresses all the problems of real time system design specially the issues of deadline inheritance and dynamic behavior of system if deadlines are introduced at early stages of the design. Most of the methodologies leave the task of handling the timing constraints for the implementation phase at the programming language level. In this paper we have proposed a design approach incorporated with our novel design metrics verification for measuring the design of real time environment applications. The metrics are measured for design of a real time weapon delivery system and it is illustrated that how design quality can be assessed before implementation. © 2017, Zarka Private University. All rights reserved.","Deadlines; Design metrics; Real time systems; Timed state statecharts",,2-s2.0-85028326123
"Patel H.H.","Package-X 2.0: A Mathematica package for the analytic calculation of one-loop integrals",2017,"Computer Physics Communications",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019675389&doi=10.1016%2fj.cpc.2017.04.015&partnerID=40&md5=d00fb45de9b863f93241b935a4e1e3f6","This article summarizes new features and enhancements of the first major update of Package-X. Package-X 2.0 can now generate analytic expressions for arbitrarily high rank dimensionally regulated tensor integrals with up to four distinct propagators, each with arbitrary integer weight, near an arbitrary even number of spacetime dimensions, giving UV divergent, IR divergent, and finite parts at (almost) any real-valued kinematic point. Additionally, it can generate multivariable Taylor series expansions of these integrals around any non-singular kinematic point to arbitrary order. All special functions and abbreviations output by Package-X 2.0 support Mathematica's arbitrary precision evaluation capabilities to deal with issues of numerical stability. Finally, tensor algebraic routines of Package-X have been polished and extended to support open fermion chains both on and off shell. The documentation (equivalent to over 100 printed pages) is accessed through Mathematica's Wolfram Documentation Center and contains information on all Package-X symbols, with over 300 basic usage examples, 3 project-scale tutorials, and instructions on linking to FEYNCALC and LOOPTOOLS. New version program summary Program title: Package-X Program files doi: http://dx.doi.org/10.17632/yfkwrd4d5t.1 Licensing provisions: CC by 4.0 Programming language: Mathematica (Wolfram Language) Journal reference of previous version: H. H. Patel, Comput. Phys. Commun 197, 276 (2015) Does the new version supersede the previous version?: Yes Summary of revisions: Extension to four point one-loop integrals with higher powers of denominator factors, separate extraction of UV and IR divergent parts, testing for power IR divergences, construction of Taylor series expansions of one-loop integrals, numerical evaluation with arbitrary precision arithmetic, manipulation of fermion chains, improved tensor algebraic routines, and much expanded documentation. Nature of problem: Analytic calculation of one-loop integrals in relativistic quantum field theory. Solution method: Passarino–Veltman reduction formula, Denner–Dittmaier reduction formulae, and additional algorithms described in the manuscript. Restrictions: One-loop integrals are limited to those involving no more than four denominator factors. © 2017 Elsevier B.V.","Feynman integrals; One-loop; Passarino–Veltman","Algebra; Chains; Kinematics; Tensors; Tungsten; Analytic calculations; Analytic expressions; Feynman integrals; Mathematica packages; One-loop; Passarino-Veltman; Quantum field theory; Taylor series expansions; Taylor series",2-s2.0-85019675389
"Knight V.B., Serrano E.E.","Post-Translational Tubulin Modifications in Human Astrocyte Cultures",2017,"Neurochemical Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019187329&doi=10.1007%2fs11064-017-2290-0&partnerID=40&md5=4169daa909c505e7c6f19e55b166b105","The cytoskeletal protein tubulin plays an integral role in the functional specialization of many cell types. In the central nervous system, post-translational modifications and the expression of specific tubulin isotypes in neurons have been analyzed in greater detail than in their astrocytic counterparts. In this study, we characterized post-translational specifications of tubulin in human astrocytes using the normal human astrocyte (NHA; Lonza) commercial cell line of fetal origin. Immunocytochemical techniques were implemented in conjunction with confocal microscopy to image class III β-tubulin (βIII-tubulin), acetylated tubulin, and polyglutamylated tubulin using fluorescent antibody probes. Fluorescent probe intensity differences and colocalization were quantitatively assessed with the ‘EBImage’ package for the statistical programming language R. Colocalization analysis revealed that, although both acetylated tubulin and polyglutamylated tubulin showed a high degree of correlation with βIII-tubulin, the correlation with acetylated tubulin was stronger. Quantification and statistical analysis of fluorescence intensity demonstrated that the fluorescence probe intensity ratio for acetylated tubulin/βIII-tubulin was greater than the ratio for polyglutamylated tubulin/βIII-tubulin. The open source GEODATA set GSE819950, comprising RNA sequencing data for the NHA cell line, was mined for the expression of enzymes responsible for tubulin modifications. Our analysis uncovered greater expression at the mRNA level for enzymes reported to function in acetylation and deacetylation as compared to enzymes implicated in glutamylation and deglutamylation. Taken together, the results represent a step toward unraveling the tubulin isotypic expression profile and post-translational modification patterns in astrocytes during human brain development. © 2017, Springer Science+Business Media New York.","Acetylation; Astrocyte; Immunocytochemistry; Polyglutamylation; Post-translational modifications; Tubulin","beta tubulin; tubulin; Article; astrocyte; cell culture; confocal microscopy; controlled study; deacetylation; fluorescent antibody technique; human; human cell; immunocytochemistry; priority journal; protein acetylation; protein expression; protein localization; protein modification",2-s2.0-85019187329
"Askenazi M., Ben Hamidane H., Graumann J.","The arc of Mass Spectrometry Exchange Formats is long, but it bends toward HDF5",2017,"Mass Spectrometry Reviews",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991363511&doi=10.1002%2fmas.21522&partnerID=40&md5=e3ff09ce8b8c723d8d7e3643027644a4","The evolution of data exchange in Mass Spectrometry spans decades and has ranged from human-readable text files representing individual scans or collections thereof (McDonald et al., 2004) through the official standard XML-based (Harold, Means, & Udemadu, 2005) data interchange standard (Deutsch, 2012), to increasingly compressed (Teleman et al., 2014) variants of this standard sometimes requiring purely binary adjunct files (Römpp et al., 2011). While the desire to maintain even partial human readability is understandable, the inherent mismatch between XML's textual and irregular format relative to the numeric and highly regular nature of actual spectral data, along with the explosive growth in dataset scales and the resulting need for efficient (binary and indexed) access has led to a phenomenon referred to as “technical drift” (Davis, 2013). While the drift is being continuously corrected using adjunct formats, compression schemes, and programs (Röst et al., 2015), we propose that the future of Mass Spectrometry Exchange Formats lies in the continued reliance and development of the PSI-MS (Mayer et al., 2014) controlled vocabulary, along with an expedited shift to an alternative, thriving and well-supported ecosystem for scientific data-exchange, storage, and access in binary form, namely that of HDF5 (Koranne, 2011). Indeed, pioneering efforts to leverage this universal, binary, and hierarchical data-format have already been published (Wilhelm et al., 2012; Rübel et al., 2013) though they have under-utilized self-description, a key property shared by HDF5 and XML. We demonstrate that a straightforward usage of plain (“vanilla”) HDF5 yields immediate returns including, but not limited to, highly efficient data access, platform independent data viewers, a variety of libraries (Collette, 2014) for data retrieval and manipulation in many programming languages and remote data access through comprehensive RESTful data-servers. © 2016 Wiley Periodicals, Inc. Mass Spec Rev 36:668–673, 2017. © 2016 Wiley Periodicals, Inc.","data exchange formats; HDF5; mass spectrometry","Aluminum; Bins; Electronic data interchange; Mass spectrometry; Spectrometry; XML; Compression scheme; Data exchange format; HDF5; Hierarchical data; Human readability; Human-readable text; Platform independent; Remote data access; Digital storage",2-s2.0-84991363511
"Shtabovenko V.","FeynHelpers: Connecting FeynCalc to FIRE and Package-X",2017,"Computer Physics Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019395876&doi=10.1016%2fj.cpc.2017.04.014&partnerID=40&md5=3e211dfce850b8c43a06e5324831ea01","We present a new interface called FEYNHELPERS that connects FEYNCALC, a MATHEMATICA package for symbolic semi-automatic evaluation of Feynman diagrams and calculations in quantum field theory (QFT) to PACKAGE-X and FIRE. The former provides a library of analytic results for scalar 1-loop integrals with up to 4 legs, while the latter is a general-purpose tool for reduction of multi-loop scalar integrals using Integration-by-Parts (IBP) identities. Program summary Program Title: FeynHelpers Program Files doi: http://dx.doi.org/10.17632/h5cfbhbbnc.1 Licensing provisions: GNU Public License 3 Programming language: Wolfram Mathematica 8 and higher External routines/libraries: FeynCalc [1,2], FeynArts [3], FeynRules [4], Package-X [5], FIRE [6] Nature of problem: FeynCalc is missing built-in capabilities to provide analytic results for scalar 1-loop integrals and to reduce multi-loop integrals using Integration-by-Parts (IBP) identities. These short-comings limit the usefulness of the package for the fully analytic evaluation of Feynman diagrams. Solution method: An easy-to-use interface implemented in Wolfram Mathematica seamlessly integrates two other Mathematica packages (Package-X and FIRE) into FeynCalc. Restrictions: The interface to FIRE currently misses the ability to recognize loop integrals that belong to the same topology, which means that each integral is processed separately. Furthermore, starting and stopping parallel kernels requires around 1.5 seconds per integral, which can be too slow, when hundreds of integrals are involved. [1] R. Mertig, M. Böhm, and A. Denner, Feyn Calc - Computer-algebraic calculation of Feynman amplitudes, Comput. Phys. Commun., 64, 345–359, (1991).[2] V. Shtabovenko, R. Mertig, and F. Orellana, New Developments in FeynCalc 9.0, Comput. Phys. Commun., 207, 432–444, (2016), arXiv:1601.01167.[3] T. Hahn, Generating Feynman Diagrams and Amplitudes with FeynArts 3, Comput. Phys. Commun., 140, 418–431, (2001), arXiv:hep-ph/0012260.[4] N. D. Christensen and C. Duhr, FeynRules - Feynman rules made easy, Comput. Phys. Commun., 180, 1614–1641, (2008), arXiv:0806.4194.[5] H. H. Patel, Package-X: A Mathematica package for the analytic calculation of one-loop integrals, Comput. Phys. Commun., 197, 276–290, (2015), arXiv:1503.01469.[6] A. V. Smirnov and V. A. Smirnov, FIRE4, LiteRed and accompanying tools to solve integration by parts relations, Comput. Phys. Commun., 184, 2820–2827, (2013), arXiv:1302.5885. © 2017 Elsevier B.V.","Dimensional regularization; Effective field theories; FeynCalc; FIRE; IBP; Loop integrals; Package-X; Passarino–Veltman","Algebra; Fires; Integration; Open source software; Transients; Tungsten; Dimensional regularization; Effective field theory; FeynCalc; Loop integrals; Passarino-Veltman; Quantum theory",2-s2.0-85019395876
"Seyhan M.F., Yılmaz E., Timirci-Kahraman Ö., Saygılı N., Kısakesen H.İ., Eronat A.P., Ceviz A.B., Bilgiç Gazioğlu S., Yılmaz-Aydoğan H., Öztürk O.","Anatolian honey is not only sweet but can also protect from breast cancer: Elixir for women from artemis to present",2017,"IUBMB Life",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022198620&doi=10.1002%2fiub.1652&partnerID=40&md5=ead3d6a2fad6169d823e2d7abd1034bb","Natural products with bioactive components are widely studied on various cancer cell lines for their possible cytotoxic effects, recently. Among these products, honey stands out as a valuable bee product containing many active phenolic compounds and flavonoids. Numerous types of multifloral honey and honeydew honey are produced in Turkey owing to its abundant vegetation. Therefore, in this study, we investigated the cytotoxic effects of particular tree-originated honeys from chestnut, cedar, pine, and multifloral honey on cell lines representing different types of the most common cancer of women, breast cancer, MCF7, SKBR3, and MDAMB-231, and fibrocystic breast epithelial cell line, MCF10A as a control. All honey samples were analyzed biochemically. The dose- (1, 2.5, 5, 7.5, and 10 µg/mL) and time (24th, 48th, and 72nd hours)-dependent effects of ethanol/water solutions of the honey samples were scrutinized. Cell viability/cytotoxicity was evaluated by the water soluble tetrazolium Salt-1 (WST-1) method. Apoptotic status was detected by Annexin V-PI assay using FACSCalibur. The statistical analysis was performed using GraphPad Prism 6 and the clustering data analysis with the R programming language. The biochemical analyses of the honey samples showed that the tree-originated honey samples contained more total phenolic compounds than the multifloral honey. Phenolic content of the honey types increases in order of multifloral, pine, cedar, and chestnut, respectively, which is compatible with their cytotoxic affectivity and dark color. In addition, the antioxidant capacity of the studied honey types was observed to increase in order of multifloral < pine < cedar ≅ chestnut. According to the WST-1 data, chestnut honey induced cytotoxicity over 50% on all the cell lines, including the control MCF10A cells, even with low doses (honey concentrations starting from 1 µg/mL) (P < 0.0001). Similarly, Cedar honey was observed to be the second most effective honey in this study. Cedar honey, with the dose of 1 µg/mL, was detected statistically highly significant on MCF10A, MCF7, and SKBR3. In contrast, pine honey showed dramatically significant cytotoxicity only on the MDAMB 231 cells with a 1 µg/mL dose at the same time point (P = 0.018). While pine honey caused an anticancer effect on the MCF-7 and SKBR3 cancer cell lines with a 2.5–5 µg/mL dose (P < 0.0001), like cedar and chestnut honeys, it increased the viability of the MCF10A control cells with the doses of 2.5–5 µg/mL. It only showed cytotoxicity with higher doses (10 µg/mL) on the MCF10A cell line (P < 0.0001). Moreover, we have observed that the multifloral and artificial honey samples were mostly ineffective or increased cell viability with the doses of 1–5 µg/mL. Apoptotic effects of the other honey samples on the MCF-7 cell line were found as chestnut> pine> cedar> multifloral in the Annexin V-propidium iodide (PI) analysis. Chestnut, cedar, and pine honey displayed a remarkably cytotoxic effect on breast cancer cell lines, MCF7, SKBR3, and even on the most aggressive MDAMB 231, representing the triple negative breast cancer, which lacks of targeted anticancer therapy. The chestnut and cedar honeys stand out to be the most cytotoxic on all cell lines, while pine honey was found to be the least toxic on control cells with appropriate toxicity on the cancer cells. © 2017 IUBMB Life, 69(9):677–688, 2017. © 2017 International Union of Biochemistry and Molecular Biology","antioxidant; breast cancer; cell line; cytotoxicity; honey; phenolic content","antineoplastic agent; cedar honey extract; chestnut honey extract; lipocortin 5; multifloral honey extract; phenol derivative; pine honey extract; plant extract; tetrazolium; unclassified drug; antioxidant activity; apoptosis; Article; biochemical analysis; breast cancer; breast cancer cell line; Cedrus; cell proliferation; cell viability; chestnut; cluster analysis; controlled study; cytotoxicity; data analysis software; elixir; flow cytometer; honey; human; human cell; pine; prism; statistical analysis",2-s2.0-85022198620
"Beickert K., Mora K.","Transforming the pediatric experience: The story of child life",2017,"Pediatric Annals",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029436741&doi=10.3928%2f19382359-20170810-01&partnerID=40&md5=a4848f402abcc8a81ffcc8a07830c9f3","During the past century, child life programming has evolved into a standard of care for children experiencing life’s most challenging events. From pediatric outpatient clinics and dentists’ offices to funeral homes and courtrooms, children are now being provided access to professionals that relieve the anxiety and fear associated with emotional and physical pain. Recognized by the American Academy of Pediatrics, child life specialists focus on the “strengths and sense of well-being of children while promoting their optimal development and minimizing the adverse effects of children’s experiences in health care or other potentially stressful settings.” Armed with a strong background in child development, child life specialists provide therapeutic play experiences and developmentally appropriate language to promote normalcy within an unknown and potentially stressful environment, procedural education and emotional support, coping and pain management techniques, and grief and bereavement support. Child life programming plays an integral role in addressing the psychosocial concerns across the health care continuum and should be included in all general pediatric provider settings as a standard of quality care for young patients. © SLACK Incorporated.",,"analgesia; anxiety; Article; bereavement support; child care; child life; emotional stress; health care; health program; hospital care; human; medical care; medical specialist; nasogastric tube; outpatient; peripherally inserted central venous catheter",2-s2.0-85029436741
"Yazejian N., Bryant D.M., Hans S., Horm D., St. Clair L., File N., Burchinal M.","Child and Parenting Outcomes After 1 Year of Educare",2017,"Child Development",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012940631&doi=10.1111%2fcdev.12688&partnerID=40&md5=b31537126ade52563f38c937747cbedd","Educare is a birth to age 5 early education program designed to reduce the achievement gap between children from low-income families and their more economically advantaged peers through high-quality center-based programming and strong school–family partnerships. This study randomly assigned 239 children (< 19 months) from low-income families to Educare or a business-as-usual control group. Assessments tracked children 1 year after randomization. Results revealed significant differences favoring treatment group children on auditory and expressive language skills, parent-reported problem behaviors, and positive parent–child interactions. Effect sizes were in the modest to medium range. No effects were evident for observer-rated child behaviors or parent-rated social competence. The overall results add to the evidence that intervening early can set low-income children on more positive developmental courses. © 2017 The Authors. Child Development © 2017 Society for Research in Child Development, Inc.",,,2-s2.0-85012940631
"Cheik Ahamed A.-K., Magoulès F.","Conjugate gradient method with graphics processing unit acceleration: CUDA vs OpenCL",2017,"Advances in Engineering Software",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008653924&doi=10.1016%2fj.advengsoft.2016.10.002&partnerID=40&md5=ea98da6adaa89683514250bef94a917b","Performance computations depend on the machine architecture, the operating system, the problem studied and obviously on the programming implementation. Solving partial differential equations by numerical methods such as the finite element method requires the solution of large sparse linear systems. Graphics processing unit (GPU) is now commonly used to accelerate numerical simulations and most supercomputers provide large number of GPUs to their users. This paper proposes a comparison of both CUDA and OpenCL GPU languages to take the highest performance of multi-GPUs clusters. We analyse, evaluate and compare their respective performances for computing linear algebra operations and for solving large sparse linear systems with the conjugate gradient iterative method on multi-GPUs clusters. © 2017 Elsevier Ltd","Conjugate gradient method; CUDA; GPU; Iterative method; Linear algebra; OpenCL; Parallel computing; Sparse matrix-vector product","Algebra; Computer graphics; Computer graphics equipment; Finite element method; Iterative methods; Linear algebra; Linear systems; Numerical methods; Parallel processing systems; Program processors; Supercomputers; Conjugate gradient iterative methods; CUDA; Graphics Processing Unit; Large sparse linear systems; Linear algebra operations; OpenCL; Performance computation; Sparse matrix vector products; Conjugate gradient method",2-s2.0-85008653924
"Hasan M.S., Dean T., Imam F.T., Garcia F., Leblanc S.P., Zulkernine M.","A constraint-based intrusion detection system",2017,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030315656&doi=10.1145%2f3123779.3123812&partnerID=40&md5=8ad9ad5eb9f398dfad20f3b3a99a7ff6","The expressiveness of constraints has a potential to define network behavior and defend against complex network intrusions. This potential can be an integral part of an Intrusion Detection System (IDS) for defending networks against various attacks. The existing approaches of constraint logic programming have limitations when it comes to solving the network constraints in the presence of the continuous, constantly changing stream of network data. In this paper, we propose two variations of a tree-based constraint satisfaction technique to evaluate network constraints on continuous network data. A Domain Specific Language (DSL) is developed so that the IDS users can specify different intrusions related to their networks. We also present a prototype implementation of these techniques. We evaluate the performance and effectiveness of our approach against the network traffic data generated from an experimental network. © 2017 ACM.","Constraint satisfaction problem; Domain specific language; Intrusion detection system","Complex networks; Computer crime; Computer programming languages; Constraint satisfaction problems; Logic programming; Mercury (metal); Network security; Problem oriented languages; Trees (mathematics); Constraint Logic Programming; Constraint satisfaction techniques; Domain specific languages; Intrusion Detection Systems; Network behaviors; Network constraints; Network intrusions; Prototype implementations; Intrusion detection",2-s2.0-85030315656
"Berta P., Bystrický M., Krempaský M., Vranić V.","Employing issues and commits for in-code sentence based use case identification and remodularization",2017,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030328011&doi=10.1145%2f3123779.3123792&partnerID=40&md5=10ddae10d4561456cabd35bfd789a61b","Use case driven modularization improves code comprehension and maintenance and provides another view on software alongside object-oriented modularization. However, approaches enabling use case driven modularization require to modularize code manually. In this paper, we propose an approach to employing issues and commits for in-code sentence based use case identification and remodularization. The approach aims at providing use case based perspective on the existing code. The sentences of use case steps are compared to sentences of issue descriptions, while the sentences generated from the source code of issue commits are compared to sentences generated from the corresponding methods in source code in order to quantify the similarity between use case steps and methods in source code using different similarity calculation algorithms. The resulting level of similarity is used to remodularize source code according to use cases. We conducted a study on the OpenCart open source e-shop employing 16 use cases. The approach achieved the recall of 3.37% and precision of 75%. The success of the approach strongly depends on issues and commits assigned to them. The results would be better especially for the code that natively employs use case driven modularization. © 2017 ACM.","Aspect-oriented programming; Dci; Information retrieval; Intent; Modularization; Natural language processing; Remodularization; Text similarity; Traceability links; Use case","Aspect oriented programming; Computer programming languages; Information retrieval; Modular construction; Natural language processing systems; Object oriented programming; Open source software; Intent; Modularizations; Remodularization; Text similarity; Traceability links; Codes (symbols)",2-s2.0-85030328011
"de Gouw S., de Boer F.S., Bubel R., Hähnle R., Rot J., Steinhöfel D.","Verifying OpenJDK’s Sort Method for Generic Collections",2017,"Journal of Automated Reasoning",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028744972&doi=10.1007%2fs10817-017-9426-4&partnerID=40&md5=e8d548d594bc8f127f3337101863f7b7","TimSort is the main sorting algorithm provided by the Java standard library and many other programming frameworks. Our original goal was functional verification of TimSort with mechanical proofs. However, during our verification attempt we discovered a bug which causes the implementation to crash by an uncaught exception. In this paper, we identify conditions under which the bug occurs, and from this we derive a bug-free version that does not compromise performance. We formally specify the new version and verify termination and the absence of exceptions including the bug. This verification is carried out mechanically with KeY, a state-of-the-art interactive verification tool for Java. We provide a detailed description and analysis of the proofs. The complexity of the proofs required extensions and new capabilities in KeY, including symbolic state merging. © 2017 The Author(s)","Case study; Program verification; Specification; Theorem proving","Artificial intelligence; Automata theory; Software engineering; Specifications; Theorem proving; Functional verification; Program Verification; Programming framework; Sorting algorithm; Standard libraries; State of the art; Uncaught exceptions; Verification tools; Java programming language",2-s2.0-85028744972
"Goldstein M., Dayan D., Rabin M., Berlowitz D., Berlowitz O., Yehezkael R.B.","Design principles of an embedded language (EFL) enabling well defined order-independent execution",2017,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030307937&doi=10.1145%2f3123779.3123789&partnerID=40&md5=cac4f8c5d145d282fc28439862321e4a","Parallel programming platforms are heterogeneous and incompatible; a common approach is needed to free programmers from platforms' technical intricacies, allowing flexible execution in which sequential and parallel executions produce identical results. The execution and programming model of an embedded flexible language (EFL), which implement this common approach, are presented. EFL allows embedding of deterministic parallel code blocks into a sequential program, written in any host language. EFL programming model constructs are presented. An EFL implementation of the Reduce Parallel Design Pattern is presented. With EFL we aim to implement safe and efficient parallel execution, in software, hardware, or both. Consequences of Rice's theorem regarding parallel computation are discussed. These consequences severely restrict what can be checked at compile time. An approach is proposed for circumventing these restrictions. © 2017 ACM.","Flexible computation; Parallel design pattern; Parallel programming","Parallel programming; Design Principles; Embedded Languages; Order independents; Parallel Computation; Parallel design patterns; Parallel executions; Programming models; Sequential programs; Computation theory",2-s2.0-85030307937
"Park J., Piehowski P.D., Wilkins C., Zhou M., Mendoza J., Fujimoto G.M., Gibbons B.C., Shaw J.B., Shen Y., Shukla A.K., Moore R.J., Liu T., Petyuk V.A., Tolić N., Paša-Tolić L., Smith R.D., Payne S.H., Kim S.","Informed-Proteomics: Open-source software package for top-down proteomics",2017,"Nature Methods",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028695564&doi=10.1038%2fnmeth.4388&partnerID=40&md5=556004a696e7e59ed95e90a3ff43afde","Top-down proteomics, the analysis of intact proteins in their endogenous form, preserves valuable information about post-translation modifications, isoforms and proteolytic processing. The quality of top-down liquid chromatography-tandem MS (LC-MS/MS) data sets is rapidly increasing on account of advances in instrumentation and sample-processing protocols. However, top-down mass spectra are substantially more complex than conventional bottom-up data. New algorithms and software tools for confident proteoform identification and quantification are needed. Here we present Informed-Proteomics, an open-source software suite for top-down proteomics analysis that consists of an LC-MS feature-finding algorithm, a database search algorithm, and an interactive results viewer. We compare our tool with several other popular tools using human-in-mouse xenograft luminal and basal breast tumor samples that are known to have significant differences in protein abundance based on bottom-up analysis. © 2017 Nature America, Inc., part of Springer Nature. All Rights Reserved.",,"proteome; proteome; algorithm; Article; breast tumor; controlled study; data analysis software; female; human; human tissue; liquid chromatography-mass spectrometry; mouse; nonhuman; priority journal; protein database; proteomics; top down proteomics; chemistry; computer interface; computer language; high performance liquid chromatography; procedures; proteomics; software; system analysis; tandem mass spectrometry; Algorithms; Chromatography, High Pressure Liquid; Programming Languages; Proteome; Proteomics; Software; Systems Integration; Tandem Mass Spectrometry; User-Computer Interface",2-s2.0-85028695564
"Baeten J., Luttik B., Yang F.","Sequential composition in the presence of intermediate termination (extended abstract)",2017,"Electronic Proceedings in Theoretical Computer Science, EPTCS",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030106836&doi=10.4204%2fEPTCS.255.1&partnerID=40&md5=a246184345abc90409dc1dc6e6c074b0","The standard operational semantics of the sequential composition operator gives rise to unbounded branching and forgetfulness when transparent process expressions are put in sequence. Due to transparency, the correspondence between context-free and pushdown processes fails modulo bisimilarity, and it is not clear how to specify an always terminating half counter. We propose a revised operational semantics for the sequential composition operator in the context of intermediate termination. With the revised operational semantics, we eliminate transparency, allowing us to establish a close correspondence between context-free processes and pushdown processes. Moreover,we prove the reactive Turing powerfulness of TCP with iteration and nesting with the revised operational semantics for sequential composition. © 2017 Jos Baeten, Bas Luttik & Fei Yang.",,"Context free languages; Semantics; Transparency; Bisimilarity; Context-free; Context-free process; Extended abstracts; Operational semantics; Pushdown process; Sequential compositions; Transparent process; Computer programming languages",2-s2.0-85030106836
"Dyseryn V., Van Glabbeek R., Höfner P.","Analysing mutual exclusion using process algebra with signals",2017,"Electronic Proceedings in Theoretical Computer Science, EPTCS",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030118716&doi=10.4204%2fEPTCS.255.2&partnerID=40&md5=f3e060216690fe0db0ab058f45132a87","In contrast to common belief, the Calculus of Communicating Systems (CCS) and similar process algebras lack the expressive power to accurately capture mutual exclusion protocols without enriching the language with fairness assumptions. Adding a fairness assumption to implement a mutual exclusion protocol seems counter-intuitive. We employ a signalling operator, which can be combined with CCS, or other process calculi, and show that this minimal extension is expressive enough to model mutual exclusion: we confirm the correctness of Peterson's mutual exclusion algorithm for two processes, as well as Lamport's bakery algorithm, under reasonable assumptions on the underlying memory model. The correctness of Peterson's algorithm for more than two processes requires stronger, less realistic assumptions on the underlying memory model. © 2017 V. Dyseryn, R.J. van Glabbeek & P. Höfner.",,"Calculations; Computer programming languages; Semantics; Bakery algorithm; Calculus of communicating systems; Expressive power; Mutual exclusion protocol; Mutual exclusions; Peterson's algorithm; Peterson's mutual exclusion algorithm; Process algebras; Algebra",2-s2.0-85030118716
"Ferlez J., Cleaveland R., Marcus S.","Bisimulation and hennessy-milner logic for generalized synchronization trees",2017,"Electronic Proceedings in Theoretical Computer Science, EPTCS",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030091576&doi=10.4204%2fEPTCS.255.3&partnerID=40&md5=7c5b189225df045a1d8a808546b9ee8e","In this work, we develop a generalization of Hennessy-Milner Logic (HML) for Generalized Synchronization Trees (GSTs) that we call Generalized Hennessy Milner Logic (GHML). Importantly, this logic suggests a strong relationship between (weak) bisimulation for GSTs and ordinary bisimulation for Synchronization Trees (STs). We demonstrate that this relationship can be used to define the GST analog for image-finiteness of STs. Furthermore, we demonstrate that certain maximal Hennessy-Milner classes of STs have counterparts in maximal Hennessy-Milner classes of GSTs with respect to GST weak bisimulation. We also exhibit some interesting characteristics of these maximal Hennessy-Milner classes of GSTs.",,"Computer programming languages; Forestry; Semantics; Synchronization; Bisimulations; Generalized synchronization; Hennessy-Milner Logics; Weak bisimulation; Computer circuits",2-s2.0-85030091576
"Hüttel H.","Using session types for reasoning about boundedness in the π-calculus",2017,"Electronic Proceedings in Theoretical Computer Science, EPTCS",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030108203&doi=10.4204%2fEPTCS.255.5&partnerID=40&md5=c79b264baf1cbd0226ea19e22f89ed07","The classes of depth-bounded and name-bounded processes are fragments of the π-calculus for which some of the decision problems that are undecidable for the full calculus become decidable. P is depth-bounded at level k if every reduction sequence for P contains successor processes with at most k active nested restrictions. P is name-bounded at level k if every reduction sequence for P contains successor processes with at most k active bound names. Membership of these classes of processes is undecidable. In this paper we use binary session types to decise two type systems that give a sound characterization of the properties: If a process is well-typed in our first system, it is depth-bounded. If a process is well-typed in our second, more restrictive type system, it will also be name-bounded. © 2017 Hans Hüttel.",,"Computer programming languages; Semantics; Boundedness; Decision problems; First systems; Pi calculus; Reduction sequence; Session types; Type systems; Calculations",2-s2.0-85030108203
"Hoey J., Ulidowski I., Yuen S.","Reversing imperative parallel programs",2017,"Electronic Proceedings in Theoretical Computer Science, EPTCS",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030101305&doi=10.4204%2fEPTCS.255.4&partnerID=40&md5=0ca6b0ecc4fa89f281568ac9195c6ae3","We propose an approach and a subsequent extension for reversing imperative programs. Firstly, we produce both an augmented version and a corresponding inverted version of the original program. Augmentation saves reversal information into an auxiliary data store, maintaining segregation between this and the program state, while never altering the data store in any other way than that of the original program. Inversion uses this information to revert the final program state to the state as it was before execution. We prove that augmentation and inversion work as intended, and illustrate our approach with several examples. We also suggest a modification to our first approach to support non-communicating parallelism. Execution interleaving introduces a number of challenges, each of which our extended approach considers. We define annotation and redefine inversion to use a sequence of statement identifiers, making the interleaving order deterministic in reverse. © 2017 J. Hoey, I. Ulidowski & S. Yuen.",,"Semantics; Auxiliary data; Data store; Imperative programs; Interleaving orders; Parallel program; Program state; Computer programming languages",2-s2.0-85030101305
"Nowak M.E., Schwab V.F., Lazar C.S., Behrendt T., Kohlhepp B., Totsche K.U., Küsel K., Trumbore S.E.","Carbon isotopes of dissolved inorganic carbon reflect utilization of different carbon sources by microbial communities in two limestone aquifer assemblages",2017,"Hydrology and Earth System Sciences",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028597432&doi=10.5194%2fhess-21-4283-2017&partnerID=40&md5=2237d4e83e09b0e3b6e1fe3ecd35279c","Isotopes of dissolved inorganic carbon (DIC) are used to indicate both transit times and biogeochemical evolution of groundwaters. These signals can be complicated in carbonate aquifers, as both abiotic (i.e., carbonate equilibria) and biotic factors influence the σ13C and 14C of DIC. We applied a novel graphical method for tracking changes in the σ13C and 14C of DIC in two distinct aquifer complexes identified in the Hainich Critical Zone Exploratory (CZE), a platform to study how water transport links surface and shallow groundwaters in limestone and marlstone rocks in central Germany. For more quantitative estimates of contributions of different biotic and abiotic carbon sources to the DIC pool, we used the NETPATH geochemical modeling program, which accounts for changes in dissolved ions in addition to C isotopes. Although water residence times in the Hainich CZE aquifers based on hydrogeology are relatively short (years or less), DIC isotopes in the shallow, mostly anoxic, aquifer assemblage (HTU) were depleted in 14C compared to a deeper, oxic, aquifer complex (HTL). Carbon isotopes and chemical changes in the deeper HTL wells could be explained by interaction of recharge waters equilibrated with post-bomb 14C sources with carbonates. However, oxygen depletion and σ13C and 14C values of DIC below those expected from the processes of carbonate equilibrium alone indicate considerably different biogeochemical evolution of waters in the upper aquifer assemblage (HTU wells). Changes in 14C and 13C in the upper aquifer complexes result from a number of biotic and abiotic processes, including oxidation of 14C-depleted OM derived from recycled microbial carbon and sedimentary organic matter as well as water-rock interactions. The microbial pathways inferred from DIC isotope shifts and changes in water chemistry in the HTU wells were supported by comparison with in situ microbial community structure based on 16S rRNA analyses. Our findings demonstrate the large variation in the importance of biotic as well as abiotic controls on 13C and 14C of DIC in closely related aquifer assemblages. Further, they support the importance of subsurface-derived carbon sources like DIC for chemolithoautotrophic microorganisms as well as rock-derived organic matter for supporting heterotrophic groundwater microbial communities and indicate that even shallow aquifers have microbial communities that use a variety of subsurface-derived carbon sources. © Author(s) 2017.",,"Aquifers; Biogeochemistry; Biological materials; C (programming language); Carbon; Carbonation; Chemical analysis; Dissolution; Groundwater; Groundwater resources; Hydrogeology; Isotopes; Limestone; Microorganisms; Organic carbon; Organic compounds; RNA; Sedimentary rocks; Carbonate equilibriums; Chemolithoautotrophic; Different carbon sources; Dissolved inorganic carbon; Microbial community structures; Quantitative estimates; Sedimentary organic matter; Water rock interactions; Hydrochemistry; abiotic factor; aquifer; bacterium; biotic factor; carbon isotope; community structure; dissolved inorganic carbon; graphical method; groundwater; hydrogeology; limestone; marl; microbial activity; microbial community; organic matter; oxidation; water chemistry; water-rock interaction; Germany; Germany; Hainich; Thuringia",2-s2.0-85028597432
"Heere M., GharibDoust S.P., Sørby M.H., Frommen C., Jensen T.R., Hauback B.C.","In situ investigations of bimetallic potassium erbium borohydride",2017,"International Journal of Hydrogen Energy",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019582184&doi=10.1016%2fj.ijhydene.2017.04.271&partnerID=40&md5=935f25127a30db4d8a4d79fa28471045","Research on rare earth (RE) borohydrides is increasing due to their potential as possible hydrogen storage materials and as solid-state Li-ion conductors for battery applications. In this work, we report the formation of a new bimetallic RE borohydride, KEr(BH4)4, via mechanochemical reaction between KBH4 and Er(BH4)3 in a molar ratio of 1:1. Post-annealing of the ball-milled mixture at 175 °C for 12 h under 40 bar of hydrogen resulted in an almost phase pure material. KEr(BH4)4 is isostructural to NaSc(BH4)4 with lattice parameters of a = 8.4472(8) Å, b = 12.4292(11) Å, c = 9.6252(9) Å and space group Cmcm. An amorphization of the new bimetallic phase was observed at ∼170 °C under 1 bar argon via temperature programmed photographic analysis, which is in agreement with in situ synchrotron radiation powder X-ray diffraction (SR-PXD) as well as thermogravimetric and differential scanning calorimetry (TG-DSC). The in situ SR-PXD data did not show decomposition into the starting monometallic borohydrides. © 2017 Hydrogen Energy Publications LLC","Borohydride; Decomposition; Hydrogen storage; In situ XRD; Rare earth","Annealing; Decomposition; Differential scanning calorimetry; Digital storage; Erbium; Hydrogen storage; Lithium compounds; Lithium-ion batteries; Rare earths; Synchrotron radiation; Thermogravimetric analysis; X ray diffraction; Ball-milled mixtures; Battery applications; Borohydrides; In-situ investigations; In-situ synchrotrons; In-situ XRD; Mechanochemical reactions; Temperature programmed; C (programming language)",2-s2.0-85019582184
"Kordic B., Popovic M., Ghilezan S., Basicevic I.","An approach to formal verification of python software transactional memory",2017,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030326067&doi=10.1145%2f3123779.3123788&partnerID=40&md5=b1462f7aa3aecf42acd9130cbf362959","Although Python is one of the most widely used programming languages, and it is a foundation for a variety of parallel and distributed computing frameworks, it still lacks an applicable and reliable software transactional memory. In this paper, we present an approach to formal verification of a Python Software Transactional Memory (PSTM) solution using UPPAAL tool. The aims are (i) to apply a formal verification process to a real STM implementation in order to derive a faithful STM model based on a PSTM design and (ii) to use developed PSTM model for automated machine-checked formal verification of core system properties such as safety and liveness using a model checker tool. Firstly, an architecture of PSTM solution is introduced. Secondly, formalization and a PSTM system model are analyzed. Finally, core PSTM system's properties are verified, namely safety, liveness, and reachability. Utilizing a UPPAAL's model checker tool it is successfully verified that the PSTM system model satisfies each of the three formerly mentioned properties. © 2017 ACM.","Formal verification; Python; Software transactional memory; UPPAAL","Computer programming; Computer software; Distributed computer systems; High level languages; Model checking; Safety engineering; Storage allocation (computer); Verification; Automated machines; Model-based OPC; Parallel and distributed computing; Python; Software transactional memory; System modeling; UPPAAL; Verification process; Formal verification",2-s2.0-85030326067
"Sung N.-J., Hong M., Lee S.-H., Choi Y.-J.","Simulation of deformable objects using GLSL 4.3",2017,"KSII Transactions on Internet and Information Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028643920&doi=10.3837%2ftiis.2017.08.021&partnerID=40&md5=caabcac3f33aad4f2f72cde0ca5233e0","In this research, we implement a deformable object simulation system using OpenGL's shader language, GLSL4.3. Deformable object simulation is implemented by using volumetric mass-spring system suitable for real-time simulation among the methods of deformable object simulation. The compute shader in GLSL 4.3 which helps to access the GPU resources, is used to parallelize the operations of existing deformable object simulation systems. The proposed system is implemented using a compute shader for parallel processing and it includes a bounding box-based collision detection solution. In general, the collision detection is one of severe computing bottlenecks in simulation of multiple deformable objects. In order to validate an efficiency of the system, we performed the experiments using the 3D volumetric objects. We compared the performance of multiple deformable object simulations between CPU and GPU to analyze the effectiveness of parallel processing using GLSL. Moreover, we measured the computation time of bounding box-based collision detection to show that collision detection can be processed in real-time. The experiments using 3D volumetric models with 10K faces showed the GPU-based parallel simulation improves performance by 98% over the CPU-based simulation, and the overall steps including collision detection and rendering could be processed in real-time frame rate of 218.11 FPS. © 2017 KSII.","Deformable object simulation; GLSL; GPGPU; Parallel graphic processing","Application programming interfaces (API); Computer simulation languages; Graphics processing unit; Program processors; Three dimensional computer graphics; Collision detection; Deformable object; GLSL; GPGPU; Mass spring systems; Parallel simulations; Real time simulations; Real-time frame rates; Deformation",2-s2.0-85028643920
"NEW M.S., FETSCHER B., FINDLER R.B., MCCARTHY J.","Fair enumeration combinators",2017,"Journal of Functional Programming",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030863146&doi=10.1017%2fS0956796817000107&partnerID=40&md5=62b939f581f26e8c4af5f714d0b2d3c4","Enumerations represented as bijections between the natural numbers and elements of some given type have recently garnered interest in property-based testing because of their efficiency and flexibility. There are, however, many ways of defining these bijections, some of which are better than others. This paper offers a new property of enumeration combinators called fairness that identifies enumeration combinators that are better suited to property-based testing. Intuitively, the result of a fair combinator indexes into its argument enumerations equally when constructing its result. For example, extracting the nth element from our enumeration of three-tuples indexes about (Formula presented.) elements into each of its components instead of, say, indexing (Formula presented.) into one and (Formula presented.) into the other two, as you would if a three-tuple were built out of nested pairs. Similarly, extracting the nth element from our enumeration of a three-way union returns an element that is (Formula presented.) into one of the argument enumerators. The paper presents a semantics of enumeration combinators, a theory of fairness, proofs establishing fairness of our new combinators and that some combinations of fair combinators are not fair. We also report on an evaluation of fairness for the purpose of finding bugs in programming-language models. We show that fair enumeration combinators have complementary strengths to an existing, well-tuned ad hoc random generator (better on short time scales and worse on long time scales) and that using unfair combinators is worse across the board. Copyright © Cambridge University Press 2017",,"Functional programming; Combinator; Combinators; Natural number; Programming language models; Property based testing; Random generators; Short time scale; Time-scales; Semantics",2-s2.0-85030863146
"Cota G.L., Ben Mokhtar S., Gianini G., Damiani E., Lawall J., Muller G., Brunie L.","Analysing Selfishness Flooding with SEINE",2017,"Proceedings - 47th Annual IEEE/IFIP International Conference on Dependable Systems and Networks, DSN 2017",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031663963&doi=10.1109%2fDSN.2017.51&partnerID=40&md5=942beb9492a435cdc1b956a60732ecc1","Selfishness is one of the key problems that confronts developers of cooperative distributed systems (e.g., file-sharing networks, voluntary computing). It has the potential to severely degrade system performance and to lead to instability and failures. Current techniques for understanding the impact of selfish behaviours and designing effective countermeasures remain manual and time-consuming, requiring multi-domain expertise. To overcome these difficulties, we propose SEINE, a simulation framework for rapid modelling and evaluation of selfish behaviours in a cooperative system. SEINE relies on a domain-specific language (SEINE-L) for specifying selfishness scenarios, and provides semi-automatic support for their implementation and study in a state-of-the-art simulator. We show in this paper that (1) SEINE-L is expressive enough to specify fifteen selfishness scenarios taken from the literature, (2) SEINE is accurate in predicting the impact of selfishness compared to real experiments, and (3) SEINE substantially reduces the development effort compared to traditional manual approaches. © 2017 IEEE.",,"Behavioral research; Computer aided software engineering; Computer programming languages; Problem oriented languages; Co-operative systems; Cooperative Distributed Systems; Domain specific languages; File sharing networks; Selfish behaviours; Simulation framework; State of the art; Voluntary computing; Distributed computer systems",2-s2.0-85031663963
"Kapul A.A., Zubova E.I., Torgaev S.N., Drobchik V.V.","Pure-tone Audiometer",2017,"Journal of Physics: Conference Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029532322&doi=10.1088%2f1742-6596%2f881%2f1%2f012010&partnerID=40&md5=fe35d8dfaf349d348b68e0709dc788d3","The research focuses on a pure-tone audiometer designing. The relevance of the study is proved by high incidence of an auditory analyser in older people and children. At first, the article provides information about subjective and objective audiometry methods. Secondly, we offer block-diagram and basic-circuit arrangement of device. We decided to base on STM32F407VG microcontroller and use digital pot in the function of attenuator. Third, we implemented microcontroller and PC connection. C programming language is used for microcontroller's program and PC's interface. Fourthly, we created the pure-tone audiometer prototype. In the future, we will implement the objective method ASSR in addition to pure-tone audiometry. © Published under licence by IOP Publishing Ltd.",,"Audiometers; Bridge decks; Controllers; Microcontrollers; Nondestructive examination; Basic circuits; Block diagrams; High incidence; Objective methods; Older People; Pure tone audiometry; Pure tones; Research focus; C (programming language)",2-s2.0-85029532322
"Baek N., Kim K.J.","Prototype implementation of the OpenGL ES 2.0 shading language offline compiler",2017,"Cluster Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028622217&doi=10.1007%2fs10586-017-1113-z&partnerID=40&md5=1620db6177d2bbdb223c059f751a091f","Latest 3D graphics libraries, including OpenGL and OpenGL ES, provide programmable rendering pipelines. These programmable pipelines naturally requires special-purpose programming languages. It is so called OpenGL Shading Language in the case of OpenGL. In this paper, we show a new compact design scheme for the implementation of OpenGL SL offline compilers. This scheme is used for our OpenGL SL offline compiler prototype implementation. Our implementation shows feasibility and correctness with respect to the standard specification. © 2017 Springer Science+Business Media, LLC","Design; Offline compiler; OpenGL ES; Prototype implementation; Shading language","Application programming interfaces (API); Design; Pipelines; Program compilers; Three dimensional computer graphics; 3D graphics libraries; Compact designs; Offline; Prototype implementations; Rendering pipelines; Shading languages; Standard specifications; Computer graphics",2-s2.0-85028622217
"Ubukata S., Koike K., Notsu A., Honda K.","Possibilistic co-clustering based on extension of noise rejection scheme in FCCMM",2017,"IFSA-SCIS 2017 - Joint 17th World Congress of International Fuzzy Systems Association and 9th International Conference on Soft Computing and Intelligent Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030867186&doi=10.1109%2fIFSA-SCIS.2017.8023366&partnerID=40&md5=817abb5e6715276d42d111594e9f25b7","When we have cooccurrence information among objects and items, fuzzy co-clustering performs fuzzy c-means-type clustering of objects and items simultaneously, where two types of fuzzy memberships for objects and items are estimated by maximizing the aggregation criteria of clusters such that mutually familiar object-item pairs have large memberships in a same cluster. This paper tries to improve a multinomial mixture models-induced fuzzy co-clustering (FCCMM) to a robust co-clustering model by introducing the possibilistic clustering concept. Because possibilistic c-means can be regarded as a cluster-wise independent noise clustering model, multiple noise FCCMM models with single cluster situations are independently performed for rejecting illegal influences of noise objects. The characteristic features of the proposed model are demonstrated through several numerical experiments. © 2017 IEEE.",,"Cluster analysis; Fuzzy clustering; Fuzzy systems; Intelligent computing; Intelligent systems; Soft computing; Co-occurrence informations; Fuzzy co-clustering; Fuzzy membership; Independent noise; Multinomial mixture models; Numerical experiments; Possibilistic C-means; Possibilistic clustering; C (programming language)",2-s2.0-85030867186
"Wang X., Liu R.-F., Cork J., Gu Y., Upham D.C., Laycock B., McFarland E.W.","Investigation of the Bromination/Dehydrobromination of Long Chain Alkanes",2017,"Industrial and Engineering Chemistry Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028608205&doi=10.1021%2facs.iecr.7b01039&partnerID=40&md5=07ada511aeb38ab765b81cbcb38416b4","The partial oxidation of dodecane and paraffin wax with bromine at relatively low temperatures (≤120°C) and the dehydrobromination of the subsequent alkyl bromide intermediates at higher temperatures (>175°C) to form higher alkenes were investigated. Products were analyzed using nuclear magnetic resonance spectroscopy, gas chromatography, and mass spectrometry. Bromination favored the formation of alkyl bromides on internal carbons of the model long chain alkanes over terminal sites. At lower temperatures (∼90°C), ultraviolet photochemical initiation of bromination was necessary, while above 105°C, thermally initiated bromination was observed. Photochemical bromination was found to be inhibited by water and oxygen. The formation of alkenes by the dehydrobromination of the alkyl bromides was observed by temperature-programmed reaction to occur at higher temperatures for n-dodecane (∼190°C) than for the mixed alkanes in paraffin wax (∼175°C). (Figure Presented). © 2017 American Chemical Society.",,"Chains; Gas chromatography; Hydrocarbons; Magnetic resonance spectroscopy; Mass spectrometry; Nuclear magnetic resonance spectroscopy; Paraffins; Reaction intermediates; Alkyl bromides; Dehydrobromination; Long chain alkane; Low temperatures; Lower temperatures; Partial oxidations; Photochemical initiation; Temperature programmed reactions; C (programming language)",2-s2.0-85028608205
"Girish D., Singh V., Ralescu A.","Preliminary study on an improved weight updating for fuzzy c-means with applications to image segmentation",2017,"IFSA-SCIS 2017 - Joint 17th World Congress of International Fuzzy Systems Association and 9th International Conference on Soft Computing and Intelligent Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030838523&doi=10.1109%2fIFSA-SCIS.2017.8023319&partnerID=40&md5=29b2f29bd7a69aea6f8da8035671eae7","Fuzzy c-means is a popular clustering algorithm which allows a single data point to belong to more than one class at any given point. It has been used for a variety of applications especially when the applications are subjective and ambiguous. Image segmentation is one such application in which the decision of a certain pixel belonging to a particular cluster is very fuzzy. The weight associated with every data point is very important as it controls the decision of assigning the data point to a particular cluster. In this study, two novel methods of updating weights that take into account the goodness of clustering and spatial relationships are proposed in order to improve the results of clustering. Fuzzy c-means with our proposed method of updating weights is applied to different kinds of images to perform image segmentation. © 2017 IEEE.",,"Clustering algorithms; Fuzzy systems; Image enhancement; Image segmentation; Intelligent computing; Intelligent systems; Soft computing; Data points; Fuzzy C mean; Novel methods; Spatial relationships; C (programming language)",2-s2.0-85030838523
"McCoy A.L., Holmes S.R., Boisjolie B.A.","Flow Restoration in the Columbia River Basin: An Evaluation of a Flow Restoration Accounting Framework",2017,"Environmental Management",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028584082&doi=10.1007%2fs00267-017-0926-0&partnerID=40&md5=45ab791b7c70223e037c7b0614b9c6ef","Securing environmental flows in support of freshwater biodiversity is an evolving field of practice. An example of a large-scale program dedicated to restoring environmental flows is the Columbia Basin Water Transactions Program in the Pacific Northwest region of North America, which has been restoring flows in dewatered tributary habitats for imperiled salmon species over the past decade. This paper discusses a four-tiered flow restoration accounting framework for tracking the implementation and impacts of water transactions as an effective tool for adaptive management. The flow restoration accounting framework provides compliance and flow accounting information to monitor transaction efficacy. We review the implementation of the flow restoration accounting framework monitoring framework to demonstrate (a) the extent of water transactions that have been implemented over the past decade, (b) the volumes of restored flow in meeting flow targets for restoring habitat for anadromous fish species, and (c) an example of aquatic habitat enhancement that resulted from Columbia Basin Water Transactions Program investments. Project results show that from 2002 to 2015, the Columbia Basin Water Transactions Program has completed more than 450 water rights transactions, restoring approximately 1.59 million megaliters to date, with an additional 10.98 million megaliters of flow protected for use over the next 100 years. This has resulted in the watering of over 2414 stream kilometers within the Columbia Basin. We conclude with a discussion of the insights gained through the implementation of the flow restoration accounting framework. Understanding the approach and efficacy of a monitoring framework applied across a large river basin can be informative to emerging flow-restoration and adaptive management efforts in areas of conservation concern. © 2017 Springer Science+Business Media, LLC","Adaptive management; Columbia River basin; Effectiveness monitoring; Environmental flows","Biodiversity; C (programming language); Ecosystems; Network function virtualization; Restoration; Watersheds; Accounting informations; Adaptive Management; Columbia River; Effectiveness monitoring; Environmental flow; Freshwater biodiversity; Large-scale programs; Monitoring frameworks; Rivers",2-s2.0-85028584082
"Li X., Su X., Liu Y.","Adaptive region control for robotic soldering of flexible PCBs",2017,"2017 18th International Conference on Advanced Robotics, ICAR 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031698877&doi=10.1109%2fICAR.2017.8023521&partnerID=40&md5=a1dee42eabbd2a75062986c8b94b2487","While robot manipulators have been widely applied in manufacturing and industry, most applications are limited to rigid objects. Increasing demands for manipulating soft objects have been reflected in the emerging 3C manufacturing, such as the soldering of flexible PCBs. Because of the property of deformation, soldering the flexible PCB cannot be performed with conventional robotic manipulation techniques. In this paper, an adaptive region controller is proposed to deal with the deformation of flexible PCBs, where the control objective is specified as a region attached to the flexible PCB. The proposed controller enables an additional assistive arm to reach the region and contact and fix the PCB, which thus eliminates the deformation. A coordination scheme is also developed to activate the soldering end effector after the deformation is stabilized. The stability of the closed-loop system is rigorously proved with Lyapunov methods, and experimental results are presented to illustrate the performance of the proposed controller. © 2017 IEEE.",,"C (programming language); Closed loop systems; Deformation; Lyapunov methods; Manipulators; Manufacture; Organic pollutants; Polychlorinated biphenyls; Robot applications; Robotics; Soldering; Adaptive region; Assistive; Control objectives; Coordination scheme; Rigid objects; Robot manipulator; Robotic manipulation; Soft objects; Controllers",2-s2.0-85031698877
"Le T.D., Le A.T., Nguyen D.T.","Model-based Q-learning for humanoid robots",2017,"2017 18th International Conference on Advanced Robotics, ICAR 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031691326&doi=10.1109%2fICAR.2017.8023674&partnerID=40&md5=a4d603f6c3b181baeeea461166825542","This paper is proposal with regarding reinforcement learning and robotics. It contains our study so far about reinforcement learning problem and Q-learning - one of the methods to solve it. The method is tested both by running on a simulation and on NAO robot. Both are written in high programming language. Since the testing are also done on NAO robot. This paper also includes our understanding about NAO robot and Robotic Operating System (ROS), and our approach to apply Q-learning on NAO robot. In the end, we have been successfully tested Q-learning method and apply it to NAO robot in real-world environment. © 2017 IEEE.","NAO Robot; Obstacle Avoidance; Q-learning; Reinforcement Learning; ROS","Anthropomorphic robots; Collision avoidance; Robotics; Robots; Humanoid robot; Model-based OPC; Q-learning; Q-learning method; Real world environments; Reinforcement learning",2-s2.0-85031691326
"Nicolaeva B.K., Borisov A.P., Zlochevskiy V.L.","Development of a software and hardware system for monitoring the air cleaning process using a cyclone-separator",2017,"Journal of Physics: Conference Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029534494&doi=10.1088%2f1742-6596%2f881%2f1%2f012023&partnerID=40&md5=4128db2330ada999fbf805ff0c18a13a","The article is devoted to the development of a hardware-software complex for monitoring and controlling the process of air purification by means of a cyclone-separator. The hardware of this complex is the Arduino platform, to which are connected pressure sensors, air velocities, dustmeters, which allow monitoring of the main parameters of the cyclone-separator. Also, a frequency converter was developed to regulate the rotation speed of an asynchronous motor necessary to correct the flow rate, the control signals of which come with Arduino. The program part of the complex is written in the form of a web application in the programming language JavaScript and inserts into CSS and HTML for the user interface. This program allows you to receive data from sensors, build dependencies in real time and control the speed of rotation of an asynchronous electric drive. The conducted experiment shows that the cleaning efficiency is 95-99.9%, while the airflow at the cyclone inlet is 16-18 m/s, and at the exit 50-70 m/s. © Published under licence by IOP Publishing Ltd.",,"Air cleaners; Application programs; Bridge decks; Cyclone separators; Digital storage; Electric drives; Hardware; Induction motors; Nondestructive examination; Process control; Separators; Storms; User interfaces; Asynchronous electric drive; Cleaning efficiency; Hardware-software complex; Main parameters; Monitoring and controlling; Software and hardwares; Speed of rotation; WEB application; Air purification",2-s2.0-85029534494
"Rios E., Iturbe E., Palacios M.C.","Self-healing multi-cloud application modelling",2017,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030312256&doi=10.1145%2f3098954.3104059&partnerID=40&md5=20505f1cbc2bc2ef606ccf7e4e179682","Cloud computing market forecasts and technology trends confirm that Cloud is an IT disrupting phenomena and that the number of companies with multi-cloud strategy is continuously growing. Cost optimization and increased competitiveness of companies that exploit multi-cloud will only be possible when they are able to leverage multiple cloud offerings, while mastering both the complexity of multiple cloud provider management and the protection against the higher exposure to attacks that multi-cloud brings. .is paper presents the MUSA Security modelling language for multi-cloud applications which is based on the Cloud Application Modelling and Execution Language (CAMEL) to overcome the lack of expressiveness of state-of-the-art modelling languages towards easing: A) the automation of distributed deployment, b) the computation of composite Service Level Agreements (SLAs) that include security and privacy aspects, and c) the risk analysis and service match-making taking into account not only functionality and business aspects of the cloud services, but also security aspects. .e paper includes the description of the MUSA Modeller as the Web tool supporting the modelling with the MUSA modelling language. the paper introduces also the MUSA SecDevOps framework in which the MUSA Modeller is integrated and with which the MUSA Modeller will be validated. © 2017 Association for Computing Machinery.","Cloud; Deployment; Modelling; Multi-cloud; Security","C (programming language); Clouds; Models; Risk analysis; Risk assessment; Cloud applications; Composite services; Deployment; Distributed deployment; Execution languages; Multi-clouds; Security; Security and privacy; Modeling languages",2-s2.0-85030312256
"Procter S., Vasserman E.Y., Hatcli J.","SAFE and secure: Deeply integrating security in a new hazard analysis",2017,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030317073&doi=10.1145%2f3098954.3105823&partnerID=40&md5=bceaddc84a013e3ec6ac2b499889db27","Safety-critical system engineering and traditional safety analyses have for decades been focused on problems caused by natural or accidental phenomena. Security analyses, on the other hand, focus on preventing intentional, malicious acts that reduce system availability, degrade user privacy, or enable unauthorized access. In the context of safety-critical systems, safety and security are intertwined, e.g., injecting malicious control commands may lead to system actuation that causes harm. Despite this intertwining, safety and security concerns have traditionally been designed and analyzed independently of one another, and examined in very different ways. In this work we examine a new hazard analysis technique- Systematic Analysis of Faults and Errors (SAFE)-and its deep integration of safety and security concerns. This is achieved by explicitly incorporating a semantic framework of error ""effects"" that unifies an adversary model long used in security contexts with a fault/error categorization that aligns with previous approaches to hazard analysis. This categorization enables analysts to separate the immediate, component-level effects of errors from their cause or precise deviation from specification. This paper details SAFE's integrated handling of safety and security through a) a methodology grounded in-and adaptable to-different approaches from the literature, b) explicit documentation of system assumptions which are implicit in other analyses, and c) increasing the tractability of analyzing modern, complex, component- based software-driven systems. We then discuss how SAFE's approach supports the long-term goals of of increased compositionality and formalization of safety/security analysis. © 2017 Association for Computing Machinery.","Component-based systems; Hazard analysis; Security; System theoretic process analysis; Systematic analysis of faults and errors","Availability; C (programming language); Errors; Hazards; Safe handling; Safety engineering; Semantics; Software engineering; Systematic errors; Component based systems; Hazard analysis; Process analysis; Security; Systematic analysis; Security systems",2-s2.0-85030317073
"Schuckert F., Ka B., Langweg H.","Source code patterns of SQL injection vulnerabilities",2017,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030322886&doi=10.1145%2f3098954.3103173&partnerID=40&md5=e4a2b3c8b16f2243457cadd43c8f04e5","Many secure software development methods and tools are wellknown and understood. Still, the same software security vulnerabilities keep occurring. To find out if new source code patterns evolved or the same patterns are reoccurring, we investigate SQL injections in PHP open source projects. SQL injections are well-known and a core part of software security education. For each common part of SQL injections, the source code patterns are analysed. Examples are pointed out showing that developers had software security in mind, but nevertheless created vulnerabilities. A comparison to earlier work shows that some categories are not found as often as expected. Our main contribution is the categorization of source code patterns. © 2017 Association for Computing Machinery.","Code review; Data mining; PHP; Software security; SQL injection; Vulnerabilities","Codes (symbols); Computer programming languages; Data mining; Open source software; Security of data; Software design; Software engineering; Code review; New sources; Open source projects; Secure software development; Software security; Source codes; SQL injection; Vulnerabilities; Open systems",2-s2.0-85030322886
"Papp D., Buttyán L., Ma Z.","Towards semi-automated detection of trigger-based behavior for software security assurance",2017,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030308920&doi=10.1145%2f3098954.3105821&partnerID=40&md5=03a220bccd7c9c070047c4b34607ed30","A program exhibits trigger-based behavior if it performs undocumented, often malicious, functions when the environmental conditions and/or specific input values match some pre-specified criteria. Checking whether such hidden functions exist in the program is important for increasing trustworthiness of software. In this paper, we propose a framework to effectively detect trigger-based behavior at the source code level. Our approach is semi-automated: We use automated source code instrumentation and mixed concrete and symbolic execution to generate potentially suspicious test cases that may trigger hidden, potentially malicious functions. The test cases must be investigated by a human analyst manually to decide which of them are real triggers. While our approach is not fully automated, it greatly reduces manual work by allowing analysts to focus on a few test cases found by our automated tools. © 2017 Association for Computing Machinery.","Mixed concrete and symbolic execution; Software security; Source code analysis; Static analysis; Trigger-based behavior","Automation; Codes (symbols); Computer programming languages; Concrete mixers; Concretes; Model checking; Network security; Automated tools; Environmental conditions; Semi-automated detection; Software security; Source code analysis; Source Code Instrumentation; Symbolic execution; Trigger-based behavior; Static analysis",2-s2.0-85030308920
"Zhang Z., Li Q.","On cartesian closed extensions of non-pointed domains",2017,"Theoretical Computer Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026835903&doi=10.1016%2fj.tcs.2017.07.017&partnerID=40&md5=e6030435086fd08143a6a990053360ce","Let P denote a cartesian closed full subcategory of the category POSET of posets and Scott continuous functions. We define C-P to be the full subcategory of objects from P whose D-completion is isomorphic to an object from C, where C is a subcategory of the category CONT of domains. The category C-P is always a subcategory of the category CONTP of continuous posets and Scott continuous functions. We prove that if C is a cartesian closed full subcategory of F-L, U-L, F-RB or U-RB, then the category C-P is also cartesian closed. It is known that the category CDCPO of consistent directed complete posets and Scott continuous functions is cartesian closed. In particular, we have the following cartesian closed categories: F-L-CDCPO, U-L-CDCPO, F-RB-CDCPO, U-RB-CDCPO, F-aL-CDCPO, U-aL-CDCPO, F-B-CDCPO, U-B-CDCPO, etc. If the categories FS and RB coincide, then it leads directly to the most potential of this uniform way of finding new cartesian closed categories of continuous posets: for every cartesian closed full subcategory C of CONT, the category C-P is also cartesian closed. © 2017 Elsevier B.V.","Cartesian closed category; Continuous poset; D-completion; Disjoint union; L-domain; RB-domain; Well rooted","Functions; Set theory; Cartesian closed category; Cartesian closed extensions; Cartesians; Continuous poset; Disjoint union; L-domain; Scott-continuous functions; C (programming language)",2-s2.0-85026835903
"Pattiyanon C., Senivongse T.","Quality model for assessing object-oriented design patterns under development",2017,"Proceedings - 18th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing, SNPD 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030861953&doi=10.1109%2fSNPD.2017.8022749&partnerID=40&md5=f95ff2559543250a989143b26fe7f3a3","Object-oriented design patterns are used to solve recurring problems in the design of object-oriented software. The success of existing design patterns encourages researchers and practitioners to propose new design patterns especially for solving recurring design problems in specific domains. Assessing the quality of the design patterns being developed is an important task for a design pattern developer to determine which parts of the patterns need improvement. This paper presents a hierarchical quality model for object-oriented design patterns under development. The model focuses on two quality attributes, i.e. Embedded Knowledge and Pattern Language quality, of the object-oriented design patterns. The model relates several properties of the design pattern descriptions, i.e. usefulness, completeness, consistency, and understandability, to the two quality attributes. Four quality metrics are proposed to quantitatively measure those properties of the design pattern descriptions. In an evaluation, we obtain a satisfactory result as the proposed quality assessment model can be used to complement other existing design pattern evaluation methods. © 2017 IEEE.","Design pattern; Object-oriented software design; Quality attribute; Quality metric; Quality model","Artificial intelligence; Quality control; Quality management; Software design; Software engineering; Design Patterns; Object-oriented software designs; Quality attributes; Quality metrices; Quality modeling; Object oriented programming",2-s2.0-85030861953
"Pareek A., Khaladkar B., Sen R., Onat B., Nadimpalli V., Agarwal M., Keene N.","Striim: A streaming analytics platform for real-time business decisions",2017,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030331089&doi=10.1145%2f3129292.3129294&partnerID=40&md5=3e5e99aac5dc57c218f6505e0dfa739a","Real-time decisions and insights over real-time data have become the essential mantra of success for many enterprises. The real-time data is generated from a multitude of sources and they come in a streaming fashion with high volume and velocity. The data could be machine generated e.g. clickstream data, logs, sensor data from IoT devices or human generated e.g. social data, mission critical transactional data. This is causing a technological shift from storage driven architectures to event driven architectures for enterprises to be able to capture, integrate and analyze these large sets of data for real-time decision making. Striim is a novel end-to-end analytics platform that enables business users to easily develop and deploy analytical applications that can generate real-time insights over real-time streaming data; business users and developers use a SQL-like declarative language (that has been extended to include streaming semantics) to write application logic in Striim. Striim provides high-throughput, low-latency event processing on commodity hardware with a scale-out architecture. In this paper, we describe the architecture of Striim and discuss some of the key aspects of the platform (a) built-in real-time data capture including streaming change data capture from transactional databases (ii) a natively built storage and query engine that uses modern data structures like skip lists to store streaming window data and performs query optimization, planning and run-time code generation (iii) enabling application de-coupling using persisted streams. © 2017 ACM.","Data capture; Exactly once processing; Streaming Analytics","Architecture; Automatic programming; Competitive intelligence; Data acquisition; Decision making; Digital storage; Information analysis; Semantics; Analytical applications; Declarative Languages; Event-driven architectures; Real time decision-making; Real time decisions; Run-time code generation; Scale-out architectures; Transactional database; Search engines",2-s2.0-85030331089
"Xie H.-B., Ren Z.-K., Xu X.-M., Wang G.-F., Lin Y.-J., Wang S.-J.","Mechanical and process parameters design of 3-roll reducing and sizing block for bar and wire",2017,"Suxing Gongcheng Xuebao/Journal of Plasticity Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029046374&doi=10.3969%2fj.issn.1007-2012.2017.04.007&partnerID=40&md5=bc258ab4a2c5e7b8198e6d6374f5251d","With the C++ programming language as the development platform and the reducing and sizing rolling of the round steel bar as solid model, the source programs for calculating the process parameters were proposed by selecting the corresponding calculation models, which included deformation resistance, spread, rolling force, rolling torque etc. In order to revise the calculation model in the program, the rolling process was simulated by Deform-3D software. The influence of elongation on spread was emphatically analyzed, then, the empirical formula of spread model was revised. Finally, taking the Ф16 mm round steel as an example, the amount of spread, sectional area of outlet and rolling force were compared by software calculation, finite element simulation and field data. Results show that the calculations of the software are in good agreement with that of the field data and simulation, which verifies the accuracy of the program calculation. © 2017, Editorial Board of Journal of Plasticity Engineering. All right reserved.","3-roll reducing and sizing block; Bar and wire; Mechanical and process parameters; Spread model",,2-s2.0-85029046374
"Yu L., Cao F., Hou L., Jia Y., Shen H., Li H., Ning Z., Xing D., Sun J.","The study of preparation process of spray formed 7075/Al-Si bimetallic gradient composite plate",2017,"Journal of Materials Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018372778&doi=10.1557%2fjmr.2017.152&partnerID=40&md5=250c6ff30a71888b91ad34539b04bb5c","To determine the spray forming process parameters of 7075/Al-Si bimetallic gradient composite plate with two gas atomizers, a calculation model of the plate has been established by using the finite element software ANSYS. The effects of different motion trajectory, advance speed, swing cycle and spray center distance on shape, and silicon distribution of deposited plate have been simulated by the APDL programming language. The results show that a smooth and uniform surface is obtained when motion trajectory is in a regular jaggies mode. The deposited plate varies from platform to stepped shape with a center distance increasing from 20 mm to 50 mm; meanwhile, the width of the transition zone decreases gradually. As the period increases to 8 s, the silicon distribution of each layer presents a jagged fluctuation. Both the thickness of the deposited plate and the width of the transition zone decrease as the advance speed increases, except the silicon distribution. Finally, the modeling and simulation of the co-spray formed 7075/Al-Si bimetallic gradient composite plate are validated by experimental investigations and the simulation results are in good agreement with the actual results. © Materials Research Society 2017.","APDL; gradient material; simulation; spray forming","Atomization; Silicon; Spray steelmaking; APDL; Experimental investigations; Finite element software; Gradient materials; Model and simulation; simulation; Spray forming; Spray forming process; Finite element method",2-s2.0-85018372778
"Marchese Robinson R.L., Palczewska A., Palczewski J., Kidley N.","Comparison of the Predictive Performance and Interpretability of Random Forest and Linear Models on Benchmark Data Sets",2017,"Journal of Chemical Information and Modeling",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028576326&doi=10.1021%2facs.jcim.6b00753&partnerID=40&md5=a2c790fe04e6ace99637d482d7d27134","The ability to interpret the predictions made by quantitative structure-activity relationships (QSARs) offers a number of advantages. While QSARs built using nonlinear modeling approaches, such as the popular Random Forest algorithm, might sometimes be more predictive than those built using linear modeling approaches, their predictions have been perceived as difficult to interpret. However, a growing number of approaches have been proposed for interpreting nonlinear QSAR models in general and Random Forest in particular. In the current work, we compare the performance of Random Forest to those of two widely used linear modeling approaches: linear Support Vector Machines (SVMs) (or Support Vector Regression (SVR)) and partial least-squares (PLS). We compare their performance in terms of their predictivity as well as the chemical interpretability of the predictions using novel scoring schemes for assessing heat map images of substructural contributions. We critically assess different approaches for interpreting Random Forest models as well as for obtaining predictions from the forest. We assess the models on a large number of widely employed public-domain benchmark data sets corresponding to regression and binary classification problems of relevance to hit identification and toxicology. We conclude that Random Forest typically yields comparable or possibly better predictive performance than the linear modeling approaches and that its predictions may also be interpreted in a chemically and biologically meaningful way. In contrast to earlier work looking at interpretation of nonlinear QSAR models, we directly compare two methodologically distinct approaches for interpreting Random Forest models. The approaches for interpreting Random Forest assessed in our article were implemented using open-source programs that we have made available to the community. These programs are the rfFC package (https://r-forge.r-project.org/R/?group-id=1725) for the R statistical programming language and the Python program HeatMapWrapper [https://doi.org/10.5281/zenodo.495163] for heat map generation. © 2017 American Chemical Society.",,"Benchmarking; Classification (of information); Computer software; Decision trees; Forecasting; HTTP; Least squares approximations; Molecular graphics; Open source software; Support vector machines; Binary classification problems; Linear Support Vector Machines; Open source projects; Partial least square (PLS); Predictive performance; Quantitative structure-activity relationships; Random forest algorithm; Support vector regression (SVR); Computational chemistry; benchmarking; comparative study; conformation; heat; information science; least square analysis; molecular model; procedures; quantitative structure activity relation; statistical model; support vector machine; Benchmarking; Hot Temperature; Informatics; Least-Squares Analysis; Linear Models; Models, Molecular; Molecular Conformation; Quantitative Structure-Activity Relationship; Support Vector Machine",2-s2.0-85028576326
"Kouki P., Schaffer J., Pujara J., O'Donovan J., Getoor L.","User preferences for hybrid explanations",2017,"RecSys 2017 - Proceedings of the 11th ACM Conference on Recommender Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030473004&doi=10.1145%2f3109859.3109915&partnerID=40&md5=c1241681701bcefd2cc8a7913f274954","Hybrid recommender systems combine several different sources of information to generate recommendations. These systems demonstrate improved accuracy compared to single-source recommendation strategies. However, hybrid recommendation strategies are inherently more complex than those that use a single source of information, and thus the process of explaining recommendations to users becomes more challenging. In this paper we describe a hybrid recommender system built on a probabilistic programming language, and discuss the benefits and challenges of explaining its recommendations to users. We perform a mixed model statistical analysis of user preferences for explanations in this system. Through an online user survey, we evaluate explanations for hybrid algorithms in a variety of text and visual, graph-based formats, that are either novel designs or derived from existing hybrid recommender systems.","Explanations; Hybrid explanations; Hybrid recommendations","Computer programming languages; Graphic methods; Recommender systems; Explanations; Hybrid algorithms; Hybrid explanations; Hybrid recommendation; Hybrid recommender systems; Probabilistic programming language; Recommendation strategies; Sources of informations; Online systems",2-s2.0-85030473004
"Tierny J., Favelier G., Levine J.A., Gueunet C., Michaux M.","The Topology ToolKit",2017,"IEEE Transactions on Visualization and Computer Graphics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028706951&doi=10.1109%2fTVCG.2017.2743938&partnerID=40&md5=8451bc270817b82bf2feebdc240350e2","This system paper presents the Topology ToolKit (TTK), a software platform designed for the topological analysis of scalar data in scientific visualization. While topological data analysis has gained in popularity over the last two decades, it has not yet been widely adopted as a standard data analysis tool for end users or developers. TTK aims at addressing this problem by providing a unified, generic, efficient, and robust implementation of key algorithms for the topological analysis of scalar data, including: critical points, integral lines, persistence diagrams, persistence curves, merge trees, contour trees, Morse-Smale complexes, fiber surfaces, continuous scatterplots, Jacobi sets, Reeb spaces, and more. TTK is easily accessible to end users due to a tight integration with ParaView. It is also easily accessible to developers through a variety of bindings (Python, VTK/C++) for fast prototyping or through direct, dependency-free, C++, to ease integration into pre-existing complex systems. While developing TTK, we faced several algorithmic and software engineering challenges, which we document in this paper. In particular, we present an algorithm for the construction of a discrete gradient that complies to the critical points extracted in the piecewise-linear setting. This algorithm guarantees a combinatorial consistency across the topological abstractions supported by TTK, and importantly, a unified implementation of topological data simplification for multi-scale exploration and analysis. We also present a cached triangulation data structure, that supports time efficient and generic traversals, which self-adjusts its memory usage on demand for input simplicial meshes and which implicitly emulates a triangulation for regular grids with no memory overhead. Finally, we describe an original software architecture, which guarantees memory efficient and direct accesses to TTK features, while still allowing for researchers powerful and easy bindings and extensions. TTK is open source (BSD license) and its code, online documentation and video tutorials are available on TTK&#x0027;s website [108]. IEEE","Algorithm design and analysis; bivariate data; Data analysis; data segmentation; Data structures; Data visualization; feature extraction; scalar data; Software; Software algorithms; Tools; Topological data analysis; uncertain data","Bins; C++ (programming language); Computer programming; Computer software; Data handling; Data mining; Data reduction; Data structures; Feature extraction; Forestry; Information analysis; Open source software; Open systems; Piecewise linear techniques; Software engineering; Surveying; Tools; Topology; Triangulation; Visualization; Algorithm design and analysis; Bivariate datum; Data segmentation; Scalar data; Software algorithms; Topological data analysis; Uncertain datas; Data visualization",2-s2.0-85028706951
"Pálovics R., Kelen D., Benczúr A.A.","Tutorial on open source online learning recommenders",2017,"RecSys 2017 - Proceedings of the 11th ACM Conference on Recommender Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030457018&doi=10.1145%2f3109859.3109937&partnerID=40&md5=a8b0008074398d4b1a491e4077dc99d8","Recommender systems have to serve in online environments that can be non-stationary. Traditional recommender algorithms may periodically rebuild their models, but they cannot adjust to quick changes in trends caused by timely information. In contrast, online learning models can adopt to temporal effects, hence they may overcome the effect of concept drift. In our tutorial, we present open source systems capable of updating their models on the fly after each event: Apache Spark, Apache Flink and Alpenglow, a C++ based Python recommender framework. Participants of the tutorial will be able to experiment with all the three systems by using interactive Jupyter and Zeppelin Notebooks. Our final objective is to compare and then blend batch and online methods to build models providing high quality top-k recommendation in non-stationary environments.","Concept drift; Open source recommender systems; Ranking prediction by online learning; Streaming; Temporal evaluation","Acoustic streaming; C++ (programming language); Online systems; Open systems; Recommender systems; Concept drifts; Non-stationary environment; Online environments; Online learning; Open sources; Recommender algorithms; Temporal evaluation; Top-K recommendations; E-learning",2-s2.0-85030457018
"Shangguan C., Wang X., Ge G., Miao Y.","New Bounds For Frameproof Codes",2017,"IEEE Transactions on Information Theory",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028527171&doi=10.1109%2fTIT.2017.2745619&partnerID=40&md5=a8271eec3211a29174fa42356323f055","Frameproof codes are used to fingerprint digital data. They can prevent copyrighted materials from unauthorized use. In this paper, we study upper and lower bounds for w- frameproof codes of length N over an alphabet of size q. The upper bound is based on a combinatorial approach and the lower bound is based on a probabilistic construction. Both bounds can improve one of the previous results when q is small compared to w, say cq &#x2264; w for some constant c &#x2264; q. Furthermore, we pay special attention to binary frameproof codes. We show a binary w-frameproof code of length N cannot have more than N codewords if N &#x003C; (w+1/2). IEEE","combinatorial counting; expurgation method; Fingerprinting; frameproof codes","Bins; Codes (symbols); Combinatorial approach; combinatorial counting; Copyrighted materials; Digital datas; expurgation method; Fingerprinting; Frameproof codes; Upper and lower bounds; C (programming language)",2-s2.0-85028527171
"Guo Y., Huang S., Wang Z., Deng W., Li L.","Crossing Ability of Grid Faults for Matrix Converter Direct Torque Control System",2017,"Diangong Jishu Xuebao/Transactions of China Electrotechnical Society",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029566003&doi=10.19595%2fj.cnki.1000-6753.tces.L70200&partnerID=40&md5=be4cc1742ad461722276e68fe0a52052","Due to the particularity of its own structure, matrix converter is vulnerable to the abnormal power supply of input side. In this paper, the equivalent mathematical model of the system is established under grid failures according to short circuit grounding faults. A new switch control strategy is proposed. This strategy ensures the security of matrix converter through the control signals of 9 groups of bidirectional switches being given respectively in different time under grid faults. The working conditions of matrix converter under normal and abnormal states of grid are simulated in Matlab/Simulink. Then DSP and FPGA algorithms are designed respectively in C language and VHDL to perform the proposed control strategy. Finally, a highly integrated experimental platform of matrix converter has been developed to verify the proposed switching control strategy. It is shown that the control strategy can not only make the speed control system have good static and dynamic performances, but also simulate the various conditions of matrix converter correctly under normal or abnormal grid operations. That is to say the matrix converter-induction motor direct torque control system has the capability of crossing grid faults. © 2017, The editorial office of Transaction of China Electrotechnical Society. All right reserved.","Direct torque control; Fault crossing; Matrix converter; Power grid fault; Space vector modulation","C (programming language); Computer hardware description languages; Control systems; Electric power transmission networks; Induction motors; MATLAB; Matrix converters; Time switches; Torque control; Vector spaces; Direct torque control; Direct torque control system; Experimental platform; Fault crossings; Power grids; Space Vector Modulation; Static and dynamic performance; Switching control strategy; Electric power system control",2-s2.0-85029566003
"Chen X., Chen W., Lu Z., Zhang Y., Chang R., Hassan M.M., Alelaiwi A., Xiang Y.","MBSA: a lightweight and flexible storage architecture for virtual machines",2017,"Concurrency Computation ",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014249992&doi=10.1002%2fcpe.4028&partnerID=40&md5=7c8892d0d36032d2386e6303d674ab47","With the advantages of extremely high access speed, low energy consumption, nonvolatility, and byte addressability, nonvolatile memory (NVM) device has already been setting off a revolution in storage field. Conventional storage architecture needs to be optimized or even redesigned from scratch to fully explore the performance potential of NVM device. However, most previous NVM-related works only explore its low access latency and low energy consumption. Few works have been done to explore the appropriate way to use NVM device for improving virtual machine's storage performance. In this paper, we comprehensively evaluate and analyze conventional virtual machine's storage architecture. We find that, even with cutting-edge optimization technologies, virtual machine can only achieve 30% of NVM device's original performance. Based on this observation, we propose a memory bus–based storage architecture, which we named MBSA. Memory bus–based storage architecture can greatly shorten the length of virtual machine's storage input/output stack and improve NVM device's use flexibility. In addition, an efficient wear-leveling algorithm is proposed to prolong NVM device's lifespan. To evaluate the new architecture, we implement it as well as the wear-leveling algorithm on real hardware and software platform. Experimental results show that MBSA can provide a big performance improvement, about 2.55X, and the wear-leveling algorithm can efficiently balance write operations on NVM device with a negligible performance overhead (no more than 3%). Copyright © 2017 John Wiley & Sons, Ltd.","nonvolatile memory, performance optimization, storage I/O stack, virtual machine","Energy utilization; Java programming language; Memory architecture; Network security; Optimization; System buses; Virtual machine; Hardware and software; Low energy consumption; Nonvolatile memory devices; Optimization technology; Performance optimizations; Performance potentials; Storage architectures; Wear-leveling algorithms; Nonvolatile storage",2-s2.0-85014249992
"Zhuang J., Young A.P., Tsung C.-K.","Integration of Biomolecules with Metal–Organic Frameworks",2017,"Small",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021315419&doi=10.1002%2fsmll.201700880&partnerID=40&md5=dd5966c4865beed14bc6cab442430821","Owing to the progressive development of metal–organic-frameworks (MOFs) synthetic processes and considerable potential applications in last decade, integrating biomolecules into MOFs has recently gain considerable attention. Biomolecules, including lipids, oligopeptides, nucleic acids, and proteins have been readily incorporated into MOF systems via versatile formulation methods. The formed biomolecule-MOF hybrid structures have shown promising prospects in various fields, such as antitumor treatment, gene delivery, biomolecular sensing, and nanomotor device. By optimizing biomolecule integration methods while overcoming existing challenges, biomolecule-integrated MOF platforms are very promising to generate more practical applications. © 2017 WILEY-VCH Verlag GmbH & Co. KGaA, Weinheim","biomolecule integration; metal–organic frameworks; nanoparticle formulation; porous coordination polymers","Crystalline materials; Gene transfer; Integration; Java programming language; Metal nanoparticles; Nucleic acids; Organic polymers; Biomolecular sensing; Hybrid structure; Integration method; Metal organic framework; Metalorganic frameworks (MOFs); Nanoparticle formulation; Porous coordination polymer; Synthetic process; Biomolecules",2-s2.0-85021315419
"Huang Y., Zhao M., Han S., Lai Z., Yang J., Tan C., Ma Q., Lu Q., Chen J., Zhang X., Zhang Z., Li B., Chen B., Zong Y., Zhang H.","Growth of Au Nanoparticles on 2D Metalloporphyrinic Metal-Organic Framework Nanosheets Used as Biomimetic Catalysts for Cascade Reactions",2017,"Advanced Materials",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021108955&doi=10.1002%2fadma.201700102&partnerID=40&md5=51a4581b48f4fae1bb6feac9752429a6","Inspired by the multiple functions of natural multienzyme systems, a new kind of hybrid nanosheet is designed and synthesized, i.e., ultrasmall Au nanoparticles (NPs) grown on 2D metalloporphyrinic metal-organic framework (MOF) nanosheets. Since 2D metalloporphyrinic MOF nanosheets can act as the peroxidase mimics and Au NPs can serve as artificial glucose oxidase, the hybrid nanosheets are used to mimic the natural enzymes and catalyze the cascade reactions. Furthermore, the synthesized hybrid nanosheets are used to detect biomolecules, such as glucose. This study paves a new avenue to design nanomaterial-based biomimetic catalysts with multiple complex functions. © 2017 WILEY-VCH Verlag GmbH & Co. KGaA, Weinheim","biomimetic catalysts; cascade reactions; hybrid nanosheets; metal-organic framework nanosheets","Biomimetics; Catalysts; Crystalline materials; Glucose; Glucose oxidase; Glucose sensors; Gold; Java programming language; Metal nanoparticles; Metals; Nanoparticles; Synthesis (chemical); Au nanoparticle; Biomimetic catalysts; Cascade reactions; Complex functions; Metal organic framework; Multiple function; Natural enzyme; Peroxidase mimics; Nanosheets",2-s2.0-85021108955
"Lazar T., Sadikov A., Bratko I.","Rewrite Rules for Debugging Student Programs in Programming Tutors",2017,"IEEE Transactions on Learning Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028557499&doi=10.1109%2fTLT.2017.2743701&partnerID=40&md5=11414253955494cb814f68ff60b6e9e1","Data-driven intelligent tutoring systems learn to provide feedback based on past student behavior, reducing the effort required for their development. A major obstacle to applying data-driven methods in the programming domain is the lack of meaningful observable actions for describing the students&#x0027; problem-solving process. We propose rewrite rules as a language-independent formalization of programming actions in terms of code edits. We describe a method for automatically extracting rewrite rules from students&#x0027; program-writing traces, and a method for debugging new programs using these rules. We used these methods to automatically provide hints in a web application for learning programming. In-class evaluation showed that students receiving automatic feedback solved problems faster and submitted fewer incorrect programs. We believe that rewrite rules provide a good basis for further research into how humans write and debug programs. IEEE","automatic debugging; Computer-assisted instruction; Debugging; intelligent tutoring systems; Problem-solving; Production facilities; program synthesis; Programming profession; Syntactics; Writing","Computer aided analysis; Computer aided instruction; Computer debugging; Computer programming; Computer systems programming; Education; Problem solving; Students; Syntactics; Technical writing; Computer Assisted Instruction; Intelligent tutoring system; Production facility; Program synthesis; Programming profession; Program debugging",2-s2.0-85028557499
"Chen J., Shen K., Li Y.","Greening the Processes of Metal–Organic Framework Synthesis and their Use in Sustainable Catalysis",2017,"ChemSusChem",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026287938&doi=10.1002%2fcssc.201700748&partnerID=40&md5=f47ae4a82e978b1c24948cd50b34afd1","Given the shortage of sustainable resources and the increasingly serious environmental issues in recent decades, the demand for clean technologies and sustainable feedstocks is of great interest to researchers worldwide. With regard to the fields of energy saving and environmental remediation, the key point is the development of efficient catalysts, not only in terms of facile synthesis methods, but also the benign utilization of such catalysts. This work reviews the use of metal–organic frameworks (MOFs) and MOF-based materials in these fields. The definition of MOFs and MOF-based materials will be primarily introduced followed by a brief description of the characterization and stability of MOF-related materials under the applied conditions. The greening of MOF synthesis processes will then be discussed and catalogued by benign solvents and conditions and green precursors of MOFs. Furthermore, their suitable application in sustainable catalysis will be summarized, focusing on several typical atom-economic reactions, such as the direct introduction of H2 or O2 and C−C bond formation. Approaches towards reducing CO2 emission by MOF-based catalysts will be described with special emphasis on CO2 fixation and CO2 reduction. In addition, driven by the explosive growth of energy consumption in the last century, much research has gone into biomass, which represents a renewable alternative to fossil fuels and a sustainable carbon feedstock for chemical production. The advanced progress of biomass-related transformations is also illustrated herein. Fundamental insights into the nature of MOF-based materials as constitutionally easily recoverable heterogeneous catalysts and as supports for various active sites is thoroughly discussed. Finally, challenges facing the development of this field and the outlook for future research are presented. © 2017 Wiley-VCH Verlag GmbH & Co. KGaA, Weinheim","atom efficiency; biomass conversion; green chemistry; heterogeneous catalysis; metal–organic frameworks","Bioconversion; Biomass; Carbon; Carbon dioxide; Catalysis; Catalyst activity; Catalysts; Characterization; Chemical bonds; Crystalline materials; Energy utilization; Environmental technology; Feedstocks; Java programming language; Alternative to fossil fuels; Atom efficiency; Biomass conversion; Environmental remediation; Green chemistry; Heterogeneous catalyst; Metal organic framework; Metalorganic frameworks (MOFs); Sustainable development; organometallic compound; catalysis; chemistry; green chemistry; procedures; synthesis; Catalysis; Chemistry Techniques, Synthetic; Green Chemistry Technology; Organometallic Compounds",2-s2.0-85026287938
"Mojahedian M.M., Aref M.R., Gohari A.","Perfectly Secure Index Coding",2017,"IEEE Transactions on Information Theory",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028558665&doi=10.1109%2fTIT.2017.2743688&partnerID=40&md5=01120a3700ea4cf67333d8e916a760eb","In this paper, we investigate the index coding problem in the presence of an eavesdropper. Messages are to be sent from one transmitter to a number of legitimate receivers who have side information about the messages, and share a set of secret keys with the transmitter. To do this, the transmitter communicates to the legitimate receivers the public code C which is also heard by the eavesdropper. We assume perfect secrecy, meaning that the eavesdropper should not be able to retrieve any information about the message set from the public communication. We study the minimum key lengths for zeroerror and perfectly secure index coding problem. On one hand, this problem is a generalization of the index coding problem (and thus a difficult one). On the other hand, it is a generalization of the Shannon&#x2019;s cipher system. We show that a generalization of Shannon&#x2019;s one-time pad strategy is optimal up to a multiplicative constant, meaning that it obtains the entire boundary of the cone formed by looking at the secure rate region from the origin. This shows the optimality of the generalized one-time pad for minimizing the consumption of shared secret keys per message bits, when public communication is free (the transmitter is not charged for the rate of the public communication). Finally, we consider relaxation of the perfect secrecy and zero-error constraints to weak secrecy and asymptotically vanishing probability of error, and provide a secure version of the result, obtained by Langberg and Effros, on the equivalence of zero-error and &#x03B5;-error regions in the conventional index coding problem. IEEE","&#x03B5;-error communication; Channel coding; Ciphers; common and private keys; Index coding; Indexes; perfect secrecy; Receivers; Servers; Shannon cipher system; strong secrecy; Transmitters; weak secrecy; zero-error communication","C (programming language); Channel coding; Cryptography; Errors; Receivers (containers); Servers; Transmitters; Ciphers; Index coding; Indexes; Perfect secrecy; Private key; Shannon; Strong secrecies; weak secrecy; Zero errors; Codes (symbols)",2-s2.0-85028558665
"Rubio-Manzano C., Pereira-Farina M.","Declarative computational perceptions networks for automatically generating excerpts in computer games by using Bousi Prolog",2017,"IEEE International Conference on Fuzzy Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030174003&doi=10.1109%2fFUZZ-IEEE.2017.8015592&partnerID=40&md5=9677a389ae479c67feba55df798f0725","Recently, we have presented a new technology for improving player experience in Computer Games by using players behaviour analysis and linguistic descriptions. Here, we explain the details about its implementation which have not been presented in any work before. Our implementation is based on a declarative version of the concept of computational perception network whose implementation has been performed by means of a fuzzy linguistic logic programming language named Bousi Prolog. Our aim is to show the potentiality of this kind of programming language in order to implement computational perceptions in computer games. © 2017 IEEE.",,"Computation theory; Computer games; Computer programming; Computer programming languages; Fuzzy systems; Linguistics; Logic programming; Behaviour analysis; Computational perception; Fuzzy linguistics; Linguistic descriptions; Player experience; PROLOG (programming language)",2-s2.0-85030174003
"Julian-Iranzo P., Saenz-Perez F.","FuzzyDES or how DES Met Bousi-Prolog",2017,"IEEE International Conference on Fuzzy Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030167722&doi=10.1109%2fFUZZ-IEEE.2017.8015580&partnerID=40&md5=a8a9f6f096ed6d6c12a3cff4638f33ef","This article describes the implementation of the fuzzy deductive database system FuzzyDES, where concepts underlying the fuzzy logic programming system Bousi∼Prolog are adapted and improved to be transferred to the DES deductive database system. We take advantage of the DES tabled-based implementation to propose new methods for rule compiling and t-closure computing, developing a terminating query answering system with graded rules. A description of the system, an example, and a link to a publicly-available, comprehensive system are provided. © 2017 IEEE.",,"Computation theory; Computer programming; Database systems; Fuzzy logic; Fuzzy systems; Logic programming; PROLOG (programming language); Query processing; Comprehensive system; Query answering systems; Intelligent databases",2-s2.0-85030167722
"Hernandez-Aguila A., Garcia-Valdez M., Castillo O., Guervós J.-J.M.","An open source implementation of an intuitionistic fuzzy inference system in Clojure",2017,"IEEE International Conference on Fuzzy Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030164935&doi=10.1109%2fFUZZ-IEEE.2017.8015697&partnerID=40&md5=bec8e7b2333ffb90cc843d50ccbe5eec","The software presented in this paper is an implementation of an intuitionistic fuzzy inference system. Such type of fuzzy inference systems provide an extra layer of uncertainty, called indeterminacy, that the user can integrate in the antecedents and consequents of the fuzzy system. The additional calculations required to make an inference in this type of system needs a negligible extra amount of computational resources, making it a low-cost alternative to type-2 fuzzy inference systems. At the current time, no other implementation of such type of system exist that is open source and free of charge. The software is developed in Clojure in order to leverage the Java libraries, the JVM itself, and the capabilities of the programming language to implement concurrency in a convenient manner. However, the goal of this implementation is to provide a language-agnostic interface based in a REST API, which can be used by any programming language capable of handling HTTP requests. A comparison between a traditional type-1 fuzzy inference is provided, where the reader can observe how the indeterminacy affects the outputs of the system. © 2017 IEEE.",,"Application programming interfaces (API); Computer programming languages; Computer software; Fuzzy sets; Fuzzy systems; Open source software; Open systems; Computational resources; Free of charge; Fuzzy inference systems; Intuitionistic fuzzy; Java library; Open source implementation; Open sources; Type-2 fuzzy; Fuzzy inference",2-s2.0-85030164935
"Fu C., Sarabakha A., Kayacan E., Wagner C., John R., Garibaldi J.M.","Similarity-based non-singleton fuzzy logic control for improved performance in UAVs",2017,"IEEE International Conference on Fuzzy Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030167418&doi=10.1109%2fFUZZ-IEEE.2017.8015440&partnerID=40&md5=67f77f731ce4934cefe6cdbd0d955b49","As non-singleton fuzzy logic controllers (NSFLCs) are capable of capturing input uncertainties, they have been effectively used to control and navigate unmanned aerial vehicles (UAVs) recently. To further enhance the capability to handle the input uncertainty for the UAV applications, a novel NSFLC with the recently introduced similarity-based inference engine, i.e., Sim-NSFLC, is developed. In this paper, a comparative study in a 3D trajectory tracking application has been carried out using the aforementioned Sim-NSFLC and the NSFLCs with the standard as well as centroid composition-based inference engines, i.e., Sta-NSFLC and Cen-NSFLC. All the NSFLCs are developed within the robot operating system (ROS) using the C++ programming language. Extensive ROS Gazebo simulation-based experiments show that the Sim-NSFLCs can achieve better control performance for the UAVs in comparison with the Sta-NSFLCs and Cen-NSFLCs under different input noise levels. © 2017 IEEE.",,"Air navigation; C++ (programming language); Computer circuits; Engines; Fuzzy logic; Fuzzy systems; Inference engines; Robot programming; Unmanned aerial vehicles (UAV); 3-D trajectory; Comparative studies; Control performance; Fuzzy logic control; Fuzzy logic controllers; Input noise; Input uncertainty; Robot operating systems (ROS); Fuzzy inference",2-s2.0-85030167418
"Nys V., De Schreye D.","Transforming coroutining logic programs into equivalent chr programs",2017,"Electronic Proceedings in Theoretical Computer Science, EPTCS",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030120978&doi=10.4204%2fEPTCS.253.4&partnerID=40&md5=71fc61086f9e0a3ab711ba3bc14fd529","We extend a technique called Compiling Control. The technique transforms coroutining logic programs into logic programs that, when executed under the standard left-to-right selection rule (and not using any delay features) have the same computational behavior as the coroutining program. In recent work, we revised Compiling Control and reformulated it as an instance of Abstract Conjunctive Partial Deduction. This work was mostly focused on the program analysis performed in Compiling Control. In the current paper, we focus on the synthesis of the transformed program. Instead of synthesizing a new logic program, we synthesize a CHR(Prolog) program which mimics the coroutining program. The synthesis to CHR yields programs containing only simplification rules, which are particularly amenable to certain static analysis techniques. The programs are also more concise and readable and can be ported to CHR implementations embedded in other languages than Prolog.",,"Computation theory; Computer circuits; Logic programming; Static analysis; Analysis techniques; Logic programs; Partial deduction; Program analysis; Selection Rules; Simplification rules; PROLOG (programming language)",2-s2.0-85030120978
"Blanchard A., Loulergue F., Kosmatov N.","From concurrent programs to simulating sequential programs: Correctness of a transformation",2017,"Electronic Proceedings in Theoretical Computer Science, EPTCS",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030083877&doi=10.4204%2fEPTCS.253.9&partnerID=40&md5=7b344cd0695f3d4403f6daed7567e2be","FRAMA-C is a software analysis framework that provides a common infrastructure and a common behavioral specification language to plugins that implement various static and dynamic analyses of C programs. Most plugins do not support concurrency. We have proposed CONC2SEQ, a FRAMA-C plugin based on program transformation, capable to leverage the existing huge code base of plugins and to handle concurrent C programs. In this paper we formalize and sketch the proof of correctness of the program transformation principle behind CONC2SEQ, and present an effort towards the full mechanization of both the formalization and proofs with the proof assistant COQ.",,"Machinery; Specification languages; Theorem proving; Behavioral specification; Concurrent program; Program transformations; Proof assistant; Proof of correctness; Sequential programs; Software analysis; Static and dynamic analysis; C (programming language)",2-s2.0-85030083877
"Guo S., Gao J., Guo J., Li N.","The LabVIEW-based control system for the upper limb rehabilitation robot",2017,"2017 IEEE International Conference on Mechatronics and Automation, ICMA 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030316567&doi=10.1109%2fICMA.2017.8016079&partnerID=40&md5=44669dc742c7553de5238ebe16558d42","In this paper, a control system of upper limb rehabilitation robot based on LabVIEW was proposed, and the structure of the control system was also provided. Through using the LabVIEW, the system had a good software interface and control effect. In addition, with the communication protocol between the robot and LabVIEW, the system can realize the real-time transmission of control signal and control character analysis, and then select the corresponding function to achieve rehabilitation training of upper limb rehabilitation robot control. LabVIEW had the rich library function and many advantages such as easy debugging, programming and so on. The control system of the upper limb rehabilitation robot rehabilitation training based on LabVIEW can be extremely convenient to control the robot's rehabilitation training, moreover, the man-machine interface was friendly and easy for the operator to use. Finally experimental results showed that the the system based on LabVIEW software can make exercises rehabilitation training of the upper limb rehabilitation robot more stable operation. © 2017 IEEE.","Control System; Rehabilitation Training; Upper limbs Rehabilitation Robot","Biological organs; Computer programming languages; Control systems; Patient rehabilitation; Personnel training; Robots; Character analysis; Lab-view softwares; Man machine interface; Real-time transmissions; Rehabilitation robot; Rehabilitation training; Software interfaces; Upper-limb rehabilitation; Neuromuscular rehabilitation",2-s2.0-85030316567
"Divya C., Koushick V.","Design and simulation of dual band Microstrip feed dual Yagi Uda antenna for C/X Band applications",2017,"2017 1st International Conference on Next Generation Computing Applications, NextComp 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030454994&doi=10.1109%2fNEXTCOMP.2017.8016184&partnerID=40&md5=52616f3e856887cad24769cc4a20ddbb","A dual band Microstrip feed dual Yagi-Uda antenna is presented in this paper. Normally, the Yagi-Uda antenna radiates in the end fire direction. The proposed antenna is intended to radiate as near as possible to obtain the maximum radiation pattern with low profile and compact size. The reflector is U shaped slot; the driven element (Radiator) is U shaped fold slot while the director is rectangular slot. These slots are printed on a top of very thin FR4 substrate with a dimension of 1.6mm and loss tangent of 0.0018. The radiator will be fed by the Microstrip feed line printed on the bottom of the substrate. A C-band (4-8 GHz) prototype is designed by using Integrated Electromagnetic 3 Dimension (IE3D) Software and to be tested using Network Analyzer. The proposed antenna resonates at multiple frequencies and the maximum gain of above 8 dBi is achieved. The main objective is to optimize the structure of a proposed antenna (interms of length and width), to achieve high gain above 8.0 dBi and directivity above 10.0 dBi and also to operate over a multiple band of microwave frequency which is used for enormous microwave applications. The performance analysis is measured in terms of return loss, bandwidth and VSWR respectively. This antenna finds application for defense and wireless communication where antenna can be widely used for satellite applications. © 2017 IEEE.","End fire direction; Gain; Return loss; VSWR","Antenna feeders; C (programming language); Directional patterns (antenna); Directive antennas; Microwave antennas; Radiators; Software testing; Uranium; Wireless telecommunication systems; Design and simulation; End fire; Gain; Microwave applications; Return loss; Satellite applications; VSWR; Wireless communications; Antenna arrays",2-s2.0-85030454994
"Sallai G., Hajdu A., Tóth T., Micskei Z.","Towards evaluating size reduction techniques for software model checking",2017,"Electronic Proceedings in Theoretical Computer Science, EPTCS",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030122269&doi=10.4204%2fEPTCS.253.7&partnerID=40&md5=fc727ff382bf571dce2ef5e892d25f66","Formal verification techniques are widely used for detecting design flaws in software systems. Formal verification can be done by transforming an already implemented source code to a formal model and attempting to prove certain properties of the model (e.g. that no erroneous state can occur during execution). Unfortunately, transformations from source code to a formal model often yield large and complex models, making the verification process inefficient and costly. In order to reduce the size of the resulting model, optimization transformations can be used. Such optimizations include common algorithms known from compiler design and different program slicing techniques. Our paper describes a framework for transforming C programs to a formal model, enhanced by various optimizations for size reduction. We evaluate and compare several optimization algorithms regarding their effect on the size of the model and the efficiency of the verification. Results show that different optimizations are more suitable for certain models, justifying the need for a framework that includes several algorithms.","CEGAR; Compiler optimizations; Model checking; Size reduction; Slicing","C (programming language); Formal verification; Optimization; Program compilers; Size determination; Verification; CEGAR; Compiler optimizations; Optimization algorithms; Size reduction techniques; Size reductions; Slicing; Software model checking; Verification techniques; Model checking",2-s2.0-85030122269
"Guo J., Li N., Guo S., Gao J.","A LabVIEW-based human-computer interaction system for the exoskeleton hand rehabilitation robot",2017,"2017 IEEE International Conference on Mechatronics and Automation, ICMA 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030309655&doi=10.1109%2fICMA.2017.8015880&partnerID=40&md5=cc772baeaa789b96687af36fb3921632","Exoskeleton upper limb rehabilitation robots are more and more applied to help hemiplegic patients to implement rehabilitation training, which makes up the shortage of rehabilitation only depend on doctors. Aiming at the training of patients' hand exercise, in this paper a kind of human-computer interaction of exoskeleton hand rehabilitation robots based on LabVIEW system was proposed, which was mainly composed of exoskeleton fingers robot part, data acquisition system, serial assistant receiver, and the virtual hand. When the patients wore the exoskeleton hand rehabilitation robots, and once his (her) fingers moved, the shape of bend sensors glued the robots would change. The changed electrical signals were shifted by A/D conversion system and delivered to the serial assistant port, impelling the hand in virtual environment to move synchronously. This course was human-computer interaction. In this paper, the PTC Creo (Parametric Technology Corporation) software was used to design a model of exoskeleton hand rehabilitation robot, and then single chip microcomputer and A/D converter were carried out to accomplish data acquisition. While the virtual environment was built with LabVIEW software, which could call the fingers model and program a serial assistant. This system could swiftly deliver the data to the virtual fingers and then implement synchronized movement between hand robot and virtual hand. © 2017 IEEE.","A/D conversion; Exoskeleton Finger rehabilitation robot; Human-computer interaction; Virtual environment","Analog to digital conversion; Computer programming languages; Data acquisition; Exoskeleton (Robotics); Human robot interaction; Machine design; Medical computing; Patient rehabilitation; Physical therapy; Robots; Virtual reality; A/D conversion; Data acquisition system; Finger rehabilitations; Hand rehabilitation robots; Human-computer interaction system; Rehabilitation training; Single chip microcomputers; Upper-limb rehabilitation; Human computer interaction",2-s2.0-85030309655
"Reger G.","A story of parametric trace slicing, garbage and static analysis",2017,"Electronic Proceedings in Theoretical Computer Science, EPTCS",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030112075&doi=10.4204%2fEPTCS.254.1&partnerID=40&md5=8e063b124f6ee44ec2e468bd57eb9092","This paper presents a proposal (story) of how statically detecting unreachable objects (in Java) could be used to improve a particular runtime verification approach (for Java), namely parametric trace slicing. Monitoring algorithms for parametric trace slicing depend on garbage collection to (i) cleanup data-structures storing monitored objects, ensuring they do not become unmanageably large, and (ii) anticipate the violation of (non-safety) properties that cannot be satisfied as a monitored object can no longer appear later in the trace. The proposal is that both usages can be improved by making the unreachability of monitored objects explicit in the parametric property and statically introducing additional instrumentation points generating related events. The ideas presented in this paper are still exploratory and the intention is to integrate the described techniques into the MarQ monitoring tool for quantified event automata.",,"Java programming language; Garbage collection; IMPROVE-A; Monitoring algorithms; Monitoring tools; Run-time verification; Object detection",2-s2.0-85030112075
"Franzoi L., Sgarro A.","Fuzzy hamming distinguishability",2017,"IEEE International Conference on Fuzzy Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030184614&doi=10.1109%2fFUZZ-IEEE.2017.8015434&partnerID=40&md5=4c82a65dc6a49282fd7fe2b14c0ddce5","Back in 1967 the Croat linguist Ž. Muljačić had used a fuzzy generalization of the Hamming distance between binary strings to classify Romance languages. In 1956 Cl. Shannon had introduced the notion of codeword distinguishability in zero-error information theory. Distance and distinguishability are subtly different notions, even if, with distances as those usually met in coding theory (ruling out zero-error information theory, which is definitely non-metric), the need for string distinguishabilities evaporates, since the distinguishability turns out to be an obvious and trivial function of the distance. Fuzzy Hamming distinguishabilities derived from Muljačić distances, instead, are quite relevant and must be considered explicitly. They are very easy to compute, however, and we show how they could be applied in coding theory to channels with erasures and blurs. Fuzzy Hamming distinguishabilities appear to be quite a promising tool to extend Muljačić approach from linguistic classification to linguistic evolution. © 2017 IEEE.",,"Classification (of information); Codes (symbols); Computer programming; Fuzzy systems; Information theory; Linguistics; Binary string; Coding Theory; Distinguishability; Fuzzy generalizations; Linguistic classification; Romance languages; Trivial functions; Zero error information; Hamming distance",2-s2.0-85030184614
"Lisitsa A.P., Nemytykh A.P.","Verification of programs via intermediate interpretation",2017,"Electronic Proceedings in Theoretical Computer Science, EPTCS",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030103789&doi=10.4204%2fEPTCS.253.6&partnerID=40&md5=62852506e19b8a5af3831eff6438b9eb","We explore an approach to verification of programs via program transformation applied to an interpreter of a programming language. A specialization technique known as Turchin's supercompilation is used to specialize some interpreters with respect to the program models. We show that several safety properties of functional programs modeling a class of cache coherence protocols can be proved by a supercompiler and compare the results with our earlier work on direct verification via supercompilation not using intermediate interpretation. Our approach was in part inspired by an earlier work by E. De Angelis et al. (2014-2015) where verification via program transformation and intermediate interpretation was studied in the context of specialization of constraint logic programs. Keywords: program specialization, supercompilation, program analysis, program transformation, safety verification, cache coherence protocols.",,"Cache memory; Logic programming; Multiprocessing systems; Program interpreters; Cache coherence protocols; Constraint logic programs; Functional programs; Program analysis; Program specialization; Program transformations; Safety property; Safety verification; Program compilers",2-s2.0-85030103789
"Nawaz F., Hussain O.K., Janjua N., Chang E.","A proactive event-driven approach for dynamic QoS compliance in cloud of things",2017,"Proceedings - 2017 IEEE/WIC/ACM International Conference on Web Intelligence, WI 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030973657&doi=10.1145%2f3106426.3109431&partnerID=40&md5=e51ba4fc269cfabe2f6290774725db4e","Cloud-of-Things service providers use various descriptions languages to describe Quality of Service (QoS) attributes. However, existing modelling approaches provide support for modelling static QoS attributes only and lack features to model and reason with dynamic QoS attributes such as response time and availability. This paper presents an event-based approach for monitoring dynamic QoS values and their compliance by modelling the behavior of QoS attributes using an Event Calculus (EC) based framework. The logic based reasoning is then performed to proactively identify the possible QoS violations in future.1. © 2017 ACM.","Cloud of things; Compliance; Quality of service; Service degradation; Service level agreement","Calculations; Logic programming; Telecommunication services; Based reasonings; Compliance; Event calculus; Event-driven approach; QoS attributes; Service degradation; Service Level Agreements; Service provider; Quality of service",2-s2.0-85030973657
"Duarte J.C., Cavalcanti M.C.R., De Souza Costa I., Esteves D.","An interoperable service for the provenance of machine learning experiments",2017,"Proceedings - 2017 IEEE/WIC/ACM International Conference on Web Intelligence, WI 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030994034&doi=10.1145%2f3106426.3106496&partnerID=40&md5=58b8b37b79fbddab7cf1911058abdd7a","Nowadays, despite the fact that Machine Learning (ML) experiments can be easily built using several ML frameworks, as the demand for practical solutions for several kinds of scientific problems is always increasing, organizing its results and the different algorithms' setups used, in order to be able to reproduce them, is a long known problem without an easy solution. Motivated by the need of a high level of interoperability and data provenance with respect to ML experiments, this work presents a generic solution using a web-service application that interacts with the MEX vocabulary, a lightweight solution for archiving and querying ML experiments. By using this solution, researchers can share their setups and results, in a interoperable format that describes all the steps needed to reproduce their research. Although the solution presented in this work could be implemented in any programming language, we chose Java to build the web-service and also we chose to present experiments with Python's Scikit-learn ML Framework, using Decorators and Code Refiection, that demonstrates the simplicity of incorporating data provenance in such a high level, simplifying the experiment logging process. © 2017 ACM.","Data provenance; Interoperability; Machine learning; Mex; Reproducible research","Artificial intelligence; High level languages; Learning systems; Problem oriented languages; Web services; Websites; Data provenance; Generic solutions; Interoperable services; Logging process; Practical solutions; Reproducible research; Web service applications; Interoperability",2-s2.0-85030994034
"Horpácsi D., Koszegi J., Horváth Z.","Trustworthy refactoring via decomposition and schemes: A complex case study",2017,"Electronic Proceedings in Theoretical Computer Science, EPTCS",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030127517&doi=10.4204%2fEPTCS.253.8&partnerID=40&md5=786ce1ca7cd63fe8d9891e07f393d501","Widely used complex code refactoring tools lack a solid reasoning about the correctness of the transformations they implement, whilst interest in proven correct refactoring is ever increasing as only formal verification can provide true confidence in applying tool-automated refactoring to industrialscale code. By using our strategic rewriting based refactoring specification language, we present the decomposition of a complex transformation into smaller steps that can be expressed as instances of refactoring schemes, then we demonstrate the semi-automatic formal verification of the components based on a theoretical understanding of the semantics of the programming language. The extensible and verifiable refactoring definitions can be executed in our interpreter built on top of a static analyser framework.",,"Semantics; Specification languages; Complex codes; Complex transformations; Industrial-scale; Refactorings; Semi-automatics; Formal verification",2-s2.0-85030127517
"Sanchez O., Moyano J.M., Sanchez L., Alcala-Fadez J.","Mining association rules in R using the package RKEEL",2017,"IEEE International Conference on Fuzzy Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030151515&doi=10.1109%2fFUZZ-IEEE.2017.8015572&partnerID=40&md5=e1cf3feff54b20f77e80cd743b3ac995","The discovery of fuzzy associations comprises a collection of data mining methods used to extract knowledge from large data sets. Although there is an extensive catalog of specialized algorithms that cover different aspects of the problem, the most recent approaches are not yet packaged in mainstream software environments. This makes it difficult to incorporate novel association rules methods to the data mining workflow. In this paper an extension of the RKEEL package is described that allows calling from the programming language R to those association rules methods contained in KEEL, which is one of the most comprehensive open source software suites. The potential of the proposed tool is illustrated through a case study comprising seven real-world datasets. © 2017 IEEE.",,"Association rules; Fuzzy systems; Open source software; Open systems; Software engineering; Data mining methods; Data mining workflow; Fuzzy associations; Large datasets; Mining associations; Novel associations; Real-world datasets; Software environments; Data mining",2-s2.0-85030151515
"Kostyukov V.N., Boychenko S.N.","Orthogonal system of fractural and integrated diagnostic features in vibration analysis",2017,"AIP Conference Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028828660&doi=10.1063%2f1.4998907&partnerID=40&md5=e6ea5c2aef49d4092878713641c9e9c2","The paper presents the results obtained in the studies of the orthogonality of the vibration diagnostic features system comprising the integrated features, particularly - root mean square values of vibration acceleration, vibration velocity, vibration displacement and fractal feature (Hurst exponent). To diagnose the condition of the equipment by the vibration signal, the orthogonality of the vibration diagnostic features is important. The fact of orthogonality shows that the system of features is not superfluous and allows the maximum coverage of the state space of the object being diagnosed. This, in turn, increases reliability of the machinery condition monitoring results. The studies were carried out on the models of vibration signals using the programming language R. © 2017 Author(s).",,,2-s2.0-85028828660
"Perrin J.L.","Recognizing connection to nature: Perspectives from the field",2017,"Applied Environmental Education and Communication",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028577184&doi=10.1080%2f1533015X.2017.1348271&partnerID=40&md5=7e8bea0e1398ba6fb251078d7a881d62","The researcher conducted 17 semistructured interviews with environmental education professionals working in the field of nature connection to better understand how practitioners define and measure connection to nature. Participants noted the development of a conservation ethic as the most important indication of connection to nature. Practitioners believed that connection to nature outcomes are overshadowed by funders and school partners' emphasis on science, technology, engineering, and math oriented outcomes and discussed the importance of sharing language consistent connection to nature evaluation tools that could be adapted to their programming. These ideas are discussed as important considerations in advancing the field. © 2017 Taylor & Francis Group, LLC",,,2-s2.0-85028577184
"Jegan R., Nimi W.S.","Low cost and improved performance measures on filtering techniques for ECG signal processing and TCP/IP based monitoring using LabVIEW",2017,"2017 4th International Conference on Advanced Computing and Communication Systems, ICACCS 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030234962&doi=10.1109%2fICACCS.2017.8014582&partnerID=40&md5=58ed8066acb6b3c2a191e9653d5997f5","Sensor based ECG signal acquisition methods are non-invasive method for diagnosing heart related diseases. A noise removal ECG signal provides certain details about the electrical activity of the heart. The main focus of this paper is to identify the suitable filtering method for ECG signal noise removal for physiological parameter measurement and monitoring using TCP/IP Protocol. Feature extraction of ECG signal is an essential in today world to identify the various characteristics parameters on the ECG signal. This paper proposes the software based biomedical signal processing algorithms for successful removal of noises from an ECG signal and monitoring. Noise removal is an essential method for measuring an important vital information and physiological parameters measurement. Here, filtering techniques are used for removing noises in ECG signal and wireless internet protocol is used for signal monitoring. Simulations are carried out using graphical programming environment. The experimental result indicates that the proposed system shows good result for removing the noises and takes reduced time for processing. The implementation and design of proposed method can be done using LabVIEW that utilizes less power and minimized area with reasonable speed. The advantages of the proposed work is very simple, low cost, easy integration with programming environment and gives high signal quality. © 2017 IEEE.","Biosensor; ECG Signal; Filtering; Hardware; LabVIEW; Patients; Software","Bioinformatics; Biosensors; Computer graphics; Computer hardware; Computer programming languages; Computer software; Diagnosis; Electrocardiography; Filtration; Internet protocols; Noninvasive medical procedures; Parameter estimation; Physiological models; Physiology; Signal denoising; Signal processing; Transmission control protocol; Characteristics parameters; ECG signals; Electrical activity of the heart; Graphical programming environment; LabViEW; Patients; Physiological parameter measurement; Physiological parameters; Biomedical signal processing",2-s2.0-85030234962
"Chen L., Zhan W., Fang H., Cao Z., Yuan C., Xie Z., Kuang Q., Zheng L.","Selective Catalytic Performances of Noble Metal Nanoparticle@MOF Composites: The Concomitant Effect of Aperture Size and Structural Flexibility of MOF Matrices",2017,"Chemistry - A European Journal",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026314886&doi=10.1002%2fchem.201702103&partnerID=40&md5=2851967f43a2f51a16373e62a08bd81d","Noble metal nanoparticles embedded in metal–organic frameworks (MOFs) are composite catalysts with enhanced or novel properties compared to the pristine counterparts. In recent years, to determine the role of MOFs during catalytic process, most studies have focussed on the confinement effect of MOFs, but ignored the structural flexibility of MOFs. In this study, we use two composite catalysts, Pt@ZIF-8 [Zn(mIM)2, mIM=2-methyl imidazole] with flexible structure and Pt@ZIF-71 [Zn(DClIM)2, DClIM=4,5-dichloroimidazole] with rigid structure, and hydrogenation of cinnamaldehyde as model reaction, to show the confinement effect and the structure flexibility of MOF matrices on the catalytic performance of composite catalysts. Both catalysts showed high selectivity for cinnamic alcohol with the confinement effect of the aperture. But, compared to Pt@ZIF-71, Pt@ZIF-8 exhibited higher conversion but lower selectivity owing to the flexible structure. The above results remind us that we will have to consider both the aperture size of MOFs and structure flexibility to select the proper MOF matrices for the composite materials to achieve the optimized performance. © 2017 Wiley-VCH Verlag GmbH & Co. KGaA, Weinheim","composite catalysts; heterogeneous catalysis; metal–organic frameworks; selective hydrogenation; structural flexibility","Catalysis; Catalyst selectivity; Catalysts; Crystalline materials; Flexible structures; Hydrogenation; Java programming language; Metals; Nanoparticles; Platinum; Precious metals; Zinc; Catalytic performance; Composite catalysts; Confinement effects; Metal organic framework; Metalorganic frameworks (MOFs); Optimized performance; Selective hydrogenation; Structural flexibilities; Metal nanoparticles",2-s2.0-85026314886
"Fire A., Zhu S.-C.","Inferring Hidden Statuses and Actions in Video by Causal Reasoning",2017,"IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030240387&doi=10.1109%2fCVPRW.2017.13&partnerID=40&md5=21698fd6f2443aeacf11919562d1638c","In the physical world, cause and effect are inseparable: ambient conditions trigger humans to perform actions, thereby driving status changes of objects. In video, these actions and statuses may be hidden due to ambiguity, occlusion, or because they are otherwise unobservable, but humans nevertheless perceive them. In this paper, we extend the Causal And-Or Graph (C-AOG) to a sequential model representing actions and their effects on objects over time, and we build a probability model for it. For inference, we apply a Viterbi algorithm, grounded on probabilistic detections from video, to fill in hidden and misdetected actions and statuses. We analyze our method on a new video dataset that showcases causes and effects. Our results demonstrate the effectiveness of reasoning with causality over time. © 2017 IEEE.",,"C (programming language); Computer vision; Inference engines; Viterbi algorithm; Ambient conditions; Causal reasoning; Cause and effects; Physical world; Probabilistic detections; Probability modeling; Sequential model; Video dataset; Pattern recognition",2-s2.0-85030240387
"Nathan V., Narayana S., Sivaraman A., Goyal P., Arun V., Alizadeh M., Jeyakumar V., Kim C.","Demonstration of the marple system for network performance monitoring",2017,"SIGCOMM Posters and Demos 2017 - Proceedings of the 2017 SIGCOMM Posters and Demos, Part of SIGCOMM 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029720428&doi=10.1145%2f3123878.3131985&partnerID=40&md5=41bcbbb6860a2bb8f8ffd9e930f450e9","We demonstrate Marple [15], a system that allows network operators to measure a wide variety of performance metrics in real time. It consists of a performance query language, Marple, modeled on familiar functional operators like map, filter, and groupby. Marple is supported by a programmable key-value store on switches, which can compute flexible aggregated statistics (e.g., per-flow counts, moving averages over queueing latencies) over packets at line rate. Our switch design implements performance queries which could previously run only on end hosts, while utilizing only a modest fraction of switch hardware resources. To demonstrate the utility of Marple, we compile Marple queries to a P4-programmable software switch running within Mininet. We demonstrate two example use cases of Marple: Diagnosing the root cause of latency spikes and measuring the flowlet size distribution. © 2017 ACM.","Network hardware; Network measurement; Network programming","Hardware; Query languages; Hardware resources; Key-value stores; Network measurement; Network operator; Network performance monitoring; Network programming; Performance metrics; Programmable software; Computer programming",2-s2.0-85029720428
"Wang W., Zhou K.","An extensible NC program interpreter for open CNC systems",2017,"International Journal of Advanced Manufacturing Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027835837&doi=10.1007%2fs00170-017-0974-x&partnerID=40&md5=8800146afd1fc1dc0a55e728568ae493","The NC program interpreter plays an important role in CNC systems. It checks for errors and translates NC programs into commands that can be executed by the CNC control module. NC program specifications differ a lot among different CNC manufacturers. However, the existing NC program interpreters only support one specific program format, which increases the programming difficulty and enterprise cost. Meanwhile, due to the closed interpreter structure, it is difficult to develop and implement new CNC function instructions, which limits the openness of CNC systems. In order to solve these problems, this paper presented a novel analysis of NC language’s grammar, and designed a set of hierarchical and modular Extend Backus-Naur Form (EBNF) expressions to describe NC language. An extensible interpreter based on EBNF was proposed. Through interaction with users to add new instructions, the system can utilize lexical analyzer (Lex) and yet another compiler compiler (Yacc) to generate a new matching interpreter. This method can also help users to produce a matching interpreter for a specific NC program specification. A prototype interpreter was developed successfully, the validity of which was verified by tests. © 2017 Springer-Verlag London Ltd.","EBNF; Extensible; Lex; NC program interpreter; Yacc","Program compilers; Specifications; Compiler-compiler; Control module; EBNF; Extensible; Lexical analyzers; Open CNC systems; Prototype interpreters; Yacc; Program interpreters",2-s2.0-85027835837
"Le X.-B.D., Chu D.-H., Lo D., Le Goues C., Visser W.","S3: Syntax- and semantic-guided repair synthesis via programming by examples",2017,"Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030757304&doi=10.1145%2f3106237.3106309&partnerID=40&md5=abfce350040c37286a28f28f99798ee8","A notable class of techniques for automatic program repair is known as semantics-based. Such techniques, e.g., Angelix, infer semantic specifications via symbolic execution, and then use program synthesis to construct new code that satisfies those inferred specifications. However, the obtained specifications are naturally incomplete, leaving the synthesis engine with a difficult task of synthesizing a general solution from a sparse space of many possible solutions that are consistent with the provided specifications but that do not necessarily generalize. We present S3, a new repair synthesis engine that leverages programming-by-examples methodology to synthesize high-quality bug repairs. The novelty in S3 that allows it to tackle the sparse search space to create more general repairs is three-fold: (1) A systematic way to customize and constrain the syntactic search space via a domain-specific language, (2) An efficient enumerationbased search strategy over the constrained search space, and (3) A number of ranking features based on measures of the syntactic and semantic distances between candidate solutions and the original buggy program.We compare S3's repair effectiveness with state-ofthe- art synthesis engines Angelix, Enumerative, and CVC4. S3 can successfully and correctly fix at least three times more bugs than the best baseline on datasets of 52 bugs in small programs, and 100 bugs in real-world large programs. © 2017 Association for Computing Machinery.","Inductive synthesis; Program repair; Programming by examples; Symbolic execution","Computer programming languages; Engines; Model checking; Problem oriented languages; Repair; Semantics; Software engineering; Specifications; Syntactics; Automatic programs; Domain specific languages; General solutions; Programming by Example; Repair effectiveness; Search strategies; Semantic specification; Symbolic execution; Program debugging",2-s2.0-85030757304
"Gopstein D., Iannacone J., Yan Y., DeLong L., Zhuang Y., Yeh M.K.-C., Cappos J.","Understanding misunderstandings in source code",2017,"Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030755893&doi=10.1145%2f3106237.3106264&partnerID=40&md5=9b346fbb24a7f07743c7fab1f48ddf17","Humans often mistake the meaning of source code, and so misjudge a program's true behavior. These mistakes can be caused by extremely small, isolated patterns in code, which can lead to signiicant runtime errors. These patterns are used in large, popular software projects and even recommended in style guides. To identify code patterns that may confuse programmers we extracted a preliminary set of atoms of confusion' from known confusing code. We show empirically in an experiment with 73 participants that these code patterns can lead to a signiicantly increased rate of misunderstanding versus equivalent code without the patterns. We then go on to take larger confusing programs and measure (in an experiment with 43 participants) the impact, in terms of programmer confusion, of removing these confusing patterns. All of our instruments, analysis code, and data are publicly available online for replication, experimentation, and feedback. © 2017 Copyright held by the owner/author(s).","Program understanding; Programming languages","Computer programming; Computer programming languages; Software engineering; Code-patterns; Equivalent codes; Isolated patterns; Program understanding; Run-time errors; Software project; Source codes; Style guides; Codes (symbols)",2-s2.0-85030755893
"Greenyer J., Gritzner D., König F., Dahlke J., Shi J., Wete E.","From scenario modeling to scenario programming for reactive systems with dynamic topology",2017,"Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030764842&doi=10.1145%2f3106237.3122827&partnerID=40&md5=3ab287bdbf6f7adfa35770c5b825acd8","Software-intensive systems often consist of cooperating reactive components. In mobile and reconfigurable systems, their topology changes at run-time, which influences howthe components must cooperate. The Scenario Modeling Language (SML) offers a formal approach for specifying the reactive behavior such systems that aligns with how humans conceive and communicate behavioral requirements. Simulation and formal checks can find specification flaws early.We present a framework for the Scenario-based Programming (SBP) that reflects the concepts of SML in Java and makes the scenario modeling approach available for programming. SBP code can also be generated from SML and extended with platform-specific code, thus streamlining the transition from design to implementation. As an example serves a car-to-x communication system. Demo video and artifact: http://scenariotools.org/esecfse-2017-tool-demo/ © 2017 Copyright held by the owner/author(s).","Assume/guarantee specifications; Distributed embedded systems; Dynamic topologies; Reactive systems; Scenario-based modeling","Computer software; Embedded systems; Software engineering; Specifications; Structural design; Topology; Car-to-X communications; Distributed embedded system; Dynamic topologies; Reactive system; Reconfigurable systems; Scenario-based modeling; Scenario-based programming; Software intensive systems; Modeling languages",2-s2.0-85030764842
"Hellendoorn V.J., Devanbu P.","Are deep neural networks the best choice for modeling source code?",2017,"Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030762913&doi=10.1145%2f3106237.3106290&partnerID=40&md5=ec2e371cd88f072b7bd7006abe198c18","Current statistical language modeling techniques, including deeplearning based models, have proven to be quite effective for source code. We argue here that the special properties of source code can be exploited for further improvements. In this work, we enhance established language modeling approaches to handle the special challenges of modeling source code, such as: frequent changes, larger, changing vocabularies, deeply nested scopes, etc.We present a fast, nested language modeling toolkit specifically designed for software, with the ability to add & remove text, and mix & swap out many models. Specifically, we improve upon prior cache-modeling work and present a model with a much more expansive, multi-level notion of locality that we show to be well-suited for modeling software. We present results on varying corpora in comparison with traditional N-gram, as well as RNN, and LSTM deep-learning language models, and release all our source code for public use. Our evaluations suggest that carefully adapting N-gram models for source code can yield performance that surpasses even RNN and LSTM based deep-learning models. © 2017 Copyright held by the owner/author(s).","Language models; Naturalness; Software tools","Codes (symbols); Computational linguistics; Computer aided software engineering; Computer programming languages; Deep learning; Deep neural networks; Natural language processing systems; Network coding; Software engineering; Cache modeling; Language model; Learning languages; Learning models; Modeling softwares; Naturalness; Special properties; Statistical language modeling; Modeling languages",2-s2.0-85030762913
"D'Antoni L., Singh R., Vaughn M.","NoFAQ: Synthesizing command repairs from examples",2017,"Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030779381&doi=10.1145%2f3106237.3106241&partnerID=40&md5=d88c0cefc995e65243cedba1951f22a5","Command-line tools are confusing and hard to use due to their cryptic error messages and lack of documentation. Novice users often resort to online help-forums for finding corrections to their buggy commands, but have a hard time in searching precisely for posts that are relevant to their problem and then applying the suggested solutions to their buggy command. We present NoFAQ, a tool that uses a set of rules to suggest possible fixes when users write buggy commands that trigger commonly occurring errors. The rules are expressed in a language called Fixit and each rule pattern-matches against the user's buggy command and corresponding error message, and uses these inputs to produce a possible fixed command. NoFAQ automatically learns Fixit rules from examples of buggy and repaired commands. We evaluate NoFAQ on two fronts. First, we use 92 benchmark problems drawn from an existing tool and show that NoFAQ is able to synthesize rules for 81 benchmark problems in real time using just 2 to 5 input-output examples for each rule. Second, we run our learning algorithm on the examples obtained through a crowd-sourcing interface and show that the learning algorithm scales to large sets of examples. © 2017 Copyright held by the owner/author(s).","Command line interface; Domain specific languages; Program repair; Program synthesis; Programming by example","Benchmarking; Computer programming languages; Errors; Learning algorithms; Problem oriented languages; Bench-mark problems; Command line interface; Domain specific languages; Error messages; Input-output; Program synthesis; Programming by Example; Set of rules; Software engineering",2-s2.0-85030779381
"Hinkel G., Burger E.","Change propagation and bidirectionality in internal transformation DSLs",2017,"Software and Systems Modeling",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027994480&doi=10.1007%2fs10270-017-0617-6&partnerID=40&md5=89e1ff88d04ce0fd90412bcaea01c421","Despite good results in several industrial projects, model-driven engineering (MDE) has not been widely adopted in industry. Although MDE has existed for more than a decade now, the lack of tool support is still one of the major problems, according to studies by Staron and Mohaghegi (Staron, in: Model driven engineering languages and systems, Springer, Berlin, 2006; Mohagheghi et al. in Empir Softw Eng 18(1):89–116, 2013). Internal languages offer a solution to this problem for model transformations, which are a key part of MDE. Developers can use existing tools of host languages to create model transformations in a familiar environment. These internal languages, however, typically lack key features such as change propagation or bidirectional transformations. In our opinion, one reason is that existing formalisms for these properties are not well suited for textual languages. In this paper, we present a new formalism describing incremental, bidirectional model synchronizations using synchronization blocks. We prove the ability of this formalism to detect and repair inconsistencies and show its hippocraticness. We use this formalism to create a single internal model transformation language for unidirectional and bidirectional model transformations with optional change propagation. In total, we currently provide 18 operation modes based on a single specification. At the same time, the language may reuse tool support for C#. We validate the applicability of our language using a synthetic example with a transformation from finite state machines to Petri nets where we achieved speedups of up to multiple orders of magnitude compared to classical batch transformations. © 2017 Springer-Verlag GmbH Germany","Bidirectional; Change propagation; Domain-specific language; Incremental; Model synchronization; Model-driven engineering","Computer programming languages; Digital subscriber lines; Petri nets; Problem oriented languages; Bidirectional; Change propagation; Domain specific languages; Incremental; Model synchronization; Model-driven Engineering; Synchronization",2-s2.0-85027994480
"Van Dijk R., Creeten C., Van Der Ham J., Van Den Bos J.","Model-driven software engineering in practice: Privacy-enhanced filtering of network traffic",2017,"Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030763813&doi=10.1145%2f3106237.3117777&partnerID=40&md5=80551a3852a17a8ceb2e0de9aef78e98","Network traffic data contains a wealth of information for use in security analysis and application development. Unfortunately, it also usually contains confidential or otherwise sensitive information, prohibiting sharing and analysis. Existing automated anonymization solutions are hard to maintain and tend to be outdated. We present Privacy-Enhanced Filtering (PEF), a model-driven prototype framework that relies on declarative descriptions of protocols and a set of filter rules, which are used to automatically transform network traffic data to remove sensitive information. This paper discusses the design, implementation and application of PEF, which is available as open-source software and configured for use in a typical malware detection scenario. © 2017 Copyright held by the owner/author(s).","Domain-specific languages; Model-driven engineering; Open-source prototype; Privacy-enhancing technology","Application programs; Computer programming languages; Data privacy; Information filtering; Open systems; Problem oriented languages; Software engineering; XML; Application development; Declarative descriptions; Domain specific languages; Model driven software engineering; Model-driven Engineering; Open sources; Privacy enhancing technologies; Sensitive informations; Open source software",2-s2.0-85030763813
"Lei Q., Meijer J., Wisse M.","Fast C-shape grasping for unknown objects",2017,"IEEE/ASME International Conference on Advanced Intelligent Mechatronics, AIM",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028771287&doi=10.1109%2fAIM.2017.8014068&partnerID=40&md5=01057d4c14caf295c04ef57f784ca9fe","Grasping of unknown objects with neither appearance data nor object models given in advance is very important for robots that work in an unfamiliar environment. In this paper, we propose an original fast grasping algorithm for unknown objects. The geometry of the under-actuated gripper is approximated as a C-shape, which is used to fit the point cloud of the target object to find a suitable grasp. In order to make the robot arm quickly execute the grasp found by the grasping algorithm, we made a comparison of the popular online motion planners. The motion planner with the highest solved runs, lowest computing time and the shortest path length is chosen to execute the grasp action. Simulations and experiments on a UR5 robot arm and an under-actuated gripper are used to examine the performance of the grasping algorithm, and successful results are obtained. © 2017 IEEE.",,"Grippers; Intelligent mechatronics; Motion planning; Robot programming; Robotic arms; Robots; Computing time; Grasping of unknown object; Motion planners; Object model; Shortest path; Target object; Underactuated; Unknown objects; C (programming language)",2-s2.0-85028771287
"García J., Garcés K.","Improving understanding of dynamically typed software developed by agile practitioners",2017,"Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030774723&doi=10.1145%2f3106237.3117772&partnerID=40&md5=bcaf2901c2d850e3ded130a7745aef1b","Agile Development values working software over documentation. Therefore, in maintenance stages of existing software, the source code is the sole software artifact that developers have for analyzing the viability and impact of a new user story. Since functionality is often spread in hundreds of lines of code, it is hard for the developer to understand the system, which may lead to under-/overestimation of the new feature cost and rework/delays in the subsequent phases of development. In a previous work, we proposed a Model-Driven Reverse Engineering approach for obtaining software visualizations from source code. Two case studies of comprehension of applications written in statically typed languages have shown the applicability of this approach. A recent experience with an industrial partner, where the systems are developed on dynamically typed languages, has motivated us to adapt the previous proposal to take as input not only the source code but also the application data schema to complete the information that is missing in the code, and then automatically generate more meaningful diagrams that help developers in maintenance tasks. In this article, we present the adaptation of the general approach to support data schema as an additional input and its instrumentation in an industrial case study where the technology is Ruby on Rails. The paper ends by explaining the precision and performance of the instrumentation when used in a Colombian company as well as lessons learned. © 2017 Association for Computing Machinery.","Model Transformation Grammars; Model-Driven Reverse Engineering; Ruby On Rails; Software visualization; Xtext","Agile manufacturing systems; Codes (symbols); Computer programming languages; Reverse engineering; Ruby; Visualization; Model transformation; Model-driven; Ruby on Rails; Software visualization; Xtext; Software engineering",2-s2.0-85030774723
"Tian Y., Ray B.","Automatically diagnosing and repairing error handling bugs in C",2017,"Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030749258&doi=10.1145%2f3106237.3106300&partnerID=40&md5=b3f75683d823d2dbab995a041554bf75","Correct error handling is essential for building reliable and secure systems. Unfortunately, low-level languages like C often do not support any error handling primitives and leave it up to the developers to create their own mechanisms for error propagation and handling. However, in practice, the developers often make mistakes while writing the repetitive and tedious error handling code and inadvertently introduce bugs. Such error handling bugs often have severe consequences undermining the security and reliability of the affected systems. Fixing these bugs is also tiring-they are repetitive and cumbersome to implement. Therefore, it is crucial to develop tool supports for automatically detecting and fixing error handling bugs. To understand the nature of error handling bugs that occur in widely used C programs, we conduct a comprehensive study of real world error handling bugs and their fixes. Leveraging the knowledge, we then design, implement, and evaluate ErrDoc, a tool that not only detects and characterizes different types of error handling bugs but also automatically fixes them. Our evaluation on five open-source projects shows that ErrDoc can detect error handling bugs with 100% to 84% precision and around 95% recall, and categorize them with 83% to 96% precision and above 90% recall. Thus, ErrDoc improves precision up to 5 percentage points, and recall up to 44 percentage points w.r.t. the state-of-the-art. We also demonstrate that ErrDoc can fix the bugs with high accuracy. © 2017 Association for Computing Machinery.","API errors; Bug detection; Bug fix; Error handling bugs","C (programming language); Errors; Knowledge management; Open source software; Software engineering; Bug detection; Bug fixes; Error handling; Error handling codes; Error propagation; Open source projects; Percentage points; Security and reliabilities; Program debugging",2-s2.0-85030749258
"Böhme M., Soremekun E.O., Chattopadhyay S., Ugherughe E., Zeller A.","Where is the bug and how is it fixed? An experiment with practitioners",2017,"Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030765884&doi=10.1145%2f3106237.3106255&partnerID=40&md5=3557b0bfc6a9fe3e1ce33ff096acaa59","Research has produced many approaches to automatically locate, explain, and repair software bugs. But do these approaches relate to the way practitioners actually locate, understand, and fix bugs? To help answer this question, we have collected a dataset named DBG Bench-the correct fault locations, bug diagnoses, and software patches of 27 real errors in open-source C projects that were consolidated from hundreds of debugging sessions of professional software engineers. Moreover, we shed light on the entire debugging process, from constructing a hypothesis to submitting a patch, and how debugging time, difficulty, and strategies vary across practitioners and types of errors. Most notably, DBG Bench can serve as reality check for novel automated debugging and repair techniques. © 2017 Copyright held by the owner/author(s).","Debugging in practice; Evaluation; User as tool benchmark; User study","C (programming language); Open source software; Open systems; Program diagnostics; Repair; Software engineering; Automated debugging; Debugging process; Debugging-time; Evaluation; Professional software engineers; Repair techniques; Software patches; User study; Program debugging",2-s2.0-85030765884
"Yu H., Chen Z., Zhang Y., Wang J., Dong W.","RGSE: A regular property guided symbolic executor for Java",2017,"Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030766569&doi=10.1145%2f3106237.3122830&partnerID=40&md5=ac3d86783efa6826f15d911b2595858b","It is challenging to effectively check a regular property of a program. This paper presents RGSE, a regular property guided dynamic symbolic execution (DSE) engine, for finding a program path satisfying a regular property as soon as possible. The key idea is to evaluate the candidate branches based on the history and future information, and explore the branches along which the paths are more likely to satisfy the property in priority.We have applied RGSE to 16 real-world open source Java programs, totaling 270K lines of code. Compared with the state-of-the-art, RGSE achieves two orders of magnitude speedups for finding the first target path. RGSE can benefit many research topics of software testing and analysis, such as path-oriented test case generation, typestate bug finding, and performance tuning. The demo video is at: https://youtu.be/7zAhvRIdaUU, and RGSE can be accessed at: http://jrgse.github.io. © 2017 Association for Computing Machinery.","Dynamic symbolic execution; Regular property; RGSE","Computer software; Model checking; Open source software; Open systems; Software engineering; Software testing; Dynamic symbolic executions; History and future; Orders of magnitude; Performance tuning; Regular properties; RGSE; Software testing and analysis; Test case generation; Java programming language",2-s2.0-85030766569
"Kusano M., Wang C.","Thread-modular static analysis for relaxed memory models",2017,"Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030789446&doi=10.1145%2f3106237.3106243&partnerID=40&md5=8e8860ce661fbd530c4b471a222d86bc","We propose a memory-model-aware static program analysis method for accurately analyzing the behavior of concurrent software running on processors with weak consistency models such as x86-TSO, SPARC-PSO, and SPARC-RMO. At the center of our method is a unified framework for deciding the feasibility of inter-thread interferences to avoid propagating spurious data flows during static analysis and thus boost the performance of the static analyzer. We formulate the checking of interference feasibility as a set of Datalog rules which are both efficiently solvable and general enough to capture a range of hardware-level memory models. Compared to existing techniques, our method can significantly reduce the number of bogus alarms as well as unsound proofs. We implemented the method and evaluated it on a large set of multithreaded C programs. Our experiments showthe method significantly outperforms state-of-the-art techniques in terms of accuracy with only moderate runtime overhead. © 2017 Association for Computing Machinery.","Abstract interpretation; Concurrency; Datalog; PSO; Relaxed memory model; RMO; Thread-modular reasoning; TSO","C (programming language); Data flow analysis; Program processors; Software engineering; Abstract interpretations; Concurrency; Datalog; Modular reasoning; Relaxed memory models; Static analysis",2-s2.0-85030789446
"Labuschagne A., Inozemtseva L., Holmes R.","Measuring the cost of regression testing in practice: A study of Java projects using continuous integration",2017,"Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030776060&doi=10.1145%2f3106237.3106288&partnerID=40&md5=9343bac1c2e39399776b1af548f8a94f","Software defects cost time and money to diagnose and fix. Conse- quently, developers use a variety of techniques to avoid introduc- ing defects into their systems. These techniques have their own costs: the benefit of using a technique must outweigh the cost of using it. In this paper we investigate the costs and benefits of automated regression testing in practice. Specifically, we studied 61 projects that use Travis CI, a cloud-based continuous integration tool, in order to examine real test failures that were encountered by the de- velopers of those projects.We determined howdevelopers resolved the failures they encountered and used this to classify the failures as being caused by a flaky test, by a bug in the system under test, or by a broken or obsolete test. We consider test failures caused by bugs represent a benefit of the suite, while failures caused by broken or obsolete tests represent test suite maintenance costs. We found that 18% of test suite executions fail and that 13% of these failures are flaky. Of the non-flaky failures, only 74% were caused by a bug in the system under test; the remaining 26% were due to incorrect or obsolete tests. In addition, we found that, in the failed builds, only 0.38% of the test case executions failed and 64% of failed builds contained more than one failed test. Our findings contribute to a wider understanding of the unfore- seen costs that can impact the overall cost effectiveness of regres- sion testing in practice. They can also inform research into test case selection techniques, as we have provided an approximate empiri- cal bound on the practical value that could be extracted from such techniques. This appears to be large, as over 99% of the test case executions could have been eliminated with a perfect oracle. © 2017 Copyright held by the owner/author(s).","Flaky tests; Regression testing; Test economics","Cost effectiveness; Costs; Defects; Java programming language; Regression analysis; Safety engineering; Software engineering; Software testing; Automated regression testing; Continuous integrations; Costs and benefits; Maintenance cost; Regression testing; Software defects; System under test; Test case selection; Integration testing",2-s2.0-85030776060
"Kögel S.","Recommender system for model driven software development",2017,"Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030768868&doi=10.1145%2f3106237.3119874&partnerID=40&md5=15d200b536b52a52fe24dd3ed3f6d97f","Models are key artifacts in model driven software engineering, similar to source code in traditional software engineering. Integrated development environments help users while writing source code, e.g. with typed auto completions, quick fixes, or automatic refactorings. Similar integrated features are rare for modeling IDEs. The above source code IDE features can be seen as a recommender system. A recommender system for model driven software engineering can combine data from different sources in order to infer a list of relevant and actionable model changes in real time. These recommendations can speed up working on models by automating repetitive tasks and preventing errors when the changes are atypical for the changed models. Recommendations can be based on common model transformations that are taken from the literature or learned from models in version control systems. Further information can be taken from instance- to meta-model relationships, modeling related artifacts (e.g. correctness constraints), and versions histories of models under version control. We created a prototype recommender that analyses the change history of a single model. We computed its accuracy via crossvalidation and found that it was between 0.43 and 0.82 for models from an open source project. In order to have a bigger data set for the evaluation and the learning of model transformation, we also mined repositories from Eclipse projects for Ecore meta models and their versions.We found 4374 meta models with 17249 versions. 244 of these meta models were changed at least ten times and are candidates for learning common model transformations. We plan to evaluate our recommender system in two ways: (1) In off-line evaluations with data sets of models from the literature, created by us, or taken from industry partners. (2) In on-line user studies with participants from academia and industry, performed as case studies and controlled experiments. © 2017 Association for Computing Machinery.","Data mining; Heuristic search algorithms; Machine learning; Model driven software engineering; Recommender system","Codes (symbols); Computer programming languages; Data mining; Engineering education; Heuristic algorithms; Information management; Learning systems; Metadata; Open source software; Search engines; Software design; Software engineering; Controlled experiment; Heuristic search algorithms; Integrated development environment; Model driven software engineering; Model transformation; Model-Driven Software Development; Open source projects; Version control system; Recommender systems",2-s2.0-85030768868
"Wang S., Nam J., Tan L.","QTEP: Quality-aware test case prioritization",2017,"Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030769956&doi=10.1145%2f3106237.3106258&partnerID=40&md5=4ec0ec5dfc5966f44144e73a76182543","Test case prioritization (TCP) is a practical activity in software testing for exposing faults earlier. Researchers have proposed many TCP techniques to reorder test cases. Among them, coverage-based TCPs have been widely investigated. Specifically, coverage-based TCP approaches leverage coverage information between source code and test cases, i.e., static code coverage and dynamic code coverage, to schedule test cases. Existing coverage-based TCP techniques mainly focus on maximizing coverage while often do not consider the likely distribution of faults in source code. However, software faults are not often equally distributed in source code, e.g., around 80% faults are located in about 20% source code. Intuitively, test cases that cover the faulty source code should have higher priorities, since they are more likely to find faults. In this paper, we present a quality-aware test case prioritization technique, QTEP, to address the limitation of existing coveragebased TCP algorithms. In QTEP, we leverage code inspection techniques, i.e., a typical statistic defect prediction model and a typical static bug finder, to detect fault-prone source code and then adapt existing coverage-based TCP algorithms by considering the weighted source code in terms of fault-proneness. Our evaluation with 16 variant QTEP techniques on 33 different versions of 7 open source Java projects shows that QTEP could improve existing coverage-based TCP techniques for both regression and new test cases. Specifically, the improvement of the best variant of QTEP for regression test cases could be up to 15.0% and on average 7.6%, and for all test cases (both regression and new test cases), the improvement could be up to 10.0% and on average 5.0%. © 2017 Association for Computing Machinery.",,"Codes (symbols); Computer programming languages; Open source software; Regression analysis; Software engineering; Testing; Transmission control protocol; Code coverage; Code inspections; Defect prediction models; Fault proneness; Open sources; Regression tests; Software fault; Test case prioritization; Software testing",2-s2.0-85030769956
"Vasic M., Parvez Z., Milicevic A., Gligoric M.","File-level vs. module-level regression test selection for .NET",2017,"Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030772975&doi=10.1145%2f3106237.3117763&partnerID=40&md5=747e54d238c1575068db5b5ba6a764cd","Regression testing is used to check the correctness of evolving software. With the adoption of Agile development methodology, the number of tests and software revisions has dramatically increased, and hence has the cost of regression testing. Researchers proposed regression test selection (RTS) techniques that optimize regression testing by skipping tests that are not impacted by recent program changes. Ekstazi is one such state-of-the art technique; Ekstazi is implemented for the Java programming language and has been adopted by several companies and open-source projects. We report on our experience implementing and evaluating Ekstazi#, an Ekstazi-like tool for .NET.We describe the key challenges of bringing the Ekstazi idea to the .NET platform. We evaluate Ekstazi# on 11 open-source projects, as well as an internal Microsoft project substantially larger than each of the open-source projects. Finally, we compare Ekstazi# to an incremental build system (also developed at Microsoft), which, out of the box, provides module-level dependency tracking and skipping tasks (including test execution) whenever dependencies of a task do not change between the current and the last successful build. Ekstazi# on average reduced regression testing time by 43.70% for the open-source projects and by 65.26% for the Microsoft project (the latter is in addition to the savings provided by incremental builds). © 2017 Association for Computing Machinery.","Ekstazi; File-level dependencies; Regression test selection","Computer programming; Open source software; Regression analysis; Software engineering; Testing; Agile development methodologies; Dependency tracking; Ekstazi; File levels; Open source projects; Regression test selection; Regression testing; State-of-the-art techniques; Software testing",2-s2.0-85030772975
"Celik A., Vasic M., Milicevic A., Gligoric M.","Regression test selection across JVM boundaries",2017,"Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030784137&doi=10.1145%2f3106237.3106297&partnerID=40&md5=686a0699d1a765cbfe7a3d3048ab8cf9","Modern software development processes recommend that changes be integrated into the main development line of a project multiple times a day. Before a new revision may be integrated, developers practice regression testing to ensure that the latest changes do not break any previously established functionality. The cost of regression testing is high, due to an increase in the number of revisions that are introduced per day, as well as the number of tests developers write per revision. Regression test selection (RTS) optimizes regression testing by skipping tests that are not affected by recent project changes. Existing dynamic RTS techniques support only projects written in a single programming language, which is unfortunate knowing that an open-source project is on average written in several programming languages. We present the first dynamic RTS technique that does not stop at predefined language boundaries. Our technique dynamically detects, at the operating system level, all file artifacts a test depends on. Our technique is, hence, oblivious to the specific means the test uses to actually access the files: be it through spawning a new process, invoking a system call, invoking a library written in a different language, invoking a library that spawns a process which makes a system call, etc. We also provide a set of extension points which allow for a smooth integration with testing frameworks and build systems. We implemented our technique in a tool called RTSLinux as a loadable Linux kernel module and evaluated it on 21 Java projects that escape the JVM by spawning new processes or invoking native code, totaling 2, 050, 791 lines of code. Our results show that RTSLinux, on average, skips 74.17% of tests and saves 52.83% of test execution time compared to executing all tests. © 2017 Association for Computing Machinery.","Language-agnostic; Regression test selection","Computer operating systems; Open source software; Regression analysis; Software design; Software engineering; Software testing; Extension points; Language boundaries; Language-agnostic; Open source projects; Regression test selection; Regression testing; Software development process; Testing framework; Integration testing",2-s2.0-85030784137
"Linares-Vásquez M., Bavota G., Tufano M., Moran K., Di Penta M., Vendome C., Bernal-Cárdenas C., Poshyvanyk D.","Enabling mutation testing for android apps",2017,"Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030749013&doi=10.1145%2f3106237.3106275&partnerID=40&md5=a48be7fac01324f8f0dbab459c898874","Mutation testing has been widely used to assess the fault-detection effectiveness of a test suite, as well as to guide test case generation or prioritization. Empirical studies have shown that, while mutants are generally representative of real faults, an effective application of mutation testing requires ""traditional"" operators designed for programming languages to be augmented with operators specific to an application domain and/or technology. This paper proposes MDroid+, a framework for effective mutation testing of Android apps. First, we systematically devise a taxonomy of 262 types of Android faults grouped in 14 categories by manually analyzing 2, 023 software artifacts from different sources (e.g., bug reports, commits). Then, we identified a set of 38 mutation operators, and implemented an infrastructure to automatically seed mutations in Android apps with 35 of the identified operators. The taxonomy and the proposed operators have been evaluated in terms of stillborn/trivial mutants generated and their capacity to represent real faults in Android apps, as compared to other well know mutation tools. © 2017 Association for Computing Machinery.","Android; Fault taxonomy; Mutation testing; Operators","Fault detection; Mathematical operators; Software engineering; Software testing; Taxonomies; Android; Empirical studies; Fault detection effectiveness; Fault taxonomies; Mutation operators; Mutation testing; Software artifacts; Test case generation; Android (operating system)",2-s2.0-85030749013
"Suderman R., Hlavacek W.S.","Truml: A translator for rule-based modeling languages",2017,"ACM-BCB 2017 - Proceedings of the 8th ACM International Conference on Bioinformatics, Computational Biology, and Health Informatics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031320217&doi=10.1145%2f3107411.3107471&partnerID=40&md5=3f5d1a5f2a3ecdb4fe9dacf52dcbe962","Rule-based modeling languages, such as the Kappa and BioNetGen languages (BNGL), are powerful frameworks for modeling the dynamics of complex biochemical reaction networks. Each language is distributed with a distinct software suite and modelers may wish to take advantage of both toolsets. This paper introduces a practical application called TRuML that translates models written in either Kappa or BNGL into the other language. While similar in many respects, key differences between the two languages makes translation sufficiently complex that automation becomes a useful tool. TRuML accommodates the languages' complexities and produces a semantically equivalent model in the alternate language of the input model when possible and an approximate model in certain other cases. Here, we discuss a number of these complexities and provide examples of equivalent models in both Kappa and BNGL. © 2017 ACM.","BNGL; Domain-specific languages; Kappa; Reaction network modeling; Rule-based modeling; Systems biology","Bioinformatics; Biology; Complex networks; Computer programming languages; Problem oriented languages; Translation (languages); BNGL; Domain specific languages; Kappa; Reaction network model; Rule-based models; Systems biology; Modeling languages",2-s2.0-85031320217
"Dantas B., Forja J., Fleitas C., Francisco A.P., Vaz C., Almeida A., Simão J.","NGSPipes: Fostering reproducibility and scalability in biosciences",2017,"ACM-BCB 2017 - Proceedings of the 8th ACM International Conference on Bioinformatics, Computational Biology, and Health Informatics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031324071&doi=10.1145%2f3107411.3108213&partnerID=40&md5=e30350822bdcb8eba22742819150ec62","Biosciences have been revolutionised by NGS technologies in last years, leading to new perspectives in medical, industrial and environmental applications. And although our motivation comes from biosciences, the following is true for many areas of science: published results are usually hard to reproduce, delaying the adoption of new methodologies and hindering innovation. Even if data and tools are freely available, pipelines for data analysis are in general barely described and their setup is far from trivial. NGSPipes addresses these issues reducing the efforts necessary to define, build and deploy pipelines, either at a local workstation or in the cloud. NGSPipes framework is freely available at http://ngspipes.github.io/. © 2017 Copyright held by the owner/author(s).","Decentralised computing; Domain specific languages; Reproducible science; Scientific workflows","Computer programming languages; Environmental technology; Pipelines; Problem oriented languages; Decentralised; Domain specific languages; Environmental applications; Reproducibilities; Reproducible science; Scientific workflows; Bioinformatics",2-s2.0-85031324071
"Bertacchini F., Bilotta E., Pantano P.","Discovery of regular domains in large DNA data sets",2017,"ACM-BCB 2017 - Proceedings of the 8th ACM International Conference on Bioinformatics, Computational Biology, and Health Informatics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031330966&doi=10.1145%2f3107411.3110419&partnerID=40&md5=aa558164db3bbdd573387b80f402d055","To analyze1 large DNA data sets, we hypothesized that the organization of repeated bases within DNA follows rules similar to Cellular Automata (CA). These sequences could be defined as regular domains. By considering DNA strings as a finite onedimensional cell automated, consisting of a finite (numerable) set of cells spatially aligned on a straight line and adopting a color code that transforms the DNA bases (A, C, T, G) in numbers, we analyzed DNA strings in the approach of computational mechanics. In this approach, a regular domain is a space-time region consisting of sequences in the same regular language (the particular rule of system evolution, which gives rise to a formal language) that creates patterns computationally homogeneous and simple to describe. We discovered that regular domain exists. Results revealed the exact number of strings of given lengths, establishing their limit in length, their precise localizations in all the human chromosomes and their complex numerical organization. Furthermore, the distribution of these domains is not at random, nor chaotic neither probabilistic, but there are numeric attractors around which the number of these domains are distributed. This leads us to think that all these domains within the DNA are connected to each other and cannot be casually distributed, but they follow some combinatorics rules. © 2017 Association for Computing Machinery.","Cellular Automata; DNA automatic segmentation; DNA regular domains","Bioinformatics; Biology; C (programming language); Cellular automata; Chromosomes; Computational mechanics; DNA; Formal languages; Probability distributions; Automatic segmentations; Combinatorics; DNA basis; DNA data sets; DNA strings; Human chromosomes; Space-time region; System evolution; Gene encoding",2-s2.0-85031330966
"Ramohlola K.E., Masikini M., Mdluli S.B., Monama G.R., Hato M.J., Molapo K.M., Iwuoha E.I., Modibane K.D.","Electrocatalytic Hydrogen Evolution Reaction of Metal Organic Frameworks decorated with poly (3-aminobenzoic acid)",2017,"Electrochimica Acta",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021720645&doi=10.1016%2fj.electacta.2017.06.165&partnerID=40&md5=6aff480dbdfffbc99fdb47a8c86d3a3b","Advanced materials for hydrogen evolution reaction are central to the area of renewable energy. Here, we developed a solvothermal synthesis of metal organic framework (MOF) nanoparticles decorated with poly (3-aminobenzoic acid) (PABA) referred as MOF-3.6 wt.%-PABA and MOF–5 wt.%-PABA composites. The parent material (MOF) and composites were characterized by ultraviolet visible (UV-vis) and Fourier transform infrared (FTIR) spectroscopy, powder X-ray diffraction (XRD), thermogravimetric analysis (TGA), scanning electron microscope (SEM), transmission electron microscope (TEM), energy dispersive X-ray spectroscopy (EDS, EDX), selected area electron diffraction (SAED) and cyclic voltammetry (CV). Detailed structural and morphological characterizations established that PABA interacts with MOF on the external surface as observed by appearance of rough surface of the composites. The XRD and SAED showed that MOF and composites are crystalline and the presence of PABA did not alter the crystallinity of the material. Experiments probing the thermal, electrochemical and photophysical properties revealed that the composites were very stable and robust and had exceptionally properties. Significant hydrogen evolution reaction (HER) using CV and Tafel plots, was generated by MOF and composites in dimethyl sulfoxide/tetrabutylammonium perchlorate (DMSO/TBAP) supporting electrolyte in the presence of hydrogen source by applying a negative potential to the electrode. © 2017 Elsevier Ltd","electrocatalytic hydrogen evolution reaction; electrochemistry; Metal organic frameworks; poly(3-amino benzoic acid); Tafel plots","Amino acids; Benzoic acid; Characterization; Cyclic voltammetry; Electrocatalysis; Electrochemistry; Electrolytes; Electron diffraction; Fourier transform infrared spectroscopy; Hydrogen; Inorganic compounds; Metal nanoparticles; Organic polymers; Organometallics; Scanning electron microscopy; Synthesis (chemical); Thermogravimetric analysis; Transmission electron microscopy; X ray diffraction; X ray spectroscopy; Energy dispersive X ray spectroscopy; Hydrogen evolution reactions; Metal organic framework; Morphological characterization; poly(3-amino benzoic acid); Powder X ray diffraction; Selected area electron diffraction; Tafel plots; Java programming language",2-s2.0-85021720645
"Malik L., Patro R.","Rich chromatin structure prediction from Hi-C data",2017,"ACM-BCB 2017 - Proceedings of the 8th ACM International Conference on Bioinformatics, Computational Biology, and Health Informatics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031319850&doi=10.1145%2f3107411.3107448&partnerID=40&md5=f6bd39daf8fc8c802acc9d88cecaeea0","Recent studies involving the 3-dimensional conformation of chromatin have revealed the important role it has to play in different processes within the cell. These studies have also led to the discovery of densely interacting segments of the chromosome, called topologically associating domains. The accurate identification of these domains from Hi-C interaction data is an interesting and important computational problem for which numerous methods have been proposed. Unfortunately, most existing algorithms designed to identify these domains assume that they are non-overlapping whereas there is substantial evidence to believe a nested structure exists. We present an efficient methodology to predict hierarchical chromatin domains using chromatin conformation capture data. Our method predicts domains at different resolutions, calculated using intrinsic properties of the chromatin data, and efficiently clusters these to construct the hierarchy. At each individual level, the domains are non-overlapping in such a way that the intra-domain interaction frequencies are maximized. We show that our predicted structure is highly enriched for actively transcribing housekeeping genes and various chromatin markers, including CTCF, around the domain boundaries. We also show that large-scale domains, at multiple resolutions within our hierarchy, are conserved across cell types and species. Apart from these, our tool is robust and highly efficient, taking only a few minutes to process each dataset. Our software, Matryoshka, is written in C++11 and licensed under GPL v3; it is available at https://github.com/COMBINE-lab/matryoshka. © 2017 Copyright held by the owner/author(s).","Chromatin conformation; Hi-C; Hierarchy; Topologically associating domains","Bioinformatics; Chromosomes; Topology; Chromatin structure; Computational problem; Different resolutions; Hierarchy; Housekeeping gene; Intra-domain interactions; Intrinsic property; Multiple resolutions; C (programming language)",2-s2.0-85031319850
"Shkurin A., Vellido A.","Using random forests for assistance in the curation of G-protein coupled receptor databases",2017,"BioMedical Engineering Online",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027698382&doi=10.1186%2fs12938-017-0357-4&partnerID=40&md5=aedb7abaf8c8394efa48ca0c2f0d699d","Background: Biology is experiencing a gradual but fast transformation from a laboratory-centred science towards a data-centred one. As such, it requires robust data engineering and the use of quantitative data analysis methods as part of database curation. This paper focuses on G protein-coupled receptors, a large and heterogeneous super-family of cell membrane proteins of interest to biology in general. One of its families, Class C, is of particular interest to pharmacology and drug design. This family is quite heterogeneous on its own, and the discrimination of its several sub-families is a challenging problem. In the absence of known crystal structure, such discrimination must rely on their primary amino acid sequences. Methods: We are interested not as much in achieving maximum sub-family discrimination accuracy using quantitative methods, but in exploring sequence misclassification behavior. Specifically, we are interested in isolating those sequences showing consistent misclassification, that is, sequences that are very often misclassified and almost always to the same wrong sub-family. Random forests are used for this analysis due to their ensemble nature, which makes them naturally suited to gauge the consistency of misclassification. This consistency is here defined through the voting scheme of their base tree classifiers. Results: Detailed consistency results for the random forest ensemble classification were obtained for all receptors and for all data transformations of their unaligned primary sequences. Shortlists of the most consistently misclassified receptors for each subfamily and transformation, as well as an overall shortlist including those cases that were consistently misclassified across transformations, were obtained. The latter should be referred to experts for further investigation as a data curation task. Conclusion: The automatic discrimination of the Class C sub-families of G protein-coupled receptors from their unaligned primary sequences shows clear limits. This study has investigated in some detail the consistency of their misclassification using random forest ensemble classifiers. Different sub-families have been shown to display very different discrimination consistency behaviors. The individual identification of consistently misclassified sequences should provide a tool for quality control to GPCR database curators. © 2017 The Author(s).","Database curation; G-Protein coupled receptors; Machine learning; Random forests","Biological membranes; Crystal structure; Cytology; Database systems; Decision trees; Learning algorithms; Learning systems; Metadata; Proteins; Quality control; Curation; Discrimination accuracy; Ensemble classification; Ensemble classifiers; G protein coupled receptors; Individual identification; Quantitative method; Random forests; C (programming language)",2-s2.0-85027698382
"Francisquez M., Zhu B., Rogers B.N.","Global 3D Braginskii simulations of the tokamak edge region of IWL discharges",2017,"Nuclear Fusion",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028415917&doi=10.1088%2f1741-4326%2faa7f23&partnerID=40&md5=8622a0010c0a2da5cd1cbe86755d8ad1","A study of plasma turbulence and profile evolution in conditions of low (L-mode) and high (H-mode) confinement at the edge of an axisymmetric, nested circular flux-surface approximation to an inner wall limited (IWL) Alcator C-Mod discharge is presented, using numerical simulations with the global drift-ballooning (GDB) code. GDB solves driftreduced Braginskii two-fluid equations for electromagnetic low-frequency turbulence in a 3D annulus centered on the last closed flux-surface (LCFS). Three simulations that investigate the conditions of a reference L-mode, a high density, and a high temperature (or H-mode-like) shot were performed using realistic parameters. L-mode transport appears to be largely driven by drift resistive ballooning structures. Its pressure profile exhibits a near-SOL breakpoint that Mirror Langmuir Probes (MLP) detect in C-Mod. The high density simulation sees an increase in the size of convective cells and enhanced turbulent transport, while H-mode conditions develop improved confinement, balanced E × B and ion diamagnetic drifts in the closed-flux region, and spontaneous generation of temperature pedestal with a density pedestal remaining absent. A statistical characterization of the turbulence both in the SOL and the closed-flux region is presented. © 2017 IAEA, Vienna Printed in the UK.","density limit; edge turbulence; H-mode; L-mode; pedestal; scrape off layer; transport","Electric discharges; Langmuir probes; Magnetoplasma; Plasma turbulence; Sols; Density limit; Edge turbulence; H-mode; L-modes; pedestal; Scrape-off layer; transport; C (programming language)",2-s2.0-85028415917
"Gutiérrez M., Gregorio-Godoy P., Pérez Del Pulgar G., Munoz L.E., Sáez S., Rodríguez-Patón A.","A New Improved and Extended Version of the Multicell Bacterial Simulator gro",2017,"ACS Synthetic Biology",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027548145&doi=10.1021%2facssynbio.7b00003&partnerID=40&md5=77ea54e100da6db295e651a3c569a759","gro is a cell programming language developed in Klavins Lab for simulating colony growth and cell-cell communication. It is used as a synthetic biology prototyping tool for simulating multicellular biocircuits and microbial consortia. In this work, we present several extensions made to gro that improve the performance of the simulator, make it easier to use, and provide new functionalities. The new version of gro is between 1 and 2 orders of magnitude faster than the original version. It is able to grow microbial colonies with up to 105 cells in less than 10 min. A new library, CellEngine, accelerates the resolution of spatial physical interactions between growing and dividing cells by implementing a new shoving algorithm. A genetic library, CellPro, based on Probabilistic Timed Automata, simulates gene expression dynamics using simplified and easy to compute digital proteins. We also propose a more convenient language specification layer, ProSpec, based on the idea that proteins drive cell behavior. CellNutrient, another library, implements Monod-based growth and nutrient uptake functionalities. The intercellular signaling management was improved and extended in a library called CellSignals. Finally, bacterial conjugation, another local cell-cell communication process, was added to the simulator. To show the versatility and potential outreach of this version of gro, we provide studies and novel examples ranging from synthetic biology to evolutionary microbiology. We believe that the upgrades implemented for gro have made it into a powerful and fast prototyping tool capable of simulating a large variety of systems and synthetic biology designs. © 2017 American Chemical Society.","bioCAD tools; cell cell interactions; cell shoving algorithm; gro; individual-based model; intercellular communication; multicellular biocircuits; synthetic biology; synthetic microbial consortia",,2-s2.0-85027548145
"Sutriadi R., Kurniasari M.I.","Understanding Urban Communication in Information Era: Analyzing Development Progress of Coastal Territories in the Context of West Java's Metropolitan Regions",2017,"IOP Conference Series: Earth and Environmental Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028604019&doi=10.1088%2f1755-1315%2f79%2f1%2f012017&partnerID=40&md5=d907ccef8049687bce2cfd80c9e83084","This paper explores a consequence of metropolitan and development centers policy to the development progress of coastal territories by analyzing municipal website base on urban communication functions of communicative city concept. In terms of coastal territories as a part of development center, efforts have to be made in enhancing the role and function of municipal website to show their development progress. Perceptual analysis is taken as a method to measure their position, especially kabupaten/kota as coastal territories in regional context (West Java Province). The results indicate that the availability of public information in coastal territories cities lower than other cities in metropolitan area. Innovation in specifying coastal features has to be promoted in illustrating development progress of coastal territories as a part of development centers in West Java Province. © Published under licence by IOP Publishing Ltd.",,"Websites; Information eras; Metropolitan area; Metropolitan regions; Perceptual analysis; Public information; Urban communications; West javas; Java programming language",2-s2.0-85028604019
"Jang S.-L., Lin Y.-C.","Low-power three-path inductor class-C VCO without any dynamic bias circuit",2017,"Electronics Letters",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028775811&doi=10.1049%2fel.2017.1845&partnerID=40&md5=480ce00d0953a5a20b9daa3eec3f1222","A 2.48 GHz class-C voltage controlled oscillator (VCO) without any dynamic back bias circuit is presented. The VCO uses three-path high Q-factor inductor as the low loss resonator and class-C crosscoupled nMOSFET pairs for high dc/RF conversion efficiency and direct cross-coupled pMOSFET for dc current reuse. At the supply voltage of 1.2 V, the core power consumption is 0.24 mW. The phase noise of the VCO is -124 dBc/Hz and the VCO figure of merit is -197.0 dBc/Hz. The VCO was implemented in the TSMC standard 0.18 μm SiGe BiCMOS process and occupies a die area of 0.799 × 0.809 mm2. © 2017 The Institution of Engineering and Technology.",,"Bias voltage; Circuit oscillations; Low power electronics; MOSFET devices; Oscillators (electronic); Oscillistors; Q factor measurement; Semiconducting silicon; Timing circuits; Variable frequency oscillators; Cross-coupled; Dc current; Dynamic bias; Figure of merits; High Q factor; Low Power; Sige bicmos process; Supply voltages; C (programming language)",2-s2.0-85028775811
"Pushpakaran B.N., Bayne S.B., Ogunniyi A.A.","Silvaco based electro-Thermal analysis of 4H-SiC TIV-JFET structure under extremely high current density resistive switching",2017,"2016 IEEE International Power Modulator and High Voltage Conference, IPMHVC 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029430130&doi=10.1109%2fIPMHVC.2016.8012789&partnerID=40&md5=ed7b6d1d54177064ac00d3a978e7b254","A 2D model of a 1200 V normally-ON 4H-SİC Trenched and Implanted Vertical Junction Field Effect Transistor (TIV-JFET) cell structure was designed and simulated using Silvaco ATLAS TCAD software to investigate and understand the effects of extremely high current density pulsed switching on the device characteristics. The JFET cell was designed for an active area of 2 μm2 and a threshold voltage of-7 V. Physics-based models were included to account for impact ionization, recombination effects, band gap narrowing, mobility and lattice heating. The electro-Thermal simulation was performed using a resistive switching circuit at an ambient lattice temperature of 300 K. The circuit was designed for an ON-state drain current density of 5000 A/cm2. The device was simulated using a 100 kHz 50% duty cycle gate signal consisting of four switching cycles considering the simulation duration bottleneck. The analysis of lattice temperature profile revealed the formation of thermal hot spot in the channel area close to the gate P+ regions in the JFET structure. Further analysis showed an increase in the minority carrier concentration in the vicinity of the gate implants which affected the switching characteristics of the JFET at extremely high current density. © 2016 IEEE.","Extreme current density; JFET; Lattice heating; Resistive switching; Silicon carbide; Silvaco TCAD","C (programming language); Carrier concentration; Current density; Drain current; Electron emission; Electronic design automation; Energy gap; Field effect transistors; Impact ionization; Junction gate field effect transistors; Silicon carbide; Switching systems; Thermoanalysis; Threshold voltage; Electro-thermal simulation; Extreme current densities; Lattice heating; Minority carrier concentration; Resistive switching; Silvaco; Switching characteristics; Vertical junction field effect transistors; Switching",2-s2.0-85029430130
"Zhou M., Wu Y.-N., Wu B., Yin X., Gao N., Li F., Li G.","Block Copolymer-Templated Approach to Nanopatterned Metal–Organic Framework Films",2017,"Chemistry - An Asian Journal",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021798207&doi=10.1002%2fasia.201700307&partnerID=40&md5=b4075225e8aafbae34bb5ce33fcf6bb5","The fabrication of patterned metal–organic framework (MOF) films with precisely controlled nanoscale resolution has been a fundamental challenge in nanoscience and nanotechnology. In this study, nanopatterned MOF films were fabricated using a layer-by-layer (LBL) growth method on functional templates (such as a bicontinuous nanoporous membrane or a structure with highly long-range-ordered nanoscopic channels parallel to the underlying substrate) generated by the microphase separation of polystyrene-b-poly(2-vinylpyridine) (PS-b-P2VP) block copolymers. HKUST-1 can be directly deposited on the templates without any chemical modification because the pyridine groups in P2VP interact with metal ions via metal-BCP complexes. As a result, nanopatterned HKUST-1 films with feature sizes below 50 nm and controllable thicknesses can be fabricated by controlling the number of LBL growth cycles. The proposed fabrication method further extends the applications of MOFs in various fields. © 2017 Wiley-VCH Verlag GmbH & Co. KGaA, Weinheim","block copolymers; layer-by-layer; metal-organic frameworks; nanopatterns; self-assembly","Block copolymers; Chemical modification; Crystalline materials; Fabrication; Java programming language; Metal ions; Microphase separation; Nanoscience; Nanotechnology; Self assembly; Layer by layer; Metal organic framework; Nano pattern; Nanoporous membrane; Nanoscale resolutions; Nanoscience and nanotechnologies; Nanoscopic channels; Poly(2-vinylpyridine) (P2VP); Metals",2-s2.0-85021798207
"Tarpin M., Benitez F., Canet L., Wschebor N.","Nonperturbative renormalization group for the diffusive epidemic process",2017,"Physical Review E",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028706431&doi=10.1103%2fPhysRevE.96.022137&partnerID=40&md5=93dfff4587fce0b6647d398cf7aaf505","We consider the Diffusive Epidemic Process (DEP), a two-species reaction-diffusion process originally proposed to model disease spread within a population. This model exhibits a phase transition from an active epidemic to an absorbing state without sick individuals. Field-theoretic analyses suggest that this transition belongs to the universality class of Directed Percolation with a Conserved quantity (DP-C, not to be confused with conserved-directed percolation C-DP, appearing in the study of stochastic sandpiles). However, some exact predictions derived from the symmetries of DP-C seem to be in contradiction with lattice simulations. Here we revisit the field theory of both DP-C and DEP. We discuss in detail the symmetries present in the various formulations of both models. We then investigate the DP-C model using the derivative expansion of the nonperturbative renormalization group formalism. We recover previous results for DP-C near its upper critical dimension dc=4, but show how the corresponding fixed point seems to no longer exist below d3. Consequences for the DEP universality class are considered. © 2017 American Physical Society.",,"Epidemiology; Percolation (solid state); Solvents; Statistical mechanics; Stochastic systems; Conserved quantity; Directed percolation; Lattice simulation; Non-perturbative renormalization groups; Reaction-diffusion process; Theoretic analysis; Universality class; Upper critical dimension; C (programming language)",2-s2.0-85028706431
"Ferdiana R.","Web Engineering Education through blended learning",2017,"Proceeding - 2017 3rd International Conference on Science and Technology-Computer, ICST 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029330926&doi=10.1109%2fICSTC.2017.8011848&partnerID=40&md5=06457c49088074389c9a39b55ee36d62","Web technology is growing with one website deployed per second. It can be said that any business will have a website. Therefore, web engineer become an essential part to make it happen. However, web technology is not simple, there are more than 50 web frameworks that can be used to develop a website. There are more than 10 web programming languages that can be chosen to develop a website. This paper proposes an idea to accelerate the learning curve for new web developers. The paper uses ADDIE (Analyze, Design, Develop, Implement, and Evaluate) framework to develop an e-learning that will support the classroom as a blended learning experience. Accordingly, this article proposes learning plan namely Web Engineering Education (W2E). W2E proposes structured blended learning approach and capstone design course model to achieve the body knowledge of web developers. This paper will describe the body knowledge for web engineering, the learning curve that proposed for a new web developer, and evaluation technique that can be used to evaluate the web developer. © 2017 IEEE.","Blended Learning; Web engineer; Web engineering education; Web technology","Curricula; Education; Teaching; Websites; Blended learning; Capstone design course; Learning curves; Web developers; Web engineering; Web frameworks; Web technologies; Engineering education",2-s2.0-85029330926
"Žic M.","Solving CNLS problems by using Levenberg-Marquardt algorithm: A new approach to avoid off-limits values during a fit",2017,"Journal of Electroanalytical Chemistry",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020737124&doi=10.1016%2fj.jelechem.2017.06.008&partnerID=40&md5=c233f107b4ea6ec907e6b307cc6c7423","Complex nonlinear least square problems (CNLS) are generally solved by using the Levenberg-Marquardt algorithm (LMA), which is utilized in specialized EIS software packages. One of the major drawbacks of LMA is inability to prevent a generation of negative and off-limits values during the fitting process. The problem of negative values is omitted in MEISP/LEVM and EQUICRT fitting engines, since the engines can impose the lower limit on parameters values. However, the problem of off-limits values has not been overcome in EIS specialized software packages yet. The study herein provides an insight and offers recommendations to support the design of a new fitting engine in which the problem of off-limits values was resolved by using limits. The new fitting engine was entirely developed in Python programming language and implemented in free (MIT license) EisPy v.2.01 software. The applicability of the new fitting engine was firmly established by analyzing synthetic and measured data. The EEC parameters values yielded by EisPy v.2.01 were compared to the ones obtained by MEISP/LEVM and EQUIVCRT software packages. The results herein clearly reveal that the new fitting engine is more robust when the limits are applied. © 2017 Elsevier B.V.","CNLS; EIS; Free program; Limits; Python","Computer programming; Computer software; Engines; High level languages; Problem oriented languages; Software packages; CNLS; Free program; Levenberg-Marquardt algorithm; Limits; Nonlinear least square problem; Python; Python programming language; Specialized software; Problem solving",2-s2.0-85020737124
"Ko H., Kaczmarowski A., Szlufarska I., Morgan D.","Optimization of self-interstitial clusters in 3C-SiC with genetic algorithm",2017,"Journal of Nuclear Materials",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019853630&doi=10.1016%2fj.jnucmat.2017.05.015&partnerID=40&md5=c7157330fecd1c5a7764027b9d257583","Under irradiation, SiC develops damage commonly referred to as black spot defects, which are speculated to be self-interstitial atom clusters. To understand the evolution of these defect clusters and their impacts (e.g., through radiation induced swelling) on the performance of SiC in nuclear applications, it is important to identify the cluster composition, structure, and shape. In this work the genetic algorithm code StructOpt was utilized to identify groundstate cluster structures in 3C-SiC. The genetic algorithm was used to explore clusters of up to ∼30 interstitials of C-only, Si-only, and Si-C mixtures embedded in the SiC lattice. We performed the structure search using Hamiltonians from both density functional theory and empirical potentials. The thermodynamic stability of clusters was investigated in terms of their composition (with a focus on Si-only, C-only, and stoichiometric) and shape (spherical vs. planar), as a function of the cluster size (n). Our results suggest that large Si-only clusters are likely unstable, and clusters are predominantly C-only for n ≤ 10 and stoichiometric for n > 10. The results imply that there is an evolution of the shape of the most stable clusters, where small clusters are stable in more spherical geometries while larger clusters are stable in more planar configurations. We also provide an estimated energy vs. size relationship, E(n), for use in future analysis. © 2017","Defect cluster; Genetic algorithm; Radiation; Self-interstitial; SiC","C (programming language); Crystal defects; Density functional theory; Genetic algorithms; Hamiltonians; Heat radiation; Optimization; Silicon; Silicon carbide; Thermodynamic stability; Defect cluster; Empirical potentials; Nuclear application; Planar configurations; Radiation-induced; Self-interstitial; Self-interstitial atom cluster; Spherical geometries; Clustering algorithms",2-s2.0-85019853630
"Sant'Anna L.G., Soares E.A.D.A., Riccomini C., Tatumi S.H., Yee M.","Age of depositional and weathering events in Central Amazonia",2017,"Quaternary Science Reviews",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021429779&doi=10.1016%2fj.quascirev.2017.06.015&partnerID=40&md5=8758626fbd8814d5bf91b7918f730724","In the last three decades, several studies have been devoted to understanding the role of Late Pleistocene–Holocene climate changes in the Amazonia lowlands environment. However, most of these studies used data obtained from sedimentary deposits (lakes, swamps, and colluvium) located away from the central plain or on the edges of the Amazonia region. This article integrates optically stimulated luminescence and accelerated mass spectrometry 14C ages with sedimentological and geomorphological data obtained during this study or compiled from the literature for fluvial and lacustrine deposits of the central alluvial plain of the Solimões-Amazon River. The age data allow us to present a chronological framework for the Late Pleistocene–Holocene deposits and conclude that (i) the dryness of the LGM in central Amazonia lowlands is recorded by the formation of fluvial terraces and their weathering to pedogenic hematite between 25.3 ka and 17.7 ka; (ii) floodplain deposition was contemporaneous with terrace weathering and occurred in a context of decreased water volume in fluvial channels, lowering of river base level and sea level, and isostatic rebound of the continent; and (iii) lateral and mid-channel fluvial bars in the Solimões-Amazon River have a minimum age of 11.5 ± 1.5 ka, and their deposition responded to increased precipitation at the beginning of the Holocene. © 2017 Elsevier Ltd","Alluvial plain; Amazonia; Iron oxide; LGM; OSL dating; Pleistocene","C (programming language); Climate change; Deposits; Iron oxides; Luminescence; Mass spectrometry; Rivers; Sea level; Weathering; Alluvial plains; Amazonia; Holocene climate change; Lacustrine deposits; Optically stimulated luminescence; OSL dating; Pleistocene; Sedimentary deposits; Deposition; accelerator mass spectrometry; age determination; alluvial plain; climate variation; deposition; fluvial deposit; hematite; iron oxide; lacustrine deposit; Last Glacial Maximum; lowland environment; Pleistocene-Holocene boundary; river terrace; weathering; Amazon River; Amazonas [Brazil]; Amazonia; Brazil; Solimoes River",2-s2.0-85021429779
"Poole A., Kotsialos A.","METANET Validation of the Large-Scale Manchester Ring-Road Network Using Gradient-Based and Particle Swarm Optimization",2017,"IEEE Transactions on Intelligent Transportation Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028473935&doi=10.1109%2fTITS.2017.2724941&partnerID=40&md5=75612002d5b5984f436c0bdc1992cab7","This paper is concerned with the problem of macroscopic traffic flow model validation for ring-road shaped large-scale motorway networks. The calibration optimization problem is solved by a gradient-based algorithm combining into a single software package METANET (traffic simulator), RPROP (resilient backpropagation search heuristic), and ADOL-C (automatic differentiation library) and by a separate implementation of particle swarm optimization with METANET. These model validation packages are applied to the motorway network around the city of Manchester, U.K. The total road length of the site is 186 km considering the traffic flow on both directions of each modeled motorway. For this large scale network, a single optimization problem is formed for calibrating METANET, i.e., for identifying its parameters. Three different data sets are used and the corresponding optimal parameter sets are obtained. The results show that the combined METANET-RPROP-ADOL-C package is able to calibrate the large scale motorway network model with very good accuracy. The optimal parameter sets, where the optimization algorithm converged for a particular data set, are verified by running METANET simulations using the other two data sets. Results do show the expected degradation of the parameter set's quality, but the essential network wide dynamics of congestion are retained. IEEE","ADOL-C; Calibration; Computational modeling; Data models; Heuristic algorithms; Mathematical model; METANET; Optimization; parameter identification; particle swarm optimisation.; Particle swarm optimization; RPROP; Traffic flow model validation","Backpropagation algorithms; C (programming language); Calibration; Computer software; Data structures; Heuristic algorithms; Identification (control systems); Mathematical models; Motor transportation; Parameter estimation; Particle swarm optimization (PSO); Roads and streets; Traffic control; Transportation; Vehicle actuated signals; Computational model; METANET; Particle swarm optimisation; RPROP; Traffic flow modeling; Optimization",2-s2.0-85028473935
"Bui T.T., Nana W.S.A., Abouri S., Limam A., Tedoldi B., Roure T.","Influence of uniaxial tension and compression on shear strength of concrete slabs without shear reinforcement under concentrated loads",2017,"Construction and Building Materials",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017580577&doi=10.1016%2fj.conbuildmat.2017.04.068&partnerID=40&md5=12886ba581f1e75829ca3c5441f14f3f","Under the shear load, reinforced concrete structures may be simultaneously subjected to the axial tensile or compressive forces due to shrinkage in restrained members, earthquake, tornado, and so on. Until now, no experiment addressing the effect of the uniaxial load on the shear resistance of reinforced concrete slab has been reported in the literature. All the experimental tests found in the literature were conducted on panel and beam (or wide beam) specimens. The current shear design provisions with axial load (ACI 318 and Eurocode 2) were developed based solely on panel and beam tests and not slab tests. Therefore, the current shear design codes applied to slab structures under the effect of axial forces urgently need revision. The present research studies the shear strength tests of slabs under the concentrated load simply supported on four sides. The effect of the tension/compression forces on the shear capacity was studied on full-scale slabs without shear reinforcement, a design similar to the slabs used in nuclear buildings, under a concentrated load near support. Experimental tests were conducted to quantify the shear capacity and the associated failure modes with the influence of axial forces. In this study, a series of seven tests on seven full-scale slabs measuring 4 m × 2.6 m × 0.3 m is presented. The experiments were used to evaluate the pertinence of Eurocode 2 in terms of shear in reinforced concrete slabs with axial load, to compare these results to the AFCEN ETC-C code used for nuclear buildings, and to compare them to the ACI 318 code. The results showed that the axial tension forces equal to 0.28fctm (average concrete tensile capacity) reduced the shear capacity up to 30% in the concrete slab experiments conducted. © 2017 Elsevier Ltd","Axial forces; Concentrated load; Concrete; Experiments; Shear; Slab; Tension","Axial flow; Axial loads; C (programming language); Codes (symbols); Concentration (process); Concrete slabs; Concretes; Experiments; Loads (forces); Reinforced concrete; Shear strength; Shearing; Standards; Testing; Axial forces; Compressive forces; Concentrated load; Shear reinforcement; Shear strength tests; Slab; Strength of concrete; Tension; Shear flow",2-s2.0-85017580577
"Rafique M., Shuai Y., Hassan M.","Structural, electronic and optical properties of CO adsorbed on the defective anatase TiO2 (101) surface; a DFT study",2017,"Journal of Molecular Structure",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017542469&doi=10.1016%2fj.molstruc.2017.04.045&partnerID=40&md5=99c1e44f8b1034e7027d31e9b59ce747","This paper illustrates the study of stable structural, electronic and optical properties of carbon mono oxide (CO) molecule adsorbed on pure anatase TiO2 (101) surface and CO molecule adsorbed on defective anatase TiO2 (101) surface containing oxygen (O) atom subsurface vacancy using first-principles study calculations based on density functional theory (DFT) method. A foreign molecule CO was added in the interstitial space of anatase TiO2 (101) surface. It was observed that, adsorption of CO molecule is not favorable on pure anatase TiO2 (101) surface, however adsorption process is improved when subsurface contains O atom vacancy defect. In case of anatase TiO2 (101) surface containing subsurface vacancy, adsorption process is exothermic, resulting in stable structures. The adsorption energies calculated for CO molecules adsorbed at O2c site, at defect site and at Ti5c site of anatase surface containing subsurface O vacancy are 0.16 eV (at O2c), 0.32 eV (at defect site) and 0.43 eV (at Ti5c) site. DOS and PDOS plots are calculated for all the structures. Results indicated that CO molecule adsorption introduces surface states at the Fermi energy level (EF) as shown in partial density of states (PDOS) plots. The dielectric matrix and absorption coefficient (α) for defective anatase TiO2 (101) surface, CO adsorbed at O2c site, at defect site and at Ti5C site of anatase TiO2 (101) surface containing O atom subsurface vacancy has been calculated within the random phase approximation (RPA) using VASP (Vienna ab-initio simulation package) code. It was observed that upon CO adsorption at defective anatase surface, real and imaginary dielectric function peaks were shifted towards lower energy level and a small absorption peak was observed at 1.1 eV energy level which is not present in case of defective anatase (101) surface. CO adsorption produces a red shift in the absorption spectrum of anatase TiO2 (101) surface containing subsurface O atom vacancy. © 2017 Elsevier B.V.","Absorption; Adsorption; Anatase; PDOS","Absorption; Absorption spectroscopy; Adsorption; Approximation algorithms; Atoms; C (programming language); Calculations; Carbon; Density functional theory; Molecules; Optical properties; Surface defects; Vacancies; Absorption co-efficient; Density functional theory methods; Electronic and optical properties; First-principles study; Partial density of state; PDOS; Random phase approximations; Vienna ab-initio simulation packages; Titanium dioxide",2-s2.0-85017542469
"Wang Y., Wang Y.","Change prediction approach and application effect for citrus fertilization and irrigation intelligent decision support system",2017,"Nongye Gongcheng Xuebao/Transactions of the Chinese Society of Agricultural Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031777930&doi=10.11975%2fj.issn.1002-6819.2017.16.023&partnerID=40&md5=690a6e52985ff5e08f202f51a1cea204","Agricultural information systems rely heavily on ontologies to realize intelligent and precision agricultural information services such as disease diagnosis and crop planting management. In the development of agricultural applications, due to the massive and cross domain knowledge required in the agricultural domain, it is impossible to develop applications after the completion of domain ontologies. Due to various reasons, ontologies are constantly modified, augmented, or evolved during the application development. Since ontologies are often tightly interwoven with applications, when changes occur in ontologies, the applications such as query services and decision support services that rely on them will be affected in different ways and may not function correctly. Therefore, it is important to provide mechanisms that fill the gap between ontology evolution management and the change management of knowledge based systems. In this paper, we proposed an approach to analyze and predict change impacts on user interface components when the underlying ontology is changed of its concepts. Our approach avoided the hard and error-prone task to analyze change impacts at the lower level, i.e., source code level. Instead, in our method, the change impact prediction was accomplished at the higher conceptual level. Specifically, we focused on the problem that when ontology concepts were changed, how to determine the affected user interface components of applications without diving into the source codes of the system. Our approach was based on constructing three matrices: the interface component dependency matrix, the ontology concept dependency matrix, and the ontology concept-user interface component correlation matrix, at the conceptual level. The interface component dependency matrix specified the direct reliance between interface components based on the shared interface variables of interface components. The ontology concept dependency matrix described the direct relationships between ontology concepts derived from domain ontology. The ontology concept-user interface component correlation matrix specified the direct dependencies between concepts and interface components. With the three matrices, we provided an algorithm to create the change impact propagation tree for each involved ontology concept. By treating the change impact propagation tree as a logical tree, we were able to calculate the change impact prediction probabilities for each concept and interface component. By setting appropriate prediction thresholds, we can obtain the predicted change impact results. To evaluate our approach of change prediction for interface components relating to ontology concepts, we applied the proposed method to the citrus fertilization and irrigation intelligent decision support system. The citrus decision support system was supported by a citrus fertilization and irrigation ontology, which contained 22 domain concepts. The decision support system had six user interface components. For each of the 22 concepts, we calculated the change impact probabilities for each of the six interface components by the change impact propagation trees. In addition, we obtained the actual data by analyzing the Java source codes of the citrus decision support systems. In order to compare the experiment data with the actual data, we set two empirical prediction thresholds, 5% and 10%, based on the existing related studies for filtering the experiment data. We applied two traditional statistic indicators, precision and recall, to evaluate the results. The final evaluation results showed that given the prediction threshold of 5%, the average precision of change impact prediction for the 22 concepts was 77% and the average recall was 98%. Given the threshold of 10%, the average precision of change impact prediction for the 22 concepts reached 85% and the average recall was 74%. There was a tradeoff between precision and recall, i.e., a higher precision indicated a lower recall. In our cases, the precision and recall rates for the both thresholds indicated satisfied results for our proposed change impact prediction approach. The proposed approach provides a feasible and effective solution to the challenging task of change management problem in agricultural information systems based on ontologies. © 2017, Editorial Department of the Transactions of the Chinese Society of Agricultural Engineering. All right reserved.","Citrus fertilization and irrigation decision support system; Ontology change management; Prediction; Semantic ontology; Software architecture; Software change management; Systems analysis","Agriculture; Artificial intelligence; Codes (symbols); Computer programming languages; Diagnosis; Forecasting; Forestry; Information management; Information services; Information systems; Irrigation; Knowledge based systems; Management information systems; Matrix algebra; Ontology; Semantics; Software architecture; Systems analysis; Trees (mathematics); User interfaces; Agricultural information systems; Agricultural informations; Decision support services; Intelligent decision support systems; Ontology changes; Semantic ontology; Software change managements; User interface components; Decision support systems",2-s2.0-85031777930
"Benli A., Karataş M., Gurses E.","Effect of sea water and MgSO4 solution on the mechanical properties and durability of self-compacting mortars with fly ash/silica fume",2017,"Construction and Building Materials",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018489890&doi=10.1016%2fj.conbuildmat.2017.04.108&partnerID=40&md5=5ac72fa614fba64a9e0221cfd412646d","This experimental study was carried out to investigate the mechanical properties of self-compacting mortars (SCMs) containing binary and ternary mixtures of silica fume (SF) and fly ash (FA) immersed in sea water and 10% by weight magnesium sulfate (MgSO4) solution. 14 series of mortar specimens including control mixture were prepared by replacing Portland cement with 10%, 20% and 30% by weight of C class fly ash (FA) and 6%, 9%, 12% and 15% by weight of silica fume (SF). Ternary mixes were produced by replacing 10% of FA containing 6%, 9%, 12% and 15% of SF and 20% replacement of FA with 6% and 9% of SF. A total of 182 samples of 40 × 40 × 160 mm mortar were prepared and cured in water at 3, 28, 56 and 180 days and immersed in sea water and magnesium sulfate (MgSO4) solution at 28, 56, 90 and 180 days to observe SCMs behavior in hardened conditions. Durability properties were evaluated by capillary absorption (sorptivity and porosity tests). Mini slump flow diameter, viscosity and mini V-funnel flow time tests were performed to assess the fresh properties of SCMs containing FA and SF. The results showed that all binary and ternary mixes of SCMs and control specimens exposed to MgSO4 solution have increasing compressive and tensile strength up to 90 days then tend to decrease at the age of 180 days. The control specimens exposed to sea water showed the best resistance in terms of tensile strength. Porosity of SF binary blended SCMs cured in water at 28 days have higher values than ternary blended SCMs and the control specimens cured in water at 28 days have the lowest porosity. The SCMs exposed to magnesium sulfate solution, some deterioration such as crack formation due to surface softening was observed. © 2017 Elsevier Ltd","Durability; Fly ash; Fresh properties; Magnesium sulfate; Mechanical properties; Seawater; Self-compacting mortar; Silica fume","Binary mixtures; Bins; C (programming language); Capillary flow; Curing; Fly ash; Magnesium; Mechanical properties; Mixtures; Mortar; Porosity; Portland cement; Seawater; Silica; Silica fume; Sulfur compounds; Tensile strength; Binary and ternary mixtures; Capillary absorption; Compressive and tensile strengths; Durability property; Fresh properties; Magnesium sulfate; Magnesium sulfate solution; Self-compacting mortars; Durability",2-s2.0-85018489890
"Szczesny S.","HDL-Based Synthesis System with Debugger for Current-Mode FPAA",2017,"IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028466022&doi=10.1109%2fTCAD.2017.2740295&partnerID=40&md5=4469cc4a4a0434f3a049d1a1f6fff37e","The study demonstrates original environment for synthesizing and implementing current-mode analog circuits in the Field Programmable Analog Array (FPAA) technology. The described approach is inspired by existing solutions for digital circuits, implemented using an FPGA. The tools are compatible with the existing hardware architecture description standards (VHDL-AMS, HSPICE) and the existing EDA software. The functionality of the system was divided into a synthesis stage (independent on the hardware layer) and an implementation stage (dedicated to an FPAA platform chosen by the user). The article presents parasitics oriented place&amp;route algorithms of the original system and a method for calibrating the analog part. The tools are also equipped with the option of debugging a programmed circuit. The author presents the functionality of the system with an example of an implementation of a 5th order filter pair and a 35-18-26 perceptron with a balanced structure. The summary is an analysis of the complexity of the implemented algorithms and the measurement of program run-times. IEEE","analog synthesis; Computer architecture; current-mode; debugging.; Electronic Design Automation (EDA); Field Programmable Analog Array (FPAA); Field programmable analog arrays; Hardware; Mirrors; Programming; Tools","Computer aided design; Computer architecture; Computer debugging; Computer hardware; Computer hardware description languages; Computer programming; Electronic design automation; Field programmable gate arrays (FPGA); Hardware; Mathematical programming; Mirrors; Tools; Analog Synthesis; Balanced structures; Current mode; Field Programmable Analog Array; Field programmable analog arrays; Hardware architecture; Original systems; Synthesis stages; Program debugging",2-s2.0-85028466022
"Brand M.","P-RAM vs. RP-RAM",2017,"Theoretical Computer Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020189727&doi=10.1016%2fj.tcs.2017.05.011&partnerID=40&md5=1bc1c48a7e0fc87bc04fe8b9838e8123","One of the fundamental open questions in computational complexity is whether the class of problems solvable by use of stochasticity under the Random Polynomial time (RP) model is larger than the class of those solvable in deterministic polynomial time (P). However, this question is only open for Turing machines, not for Random Access Machines (RAMs). Simon (1981) [31] was able to show that for a sufficiently equipped Random Access Machine, the ability to switch states nondeterministically entails no computational advantage. On the other hand, in the same paper, Simon describes a different (and arguably more natural) model for RAM stochasticity. According to Simon's proposal, instead of receiving a new random bit at each execution step, the RAM program is able to execute the pseudofunction RAND(y), which returns a uniformly distributed random integer in the range [0,y). Whether the ability to allot a random integer in this fashion is more powerful than the ability to allot a random bit remained an open question for the last 30 years. In this paper, we close Simon's open problem by fully characterising the class of languages recognisable in polynomial time by each of the RAMs regarding which the question was posed. We show that for some of these stochasticity does not entail any advantage, but, more interestingly, we show that for others it does. These results carry over also to BPP-like and coRP-like acceptance criteria. © 2017 Elsevier B.V.","Arithmetic complexity; BPP-RAM; PEL; Random Access Machine; RP; RP-RAM","Integer programming; Polynomial approximation; Polynomials; Turing machines; Acceptance criteria; Arithmetic complexity; Computational advantages; Polynomial-time; Random access machines; Random polynomials; Stochasticity; Switch state; Random access storage",2-s2.0-85020189727
"Cai L., Ding J.","Wavelet transformation coupled with CARS algorithm improving prediction accuracy of soil moisture content based on hyperspectral reflectance",2017,"Nongye Gongcheng Xuebao/Transactions of the Chinese Society of Agricultural Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031819821&doi=10.11975%2fj.issn.1002-6819.2017.16.019&partnerID=40&md5=5e37aec908ac02b5471e555a91f9beb7","The rapid estimation of soil moisture content (SMC) is of great significance to precision agriculture in arid areas. Hyperspectral remote sensing technology has been widely used in the estimation of SMC due to that it's non-destructive and rapid, and has high spectral resolution characteristics. Meanwhile, there are a lot of factors, such as massive spectral data, and surface conditions, which might affect the spectra, increasing the difficulty in extracting the effective information, and reducing the prediction accuracy of SMC. Noise reduction must be considered in developing hyperspectral estimation models, but how to reduce noise while retaining as much useful information as possible needs investigation. As advanced spectral mining methods, competitive adaptive reweighted sampling (CARS) was used to solve this problem in this study. In the present study, a total of 39 soil samples at 0-20 cm depth were collected from the delta oasis in Xinjiang. The samples were brought back to the laboratory to be dried naturally, ground and passed through a screen with 2 mm hole, and then filled into the black boxes with 12 cm diameter and 1.8 cm depth, which were leveled at the rim with a spatula. Reflectance of soil samples was measured using ASD (analytical spectral devices) Fieldspec 3 Spectrometer in a dark room. We used the following steps to process soil reflectance: First, discrete wavelet transformation (DWT) was used to decompose the original spectra in 8 levels using db4 wavelet basis with MATLAB programming language. In order to select the maximum level of DWT, correlation coefficients between the SMC and the spectra of each level were computed. Secondly, the CARS was used to filter the redundant variables, the wavelength variables with better correlation with SMC were screened out and the characteristic wavelength variables of each decomposition level were superimposed as the optimal variable set. Thirdly, partial least squares regression (PLSR) was employed to build the hyperspectral estimation models of SMC. And then, root mean square error of calibration set (RMSEC), determination coefficient of calibration set (R2 c), root mean square error of prediction set (RMSEP), determination coefficient of predicting set (R2 p) and relative prediction deviation (RPD) were used for accuracy assessment. The results showed that: 1) With the increase of the number of decomposed layers, the correlation between soil reflectance and SMC showed a trend of increasing first and then decreasing, and L6 was the most significant band at 0.01 level. In general, the characteristic spectrum of L6 was denoised, and at the same time, the spectral detail was preserved to the maximum extent, so the maximum decomposition order of the wavelet was 6-order decomposition. 2) The characteristic wavelength variable of the characteristic spectrum was selected by coupling wavelet transform and CARS algorithm. However, if only the CARS selection result of the feature spectrum was taken into account, it was easy to ignore the water features of other characteristic spectra. Therefore, in this study, by adding the characteristic wavelength variables of each layer as the optimal set of variables, it contained 131 wavelength variables near the absorption band (450, 1 400, 1 900, 2 200 nm). 3) Compared with the full-band PLSR model, the accuracy of PLSR model of CARS preferred variables for each decomposition level was high, and the PLSR model of the optimal variable set had the highest accuracy and a better performance in predicting SMC in the study area (RMSEC=0.021, R2 c=0.721, RMSEP=0.028, R2 p=0.924, RPD=2.607). It is shown that the combination of wavelet transform and CARS algorithm makes it possible to remove the noise as much as possible and to remove the noise completely when the model is established, and at the same time, it can effectively remove the non-information variable and provide a new idea of the screening of the SMC spectral variable in this region. © 2017, Editorial Department of the Transactions of the Chinese Society of Agricultural Engineering. All right reserved.","CARS; Moisture content; Soil; Spectrum analysis WT; Variable selection","Calibration; Coherent scattering; Discrete wavelet transforms; Filtration; Forecasting; Least squares approximations; MATLAB; Mean square error; Mining; Moisture; Moisture determination; Noise abatement; Railroad cars; Reflection; Remote sensing; Signal reconstruction; Soil moisture; Soil surveys; Soils; Spectral resolution; Spectrum analysis; Wavelet decomposition; Analytical spectral devices; Determination coefficients; Discrete wavelet transformation; Hyperspectral remote sensing technology; Partial least squares regressions (PLSR); Root mean square error of calibrations; Root-mean-square error of predictions; Variable selection; Wavelet transforms",2-s2.0-85031819821
"Martens C., Hammer M.A.","Languages of play: Towards semantic foundations for game interfaces",2017,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030793158&doi=10.1145%2f3102071.3102096&partnerID=40&md5=13ee4b3ce018f70e899578829bf6d234","Formal models of games help us account for and predict behavior, leading to more robust and innovative designs. While the games research community has proposed many formalisms for both the ""game half"" (game models, game description languages) and the ""human half"" (player modeling) of a game experience, little attention has been paid to the interface between the two, particularly where it concerns the player expressing her intent toward the game. We describe an analytical and computational toolbox based on programming language theory to examine the phenomenon sitting between control schemes and game rules, which we identify as a distinct player intent language for each game. © 2017 ACM.","Formal methods; Game interfaces; Programming languages","Computation theory; Computer games; Computer programming languages; Formal methods; Interactive computer graphics; Semantics; Control schemes; Description languages; Game interfaces; Innovative design; Player modeling; Programming language theory; Research communities; Semantic foundation; Modeling languages",2-s2.0-85030793158
"Blanchard J.","Hybrid environments: A bridge from blocks to text",2017,"ICER 2017 - Proceedings of the 2017 ACM Conference on International Computing Education Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030161868&doi=10.1145%2f3105726.3105743&partnerID=40&md5=a90d9a248fe8fe08e3968bb0f9cd7db9","Hybrid, dual-modality programming environments provide both blocks-based and text-based interfaces for programming. While previous research investigated the transition from visual to textual environments, few studies considered these hybrid environments. The purpose of this dissertation is to explore how hybrid programming environments impact computer science competency, confidence, and interest in computer science among students when moving from blocks-based environments to textbased languages. Exploring these questions will help us understand which hybrid environments are effective, in which contexts they are effective, and if they can improve on current approaches to CS instruction. © 2017 ACM.","Computer science education; Hybrid programming environments; Novice programming; Programming environments; Programming languages","Computer programming; Education computing; Engineering education; Computer Science Education; Dual modality; Hybrid programming; Novice programming; On currents; Programming environment; Text-based interfaces; Textual environments; Computer programming languages",2-s2.0-85030161868
"van Rozen R., van der Storm T.","Toward live domain-specific languages: From text differencing to adapting models at run time",2017,"Software and Systems Modeling",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028563306&doi=10.1007%2fs10270-017-0608-7&partnerID=40&md5=b2fc34b956785c04b625cbfed47b0fb6","Live programming is a style of development characterized by incremental change and immediate feedback. Instead of long edit-compile cycles, developers modify a running program by changing its source code, receiving immediate feedback as it instantly adapts in response. In this paper, we propose an approach to bridge the gap between running programs and textual domain-specific languages (DSLs). The first step of our approach consists of applying a novel model differencing algorithm, tmdiff, to the textual DSL code. By leveraging ordinary text differencing and origin tracking, tmdiff produces deltas defined in terms of the metamodel of a language. In the second step of our approach, the model deltas are applied at run time to update a running system, without having to restart it. Since the model deltas are derived from the static source code of the program, they are unaware of any run-time state maintained during model execution. We therefore propose a generic, dynamic patch architecture, rmpatch, which can be customized to cater for domain-specific state migration. We illustrate rmpatch in a case study of a live programming environment for a simple DSL implemented in Rascal for simultaneously defining and executing state machines. © 2017 Springer-Verlag GmbH Germany","Adapting models; Domain-specific languages; Live programming; Model patching; Models at run time; Text differencing","Codes (symbols); Computer programming; Digital subscriber lines; Problem oriented languages; Differencing algorithm; Domain specific languages; Immediate feedbacks; Incremental changes; Model executions; Models at run time; Programming environment; Text differencing; Computer programming languages",2-s2.0-85028563306
"Butler E., Siu K., Zook A.","Program synthesis as a generative method",2017,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030782548&doi=10.1145%2f3102071.3102076&partnerID=40&md5=13e5358093c3eb4a89268e773298e2de","Generative methods (also known as procedural content generation) have been used to generate a variety of static artifacts such as game levels. One key property of a generative method for a particular domain is how effectively the approach allows a designer to express the properties and constraints they care about. Generative methods have been applied much less frequently to dynamic artifacts such as boss behaviors, in part because the complex representation required to describe boss morphology and behavior is not amenable to existing generative techniques. It is challenging to describe a generative space of varied yet valid behaviors. Expanding on previous work that introduced a programming language for representing boss behaviors, we illustrate how such a language can be used by a designer to describe desirable design properties and constraints for bosses.at is, we define a generative space of bosses as a space of well-formed programs. We present a constructive algorithm that extends generative grammars to efficiently generate well-formed programs, and we show a complete example of generating Mega- Man-like bosses with complex attack patterns. We conclude that designing a generative space of dynamic behaviors can be fruitfully framed as a programming-language design problem. © 2017 ACM.","Generative Grammars; Generative Methods; Procedural Content Generation; Program Synthesis","Computer programming languages; Attack patterns; Constructive algorithms; Dynamic behaviors; Generative Grammars; Generative methods; Procedural content generations; Program synthesis; Programming language design; Computer games",2-s2.0-85030782548
"Zou Y., Zeng X., Liu Y., Liu H.","Partial precedence of context-sensitive graph grammars",2017,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030767365&doi=10.1145%2f3105971.3105983&partnerID=40&md5=3133811d86d6a9e86a325457952fc807","Context-sensitive graph grammars have been rigorous formalisms for specifying visual programming languages, as they possess sufficient expressive powers and intuitive forms. Efficient parsing mechanisms are essential to these formalisms. However, the existent parsing algorithms are either inefficient or confined to a minority of graph grammars. This paper introduces the notion of partial precedence, defines the partial precedence graph of a graph grammar and theoretically unveils the existence of a valid parsing path conforming to the topological orderings of the partial precedence graph. Then, it provides algorithms for computing the partial precedence graph and presents an approach to improving general parsing algorithms with the graph based on the drawn conclusion. It is shown that the approach can considerably improve the efficiency of general parsing algorithms. © 2017 Association of Computing Machinery.","Context-sensitive graph grammars; Efficiency; Parsing algorithms; Partial precedence graph; Visual languages","Computer programming; Context sensitive languages; Efficiency; Formal languages; Graph theory; Graphic methods; Topology; Visual communication; Visual languages; Context-sensitive graph grammar; Graph grammar; Graph-based; Parsing algorithm; Precedence graph; Topological ordering; Visual programming languages; Context sensitive grammars",2-s2.0-85030767365
"Edwards S.H., Kandru N., Rajagopal M.B.M.","Investigating static analysis errors in student Java programs",2017,"ICER 2017 - Proceedings of the 2017 ACM Conference on International Computing Education Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030171964&doi=10.1145%2f3105726.3106182&partnerID=40&md5=608e252c2e46ad7709c8f81e069bf51c","Research on students learning to program has produced studies on both compile-Time errors (syntax errors) and run-Time errors (exceptions). Both of these types of errors are natural targets, since detection is built into the programming language. In this paper, we present an empirical investigation of static analysis errors present in syntactically correct code. Static analysis errors can be revealed by tools that examine a program's source code, but this error detection is typically not built into common programming languages and instead requires separate tools. Static analysis can be used to check formatting or commenting expectations, but it also can be used to identify problematic code or to find some kinds of conceptual or logic errors. We study nearly 10 million static analysis errors found in over 500 thousand program submissions made by students over a fivesemester period. The study includes data from four separate courses, including a non-majors introductory course as well as the CS1/CS2/CS3 sequence for CS majors. We examine the differences between the error rates of CS major and non-major beginners, and also examine how these patterns change over time as students progress through the CS major course sequence. Our investigation shows that while formatting and Javadoc issues are the most common, static checks that identify coding flaws that are likely to be errors are strongly correlated with producing correct programs, even when students eventually fix the problems. With experience, students produce fewer errors, but the errors that are most frequent are consistent between both computer science majors and non-majors, and across experience levels. These results can highlight student struggles or misunderstandings that have escaped past analyses focused on syntax or run-Time errors. © 2017 ACM.","Checkstyle; Coding standard; Coding style; Documentation; Formatting; Java; Pmd; Static analysis; Web-cat","Codes (symbols); Coding errors; Computation theory; Computer software; Computer systems programming; Education; Error detection; Errors; Java programming language; Object oriented programming; Polarization mode dispersion; Students; Syntactics; System program documentation; Checkstyle; Coding standards; Coding style; Formatting; Java; Web-CAT; Static analysis",2-s2.0-85030171964
"Valls-Vargas J., Zhu J., Ontanon S.","Graph grammar-based controllable generation of puzzles for a learning game about parallel programming",2017,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030781303&doi=10.1145%2f3102071.3102079&partnerID=40&md5=4a291d3589bb52243a09cdf28494efa7","In the context of a learning game to teach parallel programming, we describe a procedural content generation (PCG) approach that can be controlled to generate programming puzzles involving a desired set of concepts, and of desired size and ""difficulty"". Our approach is based on grammars to control the generation of the puzzle structure, and orthographic graph embedding techniques to render it into a two-dimensional grid for our game. The proposed PCG system is designed to work with a player model in order to provide personalized learning experiences. We present an evaluation of the variability of the generated puzzles using several metrics including challenge and solvability as evaluated by a custom-build model checker. Our evaluation shows that this PCG system can generate a large number of varied puzzles but it is still not able to generate puzzles with certain aesthetic and functional qualities found in puzzles generated by human authors. © 2017 ACM.","Games; Parallel programming; Procedural content generation","Computer games; Formal languages; Model checking; Parallel programming; Games; Graph embeddings; Graph grammar; Model checker; Personalized learning; Player modeling; Procedural content generations; Two-dimensional grids; Quality control",2-s2.0-85030781303
"Duran R.","Towards a fine-grained analysis of complexity of programming tasks",2017,"ICER 2017 - Proceedings of the 2017 ACM Conference on International Computing Education Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030166313&doi=10.1145%2f3105726.3105731&partnerID=40&md5=5f4f0432528a2f4bf27d992ef16ebdea","Bloom's and SOLO taxonomies have been used to describe the complexity of computer science tasks and student's outcome. However, using these taxonomies have coarse granularity and programming tasks with very different demands could be equally classified at the same level. My research proposes a new framework using Neo- Piagetian stages of development based on the Model of Hierarchical Complexity (MHC) that enable formal definition and fine-grained evaluation of programming tasks nuances in paradigms, languages, and constructs. By empirically validating the model, I expect it to be a valuable tool to provide best practices to develop pedagogical approaches and tools. © 2017 ACM.","Model of hierarchical complexity; Neo-piagetian stages; Task complexity","Taxonomies; Best practices; Fine grained; Fine-grained analysis; Formal definition; Pedagogical approach; Programming tasks; Task complexity; Education computing",2-s2.0-85030166313
"Butler E., Torlak E., Popovic Z.","Synthesizing interpretable strategies for solving puzzle games",2017,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030763098&doi=10.1145%2f3102071.310208&partnerID=40&md5=d490b64c992d7a703989cc99eda5053b","Understanding how players interact with games is an important challenge for designers. When playing games centered around problem solving, such as logic puzzles like Sudoku or Nonograms, people employ a rich structure of domain-specific knowledge and strategies that are not obvious from the description of a game's rules.is paper explores automatic discovery of player-oriented knowledge and strategies, with the goal of enabling applications ranging from difficulty estimation to puzzle generation to game progression analysis. Using the popular puzzle game Nonograms as our target domain, we present a new system for learning human-interpretable rules for solving these puzzles. the system uses program synthesis, powered by an SMT solver, as the primary learning mechanism. The learned rules are represented as programs in a domain-specific language for condition-action rules. Given game mechanics and a training set of small Nonograms puzzles, our system is able to learn sound, concise rules that generalize to a test set of large real-world puzzles. We show that the learned rules outperform documented strategies for Nonograms drawn from tutorials and guides, both in terms of coverage and quality. © 2017 ACM.","Artificial Intelligence; Automated Game Analysis; Program Synthesis","Artificial intelligence; Computer games; Computer programming languages; Problem oriented languages; Automatic discovery; Condition-action rules; Difficulty estimations; Domain specific languages; Domain-specific knowledge; Game analysis; Program synthesis; Progression analysis; Problem solving",2-s2.0-85030763098
"Vu T., Tran H., Lin F., Langan J., Cavuoto L., Xu W.","A Home-Based Functional Hand-Extremity Assessment System for Stroke Rehabilitation",2017,"Proceedings - 2017 IEEE 2nd International Conference on Connected Health: Applications, Systems and Engineering Technologies, CHASE 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029363161&doi=10.1109%2fCHASE.2017.105&partnerID=40&md5=0179f654c858b9fae11a3b7830d47546","This paper presents a novel hand-grip system for evaluation and rehabilitation of individuals with stroke. This system contains a pair of hand dynamometers, which are sensors for the input of grip force, and LabVIEW VI software to translate the grip force into meaningful data. The hand-grip system requires the subjects to move a small ball on a computer screen toward a target, using the hand grip sensor to control the movement of the ball. It goes far beyond measuring maximum grip strength, a common clinical assessment, to adapt grip force and coordinate hands to perform daily functional activities. This system also provides advancement in home-rehabilitation options to improve the hand-grip control of individuals with stroke. © 2017 IEEE.",,"Computer programming languages; Assessment system; Clinical assessments; Computer screens; Functional activities; Grip strength; Home-based; LabVIEW VI; Stroke rehabilitation; Computer control systems",2-s2.0-85029363161
"Yang J., Huai R., Wang H., Li W., Wang Z., Sui M., Su X.","Global positioning system-based stimulation for robo-pigeons in open space",2017,"Frontiers in Neurorobotics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028062220&doi=10.3389%2ffnbot.2017.00040&partnerID=40&md5=3496f0b998adb6bfb532a9fe2067893f","An evaluation method is described that will enable researchers to study fight control characteristics of robo-pigeons in fully open space. It is not limited by the experi-mental environment and overcomes environmental interference with flight control in small experimental spaces using a compact system. The system consists of two components: a global positioning system (GPS)-based stimulator with dimensions of 38 mm × 26 mm × 8 mm and a weight of 18 g that can easily be carried by a pigeon as a backpack and a PC-based program developed in Virtual C++. The GPS-based stimu-lator generates variable stimulation and automatically records the GPS data and stimulus parameters. The PC-based program analyzes the recorded data and displays the flight trajectory of the tested robo-pigeon on a digital map. This method enables quick and clear evaluation of the flight control characteristics of a robo-pigeon in open space based on its visual trajectory, as well as further optimization of the microelectric stimulation parameters to improve the design of robo-pigeons. The functional effectiveness of the method was investigated and verified by performing flight control experiments using a robo-pigeon in open space. © 2017 Yu, Moirangthem and Lee.","Bio-robot; Brain-computer interface; Flight control; Robo-pigeon; Stimulator","Brain computer interface; C++ (programming language); Computer software; Interfaces (computer); Software testing; Bio robots; Control characteristics; Environmental interference; Flight control; Flight trajectory; Robo-pigeon; Stimulation parameters; Stimulator; Global positioning system",2-s2.0-85028062220
"Ushizima D., Yang C., Venkatakrishnan S., Araujo F., Silva R., Tang H., Mascarenhas J.V., Hexemer A., Parkinson D., Sethian J.","Convolutional neural networks at the interface of physical and digital data",2017,"Proceedings - Applied Imagery Pattern Recognition Workshop",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028758002&doi=10.1109%2fAIPR.2016.8010606&partnerID=40&md5=57af007c4c29dbdc634744f2b8d1c00f","Electron and X-ray interactions with matter can be recorded as digital images, which are signal acquisition mechanisms often used to investigate materials microstructure. Recently, the ability to quickly acquire large datasets at high resolution has created new challenges in areas that rely upon image-based information. The proposed analysis schemes employ Convolutional Neural Networks as the core algorithm in the reconnaissance of expected events from data gathered in two regimes: experimentally and by simulation. At the interface of physical and digital datasets, we propose classification schemes that exploit complex geometrical structure from scientific images through different machine learning packages, such as MatConvNet and TensorFlow. Our results show correct classification rates over 90% considering thousands of samples from four image modalities: cryo-electron microscopy, X-ray diffraction, X-ray scattering and X-ray microtomography. Our main contributions are: (a) developing algorithms designed for data that stem from physical experiments; (b) building new software to constrain parameter space, particularly given new hardware; and (c) testing different CNN models for classification of scientific images. © 2016 IEEE.",,"C (programming language); Classification (of information); Convolution; Electron microscopes; Learning systems; Neural networks; Signal processing; Software testing; X ray diffraction; X ray scattering; Classification rates; Classification scheme; Convolutional neural network; Cryo-electron microscopy; Geometrical structure; Physical experiments; Signal acquisitions; X ray microtomography; Pattern recognition",2-s2.0-85028758002
"Said A.F., Hazrati M.K., Akhbari F.","Real-time detection and classification of traffic light signals",2017,"Proceedings - Applied Imagery Pattern Recognition Workshop",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028773257&doi=10.1109%2fAIPR.2016.8010547&partnerID=40&md5=b9fff2f54493c0dca8cb02585648c488","Traffic light detection is an important part of Advanced Driver Assist as well as autonomous vehicle systems which ensures timely and appropriate reaction to traffic lights (TLs) in cross sections. In this paper we introduce a robust and realtime approach to detect TLs and recognize its status in complex traffic scenes solely based on image processing techniques. The proposed system uses color properties of the scene to detect TLs in real-time. An innovative technique has been developed to significantly decrease compute requirement for detection of TL color by using one Lookup Table independent of lighting conditions. Each candidate region is further analyzed, using features analysis, to segregate actual TL signals among all candidate regions. As in similar machine learning techniques, an unsupervised classifier using a set of significant features has been developed to accurately segregate circular, semi-circular, and arrow shaped TL signals without using a training dataset. The final C++ code has been implemented and optimized on intelplatform using 1920x1080 frame resolution to recognize the status of TLs during day-time and night-time scenes, achieving 95% precision and 94.7% recall at 30FPS. © 2016 IEEE.","Automatic driving assistance; Color segmentation; Gamma correction; temporal validation; Traffic light detection; unsupervised classification","Advanced driver assistance systems; Automobile drivers; C++ (programming language); Classification (of information); Color; Image processing; Learning systems; Pattern recognition; Seebeck effect; Signal detection; Table lookup; Automatic driving; Color segmentation; Gamma correction; temporal validation; Traffic light; Unsupervised classification; Traffic signals",2-s2.0-85028773257
"Jiang J., Fu M., Li C., Shang R., Fu Y.","Theoretical Investigation on Nickel-Catalyzed Hydrocarboxylation of Alkynes Employing Formic Acid",2017,"Organometallics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027394277&doi=10.1021%2facs.organomet.7b00310&partnerID=40&md5=f1df831760b8d72e0272e48166e791fc","DFT calculations have been conducted to elucidate the mechanistic details of a novel Ni-catalyzed hydrocarboxylation reaction of alkynes, in which formic acid is atom-economically used through a catalytic CO recycling manner. On the basis of our theoretical investigations, the bisphosphine (dppbz, 1,2-bis(diphenylphosphino)benzene) ligated nickel monocarbonyl complex (dppbz)NiCO was located as the active catalytic species for this process, and such a carbonyl ligand is found to be critical for the final reductive elimination. Our studies also revealed the addition of H to alkynes proceeds via a proton transfer process directly from formic acid (i.e., outer-sphere pathway) rather than through a proposed hydrometalation process (i.e., direct hydride shift from Ni-H). The thermal decomposition of formic anhydrides was found to be vital to a successful reaction, and its barrier must be slightly higher than the energetic span of the Ni catalytic cycle. Fast release of CO can poison the Ni catalyst, so that the reaction would be shut down. Other intriguing experimental observations, such as ligand effect, regioselectivity, and extraordinary compatibility of C-X (X = halogen) bonds, are also discussed in this article. © 2017 American Chemical Society.",,"C (programming language); Catalysis; Decomposition; Formic acid; Hydrocarbons; Ligands; 1 ,2bis(diphenylphosphino)benzene; Catalytic cycles; Catalytic species; DFT calculation; Hydrocarboxylation; Proton transfer process; Reductive elimination; Theoretical investigations; Nickel",2-s2.0-85027394277
"Israel M., Wherfel Q.M., Shehab S., Melvin O., Lash T.","Describing elementary students' interactions in K-5 puzzle-based computer science environments using the collaborative computing observation instrument (C-COI)",2017,"ICER 2017 - Proceedings of the 2017 ACM Conference on International Computing Education Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030169592&doi=10.1145%2f3105726.3106167&partnerID=40&md5=b5dd84b64bfcc8b1f678ea5211dfa329","Despite efforts to integrate computer science (CS) into K-12 education, there are numerous unanswered questions about how students learn CS, how to provide positive computing experiences, and how students interact with each other during CS instruction. To begin to deconstruct these complexities for a diverse range of students, it is important to not only study the outcomes and products of students' computational experiences, but also the processes they take in creating those products. In recognizing the necessity for targeted, narrow research questions, this paper focused on how elementary students interacted with each other during puzzle-based CS instruction. Future work will focus on comparing these findings to students' collaborative interactions in more open-ended computing situations. Data analysis made use of the Collaborative Computing Observation Instrument (C-COI) [6] to analyze video screen captures of nine students as they engaged in CS activities within Code.org's Code Studio. Findings confirmed three predominant types of collaborative interactions: Collaborative problem solving, excitement and accomplishment related to CS activities, and general socialization. © 2017 ACM.","Assessing computational behaviors; Collaborative computing; Collaborative computing observation instrument (C-COI); K-12 computer science education","C (programming language); Computer supported cooperative work; Education; Education computing; Problem solving; Assessing computational behaviors; Collaborative interaction; Collaborative problem solving; Computer Science Education; Diverse range; Elementary students; K-12 education; Research questions; Students",2-s2.0-85030169592
"Tay K.G., Cheong T.H., Lee M.F., Kek S.L., Abdul-Kahar R.","The Euler's Graphical User Interface Spreadsheet Calculator for Solving Ordinary Differential Equations by Visual Basic for Application Programming",2017,"IOP Conference Series: Materials Science and Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028648509&doi=10.1088%2f1757-899X%2f226%2f1%2f012186&partnerID=40&md5=cd31c3339d7be34f0f1ad44b44227319","In the previous work on Euler's spreadsheet calculator for solving an ordinary differential equation, the Visual Basic for Application (VBA) programming was used, however, a graphical user interface was not developed to capture users input. This weakness may make users confuse on the input and output since those input and output are displayed in the same worksheet. Besides, the existing Euler's spreadsheet calculator is not interactive as there is no prompt message if there is a mistake in inputting the parameters. On top of that, there are no users' instructions to guide users to input the derivative function. Hence, in this paper, we improved previous limitations by developing a user-friendly and interactive graphical user interface. This improvement is aimed to capture users' input with users' instructions and interactive prompt error messages by using VBA programming. This Euler's graphical user interface spreadsheet calculator is not acted as a black box as users can click on any cells in the worksheet to see the formula used to implement the numerical scheme. In this way, it could enhance self-learning and life-long learning in implementing the numerical scheme in a spreadsheet and later in any programming language. © Published under licence by IOP Publishing Ltd.",,"Differential equations; Graphical user interfaces; Mathematical instruments; Ordinary differential equations; Spreadsheets; Visual BASIC; Derivative functions; Error messages; Input and outputs; Interactive graphical user interface; Life long learning; Numerical scheme; Self-learning; Visual basic for applications; User interfaces",2-s2.0-85028648509
"Miljanovic M.A., Bradbury J.S.","RoboBUG: A serious game for learning debugging techniques",2017,"ICER 2017 - Proceedings of the 2017 ACM Conference on International Computing Education Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030150308&doi=10.1145%2f3105726.3106173&partnerID=40&md5=743602baf3a85f8b0384a1c28d73c8a1","Debugging is an essential but challenging task that can present a great deal of confusion and frustration to novice programmers. It can be argued that Computer Science education does not sufficiently address the challenges that students face when identifying bugs in their programs. To help students learn effective debugging techniques and to provide students a more enjoyable and motivating experience, we have designed the RoboBUG game. RoboBUG is a serious game that can be customized with respect to different programming languages and game levels. © 2017 ACM.","Computer science; Debugging; Education; Game-based learning; Programming; Serious games; Software engineering","Computer debugging; Computer games; Computer programming; Computer science; Education; Education computing; Engineering education; Mathematical programming; Program debugging; Software engineering; Students; Computer Science Education; Game-based Learning; Novice programmer; Serious games",2-s2.0-85030150308
"Margulieux L., Catrambone R.","Using learners' self-explanations of subgoals to guide initial problem solving in app inventor",2017,"ICER 2017 - Proceedings of the 2017 ACM Conference on International Computing Education Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030164732&doi=10.1145%2f3105726.3106168&partnerID=40&md5=6e461f26b49936ac29e873c1db9003ca","Our goal for the present research was to improve upon the subgoal learning framework and further enhance problem solving performance for novice programmers learning to use a block-based programming language. In particular, we are expanding upon recent work done by Margulieux and Morrison that prompts learners to self-explain the subgoals, or functional pieces, of a problem solving process to create their own instructional explanations of the process. We added to this work by exploring whether learners' self-explained instructions could be used to effectively scaffold initial problem solving attempts (i.e., practice problems) to further improve performance. In this experiment, learners self-explained subgoals using the most successful conditions from Margulieux and Catrambone's [1] prior work and then were given practice problems that were either unscaffolded (control condition), scaffolded with their own subgoal explanations, or scaffolded with explanations constructed by an instructional designer and computer scientist. Learners who were scaffolded with their own explanations performed better on later problem solving (i.e., an assessment test) than those scaffolded with the experts' explanations or those with no scaffolding. The results show that scaffolding initial problem solving with learners' explanations of the problem solving process can lead to better problem solving performance than scaffolding from experts if the learners construct explanations with adequate support. © 2017 ACM.","Block-based programming; Constructive learning; Problem solving; Selfexplanation; Subgoal learning","Education; Problem oriented languages; Scaffolds; Block based; Constructive learning; Improve performance; Instructional designer; Problem solving process; Problem-solving performance; Self explanations; Subgoal learning; Problem solving",2-s2.0-85030164732
"Hong N.K., Hafit H., Wahid N., Kasim S., Yusof M.M.","Help Me Please!: Designing and Developing Application for Emergencies",2017,"IOP Conference Series: Materials Science and Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028677302&doi=10.1088%2f1757-899X%2f226%2f1%2f012116&partnerID=40&md5=2c9fec83ac03b3face6b62827f4b7554","Help Me Please! Application is an android platform emergency button application that is designed to transmit emergency messages to target receivers with real time information. The purpose of developing this application is to help people to notify any emergency circumstances via Short Message Service (SMS) in android platform. The application will receive the current location from Global Positioning System (GPS), will obtain the current time from the mobile device and send this information to the receivers when user presses the emergency button. Simultaneously, the application will keep sending the emergency alerts to receivers and will update to database based on the time interval set by user until user stop the function. Object-oriented Software Development model is employed to guide the development of this application with the knowledge of Java language and Android Studio. In conclusion, this application plays an important role in rescuing process when emergency circumstances happen. The rescue process will become more effective by notifying the emergency circumstances and send the current location of user to others in the early hours. © Published under licence by IOP Publishing Ltd.",,"Android (operating system); Computer software; Global positioning system; Mobile devices; Object oriented programming; Software design; Android platforms; Emergency alerts; Emergency messages; Java language; Object oriented software development; Real-time information; Rescue process; Short message services; Application programs",2-s2.0-85028677302
"Nagy T., Vadai G., Gingl Z.","Digital phonocardiographic experiments and signal processing in multidisciplinary fields of university education",2017,"European Journal of Physics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028582574&doi=10.1088%2f1361-6404%2faa7ae6&partnerID=40&md5=d7952272dff3cf3415bbdd289a284ee7","Modern measurement of physical signals is based on the use of sensors, electronic signal conditioning, analog-to-digital conversion and digital signal processing carried out by dedicated software. The same signal chain is used in many devices such as home appliances, automotive electronics, medical instruments, and smartphones. Teaching the theoretical, experimental, and signal processing background must be an essential part of improving the standard of higher education, and it fits well to the increasingly multidisciplinary nature of physics and engineering too. In this paper, we show how digital phonocardiography can be used in university education as a universal, highly scalable, exciting, and inspiring laboratory practice and as a demonstration at various levels and complexity. We have developed open-source software templates in modern programming languages to support immediate use and to serve as a basis of further modifications using personal computers, tablets, and smartphones. © 2017 European Physical Society.","multidisciplinary experimentation; phonocardiography; signal processing; smartphone; sound card","Analog to digital conversion; Computer programming; Digital signal processing; Digital to analog conversion; Domestic appliances; E-learning; mHealth; Open source software; Open systems; Personal computers; Phonocardiography; Smartphones; Software engineering; Digital phonocardiography; Higher education; Laboratory practices; Medical instruments; multidisciplinary experimentation; Physical signal; Sound cards; University education; Signal processing",2-s2.0-85028582574
"Nelson G.L., Xie B., Ko A.J.","Comprehension first: Evaluating a novel pedagogy and tutoring system for program tracing in CS1",2017,"ICER 2017 - Proceedings of the 2017 ACM Conference on International Computing Education Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030150756&doi=10.1145%2f3105726.3106178&partnerID=40&md5=95d17e32d96fed3f1bf2b2e114ac4e95","What knowledge does learning programming require? Prior work has focused on theorizing program writing and problem solving skills. We examine program comprehension and propose a formal theory of program tracing knowledge based on control .ow paths through an interpreter program's source code. Because novices cannot understand the interpreter's programming language notation, we transform it into causal relationships from code tokens to instructions to machine state changes. To teach this knowledge, we propose a comprehension-first pedagogy based on causal inference, by showing, explaining, and assessing each path by stepping through concrete examples within many example programs. To assess this pedagogy, we built PLTutor, a tutorial system with a fixed curriculum of example programs. We evaluate learning gains among self-selected CS1 students using a block randomized lab study comparing PLTutor with Codecademy, a writing tutorial. In our small study, we and some evidence of improved learning gains on the SCS1, with average learning gains of PLTutor 60% higher than Codecademy (gain of 3.89 vs. 2.42 out of 27 questions). These gains strongly predicted midterms (R2=.64) only for PLTutor participants, whose grades showed less variation and no failures. © 2017 ACM.","Knowledge representation; Notional machine; Program tracing","Computation theory; Knowledge based systems; Knowledge representation; Problem solving; Program interpreters; Teaching; Causal inferences; Causal relationships; Knowledge based; Learning programming; Problem solving skills; Program comprehension; Program tracing; Program writing; Education",2-s2.0-85030150756
"Kaczmarek-Heb M.","A multilevel model of events in support of enterprise agility in the realm of enterprise modeling",2017,"Proceedings - 2017 IEEE 19th Conference on Business Informatics, CBI 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029418977&doi=10.1109%2fCBI.2017.58&partnerID=40&md5=5f7df79c6203721bf4c99125a5cbab9d","One of the challenges faced by enterprises is a need to be agile, i.e., having the ability to detect changes and respond to them efficiently and effectively. These changes are caused by 'change drivers', i.e., events occurring within an enterprise itself or within its environment. Many scholars argue that the use of conceptual modeling in general, and enterprise modeling in particular, may help achieve and sustain enterprise agility. This, however, requires enterprise modeling approaches not only to provide an integrated view on the enterprise action system and information system, but also to account for events indicating business-impacting situations and information on their impact on the enterprise. In addition, being agile requires the ability to acquire information from event sources (sensing), to process obtained information, and to support a decision-making process (response). In this paper, we argue that the fulfillment of those postulates demands the application of an alternative language paradigm, namely multilevel modeling. Therefore, we contribute a multilevel model of events developed using an integrated modeling and programming approach. © 2017 IEEE.","Enterprise modeling; FMMLx; Modeling of events; Multilevel modeling","Agile manufacturing systems; Decision making; Regression analysis; Action systems; Conceptual model; Decision making process; Enterprise agility; Enterprise modeling; FMMLx; Integrated modeling; Multilevel model; Modeling languages",2-s2.0-85029418977
"Deitrick E., Wilkerson M.H., Simoneau E.","Understanding student collaboration in interdisciplinary computing activities",2017,"ICER 2017 - Proceedings of the 2017 ACM Conference on International Computing Education Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030172317&doi=10.1145%2f3105726.3106193&partnerID=40&md5=cbe267360d32d9ebed2356473de4badc","Many students are introduced to computing through its infusion into other school subjects. Advocates argue this approach can deepen learning and broaden who is exposed to computing. In many cases, such interdisciplinary activities are student-driven and collaborative. This requires students to balance multiple learning goals and leverage knowledge across subjects. When working in groups, students must also negotiate this balance with peers based on their collective expertise. Balance and negotiation, however, are not always easy. This paper presents data from a project to infuse computing into high school statistics using the R programming language. We analyze multiple episodes of video data from two pairs of students as they negotiated (1) the statistics and computing goals of an activity, (2) the knowledge needed to meet those goals, and (3) whose expertise can help achieve those goals. One pair consistently reached agreement along these dimensions, and engaged productively with both subject ma.er and computing.The other pair did not reach agreement, and struggled to accomplish their tasks. This work provides examples of productive and unproductive interdisciplinary computing collaborations, and contributes tools to study them. © 2017 ACM.","Collaborative learning; Computational thinking; Computing education; Interdisciplinary curriculum; Research methods","Education; Knowledge management; Collaborative learning; Computational thinkings; Computing activity; Computing education; Interdisciplinary activities; Interdisciplinary curriculum; Learning goals; Student collaboration; Students",2-s2.0-85030172317
"Betzing J.H.","Design and development of an event-driven in-memory business process engine",2017,"Proceedings - 2017 IEEE 19th Conference on Business Informatics, CBI 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029439152&doi=10.1109%2fCBI.2017.31&partnerID=40&md5=5c1ba8c8002dcb59ba6dc0e0d495c05b","Although organizations have widely adopted Business Process Management Systems (BPMS) as an automation and integration middleware, these systems remain limited in their orchestration capabilities. BPMS can only react to event information that enterprise applications emit and only integrate against the service interfaces these applications provide. At the same time, organizations increasingly leverage large-scale in-memory database platforms as a shared database layer to house all their enterprise applications. These databases challenge traditional three-tier architectures by relocating data-intense application code into the data-tier. Consequently, the database contains both application data and low-level service procedures, which make up the required inputs for an orchestration capability.This paper presents the design and development of an event-oriented Business Process Engine (BPE) that runs within an in-memory platform. The approach comprises a compiler which transforms processes modeled in BPMN 2.0 into artifacts of the in-memory database, and the actual BPE that is implemented in the database platform's procedural programming language. The approach provides unconstrained reach to external events, which are expressed as arbitrary database state changes. Using BPMN as input, this paper addresses the notation's poorly specified message semantics to declare events by clarifying the notion of messages w.r.t the BPE and the message properties of BPMN. Special consideration is on message correlation and messaging patterns toward messaging scenarios far beyond the narrow BPMN specification. © 2017 IEEE.","BPMN; Business Process Execution; Event-driven Business Process Management; In-memory Database; Workflow Management","Client server computer systems; Database systems; Distributed computer systems; Engines; Enterprise resource management; Middleware; Program compilers; Semantics; Work simplification; BPMN; Business process execution; Business process management; Memory database; Workflow managements; Administrative data processing",2-s2.0-85029439152
"Cheng H.-T., Haque Z., Hong L., Ispir M., Mewald C., Polosukhin I., Roumpos G., Sculley D., Smith J., Soergel D., Tang Y., Tucker P., Wicke M., Xia C., Xie J.","TensorFlow estimators: Managing simplicity vs. Flexibility in high-level machine learning frameworks",2017,"Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029125628&doi=10.1145%2f3097983.3098171&partnerID=40&md5=dcf983c6089a1b6de99631923dd4a9e3","We present a framework for specifying, training, evaluating, and deploying machine learning models. Our focus is on simplifying cutting edge machine learning for practitioners in order to bring such technologies into production. Recognizing the fast evolution of the field of deep learning, we make no attempt to capture the design space of all possible model architectures in a domain-specific language (DSL) or similar configuration language. We allow users to write code to define their models, but provide abstractions that guide developers to write models in ways conducive to productionization. We also provide a unifying Estimator interface, making it possible to write downstream infrastructure (e.g. distributed training, hyperparameter tuning) independent of the model implementation. We balance the competing demands for flexibility and simplicity by offering APIs at different levels of abstraction, making common model architectures available out of the box, while providing a library of utilities designed to speed up experimentation with model architectures. To make out of the box models flexible and usable across a wide range of problems, these canned Estimators are parameterized not only over traditional hyperparameters, but also using feature columns, a declarative specification describing how to interpret input data. We discuss our experience in using this framework in research and production environments, and show the impact on code health, maintainability, and development speed. © 2017 Copyright held by the owner/author(s).",,"Abstracting; Artificial intelligence; Computer programming languages; Data mining; Multiprocessing systems; Object oriented programming; Problem oriented languages; Configuration languages; Domain specific languages; Hyper-parameter; Levels of abstraction; Machine learning models; Model architecture; Model implementation; Production environments; Learning systems",2-s2.0-85029125628
"Yu H., Dang S., Wu D.","Bounds and Constructions for Optimal (n, &#x007B;3, 4, 5&#x007D;, &#x2227;a, 1, Q)-OOCs",2017,"IEEE Transactions on Information Theory",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028472105&doi=10.1109%2fTIT.2017.2739778&partnerID=40&md5=888746a6d52d22e3ba642171cb132bfe","Let W &#x0003D; &#x007B;w1,...,wr&#x007D; be a set of positive integers, &#x03BB;c a positive integer, &#x2227;a &#x0003D; (&#x03BB;(1) a ,...&#x03BB;(r) a ) an r-tuple of positive integers, and Q &#x0003D; (q1,...qr) an r-tuple of positive rational numbers whose sum is 1. In 1996, Yang introduced variable-weight optical orthogonal code, (n,W,&#x2227;a, &#x03BB;c, Q)-OOC, for multimedia optical CDMA systems with multiple quality of service (QoS) requirements. Some work had been done on the constructions of optimal (n,W,&#x2227;a,1,Q)-OOCs with unequal auto-correlation constraints for W &#x0003D; &#x007B;3, 4&#x007D; and &#x007B;3, 5&#x007D;, while little is known on optimal (n,W,&#x2227;a,1,Q)-OOCs for &#x2502;W&#x2502; &#x2265; 3. In this paper, we focus our main attentions on (n, &#x007B;3, 4, 5&#x007D;,&#x2227;a,1,Q)-OOCs whith &#x2227;a &#x2208; &#x007B;(2, 1, 1), (2, 1, 2), (2, 2, 1), (2, 2, 2)&#x007D;. Tight upper bounds on the maximum code size of (n, &#x007B;3, 4, 5&#x007D;;&#x2227;a,1,Q)-OOCs are obtained, and infinite classes of optimal (n; &#x007B;3, 4, 5&#x007D;,&#x2227;a,1,Q)-OOCs are constructed. IEEE","5G mobile communication; Adaptive optics; Multiaccess communication; Optical fiber networks; optical orthogonal code; quadratic residue; Quality of service; skew starter; Upper bound; variable-weight; Zinc","C (programming language); Codes (symbols); Optical communication; Optical fiber communication; Optical fibers; Optimal systems; Quality of service; Zinc; Mobile communications; Multi-access communications; Optical fiber networks; Optical orthogonal codes; Quadratic residues; Upper Bound; Variable weight; Adaptive optics",2-s2.0-85028472105
"Kolena J., Soukupová L., Kocík J., Lederer J.","Modified hydrotalcites as precursors for catalysts effective in the hydrogenolysis of glycerol to 1,2-propanediol",2017,"Reaction Kinetics, Mechanisms and Catalysis",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027330039&doi=10.1007%2fs11144-017-1239-2&partnerID=40&md5=95582cbba9c3a045c371f58abff6f5dc","A series of hydrotalcite-like materials containing Al, Cu and one other bivalent metal, selected from the group Ni, Fe, Co and Zn, were prepared in the frame of this study. These hydrotalcite-like structures were used as precursors of the catalysts for the hydrogenolysis of glycerol. The hydrotalcites were converted to active forms of catalysts by calcination at a programmed temperature, increasing with the speed of 2 °C/min, up to 350 °C and reduction by hydrogen at 350 °C and 7 MPa. The catalysts were characterized by XRD, TGA, TPR, TPD, HRTEM, Hg porosity and N2 physisorption. The catalyst containing Zn exhibited the highest activity and selectivity to 1,2-propanediol in the hydrogenolysis of glycerol despite the fact that it had lowest internal surface area from all the catalysts studied. Its activity was attributed to its specific pore volume distribution with highest fraction of wider macropores in the range between 1 and 10 µm, remarkably distinguishing this catalyst from all the other catalysts studied. © 2017 Akadémiai Kiadó, Budapest, Hungary","1,2-propanediol; Catalyst; Cu; Glycerol; Hydrogenolysis; Hydrotalcite","C (programming language); Catalyst activity; Catalysts; Copper; Glycerol; Hydrogenolysis; Hydrolysis; Zinc; 1 ,2-propanediol; Hydrotalcite-like materials; Hydrotalcite-like structures; Hydrotalcites; Internal surface area; Pore volume distribution; Programmed temperature; Reduction by hydrogens; Catalyst selectivity",2-s2.0-85027330039
"Still V., Rockai P., Barnat J.","Using off-the-shelf exception support components in C++ verification",2017,"Proceedings - 2017 IEEE International Conference on Software Quality, Reliability and Security, QRS 2017",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029454622&doi=10.1109%2fQRS.2017.15&partnerID=40&md5=027eac16ad73a1e78ccb451e53ddb074","An important step toward adoption of formal methods in software development is support for mainstream programming languages. Unfortunately, these languages are often rather complex and come with substantial standard libraries. However, by choosing a suitable intermediate language, most of the complexity can be delegated to existing execution-oriented (as opposed to verification-oriented) compiler frontends and standard library implementations. In this paper, we describe how support for C++ exceptions can take advantage of the same principle. Our work is based on DiVM, an LLVM-derived, verification-friendly intermediate language.Our implementation consists of 2 parts: an implementation of the 'libunwind' platform API which is linked to the program under test and consists of 9 C functions. The other part is a preprocessor for LLVM bitcode which prepares exception-related metadata and replaces associated special-purpose LLVM instructions. © 2017 IEEE.","C++; Exceptions; Model Checking; Unwinder","Cesium; Computer programming; Computer software selection and evaluation; Computer systems programming; Formal methods; Formal verification; High level languages; Model checking; Software design; Software reliability; Software testing; C functions; C++ exceptions; Exceptions; Intermediate languages; Standard libraries; Unwinder; C++ (programming language)",2-s2.0-85029454622
"Tang Z., Zhai J., Li B., Zhao J.","Are your classes well-encapsulated? encapsulation analysis for Java",2017,"Proceedings - 2017 IEEE International Conference on Software Quality, Reliability and Security, QRS 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029428280&doi=10.1109%2fQRS.2017.31&partnerID=40&md5=96dabdffae1ed30d0712e2ebc45ae7b2","Encapsulation is one of the basic characteristics of object-oriented programming. However, the access modifiers provided by common object-oriented languages do not help much because they only encapsulate the member references rather than the objects pointed to by them. Bad encapsulation makes object-oriented programs difficult to understand and reason about, thus concealing potential software vulnerabilities. We present in this paper the encapsulation analysis technique, which is an expression-based dataflow analysis, to statically compute the runtime memory layouts of object-oriented programs. The analysis results can help developers to master an intuitive comprehension on the code quality regarding encapsulation of classes. The results of experiments on various open-source Java projects and libraries show that our approach is both effective (25.76% of the classes are reported as not fully encapsulated) and efficient (2.15 KLOC/s and 27.35 classes/s) in finding potential encapsulation problems. We also give common guidance on how to achieve better encapsulation for object-oriented programs. © 2017 IEEE.","Encapsulation; OOP; Ownership; Static analysis","Catalyst activity; Computer software selection and evaluation; Data flow analysis; Encapsulation; Java programming language; Open source software; Quality control; Software reliability; Static analysis; Access modifiers; Analysis techniques; Basic characteristics; Code quality; Memory layout; Object-oriented program; Ownership; Software vulnerabilities; Object oriented programming",2-s2.0-85029428280
"Boucher A., Badri M.","Predicting fault-prone classes in object-oriented software: An adaptation of an unsupervised hybrid som algorithm",2017,"Proceedings - 2017 IEEE International Conference on Software Quality, Reliability and Security, QRS 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029430229&doi=10.1109%2fQRS.2017.41&partnerID=40&md5=487f0063f9a67e96f22c98caa97bdca1","Many fault-proneness prediction models have been proposed in literature to identify fault-prone code in software systems. Most of the approaches use fault data history and supervised learning algorithms to build these models. However, since fault data history is not always available, some approaches also suggest using semi-supervised or unsupervised fault-proneness prediction models. The HySOM model, proposed in literature, uses function-level source code metrics to predict fault-prone functions in software systems, without using any fault data. In this paper, we adapt the HySOM approach for object-oriented software systems to predict fault-prone code at class-level granularity using object-oriented source code metrics. This adaptation makes it easier to prioritize the efforts of the testing team as unit tests are often written for classes in object-oriented software systems, and not for methods. Our adaptation also generalizes one main element of the HySOM model, which is the calculation of the source code metrics threshold values. We conducted an empirical study using 12 public datasets. Results show that the adaptation of the HySOM model for class-level fault-proneness prediction improves the consistency and the performance of the model. We additionally compared the performance of the adapted model to supervised approaches based on the Naive Bayes Network, ANN and Random Forest algorithms. © 2017 IEEE.","Multilayer Perceptron; Naive Bayes Network; Object-Oriented Metrics Threshold Values; Object-Oriented Software Systems; Self-Organizing Map; Unsupervised Fault-Proneness Prediction","Bayesian networks; Classifiers; Codes (symbols); Computer programming languages; Computer software; Computer software selection and evaluation; Conformal mapping; Decision trees; Forecasting; Multilayer neural networks; Self organizing maps; Software reliability; Software testing; Empirical studies; Fault-proneness prediction; Naive bayes; Object oriented metrics; Object oriented software; Object-oriented software systems; Random forest algorithm; Source code metrics; Object oriented programming",2-s2.0-85029430229
"Zhang T., Su Y., Wang J., Wang J.","A novel model for software development and testing in programmable logic",2017,"Proceedings - 2017 IEEE International Conference on Software Quality, Reliability and Security, QRS 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029430599&doi=10.1109%2fQRS.2017.18&partnerID=40&md5=49fbf9e80c01ec5019a6439d56e11b51","Life cycle management is an effective way to maintain software quality in safety-critical systems; however, it faces difficulties when applied on software of Programmable Logic Device (PLD). This is because: (1) traditional models on software development do not fit with design workflow of PLD; (2) adaptive models for PLD focus mainly on specific features during software implementation, ignoring high-level design and inspection; (3) no consideration is paid on developing and testing the PLD software based on a reference model (e.g. C/C++ model), which is often used for prototyping complex system, such as spacecraft. In this paper, we propose a novel C-W Model, aiming to complete and normalize the life cycle of software development and testing in programmable logic. We use the C-W Model in different kinds of projects to do debugging in Hardware Description Language (HDL). Experimental results suggest that testing based on the proposed model has high error detection rate and is more efficient compared with the traditional method. © 2017 IEEE.","Programmable logic; Reference model; Software development; Test process management","Computer circuits; Computer debugging; Computer hardware description languages; Computer software selection and evaluation; Life cycle; Logic devices; Programmable logic controllers; Safety engineering; Software design; Software engineering; Software prototyping; Software reliability; Software testing; Testing; Development and testing; Life-cycle management; Programmable logic; Programmable logic device; Reference modeling; Safety critical systems; Software implementation; Test process; C (programming language)",2-s2.0-85029430599
"Johansen S., Sundararajan B., Armstrong P.F.","Building an historical GIS platform from archival data: The creation of dynamic databases for visualization of historical GIS information",2017,"SIGDOC 2017 - 35th ACM International Conference on the Design of Communication",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030223249&doi=10.1145%2f3121113.3121232&partnerID=40&md5=852483a5fb26ab67aed4b1532cc576c0","We describe our efforts to create an Historical GIS platform for genealogical data in Nova Scotia. To build a demonstrable prototype, we use historical data from two communities, the ""Old North End"" of Halifax, and ""Durham Village"" in Pictou County. With the initial time set at 1881, these communities are considerably different in character on the urban/rural axis, by occupation, ethnicity, religion, and household composition. The data we have been compiling include (a) household-level geographic coordinates, (b) 1881 directory and census data, and (c) photographic images. The full-scale platform will utilize the archival records and output of the various community-based historical and genealogical groups around the province. We have conducted several sub-projects to develop the programming for joining arbitrary data from disparate research groups, and will report on how this approach can be used ""to connect content and UX design practices to local contexts/local communities."" © 2017 Association for Computing Machinery.","Data visualization; Dynamic databases; Historical GIS; Two-sided networks","C (programming language); Data visualization; Photography; Population statistics; Visualization; Community-based; Design practice; Dynamic database; Geographic coordinates; Historical data; Household level; Photographic image; Research groups; Geographic information systems",2-s2.0-85030223249
"Emeka B.O., Liu S.","Security requirement engineering using structured object-oriented formal language for m-banking applications",2017,"Proceedings - 2017 IEEE International Conference on Software Quality, Reliability and Security, QRS 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029419618&doi=10.1109%2fQRS.2017.28&partnerID=40&md5=63e345a1b51bc31c4511d8f2de27878a","In the recent times, software security has gained a great deal of attention in the Software Development Life Cycle due to increased cases of reported cyber threats and incidents. A considerable number of cyber-attacks targeting financial systems has made security be the most critical feature in banking systems. However, establishing security requirements for these applications can be a challenging task because the activities and measures demanded by their requirements calls for a clear understanding and implementation without any degree of ambiguity. In order to address this, we propose a new framework; Security Requirement Engineering with Structured Object Oriented Formal Language (SRESOFL), while giving special focus on financial applications. The framework seeks to offer a weaving approach where security requirements and the functional system requirements are fused together during the system's requirement specification phase. We will illustrate the applicability of the SRESOFL framework with a case study on the development of a mobile banking application. © 2017 IEEE.","Formal Methods; M-Banking; M-Commerce; Security Requirement Engineering; SOFL","Computer software; Computer software selection and evaluation; Cryptography; Formal languages; Formal methods; Life cycle; Object oriented programming; Software design; Software reliability; Financial applications; M-banking; M-commerce; Requirement specification; Security requirements; SOFL; Software development life cycle; Structured object-oriented formal languages; Network security",2-s2.0-85029419618
[No author name available],"Proceedings - 2017 IEEE International Conference on Software Quality, Reliability and Security, QRS 2017",2017,"Proceedings - 2017 IEEE International Conference on Software Quality, Reliability and Security, QRS 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029427338&partnerID=40&md5=87e068552e1938c8b5c97f0c80f0901c","The proceedings contain 47 papers. The topics discussed include: which factor impacts GUI traversal-based test case generation technique most? a controlled experiment on android applications; improving random test sets using a locally spreading approach; transferring context-dependent test inputs; towards ex vivo testing of MapReduce applications; a novel model for software development and testing in programmable logic; WinHeap explorer: efficient and transparent heap-based bug detection in machine code; improving spectrum-based fault localization for spreadsheet debugging; a critical evaluation of spectrum-based fault localization techniques on a large-scale software system; statement-oriented mutant reduction strategy for mutation based fault localization; towards automation in information security management systems; security requirement engineering using structured object-oriented formal language for M-banking applications; a method for developing algorithms for assessing cyber-risk cost; engineering adaptive user interfaces using monitoring-oriented programming; Intersert: assertions on distributed process interaction sessions; software reliability as user perception: application of the fuzzy analytic hierarchy process to software reliability analysis; modeling and analyzing the android permission framework using high level Petri nets; towards better understanding of software quality evolution through commit-impact analysis; and predicting fault-prone classes in object-oriented software: an adaptation of an unsupervised hybrid SOM algorithm.",,,2-s2.0-85029427338
"Kamada H., Nishikawa K., Okui Y.","The Visual Interactive Programing Learning System Using Image Processing",2017,"Proceedings - 2016 3rd International Conference on Computing Measurement Control and Sensor Network, CMCSN 2016",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010315788&doi=10.1109%2fCMCSN.2016.21&partnerID=40&md5=bdb68e5234fac51c5ccc1833a37c7ca5","It is crucial to learn programing for the software engineers, but it is difficult to master programing skills, because conventional learning programing is learning programing language grammar which is necessary but isn't efficient for students to acquire the skills to write complicate and long programs. To solve the program, we propose the visual interactive programming learning system using image processing. The system ask the students to write the programs that output the indicated figures. And the system compare the correct figures with the student's program output figures using image processing, and the system judges that students' programs are correct or not. The system can also find the wrong parts of student's programs using plural pairs of output images. Furthermore the system can judge moving output images. We developed the system and we verified the system using experiments. © 2016 IEEE.","automatic judgement; image processing; learning; programing; visual system","Education; Learning systems; Sensor networks; Students; automatic judgement; Language grammar; learning; programing; Programming learning; Students' projects; Visual systems; Image processing",2-s2.0-85010315788
"Lukman A., Aryanto M.D., Pramudito A., Andhika A., Irawan D.E.","Understanding Kendal aquifer system: A baseline analysis for sustainable water management proposal",2017,"Journal of Physics: Conference Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030149416&doi=10.1088%2f1742-6596%2f877%2f1%2f012053&partnerID=40&md5=9cb3e437b15de4fc69bd38b6dbdabf4c","North coast of Java has been grown as the center of economic activities and major connectivity hub for Sumatra and Bali. Sustainable water management must support such role. One of the basis is to understand the baseline of groundwater occurrences and potential. However the complex alluvium aquiver system has not been well-understood. A geoelectric measurements were performed to determine which rock layer has a good potential as groundwater aquifers in the northern coast of Kaliwungu Regency, Kendal District, Central Java province. Total of 10 vertical electrical sounding (VES) points has been performed, using a Schlumberger configuration with the current electrode spacing (AB/2) varies between 200 - 300 m and the potential difference electrode spacing (MN/2) varies between 0.5 to 20 m with depths target ranging between 150 - 200 m. Geoelectrical data processing is done using Ip2win software which generates resistivity value, thickness and depth of subsurface rock layers. Based on the correlation between resistivity value with regional geology, hydrogeology and local well data, we identify three aquifer layers. The first layer is silty clay with resistivity values vary between 0 - 10 ohm.m, then the second layer is tuffaceous claystone with resistivity value between 10 - 60 ohm.m. Both layers serve as impermeable layer. The third layer is sandy tuff with resistivity value between 60 - 100 ohm.m which serves as a confined aquifer layer located at 70 - 100 m below surface. Its thickness is vary between 70 to 110 m. The aquifer layer is a mixing of volcanic and alluvium sediment, which is a member of Damar Formation. The stratification of the aquifer system may change in short distance and depth. This natural setting prevent us to make a long continuous correlation between layers. Aquifer discharge is estimated between 5 - 71 L/s with the potential deep well locations lies in the west and southeast part of the study area. These hydrogeological settings should be used as the main starting point in managing water supply in this area. © Published under licence by IOP Publishing Ltd.",,"Aquifers; Data handling; Economics; Electric discharges; Electric prospecting; Electrodes; Groundwater; Hydrogeology; Java programming language; Rocks; Water conservation; Water management; Water supply; Central Java Province; Economic activities; Groundwater aquifer; Hydrogeological settings; Potential difference; Resistivity values; Sustainable water management; Vertical electrical sounding; Groundwater resources",2-s2.0-85030149416
"Siahsarani A., Behravesh A.H., Barmouz M.","Compressive shape memory behavior of spring-shaped polylactic acid alloy type",2017,"Journal of Applied Polymer Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017366371&doi=10.1002%2fapp.45115&partnerID=40&md5=a17785076aecebd15e434815529e4f99","This article presents an experimental study on the shape memory behavior of blends of thermoplastic polyurethane (TPU) and biodegradable polylactic acid (PLA) at the PLA/TPU weight ratios of 70/30 (PT7030) and 50/50 (PT5050). The manufactured springs were studied comprehensively based on their morphological and thermal properties. Scanning electron microscopy micrographs were captured, which verified that TPU was compatible with PLA. The wide-angle X-ray diffraction suggested that the crystallinity of PLA was enhanced in the presence of TPU. In order to determine the shape recovery properties [shape recovery ratio (Rr), shape fixing ratio (Rf), and shape recovery force (Fr)], the samples programmed at three different temperatures (Tp) of 70, 80, and 90 °C and at various recovery temperatures (Tr) over 40 to 90 ° C, were studied. In general, the spring made with PT7030 showed higher Rr, Rf, and Fr values. The highest Rr (99%) was obtained at programmed temperature (Tp) of 70 °C and recovery temperature (Tr) of 90 °C. However, the Rr value for this spring programmed at 70 °C and recovered near body temperature was 50% with Fr of 1.4 N. Furthermore, the highest Fr (15.6 N) was observed in the spring made of PT7030 programmed at 80 °C and recovered at Tr of 78 ° C. © 2017 Wiley Periodicals, Inc. J. Appl. Polym. Sci. 2017, 134, 45115. © 2017 Wiley Periodicals, Inc.","bioengineering; differential scanning calorimetry; glass transition; shape memory polymer; thermoplastics; X-ray","Differential scanning calorimetry; Glass transition; Metal implants; Polyesters; Recovery; Reinforced plastics; Scanning electron microscopy; Shape memory effect; Shape optimization; Systems science; Temperature distribution; Thermoplastics; X ray diffraction; X rays; Programmed temperature; Recovery temperature; Shape memory behavior; Shape memory polymers; Shape recovery properties; Shape recovery ratios; Thermoplastic polyurethanes; Wide angle Xray diffraction; C (programming language)",2-s2.0-85017366371
"Guhlin J., Silverstein K.A.T., Zhou P., Tiffin P., Young N.D.","ODG: Omics database generator - a tool for generating, querying, and analyzing multi-omics comparative databases to facilitate biological understanding",2017,"BMC Bioinformatics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027521412&doi=10.1186%2fs12859-017-1777-7&partnerID=40&md5=7a3500487e582afb613c45ed16b21ba3","Background: Rapid generation of omics data in recent years have resulted in vast amounts of disconnected datasets without systemic integration and knowledge building, while individual groups have made customized, annotated datasets available on the web with few ways to link them to in-lab datasets. With so many research groups generating their own data, the ability to relate it to the larger genomic and comparative genomic context is becoming increasingly crucial to make full use of the data. Results: The Omics Database Generator (ODG) allows users to create customized databases that utilize published genomics data integrated with experimental data which can be queried using a flexible graph database. When provided with omics and experimental data, ODG will create a comparative, multi-dimensional graph database. ODG can import definitions and annotations from other sources such as InterProScan, the Gene Ontology, ENZYME, UniPathway, and others. This annotation data can be especially useful for studying new or understudied species for which transcripts have only been predicted, and rapidly give additional layers of annotation to predicted genes. In better studied species, ODG can perform syntenic annotation translations or rapidly identify characteristics of a set of genes or nucleotide locations, such as hits from an association study. ODG provides a web-based user-interface for configuring the data import and for querying the database. Queries can also be run from the command-line and the database can be queried directly through programming language hooks available for most languages. ODG supports most common genomic formats as well as generic, easy to use tab-separated value format for user-provided annotations. Conclusions: ODG is a user-friendly database generation and query tool that adapts to the supplied data to produce a comparative genomic database or multi-layered annotation database. ODG provides rapid comparative genomic annotation and is therefore particularly useful for non-model or understudied species. For species for which more data are available, ODG can be used to conduct complex multi-omics, pattern-matching queries. © 2017 The Author(s).","Annotation; Comparative genomics; Data integration; Graph database; Non-model species","Database systems; Genes; Pattern matching; Query languages; Query processing; User interfaces; Annotated datasets; Annotation; Comparative genomic; Comparative genomics; Database generation; Graph database; Model species; Systemic integration; Data integration",2-s2.0-85027521412
"He N., Luo X., Zhao Z., Liao X.","Nondestructive Testing Method Based on Fiber Coupling and Coherent Detection",2017,"Guangxue Xuebao/Acta Optica Sinica",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031002905&doi=10.3788%2fAOS201737.0812006&partnerID=40&md5=9fe90cf820d215b8f01bd712cf8f6de4","A nondestructive laser detection method is proposed by combining the spatial laser injection into fibers with the coherent detection technique. The transmission characteristics of laser ultrasonic signals and the principle of coherent light detection are analyzed, and the signal processing and noise suppression methods in the nondestructive laser detection are discussed. The experimental system is established based on the laser excitation and detection where the laser injection and polarization-maintaining transmission are the cores, and the human-machine interactive system based on the graphical programming language LabVIEW is the monitoring way. The experimental results show that this system can reduce the influence of background light jitter on signal detection. By controlling the spot diameter and energy, one can obtain the reflection peaks of different ultrasonic signals. The sensitivity and smoothness of the ultrasonic echo signal detection on material defects are improved effectively. The testing method provides a new technique for engineering applications. © 2017, Chinese Lasers Press. All right reserved.","Coherent optical detection; Echo signal; Fiber coupling; Laser ultrasonic; Measurement; Nondestructive detection",,2-s2.0-85031002905
"Chen J., Zhang H., Zhu Z.","Coupled neutronic and thermal-hydraulic analysis of TMSR-SF1 at steady state",2017,"He Jishu/Nuclear Techniques",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032290458&doi=10.11889%2fj.0253-3219.2017.hjs.40.080603&partnerID=40&md5=0f85cb0ca20686c2f62c850cbf7e8617","Background: Neutronic and thermal-hydraulic simulations of advanced reactors can affect each other's results. Purpose:This study focuses on coupling neutronic and thermal-hydraulic simulations to achieve more accurate results for future developments of 10-MW solid-fueled thorium molten salt experimental reactor (TMSR-SF1). Methods: A program converting the MCNP (Monte Carlo N particle transport code) results to the spatial distribution of power density within the active region wascreated using C++ programming language. The spatial distribution data wereloaded into the ANSYS Fluent in the form of user-defined function (UDF) to accomplish the coupling of the two simulation processes. In regards of TMSR-SF's original design parameters, the physical and thermal-hydraulic models of the whole core wereestablished by using MCNP and ANSYS Fluent respectively. Results: The coupling method is feasible and can be used to obtain reliable results. The changes in coolant's temperature and velocity in the active region are dependent on the power density distribution. The changes in multiplication factor, power density and maximum of discrepancy in coolant temperature are 1.08%, 3.31% and 7.584 K, respectively. Conclusion: It is necessary to take the coupling effects of the reactor core into consideration in the design of associated reactor systems. In addition, the results confirm that the design parameters of the TMSR-SF1 are reasonable. © 2017, Science Press. All right reserved.","Fuel pebble; Neutronics and thermal-hydraulics coupling; Steady-state analysis; Thorium molten salt reactor",,2-s2.0-85032290458
"Li N., Huai W., Wang S.","The solution of target assignment problem in command and control decision-making behaviour simulation",2017,"Enterprise Information Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964507881&doi=10.1080%2f17517575.2016.1177207&partnerID=40&md5=d7b874e5fcdc8fddd23226894bf92f9c","C2 (command and control) has been understood to be a critical military component to meet an increasing demand for rapid information gathering and real-time decision-making in a dynamically changing battlefield environment. In this article, to improve a C2 behaviour model’s reusability and interoperability, a behaviour modelling framework was proposed to specify a C2 model’s internal modules and a set of interoperability interfaces based on the C-BML (coalition battle management language). WTA (weapon target assignment) is a typical C2 autonomous decision-making behaviour modelling problem. Different from most WTA problem descriptions, here sensors were considered to be available resources of detection and the relationship constraints between weapons and sensors were also taken into account, which brought it much closer to actual application. A modified differential evolution (MDE) algorithm was developed to solve this high-dimension optimisation problem and obtained an optimal assignment plan with high efficiency. In case study, we built a simulation system to validate the proposed C2 modelling framework and interoperability interface specification. Also, a new optimisation solution was used to solve the WTA problem efficiently and successfully. © 2016 Informa UK Limited, trading as Taylor & Francis Group.","decision-making behaviour simulation; high-dimension optimisation solution; modified differential evolution; parallel computing; Target assignment problem","C (programming language); Combinatorial optimization; Command and control systems; Decision making; Evolutionary algorithms; Interoperability; Military applications; Modeling languages; Optimization; Parallel processing systems; Reusability; Battlefield environments; Behaviour simulations; Coalition battle management languages; Modified differential evolution; Optimisations; Real time decision-making; Target assignments; Weapon-target assignment; Problem solving",2-s2.0-84964507881
"Konnerth S., Lobin G.","Models of e-Testing",2017,"MATEC Web of Conferences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028365558&doi=10.1051%2fmatecconf%2f201712112010&partnerID=40&md5=8c96cc6b4a7d4919d01575d635bbe382","Transdisciplinary interest and preoccupations regarding computer-Assisted instruction have stirred our urge to perform a thorough study of the field and trends as well as to uphold certain approaches that have emerged in specialized scientific research. We have decided to focus our analysis primarily on the assessment process as a part of computer-Assisted instruction; this in fact represents the major objective of our research, whereas the results of the experiments, performed in the context of the research projects undertaken, enabled us to set forth relevant conclusions about e-Testing. Our computer-Assisted assessment primarily includes tests with objective or semi-objective items, which inherently evince certain disadvantages specific to these items. Beginning with the year 2000 we succeeded to create such e-Tests for different examinations for basic mathematics; these e-Tests were used continuously in the last 17 years in different schools, especially for children with learning-problems. We also created e-Tests for vocabulary-Testing in language-instruction, which we applied at the University of Sibiu by student-evaluations but also in different activities with children of different ages. Some of these products were also published on different web-sites. We present these applications here, considering that they can be models for anyone, who wants to use the advantages of e-learning. © The Authors, published by EDP Sciences, 2017.",,"Computer aided analysis; E-learning; Education; Education computing; FORTH (programming language); Manufacture; Assessment process; Basic mathematics; Computer assisted assessment; Computer Assisted Instruction; Different ages; Learning problem; Scientific researches; Student evaluation; Computer aided instruction",2-s2.0-85028365558
"Borza S., Borza I.C.","Automated system for data acquisition and monitoring",2017,"MATEC Web of Conferences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028431286&doi=10.1051%2fmatecconf%2f201712104003&partnerID=40&md5=18dd0f7286f2ba287e546d7a02f56966","The Environmental management has become, with the development of human society a very important issue. There have been multiple systems that automatically monitors the environment. In this paper we propose a system that integrates GIS software and data acquisition software. In addition the proposed system implements new AHP multicriteria method that can get an answer online on each pollutant influence on limited geographical area in which the monitors. Factors pollutants of limited geographical areas are taken automatically by specific sensors through acquisition board. Labview software, with virtual instrument created by transferring them into a database Access. Access database they are taken up by software Geomedia Professional and processed using multi-criteria method AHP, so that at any moment, their influence on the environment and classify these influences, can be plotted on the screen monitoring system. The system allows, the automatic collection of data, the memorization and the generation of GIS elements. The research presented in this paper were aimed at implementing multi-criteria methods in GIS software. © The Authors, published by EDP Sciences, 2017.",,"Automation; Classification (of information); Computer programming languages; Data acquisition; Environmental management; Geographic information systems; Hierarchical systems; Manufacture; Pollution; Automated systems; Data acquisition softwares; Geographical area; Influence on the environments; Lab-view softwares; Monitoring system; Multi-criteria method; Virtual instrument; Monitoring",2-s2.0-85028431286
"Bani-Hani K.A., Abu Qamar M.I.","Artificial earthquake record generation using cascade neural network",2017,"MATEC Web of Conferences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028036459&doi=10.1051%2fmatecconf%2f201712001010&partnerID=40&md5=3405667cd6e8f811e5a1f9131ed4bc0d","This paper presents the results of using artificial neural networks (ANN) in an inverse mapping problem for earthquake accelerograms generation. This study comprises of two parts: 1-D site response analysis; performed for Dubai Emirate at UAE, where eight earthquakes records are selected and spectral matching are performed to match Dubai response spectrum using SeismoMatch software. Site classification of Dubai soil is being considered for two classes C and D based on shear wave velocity of soil profiles. Amplifications factors are estimated to quantify Dubai soil effect. Dubai's design response spectra are developed for site classes C & D according to International Buildings Code (IBC -2012). In the second part, ANN is employed to solve inverse mapping problem to generate time history earthquake record. Thirty earthquakes records and their design response spectrum with 5% damping are used to train two cascade forward backward neural networks (ANN1, ANN2). ANN1 is trained to map the design response spectrum to time history and ANN2 is trained to map time history records to the design response spectrum. Generalized time history earthquake records are generated using ANN1 for Dubai's site classes C and D, and ANN2 is used to evaluate the performance of ANN1. © The Authors, published by EDP Sciences, 2017.",,"Building materials; Earthquakes; Geophysics; Inverse problems; Mapping; Neural networks; Seismic response; Shear flow; Shear waves; Soils; Structural analysis; Sustainable development; Wave propagation; Artificial earthquake; Cascade neural networks; Design response spectrum; Earthquake records; Shear wave velocity; Site classification; Site response analysis; Time history records; C (programming language)",2-s2.0-85028036459
"Su S.-C., Yu C.-C., Lin C.-H.","Development of a web-based programming learning platform",2017,"2016 International Conference on Fuzzy Theory and Its Applications, iFuzzy 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030172032&doi=10.1109%2fiFUZZY.2016.8004936&partnerID=40&md5=c9b39de9bf2ff41742564389fff3ab6b","To most learners, programming language is not simple. In particular, when a large number of errors occur, teaching progress of courses will be affected, which leads to poor learning effectiveness. This study developed a web-based programming language teaching platform to solve this issue. © 2016 IEEE.",,"Computer programming languages; Education; Teaching; Websites; Learning effectiveness; Teaching platform; Web-based programming; E-learning",2-s2.0-85030172032
"Cholewa M.","Shannon information entropy as complexity metric of source code",2017,"Proceedings of the 24th International Conference on Mixed Design of Integrated Circuits and Systems, MIXDES 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030233321&doi=10.23919%2fMIXDES.2017.8005255&partnerID=40&md5=b52779d1369aecfcbc86d6acfb2c4411","This paper describes method, which allows comparing complexity of two or more source codes written in any programming language. The method is suitable to get the knowledge which programming language more compactly describes a given algorithm. In experiments carried out popular quick sort algorithm was analyzed. This algorithm was written in 10 most popular program languages and then complexity of source codes can be compared. The complexity is calculated using the Shannon entropy formula with statistics of syntactic units (e.g. keywords, literals, operators, etc.). All complexities was compared and discovered the source code (and hence language that generated this code) with lower entropy as optimal. The optimal source code will have smaller number of keywords, declarations, etc. compared to not optimized code. In practice, proposed approach allows to use another syntactic units (e.g. use more operators and less identifiers) to build an optimal source code according to minimization entropy rule. Proposed method is universal and can be applied to analysis of any source codes of computer programs. It should be noted that proposed measure does not take into consideration semantics of a programming language. © 2017 Department of Microelectronics and Computer Science, Lodz University of Technology.","complexity; Shannon entropy; software metric","Ada (programming language); Codes (symbols); Integrated circuits; Optimal systems; Semantics; Syntactics; complexity; Literals; Program language; Quick sorts; Shannon entropy; Shannon information entropy; Software metrices; Source codes; Computer programming languages",2-s2.0-85030233321
"Naumov V.","Optimizing the number of vehicles for a public bus line on the grounds of computer simulations",2017,"5th IEEE International Conference on Models and Technologies for Intelligent Transportation Systems, MT-ITS 2017 - Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030238004&doi=10.1109%2fMTITS.2017.8005661&partnerID=40&md5=9a60c3c0e637ce3c9a41e3c27e8fa65d","The paper presents an approach to estimate the optimal number of vehicles on public transport line; this approach is based on a simulation model of the process of servicing the bus line passengers. A problem of determining such a number of buses, that provides the minimum cost of transport at the maximum level of passenger service, is quite a complex issue due to the stochastic nature of the transport process and the random nature of the demand for trips of urban residents. An efficiency of a public bus line is proposed to be considered on the basis of the total operation costs of a bus line in terms of the interests of particular elements of the transport system-passengers as customers of public transport and public transport companies as providers of services. The author presents a class library implemented with the use of the Python programming language; on the basis of this library, the model simulating the process of the public transport line operation was developed. The results of the simulation experiment, based on the developed software, allowed the author to define the functional dependence between the total waiting time for bus passengers at bus stops and the characteristics of the public transport line. Using the obtained dependence, a formula for estimating the optimal number of vehicles on a public transport line was established as an argument, in which the function of the transport subsystem total cost reaches its extreme minimum. © 2017 IEEE.","computer simulations; number of vehicles; public transport line; Python programming","Bus terminals; Bus transportation; Buses; Computer programming; Computer simulation; Computer software; Costs; High level languages; Intelligent systems; Stochastic systems; Transportation; Urban transportation; Vehicles; Functional dependence; Number of vehicles; Public transport; Python programming; Python programming language; Total operation costs; Transport process; Transport subsystems; Intelligent vehicle highway systems",2-s2.0-85030238004
"Khazanov A.","Challenges and problems for interpretation of results for electrical resistance and direct current high voltage tests for high voltage rotating machines windings",2017,"2017 IEEE Electrical Insulation Conference, EIC 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030238433&doi=10.1109%2fEIC.2017.8004634&partnerID=40&md5=a95f1d461625e10cde833abd9bc37792","Insulation resistance and the direct current high voltage tests are in the industry use for a long period. The direct current high voltage test with measurement of the leakage current is essentially equivalent to the electrical resistance test just at the higher test voltage. At temperatures lower than 40°C the actual current related with test object could be in the order of few nano amperes (nA) already after few minutes. The slight instability of the high voltage source could induce the charge-discharge current that is comparable or higher than the test object related current. The not recognized instability of the high voltage power source could completely compromise the test results. The problem of very low leakage current measurements creates also distortion in the interpretation of the resistance dependence on temperature with the wrongful interpolation to the low temperatures. This article will discuss how to recognize the distortion of the test results related with interference from the power source. © 2017 IEEE.","direct current (DC) resistance; high voltage rotating machines (HVRM); leakage current","C (programming language); Electric resistance; Insulation; Leakage currents; Machine windings; Rotating machinery; Testing; Charge discharge current; Direct current; Direct-current-high-voltage; Electrical resistances; High voltage rotating machines; High-voltage power sources; Insulation resistance; Low-leakage current; HVDC power transmission",2-s2.0-85030238433
"Hudon C., Lévesque M., Essalihi M., Millet C.","Investigation of rotor hotspot temperature using Fiber Bragg Gratings",2017,"2017 IEEE Electrical Insulation Conference, EIC 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030256418&doi=10.1109%2fEIC.2017.8004671&partnerID=40&md5=aa3eae579086303518c96fe0d6296e15","Outward migration of the turn insulations of several poles was observed on every generators in one of Hydro-Québec's power plant and was attributed to thermomechanical stresses. The concern for these rotors is more related to consequences of such degradation and to decide what should be the next course of action considering that the units have been operating for just over thirty years out of 50 years of expected life. If shorted turns start to occur and cause magnetic, thermal or mechanical problems, this may lead to unplanned outage. A prudent alternative would be to re-insulate the poles from class-B to class-F insulation. However, since the actual hotspot temperature is not known and could be above the 155°C of maximum for class-F insulation, the problem could manifest itself again. Therefore, determination of the hotspot temperature was the primary goal of this investigation. Fiber Bragg Gratings (FBG) were used in conjunction with an optical rotating joint to carried out measurements of four of the poles of one unit in the plant. The results of this investigation are presented, highlighting the benefits of carrying localized on-line rotor temperature measurements. © 2017 IEEE.","fiber Bragg grating; poles; Rotor; temperature","Bragg gratings; C (programming language); Insulation; Poles; Rotors; Temperature; Temperature measurement; Course of action; Expected life; Hotspot temperature; Measurements of; Mechanical problems; Thermo-mechanical stress; Turn insulations; Unplanned outages; Fiber Bragg gratings",2-s2.0-85030256418
"Ingles R., Orlikowski M., Napieralski A.","A C++ shared-memory ring-buffer framework for large-scale data acquisition systems",2017,"Proceedings of the 24th International Conference on Mixed Design of Integrated Circuits and Systems, MIXDES 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030218631&doi=10.23919%2fMIXDES.2017.8005175&partnerID=40&md5=2c8a06157652175eb61367923921ada9","Large-Scale Data Acquisition Systems are an essential part in many scientific experiments, and the processing of the large amount of data, represents a challenge in designing systems capable of managing such volume of data. Owing to the nature of this type of experiments, the processes responsible for gathering the data from devices which measure real-world phenomena, and those processes in charge of distributing the data to monitoring and/or controlling systems, shall communicate with accuracy and reliability. By running those processes concurrently in a multi-processor computer system such requirements of accuracy and reliability can be achieved. In this paper, we present the design of a C++ framework which implements a ring-buffer by using shared-memory as a fast mechanism of data communication among processes. Likewise, the framework controls the access to data in the shared ringbuffer by implementing inter-process synchronization objects in shared-memory. The effectiveness of the proposed solution is evaluated by evaluating the latency time from when a new data is written into the shared ring-buffer and the longest instant when such a data is gathered. After the experimental test, the results show that it is possible to develop a C++ framework for helping programmers to create data acquisition system when a large-scale data-stream is involved, getting suitable performance by using shared-memory. © 2017 Department of Microelectronics and Computer Science, Lodz University of Technology.","atomic variables; condition variables; data acquisition system; futex; inter-process communication; large-scale; ring-buffer","C++ (programming language); Data acquisition; Human computer interaction; Integrated circuits; Memory architecture; Network function virtualization; atomic variables; condition variables; Data acquisition system; futex; Interprocess communication; large-scale; Monitoring",2-s2.0-85030218631
"Narczyk P., Siwiec K., Pleskacz W.A.","Temperature calibration technique based on on-chip resistor",2017,"Proceedings of the 24th International Conference on Mixed Design of Integrated Circuits and Systems, MIXDES 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030264400&doi=10.23919%2fMIXDES.2017.8005225&partnerID=40&md5=021f2420def6f7dc2fc743e48ffccc1a","A new temperature calibration technique based on on-chip resistor has been presented. Proposed method can be used in very wide temperature range. Temperature calibration technique was implemented in Python programing language in order to assess the suitability for practice use. The data for this model was obtained from process comers and Monte Carlo simulations. All analog blocks were designed in UMC CMOS 130 nm technology. © 2017 Department of Microelectronics and Computer Science, Lodz University of Technology.","130 nm; CMOS; Monte Carlo; Monte Carlo simulations; on-chip resistor; process corners; process corners simulations; Python model; temperature calibration","Calibration; CMOS integrated circuits; Computer software; High level languages; Intelligent systems; Resistors; 130 nm; Analog blocks; On-chip resistors; Temperature calibration; Wide temperature ranges; Monte Carlo methods",2-s2.0-85030264400
"Karam F.J., Monaghan C., Yoder P.J.","‘The students do not know why they are here’: education decision-making for Syrian refugees",2017,"Globalisation, Societies and Education",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987678773&doi=10.1080%2f14767724.2016.1222895&partnerID=40&md5=6e94930ddd3440cdf46ca838e37ae8a6","This case study, conducted collaboratively between education scholars and education practitioners, describes and analyses the ways in which Syrian refugee teachers and an NGO are developing and implementing non-formal education (NFE) programming in three refugee settlements in Lebanon. Utilising the INEE Minimum Standards for Education in Emergencies, we analyse teachers’ and programme administrators’ decision-making processes regarding curriculum, language of instruction, and pedagogy as well as how and why these decisions are made in the absence of a guiding framework or policy for NFE. We also consider the ways in which the nation-state writ large still helps to influence these decisions in the ‘global era’. © 2016 Informa UK Limited, trading as Taylor & Francis Group.","Education in emergencies; global education policy; globalisation; refugee education; schooling and migration",,2-s2.0-84987678773
"Jiang J.-Y., Cheng P.-J., Wang W.","Open source repository recommendation in social coding",2017,"SIGIR 2017 - Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029373984&doi=10.1145%2f3077136.3080753&partnerID=40&md5=80f0628c1f1412dbef10a928c60d65fb","Social coding and open source repositories have become more and more popular. Software developers have various alternatives to contribute themselves to the communities and collaborate with others. However, nowadays there is no effective recommender suggesting developers appropriate repositories in both the academia and the industry. Although existing one-class collaborative filtering (OCCF) approaches can be applied to this problem, they do not consider particular constraints of social coding such as the programming languages, which, to some extent, associate the repositories with the developers. The aim of this paper is to investigate the feasibility of leveraging user programming language preference to improve the performance of OCCF-based repository recommendation. Based on matrix factorization, we propose language-regularized matrix factorization (LRMF), which is regularized by the relationships between user programming language preferences. Extensive experiments have been conducted on the real-world dataset of GitHub. The results demonstrate that our framework significantly outperforms five competitive baselines. © 2017 ACM.","Manifold regularization; Open source repository; Repository recommendation; User programming language preference","Ada (programming language); Codes (symbols); Collaborative filtering; Computer programming languages; Factorization; Information retrieval; Matrix algebra; Manifold regularizations; Matrix factorizations; Open source repositories; Real-world; Repository recommendation; Software developer; User programming language preference; Open source software",2-s2.0-85029373984
"Mitra B., Diaz F., Craswell N.","Luandri: A clean lua interface to the indri search engine",2017,"SIGIR 2017 - Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029348397&doi=10.1145%2f3077136.3080650&partnerID=40&md5=2b083835365ad5079f261861f4cea347","In recent years, the information retrieval (IR) community has witnessed the first successful applications of deep neural network models to short-Text matching and ad-hoc retrieval tasks. However, the two communities-focused on deep neural networks and on IR-have less in common when it comes to the choice of programming languages. Indri, an indexing framework popularly used by the IR community, is written in C++, while Torch, a popular machine learning library for deep learning, is written in the light-weight scripting language Lua. To bridge this gap, we introduce Luandri (pronounced ""laundry""), a simple interface for exposing the search capabilities of Indri to Torch models implemented in Lua. © 2017 ACM.","Application programming interface; Information retrieval; Neural networks","Application programming interfaces (API); C++ (programming language); Computer systems programming; Deep learning; Information retrieval; Learning systems; Neural networks; Object oriented programming; Search engines; Ad-hoc retrieval tasks; Indexing framework; Light weight; Neural network model; Scripting languages; Search capabilities; Short texts; Deep neural networks",2-s2.0-85029348397
"Yuan Y., Lin D., Mishra A., Marwaha S., Alur R., Loo B.T.","Quantitative network monitoring with netqre",2017,"SIGCOMM 2017 -  Proceedings of the 2017 Conference of the ACM Special Interest Group on Data Communication",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029412555&doi=10.1145%2f3098822.3098830&partnerID=40&md5=19410b53220757df19fb42f2815a93c6","In network management today, dynamic updates are required for traffic engineering and for timely response to security threats. Decisions for such updates are based on monitoring network traffic to compute numerical quantities based on a variety of network and application-level performance metrics. Today's state-of-the-art tools lack programming abstractions that capture application or session-layer semantics, and thus require network operators to specify and reason about complex state machines and interactions across layers. To address this limitation, we present the design and implementation of NetQRE, a high-level declarative toolkit that aims to simplify the specification and implementation of such quantitative network policies. NetQRE integrates regular-expression-like pattern matching at flow-level as well as application-level payloads with aggregation operations such as sum and average counts. We describe a compiler for NetQRE that automatically generates an efficient implementation with low memory footprint. Our evaluation results demonstrate that NetQRE allows natural specification of a wide range of quantitative network tasks ranging from detecting security attacks to enforcing application-layer network management policies. NetQRE results in high performance that is comparable with optimized manually-written low-level code and is significantly more efficient than alternative solutions, and can provide timely enforcement of network policies that require quantitative network monitoring. © 2017 ACM.","NetQRE; Network monitoring language; Quantitative regular expression","Computer programming; Computer programming languages; Convolutional codes; Network layers; Network management; Pattern matching; Semantics; Specifications; Application layer network; Application-level performance; Design and implementations; Efficient implementation; NetQRE; Network Monitoring; Programming abstractions; Regular expressions; Computer systems programming",2-s2.0-85029412555
"Xu Z.G., Shen W.D., Yang D.Y., Liu W.M.","Parametric Design and Mechanical Analysis of Beams based on SINOVATION",2017,"IOP Conference Series: Materials Science and Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028028300&doi=10.1088%2f1757-899X%2f224%2f1%2f012024&partnerID=40&md5=e153dcfdbe6f6d7557d799ba61f62abe","In engineering practice, engineer needs to carry out complicated calculation when the loads on the beam are complex. The processes of analysis and calculation take a lot of time and the results are unreliable. So VS2005 and ADK are used to develop a software for beams design based on the 3D CAD software SINOVATION with C ++ programming language. The software can realize the mechanical analysis and parameterized design of various types of beams and output the report of design in HTML format. Efficiency and reliability of design of beams are improved. © Published under licence by IOP Publishing Ltd.",,"C++ (programming language); Computer programming; Computer software; 3-d cads; Analysis and calculations; Efficiency and reliability; Engineering practices; Mechanical analysis; Parameterized design; Parametric design; Computer aided design",2-s2.0-85028028300
"Ushiku A., Mori S., Tsuruoka Y., Kameko H.","Game state retrieval with keyword queries",2017,"SIGIR 2017 - Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029367442&doi=10.1145%2f3077136.3080668&partnerID=40&md5=5cc87f791c5cfc1e3bd6227249286ed5","There are many databases of game records available online. In order to retrieve a game state from such a database, users usually need to specify the target state in a domain-specific language, which may be difficult to learn for novice users. In this work, we propose a search system that allows users to retrieve game states from a game record database by us-ing keywords. In our approach, we first train a neural net-work model for symbol grounding using a small number of pairs of a game state and a commentary on it. We then apply it to all the states in the database to associate each of them with characteristic terms and their scores. The en-hanced database thus enables users to search for a state us-ing keywords. To evaluate the performance of the proposed method, we conducted experiments of game state retrieval using game records of Shogi (Japanese chess) with commen-Taries. The results demonstrate that our approach gives sig-nicantly better results than full-Text search and an LSTM language model. © 2017 Copyright held by the owner/author(s).","Search of Nonlinguistic Data; Shogi; Symbol Grounding","Computer programming languages; Information retrieval; Natural language processing systems; Problem oriented languages; Domain specific languages; Full-text search; Japanese chess; Keyword queries; Language model; Search of Nonlinguistic Data; Shogi; Symbol grounding; Database systems",2-s2.0-85029367442
"Bonelli N., Giordano S., Procissi G.","A pipeline functional language for stateful packet processing",2017,"2017 IEEE Conference on Network Softwarization: Softwarization Sustaining a Hyper-Connected World: en Route to 5G, NetSoft 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029349502&doi=10.1109%2fNETSOFT.2017.8004226&partnerID=40&md5=fad324c604dbdf99637af5b58b4951e4","The evolution of commodity PCs towards multi-core processing platforms equipped with high-speed network interfaces makes them reasonable and cost effective targets for the implementation of generic network functions. In addition, the availability of software accelerated I/O frameworks provides a convenient ground for running a broad variety of applications, from simple software switches to more complex network systems, with near hardware-class performance and the flexibility of a software approach. Most network functions can be implemented by composing a set of elementary operations into processing pipelines to be run on top of multiple processing cores. In this framework, maintaining the flow consistency is crucial to enable stateful operations in the processing pipelines. This paper presents Enif-Lang, a functional language for programming network pipelines specifically targeted at multi-core scenarios. In addition to a large set of functions for generic packet manipulation, filtering, steering and state management, the framework is built upon an abstract model that provides state aware packet splitting to prevent inter-state sharing and enable consistent stateful parallel processing on-top-of multi-core architectures. © 2017 IEEE.",,"Application programs; Complex networks; Computer architecture; Cost effectiveness; Functional programming; HIgh speed networks; Network function virtualization; Personal computers; Pipeline processing systems; Pipelines; Transfer functions; Abstract modeling; Complex network systems; Elementary operations; Functional languages; Multi-core processing; Multicore architectures; Multiple processing cores; Parallel processing; Multicore programming",2-s2.0-85029349502
"Narayana S., Sivaraman A., Nathan V., Goyal P., Arun V., Alizadeh M., Jeyakumar V., Kim C.","Language-directed hardware design for network performance monitoring",2017,"SIGCOMM 2017 -  Proceedings of the 2017 Conference of the ACM Special Interest Group on Data Communication",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029441157&doi=10.1145%2f3098822.3098829&partnerID=40&md5=6ffc2cade9067ead5a71b8b8b8a28ce2","Network performance monitoring today is restricted by existing switch support for measurement, forcing operators to rely heavily on endpoints with poor visibility into the network core. Switch vendors have added progressively more monitoring features to switches, but the current trajectory of adding specific features is unsustainable given the ever-changing demands of network operators. Instead, we ask what switch hardware primitives are required to support an expressive language of network performance questions. We believe that the resulting switch hardware design could address a wide variety of current and future performance monitoring needs. We present a performance query language, Marple, modeled on familiar functional constructs like map, filter, groupby, and zip. Marple is backed by a new programmable key-value store primitive on switch hardware. The key-value store performs flexible aggregations at line rate (e.g., a moving average of queueing latencies per flow), and scales to millions of keys. We present a Marple compiler that targets a P4-programmable software switch and a simulator for highspeed programmable switches. Marple can express switch queries that could previously run only on end hosts, while Marple queries only occupy a modest fraction of a switch's hardware resources. © 2017 ACM.","Network hardware; Network measurement; Network programming","Computer programming; Computer software; Convolutional codes; Network performance; Program compilers; Query languages; Query processing; Flexible aggregation; Future performance; Hardware resources; Network measurement; Network performance monitoring; Network programming; Programmable software; Programmable switches; Hardware",2-s2.0-85029441157
"Zaostrovnykh A., Pirelli S., Pedrosa L., Argyraki K., Candea G.","A formally verified nat",2017,"SIGCOMM 2017 -  Proceedings of the 2017 Conference of the ACM Special Interest Group on Data Communication",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029427951&doi=10.1145%2f3098822.3098833&partnerID=40&md5=57c3fdb01be18413c379aab0868a92f8","We present a Network Address Translator (NAT) written in C and proven to be semantically correct according to RFC 3022, as well as crash-free and memory-safe. There exists a lot of recent work on network verification, but it mostly assumes models of network functions and proves properties specific to network configuration, such as reachability and absence of loops. Our proof applies directly to the C code of a network function, and it demonstrates the absence of implementation bugs. Prior work argued that this is not feasible (i.e., that verifying a real, stateful network function written in C does not scale) but we demonstrate otherwise: NAT is one of the most popular network functions and maintains per-flow state that needs to be properly updated and expired, which is a typical source of verification challenges.We tackle the scalability challenge with a new combination of symbolic execution and proof checking using separation logic; this combination matcheswell the typical structure of a network function. We then demonstrate that formally proven correctness in this case does not come at the cost of performance. The NAT code, proof toolchain, and proofs are available at [58]. © 2017 ACM.","Lazy Proofs; Network-Function Verification; Symbolic Execution","Convolutional codes; Model checking; Network function virtualization; Source separation; Transfer functions; Lazy Proofs; Network address translators; Network configuration; Network functions; Per-flow state; Separation logic; Symbolic execution; Typical structures; C (programming language)",2-s2.0-85029427951
"Wilhelm-Stein T., Kahl S., Eibl M.","Teaching the information retrieval process using a web-based environment and game mechanics",2017,"SIGIR 2017 - Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029353860&doi=10.1145%2f3077136.3084143&partnerID=40&md5=6bd9a7a29e87b4da47acf6f3b158dc58","Predicting the performance of individual components of information retrieval systems, in particular the complex interactions between those components, is still challenging. Therefore, professionals are needed for the implementation and configuration of retrieval systems and retrieval components. Our web-based application, called Xtrieval Web Lab, enables newcomers and learners to gain practical knowledge about the information retrieval process. They can arrange a multitude of components of retrieval systems and evaluate them with real world data without utilizing a programming language. Game mechanics guide the learners in their discovery process and motivate them. © 2017 ACM.","Evaluation; Game mechanics; Information retrieval; Software-based teaching environment","E-learning; Information retrieval; Information retrieval systems; Mechanics; Websites; Evaluation; Individual components; Real-world; Retrieval systems; Web-based applications; Web-based environment; Search engines",2-s2.0-85029353860
"Schnepf N., Badonnel R., Lahmadi A., Merz S.","Automated verification of security chains in software-defined networks with synaptic",2017,"2017 IEEE Conference on Network Softwarization: Softwarization Sustaining a Hyper-Connected World: en Route to 5G, NetSoft 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029355007&doi=10.1109%2fNETSOFT.2017.8004195&partnerID=40&md5=dd89ebcbe8bdbcf9d482d8e3512bf83c","Software-defined networks provide new facilities for deploying security mechanisms dynamically. In particular, it is possible to build and adjust security chains to protect the infrastructures, by combining different security functions, such as firewalls, intrusion detection systems and services for preventing data leakage. It is important to ensure that these security chains, in view of their complexity and dynamics, are consistent and do not include security violations. We propose in this paper an automated strategy for supporting the verification of security chains in software-defined networks. It relies on an architecture integrating formal verification methods for checking both the control and data planes of these chains, before their deployment. We describe algorithms for translating specifications of security chains into formal models that can then be verified by SMT1 solving or model checking. Our solution is prototyped as a package, named Synaptic, built as an extension of the Frenetic family of SDN programming languages. The performances of our approach are evaluated through extensive experimentations based on the CVC4, veriT, and nuXmv checkers. © 2017 IEEE.","Formal Verification; Security Management; Software-Defined Networking","Chains; Computer system firewalls; Computer viruses; Formal methods; Formal verification; Intrusion detection; Model checking; Software defined networking; Verification; Automated verification; Formal verification methods; Intrusion Detection Systems; New facilities; Security functions; Security management; Security mechanism; Security violations; Network security",2-s2.0-85029355007
"Gołda G., Kampa A.","Manipulation and handling processes off-line programming and optimization with use of K-Roset",2017,"IOP Conference Series: Materials Science and Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027986617&doi=10.1088%2f1757-899X%2f227%2f1%2f012050&partnerID=40&md5=800274237116f05c7ebcc5f3bc82515e","Contemporary trends in development of efficient, flexible manufacturing systems require practical implementation of modern ""Lean production"" concepts for maximizing customer value through minimizing all wastes in manufacturing and logistics processes. Every FMS is built on the basis of automated and robotized production cells. Except flexible CNC machine tools and other equipments, the industrial robots are primary elements of the system. In the studies, authors look for wastes of time and cost in real tasks of robots, during manipulation processes. According to aspiration for optimization of handling and manipulation processes with use of the robots, the application of modern off-line programming methods and computer simulation, is the best solution and it is only way to minimize unnecessary movements and other instructions. The modelling process of robotized production cell and offline programming of Kawasaki robots in AS-Language will be described. The simulation of robotized workstation will be realized with use of virtual reality software K-Roset. Authors show the process of industrial robot's programs improvement and optimization in terms of minimizing the number of useless manipulator movements and unnecessary instructions. This is realized in order to shorten the time of production cycles. This will also reduce costs of handling, manipulations and technological process. © Published under licence by IOP Publishing Ltd.",,"Computer control systems; Computer programming; Computer software; Flexible manufacturing systems; Industrial manipulators; Industrial robots; Machine tools; Manipulators; Manufacture; Modeling languages; Robots; Virtual reality; CNC machine tools; Handling process; Logistics process; Minimizing the number of; Modelling process; Off line programming; Robotized production; Technological process; Robot programming",2-s2.0-85027986617
"Xiao Y.-P., Gao C., Wang T., Zhou L.","Carrier selective contacts: a selection of high efficiency silicon solar cells",2017,"Wuli Xuebao/Acta Physica Sinica",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031309916&doi=10.7498%2faps.66.158801&partnerID=40&md5=28572539a9316eb7d09169e15d84604c","Solar cell has two basic units: the photon absorption layer and the contact layer. The contact layer is a region between the highly recombination-active metal interface and the photon absorption layer. It is vital to reduce the recombination loss between the photon absorption layer and the contact layer in pursuit of the higher conversion efficiency of silicon solar cell. In recent years, carrier selective contact is arousing research interest in photovoltaic industry because it is deemed as one of the last remaining obstacles in approaching to the theoretical efficiency limit of silicon solar cell. In this paper, three different types of carrier selective contacts are analyzed, which includes: 1) sandwiching a heavily doped thin layer between the photon absorption layer and the metal interface, which is the so-called emitter or back surface field; 2) aligning the conduction bands or the valence bands of two materials; 3) inducing the band bending through a high work function metal oxide contacting crystalline silicon. Based on one-dimensional solar cell simulation software wxAMPS, three different silicon solar cell structures are numerically simulated, which includes: 1) diffused homojunction silicon solar cell [(p+)c-Si/(n)c-Si/(n+)c-Si]; 2) silicon heterojunction solar cell with amorphous silicon thin films [(p+)a-Si/(i)a-Si/(n)c-Si/(i)a-Si/(n+)a-Si]; 3) silicon heterojunction solar cell with metal oxide thin films [(n)MoOx/(n)c-Si/(n)TiOx], then the energy band structures and the spatial distributions of carrier concentrations of solar cells in the dark are discussed. The simulation results show that the key factor of carrier selective contacts is the asymmetric spatial distribution of the carrier concentrations, i.e. the asymmetric conductivities of electrons and holes. This leads to the formation of high resistance to electrons and low resistance to holes, or high resistance to holes and low resistance to electrons, so the holes will go through the contact easily and the electrons will be blocked simultaneously, or the electrons will go through the contact easily and the holes will be blocked simultaneously. Therefore a hole selective contact or a electron selective contact is formed, respectively. © 2017 Chinese Physical Society.","Asymmetric conductivity; Carrier selective contact; Silicon solar cell","Amorphous films; Amorphous silicon; Band structure; C (programming language); Carrier concentration; Computer software; Contacts (fluid mechanics); Electrons; Heterojunctions; Interfaces (materials); Metallic compounds; Metals; Molybdenum oxide; Oxide films; Photons; Photovoltaic cells; Silicon; Solar cells; Solar power generation; Spatial distribution; Thin films; Amorphous silicon thin films; High efficiency silicon solar cells; High-work-function metal; Metal oxide thin films; Photon absorption layers; Selective contacts; Silicon heterojunctions; Solar cell simulation; Silicon solar cells",2-s2.0-85031309916
"Yang W.Z., Jiao Y., Jia Y.Q.","Ecological stoichiometry of C, N and P on different time enclosed in desertification steppe soil",2017,"IOP Conference Series: Earth and Environmental Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027977408&doi=10.1088%2f1755-1315%2f81%2f1%2f012112&partnerID=40&md5=57b83e44229f217010d13be1d93d9ca8","It is the research object for the ecological stoichiometry of C, N and P on the different time of desertification grasslands enclosed and grazing grassland in Taibusi country of the Inner Mongolia, China. Through the measurement and analysis on ecological stoichiometric ratio of C, N and P in soil, the time of desertification grassland enclosed is determined. There are 13 soil of desertification grassland with different en-closure time, and 1 soil of grazing grassland. They are analyzed for the soil organic carbon, total nitro-gen, total phosphorus content and their density. The C/N of soil were increased with the extension of the time of desertification grassland enclosed. To 22 years enclosed, the C/N of grassland desertification soil enclosed is greater than the soil of grazing grassland that is 17. After the desertification grassland is en-closed, the C/N of soil is 13, and it is accumulated to maximum for C and N, and The grazing period is the best. © Published under licence by IOP Publishing Ltd.",,"Carbon; Climatology; Ecology; Environmental engineering; Environmental technology; Organic carbon; Soils; Stoichiometry; Ecological stoichiometry; Grassland desertification; Inner Mongolia; Measurement and analysis; Research object; Soil organic carbon; Stoichiometric ratio; Total phosphorus; C (programming language)",2-s2.0-85027977408
"Oanta E., Raicu A., Panait C.","Ideas for the rapid development of the structural models in mechanical engineering",2017,"IOP Conference Series: Materials Science and Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027961366&doi=10.1088%2f1757-899X%2f227%2f1%2f012084&partnerID=40&md5=209e7b9c96c70e4c8eafde2e8a497347","Conceiving computer based instruments is a long run concern of the authors. Some of the original solutions are: optimal processing of the large matrices, interfaces between the programming languages, approximation theory using spline functions, numerical programming increased accuracy based on the extended arbitrary precision libraries. For the rapid development of the models we identified the following directions: atomization, 'librarization', parameterization, automatization and integration. Each of these directions has some particular aspects if we approach mechanical design problems or software development. Atomization means a thorough top-down decomposition analysis which offers an insight regarding the basic features of the phenomenon. Creation of libraries of reusable mechanical parts and libraries of programs (data types, functions) save time, cost and effort when a new model must be conceived. Parameterization leads to flexible definition of the mechanical parts, the values of the parameters being changed either using a dimensioning program or in accord to other parts belonging to the same assembly. The resulting templates may be also included in libraries. Original software applications are useful for the model's input data generation, to input the data into CAD/FEA commercial applications and for the data integration of the various types of studies included in the same project. © Published under licence by IOP Publishing Ltd.",,"Application programs; Atomization; Computer aided design; Computer software reusability; Libraries; Software design; Arbitrary precision; Commercial applications; Computer-based instruments; Decomposition analysis; Flexible definition; Numerical programming; Optimal processing; Software applications; Data integration",2-s2.0-85027961366
"Castro I., Martin K., Vazquez A., Arias M., Lamar D.G., Sebastian J.","An ac-dc PFC single-stage Dual Inductor Current-Fed Push-Pull for HB-LED lighting applications",2017,"IEEE Journal of Emerging and Selected Topics in Power Electronics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028918235&doi=10.1109%2fJESTPE.2017.2736250&partnerID=40&md5=5f8c35bc19ccd508f136896dc00ebc40","An ac-dc single-stage driver for High Brightness Light-Emitting Diodes with galvanic isolation is presented in this paper. The driver is based on a Dual Inductor Current-Fed Push-Pull converter with each inductor operating in Boundary Conduction Mode. The interleaving between the two inductors enables the converter to reduce the high input current ripple inherent to a BCM. Moreover, it is fully compliant with IEC 1000-3-2 Class C and it is able to achieve a high Power Factor. Its low component count, simplicity and overall outstanding characteristics make this current-fed topology suitable for medium power range HB-LED drivers in low cost applications. The proposed topology has been tested on a 100W prototype for the full range of the US single-phase line voltage, feeding several HB-LED strings, with an output voltage equivalent to 48V at full load. The prototype achieves a maximum efficiency of 92&#x0025; with a 0.99 power factor, 8&#x0025; THD at full load while guaranteeing good quality light. IEEE","ac-dc power conversion; Demagnetization; HB-LED driver; Inductors; Lighting; Magnetic domains; Magnetic switching; Power Factor Correction; Single phase; Switches; Topology","C (programming language); Demagnetization; Electric inductors; Lighting; Magnetic domains; Power converters; Rectifying circuits; Switches; Topology; Ac-dc power conversion; LED drivers; Magnetic switching; Power factor corrections; Single phase; Light emitting diodes",2-s2.0-85028918235
"Mei Z., Peng Z., Zhang X.","Optimal dynamic weapon-target assignment based on receding horizon control heuristic",2017,"IEEE International Conference on Control and Automation, ICCA",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029898170&doi=10.1109%2fICCA.2017.8003176&partnerID=40&md5=bb6133d4aef3a0062e411aae76e8a365","In this paper, we establish a Dynamic Weapon-Target Assignment (DWTA) model based on the killing region of weapon platform. The model considers the time window constraint, intercept feasibility constraint and guidance constraint, which can guarantee the rationality of the solution and is consistent with the real combat scenario. We propose a combinatorial algorithm derived from heuristic algorithm and Receding Horizon Control (RHC), and the algorithm using the domain knowledge can be calculated directly to get the assignment results and determine the weapons' firing time. The advantage is that it makes decisions rapidly and deals with dynamic events timely which appear in distribution process without a great deal of iterative calculations. The algorithm is mainly focused on solving real-time and dynamic problems in DWTA. Experimental verification part, we simulate the combat process in C++, use timer to update real-time target and weapon status information, solve the fire distribution results regularly, and insert random dynamic situation in the process of code running. Experimental results show that the proposed model and algorithm can solve the DWTA problem quickly and effectively. © 2017 IEEE.",,"C++ (programming language); Computer software; Heuristic algorithms; Combinatorial algorithm; Distribution process; Experimental verification; Iterative calculation; Model and algorithms; Receding horizon control; Time window constraint; Weapon-target assignment; Iterative methods",2-s2.0-85029898170
"Süzer A.E., Oktal H.","PRN code correlation in GPS receiver",2017,"Proceedings of 8th International Conference on Recent Advances in Space Technologies, RAST 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030258049&doi=10.1109%2fRAST.2017.8002960&partnerID=40&md5=e2dca744fc86effe91dda03f276dc34c","Satellite based positioning systems like GPS (Global Positioning System) exist in every moment of our lives. GPS signal is broadcasted by Link1 (L1) and Link2 (L2) frequencies, separately. L1 is assigned to civil users, while L2 is especially for military users. GPS signal consists of navigation message and PRN codes (C/A for civil and P-code for military) which is an identity for satellite. PRN codes are also used to determine the range between the satellite and the receiver. The navigation message added on PRN code, must be known to find the position of GPS receiver on Earth. Identification of PRN code is the most important process to calculate the receiver's position. A correlation process in receiver is implemented to find PRN code changing for each satellite. Three common methods are available for the correlation process. These methods are Serial Search, Parallel Frequency Space Search and Parallel Code Phase Search Acquisition. Parallel Code Phase Search is faster and ended in less steps compared to other two methods. The aim of this study is to present the correlation technics used for the acquisition of satellite signal in GPS receivers. For this purpose, a correlation example is simulated in MATLAB environment to demonstrate how the correlation process in GPS receiver is performed. © 2017 IEEE.","acqusition; correlation; GPS signal; Matlab; PRN code","C (programming language); Codes (symbols); Correlation methods; MATLAB; Phase space methods; Satellites; Signal processing; Signal receivers; acqusition; Gps (global positioning system); GPS signals; MATLAB environment; Navigation messages; Positioning system; PRN code; Satellite signals; Global positioning system",2-s2.0-85030258049
"Wang D., Pan Q., Hu J., Zhao C., Xu Z., Lan H.","VMS real-time distributed simulation system design",2017,"IEEE International Conference on Control and Automation, ICCA",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029910015&doi=10.1109%2fICCA.2017.8003207&partnerID=40&md5=f8ec25cf159d0a45562f11d1fc06df81","Vehicle Management System (VMS) is onboard real-time network, which ensures the flight safety and economy by scheduling and managing the onboard resources. With the help of computers, local area network (LAN), simulation software and real-time operation system, we build a distributed computer simulation platform to simulate this onboard network. In this paper, we present a Simulink/RTX/Reflective memory card-based design solution for VMS distributed simulation platform, which is discussed at length in the two aspects of software design and hardware network establishment. We use the Rapid Control Prototyping (RCP) solution to model VMS in Simulink and generate real-time C code for RTX operation system. We realize the inter-process communication (IPC) and synchronization by shared memory mechanism. The reflective memory (RFM) is used to build a network for communication and synchronization among computer cluster. We test and validate this system by simulating the whole flight process of an airfreighter with real aerodynamic parameters. The simulation results show every module in this simulation system works normally. It meets the engineering need in practice. © 2017 IEEE.",,"C (programming language); Computer software; Local area networks; Scheduling; Software design; Systems analysis; Communication and synchronizations; Distributed computer simulation; Interprocess communication; Local area networks (LAN); Rapid control prototyping; Real time operation system; Real-time distributed simulation; Vehicle management systems; Distributed computer systems",2-s2.0-85029910015
"Ali A.M., Tumian A., Seman M.S.A.","A conceptual approach for understanding computer programming skills development",2017,"International Conference on Research and Innovation in Information Systems, ICRIIS",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029912919&doi=10.1109%2fICRIIS.2017.8002526&partnerID=40&md5=76a4de9d1e28d964d07b487433e7e376","This paper highlights the relevant curricular and pedagogical ideas on how to evaluate students in learning computer programming. It explores the literature in the area of programming skills development towards constructive alignment in outcome-based education. Research on teaching computer programming has led to numerous practices, instructional theories, and empirical results for computer science pedagogy. The change towards constructivism seems promising in establishing a systematic computer programming skills development in the future. Three main areas that affect students learning computer programming are teaching approach, computer programming language selection, and programming development environment. The outcome of this paper is a conceptual approach that covers (1) the teaching and learning alignment as unit of analysis (2) a holistic approach on how programming skills are developed, (3) an emphasis on activities and (4) the importance of providing guidelines for lecturers. © 2017 IEEE.","Constructive alignment; Programming languages; Programming skills development; Teaching programming approaches","Computer programming languages; Education; Information systems; Metadata; Teaching; Computer programming skills; Conceptual approaches; Constructive alignments; Outcome-based education; Programming development environment; Programming skills; Teaching and learning; Teaching programming; Computer programming",2-s2.0-85029912919
"Chiriaco V., Franzen A., Thayil R., Zhang X.","Finding partial hash collisions by brute force parallel programming",2017,"2017 IEEE Long Island Systems, Applications and Technology Conference, LISAT 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028593684&doi=10.1109%2fLISAT.2017.8001964&partnerID=40&md5=eb1deced2fdc605e75fc41a45df0f77f","A hash function hashes a longer message of arbitrary length into a much shorter bit string of fixed length, called a hash. Inevitably, there will be a lot of different messages being hashed to the same or similar hash. We call this a hash collision or a partial hash collision. By utilizing multiple processors from the CUNY High Performance Computing Center's clusters, we can locate partial collisions for the hash functions MD5 and SHA1 by brute force parallel programming in C with MPI library. The brute force method of finding a second preimage collision entails systematically computing all of the permutations, hashes, and Hamming distances of the target preimage. We explore varying size target strings and the number of processors allocation to examine the effect these variables have on finding partial collisions. The results show that for the same message space the search time for the partial collisions is roughly halved for each doubling of the number of processors; the longer the message is the better partial collisions are produced. © 2017 IEEE.","brute force; high performance computing; MD5; MPI; parallel programming; Partial hash collision; SHA1","Hamming distance; Hash functions; Parallel processing systems; Parallel programming; Brute force; Hash collisions; High performance computing; Message space; Mpi libraries; Multiple processors; Processors allocation; SHA1; C (programming language)",2-s2.0-85028593684
"Zhang C., Guo S.","Error compensation model considering tool wear in milling difficult to cut materials",2017,"International Journal of Computer Integrated Manufacturing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978942587&doi=10.1080%2f0951192X.2016.1210232&partnerID=40&md5=594e5c54db4f52290aca2b0f17d17d2b","In this paper, error compensation considering tool wear is studied to improve machining precision of difficult-to-cut material in milling process. First, an error model considering tool wear in milling process is established based on the relationship between the position angle and the radius of the section circle of ball-end milling cutter, and the established error model is solved and verified. Then, based on the verified error model, a new error compensation method based on a scale division idea is proposed to determine the required compensation value and generate the compensated tool path by tracing the initial tool path and tool wear deviations. Based on the above error compensation method, the detailed compensated processes for a plane, cylindrical surface and sculptured surface are analysed and an off-line error compensation software is developed by using Visual C++ programming tool. Finally, experimental tests performed with stainless steel 1Cr18Ni9Ti and cemented carbide cutters, are used to validate the reliability of the proposed error compensation method in milling operations. Experimental results show that the proposed error compensation method can reduce machining error and improve machining surface quality. © 2016 Informa UK Limited, trading as Taylor & Francis Group.","advanced manufacturing process; error compensation; metal cutting; modelling; tool path modification; tool wear","Ball milling; C++ (programming language); Carbide cutting tools; Carbides; Computer programming; Computer software; Cutting; Error compensation; Errors; Metal cutting; Milling (machining); Milling cutters; Models; Stainless steel; Wear of materials; Advanced manufacturing; Ball-end milling cutters; Difficult-to-cut materials; Error compensation methods; Stainless steel 1Cr18Ni9Ti; Tool path modification; Tool wear; Visual C++ programming; Cutting tools",2-s2.0-84978942587
"Mirez J.","A modeling and simulation of optimized interconnection between DC microgrids with novel strategies of voltage, power and control",2017,"2017 IEEE 2nd International Conference on Direct Current Microgrids, ICDCM 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028638078&doi=10.1109%2fICDCM.2017.8001098&partnerID=40&md5=e7456b3b89c1b15c7b9083170916c92e","The interconnection between DC microgrids has been studied through the modeling and simulation of two DC microgrids and utility network with independent connection to each microgrid. Each microgrid has generation sources, storage source, electrical charges, two points of common coupling (one with the utility network and other with the neighboring microgrid) and a central controller. By performing the simulations and searching for new ways in which the interconnection can be made, the following contributions are reached: (a) although a nominal voltage is present on the DC microgrid bus, it becomes necessary to have three mini-voltage scales (one for the micro-sources, another for the storage sources and a third for AC/DC converter output that connects the utility supply and DC microgrid bus); (b) the power to avoid being heavily dependent on random variables requires temporary storage at the generation sources and that electrical loads define a very stable demand and clearance for certain period of time (of a few minutes), said period would be a new time scale of microgrid operation; (c) the cost associated with generation and storage sources must be optimized for the microgrids operation on the new unit of measurement and for which linear programming techniques have been used, and (d) it representing new coordination actions for tertiary control among central controllers of the microgrids. The new strategies of control, voltage and power will serve to propose and study new designs of: topologies of the electrical network, interconnection devices between microredes and other topics. © 2017 IEEE.","control; DC; microgrid; operation; optimization","C (programming language); Control; Controllers; Linear programming; Optimization; Power control; Rectifying circuits; Voltage scaling; Coordination action; Electrical networks; Interconnection devices; Linear programming techniques; Micro grid; Microgrid operations; Model and simulation; operation; Electric power system interconnection",2-s2.0-85028638078
"Aiello G., Cacciato M., Scarcella G., Scelba G.","Failure analysis of AC motor drives via FPGA-based hardware-in-the-loop simulations",2017,"Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026805768&doi=10.1007%2fs00202-017-0630-3&partnerID=40&md5=e68547b6369c956ece3135a84146bdb1","The paper deals with an extensive analysis of power converters failures in AC motor drives by exploiting the capability of a hardware-in-the-loop (HIL) simulation platform to emulate the real-time behavior of electrical machines and power converters. In this way it is possible to investigate the effects of power converter faults in electrical drives with the aim to propose solutions that allow to reduce the periods of drives inoperability. In this paper, a suitable realization of a test bench combining an embedded system based on a FPGA board with a high-level graphical programming language is proposed to replace part of the electrical drive hardware. Differently than standard approaches for FPGA programming, which are normally based on hardware description languages, the proposed solution exploits an environment software platform with a high level of abstraction that leads to a good trade-off between accuracy and hardware resources, also allowing a faster prototyping procedure. The proposed HIL solution has been used to study some common faults occurring in power converters, evaluating the behavior of a standard drive operating with different control algorithms. © 2017 Springer-Verlag GmbH Germany","Advanced simulation platform; FPGA; Hardware in the loop; Motor control; Motor drive simulator; power converters","Computer graphics; Computer hardware description languages; Drives; Economic and social effects; Electric drives; Electric motors; Embedded systems; Field programmable gate arrays (FPGA); Hardware; High level languages; Power converters; Synthetic apertures; Advanced simulation; Graphical programming language; Hard-ware-in-the-loop; Hardware-in-the-loop simulation; High level of abstraction; Motor control; Motor drive; Software platforms; AC motors",2-s2.0-85026805768
"Mirza O.M., Joy M., Cosma G.","Style Analysis for Source Code Plagiarism Detection - An Analysis of a Dataset of Student Coursework",2017,"Proceedings - IEEE 17th International Conference on Advanced Learning Technologies, ICALT 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030218680&doi=10.1109%2fICALT.2017.117&partnerID=40&md5=b909bb201c47854d696e4d84f2ae2ed3","Plagiarism has become an increasing problem in higher education in recent years. Coding style can be used to detect source code plagiarism that involves writing and deciding the structure of the code which does not affect the logic of a program, thus offering a way to differentiate between different code authors. This paper focuses to identify whether a data set consisting of student programming assignments is rich enough to apply coding style metrics to detect similarities between code sequences, and we use the BlackBox dataset as a case study. © 2017 IEEE.","Coding Style; Source Code Plagairism Detection; Style Analysis","Computer programming languages; Education; Intellectual property; Code sequences; Coding Style; Higher education; Programming assignments; Source code plagiarisms; Source codes; Student coursework; Style Analysis; Codes (symbols)",2-s2.0-85030218680
"Jamil H.M.","Automated Personalized Assessment of Computational Thinking MOOC Assignments",2017,"Proceedings - IEEE 17th International Conference on Advanced Learning Technologies, ICALT 2017",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030102328&doi=10.1109%2fICALT.2017.147&partnerID=40&md5=fdd142180b8a9312676d625ad8a11d19","One of the major hurdles toward automatic semantic understanding of computer programs is the lack of knowledge about what constitutes functional equivalence of code segments. We postulate that a sound knowledgebase can be used to deductively understand code segments in a hierarchical fashion by first de-constructing a code and then reconstructing it from elementary knowledge and equivalence rules of elementary code segments. The approach can also be engineered to produce computable programs from conceptual and abstract algorithms as an inverse function. In this paper, we introduce the core idea behind the MindReader online assessment system that is able to understand a wide variety of elementary algorithms students learn in their entry level programming classes such as Java, C++ and Python. The MindReader system is able to assess student assignments and guide them how to develop correct and better code in real time without human assistance. © 2017 IEEE.","Authentic assessment; automated assessment; computational thinking; computer programming; program equivalence","Codes (symbols); Computer programming; Education; Semantics; Authentic assessment; Automated assessment; Computational thinkings; Functional equivalence; On-line assessment; Program equivalence; Semantic understanding; Student assignments; C++ (programming language)",2-s2.0-85030102328
"Oltean G., Ivanciu L.-N.","Implementation of a fuzzy logic-based embedded system for temperature control",2017,"Proceedings of the International Spring Seminar on Electronics Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029907752&doi=10.1109%2fISSE.2017.8001006&partnerID=40&md5=8efc2c279c17db68a6a0dd99a76e5711","The core of this work consists in an explicit and complete implementation of an embedded system for temperature control. The embedded system is developed around an Arduino board and uses a fuzzy logic system as controller. The literature abounds in various solutions referring to design, implementation, and/or simulations of control systems, fuzzy logic controllers, embedded systems, and their combinations. This implementation offers to novice designers a platform for understanding, experimenting and learning the main concepts of both embedded system and closed loop control system, operating in a real environment. The major achievements of this work can be summarized as follows: access for measurements in relevant points of the system, illustration of the use of some fundamental devices and concepts in modern electronics (smart sensor for temperature measurement, power control using SCR, DAC converter, C++ programming, implementation of a fuzzy logic controller, I2C and 1-Wire interfaces), possibility to create different operating scenarios (by changing the set point temperature, sampling period, and scaling factors). The experimental results, in various scenarios, substantiate the expected operation of our temperature control system. © 2017 IEEE.",,"C++ (programming language); Closed loop control systems; Computer circuits; Control systems; Controllers; Fuzzy logic; Identification (control systems); Power control; Temperature control; Temperature measurement; Thermal management (electronics); Traffic signals; C++ programming; Fuzzy logic controllers; Fuzzy logic system; Real environments; Sampling period; Scaling factors; Set-point temperatures; Embedded systems",2-s2.0-85029907752
"Ingalalli A., Bapiraju J.V.V.N.","Analytical model for real time simulation of low voltage induction motor drive",2017,"2017 IEEE International Electric Machines and Drives Conference, IEMDC 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030329590&doi=10.1109%2fIEMDC.2017.8002039&partnerID=40&md5=0dd733a152909fff6ff3db1b50d5f639","The purpose of a real-Time simulation is to provide a closed loop system required for validating the control firmware or application. Detailed plant model with tolerable accuracy and achieving required real-Time model execution time are conflicting requirements for a given embedded target hardware. In design of control methods for Pulse Width Modulation (PWM) inverters analytical models are important tools for predicting dynamic performance and stability limits. This paper presents the analytical modeling of a 3-phase low voltage (LV) drive model tested in closed loop. The model is developed in Simulink using C language based S-functions compatible with the Real-Time Workshop (RTW) environment. To approximate the definite integral, trapezoidal rule is used and the dynamic equations are solved in fixed steps for entire induction motor model. The new method of modeling enabled to run the entire model in a limited resource target hardware with cycle time of 25 micro seconds and 25-32% CPU load. The results obtained using analytical model are found to be reducing the computation time by significant amount compared to numerical solver methods making it possible to run in real time. Results presented in this paper clearly show that important functionalities of the drive can be verified. © 2017 IEEE.","IM Model; LV Drive; Real-Time Simulation; S-functions","C (programming language); Closed loop systems; Electric drives; Electric machinery; Firmware; Hardware; Induction motors; Numerical methods; Pulse width modulation; Transients; Voltage control; Dynamic performance; Induction motor drive; Induction motor model; Pulse width modulation inverters; Real time modeling; Real time simulations; Real time workshop; S function; Analytical models",2-s2.0-85030329590
"Kader A.S.M.A., Dorojevets M.","Novel integration of Dimetheus and WalkSAT solvers for κ-SAT filter construction",2017,"2017 IEEE Long Island Systems, Applications and Technology Conference, LISAT 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028590896&doi=10.1109%2fLISAT.2017.8001989&partnerID=40&md5=1540b56e778559ad6a3821fdf73059e8","This paper describes a novel approach used to integrate two leading satisfiability (SAT) solvers, Dimetheus and WalkSAT, into a system to provide users with solver selection and solution customization capabilities. The two solvers are efficient for two different cases, have different execution procedures and generate a single solution from a single line of command. This integration provides the most efficient way to find multiple random solutions of any set membership problem from a common single line of command. To build an effective k-SAT filter, multiple random solutions are essential. The integration also provides a unified solution output format rather than two different output formats of two solvers. The theoretical approach and a practical C program were developed and tested during the work in an on-going project to build world's first practical k-SAT filter for deep packet inspection in network intrusion detection systems at Stony Brook University. © 2017 IEEE.","Dimetheus; k-SAT filtes; SAT solver; Satisfiability filters; WalkSAT","Bandpass filters; C (programming language); Formal logic; Integration; Software testing; Deep packet inspection; Dimetheus; Filter construction; SAT solvers; Satisfiability; Satisfiability solvers; Theoretical approach; WalkSAT; Intrusion detection",2-s2.0-85028590896
"Cantu M., Kim J., Zhang X.","Finding hash collisions using MPI on HPC clusters",2017,"2017 IEEE Long Island Systems, Applications and Technology Conference, LISAT 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028591358&doi=10.1109%2fLISAT.2017.8001961&partnerID=40&md5=70961c99da5f3b9dd1f53d392c94537c","In cryptography, a hash function is a very important cryptographic primitive with a wide range of applications. There are three required properties for a good hash function, i.e., collision, pre-image, and second pre-image resistance. In this paper, we try to contest these properties on a popular and widely used hash function called MD5 - and its two simplified versions that we made. The birthday attack technique was used to test MD5's general collision resistance, while the brute force method was used in the search for pre-image and second pre-image collisions. We calculated the Hamming distance to monitor the progress in our search for a collision; the smaller the Hamming distance the better. Our input domain for the MD5 hash function consisted of hexadecimal bit-strings and strategically generated ASCII character strings. Since finding hash collisions demands much more computing power and storage, we wrote C parallel programs in conjunction with the Message Passing Interface (MPI) library that runs over multiple processors / cores in the heavily used CUNY HPC cluster called Penzias. Multiple search / sort / merge algorithms were tested, not only to reduce time and space complexities, but also to improve performance. Hash distributions, numerous arbitrary meaningless and a few meaningful collisions were found. © 2017 IEEE.","Hash function; hash function collisions; HPC; MD5; MPI","C (programming language); Character sets; Cluster computing; Cryptography; Hash functions; Message passing; Birthday attacks; Character strings; Collision resistance; Cryptographic primitives; Improve performance; Message passing interface libraries; Multiple processors; Parallel program; Hamming distance",2-s2.0-85028591358
"Viet H.N., Kwon K.-R., Moon K.-S., Lee S.-H.","Simulation model implementation of GPS if signal generator",2017,"Proceedings of KICS-IEEE International Conference on Information and Communications with Samsung LTE and 5G Special Workshop, ICIC 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030245954&doi=10.1109%2fINFOC.2017.8001685&partnerID=40&md5=60821258e41544e0e24cce407c0769ea","In this paper, a simulation model of digital intermediate frequency (IF) GPS signal is presented. This design is developed based on mathematical mode representing the digitized IF GPS signal includes C/A code, navigation data and P code, and the noise which can set some initial configurations simultaneously. Simulation results show that the simulated signals have the same properties with real signals (e.g. C/A code correlation properties, the spread spectrum). The simulated IF GPS signal data can work as input for various signal processing algorithm of GPS receivers, such as acquisition, tracking, carrier-to-noise ratio (C/No) estimation. © 2017 IEEE.","GPS signal generator; IF (intermediate frequency) signals; Signal-to-noise ratio (SNR)","5G mobile communication systems; C (programming language); Codes (symbols); Global positioning system; Signal generators; Signal processing; Signal to noise ratio; Wireless telecommunication systems; Carrier to noise ratio; Correlation properties; Digital intermediate frequency; GPS signal generators; Initial configuration; Intermediate frequencies; Signal processing algorithms; Simulated signals; Signal receivers",2-s2.0-85030245954
"Reddy P.D., Iyer S., Sasikumar M.","FATHOM: TEL Environment to Develop Divergent and Convergent Thinking Skills in Software Design",2017,"Proceedings - IEEE 17th International Conference on Advanced Learning Technologies, ICALT 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030236098&doi=10.1109%2fICALT.2017.83&partnerID=40&md5=a078e15dd02f65b6fa68a5a8428d925a","Divergent and convergent (D&C) thinking skills are important in solving software design problems. Divergent thinking involves processes like understanding the problem from multiple perspectives and generating multiple solutions to a problem. While, convergent thinking is evaluating and selecting the solution based on the criteria and constraints. These skills are important in software design process for better design outcomes. Studies have shown that students lack the abilities to apply these skills spontaneously to solve design problem. In this paper, we present the design of a Technology Enhanced Learning (TEL) environment with metacognitive support to foster D&C thinking skills in engineering students. The scaffolds are characterized in the form of prompts, examples, simulations, and D & C thinking tools to trigger D & C thinking during real life design problem solving in data structures. A study was conducted with second year computer engineering students to find the effectiveness of the metacognitive and cognitive prompts in doing the D & C thinking activities. The results show that design features have helped students perform the activities effectively. These results are supported with student's perception survey and student interviews. © 2017 IEEE.","cognitive prompts; convergent thinking; divergent thinking; metacognitive prompts; software design","Education; Engineering education; Problem solving; Scaffolds; Software design; Students; cognitive prompts; Convergent thinkings; Design problem solving; Divergent thinkings; Metacognitives; Software design problems; Software design process; Technology enhanced learning; C (programming language)",2-s2.0-85030236098
"Xiao C., Cheng D., Wei K.","An LCC-C Compensated Wireless Charging System for Implantable Cardiac Pacemakers: Theory, Experiment and Safety Evaluation",2017,"IEEE Transactions on Power Electronics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028801022&doi=10.1109%2fTPEL.2017.2735441&partnerID=40&md5=23325749af7fc68d0573d7110435dcaa","The technique of wireless power transfer (WPT) via magnetic coupling resonance provides a way to transfer power to cardiac pacemakers from external source. For wireless charging system to be used in clinical, this paper gives priority consideration to three technical difficulties, i.e. implantation, efficiency and safety. The LCC-C compensation topology for pacemaker wireless charger is presented, where only one secondary side resonancecapacitor needs to be implanted, and resonance compensation parameters are derived. The compensation network can make the WPT system operate at stable resonance and high efficiency. The wireless charging prototype for cardiac pacemaker is developed, where a thin flexible receiving coil with a ferrite film was designed to effectively shield eddy currents in the pacemaker shell. The experiments of wireless charging through pork tissues reveal that 3.072W power can be received from a 3.919W power source at 300kHz, reaching a high efficiency of 78.4%; the charging is fast, i.e. the 1050mA&#x00B7;h, 4.2V Li-ion battery voltage increasing from 3.98V(80% residual capacity) to 4.2V within only 27minutes; and the maximum temperature rise of the pork only 3.3 &#x00B0;C is in safe limits. The feasibility and safety of the charging system were further evaluated by simulations of SAR and temperature rise in human tissues and electromagnetic fields in the pacemaker case. IEEE","Batteries; Capacitors; Coils; Couplings; electromagnetic compatibility; Implantable cardiac pacemaker; Inductive charging; LCC-C compensation networks; magnetic coupling resonance; Pacemakers; Safety; SAR; temperature rise; wireless charging system; wireless power transfer","Accident prevention; C (programming language); Capacitors; Charging (batteries); Couplings; Eddy currents; Efficiency; Electromagnetic compatibility; Electromagnetic field effects; Electromagnetic fields; Energy transfer; Heart; Histology; Inductive power transmission; Lithium-ion batteries; Magnetic couplings; Resonance; Solar cells; Tissue; Coils; Compensation network; Coupling resonance; Implantable cardiac pacemakers; Inductive charging; Temperature rise; Wireless charging system; Wireless power transfer; Pacemakers",2-s2.0-85028801022
"Maity T., Prasad H.","Real-time performance evaluation of quasi z-source inverter for induction motor drives",2017,"IEEE International Symposium on Industrial Electronics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029905485&doi=10.1109%2fISIE.2017.8001356&partnerID=40&md5=45f6e700c5c6a4226682600d17f56b66","This paper demonstrates and validates the real-time performance of quasi z-source inverter (QZSI) for medium voltage induction motor drives using the field-programming gate array (FPGA)-based real-time digital simulator (RTDS). The simulator was built using hardware description language (HDL), making it versatile and moveable. The proposed QZSI-fed drive model is designed in MALTAB/Simulink and implemented on FPGA-based real-time simulator and executed at fixed-time step of 10 μs and constant switching frequency of 5 KHz. The QZSI drive has a unique capability to boost the inverter output voltage during voltage sag and maintain steady state speed of the induction motor. The proposed drive system provides uninterrupted motor speed during voltage sag and removes the crisis in manufacturing and economical losses. Real-time simulation results show steady state and transient performance of QZSI-fed 225 KW, 3.3 KV induction motor drives. The experimental results using RTDS as rapid control prototype controller validate the simulation results. © 2017 IEEE.","Field-programming gate array (FPGA); Hardware-in-the-Loop (HIL); Induction motor drives; Rapid control prototype (RCP); Real-time digital simulation (RTDS)","Computer hardware description languages; Drives; Electric drives; Electric fault currents; Electric inverters; Electric motors; Field programmable gate arrays (FPGA); Hardware; Industrial electronics; Simulators; Field-programming gate arrays; Hardware in the loops; Induction motor drive; Rapid control prototypes; Real-time digital simulations; Induction motors",2-s2.0-85029905485
"Pleshkova S., Kinanev D.","Method for comparative performance analyze of encryption algorithms used in public key infrastructure for secure transmitting of audio information",2017,"Proceedings of the International Spring Seminar on Electronics Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029908282&doi=10.1109%2fISSE.2017.8000946&partnerID=40&md5=a846c5fa1d2ac4ac20c08cdfd81b39bf","In this article it will be analyzed the characteristics of the symmetric encryption algorithms Blowfish, Advanced Encryption Standard, Data Encryption Standard and Triple Data Encryption Standard for securing audio information using developed method for measuring their performance. The results will be compared with already examined ones based on the developed method for performance evaluation of the asymmetric encryption algorithm Rivest-Shamir-Adleman with which their advantages and disadvantages will be analyzed. For that purpose the resources provided by the Java programming language will be used. © 2017 IEEE.",,"Computer programming; Data privacy; Public key cryptography; Advanced Encryption Standard; Asymmetric encryption; Comparative performance; Data encryption standard; Encryption algorithms; Public key infrastructure; Rivest-shamir-adleman; Symmetric encryption; Cryptography",2-s2.0-85029908282
"Ameen E.-M.M., Ali H.A., Salem M.M., Badawy M.","Towards Implementation of a Generalized Architecture for High-Level Quantum Programming Language",2017,"International Journal of Theoretical Physics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018736344&doi=10.1007%2fs10773-017-3391-x&partnerID=40&md5=4320e4cf3544f1bf722711c0a7ac869c","This paper investigates a novel architecture to the problem of quantum computer programming. A generalized architecture for a high-level quantum programming language has been proposed. Therefore, the programming evolution from the complicated quantum-based programming to the high-level quantum independent programming will be achieved. The proposed architecture receives the high-level source code and, automatically transforms it into the equivalent quantum representation. This architecture involves two layers which are the programmer layer and the compilation layer. These layers have been implemented in the state of the art of three main stages; pre-classification, classification, and post-classification stages respectively. The basic building block of each stage has been divided into subsequent phases. Each phase has been implemented to perform the required transformations from one representation to another. A verification process was exposed using a case study to investigate the ability of the compiler to perform all transformation processes. Experimental results showed that the efficacy of the proposed compiler achieves a correspondence correlation coefficient about R ≈ 1 between outputs and the targets. Also, an obvious achievement has been utilized with respect to the consumed time in the optimization process compared to other techniques. In the online optimization process, the consumed time has increased exponentially against the amount of accuracy needed. However, in the proposed offline optimization process has increased gradually. © 2017, Springer Science+Business Media New York.","High-level language; Quantum mechanics; Quantum processor; Quantum programming",,2-s2.0-85018736344
"Said R.F.M., Rahman T.F.A.","Validation of C programming language assessment for foundation students",2017,"Advanced Science Letters",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032192119&doi=10.1166%2fasl.2017.9539&partnerID=40&md5=3b8da9c403031dc9c82b758a327c7f01","Students’ programming skills is important in identifying their learning pattern. Their programming skills will indicate whether the learning objective has achieved or otherwise In Center of Foundation Studies UiTM, engineering students learn the basic C programming language. Students are taught the theoretical and practical basic concepts of the language. This study is to validate the assessment in order to measure their programming skills. In this study, Rasch measurement model is used for validation. The reason for choosing Rasch measurement model is because the model moves the concept of reliability from creating ‘best fit line’ of the data into constructing reliable measurement instrument. A collection of programming questions is used for this study. The questions comprise of various topic in C Programming language which was developed according to Bloom’s Taxanomy level of mastery. Based on the analysis, it showed that the assessment is valid to measure students programming skill and this assessment can be used to test students understanding as a beginner in learning C programming language. © 2017 American Scientific Publishers. All rights reserved.","C programming; Foundation; Rasch measurement model",,2-s2.0-85032192119
"Pu J., Bell S., Yang X., Setter J., Richardson S., Ragan-Kelley J., Horowitz M.","Programming heterogeneous systems from an image processing DSL",2017,"ACM Transactions on Architecture and Code Optimization",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028621454&doi=10.1145%2f3107953&partnerID=40&md5=401139e0b51efddb7da3d8a2b5bebc00","Specialized image processing accelerators are necessary to deliver the performance and energy efficiency required by important applications in computer vision, computational photography, and augmented reality. But creating, ""programming,"" and integrating this hardware into a hardware/software system is difficult.We address this problem by extending the image processing language Halide so users can specify which portions of their applications should become hardware accelerators, and then we provide a compiler that uses this code to automatically create the accelerator along with the ""glue"" code needed for the user's application to access this hardware. Starting with Halide not only provides a very high-level functional description of the hardware but also allows our compiler to generate a complete software application, which accesses the hardware for acceleration when appropriate. Our system also provides high-level semantics to explore different mappings of applications to a heterogeneous system, including the flexibility of being able to change the throughput rate of the generated hardware. We demonstrate our approach by mapping applications to a commercial Xilinx Zynq system. Using its FPGA with two low-power ARM cores, our design achieves up to 6× higher performance and 38× lower energy compared to the quad-core ARM CPU on an NVIDIA Tegra K1, and 3.5× higher performance with 12× lower energy compared to the K1's 192-core GPU. © 2017 ACM.","domain specific languages; FPGAs; high-level synthesis; Image processing","Application programs; Augmented reality; Color photography; Computer hardware; Computer programming languages; Computer systems programming; Digital subscriber lines; Energy efficiency; Field programmable gate arrays (FPGA); Green computing; Hardware; High level languages; High level synthesis; Mapping; Problem oriented languages; Program compilers; Semantics; Computational photography; Domain specific languages; Hardware accelerators; Hardware/software systems; Heterogeneous systems; High level semantics; Mapping applications; Software applications; Image processing",2-s2.0-85028621454
"Milazzo P., Pardini G.","Objective/MC: A high-level model checking language: Formalization of the imperative core and translation into PRISM",2017,"Journal of Intelligent Information Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026525184&doi=10.1007%2fs10844-017-0475-2&partnerID=40&md5=c8259d55186bad36cc8d099cd74f999f","Among model checking tools, the behaviour of a system is often formalized as a transition system with atomic propositions associated with states (Kripke structure). In current modeling languages, transitions are usually specified as updates of the system’s variables to be performed when certain conditions are satisfied. However, such a low-level representation makes the description of complex transformations difficult, in particular in the presence of structured data. We present Objective/MC, a high-level language with imperative semantics for modeling finite-state systems. The language features are selected with the aim of enabling the translation of models into compact transition systems, amenable to efficient verification via model checking. To this end, we have developed a compiler of our high-level language into the modeling language of the PRISM probabilistic model checker. One of the main characteristics of the language is that it makes a very different treatment of global and local variables. It is assumed that global variables are actually the variables that describe the state of the modeled system, whereas local variables are only used to ease the specification of the system’s internal mechanisms. In this paper, we give a complete formal definition of the language, its type system and static analyses, of the transformations to be performed at the level of the Control Flow Graph for the pruning of local variables, and of the PRISM code generation. © 2017 Springer Science+Business Media, LLC","Compilers; Complex systems analysis; Local variables elimination; Model checking; Programming languages","Computer programming languages; Data flow analysis; Flow graphs; High level languages; Large scale systems; Modeling languages; Object oriented programming; Prisms; Program compilers; Semantics; Static analysis; Systems analysis; Translation (languages); Complex transformations; Different treatments; Finite state systems; High-level modeling; Local variables; Low level representation; Model checking tools; Probabilistic modeling; Model checking",2-s2.0-85026525184
"Noura M., Ahmad I., Noura A., Nordin R.","A Discrete Event Simulation for Hierarchical Mobile IPv6",2017,"Wireless Personal Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017474298&doi=10.1007%2fs11277-017-4130-6&partnerID=40&md5=68549a27d58211baaac314d7945979cc","In recent years’ simulators like the open source tool ns-2, and commercial software’s like OPNET have included Mobile IPv6 extensions in order to provide analysis for advanced Mobile IPv6 system development. Although these simulators are among the significant simulators, however, they have a tendency to be specific to hardware, vast integrated components, complex and the need of licensing cost for commercial simulators. To strike an ideal balance in gauging these tradeoffs and to further complement the repository of simulators, this study deliberates the details of a general-purpose programming language based Discrete Event Simulation for Hierarchical Mobile IPv6. This paper has incorporated a call admission control algorithm as an example to validate the simulator for Hierarchical Mobile IPv6. A Fuzzy Inference System based call admission control has been used as a benchmark deployment algorithm. The base model has been extensively analyzed and the set of parameters (simulation and non-simulation parameters), events, performance metrics and other fundamental elements has been derived. The Fuzzy Inference based call admission control is studied and evaluated against the benchmark model. The results demonstrate that the developed discrete event simulator has effectively produced the benchmark results and verified that the new simulator has effectively become a dependable selection for Hierarchical Mobile IPv6 performance analysis. © 2017, Springer Science+Business Media New York.","Call admission control; Discrete event simulator; General purpose programming language; Hierarchical Mobile IPv6","Benchmarking; Computer programming languages; Congestion control (communication); Discrete event simulation; Fuzzy inference; Inference engines; Open source software; Open systems; Commercial simulators; Deployment algorithms; Discrete-event simulators; Fuzzy inference systems; General-purpose programming language; Hierarchical Mobile IPv6; Performance metrics; Simulation parameters; Simulators",2-s2.0-85017474298
"Rodríguez-Fernández R., Pereira F.B., Marques J.M.C., Martínez-Núñez E., Vázquez S.A.","GAFit: A general-purpose, user-friendly program for fitting potential energy surfaces",2017,"Computer Physics Communications",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018450717&doi=10.1016%2fj.cpc.2017.02.008&partnerID=40&md5=9bb642451185bac906b9a95997ed71b1","We have developed a software package based on a genetic algorithm that fits an analytic function to a given set of data points. The code, called GAFit, was also interfaced with the CHARMM and MOPAC programs in order to facilitate force field parameterizations and fittings of specific reaction parameters (SRP) for semiempirical Hamiltonians. The present tool may be applied to a wide range of fitting problems, though it has been especially designed to significantly reduce the hard work involved in the development of potential energy surfaces for complex systems. For this purpose, it has been equipped with several programs to help the user in the preparation of the input files. We showcase the application of the computational tool to several chemical-relevant problems: force-field parameterization, with emphasis on nonbonded energy terms or intermolecular potentials, derivation of SRP for semiempirical Hamiltonians, and fittings of generic analytical functions. Program summary Program title : GAFit Program Files doi : http://dx.doi.org/10.17632/9gy6bjcwk5.1 Licensing provisions : GNU General Public License 3 (GPL) Programming language : Fortran 90, C, Perl and Java Nature of problem : Potential energy surfaces (PESs) have a key role in reaction dynamics and molecular dynamics. Chemical dynamics simulations can be performed by using analytical PESs or by direct dynamics, that is, by computing energies and forces “on-the-fly” by molecular structure calculations. The development of analytical PESs is, quite often, a very complex and tedious task. There are several programs in the literature that may help to develop PESs but, as far as we know, none of them show, at the same time, great generality and flexibility. Solution method : GAFit was designed to help users develop analytical potential energy functions. We made special efforts to write a code that exhibits the three features mentioned above. For this reason, we have also interfaced GAFit with the CHARMM and MOPAC programs. The former is one of the popular packages for molecular dynamics and the latter is a semiempirical quantum chemistry program that may be conveniently used for direct dynamics simulations. Because, in general, the fitting of PESs involves a simultaneous optimization of many nonlinear parameters, we have selected a genetic algorithm as the driver for the parameterizations. As shown in the paper, GAFit may be applied to other fitting problems. © 2017 Elsevier B.V.","Force field parameterization; Genetic algorithm; Intermolecular potentials; Potential energy surfaces; Specific reaction parameters","Chemical analysis; Computer programming; FORTRAN (programming language); Genetic algorithms; Hamiltonians; Molecular dynamics; Molecular physics; Open source software; Optimization; Parameter estimation; Parameterization; Potential energy; Potential energy functions; Potential energy surfaces; Problem oriented languages; Quantum chemistry; Reaction kinetics; Surface reactions; Analytical potential energy functions; Force field parameterization; GNU general public license; Intermolecular potentials; Semiempirical Hamiltonians; Simultaneous optimization; Specific reaction parameters; Structure calculation; C (programming language)",2-s2.0-85018450717
"Sánchez-Gil V., Noya E.G., Lomba E.","NRMC – A GPU code for N-Reverse Monte Carlo modeling of fluids in confined media",2017,"Computer Physics Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018422053&doi=10.1016%2fj.cpc.2017.04.008&partnerID=40&md5=f52b4fb54391071ad60b4387c4a12a03","NRMC is a parallel code for performing N-Reverse Monte Carlo modeling of fluids in confined media [V. Sánchez-Gil, E.G. Noya, E. Lomba, J. Chem. Phys. 140 (2014) 024504]. This method is an extension of the usual Reverse Monte Carlo method to obtain structural models of confined fluids compatible with experimental diffraction patterns, specifically designed to overcome the problem of slow diffusion that can appear under conditions of tight confinement. Most of the computational time in N-Reverse Monte Carlo modeling is spent in the evaluation of the structure factor for each trial configuration, a calculation that can be easily parallelized. Implementation of the structure factor evaluation in NVIDIA® CUDA so that the code can be run on GPUs leads to a speed up of up to two orders of magnitude. Program summary Program Title: NRMC_gpu Program Files doi: http://dx.doi.org/10.17632/kbbgbkn68m.1 Licensing provisions: GNU General Public License 3 (GPL) Programming language: FORTRAN, C and NVIDIA® CUDA Supplementary material: An example calculation is provided External routines/libraries: LAPACK (for gfortran) or Intel® MathKernel for Intel® Fortran (included in Intel's distribution) Nature of problem: Determination of structural models of confined fluids compatible with experimental diffractograms Solution method:N-Reverse Monte Carlo simulations using GPUs © 2017 Elsevier B.V.","Adsorption; Modeling; Reverse Monte Carlo; Structure; Zeolites","Adsorption; C (programming language); Codes (symbols); Diffusion in liquids; FORTRAN (programming language); Graphics processing unit; Intelligent systems; Models; Open source software; Problem oriented languages; Program processors; Structure (composition); Zeolites; Computational time; GNU general public license; Orders of magnitude; Reverse Monte Carlo; Reverse Monte Carlo method; Reverse Monte Carlo modeling; Reverse monte carlo simulation; Structure factors; Monte Carlo methods",2-s2.0-85018422053
"Vocke S., Corporaal H., Jordans R., Corvino R., Nas R.","Extending halide to improve software development for imaging DSPs",2017,"ACM Transactions on Architecture and Code Optimization",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029543730&doi=10.1145%2f3106343&partnerID=40&md5=6b4ef70a4f5d75ac45ccc24ecae7e7ed","Specialized Digital Signal Processors (DSPs), which can be found in a wide range of modern devices, play an important role in power-efficient, high-performance image processing. Applications including camera sensor post-processing and computer vision benefit from being (partially) mapped onto such DSPs. However, due to their specialized instruction sets and dependence on low-level code optimization, developing applications for DSPs is more time-consuming and error-prone than for general-purpose processors. Halide is a domain-specific language (DSL) that enables low-effort development of portable, high-performance imaging pipelines-A combination of qualities that is hard, if not impossible, to find among DSP programming models. We propose a set of extensions and modifications to Halide to generate code for DSP C compilers, focusing specifically on diverse SIMD target instruction sets and heterogeneous scratchpad memory hierarchies. We implement said techniques for a commercial DSP found in an Intel Image Processing Unit (IPU), demonstrating that this solution can be used to achieve performance within 20% of highly tuned, manually written C code, while leading to a reduction in code complexity. By comparing performance of Halide algorithms using our solution to results on CPU and GPU targets, we confirm the value of using DSP targets with Halide. © 2017 ACM.","Accelerator; Asip; DSP; Embedded processor; Halide; Image processing unit; IPU; Optimization; Parallel computing; Performance optimization; Scratchpad memory; SIMD; VLIW","C (programming language); Codes (symbols); Computer programming languages; Digital devices; Digital signal processing; Digital signal processors; General purpose computers; Memory architecture; Modems; Multiprocessing systems; Optimization; Parallel processing systems; Particle accelerators; Problem oriented languages; Signal processing; Software design; Very long instruction word architecture; Asip; Embedded processors; Halide; Performance optimizations; Scratch pad memory; SIMD; VLIW; Image processing",2-s2.0-85029543730
"Hefetz E.F., Chien E., Weber O.","Fast Planar Harmonic Deformations with Alternating Tangential Projections",2017,"Computer Graphics Forum",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027976844&doi=10.1111%2fcgf.13255&partnerID=40&md5=4dadcb87e05d1ac25761b530bd058566","We present a planar harmonic cage-based deformation method with local injectivity and bounded distortion guarantees, that is significantly faster than state-of-the-art methods with similar guarantees, and allows for real-time interaction. With a convex proxy for a near-convex characterization of the bounded distortion harmonic mapping space from [LW16], we utilize a modified alternating projection method (referred to as ATP) to project to this proxy. ATP draws inspiration from [KABL15] and restricts every other projection to lie in a tangential hyperplane. In contrast to [KABL15], our convex setting allows us to show that ATP is provably convergent (and is locally injective). Compared to the standard alternating projection method, it demonstrates superior convergence in fewer iterations, and it is also embarrassingly parallel, allowing for straightforward GPU implementation. Both of these factors combine to result in unprecedented speed. The convergence proof generalizes to arbitrary pairs of intersecting convex sets, suggesting potential use in other applications. Additional theoretical results sharpen the near-convex characterization that we use and demonstrate that it is homeomorphic to the bounded distortion harmonic mapping space (instead of merely being bijective). © 2017 The Author(s) Computer Graphics Forum © 2017 The Eurographics Association and John Wiley & Sons Ltd. Published by John Wiley & Sons Ltd.","Categories and Subject Descriptors (according to ACM CCS); G.1.6 [Numerical Analysis]: Optimization—Convex programming; I.3.5 [Computer Graphics]: Computational Geometry and Object Modeling—Geometric algorithms, languages, and systems; Hierarchy and geometric transformations; I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism—Animation","Computational geometry; Computer graphics; Computer programming; Computer programming languages; Computer systems programming; Convex optimization; Deformation; Geometry; Harmonic analysis; Mapping; Mathematical transformations; Modeling languages; Set theory; Alternating projection method; Bounded distortions; Computational Geometry and Object Modeling; Descriptors; GPU implementation; I.3.7 [computer graphics]: three-dimensional graphics and realism; Real time interactions; State-of-the-art methods; Three dimensional computer graphics",2-s2.0-85027976844
"Johanson A.N., Hasselbring W.","Effectiveness and efficiency of a domain-specific language for high-performance marine ecosystem simulation: a controlled experiment",2017,"Empirical Software Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84996560163&doi=10.1007%2fs10664-016-9483-z&partnerID=40&md5=90256cafb19e5a9fd34e64563a000978","It is a long-standing hypothesis that the concise and customized notation of a DSL improves the performance of developers when compared with a GPL. For non-technical domains—e.g., science—, this hypothesis lacks empirical evidence. Given this lack of empirical evidence, we evaluate a DSL for ecological modeling designed and implemented by us with regard to performance improvements of developers as compared to a GPL. We conduct an online survey with embedded controlled experiments among ecologists to assess the correctness and time spent of the participants when using a DSL for ecosystem simulation specifications compared with a GPL-based solution. We observe that (1) solving tasks with the DSL, the participants’ correctness point score was —depending on the task— on average 61 % up to 63 % higher than with the GPL-based solution and their average time spent per task was reduced by 31 % up to 56 %; (2) the participants subjectively find it easier to work with the DSL, and (3) more than 90 % of the subjects are able to carry out basic maintenance tasks concerning the infrastructure of the DSL used in our treatment, which is based on another internal DSL embedded into Java. The tasks of our experiments are simplified and our web-based editor components do not offer full IDE-support. Our findings indicate that the development of further DSL for the specific needs of the ecological modeling community should be a worthwhile investment to increase its members’ productivity and to enhance the reliability of their scientific results. © 2016, Springer Science+Business Media New York.","Computational science; Domain-specific languages (DSLs); Program comprehension; Scientific software development","Computer programming languages; Digital subscriber lines; Ecology; Graphical user interfaces; Investments; Marine engineering; Problem oriented languages; Software design; Surveys; XML; Computational science; Controlled experiment; Domain specific languages; Ecological modeling; Ecosystem simulations; Effectiveness and efficiencies; Program comprehension; Scientific software development; Ecosystems",2-s2.0-84996560163
"Alvares F., Rutten E., Seinturier L.","A domain-specific language for the control of self-adaptive component-based architecture",2017,"Journal of Systems and Software",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011965743&doi=10.1016%2fj.jss.2017.01.030&partnerID=40&md5=14ac2204dc22a03e570647f7d7d87e40","Self-adaptive behaviours in the context of Component-based Architecture are generally designed based on past monitoring events, configurations (component assemblies) as well as behavioural programs defining the adaptation logics and invariant properties. Providing assurances on the navigation through the configuration space remains a challenge. That requires taking decisions on predictions on the possible futures of the system in order to avoid going into branches of the behavioural program leading to bad configurations. We propose the design of self-adaptive software components based on logical discrete control approaches, in which the self-adaptive behavioural models enrich component controllers with a knowledge not only on events, configurations and past history, but also with possible future configurations. This article provides the description, implementation and discussion of Ctrl-F, a Domain-specific Language whose objective is to provide high-level support for describing these control policies. Ctrl-Fis formally defined by translation to Finite State Automata models, which allow for the exploration of behavioural programs by verification or Discrete Controller Synthesis, i.e., by automatically generating a controller to enforce correct self-adaptive behaviours. We integrate Ctrl-F with FraSCAti, a Service Component Architecture middleware platform and we illustrate the use of Ctrl-Fby applying it to two case studies. © 2017 Elsevier Inc.","Component-based architecture; Discrete control; Self-adaptation","Computer programming languages; High level languages; Middleware; Problem oriented languages; Program translators; 10.040; 10.050; 10.090; 10.280; 20.120; Component-based architecture; Discrete Control; Self adaptation; Controllers",2-s2.0-85011965743
"Fanni T., Li L., Viitanen T., Sau C., Xie R., Palumbo F., Raffo L., Huttunen H., Takala J., Bhattacharyya S.S.","Hardware design methodology using lightweight dataflow and its integration with low power techniques",2017,"Journal of Systems Architecture",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020917888&doi=10.1016%2fj.sysarc.2017.06.003&partnerID=40&md5=e58290bb3db63a9ad47f7380120b406d","Dataflow models of computation are capable of providing high-level descriptions for hardware and software components and systems, facilitating efficient processes for system-level design. The modularity and parallelism of dataflow representations make them suitable for key aspects of design exploration and optimization, such as efficient scheduling, task synchronization, memory and power management. The lightweight dataflow (LWDF) programming methodology provides an abstract programming model that supports dataflow-based design of signal processing hardware and software components and systems. Due to its formulation in terms of abstract application programming interfaces, the LWDF methodology can be integrated with a wide variety of simulation- and implementation-oriented languages, and can be targeted across different platforms, which allows engineers to integrate dataflow modeling approaches relatively easily into existing design processes. Previous work on LWDF techniques has emphasized their application to DSP software implementation (e.g., through integration with C and CUDA). In this paper, we efficiently integrate the LWDF methodology with hardware description languages (HDLs), and we apply this HDL-integrated form of the methodology to develop efficient methods for low power DSP hardware implementation. The effectiveness of the proposed LWDF-based hardware design methodology is demonstrated through a case study of a deep neural network application for vehicle classification. © 2017 Elsevier B.V.","Clock gating; Dataflow; Deep neural networks; Digital systems design; Globally asynchronous locally synchronous; Low power design; Signal processing","Application programming interfaces (API); Application programs; C (programming language); Computer hardware description languages; Computer simulation languages; Data flow analysis; Deep neural networks; Electric power supplies to apparatus; Hardware; Low power electronics; Modeling languages; Scheduling; Signal processing; Clock gating; Dataflow; Digital systems design; Globally asynchronous locally synchronous; Low-power design; Design",2-s2.0-85020917888
"Rizzardi M.","Algorithm 981: Talbot Suite DE: Application of modified Talbot's method to solve differential problems",2017,"ACM Transactions on Mathematical Software",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028517211&doi=10.1145%2f3089248&partnerID=40&md5=99cfa0f200e02711098bcd9b390be464","In order to solve a differential problem, the Laplace Transform method, when applicable, replaces the problem with a simpler one; the solution is obtained by solving the new problem and then by computing the inverse Laplace Transform of this function. In a numerical context, since the solution of the transformed problem consists of a sequence of Laplace Transform samples, most of the software for the numerical inversion cannot be used since the transform, among parameters, must be passed as a function. To fill this gap, we present Talbot Suite DE, a C software collection for Laplace Transform inversions, specifically designed for these problems and based on Talbot's method. It contains both sequential and parallel implementations; the latter is accomplished by means of OpenMP. We also report some performance results. Aimed at non-expert users, the software is equipped with several examples and a User Guide that includes the external documentation, explains how to use all the sample code, and reports its results about accuracy and efficiency. Some examples are entirely in C and others combine different programming languages (C/MATLAB, C/FORTRAN). The User Guide also contains useful hints to avoid possible errors issued during the compilation or execution of mixed-language code. © 2017 ACM.","Inverse Laplace transform; Parallel algorithms; Talbot's method","Application programming interfaces (API); C (programming language); Inverse transforms; Laplace transforms; Parallel algorithms; Problem oriented languages; Problem solving; Differential problems; Expert users; Inverse Laplace transform; Laplace transform inversions; Laplace transform method; Numerical inversion; Parallel implementations; Talbot's method; Inverse problems",2-s2.0-85028517211
"Łoś M.M., Woźniak M., Paszyński M., Lenharth A., Hassaan M.A., Pingali K.","IGA-ADS: Isogeometric analysis FEM using ADS solver",2017,"Computer Physics Communications",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018707944&doi=10.1016%2fj.cpc.2017.02.023&partnerID=40&md5=963a91c07bb5c49f1965fc12b673dd21","In this paper we present a fast explicit solver for solution of non-stationary problems using L2 projections with isogeometric finite element method. The solver has been implemented within GALOIS framework. It enables parallel multi-core simulations of different time-dependent problems, in 1D, 2D, or 3D. We have prepared the solver framework in a way that enables direct implementation of the selected PDE and corresponding boundary conditions. In this paper we describe the installation, implementation of exemplary three PDEs, and execution of the simulations on multi-core Linux cluster nodes. We consider three case studies, including heat transfer, linear elasticity, as well as non-linear flow in heterogeneous media. The presented package generates output suitable for interfacing with Gnuplot and ParaView visualization software. The exemplary simulations show near perfect scalability on Gilbert shared-memory node with four Intel® Xeon® CPU E7-4860 processors, each possessing 10 physical cores (for a total of 40 cores). Program summary Program Title: IGA-ADS Program Files doi: http://dx.doi.org/10.17632/pbpsyzyvfy.1 Licensing provisions: MIT license (MIT) Programming language: C++ Nature of problem: Solving non-stationary problems in 1D, 2D and 3D Solution method:L2 projections with isogeometric finite element method Additional comments including Restrictions and Unusual features: Due to nature of the ADS solver, using explicit Euler scheme is necessary. This imposes some restrictions on time step size required to maintain stability. © 2017 Elsevier B.V.","Finite element method; Isogeometric analysis; Shared memory","C++ (programming language); Computer operating systems; Computer programming; Deceleration; Heat transfer; Memory architecture; Problem oriented languages; Problem solving; Heterogeneous media; Isogeometric analysis; Linear elasticity; Non-stationary problems; Shared memory; Solution methods; Time-dependent problem; Visualization software; Finite element method",2-s2.0-85018707944
"Pérez G., Yovine S.","Formal specification and implementation of an automated pattern-based parallel-code generation framework",2017,"International Journal on Software Tools for Technology Transfer",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026498954&doi=10.1007%2fs10009-017-0465-2&partnerID=40&md5=4dbfb5b172d0329caa05253d3b58b09b","Programming correct parallel software in a cost-effective way is a challenging task requiring a high degree of expertise. As an attempt to overcoming the pitfalls undermining parallel programming, this paper proposes a pattern-based, formally grounded tool that eases writing parallel code by automatically generating platform-dependent programs from high-level, platform-independent specifications. The tool builds on three pillars: (1) a platform-agnostic parallel programming pattern, called PCR, (2) a formal translation of PCRs into a parallel execution model, namely Concurrent Collections (CnC), and (3) a program rewriting engine that generates code for a concrete runtime implementing CnC. The experimental evaluation carried out gives evidence that code produced from PCRs can deliver performance metrics which are comparable with handwritten code but with assured correctness. The technical contribution of this paper is threefold. First, it discusses a parallel programming pattern, called PCR, consisting of producers, consumers, and reducers which operate concurrently on data sets. To favor correctness, the semantics of PCRs is mathematically defined in terms of the formalism FXML. PCRs are shown to be composable and to seamlessly subsume other well-known parallel programming patterns, thus providing a framework for heterogeneous designs. Second, it formally shows how the PCR pattern can be correctly implemented in terms of a more concrete parallel execution model. Third, it proposes a platform-agnostic C++ template library to express PCRs. It presents a prototype source-to-source compilation tool, based on C++ template rewriting, which automatically generates parallel implementations relying on the Intel CnCC++ library. © 2017 Springer-Verlag GmbH Germany","Automated code generation; Formal methods; Parallel programming; Software design patterns","Codes (symbols); Computer architecture; Computer programming; Concretes; Cost effectiveness; Formal methods; Formal specification; Parallel programming; Program translators; Semantics; Software design; Specifications; Automated code generation; C++ template library; Experimental evaluation; Parallel implementations; Platform independent; Software design patterns; Source-to-source compilation; Technical contribution; C++ (programming language)",2-s2.0-85026498954
"Tavakkol S., Lynett P.","Celeris: A GPU-accelerated open source software with a Boussinesq-type wave solver for real-time interactive simulation and visualization",2017,"Computer Physics Communications",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018744553&doi=10.1016%2fj.cpc.2017.03.002&partnerID=40&md5=87cb78fe04faf389b66ffe965b965897","In this paper, we introduce an interactive coastal wave simulation and visualization software, called Celeris. Celeris is an open source software which needs minimum preparation to run on a Windows machine. The software solves the extended Boussinesq equations using a hybrid finite volume–finite difference method and supports moving shoreline boundaries. The simulation and visualization are performed on the GPU using Direct3D libraries, which enables the software to run faster than real-time. Celeris provides a first-of-its-kind interactive modeling platform for coastal wave applications and it supports simultaneous visualization with both photorealistic and colormapped rendering capabilities. We validate our software through comparison with three standard benchmarks for non-breaking and breaking waves. Program summary Program title: Celeris Program Files doi: http://dx.doi.org/10.17632/5djwvf5x5k.1 Licensing provisions : GNU General Public License 3 (GPL) Programming language : C++, HLSL Nature of problem : Boussinesq-type models provide the research-level accuracy needed for modeling wave propagation in coastal zones. However the current models, both commercial and open source, do not provide means for real-time computation, nor provide model interactivity and concurrent visualization. In order to achieve a real-time simulation speed in current parallelized models, dozens to hundreds of CPU cores are needed. Celeris is an interactive software which provides faster than real-time simulation and visualization speed on an average user laptop. The novelty of this software is its interactive environment, which allows the user to modify the model and field parameters as the model is running, and to see the effect of these changes immediately. Solution method : A hybrid finite volume-finite difference scheme is used to solve the extended Boussinesq equations. The solver is parallelized using shader programming with Direct3D libraries. Visualization is also performed with the same libraries. © 2017 Elsevier B.V.","Boussinesq; GPU; Interactive modeling; Shader; Wave propagation; Wave visualization","C++ (programming language); Coastal engineering; Coastal zones; Computer aided software engineering; Computer programming; Computer software; Finite difference method; Graphics processing unit; Libraries; Open systems; Software engineering; Transients; Visualization; Water waves; Wave propagation; Boussinesq; GNU general public license; Hybrid finite volume finite difference scheme; Interactive Environments; Interactive modeling; Real-time interactive simulation and visualization; Shader; Simulation and visualizations; Open source software",2-s2.0-85018744553
"Maurits L., Forkel R., Kaiping G.A., Atkinson Q.D.","BEASTling: A software tool for linguistic phylogenetics using BEAST 2",2017,"PLoS ONE",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027222934&doi=10.1371%2fjournal.pone.0180908&partnerID=40&md5=9dc8cb489c85e8537f84c373ffaa9ce6","We present a new open source software tool called BEASTling, designed to simplify the preparation of Bayesian phylogenetic analyses of linguistic data using the BEAST 2 platform. BEASTling transforms comparatively short and human-readable configuration files into the XML files used by BEAST to specify analyses. By taking advantage of Creative Commons-licensed data from the Glottolog language catalog, BEASTling allows the user to conveniently filter datasets using names for recognised language families, to impose monophyly constraints so that inferred language trees are backward compatible with Glottolog classifications, or to assign geographic location data to languages for phylogeographic analyses. Support for the emerging cross-linguistic linked data format (CLDF) permits easy incorporation of data published in cross-linguistic linked databases into analyses. BEASTling is intended to make the power of Bayesian analysis more accessible to historical linguists without strong programming backgrounds, in the hopes of encouraging communication and collaboration between those developing computational models of language evolution (who are typically not linguists) and relevant domain experts. © 2017 Maurits et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",,"Article; Bayes theorem; Bayesian linguistic phylogenetics; binary Covarion model; broad data compatibility; cladistics; classification; comma separated value; computational model; computer language; cross linguistic linked data format; data processing; expert knowledge; factual database; Glottolog classification; information processing device; intelligent processing; knowledge; Lewis Mk model; linguistics; Markov Chain Monte Carlo; Monte Carlo method; phylogenetic tree; phylogeny; phylogeography; posterior distribution; probabilistic model; probability; reproducibility; software; statistical distribution; statistical model; tab separated value; uncertainty; Bayes theorem; Europe; expert system; human; language; linguistics; procedures; Bayes Theorem; Europe; Expert Systems; Humans; Language; Linguistics; Programming Languages; Software",2-s2.0-85027222934
"Shi N., Min Z., Zhang P.","Effects of visualizing roles of variables with animation and IDE in novice program construction",2017,"Telematics and Informatics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013954997&doi=10.1016%2fj.tele.2017.02.005&partnerID=40&md5=6afff5728c45e071d9e256459439521f","In this research, the researchers apply the roles of variables visualization to the teaching of novice C language programmers. The results are evaluated using the Structure of Observed Learning Outcomes (SOLO) taxonomy. The participants of the research were fifty-five undergraduates who major in computer science at a polytechnic institute. They were divided into an experimental group and a control group. The students from the control group learned programming in the traditional role-based teaching method. The students in the experimental group learned programming using variables visualization with the support of PlanAni and generic integrated development environment (IDE). For the purposes of determining the effects of the role-based visualization teaching, the SOLO level of the code writing was graded according the SOLO categories for program construction. A course satisfaction questionnaire was conducted. Data analyses show there was a significant improvement of SOLO level of program construction and a higher approval about the roles of variables. These results indicate that visualizing the roles of variables with animations and IDE can provide novices with a new conceptual framework that enables them to design relational program from a holistic point of view and helps them learn the concept of the roles of variables. © 2017 Elsevier Ltd","Novice programming; Roles of variables; SOLO taxonomy; Teaching/learning strategies; Visualization","Flow visualization; Integrodifferential equations; Taxonomies; Teaching; Visualization; Conceptual frameworks; Experimental groups; Integrated development environment; Novice programming; Program construction; Roles of variables; Teaching methods; Teaching/learning strategy; C (programming language)",2-s2.0-85013954997
"Könemann J., Olver N., Pashkovich K., Ravi R., Swamy C., Vygen J.","On the integrality gap of the prize-collecting steiner forest LP",2017,"Leibniz International Proceedings in Informatics, LIPIcs",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028703666&doi=10.4230%2fLIPIcs.APPROX%2fRANDOM.2017.17&partnerID=40&md5=7ec26ce9c31e19d02175dec121ac44bc","In the prize-collecting Steiner forest (PCSF) problem, we are given an undirected graph G = (V,E), edge costs {ce φ 0}e2E, terminal pairs {(si, ti)}ki =1, and penalties {i}ki =1 for each terminal pair; the goal is to find a forest F to minimize c(F) + P i:(si,ti) not connected in F i. The Steiner forest problem can be viewed as the special case where i = 1 for all i. It was widely believed that the integrality gap of the natural (and well-studied) linear-programming (LP) relaxation for PCSF (PCSF-LP) is at most 2. We dispel this belief by showing that the integrality gap of this LP is at least 9/4. This holds even for planar graphs. We also show that using this LP, one cannot devise a Lagrangian-multiplier-preserving (LMP) algorithm with approximation guarantee better than 4. Our results thus show a separation between the integrality gaps of the LP-relaxations for prize-collecting and non-prize-collecting (i.e., standard) Steiner forest, as well as the approximation ratios achievable relative to the optimal LP solution by LMP- and non-LMP- approximation algorithms for PCSF. For the special case of prize-collecting Steiner tree (PCST), we prove that the natural LP relaxation admits basic feasible solutions with all coordinates of value at most 1/3 and all edge variables positive. Thus, we rule out the possibility of approximating PCST with guarantee better than 3 using a direct iterative rounding method. © Jochen Könemann, Neil Olver, Kanstantsin Pashkovich, R. Ravi, Chaitanya Swamy, and Jens Vygen.","Integrality gap; Lagrangianmultiplier-preserving; Prize-collecting; Steiner forest; Steiner tree","C (programming language); Combinatorial optimization; Graph theory; Iterative methods; Lagrange multipliers; Linear programming; Optimization; Random processes; Integrality gaps; Lagrangianmultiplier-preserving; Prize-collecting; Steiner forests; Steiner trees; Approximation algorithms",2-s2.0-85028703666
"Michelet C., Barberet P., Desbarats P., Giovannelli J.-F., Schou C., Chebil I., Delville M.-H., Gordillo N., Beasley D.G., Devès G., Moretto P., Seznec H.","An implementation of the NiftyRec medical imaging library for PIXE-tomography reconstruction",2017,"Nuclear Instruments and Methods in Physics Research, Section B: Beam Interactions with Materials and Atoms",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012253711&doi=10.1016%2fj.nimb.2017.01.067&partnerID=40&md5=a0ffdfe0646751074b226c581fab95eb","A new development of the TomoRebuild software package is presented, including “thick sample” correction for non linear X-ray production (NLXP) and X-ray absorption (XA). As in the previous versions, C++ programming with standard libraries was used for easier portability. Data reduction requires different steps which may be run either from a command line instruction or via a user friendly interface, developed as a portable Java plugin in ImageJ. All experimental and reconstruction parameters can be easily modified, either directly in the ASCII parameter files or via the ImageJ interface. A detailed user guide in English is provided. Sinograms and final reconstructed images are generated in usual binary formats that can be read by most public domain graphic softwares. New MLEM and OSEM methods are proposed, using optimized methods from the NiftyRec medical imaging library. An overview of the different medical imaging methods that have been used for ion beam microtomography applications is presented. In TomoRebuild, PIXET data reduction is performed for each chemical element independently and separately from STIMT, except for two steps where the fusion of STIMT and PIXET data is required: the calculation of the correction matrix and the normalization of PIXET data to obtain mass fraction distributions. Correction matrices for NLXP and XA are calculated using procedures extracted from the DISRA code, taking into account a large X-ray detection solid angle. For this, the 3D STIMT mass density distribution is used, considering a homogeneous global composition. A first example of PIXET experiment using two detectors is presented. Reconstruction results are compared and found in good agreement between different codes: FBP, NiftyRec MLEM and OSEM of the TomoRebuild software package, the original DISRA, its accelerated version provided in JPIXET and the accelerated MLEM version of JPIXET, with or without correction. © 2017 Elsevier B.V.","Caenorhabditis elegans; Filtered backprojection; ImageJ; MLEM; OSEM; PIXE tomography; Quantitative imaging","C++ (programming language); Chemical elements; Computer programming; Data reduction; Image processing; Image reconstruction; Ion beams; Matrix algebra; Software packages; Tomography; X ray absorption; X ray production; Caenorhabditis elegans; Filtered back-projection; ImageJ; MLEM; OSEM; Quantitative imaging; Medical imaging",2-s2.0-85012253711
"Trinder P., Chechina N., Papaspyrou N., Sagonas K., Thompson S., Adams S., Aronis S., Baker R., Bihari E., Boudeville O., Cesarini F., Di Stefano M., Eriksson S., Fördos V., Ghaffari A., Giantsios A., Green R., Hoch C., Klaftenegger D., Li H., Lundin K., Mackenzie K., Roukounaki K., Tsiouris Y., Winblad K.","Scaling reliably: Improving the scalability of the Erlang distributed actor platform",2017,"ACM Transactions on Programming Languages and Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028507134&doi=10.1145%2f3107937&partnerID=40&md5=5904bb1d0e4f3acb862eb58b1c7e5dca","Distributed actor languages are an effective means of constructing scalable reliable systems, and the Erlang programming language has a well-established and influential model. While the Erlang model conceptually provides reliable scalability, it has some inherent scalability limits and these force developers to depart from the model at scale. This article establishes the scalability limits of Erlang systems and reports the work of the EU RELEASE project to improve the scalability and understandability of the Erlang reliable distributed actor model. We systematically study the scalability limits of Erlang and then address the issues at the virtual machine, language, and tool levels. More specifically: (1) We have evolved the Erlang virtual machine so that it can work effectively in large-scale single-host multicore and NUMA architectures. We have made important changes and architectural improvements to the widely used Erlang/OTP release. (2) We have designed and implemented Scalable Distributed (SD) Erlang libraries to address language-level scalability issues and provided and validated a set of semantics for the new language constructs. (3) To make large Erlang systems easier to deploy, monitor, and debug, we have developed and made open source releases of five complementary tools, some specific to SD Erlang. Throughout the article we use two case studies to investigate the capabilities of our new technologies and tools: a distributed hash table based Orbit calculation and Ant Colony Optimisation (ACO). Chaos Monkey experiments show that two versions of ACO survive random process failure and hence that SD Erlang preserves the Erlang reliability model. While we report measurements on a range of NUMA and cluster architectures, the key scalability experiments are conducted on the Athos cluster with 256 hosts (6,144 cores). Even for programs with no global recovery data to maintain, SD Erlang partitions the network to reduce network traffic and hence improves performance of the Orbit and ACO benchmarks above 80 hosts. ACO measurements show that maintaining global recovery data dramatically limits scalability; however, scalability is recovered by partitioning the recovery data. We exceed the established scalability limits of distributed Erlang, and do not reach the limits of SD Erlang for these benchmarks at this scale (256 hosts, 6,144 cores). © 2017 ACM.","Erlang; Reliability; Scalability","Ant colony optimization; Artificial intelligence; Benchmarking; Computer system recovery; Network architecture; Network security; Open source software; Open systems; Program debugging; Random processes; Recovery; Reliability; Scalability; Semantics; Virtual addresses; Virtual machine; Architectural improvements; Cluster architecture; Complementary tools; Distributed Hash Table; Erlang; Erlang programming language; Language constructs; Monkey experiments; Distributed computer systems",2-s2.0-85028507134
"Kebir S., Borne I., Meslati D.","A genetic algorithm-based approach for automated refactoring of component-based software",2017,"Information and Software Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015986827&doi=10.1016%2fj.infsof.2017.03.009&partnerID=40&md5=0f645a97f59e8f9bf9c137c3cf006278","Context: During its lifecycle, a software system undergoes repeated modifications to quickly fulfill new requirements, but its underlying design is not properly adjusted after each update. This leads to the emergence of bad smells. Refactoring provides a de facto behavior-preserving approach to eliminate these anomalies. However, manually determining and performing useful refactorings is a formidable challenge, as stated in the literature. Therefore, framing object-oriented automated refactoring as a search-based technique has been proposed. However, the literature shows that search-based refactoring of component-based software has not yet received proper attention. Objective: This paper presents a genetic algorithm-based approach for the automated refactoring of component-based software. This approach consists of detecting component-relevant bad smells and eliminating these bad smells by searching for the best sequence of refactorings using a genetic algorithm. Method: Our approach consists of four steps. The first step includes studying the literature related to component-relevant bad smells and formulating bad smell detection rules. The second step involves proposing a catalog of component-relevant refactorings. The third step consists of constructing a source code model by extracting facts from the source code of a component-based software. The final step seeks to identify the best sequence of refactorings to apply to reduce the presence of bad smells in the source code model using a genetic algorithm. The latter uses bad smell detection rules as a fitness function and the catalog of refactorings as a means to explore the search space. Results: As a case study, we conducted experiments on an unbiased set of four real-world component-based applications. The results indicate that our approach is able to efficiently reduce the total number of bad smells by more than one half, which is an acceptable value compared to the recent literature. Moreover, we determined that our approach is also accurate in refactoring only components suffering from bad smells while leaving the remaining components untouched whenever possible. Furthermore, a statistical analysis shows that our genetic algorithm outperforms random search and local search in terms of efficiency and accuracy on almost all the systems investigated in this work. Conclusion: This paper presents a search-based approach for the automated refactoring of component-based software. To the best of our knowledge, our approach is the first to focus on component-based refactoring, whereas the state-of-the-art approaches focus only on object-oriented refactoring. © 2017 Elsevier B.V.","Bad smells; Component-based software engineering; Genetic algorithm; Refactoring","Automation; Codes (symbols); Computer programming languages; Genetic algorithms; Odors; Software engineering; Bad smells; Component based applications; Component based software; Component-based software engineering; Refactorings; Remaining component; Search-based refactoring; State-of-the-art approach; Object oriented programming",2-s2.0-85015986827
"Stavropoulou I., Grigoriou M., Kontogiannis K.","Case study on which relations to use for clustering-based software architecture recovery",2017,"Empirical Software Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010789952&doi=10.1007%2fs10664-016-9459-z&partnerID=40&md5=aa7567762ac15bbe4cf7cffb1b99068f","Clustering-based software architecture recovery is an area that has received significant attention in the software engineering community over the years. Its key concept is the compilation and clustering of a system-wide graph that consists of source code entities as nodes, and source code relations as edges. However, the related research has mostly focused on investigating different clustering methods and techniques, and consequently there is limited work on addressing the question of what is a minimal set of relations that can be easily extracted from the system’s source code, and yet can be accurately used for extracting its architecture. In this paper, we report on results obtained from an architecture recovery case study we have conducted, by considering all possible combinations which can be generated from thirteen commonly used source code relations. We have examined the similarity of the extracted architectures obtained by using each different relation combination for different systems, against the corresponding architecture which is obtained by applying all thirteen relations and whch we consider as the ground truth architecture. For this purpose, we have also examined whether the use of all these thirteen relations is indeed adequate to yield a ground truth architecture, by applying this architecture extraction process on five large sofware systems for which their ground truth architecture has been independently established. The overall results of our study indicate that there is small set of relations for procedural systems, and another similar set for object oriented systems, that can be easily extracted from the source code and yet used to yield an architecture that is close to the ground truth architecture. © 2017, Springer Science+Business Media New York.","Architecture recovery; Case study; Clustering; Reverse engineering; Source code relations","Codes (symbols); Computer programming languages; Engineering research; Object oriented programming; Recovery; Reverse engineering; Software architecture; Software engineering; Architecture recovery; Clustering; Engineering community; Extraction process; Object-oriented system; Software architecture recovery; Source code entities; Source codes; Extraction",2-s2.0-85010789952
"Oliehoek F.A., Spaan M.T.J., Terwijn B., Robbel P., Messias J.V.","The MADP toolbox: An open source library for planning and learning in (multi-)agent systems",2017,"Journal of Machine Learning Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030168139&partnerID=40&md5=2bfca295b227177817fff495a5075037","This article describes the Multiagent Decision Process (MADP) Toolbox, a software library to support planning and learning for intelligent agents and multiagent systems in uncertain environments. Key features are that it supports partially observable environments and stochastic transition models; has unified support for single- and multiagent systems; provides a large number of models for decision-theoretic decision making, including one-shot and sequential decision making under various assumptions of observability and cooperation, such as Dec-POMDPs and POSGs; provides tools and parsers to quickly prototype new problems; provides an extensive range of planning and learning algorithms for single- and multiagent systems; is released under the GNU GPL v3 license; and is written in C++ and designed to be extensible via the object-oriented paradigm. ©2017 Frans A. Oliehoek, Matthijs T. J. Spaan, Bas Terwijn, Philipp Robbel and João V. Messias.","Decision-theoretic planning; Multiagent systems; Reinforcement learning; Software","C++ (programming language); Computer software; Decision making; Intelligent agents; Learning algorithms; Object oriented programming; Open source software; Open systems; Reinforcement learning; Software agents; Stochastic models; Stochastic systems; Decision-theoretic planning; Multiagent decisions; Object oriented paradigm; Open-source libraries; Partially observable environments; Sequential decision making; Stochastic transitions; Uncertain environments; Multi agent systems",2-s2.0-85030168139
"Smith S., Chan S.","Collaborative and Competitive Video Games for Teaching Computing in Higher Education",2017,"Journal of Science Education and Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015241595&doi=10.1007%2fs10956-017-9690-4&partnerID=40&md5=89ddd17e747f2c566b7fe70f837f4035","This study measures the success of using a collaborative and competitive video game, named Space Race, to teach computing to first year engineering students. Space Race is played by teams of four, each with their own tablet, collaborating to compete against the other teams in the class. The impact of the game on student learning was studied through measurements using 485 students, over one term. Surveys were used to gauge student reception of the game. Pre and post-tests, and in-course examinations were used to quantify student performance. The game was well received with at least 82% of the students that played it recommending it to others. In some cases, game participants outperformed non-participants on course exams. On the final course exam, all of the statistically significant (p<0.05) comparisons (42% of the relevant questions) showed a performance improvement of game participants on the questions, with a maximum grade improvement of 41%. The findings also suggest that some students retain the knowledge obtained from Space Race for at least 7 weeks. The results of this study provide strong evidence that a collaborative and competitive video game can be an effective tool for teaching computing in post-secondary education. © 2017, Springer Science+Business Media New York.","Collaborative learning; Game design; Improving classroom teaching; Post-secondary education; Programming and programming languages",,2-s2.0-85015241595
"Accattoli B., Sacerdoti Coen C.","On the value of variables",2017,"Information and Computation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010931262&doi=10.1016%2fj.ic.2017.01.003&partnerID=40&md5=07a92395d2a937d0672d62d5d654317a","Call-by-value and call-by-need λ-calculi are defined using the distinguished syntactic category of values. In theoretical studies, values are variables and abstractions. In more practical works, values are usually defined simply as abstractions. This paper shows that practical values lead to a more efficient process of substitution—for both call-by-value and call-by-need—once the usual hypotheses for implementations hold (terms are closed, reduction does not go under abstraction, and substitution is done in micro steps, replacing one variable occurrence at a time). Namely, the number of substitution steps becomes linear in the number of β-redexes, while theoretical values only provide a quadratic bound. We complete the picture by showing that the same quadratic / linear bounds also hold for theoretical / practical versions of call-by-name. © 2017 Elsevier Inc.","Cost models; Explicit substitutions; Implementations of functional programming languages; λ-Calculus","Abstracting; Biomineralization; Calculations; Differentiation (calculus); Syntactics; Cost models; Efficient process; Explicit Substitutions; Practical works; Quadratic bound; Substitution step; Theoretical study; Theoretical values; Functional programming",2-s2.0-85010931262
"Mahmoud A., Bradshaw G.","Semantic topic models for source code analysis",2017,"Empirical Software Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84996550774&doi=10.1007%2fs10664-016-9473-1&partnerID=40&md5=c6347f485af1fc7281259cdca46e78b0","Topic modeling techniques have been recently applied to analyze and model source code. Such techniques exploit the textual content of source code to provide automated support for several basic software engineering activities. Despite these advances, applications of topic modeling in software engineering are frequently suboptimal. This can be attributed to the fact that current state-of-the-art topic modeling techniques tend to be data intensive. However, the textual content of source code, embedded in its identifiers, comments, and string literals, tends to be sparse in nature. This prevents classical topic modeling techniques, typically used to model natural language texts, to generate proper models when applied to source code. Furthermore, the operational complexity and multi-parameter calibration often associated with conventional topic modeling techniques raise important concerns about their feasibility as data analysis models in software engineering. Motivated by these observations, in this paper we propose a novel approach for topic modeling designed for source code. The proposed approach exploits the basic assumptions of the cluster hypothesis and information theory to discover semantically coherent topics in software systems. Ten software systems from different application domains are used to empirically calibrate and configure the proposed approach. The usefulness of generated topics is empirically validated using human judgment. Furthermore, a case study that demonstrates thet operation of the proposed approach in analyzing code evolution is reported. The results show that our approach produces stable, more interpretable, and more expressive topics than classical topic modeling techniques without the necessity for extensive parameter calibration. © 2016, Springer Science+Business Media New York.","Clustering; Information theory; Topic modeling","Application programs; Calibration; Codes (symbols); Computer programming languages; Computer software; Information theory; Semantics; Software engineering; Clustering; Data analysis models; Engineering activities; Natural language text; Operational complexity; Parameter calibration; Source code analysis; Topic Modeling; Modeling languages",2-s2.0-84996550774
"Jiang Y., Song H., Wang R., Gu M., Sun J., Sha L.","Data-centered runtime verification of wireless medical cyber-physical system",2017,"IEEE Transactions on Industrial Informatics",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029676612&doi=10.1109%2fTII.2016.2573762&partnerID=40&md5=4ebb96e39179720c8939934def1071c3","Wireless medical cyber-physical systems are widely adopted in the daily practices of medicine, where huge amounts of data are sampled by the wireless medical devices and sensors, and is passed to the decision support systems (DSSs). Many text-based guidelines have been encoded for work-flow simulation of DSS to automate health care based on those collected data. But for some complex and life-critical diseases, it is highly desirable to automatically rigorously verify some complex temporal properties encoded in those data, which brings new challenges to current simulation-based DSS with limited support of automatical formal verification and real-time data analysis. In this paper, we conduct the first study on applying runtime verification to cooperate with current DSS based on real-time data. Within the proposed technique, a user-friendly domain specific language, named DRTV, is designed to specify vital real-time data sampled by medical devices and temporal properties originated from clinical guidelines. Some interfaces are developed for data acquisition and communication. Then, for medical practice scenarios described in DRTV model, we will automatically generate event sequences and runtime property verifier automata. If a temporal property violates, real-time warnings will be produced by the formal verifier and passed to medical DSS. We have used DRTV to specify different kinds of medical care scenarios and have applied the proposed technique to assist existing wireless medical cyber-physical system. As presented in experiment results, in terms of warning detection, it outperforms the only use of DSS or human inspection, and improves the quality of clinical health care of hospital. © 2005-2012 IEEE.","Decision support system (DSS); real-time data; runtime verification; wireless medical cyber-physical system","Artificial intelligence; Biomedical equipment; Computer aided software engineering; Computer programming languages; Cyber Physical System; Data acquisition; Decision support systems; Formal verification; Graphical user interfaces; Health care; Medicine; Problem oriented languages; Decision support system (dss); Decision support system (DSSs); Domain specific languages; Medical cyber physical systems; Real time data analysis; Real-time data; Run-time verification; Wireless medical devices; Embedded systems",2-s2.0-85029676612
"Dunster T.M., Gil A., Segura J., Temme N.M.","Conical : An extended module for computing a numerically satisfactory pair of solutions of the differential equation for conical functions",2017,"Computer Physics Communications",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019131876&doi=10.1016%2fj.cpc.2017.04.007&partnerID=40&md5=bf90c4913ac079e93a05756a6b6c10b1","Conical functions appear in a large number of applications in physics and engineering. In this paper we describe an extension of our module Conical (Gil et al., 2012) for the computation of conical functions. Specifically, the module includes now a routine for computing the function R−[Formula presented]+iτ m(x), a real-valued numerically satisfactory companion of the function P−[Formula presented]+iτ m(x) for x&gt;1. In this way, a natural basis for solving Dirichlet problems bounded by conical domains is provided. The module also improves the performance of our previous algorithm for the conical function P−[Formula presented]+iτ m(x) and it includes now the computation of the first order derivative of the function. This is also considered for the function R−[Formula presented]+iτ m(x) in the extended algorithm. Program summary Program Title: Module Conical Program Files doi: http://dx.doi.org/10.17632/rpw5d8gdkg.1 Licensing provisions: CC by 4.0 Programming language: Fortran 90 External routines/libraries: The module Conical uses a Fortran 90 version of the routine dkia (developed by the authors) for computing the modified Bessel functions Kia(x) and its derivative. This routine is available at http://toms.calgo.org. Nature of problem: These functions are the natural function basis for solving, for example, the Laplace's problem in spherical coordinates for two intersecting cones or for regions bounded by two intersecting spheres, or by one or two confocal hyperboloids of revolution when using toroidal coordinates. The conical function P−[Formula presented]+iτ m(x) is also used in the Mehler–Fock integral transform for problems in potential and heat theory, Solution method: The algorithm uses different methods of computation depending on the function under consideration (P−[Formula presented]+iτ m(x) or R−[Formula presented]+iτ m(x)) and the values of x, τ and m: numerical quadrature, asymptotic expansions in terms of elementary functions, asymptotic expansions in terms of Bessel functions, asymptotic expansions for tau large and backward/forward recursion of three-term recurrence relations. Restrictions: In order to avoid underflow/overflow problems in standard IEEE double precision arithmetic, the admissible parameter ranges for computing the conical function P−[Formula presented]+iτ m(x) in the routine conicp are: −1&lt;x&lt;1,0&lt;τ&lt;=100,0≤m≤40 1&lt;x≤100,0&lt;τ≤100,0≤m≤100.When using the routines conicr and conicpr, the admissible parameter ranges for computing the functions P−[Formula presented]+iτ m(x) and R−[Formula presented]+iτ m(x) are 1&lt;x≤100,0&lt;τ≤100,0≤m≤100. © 2017 Elsevier B.V.","Algorithms; Conical functions; Legendre functions; Numerical evaluation of special functions; Real-valued numerically satisfactory pair of solutions","Algorithms; Asymptotic analysis; Bessel functions; Computation theory; Differential equations; Digital arithmetic; FORTRAN (programming language); Functions; Integral equations; Numerical methods; Problem oriented languages; Admissible parameters; First order derivatives; Legendre function; Modified Bessel function; Special functions; Spherical coordinates; Three term recurrence relations; Toroidal coordinates; Problem solving",2-s2.0-85019131876
"Karimi M., Droghetti H., Marchisio D.L.","PUFoam : A novel open-source CFD solver for the simulation of polyurethane foams",2017,"Computer Physics Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018770844&doi=10.1016%2fj.cpc.2017.03.010&partnerID=40&md5=88540b8c23ff6f289b2aaa998725f901","In this work a transient three-dimensional mathematical model is formulated and validated for the simulation of polyurethane (PU) foams. The model is based on computational fluid dynamics (CFD) and is coupled with a population balance equation (PBE) to describe the evolution of the gas bubbles/cells within the PU foam. The front face of the expanding foam is monitored on the basis of the volume-of-fluid (VOF) method using a compressible solver available in OpenFOAM version 3.0.1. The solver is additionally supplemented to include the PBE, solved with the quadrature method of moments (QMOM), the polymerization kinetics, an adequate rheological model and a simple model for the foam thermal conductivity. The new solver is labelled as PUFoam and is, for the first time in this work, validated for 12 different mixing-cup experiments. Comparison of the time evolution of the predicted and experimentally measured density and temperature of the PU foam shows the potentials and limitations of the approach. Program summary Program Title: PUFoam Program Files doi: http://dx.doi.org/10.17632/62ggzx623g.1 Licensing provisions: GNU General Public License 3 (GPL) Programming language: C++. Supplementary material: In order to test the main solver all the required input files have been provided within the testCase directory. This could be either directly used or modified according to user's needs. Nature of problem: The CFD solver developed through this research work provides a numerical mean for the simulation of polyurethane foam. The problem includes a reacting multi-phase system in which the liquid mixture expands due to the polymerization phenomenon and the presence of different additives. In that, the gas bubbles nuclei within the reacting liquid mixture start to grow owing to the diffusion of gases produced due to the chemical reactions. Further, industrial applications such as mould-filling seek for capturing the foam front face and the evolution of its physical and thermal properties during the foaming process. Thus, the solver shall facilitate the evolution of gas bubbles via a population balance equation, capturing the foam interface using a volume-of-fluid method, and eventually predicts the foam characteristics. Solution method: Conservation equations for mass and momentum as well as phase fraction equations are solved using the standard finite volume method. The indicator function (i.e., the phase fraction equation in this case) is solved for the primary phase taking into account the density variation of the foam which is implemented as the compressibility effect. Additional transport equations are also solved to yield the progress of the polymerization process through the conversions of water, isocyanate, and the amount of gases produced. Finally, the evolution of the cell size distribution inside the foam phase is evaluated by using a population balance equation. The solution of PBE inside the CFD code is performed by transforming the problem into a set of transport equations for the moments of bubble/cell size distribution. The quadrature method of moments (QMOM) is applied to approximate the right hand side of moments equations which represent the growth and coalescence of bubbles. External routines/libraries: OpenFOAM® (version 3.0.1) (http://www.openfoam.org) Restrictions: Due to lack of available experimentally-based or analytical models, the current version of the solver supports two different blowing agents including n-pentane and R-11. Further, the growth rate of the bubbles is assumed to be diffusion-controlled and its rate associated with the concentration gradient around the bubbles. This restriction will be relaxed in near future by adopting a detailed model for the bubble growth rate. It must be also reminded that the solver is compiled with OpenFOAM version 3.0.1 and compiling it with other versions might require additional efforts. © 2017 Elsevier B.V.","Computational fluid dynamics; Polyurethane foam; Population balance equation; Quadrature method of moments; Volume-of-fluid","Blowing agents; Bubbles (in fluids); C++ (programming language); Diffusion in liquids; Finite volume method; Fluid dynamics; Gases; Method of moments; Mixtures; Molds; Open source software; Paraffins; Phase interfaces; Polymerization; Polyurethanes; Problem oriented languages; Produced Water; Rigid foamed plastics; Size distribution; Thermal conductivity; Compressibility effects; Concentration gradients; GNU general public license; Polyurethane Foam; Population balance equation; Quadrature method of moments; Three-dimensional mathematical models; Volume of fluids; Computational fluid dynamics",2-s2.0-85018770844
"Baxhaku B., Agrawal P.N.","Degree of approximation for bivariate extension of Chlodowsky-type q-Bernstein–Stancu–Kantorovich operators",2017,"Applied Mathematics and Computation",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014768157&doi=10.1016%2fj.amc.2017.02.007&partnerID=40&md5=11c9348f0d2fffa344c5bc47fc292de3","In this paper, we introduce the bivariate generalization of the Chlodowsky-type q-Bernstein–Stancu–Kantorovich operators on an unbounded domain and studied the rate of convergence in terms of the Lipschitz class function and complete modulus of continuity. Further, we establish the weighted approximation properties for these operators. The aim of this paper is to obtain the degree of approximation for these bivariate operators in terms of the partial moduli of continuity and the Peetre's K- functional. Then, we give generalization of the operators and investigate their approximations. Furthermore, we show the convergence of the bivariate Chlodowsky-type operators to certain functions by illustrative graphics using Python programming language. Finally, we construct the GBS operators of bivariate Chlodowsky-type q-Bernstein–Stancu–Kantorovich and estimate the rate of convergence for these operators with the help of mixed modulus of smoothness. © 2017 Elsevier Inc.","B-continuous; B-differentiable; GBS operators; Partial moduli of continuity; q-Bernstein–Stancu–Kantorovich operators; Weighted approximation","Computational methods; Mathematical techniques; Degree of approximation; Moduli of continuities; Modulus of continuity; Modulus of smoothness; Python programming language; Rate of convergence; Unbounded domain; Weighted approximation; Approximation theory",2-s2.0-85014768157
"Avery P., Falls Z., Zurek E.","XTALOPT Version r10: An open–source evolutionary algorithm for crystal structure prediction",2017,"Computer Physics Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969797888&doi=10.1016%2fj.cpc.2017.04.001&partnerID=40&md5=e64d247022e998c1fd0d2b11744d0a31","A new version of XTALOPT, an evolutionary algorithm for crystal structure prediction, is available for download from the CPC library or the XTALOPT website, http://xtalopt.github.io. XTALOPT is published under the Gnu Public License (GPL), which is an open source license that is recognized by the Open Source Initiative. The new version incorporates many bug-fixes and new features, as detailed below. New version program summary Program Title:XTALOPT Program Files doi: http://dx.doi.org/10.17632/jt5pvnnm39.1 Licensing provisions: GPL v2.1 [1] Programming language: C++ Journal Reference of previous version: Comput. Phys. Commun. 199 (2016) 178 External routines/libraries:QT [2], OPEN BABEL [3], AVOGADRO [4], LIBSSH [5] and one of: VASP [6], PWSCF [7], GULP [8], CASTEP [9], SIESTA [10] MOPAC [11], ADF [12], GAMESS [13], Gaussian [14] Subprograms used:SPGLIB [15], RANDSPG [16] Nature of problem: Predicting the crystal structure of a system from its stoichiometry alone remains a grand challenge in computational materials science, chemistry, and physics. Solution method: Evolutionary algorithms (EAs) are stochastic search techniques that use concepts from biological evolution to search for the global minimum (or a good approximation for it) in a multidimensional problem. Applied to a priori crystal structure prediction, EAs search to find atomic arrangements that correspond to stable (low energy or enthalpy) regions of the chemical structure's potential energy landscape. The XTALOPT evolutionary algorithm is available for use and collaboration under the GNU Public License, which is an open-source license that is officially recognized by the Open Source Initiative [17]. See the publication on XTALOPT's original implementation [18] and previous version announcements [19, 20], as well as publications on XTALCOMP [21] and RANDOMDOCK [22], for more information on the method. Reasons for new version: Since the release of XTALOPT version r9 in February 2016 various bug-fixes have been made, along with the addition of several new features: • Implementation of RANDSPG [23], an algorithm that generates random crystals with specific spacegroups. This algorithm can optionally be used to create symmetric structures in the initial random generation.• Inclusion of variable formula units within XTALOPT enables the search for cells with multiple numbers of formula units within a single run.• A molecular-unit generator permits users to create single-center molecules in the unit cell during the initial generation step. Summary of revisions:RANDSPG has been incorporated into XTALOPT to allow users to define spacegroups for the initial structure generation. Variable formula units have also been included so that instead of carrying out many runs with various formula units, a single run involving a range of formula units can be performed. To create molecular-like structures during the initial generation, a molecular builder has been introduced within this version of XTALOPT. Acknowledgments: We acknowledge the NSF (DMR-1505817) and the ONR (N000141612583) for financial support and the Center for Computational Research (CCR) at SUNY Buffalo for computational support. This research was supported in part by the New York State Center of Excellence in Materials Informatics. References: [1] http://www.gnu.org/licenses/gpl.html[2] http://www.qt.io[3] http://openbabel.org[4] http://avogadro.cc[5] http://www.libssh.org[6] http://www.vasp.at[7] http://www.quantum-espresso.org[8] https://gulp.curtin.edu.au/gulp/[9] http://www.castep.org[10] http://www.icmab.es/siesta[11] http://www.openmopac.net[12] http://www.scm.com[13] http://www.msg.ameslab.gov/gamess[14] http://gaussian.com[15] https://atztogo.github.io/spglib/[16] http://xtalopt.openmolecules.net/randSpg/randSpg.html[17] http://opensource.org/[18] D. Lonie, E. Zurek, Comput. Phys. Commun. 182 (2011) 372–387, http://dx.doi.org/10.1016/j.cpc.2010.07.048[19] D. Lonie, E. Zurek, Comput. Phys. Commun. 182 (2011) 2305–2306, http://dx.doi.org/10.1016/j.cpc.2011.06.003[20] Z. Falls, D. Lonie, P. Avery, A. Shamp, E. Zurek, Comput. Phys. Commmun. 199 (2016) 178–179, http://dx.doi.org/10.1016/j.cpc.2015.09.018[21] D. Lonie, E. Zurek, Comput. Phys. Commun. 183 (2012) 690–697, http://dx.doi.org/10.1016/j.cpc.2011.11.007[22] A. Wach, J. Chen, Z. Falls, D. Lonie, E. Mojica, D. Aga, J. Autschbach, E. Zurek, Anal. Chem. 85 (2013) 8577–8584, http://dx.doi.org/10.1021/ac402004z[23] P. Avery, E. Zurek, Comput. Phys. Commun. 213 (2017) 208–216, http://dx.doi.org/10.1016/j.cpc.2016.12.005 © 2017 Elsevier B.V.","Crystal structures; Evolutionary algorithm; Genetic algorithm; Structure prediction","Approximation algorithms; Bioinformatics; Biology; C++ (programming language); Computational chemistry; Crystal atomic structure; Evolutionary algorithms; Forecasting; Genetic algorithms; HTTP; Open source software; Potential energy; Problem oriented languages; Stochastic systems; Computational materials science; Computational researches; Crystal structure prediction; Evolutionary algorithms (EAs); Multidimensional problems; Potential energy landscapes; Stochastic search techniques; Structure prediction; Crystal structure",2-s2.0-84969797888
"Muñoz-Santiburcio D., Hernández-Laguna A.","AWESOME 1.1: A code for the calculation of phase and group velocities of acoustic waves in homogeneous solids",2017,"Computer Physics Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018380502&doi=10.1016%2fj.cpc.2017.03.015&partnerID=40&md5=0600ed9ac464420cd28b3fa6e4a5095e","We present an improved version of the code AWESOME, capable of computing phase and group velocities, power flow angles and enhancement factors of acoustic waves in homogeneous solids. In this version, some algorithms are improved and the code provides a better estimation of the enhancement factor compared to the previous version. In addition, we include a quadruple-precision version of the code, which even though using the same numerical approach as the double-precision version, is able to calculate the exact values of the enhancement factor. The standard, double-precision version of the code has been interfaced and merged with the development version of CRYSTAL and will be available as part of its next stable release. Finally, we have improved the scripts for visualizing the results, which now are compatible with GNUPLOT 5.X.X, including new scripts for the visualization of the normal and ray surfaces. New version program summary Program Title:AWESOME 1.1 Program Files doi: http://dx.doi.org/10.17632/fr58gfsc9n.1 Licensing provisions: GPLv3 Programming language: Fortran90 Journal reference of previous version: Computer Physics Communications 192 (2015) 272–277 Does the new version supersede the previous version?: Yes Reasons for the new version: Improved accuracy, improved visualization scripts. Nature of problem: Calculation of acoustic wave phase and group velocities, power flow angles and enhancement factors in homogeneous solids. Solution method: Solving the Christoffel equation by diagonalization; computing group velocities and enhancement factors by vector operations. Additional comments: The DSYEVJ3 [1] subroutine is included in the AWESOME code file. Summary of revisions: New approach for sampling the unit sphere around the propagation direction l→: In the first version of the code, the direction of the group velocities was determined by the vector product of two vectors a→ and b→, constructed with four points of the slowness surface evaluated at (θi±dθ,ϕi) and (θi,ϕi±dϕ), where (θi,ϕi) is the point of the unit sphere defined by the (phase) propagation direction l→. This approach had the drawbacks of been ill-defined at the poles and also potentially leading to different precisions depending on ϕ (even though we always observed a perfect estimation of the group velocities in the test cases). In the present revision we introduce a more consistent approach for estimating the normal to the slowness surface. Now, the phase velocity is first evaluated at the point A(θi,ϕi+dϕ), and then at three points B, C and D obtained by rotating A by 90, 180 and 270 degrees around the propagation direction l→ (Fig. 1(a)). The calculation of the normal to the slowness surface n→=a→×b→ (Fig. 1(b)) is straightforward as in the previous version of the code, but now we ensure the same accuracy for all the points in the unit sphere. New approach for computing the enhancement factor: The calculation of the enhancement factor presented a similar issue. The 3×3 grid used for the estimation of the solid angles ΔΩk and ΔΩg employed the same points as those used for sampling the propagation directions l→ in the unit sphere (cf. Fig. 3(b) in [2]). Thus, not only the accuracy was remarkably different depending on the azimuth ϕ, but also the grid was quite coarse and consequently the estimation of the enhancement factor was somewhat poor. In this new version, the points used for estimating ΔΩk and ΔΩg have an umbrella-like arrangement where the first point is (θi,ϕi+Δϕ) and the next 7 points are obtained by rotating the former in steps of 45 degrees around l→ (Fig. 1(c)). As in the case of the group velocities, the accuracy is now independent of ϕ. Another problem with the numerical estimation of the enhancement factor is that a good estimation requires using small values of Δϕ, but for this a very high precision for computing the vectors u→ and w→ is needed (since the points A–H can be extremely close to P). In consequence, in the standard version of the code we have optimized the Δϕ parameter to minimize the error in the enhancement factor, setting it to Δϕ=0.02∘. In addition, we now provide another version of the code where we employ quadruple precision instead of the usual double precision of the standard version. In this higher-precision version, Δϕ is set to (10−5)∘, which is enough to obtain the exact values (i.e. indistinguishable from that obtained with analytical methods) of the enhancement factor. We note that AWESOME produces the exact values of all the other parameters (phase and group velocities, power flow angles and polarization vectors) ever since its first version [2], and only the exact determination of the enhancement factor remained to be settled. Improved visualization scripts: As a minor improvement, we have also updated the visualization scripts so that they are compatible with GNUPLOT 5.X.X versions, and in addition we include two new scripts for plotting the normal surfaces and the ray surfaces (Fig. 2). AWESoMe merged into CRYSTAL: Finally, we are happy to announce that the present AWESOME version 1.1 (in its double-precision implementation) has been successfully merged into the development version of the CRYSTAL code [3]. Therefore, starting with its next stable version release, after CRYSTAL performs an automated calculation of the elastic tensor of a crystalline system (a feature that was already present in CRYSTAL14), AWESOME can be internally run within CRYSTAL so that the user gets directly the same output provided by AWESOME in addition to the usual CRYSTAL output. Again, we note that this will provide the exact values for phase and group velocities, polarization vectors and power flow angles, together with a reasonable estimation of the enhancement factor (for the exact values of the latter, simply run the quadruple precision version of the present release AWESOME 1.1). Acknowledgments: We are very grateful to Alessandro Erba and Roberto Dovesi for merging AWESOME into CRYSTAL. The development of AWESOME was funded through the project Ministerio de Ciencia e Innovación. We are thankful to the Centro de Servicios de Informática y Redes de Comunicaciones (CSIRC), University of Granada, for providing the computing time. [1] J. Kopp, Efficient numerical diagonalization of hermitian 3× 3 matrices, Int. J. Mod. Phys. C 19 (2008) 523–548. [2] D. Muñoz-Santiburcio, A. Hernández-Laguna, J. I. Soto, AWESoMe: A code for the calculation of phase and group velocities of acoustic waves in homogeneous solids, Comput. Phys. Commun. 192 (2015) 272–277. [3] R. Dovesi, R. Orlando, A. Erba, C.M. Zicovich-Wilson, B. Civalleri, S. Casassa, L. Maschio, M. Ferrabone, M. De La Pierre, P. D'Arco, Y. Noël, M. Causà, M. Rérat, B. Kirtman, CRYSTAL14: A program for the ab initio investigation of crystalline solids, Int. J. Quantum Chem. 114 (2014) 1287–1317. © 2017 Elsevier B.V.","Acoustic waves; Christoffel equation; Enhancement factor; Group velocity; Phase velocity","Acoustic waves; Calculations; Codes (symbols); Crystalline materials; Electric load flow; Light velocity; Mergers and acquisitions; Phase velocity; Polarization; Precision engineering; Problem oriented languages; Spheres; Vectors; Velocity; Visualization; Ab initio investigation; Christoffel equation; Enhancement factor; Group velocities; Numerical approaches; Phase and group velocities; Polarization vectors; Propagation direction; C (programming language)",2-s2.0-85018380502
"Giorgino T., Laio A., Rodriguez A.","METAGUI 3: A graphical user interface for choosing the collective variables in molecular dynamics simulations",2017,"Computer Physics Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019057444&doi=10.1016%2fj.cpc.2017.04.009&partnerID=40&md5=091efeeb791d9c00b91b6cfcd1b243a4","Molecular dynamics (MD) simulations allow the exploration of the phase space of biopolymers through the integration of equations of motion of their constituent atoms. The analysis of MD trajectories often relies on the choice of collective variables (CVs) along which the dynamics of the system is projected. We developed a graphical user interface (GUI) for facilitating the interactive choice of the appropriate CVs. The GUI allows: defining interactively new CVs; partitioning the configurations into microstates characterized by similar values of the CVs; calculating the free energies of the microstates for both unbiased and biased (metadynamics) simulations; clustering the microstates in kinetic basins; visualizing the free energy landscape as a function of a subset of the CVs used for the analysis. A simple mouse click allows one to quickly inspect structures corresponding to specific points in the landscape. Program summary Program Title: METAGUI 3 Program Files doi: http://dx.doi.org/10.17632/wyxjndwkbp.1 Licensing provisions: GPLv3 Programming language: Tcl/Tk, Fortran Journal reference of previous version: METAGUI [1] Does the new version supersede the previous version?: No Nature of problem: Choose the appropriate collective variables for describing the thermodynamics and kinetics of a biomolecular system through biased and unbiased molecular dynamics. Solution method: Provide an environment to compute and visualize free energy surfaces as a function of collective variables, interactively defined. Additional comments: METAGUI 3 is not a standalone program but a plugin that provides analysis features within VMD (version 1.9.2 or higher). [1] X. Biarnés, F. Pietrucci, F. Marinelli, A. Laio, METAGUI. A VMD interface for analyzing metadynamics and molecular dynamics simulations, Computer Physics Communications 183 (2012) 203–211. © 2017","Clustering; Free energy; GUI; Molecular dynamics","Biopolymers; Equations of motion; FORTRAN (programming language); Free energy; Graphical user interfaces; Phase space methods; Thermodynamics; User interfaces; Biomolecular system; Clustering; Collective variables; Free energy landscape; Free energy surface; Graphical user interfaces (GUI); Molecular dynamics simulations; Thermodynamics and kinetics; Molecular dynamics",2-s2.0-85019057444
"Blumers A.L., Tang Y.-H., Li Z., Li X., Karniadakis G.E.","GPU-accelerated red blood cells simulations with transport dissipative particle dynamics",2017,"Computer Physics Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018950591&doi=10.1016%2fj.cpc.2017.03.016&partnerID=40&md5=edd80f59860d7666dcc2a7afd83bccd9","Mesoscopic numerical simulations provide a unique approach for the quantification of the chemical influences on red blood cell functionalities. The transport Dissipative Particle Dynamics (tDPD) method can lead to such effective multiscale simulations due to its ability to simultaneously capture mesoscopic advection, diffusion, and reaction. In this paper, we present a GPU-accelerated red blood cell simulation package based on a tDPD adaptation of our red blood cell model, which can correctly recover the cell membrane viscosity, elasticity, bending stiffness, and cross-membrane chemical transport. The package essentially processes all computational workloads in parallel by GPU, and it incorporates multi-stream scheduling and non-blocking MPI communications to improve inter-node scalability. Our code is validated for accuracy and compared against the CPU counterpart for speed. Strong scaling and weak scaling are also presented to characterize scalability. We observe a speedup of 10.1 on one GPU over all 16 cores within a single node, and a weak scaling efficiency of 91% across 256 nodes. The program enables quick-turnaround and high-throughput numerical simulations for investigating chemical-driven red blood cell phenomena and disorders. Program summary Program Title: USERMESO 2.0 Program Files doi: http://dx.doi.org/10.17632/89849t3ngk.1 Licensing provisions: GNU General Public License, Version 3 Programming language: C/C++, CUDA C/C++, MPI. Nature of problem: Particle-based simulation of a red blood cell suspension with chemical transport property. Solution method: Each red blood cell is represented by a 3-D triangular mesh with bonded potential under area and volume constraints. The solvent is approximated with coarse-grained particles. The time evolution of the system is integrated using Velocity-Verlet algorithm. Restrictions: The code is compatible with NVIDIA GPGPUs with compute capability 3.0 and above. Unusual features: The code is implemented on GPGPUs with significantly improved speed. Additional Comments: Github repository link https://github.com/AnselGitAccount/USERMESO-2.0 © 2017 Elsevier B.V.","Advection–diffusion–reaction; Blood flow; Dissipative particle dynamics; GPU; Mesoscopic modeling; Red blood cell","Advection; C (programming language); Cell culture; Cells; Codes (symbols); Computational fluid dynamics; Cytology; Dynamics; Graphics processing unit; Numerical models; Open source software; Program processors; Scalability; Superconducting materials; Suspensions (fluids); Advection-diffusion-reaction; Blood flow; Dissipative particle dynamics; Mesoscopic modeling; Red blood cell; Blood",2-s2.0-85018950591
"Borlido C., Czarnetzki S., Gehrke M., Krebs A.","Stone duality and the substitution principle",2017,"Leibniz International Proceedings in Informatics, LIPIcs",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028718324&doi=10.4230%2fLIPIcs.CSL.2017.13&partnerID=40&md5=2264992308f9248d99642763989b36ae","In this paper we relate two generalisations of the finite monoid recognisers of automata theory for the study of circuit complexity classes: Boolean spaces with internal monoids and typed monoids. Using the setting of stamps, this allows us to generalise a number of results from algebraic automata theory as it relates to Büchi's logic on words. We obtain an Eilenberg theorem, a substitution principle based on Stone duality, a block product principle for typed stamps and, as our main result, a topological semidirect product construction, which corresponds to the application of a general form of quantification. These results provide tools for the study of language classes given by logic fragments such as the Boolean circuit complexity classes. © Célia Borlido, Silke Czarnetzki, Mai Gehrke, and Andreas Krebs.","Boolean space with an internal monoid; C-variety of languages; Semidirect product; Substitution principle; Typed monoid","Algebra; Automata theory; C (programming language); Computational complexity; Algebraic automata theories; Boolean circuit; Boolean space with an internal monoid; Circuit complexity; Eilenberg theorems; Semidirect product; Substitution principles; Typed monoid; Computer circuits",2-s2.0-85028718324
"Speer S., Klein A., Kober L., Weiss A., Yohannes I., Bert C.","Automation of radiation treatment planning: Evaluation of head and neck cancer patient plans created by the Pinnacle3 scripting and Auto-Planning functions [Automatisierte Bestrahlungsplanung: Auswertung von mit Pinnacle3 via Scripting und Auto-Planning erzeugten Bestrahlungsplänen von Patienten mit Kopf-Hals-Tumor]",2017,"Strahlentherapie und Onkologie",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021262441&doi=10.1007%2fs00066-017-1150-9&partnerID=40&md5=eea6541029121d48263ef699685db724","Background: Intensity-modulated radiotherapy (IMRT) techniques are now standard practice. IMRT or volumetric-modulated arc therapy (VMAT) allow treatment of the tumor while simultaneously sparing organs at risk. Nevertheless, treatment plan quality still depends on the physicist’s individual skills, experiences, and personal preferences. It would therefore be advantageous to automate the planning process. This possibility is offered by the Pinnacle3 treatment planning system (Philips Healthcare, Hamburg, Germany) via its scripting language or Auto-Planning (AP) module. Materials and methods: AP module results were compared to in-house scripts and manually optimized treatment plans for standard head and neck cancer plans. Multiple treatment parameters were scored to judge plan quality (100 points = optimum plan). Patients were initially planned manually by different physicists and re-planned using scripts or AP. Results and discussion: Script-based head and neck plans achieved a mean of 67.0 points and were, on average, superior to manually created (59.1 points) and AP plans (62.3 points). Moreover, they are characterized by reproducibility and lower standard deviation of treatment parameters. Even less experienced staff are able to create at least a good starting point for further optimization in a short time. However, for particular plans, experienced planners perform even better than scripts or AP. Experienced-user input is needed when setting up scripts or AP templates for the first time. Moreover, some minor drawbacks exist, such as the increase of monitor units (+35.5% for scripted plans). Conclusion: On average, automatically created plans are superior to manually created treatment plans. For particular plans, experienced physicists were able to perform better than scripts or AP; thus, the benefit is greatest when time is short or staff inexperienced. © 2017, Springer-Verlag Berlin Heidelberg.","Brainstem; Organs at risk; Parotid gland; Radiotherapy, intensity-modulated; Spinal cord","Article; auditory cortex; automation; brain; cancer patient; cancer radiotherapy; dosimetry; evaluation study; head and neck cancer; human; intensity modulated radiation therapy; larynx; mandible; mouth; mouth cavity; organs at risk; radiation dose distribution; radiotherapy dosage; skin; treatment planning; volumetric modulated arc therapy; algorithm; comparative study; computer assisted radiotherapy; computer language; Head and Neck Neoplasms; radiation response; radiotherapy planning system; reproducibility; sensitivity and specificity; software; treatment outcome; tumor volume; Algorithms; Head and Neck Neoplasms; Humans; Programming Languages; Radiotherapy Dosage; Radiotherapy Planning, Computer-Assisted; Radiotherapy, Computer-Assisted; Reproducibility of Results; Sensitivity and Specificity; Software; Treatment Outcome; Tumor Burden",2-s2.0-85021262441
"Tian J., Gao M., Zhou Y.","Wireless Sensor Network for Multi-channel 3D Data Synchronizing Acquisition System and Visual Simulation Research",2017,"Wireless Personal Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84995469425&doi=10.1007%2fs11277-016-3875-7&partnerID=40&md5=014e0568aa256912dba00298451ace63","A multi-channel three-dimension (3D) data synchronizing acquisition system based on wireless sensor network is proposed and used to collect underground three-dimension data in this paper. The channel number and the sampling rate of the data acquisition are the bottleneck of the seismic exploration. The synchronization precision of the multi-channel data affects the oil seismic exploration efficiency directly. The system adopts distributing collecting, conversion, storage and transfer multi-channel seismic data during specific time. The system can synchronizing gather 1024 channel data, and the collective data can form 3D data cube by corresponding process. The data structure of 3D data cube is analyzed and the 3D simulation model of underground oil reservoir is established. The methods of displaying slice for the 3D simulation model are studied using the technology of computer graphic and image processing, and we accomplish the horizontal slices, vertical slices of underground oil reservoir from multi-direction and multi-angle in this paper. Some typical simulation images for an underground oil reservoir are given by programming the corresponding algorithm and graphic display program using C++. © 2016, Springer Science+Business Media New York.","3D data cube; Synchronizing acquisition; Visual simulation; Wireless sensor network","C++ (programming language); Computer software; Data acquisition; Digital storage; Geometry; Image processing; Petroleum reservoir engineering; Petroleum reservoirs; Seismic prospecting; Seismology; Synchronization; Three dimensional computer graphics; Visualization; 3D data; Multi-channel seismic datum; Oil seismic exploration; Seismic exploration; Synchronization precision; Synchronizing acquisition; Underground oil reservoir; Visual simulation; Wireless sensor networks",2-s2.0-84995469425
"Krötzsch M., Masopust T., Thomazo M.","Complexity of universality and related problems for partially ordered NFAs",2017,"Information and Computation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022196483&doi=10.1016%2fj.ic.2017.06.004&partnerID=40&md5=2c1585c26fc1fe3d8d231cc2c58f43ce","Partially ordered NFAs (poNFAs) are NFAs where cycles occur only in the form of self-loops. A poNFA is universal if it accepts all words over its alphabet. Deciding universality is PSPACE -complete for poNFAs. We show that this remains true when restricting to fixed alphabets. This is nontrivial since standard encodings of symbols in, e.g., binary can turn self-loops into longer cycles. A lower CONP -complete complexity bound is obtained if all self-loops in the poNFA are deterministic. We find that such restricted poNFAs (rpoNFAs) characterize R-trivial languages, and establish the complexity of deciding if the language of an NFA is R-trivial. The limitation to fixed alphabets is essential even in the restricted case: deciding universality of rpoNFAs with unbounded alphabets is PSPACE -complete. Consequently, we obtain the complexity results for inclusion and equivalence problems. Finally, we show that the languages of rpoNFAs are definable by deterministic (one-unambiguous) regular expressions. © 2017 Elsevier Inc.","Automata; Equivalence; Inclusion; Nondeterminism; Partial order; Universality","Computer programming languages; Equivalence classes; Finite automata; Inclusions; Pipeline processing systems; Automata; Equivalence; Non-determinism; Partial order; Universality; Nanostructured materials",2-s2.0-85022196483
"Wu T., Paun A., Zhang Z., Pan L.","Spiking Neural P Systems With Polarizations",2017,"IEEE Transactions on Neural Networks and Learning Systems",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028984514&doi=10.1109%2fTNNLS.2017.2726119&partnerID=40&md5=a6884665c0fae981d629aabad81fbfa2","Spiking neural P (SN P) systems are a class of parallel computation models inspired by neurons, where the firing condition of a neuron is described by a regular expression associated with spiking rules. However, it is NP-complete to decide whether the number of spikes is in the length set of the language associated with the regular expression. In this paper, in order to avoid using regular expressions, two major and rather natural modifications in their form and functioning are proposed: the spiking rules no longer check the number of spikes in a neuron, but, in exchange, a polarization is associated with neurons and rules, one of the three electrical charges -, 0, +. Surprisingly enough, the computing devices obtained are still computationally complete, which are able to compute all Turing computable sets of natural numbers. On this basis, the number of neurons in a universal SN P system with polarizations is estimated. Several research directions are mentioned at the end of this paper. IEEE","Bio-inspired computing; Biomembranes; Computational modeling; Computer science; Electric potential; membrane computing; Neurons; polarization; spiking neural P (SN P) system; Standards; Turing completeness","Computability and decidability; Computation theory; Computer programming languages; Computer science; Electric potential; Pattern matching; Polarization; Standards; Bio-inspired computing; Biomembranes; Computational model; Membrane computing; spiking neural P (SN P) system; Turing completeness; Neurons",2-s2.0-85028984514
"Clausen P., Skaloud J., Molinari R., Balamuta J., Guerrier S.","An overview of a new sensor calibration platform",2017,"4th IEEE International Workshop on Metrology for AeroSpace, MetroAeroSpace 2017 - Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028558451&doi=10.1109%2fMetroAeroSpace.2017.7999598&partnerID=40&md5=76bad6cd00aa02c102567cb87f338b64","Inertial sensors are increasingly being employed in different types of applications. The reduced cost and the extremely small size makes them the number-one-choice in miniature embedded devices like phones, watches, and small unmanned aerial vehicles. The more complex the application, the more it is necessary to understand the structure of the error signal coming from these sensors. Indeed, their error signals are composed of deterministic and stochastic parts. The deterministic errors or faults can be compensated by proper calibration while the stochastic signal is usually ignored since its modeling is relatively difficult due to computational or statistical reasons, especially due to its complex spectral structure. However, a recently proposed approach called the Generalized Method of Wavelet Moments overcomes these limitations and this paper presents the software platform that implements this method for the analysis of the stochastic errors. As an example throughout the paper we will consider an inertial measurement unit, but the platform can be used for the stochastic calibration of any kind of sensor. The software is developed in the widely used statistical tool R using C++ language. The tools enable the user to study with ease any signal by the means of a vast range of predefined models and tools. © 2017 IEEE.","Allan Variance; Composite Stochastic Processes; GMWM; IMU; Latent Models; MEMS; Wavelet Variance","C++ (programming language); Calibration; Computer software; Errors; MEMS; Random processes; Statistical mechanics; Stochastic models; Units of measurement; Allan variance; Generalized method; GMWM; Inertial measurement unit; Latent models; Sensor calibration; Small unmanned aerial vehicles; Wavelet Variance; Stochastic systems",2-s2.0-85028558451
"Donyagard F., Zarei A.R., Rezaei-Vahidian H.","Application of magnetic carbon nanocomposites to remove melanoidin from aqueous media: kinetic and isotherm studies",2017,"Research on Chemical Intermediates",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013093340&doi=10.1007%2fs11164-017-2902-y&partnerID=40&md5=4a71eebfdbfdc1cfdf68e9509dc72dd0","This study examined the removal of melanoidin as a by-product of bioethanol production from aqueous solutions through an adsorption process using a magnetic carbon nanocomposite (MCNC). The magnetic adsorbent was synthesized by the chemical precipitation method and characterized by TEM, BET, and FTIR analysis. The effect of operational factors such as pH, adsorbent dosage, and temperature on the removal efficiency was modeled and optimized by the statistical response surface method. The data were well fitted by a second order polynomial model with R2 of 0.977. Based on the model, the process optimum conditions were introduced as adsorbent dosage of 413.6 ppm, pH = 3.03, and temperature of 39.9 °C that for these conditions the software predicted 90% removal efficiency for 40 ppm of melanoidin. Also, the data obtained from adsorption of melanoidin on the MCNC were fitted by a Langmuir isotherm model and a pseudo-second-order kinetic model. Finally, removal of melanoidin from a real alcohol industries wastewater was assessed such that 80.76% efficiency was obtained in the optimum condition after 30 min of the process. © 2017, Springer Science+Business Media Dordrecht.","Alcohol industry; Isotherm; Kinetic; Magnetic nano composite; Melanoidin","Bioethanol; C (programming language); Chemical analysis; Chemical industry; Efficiency; Isotherms; Kinetics; Magnetism; Nanocomposites; Positive ions; Precipitation (chemical); Solutions; Alcohol industry; Bio-ethanol production; Chemical precipitation method; Langmuir isotherm models; Melanoidins; Pseudo-second-order kinetic models; Response surface method; Second-order polynomial; Adsorption",2-s2.0-85013093340
"Ahmadu U., Olarinoye O.I., Agida M., Muhammad A.M., Usman A.B.","Crystal structure refinement of co-doped Ba0.88Ca0.12Ti0.975Sn0.025O3 ceramic",2017,"Materials Chemistry and Physics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019886347&doi=10.1016%2fj.matchemphys.2017.04.063&partnerID=40&md5=8a4e2ddfa43cc9e2b51c5e8fac0e1155","Ba/Ca-doped barium titanate has been prepared by solid state reaction to produce Ba0.88Ca0.12Ti0.975Sn0.025O3(BCST) ceramics. Five samples were irradiated using neutron fluence of 8.1 × 106, 9.72 × 107, 8.75 × 108, 6.99 × 109 and 1.4 × 1010 n/cm2 (BCST-06 to -10). The structure and phase compositions of the control (BCST) and irradiated samples were determined by X-ray diffraction and indicate the presence of a majorly single phase tetragonal barium titanate (S.G.P4mm) with a minor phase CaTiO3 (orthorhombic). However, Rietveld refinement using GSAS II suite of programs indicates a tetragonality ratio (c/a = 0.996) which is pseudocubic with a reduction in volume of 0.03% in the control compared to pristine BT. The irradiated samples exhibited changes in tetragonality (maximum of 0.82%) and variation in volume (0.58%, maximum) over the range of fluence investigated. A complete vacancy was observed in the Ca site of BCST10 but not in the oxygen sites while the occupancies of other metal sites varied. The substitution of Sn is expected to lead to a lower transition temperature and an increase in dielectric constant near the transition temperature of the control. While the changes in volume, tetragonality and occupancy of the irradiated samples are expected to affect their electromechanical properties due to changes in the Ti octahedra which would lead to a slight degradation in device performance. © 2017 Elsevier B.V.","Ca/Sn-doped barium titanate; Crystallographic parameters; Neutron irradiation; Vacancies","Barium; Barium titanate; C (programming language); Calcium; Ceramic materials; Electromechanical devices; Neutron irradiation; Rietveld refinement; Solid state reactions; Temperature; Tin; Titanium compounds; Vacancies; X ray diffraction; Changes in volume; Crystal structure refinement; Crystallographic parameters; Device performance; Electromechanical property; Irradiated samples; Neutron fluences; Tetragonal barium titanate; Crystal structure",2-s2.0-85019886347
"Kim J., Reinert K.","Vaquita: Fast and accurate identification of structural variation using combined evidence",2017,"Leibniz International Proceedings in Informatics, LIPIcs",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028750108&doi=10.4230%2fLIPIcs.WABI.2017.13&partnerID=40&md5=cc61b7745614b7192020b1f30fa4db27","Motivation: Comprehensive identification of structural variations (SVs) is a crucial task for studying genetic diversity and diseases. However, it remains challenging. There is only a marginal consensus between different methods, and our understanding of SVs is substantially limited. In general, integration of multiple pieces of evidence including split-read, read-pair, soft-clip, and read-depth yields the best result regarding accuracy. However, doing this step by step is usually cumbersome and computationally expensive. Result: We present Vaquita, an accurate and fast tool for the identification of structural variations, which leverages all four types of evidence in a single program. After merging SVs from split-reads and discordant read-pairs, Vaquita realigns the soft-clipped reads to the selected regions using a fast bit-vector algorithm. Furthermore, it also considers the discrepancy of depth distribution around breakpoints using Kullback-Leibler divergence. Finally, Vaquita provides an additional metric for candidate selection based on voting, and also provides robust prioritization based on rank aggregation. We show that Vaquita is robust in terms of sequencing coverage, insertion size of the library, and read length, and is comparable or even better for the identification of deletions, inversions, duplications, and translocations than state-of-the-art tools, using both simulated and real datasets. In addition, Vaquita is more than eight times faster than any other tools in comparison. Availability: Vaquita is implemented in C++ using the SeqAn library. The source code is distributed under the BSD license and can be downloaded at http://github.com/seqan/vaquita. © Jongkyu Kim and Knut Reinert.","Structural variation","Bioinformatics; Candidate selection; Depth distribution; Fast bit-vector algorithm; Genetic diversity; Kullback Leibler divergence; Rank aggregation; State of the art; Structural variations; C++ (programming language)",2-s2.0-85028750108
"Kang M.-H.","An ultrasonic positioning system using Zynq SoC",2017,"Transactions of the Korean Institute of Electrical Engineers",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030636910&doi=10.5370%2fKIEE.2017.66.8.1250&partnerID=40&md5=e91d68c8d978c12d18f38e1889c2e2f1","In this research, a high-performance ultrasonic positioning system is proposed to track the positions of an indoor mobile object. Composed of an ultrasonic sender (mobile object) and a receiver (anchor), the system employs three ultrasonic time-off-flights (TOFs) and trilateration to estimate the positions of the object with an accuracy of sub-centimeter. On the other hand, because ultrasonic waves are interfered by temperature, wind and various obstacles obstructing the propagation while propagating in air, ultrasonic pulse debounce technique and Kalman filter were applied to TOF and position calculation, respectively, to compensate for the interference and to obtain more accurate moving object position. To perform tasks in real time, ultrasonic signals are processed full-digitally with a Zynq SoC, and as a software design tool, Vivado IDE(integrated design environment) is used to design the whole signal processing system in hierarchical block diagrams. And, a hardware/software co-design is implemented, where the digital circuit portion is designed in the Zynq's fpga and the software portion is c-coded in the Zynq's processors by using the baremetal multiprocessing scheme in which the c-codes are distributed to dual-core processors, cpu0 and cpu1. To verify the usefulness of the proposed system, experiments were performed and the results were analyzed, and it was confirmed that the moving object could be tracked with accuracy of sub-cm. Copyright © The Korean Institute of Electrical Engineers.","Baremetal multiprocessing; Kalman filter; Positions tracking; Pulse debounce; Trilateration; Ultrasonic TOF; Vivado; Zynq SoC","C (programming language); Hardware-software codesign; Kalman filters; Signal processing; Software design; Surveying; System-on-chip; Ultrasonic applications; Baremetal multiprocessing; Debounce; Dual core processors; Integrated design environments; Signal processing systems; Trilateration; Ultrasonic positioning systems; Vivado; Integrated circuit design",2-s2.0-85030636910
"Huang Y., Cai X., Kan W., Qiu S., Guo X., Liu C., Liu P.","A flexible dual-mode proximity sensor based on cooperative sensing for robot skin applications",2017,"Review of Scientific Instruments",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028055902&doi=10.1063%2f1.4998995&partnerID=40&md5=41446429258dd780ed1a0378c7840cb4","A flexible dual-mode proximity sensor has been designed and implemented, which is capable of combining capacitive-resistive detection in this paper. The capacitive type proximity sensor detecting is defined as mode-C, and the resistive type proximity sensor detecting is defined as mode-R. The characteristics of the proximity sensor are as follows: (1) the theoretical mode is developed which indicates that this proximity sensor can reflect proximity information accurately; (2) both sensing modes are vertically integrated into a sandwich-like chip with an 8 mm × 12 mm unit area. The thickness of a mode-R sensing material (graphene nanoplatelets) and mode-C dielectric (the mixture of carbon black and silicone rubber) is 1 mm and 2.5 mm, respectively; (3) for mode-R, the linearity of temperature-resistance curve can achieve 0.998 in the temperature range from 25 °C to 65 °C. And for mode-C, various materials can be successfully detected with fast response and high reversibility. Meanwhile, the study compensated the influence of object temperature to ensure mode-C properly works. A cooperative sensing test shows that R-C dual modes sense effectively which can enlarge the sensing distance compared with the single mode proximity sensor. The fabrication of this sensor is convenient, and the integrity of a flexible sandwich-like structure based on dual modes is beneficial to form arrays, which is suitable to be used in skin-like sensing applications. © 2017 Author(s).",,"Capacitive sensors; Carbon; Carbon black; Dielectric properties; Proximity sensors; Silicones; Cooperative sensing; Graphene nanoplatelets; Sandwich-like structure; Sensing applications; Sensing material; Silicone rubber; Temperature range; Temperature resistances; C (programming language)",2-s2.0-85028055902
"Rouillard F., Courouau J.-L., Duprey B., Mathieu S., Vilasi M., Bouizi Y., Boissonnet G., Pedraza F., Proriol-Serre I.","Evaluation of the Compatibility of Aluminide Coatings in High-Temperature Sodium for Fast Reactor Application",2017,"Oxidation of Metals",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007173684&doi=10.1007%2fs11085-016-9689-x&partnerID=40&md5=968db7d13e00a31cdab0ae3aea523d04","Nickel and iron aluminide coatings were identified as possible candidates for hardfacing materials in Sodium Fast Reactors. Both coatings were developed on two steel grades of interest for the next French Sodium Fast Reactor prototype, 316L(N) and T91. Pack cementation and slurry were employed as aluminization processes. The compatibility of all coatings with purified Na was evaluated at 550 °C for exposure times up to 4250 h. All coatings evidenced high chemical stability in Na even though Na penetration and slow coating dissolution could be evidenced. The penetration depth of Na was observed to depend on the coating nature induced by the deposition process. © 2016, Springer Science+Business Media New York.","Aluminides; Coatings; Hardfacing; Sodium","C (programming language); Chemical stability; Coatings; Fast reactors; Hard facing; Sodium; Aluminide coating; Aluminides; Coating dissolution; Deposition process; Hard facing materials; Iron aluminide coatings; Pack cementation; Sodium fast reactors; Nickel coatings",2-s2.0-85007173684
"Jin Y., Zhao C., Lin Y., Wang D., Chen L., Shen C.","Fe-Based Metal-Organic Framework and Its Derivatives for Reversible Lithium Storage",2017,"Journal of Materials Science and Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007482719&doi=10.1016%2fj.jmst.2016.11.021&partnerID=40&md5=1e660707f0fc340a87fe5da57cbeedeb","The use of a Fe-based metal organic framework (MOF), namely MIL-88B(Fe), as active material for lithium ion batteries (LIBs) is reported for the first time in the present work. Fe-based MOF demonstrated high capacity, excellent cycling stability and rate performance when used as anode. A highly reversible capacity of ~680 mA h g−1 after 500 cycles at a current density of 200 mA g−1 was obtained. In addition, Fe2O3 and Fe3O4/C composites were obtained from Fe-based MOFs through thermal treatment. Both Fe2O3 and Fe3O4/C composites demonstrated high capacity and excellent cycling stability. © 2016","Anode; Lithium ion battery; Metal organic framework; Metal oxide","Anodes; Crystalline materials; Electrodes; Java programming language; Lithium; Lithium alloys; Lithium compounds; Lithium-ion batteries; Metals; Organometallics; Active material; Cycling stability; High capacity; Lithium storages; Metal organic framework; Metal oxides; Rate performance; Reversible capacity; Iron compounds",2-s2.0-85007482719
"Zhao H., Lei Y., Fu L.","Biomass and Uncertainty Estimates of Pinus massoniana Forest for Different Site Classes in Jiangxi Province",2017,"Linye Kexue/Scientia Silvae Sinicae",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031796386&doi=10.11707%2fj.1001-7488.20170810&partnerID=40&md5=dad1e33a3801bf52847d9132a82e68f1","Objective: To obtain the regional tree aboveground biomass and its uncertainty estimate on different site quality and choose the optimizational model for biomass estimation, this study presented a novel method to obtain more accurate estimates of forest biomass in the forest productivity estimation. Method: The regional site quality classification in Pinus massoniana forests of Jiangxi Province was determined using the dominant tree height (H)-diameter at breast height (D) model. The aboveground biomass density and its root mean square error (RMSE) in each site class were estimated by the Monte Carolmethod based on the three allometric biomass models including (1) gi=aDi b+ε, (2) gi=a(Di 2Hi)b+ε, and (3) gi=aDi bHi c+ε, where gi is the individual biomass of the ith sample tree, Di and Hiare the diameter at breast height (DBH) and tree height for the ith sample tree, respectively; a, b and c are model parameters; ε is the error term. Result: 1) The coefficient of determination (R2) obtained from the three biomass equations are more than 0.95, which indicated that the three equations have good fitting abilities. Among the candidate models, Model (3) showed the best performance. 2) The dominant H-D model showed a good fitting ability with R2=0.907, mean error (ME)=0.001, mean absolute error (MAE)=0.559, and RMSE=0.027. Plots classified by site quality were distributed to all the regions of Jiangxi Province and the sample plots in the same site level were relatively concentrated. 3) The simulation studies using Monte Carlo method were achieved stability by 10 000 times repeats. Aboveground biomass estimates calculating by the same individual tree biomass equation increased with increasing level of site. The middle site class level (the third level) represents the mean level of the regional site conditions and has similar biomass estimate with the whole region. Under the same site class, the order of mean aboveground biomass estimate values of the three models was the following: equation (1)&gt; equation (3)&gt; equation (2) and the order of both RMSE and relative RMSE estimates values was the following: equation (2) &lt;equation (3) &lt;equation (1). Conclusion: 1) The equation (2) is better than equation (3) and then the equation (1) by comparing the relative RMSEs of the mean biomass density estimate. 2) The more similar the site quality is to the mean site quality level, the smaller the relative RMSE of the aboveground biomass density will be. 3) This study put forward a method to estimate the regional tree biomass and uncertainty in different site quality by combining the H-D model and the Monte Carlo simulation, and provides a probability and reference to accurately estimate the site productivity and biomass under different site quality. © 2017, Editorial Department of Scientia Silvae Sinicae. All right reserved.","Allometric model; Biomass estimates; Monte Carlo simulation; Site classification; Uncertainty estimates","Biomass; C (programming language); Errors; Intelligent systems; Mean square error; Monte Carlo methods; Productivity; Reactor cores; Uncertainty analysis; Above ground biomass; Allometric models; Coefficient of determination; Diameter-at-breast heights; Forest productivity; Root mean square errors; Site classification; Uncertainty estimates; Forestry",2-s2.0-85031796386
"Chihi T., Fatmi M., Ghebouli B.","Ab initio study of the structural stability, elastic, electronic and optical properties of NaMgHiFj [(i, j) = (3, 0), (2, 1), (1, 2), (0, 3)] compounds",2017,"Solid State Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019628740&doi=10.1016%2fj.ssc.2017.05.018&partnerID=40&md5=7c817cbbab3c465635d8967335abf1eb","We studied the structural, elastic, electronic and optical properties of the orthorhombic NaMgH3, NaMgH2F, NaMgHF2 and NaMgF3 compounds. By means of the self-consistent CASTEP code, pseudopotentials, density functional theory in the LDA and GGA approximations, basic physical properties, such as lattice constant, shear modulus, elastic constants (Cij) and optical constants are computed. This study includes elastic parameters of mono and poly-crystalline aggregates. Derived elastic constants, such as bulk, Young's and Shear modulus, Poisson coefficient, Debye temperature and brittle/ductile behavior are estimated with the polycrystalline approach, using Voigt–Reuss–Hill theory. The calculations show that the orthorhombic Pnma structures are mechanically and dynamically stable in the pressure range (0–20 GPa). The calculated density of states shows that the orthorhombic compounds are insulators. © 2017","Brittle; Ductile; NaMgF3; NaMgH2F; NaMgH3; NaMgHF2","C (programming language); Calculations; Density functional theory; Elastic constants; Elastic moduli; Lattice constants; Lattice theory; Optical lattices; Shear strain; Stability; Time varying systems; Brittle; Ductile; NaMgF<sub>3</sub>; NaMgH<sub>3</sub>; NaMgHF<sub>2</sub>; Optical properties",2-s2.0-85019628740
"Carmosino M.L., Impagliazzo R., Kabanets V., Kolokolova A.","Agnostic learning from tolerant natural proofs",2017,"Leibniz International Proceedings in Informatics, LIPIcs",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028698975&doi=10.4230%2fLIPIcs.APPROX%2fRANDOM.2017.35&partnerID=40&md5=b813c4b1bee746e32b41a965af21deee","We generalize the ""learning algorithms from natural properties"" framework of [4] to get agnostic learning algorithms from natural properties with extra features. We show that if a natural property (in the sense of Razborov and Rudich [28]) is useful also against functions that are close to the class of ""easy"" functions, rather than just against ""easy"" functions, then it can be used to get an agnostic learning algorithm over the uniform distribution with membership queries. For AC0[q], any prime q (constant-depth circuits of polynomial size, with AND, OR, NOT, and MODq gates of unbounded fanin), which happens to have a natural property with the requisite extra feature by [27, 31, 28], we obtain the first agnostic learning algorithm for AC0[q], for every prime q. Our algorithm runs in randomized quasi-polynomial time, uses membership queries, and outputs a circuit for a given boolean function f : {0, 1}n ! {0, 1} that agrees with f on all but at most (poly log n) opt fraction of inputs, where opt is the relative distance between f and the closest function h in the class AC0[q]. For the ideal case, a natural proof of strongly exponential correlation circuit lower bounds against a circuit class C containing AC0[2] (i.e., circuits of size exp( (n)) cannot compute some n-variate function even with exp(- (n)) advantage over random guessing) would yield a polynomial-time query agnostic learning algorithm for C with the approximation error O(opt). © Marco L. Carmosino, Russell Impagliazzo, Valentine Kabanets, and Antonina Kolokolova.","AC0[q]; Agnostic learning; Circuit lower bounds; Meta-algorithms; Natural proofs; Nisan-Wigderson generator","Approximation algorithms; Boolean functions; C (programming language); Combinatorial optimization; Optimization; Polynomial approximation; Polynomials; Random processes; AC0[q]; Agnostic learning; Circuit lower bounds; Meta-algorithms; Natural proofs; Nisan-Wigderson generator; Learning algorithms",2-s2.0-85028698975
"Ebrahimi A.K., Sheikhshoaie I., Mehran M.","Facile synthesis of a new metal-organic framework of copper (II) by interface reaction method, characterization, and its application for removal of Malachite Green",2017,"Journal of Molecular Liquids",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021853984&doi=10.1016%2fj.molliq.2017.06.097&partnerID=40&md5=48cf1055145d58194707b5e3e16b5e8c","In this study, we demonstrated the synthesis of a new copper (II) metal organic framework (Cu-MOF) by using 1,2,4,5-benzenetetracarboxylic acid and copper (II) acetate and characterized its structure by some methods like FT-IR, scanning electron microscopy (SEM), differential thermal (TG– DT) analyses, X-ray diffraction (XRD) patterns, and specific surface area was calculated by Brunauer–Emmett–Teller (BET) method. The dye removal activity of Cu-MOF was investigated by Malachite Green (MG) removal under visible light irradiation in different conditions. The optimized parameter values of temperature, pH, and initial concentration of Cu-MOF obtained 25 °C, 9.0 and 5 mg respectively. In addition, the dye removal process can be explained in terms of the pseudo-first-order kinetic model. © 2017 Elsevier B.V.","Batch analysis; Copper (II) metal organic framework; Interface reaction method; Malachite Green","Carbonate minerals; Crystalline materials; Java programming language; Organometallics; Scanning electron microscopy; X ray diffraction; 1 ,2 ,4 ,5-benzenetetracarboxylic acid; Batch analysis; Brunauer-Emmett-Teller method; Interface reactions; Malachite green; Metal organic framework; Pseudo-first order kinetic model; Visible-light irradiation; Copper",2-s2.0-85021853984
"Martignano M.","Bounded model checking and abstract interpretation of large C codebases",2017,"4th IEEE International Workshop on Metrology for AeroSpace, MetroAeroSpace 2017 - Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028537812&doi=10.1109%2fMetroAeroSpace.2017.7999568&partnerID=40&md5=ca6fd7f8b4bf0963c7b888d4cf16445b","This paper presents a methodology allowing the execution of Bounded Model Checking (via CBMC) and Abstract Interpretation (via Frama-C) analyses on large, real case, C codebases. Then the paper shows some of the results that can nowadays be achieved with relatively new tools like Clang Static Analyzer and Facebook Infer. Finally, a brief introduction on SonarQube and how it can be used to display and monitor the analyses results is given. © 2017 IEEE.","Abstract Interpretation; Bounded Model Checking; CBMC; Clang Static Analyzer; Facebook Infer; Frama-C; SonarQube","Abstracting; C (programming language); Display devices; Social networking (online); Units of measurement; Abstract interpretations; Bounded model checking; CBMC; Facebook; SonarQube; Static analyzers; Model checking",2-s2.0-85028537812
"Ruiz Rodríguez L.G., Aller K., Bru E., De Vuyst L., Hébert E.M., Mozzi F.","Enhanced mannitol biosynthesis by the fruit origin strain Fructobacillus tropaeoli CRL 2034",2017,"Applied Microbiology and Biotechnology",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021784725&doi=10.1007%2fs00253-017-8395-1&partnerID=40&md5=ca0934a4dedbadc3cfc5fd43569f47b2","Mannitol is a natural low-calorie sugar alcohol produced by certain (micro)organisms applicable in foods for diabetics due to its zero glycemic index. In this work, we evaluated mannitol production and yield by the fruit origin strain Fructobacillus tropaeoli CRL 2034 using response surface methodology with central composite design (CCD) as optimization strategy. The effect of the total saccharide (glucose + fructose, 1:2) content (TSC) in the medium (75, 100, 150, 200, and 225 g/l) and stirring (S; 50, 100, 200, 300 and 350 rpm) on mannitol production and yield by this strain was evaluated by using a 22 full-factorial CCD with 4 axial points (α = 1.5) and four replications of the center point, leading to 12 random experimental runs. Fermentations were carried out at 30 °C and pH 5.0 for 24 h. Minitab-15 software was used for experimental design and data analyses. The multiple response prediction analysis established 165 g/l of TSC and 200 rpm of S as optimal culture conditions to reach 85.03 g/l [95% CI (78.68, 91.39)] of mannitol and a yield of 82.02% [95% CI (71.98, 92.06)]. Finally, a validation experiment was conducted at the predicted optimum levels. The results obtained were 81.91 g/l of mannitol with a yield of 77.47% in outstanding agreement with the expected values. The mannitol 2-dehydrogenase enzyme activity was determined with 4.6–4.9 U/mg as the highest value found. To conclude, F. tropaeoli CRL 2034 produced high amounts of high-quality mannitol from fructose, being an excellent candidate for this polyol production. © 2017, Springer-Verlag GmbH Germany.","Central composite design; Fructobacillus; Lactic acid bacteria; Mannitol; Response surface methodology","Biochemistry; C (programming language); Drug products; Enzyme activity; Fructose; Fruits; Lactic acid; Surface properties; Central composite designs; Fructobacillus; Lactic acid bacteria; Mannitol; Response surface methodology; Polyols; carbohydrate; fructose; glucose; mannitol; mannitol dehydrogenase; alcohol; bacterium; chemical compound; design method; enzyme; enzyme activity; experimental design; fermentation; fruit; optimization; response surface methodology; software; sugar; Article; bacterial strain; bacterium culture; biosynthesis; controlled study; enzyme activity; fermentation; Fructobacillus tropaeoli; lactic acid bacterium; molecular typing; nonhuman; response surface method",2-s2.0-85021784725
"Cividino L., Ho H.","EMI test considerations for power supplies",2017,"Electronic Products",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026288454&partnerID=40&md5=3f9483ce284ad58407e0a930c97643c7","Some considerations when performing verification tests and provides data showing significant electromagnetic interference (EMI) performance variations over load ranges. Recommendations are made on the load and line conditions to perform the verification testing. These recommendations ensure proper and thorough evaluation while also minimizing the tests required to achieve a high confidence level of compliance. Higher-power converters especially those needing to meet class C or D harmonic current, will have a power factor correction (PFC) stage to minimize input current harmonics. There are various methods of achieving the PFC. These include transition mode control, two-phase PFC stage, in which one phase may be disabled at lower loads, then enabled and phase-shifted to reduce input ripple current at higher loads and fixed and variable frequency modes. With the end application in mind and lessons from the above case studies, it is essential to perform conducted emissions tests at 100 Vac, 120 Vac, and 240 Vac and load current sweeps from zero to full load, or at least at 100%, 50%, and 10% of rated load to ensure compliance to internal norms.",,"C (programming language); Electric power factor correction; Electromagnetic pulse; Conducted emissions; Harmonic currents; Input current harmonics; Performance variations; Power factor corrections; Variable frequencies; Verification testing; Verification tests; Load testing",2-s2.0-85026288454
"Fokkink W., Van Glabbeek R.J.","Precongruence formats with lookahead through modal decomposition",2017,"Leibniz International Proceedings in Informatics, LIPIcs",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028713738&doi=10.4230%2fLIPIcs.CSL.2017.25&partnerID=40&md5=9f615d131ffd63d84a12bc2c14bbf21b","Bloom, Fokkink & van Glabbeek (2004) presented a method to decompose formulas from Hennessy-Milner logic with regard to a structural operational semantics specification. A term in the corresponding process algebra satisfies a Hennessy-Milner formula if and only if its subterms satisfy certain formulas, obtained by decomposing the original formula. They used this decomposition method to derive congruence formats in the realm of structural operational semantics. In this paper it is shown how this framework can be extended to specifications that include bounded lookahead in their premises. This extension is used in the derivation of a congruence format for the partial trace preorder. © Wan Fokkink and Rob J. van Glabbeek.","Compositionality; Congruence; Lookahead; Modal Decomposition; Modal Logic; Structural Operational Semantics","Computer programming languages; Decomposition; Semantics; Specifications; Compositionality; Congruence; Lookahead; Modal decomposition; Modal logic; Structural operational semantics; Computer circuits",2-s2.0-85028713738
"Lian X., Wang Y., Hou X., Meng X.","Acquisition Scheme for Impulse Radio UWB TT&C Signal",2017,"Dianzi Yu Xinxi Xuebao/Journal of Electronics and Information Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032183749&doi=10.11999%2fJEIT161213&partnerID=40&md5=9998f33ab38a59cd6949cacd9880ce0f","The impulse radio Ultra-WideBand (UWB) Tracking, Telemetry, and Command (TT&C) system is a new kind of TT&C system that can greatly improve the concealment and anti-interference performance. To solve the acquisition problem of the impulse radio UWB TT&C signal, an acquisition scheme based on Partial Matched Filtering and Fast Fourier Transform (PMF-FFT) is proposed to accomplish the three-dimensional acquisition of pulse phase, pseudorandom code phase and Doppler frequency simultaneously. Then, according to the problem of excessive search space, long acquisition time and low estimation accuracy of Doppler frequency, a new improved acquisition scheme is proposed. It adopts the two-step scheme to accomplish time delay phase acquisition, and uses the modified Rife algorithm to further estimate the Doppler frequency. Simulation results show that this scheme can effectively improve the acquisition speed, reduce the acquisition time, and greatly improve the estimation accuracy of Doppler frequency. © 2017, Science Press. All right reserved.","Acquisition; Doppler frequency; Impulse radio UWB; Rife algorithm; Tracking, Telemetry, and Command (TT&C)","Broadband amplifiers; Doppler effect; Fast Fourier transforms; Frequency estimation; Impulse noise; Mergers and acquisitions; Radio; Signal processing; Signal receivers; Telemetering equipment; Ultra-wideband (UWB); Acquisition; Anti-interference; Doppler frequency; Impulse Radio; Impulse radio ultra-wideband; Matched filtering; Pseudo random codes; Three dimensional acquisition; C (programming language)",2-s2.0-85032183749
"Braga M.S., Jaimes R.F.V.V., Borysow W., Gomes O.F., Salcedo W.J.","Portable multispectral colorimeter for metallic ion detection and classification",2017,"Sensors (Switzerland)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026624561&doi=10.3390%2fs17081730&partnerID=40&md5=e9a8f9aa05c953348b76b527738e56f1","This work deals with a portable device system applied to detect and classify different metallic ions as proposed and developed, aiming its application for hydrological monitoring systems such as rivers, lakes and groundwater. Considering the system features, a portable colorimetric system was developed by using a multispectral optoelectronic sensor. All the technology of quantification and classification of metallic ions using optoelectronic multispectral sensors was fully integrated in the embedded hardware FPGA (Field Programmable Gate Array) technology and software based on virtual instrumentation (NI LabView®). The system draws on an indicative colorimeter by using the chromogen reagent of 1-(2-pyridylazo)-2-naphthol (PAN). The results obtained with the signal processing and pattern analysis using the method of the linear discriminant analysis, allows excellent results during detection and classification of Pb(II), Cd(II), Zn(II), Cu(II), Fe(III) and Ni(II) ions, with almost the same level of performance as for those obtained from the Ultravioled and visible (UV-VIS) spectrophotometers of high spectral resolution. © 2017 by the authors. Licensee MDPI, Basel, Switzerland.","Colorimetric system; Metallic ions detection; Portable environmental monitoring systems","Cadmium compounds; Color; Colorimeters; Colorimetry; Computer programming languages; Discriminant analysis; Field programmable gate arrays (FPGA); Groundwater; Ions; Lead; Metals; Signal processing; Spectral resolution; Zinc compounds; 1-(2-Pyridylazo)-2-naphthol; Colorimetric system; Environmental monitoring system; Fpga(field programmable gate array); High spectral resolution; Linear discriminant analysis; Metallic ions; Virtual Instrumentation; Monitoring",2-s2.0-85026624561
"Liu J., Foo C.C., Zhang Z.-Q.","A 3D multi-field element for simulating the electromechanical coupling behavior of dielectric elastomers",2017,"Acta Mechanica Solida Sinica",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027420682&doi=10.1016%2fj.camss.2017.07.005&partnerID=40&md5=017d924b3a8eaba52049c845cf2cca0f","We propose a multi-field implicit finite element method for analyzing the electromechanical behavior of dielectric elastomers. This method is based on a four-field variational principle, which includes displacement and electric potential for the electromechanical coupling analysis, and additional independent fields to address the incompressible constraint of the hyperelastic material. Linearization of the variational form and finite element discretization are adopted for the numerical implementation. A general FEM program framework is developed using C++ based on the open-source finite element library deal.II to implement this proposed algorithm. Numerical examples demonstrate the accuracy, convergence properties, mesh-independence properties, and scalability of this method. We also use the method for eigenvalue analysis of a dielectric elastomer actuator subject to electromechanical loadings. Our finite element implementation is available as an online supplementary material. © 2017","Dielectric elastomer; Eigenvalue problem; Electromechanical coupling; Implicit multi-field finite element method","C++ (programming language); Computer software; Convergence of numerical methods; Eigenvalues and eigenfunctions; Elastomers; Electric potential; Electroactive polymer actuators; Electromechanical coupling; Incompressible flow; Numerical methods; Plastics; Dielectric elastomer actuators; Dielectric elastomers; Eigenvalue problem; Finite element implementation; Finite-element discretization; Implicit finite element methods; Multi-field; Online supplementary material; Finite element method",2-s2.0-85027420682
"Lin Y.-S., Chao T.-C., Hong J.-H., Tung C.-J.","Comparisons of longitudinal and lateral dose profiles and relative biological effectiveness for DNA double strand breaks among 1H, 4He and 12C beams",2017,"Radiation Physics and Chemistry",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84956862210&doi=10.1016%2fj.radphyschem.2016.02.007&partnerID=40&md5=5ea772049709a37ae4fc549a431f7fad","Monte Carlo FLUKA and MCDS codes were used to study 1H, 4He and 12C ion beams with similar ranges in water phantom. The longitudinal and lateral dose profiles and the relative biological effectiveness (RBE) were investigated. Simulations were performed with particular emphasis in the vicinity of the Bragg peak (BP). The impact of individual nuclear fragments created by the primary beams was examined. Comparisons were made for the BP width, lateral dose profile width, and RBE value at different depths in the phantom. RBE values for the induction of DNA double-strand breaks were estimated, particularly in the vicinity of the BP. Results showed that 12C beam had the narrowest BP width, smallest lateral dose profile, and largest RBE value, followed by 4He and 1H beams. However, the differences between 4He and 12C were smaller than those between 1H and 4He. It also showed that the influence of nuclear fragments was significant for 12C beam, moderate for 4H beam, and minor for 1H beam. This influence was important for 12C at depths beyond the BP. Our results suggest that 4He beam is also a promising option for cancer therapy. © 2016 Elsevier Ltd","Bragg peak; Ion beam; Lateral dose profile; Nuclear fragments; RBE","Heavy ions; Ion beams; Bragg peaks; Cancer therapy; DNA double strand breaks; Dose profile; Nuclear fragments; Primary beams; Relative biological effectiveness; Water phantom; C (programming language); carbon; double stranded DNA; helium; proton; Article; Bragg peak; carbon beam; cell death; chromosome aberration; comparative study; controlled study; DNA strand breakage; dosimetry; helium beam; lateral dose profile; longitudinal dose profile; phantom; proton radiation; radiation beam; radiation energy; radiological parameters; relative biologic effectiveness; simulation",2-s2.0-84956862210
"Huang Y., Liu B., Cao H., Lin Y., Tang S., Wang M., Li X.","Novel gel polymer electrolyte based on matrix of PMMA modified with polyhedral oligomeric silsesquioxane",2017,"Journal of Solid State Electrochemistry",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016548209&doi=10.1007%2fs10008-017-3568-5&partnerID=40&md5=8c414a651a42295509d728f89131861d","One novel cage kind of polyhedral ligomeric silsesquioxane (POSS), for modification application of gel polymer electrolyte (GPE) in lithium ion batteries (LIBs), was successfully synthesized via a facile two-step reaction under simple conditions. In four kinds of GPE with different filling amount of POSS, GPE-8 with 8 wt.% POSS content expresses the highest ionic conductivity up to the level of 10−3 S cm−1 at 30 °C. The comprehensive investigation indicates that GPE-8 is thermally stable before 100 °C, electrochemical stability window (ESW) is identified as 5.0 V, and the compatibility of electrolyte with lithium electrode and the charging-discharging cycling property of the assembled cell is satisfying. © 2017, Springer-Verlag Berlin Heidelberg.","Gel polymer electrolyte; Polyhedral oligomeric silsesquioxane; Polymethyl methacrylate","C (programming language); Electrolytes; Lithium alloys; Lithium compounds; Lithium-ion batteries; Oligomers; Polymers; Polymethyl methacrylates; Cycling properties; Electrochemical stabilities; Gel polymer electrolytes; Lithium electrode; Polyhedral oligomeric silsesquioxanes; Silsesquioxanes; Thermally stable; Two-step reactions; Polyelectrolytes",2-s2.0-85016548209
"Rakočević M., Popović S., Ivanišević N.","A computational method for laminated composite plates based on layerwise theory",2017,"Composites Part B: Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019632264&doi=10.1016%2fj.compositesb.2017.03.044&partnerID=40&md5=745012c885115c51c00f4c46c3247bb9","This paper presents a new computational method for stress-strain analysis of simply supported rectangular cross-ply laminated composite plates subjected to transverse loads which was applied in the authors FORTRAN program code. The algorithm of the program is based on the layerwise theory of Reddy. Equations obtained by applying the principle of virtual displacements were solved in a closed form using double trigonometric series. Convergence control and numerical stability of the program's outputs: displacements and stresses, with appropriate comments, are discussed. Comparison and verification of the presented computational method was carried out in relation to the results given in the available literature. Also, a comparison with the values calculated using the ANSYS program which is based on finite element method was performed. The paper presents and provides comments on edge dimensionless displacements and v¯ of a laminated plate. For the adopted simply supported rectangular four-layer plate with antisymmetric layer an analysis of dimensionless deflection change in the middle of the plate and displacemen u¯ on the edge of the plate was performed, as well as the analysis of the ratio between the maximum values σxy/σyy and σyz/σyy due to the change of the aspect ratio a/b, the side-to-thickness ratio b/h and elastic modulus ratio E1/E2. The results of the proposed computational model based on the layerwise theory are given in a tabular and graphical form. © 2017 Elsevier Ltd","Analytical solution; Displacements; FORTRAN program; Laminated plates; Layerwise theory; Stresses","Aspect ratio; Computation theory; Computational methods; FORTRAN (programming language); Laminated composites; Laminating; Stresses; Dimensionless displacements; Displacements; Displacements and stress; FORTRAN programs; Laminated composite plates; Laminated plate; Layer-wise theory; Principle of virtual displacements; Finite element method",2-s2.0-85019632264
"Prezza N.","A framework of DYNAMIC data structures for string processing",2017,"Leibniz International Proceedings in Informatics, LIPIcs",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028751276&doi=10.4230%2fLIPIcs.SEA.2017.11&partnerID=40&md5=4caf697a9d6b82150c70be0a0b23ce5e","In this paper we present DYNAMIC, an open-source C++ library implementing dynamic compressed data structures for string manipulation. Our framework includes useful tools such as searchable partial sums, succinct/gap-encoded bitvectors, and entropy/run-length compressed strings and FM indexes. We prove close-to-optimal theoretical bounds for the resources used by our structures, and show that our theoretical predictions are empirically tightly verified in practice. To conclude, we turn our attention to applications. We compare the performance of five recently-published compression algorithms implemented using DYNAMIC with those of stateof-the-art tools performing the same task. Our experiments show that algorithms making use of dynamic compressed data structures can be up to three orders of magnitude more space-efficient (albeit slower) than classical ones performing the same tasks. © Nicola Prezza.","Bitvector; C++; Compression; Data structure; DYNAMIC; String","C++ (programming language); Cesium; Compaction; Dynamics; Bitvector; Compressed data structures; Compression algorithms; Dynamic data structure; String; String processing; Theoretical bounds; Three orders of magnitude; Data structures",2-s2.0-85028751276
"Volkovich I.","On some computations on sparse polynomials",2017,"Leibniz International Proceedings in Informatics, LIPIcs",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028724392&doi=10.4230%2fLIPIcs.APPROX%2fRANDOM.2017.48&partnerID=40&md5=d23008c25acd470cd5a2a8e55f94a782","In arithmetic circuit complexity the standard operations are {+, ×}. Yet, in some scenarios exponentiation gates are considered as well (see e.g. [6, 1, 28, 30]). In this paper we study the question of efficiently evaluating a polynomial given an oracle access to its power. Among applications, we show that: A reconstruction algorithm for a circuit class C can be extended to handle fe for f 2 C. There exists an efficient deterministic algorithm for factoring sparse multiquadratic1 polynomials. There is a deterministic algorithm for testing a factorization of sparse polynomials, with constant individual degrees, into sparse irreducible factors. That is, testing if f = g1 . . . gm when f has constant individual degrees and gi-s are irreducible. There is a deterministic reconstruction algorithm for multilinear2 depth-4 circuits with two multiplication gates. There exists an efficient deterministic algorithm for testing whether two powers of sparse polynomials are equal. That is, fd ge when f and g are sparse. © Ilya Volkovich.","Arithmetic Circuits; Derandomization; Reconstruction","C (programming language); Combinatorial optimization; Image reconstruction; Logic circuits; Optimization; Polynomials; Random processes; Arithmetic circuit; Derandomization; Deterministic algorithms; Exponentiations; Oracle access; Reconstruction algorithms; Sparse polynomials; Approximation algorithms",2-s2.0-85028724392
"Awalludin M.F., Sulaiman O., Hashim R., Yhaya M.F.","Assessment of oil palm trunk liquefaction in glycerol and ethylene glycol by 24-1 fractional factorial design",2017,"Nihon Enerugi Gakkaishi/Journal of the Japan Institute of Energy",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029229529&doi=10.3775%2fjie.96.319&partnerID=40&md5=f04d85959f56d9b0c3c68438a4e518c8","Liquefaction of oil palm trunk (OPT) in ethylene glycol and glycerol, with H2SO4 as a catalyst, at a temperature of 150 °C was conducted based on Design of Experiment (DoE) aided by software Stat-Ease Inc., Design-Expert® Version 7. A 24-1 fractional factorial design was used. The results showed that factors such as types of solvents, percentage of H2SO4 catalyst and liquefaction time influenced the final liquefaction yield. Liquefaction of OPT in glycerol gave higher amount of liquefied yield. Besides, higher percentage of H2SO4 catalyst and longer liquefaction time also gave higher liquefaction yields. © 2017, Japan Institute of Energy. All rights reserved.","Design of experiment; Liquefaction; Oil palm trunk","C (programming language); Catalysts; Ethylene; Ethylene glycol; Glycerol; Liquefaction; Palm oil; Polyols; Design-expert; Fractional factorial designs; Oil palm trunks; Design of experiments; Catalysts; Computer Programs; Ethylene Glycol; Glycerol; Liquefaction",2-s2.0-85029229529
"Zibordi G., Talone M., Jankowski L.","Response to temperature of a class of in situ hyperspectral radiometers",2017,"Journal of Atmospheric and Oceanic Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028019935&doi=10.1175%2fJTECH-D-17-0048.1&partnerID=40&md5=e85bc36cd89a851a9ea6c57fd4d1794c","The response to temperature of sample hyperspectral radiometers commonly used to support the validation of satellite ocean color data was characterized in the 400-800-nm spectral range. Measurements performed in the 10°-40°C interval at 5°C increments showed mean temperature coefficients varying from -0.04 × 10-2 (°C)-1 at 400 nm to +0.33 × 10-2 (°C)-1 at 800 nm, which are largely explained by the temperature coefficient of the photodetector array constituting the core of the sensor. Overall, the results indicate the possibility of applying temperature corrections with an uncertainty of approximately 0.03 × 10-2 (°C)-1 for the class of hyperspectral radiometers investigated in the study. © 2017 American Meteorological Society.","In situ oceanic observations; Instrumentation/sensors","Ferroelectric films; Ion sensitive field effect transistors; Radiometers; Temperature; Instrumentation/sensors; Mean temperature; Photo detector array; Satellite Ocean Color; Situ oceanic observations; Spectral range; Temperature coefficient; Temperature correction; C (programming language)",2-s2.0-85028019935
"Safar M., Button T.W., Zabcik M.","Control of PbO loss during sintering of PZT: Laboratory vs industry",2017,"2017 Joint IEEE International Symposium on Applications of Ferroelectrics, International Workshop on Acoustic Transduction Materials and Devices and Piezoresponse Force Microscopy Workshop, ISAF-IWATMD-PFM 2017 - Conference",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028560791&doi=10.1109%2fISAF.2017.8000218&partnerID=40&md5=8dcd14932a344b3d36074d3bec5fa755","The relatively low melting point of lead oxide (approx. 900 °C) has always presented an issue in the processing of lead zirconium titanate (PZT) piezoelectric ceramics. The loss of PbO at high sintering temperatures (up to 1300 °C) can cause undesirable changes in stoichiometry, phase composition and electrical properties of the final ceramic product. In high-volume production, the PbO loss per piece is low and, with a small excess of lead oxide in the initial powder composition, it is usually sufficient to sinter samples in enclosed crucibles. Small-scale lab processing requires better atmosphere control, usually implemented by surrounding the sample in a lead oxide-containing powder bed. Such control is required in order to prepare samples for detailed composition- microstructure-property studies. In this work, a typical industrial sintering program with slow heating rate and long dwell time was used to sinter hard PZT samples (NCE40 supplied by Noliac) at 1260 °C in a laboratory furnace. It was found that conventionally used powder beds such as PZT or PbZrO3 mixed in different ratios with ZrO2 were either difficult to separate from the crucible/samples or not able to sufficiently prevent the weight loss of the samples. Excessive PbO loss was indicated by the presence of ZrO2 secondary phase in sintered samples. Weight loss of individual samples, and their resulting electrical properties, varied depending on the composition and particle size of the powder bed. An alternative powder bed consisting of ZrO2 sand reacted with PbO was found to sufficiently reduce the PbO loss in the samples (no secondary phase detected) while being easily separated from both the samples and crucible after sintering, and maintaining good piezoelectric properties in the sintered samples. © 2017 IEEE.","atmosphere control; PbO loss; piezoelectric ceramics; powder bed; processing; PZT; sintering","Bacteriophages; C (programming language); Ceramic materials; Crucibles; Lead oxide; Particle size; Piezoelectric ceramics; Piezoelectricity; Processing; Scanning probe microscopy; Atmosphere controls; High sintering temperatures; High-volume production; Lead zirconium titanate; Microstructure properties; Piezoelectric property; Powder bed; Powder composition; Sintering",2-s2.0-85028560791
"Hu W., Wang H., Zhou J.","Design of Abnormal Event Diagnosis System Based on Petri Net for High-Speed Vehicle",2017,"Xibei Gongye Daxue Xuebao/Journal of Northwestern Polytechnical University",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028353094&partnerID=40&md5=b61fbec69a4af0dd5e78e04491a0b8be","High-speed vehicle adopt different control strategies for different fault events in the event of external environment disturbance and servo failure event leading to state instability. In order to enable the vehicle to identify the type of event that causes the abnormal state autonomously, and accordingly call the corresponding processing strategy, this paper proposes a decision system based on decision network for vehicle anomaly diagnosis. Based on the Petri net method, the abnormal event diagnosis system of the vehicle is constructed. By analyzing the influence of the different event on the flight state, the system can make the vehicle autonomously locate the event types that cause the abnormal state quickly by using the matrix reasoning ability of Petri net, with sensor reading of each state quantity as input and event type as output, provides the basis for the follow-up control behavior. Finally, a RLV reentry section is taken as an example. After the various types of faults are injected into it, the correctness of the event diagnosis system is verified by C++ software. The result proves that the diagnosis system can diagnose and distinguish different types of events correctly. © 2017, Editorial Board of Journal of Northwestern Polytechnical University. All right reserved.","Environment disturbance; Matrix reasoning; Online positioning; Petri net; Servo failure","C++ (programming language); Computer software; Petri nets; Anomaly diagnosis; Control strategies; Environment disturbance; External environments; Follow-up control; High speed vehicles; Online positioning; Processing strategies; Vehicles",2-s2.0-85028353094
"Pepe F., Bevilacqua A., Andreani P.","On the Remarkable Performance of the Series-Resonance CMOS Oscillator",2017,"IEEE Transactions on Circuits and Systems I: Regular Papers",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028954055&doi=10.1109%2fTCSI.2017.2727283&partnerID=40&md5=f64812ccd4de499d54091dd0f498f1c2","Common harmonic oscillator topologies, such as class-B and class-C, are typically unable to meet ultra stringent phase noise requirements, due to the exceedingly large capacitance (and, symmetrically, low inductance) that would be required in the parallel resonator. In this paper, we show that an oscillator making use of series resonators is ideally able to overcome this limitation, with the additional, surprising benefit that the phase noise contribution from the active oscillator core can be made negligible, provided that very good MOS switches are available. IEEE","Harmonic analysis; Impedance; impulse sensitivity function (ISF); Inverters; MOS devices; oscillators; Phase noise; Phase noise; Topology","C (programming language); CMOS integrated circuits; Electric impedance; Electric inverters; Harmonic analysis; MOS devices; Oscillators (electronic); Resonators; Topology; Class B; CMOS oscillators; Harmonic oscillators; Impulse sensitivity functions; Low inductance; MOS switches; Series resonance; Phase noise",2-s2.0-85028954055
"Cecilia J.A., García-Sancho C., Mérida-Robles J.M., Santamaría-González J., Infantes-Molina A., Moreno-Tost R., Maireles-Torres P.","Aluminum doped mesoporous silica SBA-15 for glycerol dehydration to value-added chemicals",2017,"Journal of Sol-Gel Science and Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019651834&doi=10.1007%2fs10971-017-4411-2&partnerID=40&md5=9dd8ace7a1251db16629165cc123aa92","Abstract: A series of Al-grafted mesoporous SBA-15 silica was synthesized and tested as catalysts in the gas-phase dehydration of glycerol to acrolein. Different Si/Al molar ratios were employed to tune the structure, texture and acidity of catalysts in order to analyze their effect on the catalytic performance. Different characterization techniques, such as powder X-ray diffraction, X-ray photoelectron spectroscopy, 27Al MAS NMR, N2 adsorption–desorption at −196 °C, ammonia temperature programmed desorption (NH3-TPD) and adsorption of pyridine coupled to Fourier transform infrared spectroscopy were employed. All materials were active in glycerol dehydration, being acrolein the main product in all cases. The catalyst with the highest Al content (AlSBA-2.5) showed the highest acrolein yield (27.6%) after 8 h of time-on-stream. A clear relationship between the effective production of acrolein and the acidity of catalysts could be established. Catalysts suffered from deactivation by coke deposition on the surface, but they can be reused, at least during three catalytic cycles, after regeneration at 550 °C in air during 4 h after each cycle. Graphical Abstract: [InlineMediaObject not available: see fulltext.]. © 2017, Springer Science+Business Media New York.","Acid catalysts; Acrolein; Aluminium doped mesoporous silica; Glycerol dehydration","Aldehydes; Aluminum; C (programming language); Catalysts; Dehydration; Desorption; Fourier transform infrared spectroscopy; Glycerol; Herbicides; Mesoporous materials; Silica; Temperature programmed desorption; X ray diffraction; Acid catalyst; Acrolein; Catalytic performance; Characterization techniques; Glycerol dehydrations; Mesoporous Silica; Powder X ray diffraction; Value-added chemicals; X ray photoelectron spectroscopy",2-s2.0-85019651834
"Zaghloul M.R.","Algorithm 985: Simple, efficient, and relatively accurate approximation for the evaluation of the Faddeyeva function",2017,"ACM Transactions on Mathematical Software",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029801926&doi=10.1145%2f3119904&partnerID=40&md5=e972a86bc5de90201c17b6c20bb5a1e5","We present a new simple algorithm for efficient, and relatively accurate computation of the Faddeyeva function w(z). The algorithm carefully exploits previous approximations by Hui et al. (1978) and Humlíček (1982) along with asymptotic expressions from Laplace continued fractions. Over a wide and fine grid of the complex argument, z = x + iy, numerical results from the present approximation show a maximum relative error less than 4.0 × 10-5 for both real and imaginary parts of w while running in a relatively shorter execution time than other competitive techniques. In addition to the calculation of the Faddeyeva function, w, partial derivatives of the real and imaginary parts of the function can easily be calculated and returned as optional output. © 2017 ACM.","Accuracy; Complex probability function; Fortran; Function evaluation; Matlab","Approximation algorithms; Computational efficiency; FORTRAN (programming language); MATLAB; Accuracy; Accurate computations; Asymptotic expressions; Continued fraction; Faddeyeva functions; Maximum relative errors; Partial derivatives; Probability functions; Function evaluation",2-s2.0-85029801926
"Lopes J., Rocha J., Redondo L., Cruz J.","Particle Accelerator Focus Automation",2017,"Measurement Science Review",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029602183&doi=10.1515%2fmsr-2017-0024&partnerID=40&md5=b0b4f76f9a1130cc9c2d58685eb9dba6","The Laboratório de Aceleradores e Tecnologias de Radiacaõ (LATR) at the Campus Tecnológico e Nuclear, of Instituto Superior Técnico (IST) has a horizontal electrostatic particle accelerator based on the Van de Graaff machine which is used for research in the area of material characterization. This machine produces alfa (He+) and proton (H+) beams of some μA currents up to 2 MeV/q energies. Beam focusing is obtained using a cylindrical lens of the Einzel type, assembled near the high voltage terminal. This paper describes the developed system that automatically focuses the ion beam, using a personal computer running the LabVIEW software, a multifunction input/output board and signal conditioning circuits. The focusing procedure consists of a scanning method to find the lens bias voltage which maximizes the beam current measured on a beam stopper target, which is used as feedback for the scanning cycle. This system, as part of a wider start up and shut down automation system built for this particle accelerator, brings great advantages to the operation of the accelerator by turning it faster and easier to operate, requiring less human presence, and adding the possibility of total remote control in safe conditions. © 2017 José Lopes et al.","beam focus; ion source; LabVIEW; Particle accelerator","Acceleration; Automation; Computer programming languages; Ion beams; Ion sources; Particle accelerators; Personal computers; Remote control; Automation systems; Beam focus; Beam focusing; Cylindrical lens; Lab-view softwares; LabViEW; Material characterizations; Scanning methods; Signal conditioning circuits",2-s2.0-85029602183
"Kumar L., Misra S., Rath S.K.","An empirical analysis of the effectiveness of software metrics and fault prediction model for identifying faulty classes",2017,"Computer Standards and Interfaces",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014063875&doi=10.1016%2fj.csi.2017.02.003&partnerID=40&md5=54444f08395563f7f3b13de84319b119","Software fault prediction models are used to predict faulty modules at the very early stage of software development life cycle. Predicting fault proneness using source code metrics is an area that has attracted several researchers' attention. The performance of a model to assess fault proneness depends on the source code metrics which are considered as the input for the model. In this work, we have proposed a framework to validate the source code metrics and identify a suitable set of source code metrics with the aim to reduce irrelevant features and improve the performance of the fault prediction model. Initially, we applied a t-test analysis and univariate logistic regression analysis to each source code metric to evaluate their potential for predicting fault proneness. Next, we performed a correlation analysis and multivariate linear regression stepwise forward selection to find the right set of source code metrics for fault prediction. The obtained set of source code metrics are considered as the input to develop a fault prediction model using a neural network with five different training algorithms and three different ensemble methods. The effectiveness of the developed fault prediction models are evaluated using a proposed cost evaluation framework. We performed experiments on fifty six Open Source Java projects. The experimental results reveal that the model developed by considering the selected set of source code metrics using the suggested source code metrics validation framework as the input achieves better results compared to all other metrics. The experimental results also demonstrate that the fault prediction model is best suitable for projects with faulty classes less than the threshold value depending on fault identification efficiency (low – 48.89%, median- 39.26%, and high – 27.86%). © 2017 Elsevier B.V.","Artificial neural network; Cost analysis framework; Ensemble method; Feature selection techniques; Source code metrics","Codes (symbols); Computer programming languages; Computer software; Cost benefit analysis; Forecasting; Life cycle; Multivariant analysis; Neural networks; Regression analysis; Software design; Cost analysis; Ensemble methods; Logistic regression analysis; Multivariate linear regressions; Selection techniques; Software development life cycle; Software fault prediction; Source code metrics; Open source software",2-s2.0-85014063875
"Chochlov M., English M., Buckley J.","A historical, textual analysis approach to feature location",2017,"Information and Software Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018634750&doi=10.1016%2fj.infsof.2017.04.003&partnerID=40&md5=4b341206a4635905b42cbc381d525d0c","Context Feature location is the task of finding the source code that implements specific functionality in software systems. A common approach is to leverage textual information in source code against a query, using Information Retrieval (IR) techniques. To address the paucity of meaningful terms in source code, alternative, relevant source-code descriptions, like change-sets could be leveraged for these IR techniques. However, the extent to which these descriptions are useful has not been thoroughly studied. Objective This work rigorously characterizes the efficacy of source-code lexical annotation by change-sets (ACIR), in terms of its best-performing configuration. Method A tool, implementing ACIR, was used to study different configurations of the approach and to compare them to a baseline approach (thus allowing comparison against other techniques going forward). This large-scale evaluation employs eight subject systems and 600 features. Results It was found that, for ACIR: (1) method level granularity demands less search effort; (2) using more recent change-sets improves effectiveness; (3) aggregation of recent change-sets by change request, decreases effectiveness; (4) naive, text-classification-based filtering of “management” change-sets also decreases the effectiveness. In addition, a strongly pronounced dichotomy of subject systems emerged, where one set recorded better feature location using ACIR and the other recorded better feature location using the baseline approach. Finally, merging ACIR and the baseline approach significantly improved performance over both standalone approaches for all systems. Conclusion The most fundamental finding is the importance of rigorously characterizing proposed feature location techniques, to identify their optimal configurations. The results also suggest it is important to characterize the software systems under study when selecting the appropriate feature location technique. In the past, configuration of the techniques and characterization of subject systems have not been considered first-class entities in research papers, whereas the results presented here suggests these factors can have a big impact. © 2017 Elsevier B.V.","Dataset expansion; Feature location; Search effort; Software systems’ characterization; Version histories","Classification (of information); Codes (symbols); Computer programming languages; Computer software; Location; Text processing; Feature location; IR techniques; Research papers; Search efforts; Software systems; Text classification; Textual analysis; Textual information; Feature extraction",2-s2.0-85018634750
"Zhao X.-D., Liang S.-X., Sun Z.-C., Zhao X.-Z., Sun J.-W., Liu Z.-B.","A GPU accelerated finite volume coastal ocean model",2017,"Journal of Hydrodynamics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023593879&doi=10.1016%2fS1001-6058%2816%2960780-1&partnerID=40&md5=3044c07411d8d45e14c9df7c72180ac8","With the unstructured grid, the Finite Volume Coastal Ocean Model (FVCOM) is converted from its original FORTRAN code to a Compute Unified Device Architecture (CUDA) C code, and optimized on the Graphic Processor Unit (GPU). The proposed GPU-FVCOM is tested against analytical solutions for two standard cases in a rectangular basin, a tide induced flow and a wind induced circulation. It is then applied to the Ningbo's coastal water area to simulate the tidal motion and analyze the flow field and the vertical tide velocity structure. The simulation results agree with the measured data quite well. The accelerated performance of the proposed 3-D model reaches 30 times of that of a single thread program, and the GPU-FVCOM implemented on a Tesla k20 device is faster than on a workstation with 20 CPU cores, which shows that the GPU-FVCOM is efficient for solving large scale sea area and high resolution engineering problems. © 2017 Publishing House for Journal of Hydrodynamics","3-D ocean model; finite volume coastal ocean model (FVCOM); Graphic Processor Unit (GPU); unstructured grid","C (programming language); Computer graphics equipment; Oceanography; Compute Unified Device Architecture(CUDA); Engineering problems; Finite-volume coastal ocean models; Graphic processor units; High resolution; Ocean model; Unstructured grid; Velocity structure; Graphics processing unit",2-s2.0-85023593879
"Rani S., Verma S., Kumar S.","Tailoring the structural and optical parameters of zirconia nanoparticles via silver",2017,"Applied Physics A: Materials Science and Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025684357&doi=10.1007%2fs00339-017-1148-2&partnerID=40&md5=d0630d7791be6b37505ffd3ff5a79a41","Silver-doped zirconia nanoparticles/thin films with different doping concentrations 0.03, 0.05 and 0.07 mol% were synthesized by sol–gel route followed by spin coating. Zirconium (IV) chloride and silver nitrate were used as precursors. The prepared powdered samples and thin films were annealed in a programmable furnace at 650 °C for 3 h. XRD spectra showed prominent tetragonal phase of zirconia and cubic phase of silver nanoparticles. Structural parameters such as crystallite size, lattice constants, micro-strain, dislocation density, specific surface area and the number of unit cell in a particle were evaluated. FTIR spectra confirmed the expected functional groups present in the annealed samples. Optical absorption spectra of Ag-doped ZrO2 thin films established the tuning of band-gap with dopant concentration. PL spectra exhibited two broad blue emission bands centered at ~340 and 475 nm. TG–DTA thermal analysis of as-prepared sample was also carried out. © 2017, Springer-Verlag GmbH Germany.",,"C (programming language); Crystallite size; Doping (additives); Electromagnetic wave absorption; Film preparation; Fourier transform infrared spectroscopy; Lattice constants; Light absorption; Nanoparticles; Semiconductor doping; Sols; Synthesis (chemical); Thermoanalysis; Thin films; Zirconia; Blue emission bands; Dislocation densities; Dopant concentrations; Doping concentration; Number of unit cells; Silver nanoparticles; Structural parameter; Zirconia nanoparticles; Silver",2-s2.0-85025684357
"Luo F., Wu K., Lu M., Yang L., Shi J.","Surface modification of aluminum hypophosphite and its application for polyurethane foam composites",2017,"Journal of Thermal Analysis and Calorimetry",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992376457&doi=10.1007%2fs10973-016-5908-6&partnerID=40&md5=30480cb3dc9d441157f1035056a105f8","Aluminum hypophosphite (AHP) is surface modified by melamine derivative to fabricate reactive solid flame retardant (MCAHP) for polyurethane foam. MCAHP is successfully prepared and characterized by FTIR and SEM. The flame-retarded efficiency of MCAHP in PU is higher than that of AHP. It demonstrated that MCAHP has better compatibility in PU matrix compared with AHP based on the SEM observation. After surface modification, due to the reaction between MCAHP and PU matrix, crosslinking might be formed between MCAHP and PU matrix, which contributes to the excellent compatibility of MCAHP in PU matrix, and as a result, the glass transition temperature of PU/MCAHP is 4 °C higher than that of PU/AHP. The thermal behavior of PU composites is characterized by TG and TG-FTIR, and results suggest the sublimation of melamine at about 320 °C because of the decomposition of the melamine derivative. The sublimation of melamine can consume abundant heat and dilute the oxygen concentration, which is benefit for the improvement of flame retardancy. © 2016, Akadémiai Kiadó, Budapest, Hungary.","Aluminum hypophosphite; Flame retardant; Polyurethane foam; Thermal analysis","Aluminum; Crosslinking; Flame retardants; Foams; Glass transition; Hierarchical systems; Polyurethanes; Rigid foamed plastics; Sublimation; Surface treatment; Thermoanalysis; Flame retardancy; ITS applications; Melamine derivatives; Oxygen concentrations; Polyurethane Foam; SEM observation; Surface-modified; Thermal behaviors; C (programming language)",2-s2.0-84992376457
"Abdulla P.A., Aronis S., Jonsson B., Sagonas K.","Source sets: A foundation for optimal dynamic partial order reduction",2017,"Journal of the ACM",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028081944&doi=10.1145%2f3073408&partnerID=40&md5=0bdae70d99de4e8d7b0646b46f56713f","Stateless model checking is a powerful method for program verification that, however, suffers from an exponential growth in the number of explored executions. A successful technique for reducing this number, while still maintaining complete coverage, is Dynamic Partial Order Reduction (DPOR), an algorithm originally introduced by Flanagan and Godefroid in 2005 and since then not only used as a point of reference but also extended by various researchers. In this article, we present a new DPOR algorithm, which is the first to be provably optimal in that it always explores the minimal number of executions. It is based on a novel class of sets, called source sets, that replace the role of persistent sets in previous algorithms. We begin by showing how to modify the original DPOR algorithm to work with source sets, resulting in an eficient and simple-to-implement algorithm, called source-DPOR. Subsequently, we enhance this algorithm with a novel mechanism, called wakeup trees, that allows the resulting algorithm, called optimal-DPOR, to achieve opti-mality. Both algorithms are then extended to computational models where processes may disable each other, for example, via locks. Finally, we discuss tradeoffs of the source- and optimal-DPOR algorithm and present programs that illustrate significant time and space performance differences between them. We have implemented both algorithms in a publicly available stateless model checking tool for Erlang programs, while the source-DPOR algorithm is at the core of a publicly available stateless model checking tool for C/pthread programs running on machines with relaxed memory models. Experiments show that source sets significantly increase the performance of stateless model checking compared to using the original DPOR algorithm and that wakeup trees incur only a small overhead in both time and space in practice. © 2017 ACM.","Concurrency; Dynamic partial order reduction; Software model checking; Source sets; Systematic testing; Wakeup trees","C (programming language); Forestry; Software testing; State space methods; Trees (mathematics); Concurrency; Partial order reductions; Software model checking; Source sets; Systematic testing; Wakeup trees; Model checking",2-s2.0-85028081944
"Yao G.-G., Pei C.-J., Liu P., Zhou J.-P., Zhang H.-W.","Low temperature sintering and microwave dielectric properties of Ca5Ni4(VO4)6 ceramics",2017,"Ceramics International",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020274944&doi=10.1016%2fj.ceramint.2017.05.314&partnerID=40&md5=9fe5bcf7d5a02fcf699795316f68753b","Low-temperature sinterable Ca5Ni4(VO4)6 ceramics were prepared by the conventional solid-state reaction route and its microwave dielectric properties were investigated. The crystalline phase, microstructure, and sintering behavior were studied by XRD and SEM. At the sintering temperatures ranging from 825 °C to 900 °C, pure phase Ca5Ni4(VO4)6 was obtained. The variation trend of εr was in accordance with that of relative density. The Q×f value was closely related to the packing fraction and relative density. The Ca5Ni4(VO4)6 ceramics sintered at 875 °C for 5 h possessed good microwave dielectric properties: εr=9.5, Q×f=54, 100 GHz (at 10.5 GHz) and τf=−60 ppm/°C, which also exhibited good chemical compatibility with silver electrode. © 2017 Elsevier Ltd and Techna Group S.r.l.","Ceramics; Dielectric properties; Rietveld analysis; Sintering","Calcium; Ceramic materials; Dielectric properties; Nickel; Rietveld analysis; Sintering; Solid state reactions; Temperature; Ceramics; Chemical compatibility; Conventional solid state reaction route; Low-temperature sintering; Microwave dielectric properties; Packing fractions; Sintering behaviors; Sintering temperatures; C (programming language)",2-s2.0-85020274944
"Sampath K., Drube T., Rana M.","A Reaffirmation of Fracture Toughness Requirements for ASME Section VIII Vessels for Service Temperatures Colder Than 77 K",2017,"Journal of Pressure Vessel Technology, Transactions of the ASME",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018646014&doi=10.1115%2f1.4036138&partnerID=40&md5=892d46f1fbf17e64b76c972fbf3d5502","To assure adequate fracture resistance of cryogenic pressure vessels designed to operate at a minimum design metal temperature (MDMT) colder than 77 K (196 °C or'320 °F), current American Society of Mechanical Engineers (ASME) Code, Section VIII, Division 1, UHA-51 Impact Test rule requires that the weld metal (WM) meets or exceeds 0.53 mm (21 mils) lateral expansion at 77 K, i.e., LE77K ≥ 0.53 mm (21 mils), as determined using Charpy V-notch (CVN) impact testing. To the credit of this rule, cryogenic pressure vessels fabricated to date meeting the above requirement had continued to serve well-without any adverse incident-in numerous applications across the world, at cryogenic temperatures colder than 77 K. However, a critical examination of the underlying research which relied on a regression equation relating ratio of fracture toughness to yield strength obtained at 4 K, i.e., [KIc/YS]4K with LE77K, revealed that the technical basis for establishing the above requirement is metallurgically unsustainable. To successfully overcome this, the present research employed dimensional analysis and balancing of the previously published regression equations and proposed [KIc/YS]277K as a valid fracture resistance parameter applicable for MDMT 77 K and warmer, as well as MDMT colder than 77 K. Related efforts offered equivalent fracture resistance as an insightful concept, wherein the minimum fracture resistance parameter for a MDMT colder than 77 K is equated as a simple multiple of the minimum fracture resistance parameter at 77 K MDMT. Concluding efforts applied numerical analysis to the equivalent fracture resistance equation to reaffirm the current minimum 0.53 mm (21 mils) CVN LE77K requirement for WM when MDMT is colder than 77 K and to identify minimum required [KIc/YS]277K values for cryogenic service at MDMT 77 K and warmer, and MDMT colder than 77 K. Inherently, the use of [KIc/YS]277K as a fracture resistance parameter offers a tremendous benefit to cryogenic equipment manufacturers, particularly in schedule and cost savings, as LE, KIc, and YS measured at 77 K can be used to successfully assess the fracture resistance at MDMT 77 K and warmer, as well as MDMT colder than 77 K. © 2017 by ASME.",,"C (programming language); Charpy impact testing; Cost benefit analysis; Cryogenics; Fracture; Fracture testing; Impact testing; Metal testing; Pressure vessel codes; Pressure vessels; Service vessels; American society of mechanical engineers; Cryogenic pressure vessels; Cryogenic temperatures; Dimensional analysis; Equipment manufacturers; Regression equation; Resistance parameters; Service temperature; Fracture toughness",2-s2.0-85018646014
"Dekeyser W., Bonnin X., Lisgo S.W., Pitts R.A., Brunner D., LaBombard B., Terry J.L.","SOLPS-ITER Study of neutral leakage and drift effects on the alcator C-Mod divertor plasma",2017,"Nuclear Materials and Energy",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018383035&doi=10.1016%2fj.nme.2017.03.029&partnerID=40&md5=58a5dc5e978cf7b822809b0bc15d3083","As part of an effort to validate the edge plasma model in the SOLPS-ITER code suite under ITER-relevant divertor plasma and neutral conditions, we report on progress in the modeling of the Alcator C-Mod divertor plasma with the new code. We perform simulations with a complete drifts model and kinetic neutrals, including effects of neutral viscosity, ion-molecule collisions and Lyα-opaque conditions, but assuming a pure deuterium plasma. Through a series of simulations with varying divertor geometries, we show the importance of including neutal leakage paths through the divertor substructure on the divertor plasma solution. Moreover, the impact of drifts on inner-outer target asymmetries is assessed. Including both effects, we achieve excellent agreement between simulations and upstream and outer target Langmuir Probe data. In absence of strong volumetric losses due to e.g. impurity radiation in our simulations, the strong inner target detachment observed experimentally remains elusive in our modeling at present. © 2017","Alcator C-Mod; Divertor modeling; SOLPS-ITER","Fusion reactor divertors; Plasma turbulence; Alcator-C-mod; Divertor modeling; Edge plasma modeling; Impurity radiation; Ion-molecule collisions; Neutral conditions; SOLPS-ITER; Target asymmetries; C (programming language)",2-s2.0-85018383035
"Vallejo E., Avignon M.","New metastable phases in an oxyborate compound obtained by an evolutionary algorithm and Density Functional Theory",2017,"Journal of Magnetism and Magnetic Materials",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016977624&doi=10.1016%2fj.jmmm.2017.03.061&partnerID=40&md5=03e6056f4ae45c6514b9531a9fa7e8b4","New metastable phases in the Fe homometallic ludwigite compound are obtained and studied using an evolutionary algorithm and Density Functional Theory. Our lowest energy monoclinic structure is identified as P21/m with space group number of 11. This structure evolves towards the monoclinic structure as the result of the spin orbit coupling and a particular zigzag magnetic structure. A zigzag distortion in a class of three-leg ladders follows similar to the experimental one observed below the transition temperature of Tc = 283 K. In this distortion long and short bonds inside rungs alternating in a zigzag way along the ladder legs. Furthermore, a new type of zigzag structural ordering is observed in other two low-energy phases analyzed. In this case, the magnetic ordering behaves qualitatively similar to the experimental structure at 82 K, with antiferromagnetically coupled ferromagnetic rungs. Our calculations show that magnetic symmetry is not favorable for zigzag structural ordering. Finally, structural and magnetic properties will be discussed in comparison with the experimentally known phases. © 2017 Elsevier B.V.","Ab initio calculations (electronic structure of atoms and molecules); Heavy fermions; Magnetism and magnetic materials systems; Strongly correlated electron systems","C (programming language); Calculations; Electronic structure; Evolutionary algorithms; Magnetic materials; Magnetism; Metastable phases; Single crystals; Ab initio calculations; Antiferro-magnetically coupled; Heavy fermion; Monoclinic structures; Spin-orbit couplings; Strongly correlated electron system; Structural and magnetic properties; Structural ordering; Density functional theory",2-s2.0-85016977624
"Rahman M.A., Møller H.B., Saha C.K., Alam M.M., Wahid R., Feng L.","Optimal ratio for anaerobic co-digestion of poultry droppings and lignocellulosic-rich substrates for enhanced biogas production",2017,"Energy for Sustainable Development",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019147037&doi=10.1016%2fj.esd.2017.04.004&partnerID=40&md5=3b88d47148eae16d8ab8d41f6c7fc283","The poultry industry is a progressive and prospective agro-based sector in Bangladesh. Poultry droppings (PD) make an excellent and abundant raw material for anaerobic co-digestion (AD) because of its high nitrogen content. Two sets of comparative assays were conducted on the anaerobic co-digestion of PD with two lignocellulosic co-substrates (LCSs), namely wheat straw (WS) and meadow grass (MG), under five different mixing ratios to optimize substrate composition and C:N ratio for enhanced biogas production. All digesters were run simultaneously under a mesophilic temperature of 35 ± 1 °C with an identical volatile solids (VS) concentration. The results showed that the co-digestion of PD with LCSs was significantly higher in terms of biogas yield and bio-methane potential (BMP) than those obtained by mono-digestion of PD and LCSs. Co-digestion of PD and MG produced a higher cumulative biogas production, biogas yield and BMP than from respectively PD and WS. The highest methane contents found were 330.1 and 340.1 Nl kg− 1 VS after digestion for 90 days at a mixing ratio of, respectively, 70:30 (PD:WS) with a C:N ratio of 32.02 and a mixing ratio of 50:50 (PD:MG) with a C:N ratio of 31.52. The increases were 1.14 and 1.13 times those of the LCSs alone, respectively. Predicted optimum ratio for PD:LCSs and C:N ratios, maximum BMP and percentage volatile solids destruction (PVSD) were calculated by using software MINITAB-17 according to the best fit regression models for co-digestion of PD with LCSs. © 2017 International Energy Initiative","Anaerobic co-digestion; Biochemical methane potential; Meadow grass; Optimal ratio; Poultry droppings; Wheat straw","Biogas; C (programming language); Methane; Mixing; Regression analysis; Straw; Substrates; Anaerobic co-digestion; Biochemical methane potential; Meadow grass; Optimal ratio; Wheat straws; Anaerobic digestion; anaerobic digestion; biogas; cellulose; gas production; lignin; manure; meadow; methane; poultry; substrate; Triticum aestivum",2-s2.0-85019147037
"Szayer G., Kovács B., Tajti F., Korondi P.","Feasible utilization of the inherent characteristics of holonomic mobile robots",2017,"Robotics and Autonomous Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020288657&doi=10.1016%2fj.robot.2017.04.002&partnerID=40&md5=9a014f92fa6b23e61c99062dbed8b4fe","This paper presents a computationally inexpensive generic method to utilize the maximum velocity and acceleration of an omnidirectional mobile robot. The proposed method is based on the inverse kinematic and inverse dynamic models by defining novel velocity and acceleration reserve multipliers respectively. The defined multipliers enable a computationally inexpensive solution and give representative index numbers, showing the amount of utilized resources during online computation. The model was applied to control a kiwi drive mobile robot and validated by experimental measurements. An open-source Robot Operating System (ROS) catkin C++ package was published to enable the feasible implementation of the results. © 2017 Elsevier B.V.","Holonomic robot; Kiwi drive; Phase space; Robot Operating System; Wheel-slip","Birds; C++ (programming language); Fruits; Inverse kinematics; Mobile robots; Open systems; Phase space methods; Holonomic robots; Inherent characteristics; Inverse dynamic model; Omnidirectional mobile robot; Representative indices; Robot operating system; Robot operating systems (ROS); Wheel slips; Robots",2-s2.0-85020288657
"Springer P., Hammond J.R., Bientinesi P.","TTC: A high-performance Compiler for tensor transpositions",2017,"ACM Transactions on Mathematical Software",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028516429&doi=10.1145%2f3104988&partnerID=40&md5=49624fe511f833218ff1bc48b90a6d3f","We present Tensor Transpose Compiler (TTC), an open-source parallel compiler for multidimensional tensor transpositions. To generate high-performance C++ code, TTC explores a number of optimizations, including software prefetching, blocking, loop-reordering, and explicit vectorization. To evaluate the performance of multidimensional transpositions across a range of possible use-cases, we also release a benchmark covering arbitrary transpositions of up to six dimensions. Performance results showthat the routines generated by TTC achieve close to peak memory bandwidth on both the Intel Haswell and the AMD Steamroller architectures and yield significant performance gains over modern compilers. By implementing a set of pruning heuristics, TTC allows users to limit the number of potential solutions; this option is especially useful when dealing with high-dimensional tensors, as the search space might become prohibitively large. Experiments indicate that when only 100 potential solutions are considered, the resulting performance is about 99% of that achieved with exhaustive search. © 2017 ACM.","Domain-specific compiler; Highperformance computing; Multidimensional transpositions","Benchmarking; C++ (programming language); Computer software; Open source software; Program compilers; Domain specific; High-dimensional; High-performance computing; Memory bandwidths; Multidimensional transpositions; Parallel compilers; Performance Gain; Software prefetching; Tensors",2-s2.0-85028516429
"Aceto L., Fábregas I., García-Pérez A., Ingólfsdóttir A., Ortega-Mallén Y.","Rule formats for nominal process calculi",2017,"Leibniz International Proceedings in Informatics, LIPIcs",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030653868&doi=10.4230%2fLIPIcs.CONCUR.2017.10&partnerID=40&md5=911c062a83c2b01abd7e9727d3ea2760","The nominal transition systems (NTSs) of Parrow et al. describe the operational semantics of nominal process calculi. We study NTSs in terms of the nominal residual transition systems (NRTSs) that we introduce. We provide rule formats for the specifications of NRTSs that ensure that the associated NRTS is an NTS and apply them to the operational specification of the early pi-calculus. Our study stems from the recent Nominal SOS of Cimini et al. and from earlier works in nominal sets and nominal logic by Gabbay, Pitts and their collaborators. © Luca Aceto, Ignacio Fábregas, Álvaro García-Pérez, Anna Ingólfsdóttir, and Yolanda Ortega-Mallén.","Nominal sets; Nominal structural operational semantics; Nominal transition systems; Process algebra; Rule formats; Scope opening","Calculations; Computer programming languages; Semantics; Specifications; Nominal Sets; Process algebras; Rule formats; Scope opening; Structural operational semantics; Transition system; Pathology",2-s2.0-85030653868
"Afshinnia K., Rangaraju P.R.","Effect of fineness of high lime fly ash on pozzolanic reactivity and ASR mitigation",2017,"Computers and Concrete",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028776500&doi=10.12989%2fcac.2017.20.2.197&partnerID=40&md5=1bdde36ccf8d0a4ea36fc69d1505f8cd","Typically, high lime fly ash (Class C) has been characterized as a fly ash, which at lower replacement levels is not as effective as the low lime (Class F) fly ash, in mitigating alkali-silica reaction (ASR) in portland cement concrete. The influence of fineness of Class C, obtained by grinding virgin fly ash into finer particles, on its pozzolanic reactivity and ASR mitigation performance was investigated in this study. In order to assess the pozzolanic reactivity of mortar mixtures containing virgin or ground fly ashes, the strength activity index (SAI) test and thermo-gravimetric analysis (TGA) were conducted on the mortar cubes and paste samples, respectively, containing virgin fly ash or two ground fly ashes. In addition, to evaluate any improvement in the ASR mitigation of ground fly ashes compared to that of the virgin fly ash, the accelerated mortar bar test (AMBT) was conducted on the mortar mixtures containing different dosages of either virgin or ground fly ashes. In all tests crushed glass aggregate was used as a highly reactive aggregate. Results from this study showed that the finest fly ash (i.e., with an average particle size of 3.1 microns) could increase the flow ability along with the pozzolanic reactivity of the mortar mixture. However, results from this study suggested that the fineness of high lime fly ash does not seem to have any significant effect on ASR mitigation. Copyright © 2017 Techno-Press, Ltd.","ASR; Class C fly ash; Fineness; Mitigation; Pozzolanic reactivity","Aggregates; C (programming language); Gravimetric analysis; Lime; Mixtures; Mortar; Particle size; Portland cement; Thermogravimetric analysis; Alkali-silica reaction; Average particle size; Class C fly ashes; Fineness; Mitigation; Portland cement concretes; Pozzolanic reactivity; Strength activity index; Fly ash",2-s2.0-85028776500
"Wang A., Xu H., Zhou Q., Liu X., Li Z., Gao R., Liu X., Zhang L.","Electrochemical performances of a new solid composite polymer electrolyte based on hyperbranched star polymer and ionic liquid for lithium-ion batteries",2017,"Journal of Solid State Electrochemistry",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017270671&doi=10.1007%2fs10008-017-3582-7&partnerID=40&md5=73e4a1189a972e749d944843b2b1889d","A new composite polymer electrolyte membrane composed of hyperbranched star polymers (HBPS-(PMMA-b-PPEGMA)30 (the hyperbranched star polymer with hyperbranched polystyrene as core and polymethyl methacrylate block poly(ethylene glycol) methyl ether methacrylate) as arms)), ionic liquid (1-butyl-3-methylimidazolium tetrafluoroborate (BMImBF4) or 1-butyl-3-methylimidazolium hexafluorophosphate (BMImPF6)), and lithium bis(trifluoromethanesulfonyl) imide (LiTFSI) has been fabricated by solution casting method. This type of solid polymer electrolyte membrane shows an excellent flexibility, transparency, and free-standing properties. Room temperature ionic conductivity of composite electrolytes with 40 wt% BMImBF4 or 40 wt% BMImPF6 can reach 2.5 × 10−4 and 4.1 × 10−5 S cm−1, respectively. The HBPS-(PMMA-b-PPEGMA)30/BMImPF6/LiTFSI (the composite polymer electrolyte with 1-butyl-3-methylimidazolium hexafluorophosphate) composite polymer electrolyte displays better performances including a good thermal stability with decomposition temperature of 350 °C, a wide electrochemical window with oxidation potential of 4.3 V, and the excellent interfacial compatibility with lithium electrode. Moreover, the Li/LiFePO4 batteries based on HBPS-(PMMA-b-PPEGMA)30/BMImPF6/LiTFSI electrolyte retain about 96% of their highest discharge capacity (120.5 mAh g−1) after 100 cycles under a current density of 0.1 C at 60 °C, exhibiting the excellent reversible cyclability. [Figure not available: see fulltext.]. © 2017, Springer-Verlag Berlin Heidelberg.","Electrochemical property; High ionic conductivity; Hyperbranched star polymer; Ionic liquid; Solid composite polymer electrolyte","C (programming language); Dendrimers; Electric batteries; Electric discharges; Electrochemical properties; Electrolytes; Ionic conduction in solids; Ionic conductivity; Ionic liquids; Liquids; Lithium; Lithium alloys; Lithium compounds; Lithium-ion batteries; Polyethylene glycols; Polymers; Polymethyl methacrylates; Solid electrolytes; 1-Butyl-3-methyl-imidazolium hexafluorophosphate; 1-Butyl-3-methylimidazolium tetrafluoroborate; Bis(trifluoromethane sulfonyl)imide; Composite polymer electrolyte membranes; Poly(ethylene glycol) methyl ether methacrylate (PEG-MMA); Solid composites; Solid polymer electrolyte membranes; Star polymers; Polyelectrolytes",2-s2.0-85017270671
"Marsh M.P., Kruchowski J.N., Hara S.A., McIntosh M.B., Forsman R.M., Reed T.L., Kimble C., Lee K.H., Bennet K.E., Tomshine J.R.","Instrumentation for electrochemical performance characterization of neural electrodes",2017,"Review of Scientific Instruments",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026820750&doi=10.1063%2f1.4993796&partnerID=40&md5=aadd53f759f3e3d6036ddacb2e7b425c","In an effort to determine the chronic stability, sensitivity, and thus the potential viability of various neurochemical recording electrode designs and compositions, we have developed a custom device called the Voltammetry Instrument for Neurochemical Applications (VINA). Here, we describe the design of the VINA and initial testing of its functionality for prototype neurochemical sensing electrodes. The VINA consists of multiple electrode fixtures, a flowing electrolyte bath, associated reservoirs, peristaltic pump, voltage waveform generator, data acquisition hardware, and system software written in National Instrument's LabVIEW. The operation of VINA was demonstrated on a set of boron-doped diamond neurochemical recording electrodes, which were subjected to an applied waveform for a period of eighteen days. Each electrode's cyclic voltammograms (CVs) were recorded, and sensitivity calibration to dopamine (DA) was performed. Results showed an initial decline with subsequent stabilization in the CV current measured during the voltammetric sweep, corresponding closely with changes in electrode sensitivity to DA. The VINA has demonstrated itself as a useful tool for the characterization of electrode stability and chronic electrochemical performance. © 2017 Author(s).",,"Computer programming languages; Data acquisition; Electrodes; Electrolytes; Cyclic voltammograms; Data acquisition hardware; Electrochemical performance; Flowing electrolytes; Multiple electrodes; National Instruments; Recording electrodes; Sensitivity calibration; Electrochemical electrodes",2-s2.0-85026820750
"Bhattacharyya A., Gopi S., Tal A.","Lower bounds for 2-query LCCs over large alphabet",2017,"Leibniz International Proceedings in Informatics, LIPIcs",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028692096&doi=10.4230%2fLIPIcs.APPROX%2fRANDOM.2017.30&partnerID=40&md5=9493914536e9d752876bcb52c16b7ec1","A locally correctable code (LCC) is an error correcting code that allows correction of any arbitrary coordinate of a corrupted codeword by querying only a few coordinates. We show that any 2- query locally correctable code C : {0, 1}k ! -n that can correct a constant fraction of corrupted symbols must have n > exp(k/ log) under the assumption that the LCC is zero-error. We say that an LCC is zero-error if there exists a non-adaptive corrector algorithm that succeeds with probability 1 when the input is an uncorrupted codeword. All known constructions of LCCs are zero-error. Our result is tight upto constant factors in the exponent. The only previous lower bound on the length of 2-query LCCs over large alphabet was((k/ log |-|)2) due to Katz and Trevisan (STOC 2000). Our bound implies that zero-error LCCs cannot yield 2-server private information retrieval (PIR) schemes with sub-polynomial communication. Since there exists a 2-server PIR scheme with sub-polynomial communication (STOC 2015) based on a zero-error 2-query locally decodable code (LDC), we also obtain a separation between LDCs and LCCs over large alphabet. © Arnab Bhattacharyya, Sivakanth Gopi, and Avishay Tal.","Locally correctable code; Private information retrieval; Szemerédi regularity lemma","Approximation algorithms; Codes (symbols); Combinatorial optimization; Errors; Information retrieval; Optimization; Random processes; Constant factors; Error correcting code; Large alphabets; Locally correctable codes; Locally-decodable codes; Lower bounds; Private information retrieval; Regularity lemma; C (programming language)",2-s2.0-85028692096
"Mahmud M.A., Elumalai N.K., Upama M.B., Wang D., Puthen-Veettil B., Haque F., Wright M., Xu C., Pivrikas A., Uddin A.","Controlled Ostwald ripening mediated grain growth for smooth perovskite morphology and enhanced device performance",2017,"Solar Energy Materials and Solar Cells",6,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017318117&doi=10.1016%2fj.solmat.2017.03.034&partnerID=40&md5=91b1281ff6c7b0b145788ffd81dd83ac","Here we report, a novel two-step dipping technique via post-immersion polar solvent engineering for controlled secondary grain growth (Ostwald Ripening) to fabricate efficient mixed organic cation based MA0.6FA0.4PbI3 perovskite solar cell (PSC) in conjunction with low temperature (140 °C) processed sol-gel ZnO ETL for full process compatibility with flexible substrates. The reported MTD-SE method (stands for Modified Two Step Dipping - Solvent Engineering) limits the grain coarsening effect during post-immersion stage of two-step dipping method and provides substantially smooth perovskite surface morphology for enhanced charge transport properties compared to conventional two-step techniques by means of controlled Ostwald Ripening process. The grain coarsening process and concomitant irregular grain size distribution are judiciously controlled by increasing the chemical potential or free energy change (ΔG) of the system at the post-immersion. The photovoltaic performance and photo-current hysteresis phenomena of the reported MTD-SE PSC have been compared with PSCs fabricated with conventional two-step techniques, incorporating 2-Propanol or ethyl alcohol as dipping solvents. The enhanced device performance of MTD-SE PSCs is correlated with the conducive role of the evenly distributed grain boundaries in them, which act as carrier dissociation interfaces and carrier transport pathways to charge selective contacts for superior charge separation and extraction properties. Adding to the merits, MTD-SE PSCs also demonstrate significantly suppressed photo-current hysteretic behaviour which has been elucidated in the context of faster ion migration kinetics with the increased grain boundaries, which exhibit higher ionic diffusivity. The favourable ion migration kinetics with MTD-SE PSC have also been comprehensively analysed from the frequency-dependent capacitive spectra. © 2017 Elsevier B.V.","Charge transport; Controlled ostwald ripening; Low temperature; Mixed organic cation perovskite; ZnO ETL","C (programming language); Carrier transport; Cell engineering; Charge transfer; Contacts (fluid mechanics); Free energy; Grain boundaries; Grain size and shape; Hysteresis; Ostwald ripening; Perovskite; Perovskite solar cells; Positive ions; Process control; Sol-gel process; Sol-gels; Solar cells; Solvents; Temperature; Zinc oxide; Grain size distribution; Hysteretic behaviour; Low temperatures; Organic cations; Ostwald ripening process; Photovoltaic performance; Process compatibility; Secondary grain growth; Grain growth",2-s2.0-85017318117
"di Stasio S.","Soot with 1013 cm−3 high concentration and 25 Å radius of gyration as detected by small-angle X-ray scattering in a premixed ethylene-air flame at sooting threshold",2017,"Journal of Aerosol Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019387500&doi=10.1016%2fj.jaerosci.2017.05.003&partnerID=40&md5=f5327f573686e9683cd9ed4cdb8af1bc","SAXS experiments on a premixed ethylene-air flame burning at the so-called sooting threshold, i.e., a flame with Carbon-to-Oxygen molecular ratio between fuel C2H4 and air equal to [C]/[O] = 0.65 (ΦAir=25 cm3/min, ΦC2H4=11.7 cm3/min) is the object of this work. Measurements are performed at synchrotron SOLEIL / beamline SWING under the approved proposal #20130463. The height above burner considered for this case study is z=21 mm (τres about 10ms). The background is made by considering an identical lean flame with [C]/[O]=0.19. The data processing approach consisting in subtracting to the signal S, the X-ray scattering from the air molecules surrounding the flame as background BCKG, is here revealed to be incorrect, owing to the fact that sometimes the S-BCKG evaluated as above is a negative quantity. This is caused by the much higher cool gas molecule number density at ambient conditions (300 K) with respect to the lower gas molecule density inside the flame at hot temperatures (about 1800–2100 K). Vice versa, by using a lean flame one obtains as BCKG the scattering contribute from the gas molecules alone in the absence of soot at about the identical premixed flame under test, which results in appreciating even the low signal from ultrafine incipient soot nanoparticles. The main results from the fit of SAXS data at larger q's are two: first, the demonstration of ultrafine nanoparticles, with gyration radius Rg=25±10 Å, as inferred by the Guinier regime fit, and overall size D=45±10 Å, as evaluated through Kratky plots; second, the fact that these entities are present in the premixed flame with a huge concentration, about N=1013 cm−3. Such nanoparticles with D=45 Å (Rg=25 Å), do coexist contemporarily to isolated 20 nm primaries and 160 nm nanoparticle aggregates, which are observed with a number concentrations 6 and 8 order of magnitudes smaller with respect to the one of ultrafine nanoparticles. Our SAXS results do accord very well previous findings on size of premixed flame soot nanoparticles reported both by Wersborg et al. (1973) from molecular beam sampling and TEM analysis and, with concern to the number concentration, the results by Minutolo et al. (1998) and Sgro et al. (2009). © 2017 Elsevier Ltd","Carbon; Combustion Aerosols; Soot nanoparticles; Synchrotron SAXS","Aluminum; C (programming language); Carbon; Data handling; Density of gases; Dust; Ethylene; Molecular beams; Molecular oxygen; Molecules; Nanoparticles; Soot; X ray scattering; Ambient conditions; Combustion aerosols; Molecular beam sampling; Nanoparticle aggregate; Number concentration; Processing approach; Synchrotron saxs; Ultra-fine nanoparticles; Combustion; carbon; ethylene; fuel; nanoparticle; oxygen; aerosol; carbon; combustion; concentration (composition); data processing; detection method; ethylene; experimental study; machinery; nanoparticle; oxygen; particle size; scattering; soot; temperature; threshold; X-ray; absorption; air analysis; ambient air; analytical parameters; Article; case study; combustion; concentration (parameters); data processing; density; dielectric constant; flame; gas; gyration radius; heat; light intensity; molecular weight; molecule; particle size; priority journal; refraction index; soot; synchrotron radiation; X ray crystallography",2-s2.0-85019387500
"Dubbeldam R., Baten C., Buurke J.H., Rietman J.S.","SOFIE, a bicycle that supports older cyclists?",2017,"Accident Analysis and Prevention",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008715962&doi=10.1016%2fj.aap.2016.09.006&partnerID=40&md5=fc749bda5a193d33711cef5e7f9bafee","Older cyclists remain at high risk of sustaining an injury after a fall with their bicycle. A growing awareness for the need and possibilities to support safety of older cyclists has been leading to bicycle design ideas. However, the effectiveness and acceptance of such designs has not been studied yet. This study aims to analyse the effect of 3 support systems: an automatic adjustable saddle height, optimised frame and wheel geometry and drive-off assistance. The support systems are integrated on the SOFIE bicycle, a prototype bicycle designed to support older cyclists during (dis-)mounting and at lower cycling speeds. Nine older cyclists (65–80 years) were asked to cycle on a ‘normal’ and on the ‘SOFIE’ bicycle. They cycled on a parking lot to avoid interaction with traffic. The following tasks were analysed: cycling at comfortable and low speed avoiding an obstacle and (dis-)mounting the bicycle. Bicycle and cyclist motions were recorded with 10 Inertial Measurement Units and by 2 video cameras. FUSION software (LABVIEW) was used to assess kinematic parameters. First, a subjective analysis of the different cycling tasks was made, supported by video analysis. Second, differences in cyclist and bicycle kinematic parameters between the normal and SOFIE bicycle were studied for the various cycling tasks. The SOFIE bicycle was experienced as a ‘supportive’ and comfortable bicycle and objectively performed ‘safer’ on various cycling tasks. For example: The optimised frame geometry with low step-in enabled a faster (dis-)mounting time and less sternum roll angle and angular acceleration. The adjustable saddle height enabled the participants to keep both feet on the ground till they started cycling with the ‘drive-off’ support. The latter reduces steering activity: maximum steer angle and angular acceleration. During sudden obstacle avoidance, less upper body and thigh accelerations are recorded. In conclusion, the SOFIE bicycle was able to support older cyclists during various cycling tasks and may reduce fall risk. © 2016 Elsevier Ltd","Cycling kinematics; Cycling safety; Mounting and dismounting; Older cyclists","Bicycles; Computer programming languages; Kinematics; Mountings; Safety engineering; Units of measurement; Video cameras; Angular acceleration; Inertial measurement unit; Kinematic parameters; Older cyclists; Parking lots; Subjective analysis; Support systems; Video analysis; Sporting goods",2-s2.0-85008715962
"Paneta V., Fluch U., Petersson P., Ott S., Primetzhofer D.","Characterization of compositional modifications in metal-organic frameworks using carbon and alpha particle microbeams",2017,"Nuclear Instruments and Methods in Physics Research, Section B: Beam Interactions with Materials and Atoms",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014114440&doi=10.1016%2fj.nimb.2017.01.058&partnerID=40&md5=cf43908c85036af5d8c414002783394c","Zirconium-oxide based metal-organic frameworks (MOFs) were grown on p-type Si wafers. A modified linker molecule containing iodine was introduced by post synthetic exchange (PSE). Samples have been studied using Rutherford Backscattering Spectrometry (RBS) and Particle Induced X-ray Emission (PIXE) techniques, employing the 5 MV 15SDH-2 Pelletron Tandem accelerator at the Ångström laboratory. The degree of post synthetic uptake of the iodine-containing linker has been investigated with both a broad beam and a focused beam of carbon and alpha particles targeting different kind of MOF crystals which were of ∼1–10 μm in size, depending on the linker used. Iodine concentrations in MOF crystallites were also measured by Nuclear Magnetic Resonance Spectroscopy (NMR) and are compared to the RBS results. In parallel to the ion beam studies, samples were investigated by Scanning Electron Microscopy (SEM) to quantify possible crystallite clustering, develop optimum sample preparation routines and to characterize the potential ion beam induced sample damage and its dependence on different parameters. Based on these results the reliability and accuracy of ion beam data is assessed. © 2017 Elsevier B.V.","Metal-organic frameworks; Rutherford Backscattering Spectrometry","Alpha particles; Backscattering; Crystalline materials; Crystallites; Iodine; Ions; Java programming language; Magnetic resonance spectroscopy; Nuclear magnetic resonance spectroscopy; Organic carbon; Organometallics; Rutherford backscattering spectroscopy; Scanning electron microscopy; Silicon wafers; Spectrometry; Compositional modification; Iodine concentration; Metal organic framework; Metalorganic frameworks (MOFs); Particle induced X-ray emission; Rutherford back-scattering spectrometry; Sample preparation; Tandem accelerators; Ion beams",2-s2.0-85014114440
"Lin J., Song Z., Wei M., Chi B.","A 6.6 mW 1.25–2.25 GHz low phase noise PLL frequency synthesizer based on wide tuning range Class-C VCO",2017,"Microelectronics Journal",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021400547&doi=10.1016%2fj.mejo.2017.06.007&partnerID=40&md5=97d807c07275955ac31ecce6d033ecd7","A wide tuning range low phase noise phase-locked loop (PLL) frequency synthesizer based on Class-C voltage-controlled oscillator (VCO) for IEEE 802.11ah is presented. Feedback loop technique is adopted to provide dynamic gate bias to the core transistors of the Class-C VCO, guaranteeing robust start-up against process, voltage and temperature (PVT) variations. Automatic frequency control (AFC) algorithm with tail bias switching scheme is proposed to guarantee start-up condition and maintain optimum oscillation amplitude across the whole tuning range, avoiding the deterioration of figure-of-merit (FoM). Implemented in 65-nm CMOS, the presented frequency synthesizer prototype achieves a tuning range of 57%, from 1.25 GHz to 2.25 GHz. Drawing 5.5 mA current from a 1.2-V power supply, the prototype demonstrates −127.8 dBc/Hz phase noise at 1-MHz offset and −94.6 dBc/Hz in-band phase noise from a carrier of 1.536 GHz. With the proposed dynamic gate bias technique and AFC-assisted tail bias switching scheme, the wide tuning range Class-C VCO exhibits a peak FoM of 187.5 dBc/Hz, with only 2.5 dB variation across the whole tuning range. © 2017 Elsevier Ltd","Class-C voltage-controlled oscillator (VCO); CMOS; Frequency synthesizer; IEEE 802.11ah; Low phase noise; Phase-locked loop (PLL); Wide tuning range","Bias voltage; C (programming language); CMOS integrated circuits; Frequency synthesizers; Gates (transistor); Locks (fasteners); Oscillistors; Phase locked loops; Standards; Variable frequency oscillators; Automatic frequency control; IEEE 802.11ah; Low phase noise; Oscillation amplitude; Phase Locked Loop (PLL); PLL frequency synthesizer; Process , voltage and temperatures; Wide tuning range; Phase noise",2-s2.0-85021400547
"Gale F., Baker T.","Conceptualising ‘code complexes’: A case study of harvesting-related codes applying to forest operations in Tasmania, Australia",2017,"Forest Policy and Economics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019414624&doi=10.1016%2fj.forpol.2017.05.002&partnerID=40&md5=643e9fe1501067feeddf9ad82953a246","In the past 20 years, a proliferation of governance instruments has been developed by both state and non-state actors. Today, many industrial sectors are governed by a variety of overlapping instruments that are usually analysed separately rather than as a collective. In this paper, we make the case for analysing such codes as a collective, given that is how they are experienced from the perspective of users and how, ultimately, they achieve their governance objectives. Drawing on an exhaustive database of all related governance instruments, we present an overview of the Tasmanian forestry code complex with regard to harvesting-related forest operations, highlighting how public and private instruments relate to each other and intersect. Three key findings from the study are (a) the critical importance of Tasmania's Forest Practices Code as a master code, which sits at the centre of the State's Forest Code Complex with regard to harvesting; (b) the role that company management plans play in mediating between Tasmanian and international codes such as those endorsed by the Programme for the Endorsement of Forest Certification and the Forest Stewardship Council; and (c) the utility of the code complex concept for comparative analyses of resource management. © 2017 Elsevier B.V.",,"Codes (symbols); Forestry; Harvesting; Company management; Comparative analysis; Forest Certification; Forest stewardship councils; Industrial sector; International codes; Resource management; Tasmania , Australia; C (programming language)",2-s2.0-85019414624
"Djordjevic I.B.","OAM-Based Hybrid Free-Space Optical-Terahertz Multidimensional Coded Modulation and Physical-Layer Security",2017,"IEEE Photonics Journal",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023191246&doi=10.1109%2fJPHOT.2017.2724563&partnerID=40&md5=e74f6447f82f47de20cd6cb020402b69","To address capacity constraints and physical-layer security (PLS), defined in information-theoretic sense, of both optical and wireless networks in a simultaneous manner, we propose to use the hybrid free-space optical (FSO)-THz technologies employing orbital angular momentum (OAM) modes in both FSO and THz subsystems. The OAM modes, related to azimuthal dependence of the wavefront, are mutually orthogonal so that this additional degree of freedom can be utilized to improve both spectral efficiency and PLS in both optical and wireless networks. Spatial light modulators (SLMs) are routinely used to generate OAM modes in optical domain, in particular in FSO communications links. On the other hand, it has been recently demonstrated that a traveling-wave circular loop antenna, with azimuthal phase distribution along the loop, can be used to generate OAM in the RF domain. Reliability of FSO links is affected by atmospheric turbulence effects, scattering effects, and low-visibility in foggy conditions. On the other hand, RF technologies are not affected by these effects, but are sensitive to rain and snow. In particular, THz technologies, have available bandwidths comparable to a typical wavelength channel in WDM systems. Based on this complementarity, here we propose to use hybrid FSO-THz technologies to significantly improve the spectral efficiency and PLS of both FSO and wireless communications systems and networks. © 2009-2012 IEEE.","atmospheric turbulence; free-space optical (FSO) communication; hybrid FSO-terahertz technology; multidimensional coded modulation; multipath fading.; orbital angular momentum (OAM); Physical-layer security","Angular momentum; Atmospheric thermodynamics; Atmospheric turbulence; Bandwidth; Efficiency; Light modulators; Loop antennas; Modula (programming language); Modulation; Multipath fading; Optical signal processing; Traveling wave antennas; Wireless networks; Wireless telecommunication systems; Coded modulation; Free-space optical; Orbital angular momentum; Physical layer security; Terahertz technology; Network security",2-s2.0-85023191246
"Chang S.-I., Park S.-Y., Yoon E.","Low-power low-noise pseudo-open-loop preamplifier for neural interfaces",2017,"IEEE Sensors Journal",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021832822&doi=10.1109%2fJSEN.2017.2717787&partnerID=40&md5=74e2f9082cf6d4586a54a3256d58a8eb","In this paper, we present a low-power, low-noise fully differential pseudo-open-loop preamplifier with programmable bandwidth for monitoring neural activities. The proposed pseudo-open-loop topology can achieve high-power-noise efficiency as well as high linearity and precise gain control over process. The proposed fully differential preamplifier can balance the common mode of the differential outputs without a common-mode feedback circuit, and bias the ac-coupled input transistors without an external reference. A current-ratio gain design can set a stable gain over process and bias current variations. A programmable embedded gm-C low-pass filter (LPF) can be tuned by adjusting bias current, so that the proposed preamplifier can be configured to be used in recording single neuron spikes or field potentials (EEG, ECoG). The proposed amplifier is configured to consume 400 nA at 2.5-V power supply; the total chip area is 0.189 mm2. The measured thermal noise floor is 85 nV/ √ Hz and input-referred noise is 1.69μ Vrms from 0.3 Hz to 1 kHz when using a chopper stabilization technique to suppress 1/f noise. The fabricated preamplifier shows a noise efficiency factor of 2.43 in the fully differential topology. © 2001-2012 IEEE.","action potential; brain-machine (computer) interface; ECoG; EEG; fully-differential; local field potential; low-noise; low-power; neural amplifier; Neural interface; noise efficiency factor; pseudo-open-loop; weak inversion","Bandwidth; Brain; C (programming language); Chopper amplifiers; Efficiency; Electric fields; Electric potential; Electric power systems; Electroencephalography; Electrophysiology; Integrated circuits; Low pass filters; Low power electronics; Thermal noise; Topology; Transistors; Action potentials; ECoG; Fully differential; Local field potentials; Low noise; Low Power; Neural interfaces; Noise efficiency factors; Open-loop; Weak inversions; Amplifiers (electronic)",2-s2.0-85021832822
"De Lozzo M., Marrel A.","Sensitivity analysis with dependence and variance-based measures for spatio-temporal numerical simulators",2017,"Stochastic Environmental Research and Risk Assessment",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978028203&doi=10.1007%2fs00477-016-1245-3&partnerID=40&md5=71abf84163de29e7e362331ae76669d2","In a case of radioactive release in the environment, modeling the radionuclide atmospheric dispersion is particularly useful for emergency response procedures and risk assessment. For this, the CEA has developed a numerical simulator, called Ceres-Mithra, to predict spatial maps of radionuclide concentrations at different instants. This computer code depends on many uncertain scalar and temporal parameters, describing the radionuclide, release or weather characteristics. The purpose is to detect the input parameters the uncertainties of which highly affect the predicted concentrations and to quantify their influences. To this end, we present various measures for the sensitivity analysis of a spatial model. Some of them lead to as many analyses as spatial locations (site sensitivity indices) while others consider a single one, with respect to the whole spatial domain (block sensitivity indices). For both categories, variance-based and dependence measures are considered, based on recent literature. All of these sensitivity measures are applied to the C-M computer code and compared to each other, showing the complementarity of block and site sensitivity analyses. Finally, a sensitivity analysis summarizing the input uncertainty contribution over the entirety of the spatio-temporal domain is proposed. © 2016, Springer-Verlag Berlin Heidelberg.","Dependence measures; Gaussian process metamodel; Global sensitivity analysis; Site & block sensitivity measures; Sobol’ indices; Spatio-temporal models","Atmospheric movements; C (programming language); Motion estimation; Radioisotopes; Risk assessment; Spatial variables measurement; Uncertainty analysis; Block sensitivity; Dependence measures; Gaussian Processes; Global sensitivity analysis; Spatio-temporal models; Sensitivity analysis; computer simulation; Gaussian method; radionuclide; risk assessment; sensitivity analysis; spatiotemporal analysis; Ceres",2-s2.0-84978028203
"Liu P., Ptacek C.J., Blowes D.W., Finfrock Y.Z.","A beam path-based method for attenuation correction of confocal micro-X-ray fluorescence imaging data",2017,"Journal of Analytical Atomic Spectrometry",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026867505&doi=10.1039%2fc7ja00148g&partnerID=40&md5=295ef44313753ffc38a3b80de57ee281","Confocal micro-X-ray fluorescence imaging (C-μXRF-I), an emerging X-ray spectroscopy technique for collecting X-ray fluorescence (XRF) data within intact objects, is beginning to see widespread use in many fields of study. However, the XRF intensity is attenuated during data collection, and corrections are required prior to data interpretation. A beam path (pixel)-based correction method is presented that takes into account heterogeneity of a sample and C-μXRF-I setup geometry. The sample heterogeneity is addressed by assuming the mass distribution of an element is the same as the XRF intensity distribution of the element in each pixel. The beam path in each pixel is calculated using the C-μXRF-I step size and geometry. The Beer-Lambert law is then applied to correct the attenuated XRF. The XRF intensity used to calculate the mass distribution is updated iteratively using values from the previous step, until the difference in intensity between the previous and current step is less than a threshold value. This correction method was verified using two distinct standard reference materials (NIST SRM 1834 and 611), and was then applied to imaging of fresh and aged switchgrass biochars. The corrected intensity of SRM 1834 indicates most elements were distributed homogeneously, but the distribution of some trace elements was more heterogeneous (P < 0.05). The corrected intensities of SRM 611 indicate all the elements are homogeneously distributed. The difference between the raw and corrected intensities for the biochar samples was not as pronounced as for standard reference materials due to a lower density and fewer high Z elements. © 2017 The Royal Society of Chemistry.",,"Electromagnetic wave attenuation; Fluorescence; Iterative methods; Pixels; Trace elements; X ray spectroscopy; Attenuation correction; Correction method; Data interpretation; Intensity distribution; Mass distribution; Micro X-ray fluorescence; Standard reference material; X ray fluorescence; C (programming language)",2-s2.0-85026867505
"Limasset A., Rizk G., Chikhi R., Peterlongo P.","Fast and scalable minimal perfect hashing for massive key sets",2017,"Leibniz International Proceedings in Informatics, LIPIcs",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028774755&doi=10.4230%2fLIPIcs.SEA.2017.25&partnerID=40&md5=94a707c55201e871d0968c7a877b7dd0","Minimal perfect hash functions provide space-efficient and collision-free hashing on static sets. Existing algorithms and implementations that build such functions have practical limitations on the number of input elements they can process, due to high construction time, RAM or external memory usage. We revisit a simple algorithm and show that it is highly competitive with the state of the art, especially in terms of construction time and memory usage. We provide a parallel C++ implementation called BBhash. It is capable of creating a minimal perfect hash function of 1010 elements in less than 7 minutes using 8 threads and 5 GB of memory, and the resulting function uses 3.7 bits/element. To the best of our knowledge, this is also the first implementation that has been successfully tested on an input of cardinality 1012. Source code: https://github.com/rizkg/BBHash. © Antoine Limasset, Guillaume Rizk, Rayan Chikhi, and Pierre Peterlongo.","Algorithms; Big data; Data structures; Minimal perfect hash functions","Algorithms; C++ (programming language); Data structures; Hash functions; Random access storage; Collision-free; Construction time; External memory; Minimal perfect hashes; Minimal perfect hashing; SIMPLE algorithm; Space efficient; State of the art; Big data",2-s2.0-85028774755
"Celentano L.","Design of a pseudo-PD or PI robust controller to track C2 trajectories for a class of uncertain nonlinear MIMO systems",2017,"Journal of the Franklin Institute",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020264480&doi=10.1016%2fj.jfranklin.2017.05.019&partnerID=40&md5=ed9d4e684e63697f4e03a8b12029b8f3","In this paper, some theorems are stated, which allow to design robust control laws without chattering, of type PD or PI, for uncertain nonlinear MIMO systems having a quite general structure, to track sufficiently regular trajectories with preassigned maximum error. The proposed control laws are easy to design and implement, above all for the robotic systems, because these laws can also be decentralized and they are based on two design parameters: the first related to the maximum eigenvalue of the inertia matrix from which the practical stability depends on, and the second related to the practical region of asymptotic stability (RAS), to the precision of the tracking error and to the convergence velocity of the tracking error to the desired neighborhood. If the trajectories to track are not sufficiently regular, suitable filtering laws are proposed for these trajectories, so as to facilitate the implementation of the controller and reduce the control action especially during the transient phase. Three significant examples of application in the terrestrial, sea transportation and robotic areas, well showing the simplicity of design and implementation of the controllers and their effectiveness, are reported. © 2017 The Franklin Institute",,"Asymptotic stability; C (programming language); Control theory; Eigenvalues and eigenfunctions; Errors; MIMO systems; Robotics; Robust control; Trajectories; Convergence velocity; Design and implementations; Design and implements; General structures; Nonlinear MIMO systems; Practical stability; Robust controllers; Sea transportation; Controllers",2-s2.0-85020264480
"Alizadeh A., Yaghoobi M., Medi A.","Class-J2 Power Amplifiers",2017,"IEEE Transactions on Circuits and Systems I: Regular Papers",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017121848&doi=10.1109%2fTCSI.2017.2683067&partnerID=40&md5=c95922ab5581b77c3fac6fa6d6146142","This paper presents the theoretical introduction and experimental validation of the ""Class-J2 Mode Power Amplifier,"" which provides higher efficiency and output power compared with conventional class-J mode counterpart. This mode of operation is realized by injection of the second-harmonic current to drain node of a class-J power amplifier (PA) to reduce the 45° phase shift between drain current and voltage signals. Similar to class-J PAs, the second-harmonic impedance of class-J2 PAs is purely reactive to simplify the design of the output matching network. The auxiliary second-harmonic injection circuit comprises a transistor biased in class-B mode followed by a class-C biased amplifier to achieve high second-harmonic current conversion efficiency. Theoretical formulations suggest that a 5% improvement in drain efficiency (ηD) as well as a 1.5-dB increase in output power can be achieved for the class-J2 mode in comparison with the typical class-J operation. To check the accuracy of theoretical predictions, a proof-of-concept 1-GHz class-J2 PA with 12.2-dBm output power and 43% PAE is implemented in a 0.18-μm CMOS technology. For better comparison, a 1-GHz class-J PA with the same transistor size and bias condition as the class-J2 PA is also fabricated. The output power and PAE of the reference class-J PA are 11.4 dBm and 40.6%, respectively, which are in agreement with theoretical predictions. © 2017 IEEE.","Class-J; CMOS integrated circuits; harmonic-injection power amplifiers; high-efficiency power amplifiers; reduced conduction angle (RCA); wideband power amplifiers","Amplifiers (electronic); Drain current; Efficiency; Harmonic analysis; Phase shift; Power amplifiers; Drain efficiency; Experimental validations; Higher efficiency; Mode of operations; Output matching network; Proof of concept; Second harmonics; Theoretical formulation; C (programming language)",2-s2.0-85017121848
"Sun X., Han C., Chen P.","Precise real-time navigation of LEO satellites using a single-frequency GPS receiver and ultra-rapid ephemerides",2017,"Aerospace Science and Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018486864&doi=10.1016%2fj.ast.2017.04.006&partnerID=40&md5=815f4ff67b28aff9273d0bb2c647154d","Precise (sub-meter level) real-time navigation using a space-capable single-frequency global positioning system (GPS) receiver and ultra-rapid (real-time) ephemerides from the international global navigation satellite systems service is proposed for low-Earth-orbiting (LEO) satellites. The C/A code and L1 carrier phase measurements are combined and single-differenced to eliminate first-order ionospheric effects and receiver clock offsets. A random-walk process is employed to model the phase ambiguities in order to absorb the time-varying and satellite-specific higher-order measurement errors as well as the GPS clock correction errors. A sequential Kalman filter which incorporates the known orbital dynamic model is developed to estimate orbital states and phase ambiguities without matrix inversion. Real flight data from the single-frequency GPS receiver onboard China's SJ-9A small satellite are processed to evaluate the orbit determination accuracy. Statistics from internal orbit assessments indicate that three-dimensional accuracies better than 0.50 m and 0.55 mm/s are achieved for position and velocity, respectively. © 2017","LEO; Precise real-time navigation; Sequential Kalman filter; Single-frequency GPS receiver; Ultra-rapid ephemerides","C (programming language); Clocks; Earth (planet); Kalman filters; Navigation; Navigation systems; Orbits; Phase measurement; Random errors; Real time systems; Satellites; Tracking (position); Carrier-phase measurement; Dimensional accuracy; Global Navigation Satellite Systems; Global positioning system receivers; GPS receivers; Low earth orbiting satellites; Real-time navigation; Ultra-rapid ephemerides; Global positioning system",2-s2.0-85018486864
"Sliwa K., Downes D.","PdBI U/LIRG Survey (PULS): Dense molecular gas in Arp 220 and NGC 6240",2017,"Astronomy and Astrophysics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026325057&doi=10.1051%2f0004-6361%2f201630139&partnerID=40&md5=f05ee080611b61260c680c81b08da9e8","Aims. We present new IRAM Plateau de Bure Interferometer observations of Arp 220 in HCN, HCO+, HN13C J = 1-0, C2H N = 1-0, SiO J = 2-1, HNCO Jk,k′ = 50,4-40,4, CH3CN(6-5), CS J = 2-1 and 5-4 and 13CO J = 1-0 and 2-1 and of NGC 6240 in HCN, HCO+J = 1-0 and C2H N = 1-0. In addition, we present Atacama Large Millimeter/submill-meter Array science verification observations of Arp 220 in CS J = 4-3 and CH3CN(10-9). Various lines are used to analyse the physical conditions of the molecular gas including the [12CO]/[13CO] and [12CO]/[C18O] abundance ratios. These observations will be made available to the public. Methods. We create brightness temperature line ratio maps to present the different physical conditions across Arp 220 and NGC 6240. In addition, we use the radiative transfer code RADEX and a Monte Carlo Markov chain likelihood code to model the 12CO, 13CO and C18O lines of Arp 220 at ~2′′ (~700 pc) scales, where the 12CO and C18O measurements were obtained from literature. Results. Line ratios of optically thick lines such as 12CO show smoothly varying ratios while the line ratios of optically thin lines such as 13CO show a east-west gradient across Arp 220. The HCN/HCO+ line ratio differs between Arp 220 and NGC 6240, where Arp 220 has line ratios above 2 and NGC 6240 below 1. The radiative transfer analysis solution is consistent with a warm (~40 K), moderately dense (~103.4 cm-3) molecular gas component averaged over the two nuclei. We find [12CO]/[13CO] and [12CO]/[C18O] abundance ratios of ~90 for both. The abundance enhancement of C18O can be explained by stellar nucleosynthesis enrichment of the interstellar medium. © 2017 ESO.","Galaxies: Abundances; Galaxies: ISM; Galaxies: Starburst; ISM: Molecules","Chemical elements; Galaxies; Markov processes; Molecules; Radiative transfer; Stars; Brightness temperatures; Galaxies: abundances; Galaxies: ISM; Galaxies: starbursts; ISM: molecules; Monte Carlo Markov chain; Radiative transfer codes; Stellar nucleosynthesis; C (programming language)",2-s2.0-85026325057
"Balasubramani N.","Shape preserving rational cubic fractal interpolation function",2017,"Journal of Computational and Applied Mathematics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011365868&doi=10.1016%2fj.cam.2017.01.014&partnerID=40&md5=f428180efad973647ae880f6f5578b34","A new type of C1 Fractal Interpolation Function (FIF) is developed using the Iterated Function System (IFS) which contains the rational spline. The numerator of this rational spline contains cubic polynomial and the denominator of the rational spline contains quadratic polynomial. We find uniform error bound between the original function which belongs to the class C2 and the FIF. We described suitable conditions on scaling factors and shape parameters such that they preserve the shape properties which are inherited in the data. © 2017 Elsevier B.V.","Convexity; Fractal interpolation function; Iterated function system; Monotonicity; Positivity","C (programming language); Computational mechanics; Constraint theory; Fractals; Interpolation; Convexity; Fractal interpolation functions; Iterated function system; Monotonicity; Positivity; Rational functions",2-s2.0-85011365868
"Kanwal J., Smith K., Culbertson J., Kirby S.","Zipf's Law of Abbreviation and the Principle of Least Effort: Language users optimise a miniature lexicon for efficient communication",2017,"Cognition",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018417933&doi=10.1016%2fj.cognition.2017.05.001&partnerID=40&md5=f43b7f44c43b540e46840335e344000a","The linguist George Kingsley Zipf made a now classic observation about the relationship between a word's length and its frequency; the more frequent a word is, the shorter it tends to be. He claimed that this “Law of Abbreviation” is a universal structural property of language. The Law of Abbreviation has since been documented in a wide range of human languages, and extended to animal communication systems and even computer programming languages. Zipf hypothesised that this universal design feature arises as a result of individuals optimising form-meaning mappings under competing pressures to communicate accurately but also efficiently—his famous Principle of Least Effort. In this study, we use a miniature artificial language learning paradigm to provide direct experimental evidence for this explanatory hypothesis. We show that language users optimise form-meaning mappings only when pressures for accuracy and efficiency both operate during a communicative task, supporting Zipf's conjecture that the Principle of Least Effort can explain this universal feature of word length distributions. © 2017 Elsevier B.V.","Artificial language learning; Efficient communication; Information theory; Language universals; Principle of Least Effort; Zipf's Law of Abbreviation","accuracy; adult; aged; ambiguity; animal communication; Article; female; human; interpersonal communication; language; language development; major clinical study; male; nomenclature; pressure; principle of least effort; priority journal; software; Zipfs law of abbreviation",2-s2.0-85018417933
"Chen Z., Liu Z., Sun K., Wu B.","Measurement error analysis and experimental verification of hybrid simulation testing method for reduced scale model",2017,"Jianzhu Jiegou Xuebao/Journal of Building Structures",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031822818&doi=10.14006%2fj.jzjgxb.2017.08.018&partnerID=40&md5=19d096e60a2de076befe3b923ab2a4d1","Based on the presented hybrid simulation testing method for the reduced scale model, the numerical simulation of the measurement error, which is simulated by the random number of the normal distribution, on both the shear model and the bending-shear model have been finished by using the multi-language programming technology with MATLAB and OpenSEES. The measurement error used in the numerical simulation analysis, which meets the code of JGJ/T 101-2015 'Specification of testing methods for earthquake resistant building', is obtained from the normal distribution random number by using the Matlab. The numerical simulation results demonstrate that the errors from the 1/2 and 1/4 reduced scale model are basically equivalent with the ones from the full-scale model in both the relative error of the peak point and the accumulated error. With the reduced-scale more than 1/4, the accumulated errors increase with the increase of the peak ground acceleration. Meanwhile, the accumulated errors decrease with the increase of beam column linear stiffness ratio under the same peak ground acceleration. The hybrid simulation test of the 1/2 reduced-scale steel frame structure was completed in the laboratory, and the accuracy and feasibility of the hybrid simulation testing method are verified by the test results. © 2017, Editorial Office of Journal of Building Structures. All right reserved.","Error analysis; Hybrid programming; Hybrid simulation; Numerical simulation; Scale model","Computer simulation; Computer simulation languages; Earthquake engineering; Error analysis; Errors; MATLAB; Measurement errors; Normal distribution; Numerical methods; Steel testing; Structural frames; Earthquake-resistant buildings; Experimental verification; Hybrid programming; Hybrid simulation; Numerical simulation analysis; Peak ground acceleration; Programming technology; Scale modeling; Numerical models",2-s2.0-85031822818
"Zou Y., Kiviniemi A., Jones S.W.","Retrieving similar cases for construction project risk management using Natural Language Processing techniques",2017,"Automation in Construction",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017507109&doi=10.1016%2fj.autcon.2017.04.003&partnerID=40&md5=446131498d9575ff3d41c9d8a92460e7","Case-based reasoning (CBR) is an important approach in construction project risk management. It emphasises that previous knowledge and experience of accidents and risks are highly valuable and could contribute to avoiding similar risks in new situations. In the CBR cycle, retrieving useful information is the first and the most important step. To facilitate the CBR for practical use, some researchers and organisations have established construction accident databases and their size is growing. However, as those documents are written in everyday language using different ways of expression, how information in similar cases is retrieved quickly and accurately from the database is still a huge challenge. In order to improve the efficiency and performance of risk case retrieval, this paper proposes an approach of combining the use of two Natural Language Processing (NLP) techniques, i.e. Vector Space Model (VSM) and semantic query expansion, and outlines a framework for this Risk Case Retrieval System. A prototype system is developed using the Python programming language to support the implementation of the proposed method. Preliminary test results show that the proposed system is capable of retrieving similar cases automatically and returning, for example, the top 10 similar cases. © 2017 Elsevier B.V.","Case retrieval; Case-based reasoning (CBR); Natural Language Processing (NLP); Query expansion; Risk management; Vector Space Model (VSM)","Accidents; Case based reasoning; Project management; Query processing; Risk management; Semantics; Vector spaces; Case retrieval; Casebased reasonings (CBR); NAtural language processing; Query expansion; Vector space models; Natural language processing systems",2-s2.0-85017507109
"Yoo Y., Lee J.","Vibration analysis and parameter design of two degree of freedom system using modelica",2017,"Transactions of the Korean Society of Mechanical Engineers, A",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029208177&doi=10.3795%2fKSME-A.2017.41.8.791&partnerID=40&md5=64367e519095ef96a0489fffae18176f","Today, we are using computer simulations in various engineering disciplines to reduce the time and cost of product development. The scope of simulations is increasingly complex and diverse for different fields such as mechanical, electrical, thermal, and fluid. Thus, it is necessary to use integrated simulations. In order to overcome these problems, a language has been developed to effectively describe and implement simulations is Modelica. To model and simulate a system, physical models can be broadly divided into causal and acausal models. The most important feature of Modelica is acausal programming. In this study, we will introduce simple concepts and explain about the usage of Modelica. Furthermore, we will explain the vibration analysis of a two degree-of-freedom system and the design of appropriate parameters by using Modelica. © 2017 The Korean Society of Mechanical Engineers.","Acausal programming; Modelica; Parameter design; Simulation language; Vibration analysis","Computer simulation languages; Cost engineering; Degrees of freedom (mechanics); Engineering disciplines; Important features; Integrated simulations; Modelica; Parameter designs; Physical model; Two-degree-of-freedom system; Vibration analysis",2-s2.0-85029208177
"Vieira C., Magana A.J., Falk M.L., Garcia R.E.","Writing in-code comments to self-explain in computational science and engineering education",2017,"ACM Transactions on Computing Education",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028596882&doi=10.1145%2f3058751&partnerID=40&md5=fc5b3884ae53e141adf5767238dea4f4","This article presents two case studies aimed at exploring the use of self-explanations in the context of computational science and engineering (CSE) education. The self-explanations were elicited as students' in-code comments of a set of worked-examples, and the cases involved two different approaches to CSE education: glass box and black box. The glass-box approach corresponds to a programming course for materials science and engineering students that focuses on introducing programming concepts while solving disciplinary problems. The black-box approach involves the introduction of Python-based computational tools within a thermodynamics course to represent disciplinary phenomena. Two semesters of data collection for each case study allowed us to identify the effect of using in-code comments as a self-explanation strategy on students' engagement with the worked-examples and students' perceptions of these activities within each context. The results suggest that the use of in-code comments as a self-explanation strategy increased students' awareness of the worked-examples while engaging with them. The students' perceived uses of the in-code commenting activities include: understanding the example, making a connection between the programming code and the disciplinary problem, and becoming familiar with the programming language syntax, among others. © 2017 ACM.","Applied computing education; Comments; Programming learning; Self-explaining","Codes (symbols); Education; Glass; Problem oriented languages; Thermodynamics; Applied computing; Comments; Computational science and engineerings; Materials science and engineering; Programming learning; Self-explaining; Students' engagements; Thermodynamics course; Students",2-s2.0-85028596882
"Silva L.H., Valente M.T., Bergel A., Anquetil N., Etien A.","Identifying Classes in Legacy JavaScript Code",2017,"Journal of Software: Evolution and Process",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026836053&doi=10.1002%2fsmr.1864&partnerID=40&md5=e3ca1bd5a022845d4038e4dd9fa7474e","JavaScript is the most popular programming language for the Web. Although the language is prototype-based, developers can emulate class-based abstractions in JavaScript to master the increasing complexity of their applications. Identifying classes in legacy JavaScript code can support these developers at least in the following activities: (1) program comprehension; (2) migration to the new JavaScript syntax that supports classes; and (3) implementation of supporting tools, including IDEs with class-based views and reverse engineering tools. In this paper, we propose a strategy to detect class-based abstractions in the source code of legacy JavaScript systems. We report on a large and in-depth study to understand how class emulation is employed, using a dataset of 918 JavaScript applications available on GitHub. We found that almost 70% of the JavaScript systems we study make some usage of classes. We also performed a field study with the main developers of 60 popular JavaScript systems to validate our findings. The overall results range from 97% to 100% for precision, from 70% to 89% for recall, and from 82% to 94% for F-score. Copyright © 2017 John Wiley & Sons, Ltd.","JavaScript; Program comprehension; Reverse engineering","Abstracting; Codes (symbols); Computer programming; Legacy systems; Reverse engineering; Software prototyping; Class-based; Field studies; In-depth study; Javascript; Program comprehension; Reverse engineering tools; Source codes; Supporting tool; High level languages",2-s2.0-85026836053
"Ahrendt W., Chimento J.M., Pace G.J., Schneider G.","Verifying data- and control-oriented properties combining static and runtime verification: theory and tools",2017,"Formal Methods in System Design",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017166327&doi=10.1007%2fs10703-017-0274-y&partnerID=40&md5=1ef211cf76bb1d632ff60220d5e1c214","Static verification techniques are used to analyse and prove properties about programs before they are executed. Many of these techniques work directly on the source code and are used to verify data-oriented properties over all possible executions. The analysis is necessarily an over-approximation as the real executions of the program are not available at analysis time. In contrast, runtime verification techniques have been extensively used for control-oriented properties, analysing the current execution path of the program in a fully automatic manner. In this article, we present a novel approach in which data-oriented and control-oriented properties may be stated in a single formalism amenable to both static and dynamic verification techniques. The specification language we present to achieve this that of ppDATEs, which enhances the control-oriented property language of DATEs, with data-oriented pre/postconditions. For runtime verification of ppDATE specifications, the language is translated into a DATE. We give a formal semantics to ppDATEs, which we use to prove the correctness of our translation from ppDATEs to DATEs. We show how ppDATE specifications can be analysed using a combination of the deductive theorem prover KeY and the runtime verification tool LARVA. Verification is performed in two steps: KeY first partially proves the data-oriented part of the specification, simplifying the specification which is then passed on to LARVA to check at runtime for the remaining parts of the specification including the control-oriented aspects. We show the applicability of our approach on two case studies. © 2017, The Author(s).","Java; Program analysis; Runtime verification; Static verification","Computer programming; Computer software; Formal methods; Semantics; Specification languages; Translation (languages); Dynamic verifications; Execution paths; Formal Semantics; Java; Program analysis; Run-time verification; Static verification; Theorem provers; Specifications",2-s2.0-85017166327
"Cheng K., Chen G., Zhang R., Wu L., Wang Z., Kang R.","A Method for Unifying the Representations of Domain Knowledge and Planning Algorithm in Hierarchical Task Network",2017,"International Journal of Pattern Recognition and Artificial Intelligence",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019076916&doi=10.1142%2fS0218001417590145&partnerID=40&md5=987c691c3a7d0b1307e04f954a4a761d","Domain knowledge of hierarchical task network (HTN) usually involves logical expressions with predicates. One needs to master two different languages which are used to describe domain knowledge and implement planner. This has presented enormous challenges for most programmers who are not familiar with logical expressions. To solve the problem a method of state variable representation from the programmer's point of view is introduced. This method has powerful expressivity and can unify the representations of domain knowledge and planning algorithm. In Pyhop a HTN planner written in Python, methods and operators are all as ordinary Python functions rather than using a special-purpose language. Pyhop uses a Python object that contains variable bindings and does not include a horn-clause inference engine for evaluating preconditions of operators and methods. By taking a simple travel-planning problem, it shows that the method is easy to understand and integrate planning into ordinary programming. © 2017 World Scientific Publishing Company.","predicate representation; Pyhop; Python; Simple hierarchical ordered planner; state variable representation","Logic programming; predicate representation; Pyhop; Python; Simple hierarchical ordered planners; State variable representations; High level languages",2-s2.0-85019076916
"Aiken C.","Long-term neurodevelopmental outcomes in small babies",2017,"Obstetrics, Gynaecology and Reproductive Medicine",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021253698&doi=10.1016%2fj.ogrm.2017.06.001&partnerID=40&md5=691e2fa194553995a2f42a56010cbed4","The concept that health and disease outcomes in later life can be programmed during development in the womb is now well established through work in both human epidemiological studies and animal models. However clinicians are not often encouraged to consider this concept when caring for a baby who is at risk from a suboptimal intrauterine environment. Babies who are born at term below the 10th centile for gestational age are at increased risk of poor neurocognitive development later in childhood. The effect is consistent between studies that have examined development in infancy, mid-childhood, and through to adolescence. Impairment has been demonstrated in several different neurocognitive domains, including motor, vision, hearing and language development. Care must be taken however in the interpretation of the numerous studies in this area to carefully correct for all of the confounding socio-economic variables that can contribute both to restricted fetal growth and to poor childhood cognitive outcomes. When these are fully corrected for, an overall effect of poor intrauterine growth on neurodevelopment still remains, but the impact is less. Predicting a subset of small babies who are at particularly high risk for poor neurodevelopmental outcomes has as yet remained elusive, despite multiple attempts to use various individual growth parameters, Doppler ultrasound measurements and serum biomarkers to boost the predictive power. © 2017 Elsevier Ltd","developmental programming; intrauterine growth restriction; neurodevelopment; small-for-gestational age","glucocorticoid; placental growth factor; abdominal circumference; catch up growth; child development; cognitive defect; Doppler ultrasonography; head circumference; hearing impairment; human; intrauterine growth retardation; language disability; motor dysfunction; nervous system development; nonhuman; predictive value; premature labor; Review; risk factor; small for date infant; visual impairment",2-s2.0-85021253698
"Morgan-Lopez A.A., Kim A.E., Chew R.F., Ruddle P.","Predicting age groups of Twitter users based on language and metadata features",2017,"PLoS ONE",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029234026&doi=10.1371%2fjournal.pone.0183537&partnerID=40&md5=a393598ab83adc32a1a50250eee0dc26","Health organizations are increasingly using social media, such as Twitter, to disseminate health messages to target audiences. Determining the extent to which the target audience (e.g., age groups) was reached is critical to evaluating the impact of social media education campaigns. The main objective of this study was to examine the separate and joint predictive validity of linguistic and metadata features in predicting the age of Twitter users. We created a labeled dataset of Twitter users across different age groups (youth, young adults, adults) by collecting publicly available birthday announcement tweets using the Twitter Search application programming interface. We manually reviewed results and, for each age-labeled handle, collected the 200 most recent publicly available tweets and user handles’ metadata. The labeled data were split into training and test datasets. We created separate models to examine the predictive validity of language features only, metadata features only, language and metadata features, and words/phrases from another age-validated dataset. We estimated accuracy, precision, recall, and F1 metrics for each model. An L1-regularized logistic regression model was conducted for each age group, and predicted probabilities between the training and test sets were compared for each age group. Cohen’s d effect sizes were calculated to examine the relative importance of significant features. Models containing both Tweet language features and metadata features performed the best (74% precision, 74% recall, 74% F1) while the model containing only Twitter metadata features were least accurate (58% precision, 60% recall, and 57% F1 score). Top predictive features included use of terms such as “school” for youth and “college” for young adults. Overall, it was more challenging to predict older adults accurately. These results suggest that examining linguistic and Twitter metadata features to predict youth and young adult Twitter users may be helpful for informing public health surveillance and evaluation research. © 2017 Morgan-Lopez et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",,"adult; aged; controlled study; effect size; evaluation research; female; human; human experiment; joint; juvenile; language; male; metadata; predictive validity; probability; public health; recall; young adult; adolescent; age; decision making; information processing; social media; theoretical model; Adolescent; Adult; Age Factors; Data Collection; Humans; Judgment; Language; Metadata; Models, Theoretical; Social Media; Young Adult",2-s2.0-85029234026
"Schmieschek S., Shamardin L., Frijters S., Krüger T., Schiller U.D., Harting J., Coveney P.V.","LB3D: A parallel implementation of the Lattice-Boltzmann method for simulation of interacting amphiphilic fluids",2017,"Computer Physics Communications",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019106890&doi=10.1016%2fj.cpc.2017.03.013&partnerID=40&md5=820e2852b7e8275edc5c962da7782480","We introduce the lattice-Boltzmann code LB3D, version 7.1. Building on a parallel program and supporting tools which have enabled research utilising high performance computing resources for nearly two decades, LB3D version 7 provides a subset of the research code functionality as an open source project. Here, we describe the theoretical basis of the algorithm as well as computational aspects of the implementation. The software package is validated against simulations of meso-phases resulting from self-assembly in ternary fluid mixtures comprising immiscible and amphiphilic components such as water–oil–surfactant systems. The impact of the surfactant species on the dynamics of spinodal decomposition are tested and quantitative measurement of the permeability of a body centred cubic (BCC) model porous medium for a simple binary mixture is described. Single-core performance and scaling behaviour of the code are reported for simulations on current supercomputer architectures. Program summary Program Title: LB3D Program Files doi: http://dx.doi.org/10.17632/9g9x2wr8z8.1 Licensing provisions: BSD 3-clause Programming language: FORTRAN90, Python, C Nature of problem: Solution of the hydrodynamics of single phase, binary immiscible and ternary amphiphilic fluids. Simulation of fluid mixtures comprising miscible and immiscible fluid components as well as amphiphilic species on the mesoscopic scale. Observable phenomena include self-organisation of mesoscopic complex fluid phases and fluid transport in porous media. Solution method: Lattice-Boltzmann (lattice-Bhatnagar–Gross–Krook, LBGK) [1, 2, 3] method describing fluid dynamics in terms of the single particle velocity distribution function in a 3-dimensional discrete phase space (D3Q19) [4, 5, 6]. Multiphase interactions are modelled using a phenomenological pseudo-potential approach [7, 8] with amphiphilic interactions utilising an additional dipole field [9, 10]. Solid boundaries are modelled using simple bounce-back boundary conditions and additional pseudo-potential wetting interactions [11]. Additional comments including Restrictions and Unusual features: The purpose of the release is the provision of a refactored minimal version of LB3D suitable as a starting point for the integration of additional features building on the parallel computation and IO functionality. [1] S. Succi, The Lattice Boltzmann Equation: For Fluid Dynamics and Beyond, Oxford University Press, 2001.[2] B. Dünweg, A. Ladd, Lattice Boltzmann simulations of soft matter systems, Adv. Poly. Sci. 221 (2009) 89–166[3] C. K. Aidun, J. R. Clausen, Lattice-Boltzmann Method for Complex Flows, Annual Review of Fluid Mechanics 42 (2010) 439.[4] X. He, L.-S. Luo, A priori derivation of the lattice-Boltzmann equation, Phys. Rev. E 55 (1997) R6333.[5] X. He, L.-S. Luo, Theory of the lattice Boltzmann method: from the Boltzmann equation to the lattice Boltzmann equation, Phys. Rev. E 56.[6] Y. H. Qian, D. D'Humiéres, P. Lallemand, Lattice BGK Models for Navier–Stokes Equation, Europhysics Letters 17 (1992) 479.[7] X. Shan, H. Chen, Lattice-Boltzmann model for simulating flows with multiple phases and components, Physical Review E 47 (1993) 1815.[8] X. Shan, G. Doolen, Multicomponent lattice-Boltzmann model with interparticle interaction, Journal of Statistical Physics 81 (1995) 379.[9] H. Chen, B. Boghosian, P.V. Coveney, M. Nekovee, A ternary lattice-Boltzmann model for amphiphilic fluids, Proceedings of the Royal Society of London A 456 (2000) 2043.[10] M. Nekovee, P. V. Coveney, H. Chen, B. M. Boghosian, Lattice-Boltzmann model for interacting amphiphilic fluids, Phys. Rev. E 62 (2000) 8282.[11] N. S. Martys, H. Chen, Simulation of multicomponent fluids in complex three-dimensional geometries by the lattice-Boltzmann method, Phys. Rev. E 53 (1996) 743. © 2017 The Authors","High performance computing; Lattice-Boltzmann method; LB3D; LBM; Multiphase flow","Association reactions; Binary mixtures; Boltzmann equation; Codes (symbols); Computation theory; Computational fluid dynamics; Computer programming; Distribution functions; Dynamics; Electroosmosis; Fluid dynamics; Fluid mechanics; Kinetic theory; Mechanical permeability; Mixtures; Multiphase flow; Navier Stokes equations; Open source software; Open systems; Phase space methods; Porous materials; Self assembly; Spinodal decomposition; Supercomputers; Superconducting materials; Surface active agents; Transport properties; Two phase flow; Velocity control; Bounce-back boundary condition; High performance computing; High-performance computing resources; Lattice Boltzmann equations; Lattice Boltzmann method; Lattice Boltzmann simulations; LB3D; Three dimensional geometry; Lattice theory",2-s2.0-85019106890
"Lu Q., Li Z., Zhang W., Yang L.T.","Autonomic deployment decision making for big data analytics applications in the cloud",2017,"Soft Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947592799&doi=10.1007%2fs00500-015-1945-5&partnerID=40&md5=b0acf8dccbd51c4925ba2220ef340c80","When changes happen to big data analytics (BDA) applications in the Cloud at runtime, the affected BDA applications have to be re-deployed to accommodate the changes. Deciding the most suitable deployment is critical and complicated. Although there have been various research studies working on BDA application management, autonomic deployment decision making is still an open research issue. This paper proposes a deployment decision making solution for BDA applications in the Cloud: first, we propose a novel language, named DepPolicy, to specify runtime deployment information as policies; second, we model the deployment decision making problem as a constraint programming problem using MiniZinc; third, we propose a decision making algorithm that can make different deployment decisions for different jobs in a way that maximises overall utility while satisfying all given constraints (e.g., cost limit); fourth, we design and implement a decision making middleware, named DepWare, for BDA application deployment in the Cloud. The proposed solution is evaluated in terms of feasibility, functional correctness, performance and scalability. © 2015, Springer-Verlag Berlin Heidelberg.","Autonomic computing; Big data analytics; Cloud; Decision making; Deployment; QoS","Big data; Clouds; Computer programming; Constraint satisfaction problems; Constraint theory; Middleware; Quality of service; Application management; Autonomic Computing; Data analytics; Decision-making algorithms; Decision-making problem; Deployment; Functional correctness; Performance and scalabilities; Decision making",2-s2.0-84947592799
"Zhang D., Myers A.C., Vytiniotis D., Peyton-Jones S.","SHErrLoc: A static holistic error locator",2017,"ACM Transactions on Programming Languages and Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028501444&doi=10.1145%2f3121137&partnerID=40&md5=523228eb9afe759e931f7f6cbf8584d8","We introduce a general way to locate programmer mistakes that are detected by static analyses. The program analysis is expressed in a general constraint language that is powerful enough to model type checking, information flow analysis, dataflow analysis, and points-to analysis. Mistakes in program analysis result in unsatisfiable constraints. Given an unsatisfiable system of constraints, both satisfiable and unsatisfiable constraints are analyzed to identify the program expressions most likely to be the cause of unsatisfiability. The likelihood of different error explanations is evaluated under the assumption that the programmer's code is mostly correct, so the simplest explanations are chosen, following Bayesian principles. For analyses that rely on programmer-stated assumptions, the diagnosis also identifies assumptions likely to have been omitted. The new error diagnosis approach has been implemented as a tool called SHErrLoc, which is applied to three very different program analyses, such as type inference for a highly expressive type system implemented by the Glasgow Haskell Compiler-including type classes, Generalized Algebraic Data Types (GADTs), and type families. The effectiveness of the approach is evaluated using previously collected programs containing errors. The results show that when compared to existing compilers and other tools, SHErrLoc consistently identifies the location of programmer errors significantly more accurately, without any language-specific heuristics. © 2017 ACM.","Error diagnosis; Haskell; Information flow; Jif; OCaml; Static program analysis; Type inference","Computer programming; Data flow analysis; Errors; Program diagnostics; Static analysis; Error diagnosis; Haskell; Information flows; OCaml; Static program analysis; Type inferences; Program compilers",2-s2.0-85028501444
"Peng Q., Feng L., Wen C., Zhang X.","Structural Brittleness Analysis of Information Transfer Process of High-speed Railway Train Control",2017,"Xinan Jiaotong Daxue Xuebao/Journal of Southwest Jiaotong University",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028363862&doi=10.3969%2fj.issn.0258-2724.2017.04.019&partnerID=40&md5=32fc019d84023441455c7349aeca8935","The majority of previous studies on train control process safety focused on individual subsystems; this approach lacks wholeness and ignores the risk-sharing problem introduced by information transfer between different subsystems. Here, a three-level system, namely a computer-based interlocking system, train control system, and centralized train control system, was modelled from the perspective of information passing between subsystems, and the structural brittleness of the train control process was analysed. First, the structural brittleness of the high-speed railway train control process was stated according to brittleness sources, the brittleness propagation path, and the system crash standard. Then, a simulation platform was set up for system brittleness analysis based on the I/O file stream in CPN Tools and C# programming language, and a simulation example was designed. The results show that the average correlation between sub-transitions in the movement authority request submodel is 56.72%, and that in the CTCS-3 submodel is 9.56%; these results provide a reference for the differentiated typical safety management strategy. © 2017, Editorial Department of Journal of Southwest Jiaotong University. All right reserved.","Brittleness; CPN Tools; High-speed rail; Simulation platform; Train control","Brittleness; Computer control systems; Computer hardware description languages; Computer simulation languages; Control systems; Crack propagation; Fracture mechanics; Plasticity; Railroad engineering; Railroad plant and structures; Railroad transportation; Railroads; Rails; Risk management; Safety engineering; Computer Based Interlocking; Cpn tools; High - speed railways; High speed rail; Information transfers; Simulation platform; Train control; Train control systems; Process control",2-s2.0-85028363862
"Falloon P.E., Rodriguez J., Wang J.B.","QSWalk: A Mathematica package for quantum stochastic walks on arbitrary graphs",2017,"Computer Physics Communications",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019024977&doi=10.1016%2fj.cpc.2017.03.014&partnerID=40&md5=b3f5117b338bb78066788f7950ba5926","We present a Mathematica package, QSWalk, to simulate the time evaluation of Quantum Stochastic Walks (QSWs) on arbitrary directed and weighted graphs. QSWs are a generalization of continuous time quantum walks that incorporate both coherent and incoherent dynamics and as such, include both quantum walks and classical random walks as special cases. The incoherent component allows for quantum walks along directed graph edges. The dynamics of QSWs are expressed using the Lindblad formalism, originally developed for open quantum systems, which frames the problem in the language of density matrices. For a QSW on a graph of N vertices, we have a sparse superoperator in an N2-dimensional space, which can be solved efficiently using the built-in MatrixExp function in Mathematica. We illustrate the use of the QSWalk package through several example case studies. Program summary Program Title: QSWalk.m Program Files doi: http://dx.doi.org/10.17632/8rwd3j9zhk.1 Licensing provisions: GNU General Public License 3 (GPL) Programming language: Mathematica. Nature of problem: The QSWalk package provides a method for simulating quantum stochastic walks on arbitrary (directed/undirected, weighted/unweighted) graphs. Solution method: For an N-vertex graph, the solution of a quantum stochastic walk can be expressed as an N2×N2 sparse matrix exponential. The QSWalk package makes use of Mathematica's sparse linear algebra routines to solve this efficiently. Restrictions: The size of graphs that can be treated is constrained by available memory. © 2017 Elsevier B.V.","Density matrix; Lindblad master equation; Mathematica; Open system; Quantum stochastic walk; Superoperator","Continuous time systems; Directed graphs; Graphic methods; Linear algebra; Matrix algebra; Open source software; Open systems; Problem oriented languages; Quantum optics; Quantum theory; Stochastic systems; Density matrix; Lindblad master equation; Mathematica; Quantum stochastic walk; Superoperators; Graph theory",2-s2.0-85019024977
"Hollman C., Paulden M., Pechlivanoglou P., McCabe C.","A Comparison of Four Software Programs for Implementing Decision Analytic Cost-Effectiveness Models",2017,"PharmacoEconomics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019054747&doi=10.1007%2fs40273-017-0510-8&partnerID=40&md5=6ccff0feed3c0ac6003898b8f2dcbb04","The volume and technical complexity of both academic and commercial research using decision analytic modelling has increased rapidly over the last two decades. The range of software programs used for their implementation has also increased, but it remains true that a small number of programs account for the vast majority of cost-effectiveness modelling work. We report a comparison of four software programs: TreeAge Pro, Microsoft Excel, R and MATLAB. Our focus is on software commonly used for building Markov models and decision trees to conduct cohort simulations, given their predominance in the published literature around cost-effectiveness modelling. Our comparison uses three qualitative criteria as proposed by Eddy et al.: “transparency and validation”, “learning curve” and “capability”. In addition, we introduce the quantitative criterion of processing speed. We also consider the cost of each program to academic users and commercial users. We rank the programs based on each of these criteria. We find that, whilst Microsoft Excel and TreeAge Pro are good programs for educational purposes and for producing the types of analyses typically required by health technology assessment agencies, the efficiency and transparency advantages of programming languages such as MATLAB and R become increasingly valuable when more complex analyses are required. © 2017, Springer International Publishing Switzerland.",,"benchmarking; biomedical technology assessment; clinical education; comparative study; computer analysis; computer language; computer simulation; controlled study; cost effectiveness analysis; decision tree; learning curve; Markov chain; matlab; microsoft excel; Monte Carlo method; priority journal; quantitative analysis; Review; software; treeage pro",2-s2.0-85019054747
"Koen J.D., Barrett F.S., Harlow I.M., Yonelinas A.P.","The ROC Toolbox: A toolbox for analyzing receiver-operating characteristics derived from confidence ratings",2017,"Behavior Research Methods",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984652005&doi=10.3758%2fs13428-016-0796-z&partnerID=40&md5=a304c9efc22a21549a62be041a0a83f2","Signal-detection theory, and the analysis of receiver-operating characteristics (ROCs), has played a critical role in the development of theories of episodic memory and perception. The purpose of the current paper is to present the ROC Toolbox. This toolbox is a set of functions written in the Matlab programming language that can be used to fit various common signal detection models to ROC data obtained from confidence rating experiments. The goals for developing the ROC Toolbox were to create a tool (1) that is easy to use and easy for researchers to implement with their own data, (2) that can flexibly define models based on varying study parameters, such as the number of response options (e.g., confidence ratings) and experimental conditions, and (3) that provides optimal routines (e.g., Maximum Likelihood estimation) to obtain parameter estimates and numerous goodness-of-fit measures.The ROC toolbox allows for various different confidence scales and currently includes the models commonly used in recognition memory and perception: (1) the unequal variance signal detection (UVSD) model, (2) the dual process signal detection (DPSD) model, and (3) the mixture signal detection (MSD) model. For each model fit to a given data set the ROC toolbox plots summary information about the best fitting model parameters and various goodness-of-fit measures. Here, we present an overview of the ROC Toolbox, illustrate how it can be used to input and analyse real data, and finish with a brief discussion on features that can be added to the toolbox. © 2016, Psychonomic Society, Inc.","Memory; Open source software; Perception; Signal detection theory","computer language; experimental model; human; human experiment; maximum likelihood method; receiver operating characteristic; recognition; scientist; signal detection; software",2-s2.0-84984652005
"Freitas A.A., Alfaro Vigo D.G., Teixeira M.G., Vasconcellos C.A.B.D.","Horizontal water flow in unsaturated porous media using a fractional integral method with an adaptive time step",2017,"Applied Mathematical Modelling",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020165480&doi=10.1016%2fj.apm.2017.03.032&partnerID=40&md5=7760e9ebc1c751bf1f0775565d44046f","Predicting the horizontal groundwater flow in unsaturated porous media is a challenge in many areas of science and engineering. The governing equation associated with this phenomenon is a nonlinear partial differential equation known as the Richards equation. However, the numerical results obtained using this equation can differ substantially from the experimental results. In order to overcome this difficulty, a new version of the Richards equation was proposed recently that considers a time derivative of fractional order. In this study, we present a numerical method for solving this fractional Richards equation. Our method comprises an adaptive time marching scheme that uses Picard iterations to solve the corresponding nonlinear equations. A computational code was implemented for the proposed method using the Scilab programming language. We performed numerical simulations of the anomalous diffusion of water in a white siliceous brick and showed that the numerical results were consistent with the available experimental data. © 2017 Elsevier Inc.","Adaptive time step; Finite difference method; Fractional integral; Horizontal water flow; Picard technique; Unsaturated porous media","Finite difference method; Flow of water; Groundwater; Groundwater flow; Hydraulics; Numerical methods; Partial differential equations; Porous materials; Solute transport; Adaptive time step; Fractional integrals; Picard technique; Unsaturated porous media; Water flows; Nonlinear equations",2-s2.0-85020165480
"Franco F.J., Clemente J.A., Baylac M., Rey S., Villa F., Mecha H., Agapito J.A., Puchner H., Hubert G., Velazco R.","Statistical Deviations from the Theoretical Only-SBU Model to Estimate MCU Rates in SRAMs",2017,"IEEE Transactions on Nuclear Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028930739&doi=10.1109%2fTNS.2017.2726938&partnerID=40&md5=8e079863e9d2579d300024708a31f413","This paper addresses a well-known problem that occurs when memories are exposed to radiation: the determination if a bit flip is isolated or if it belongs to a multiple event. As it is unusual to know the physical layout of the memory, this paper proposes to evaluate the statistical properties of the sets of corrupted addresses and to compare the results with a mathematical prediction model where all of the events are single bit upsets. A set of rules easy to implement in common programming languages can be iteratively applied if anomalies are observed, thus yielding a classification of errors quite closer to reality (more than 80% accuracy in our experiments). © 1963-2012 IEEE.","Multiple cell upsets (MCUs); single bit upsets (SBUs); single events; soft errors; static random access memories (SRAMs)","Computer architecture; Electronic mail; Error correction; Errors; Iterative methods; Microcontrollers; Microprocessor chips; Monte Carlo methods; Radiation hardening; Random access storage; Random errors; Voltage control; Error correction codes; Multiple cell upset; Random access memory; Single event; Single-bit; Soft error; Static random access storage",2-s2.0-85028930739
"Bharoto, Sairun, Ramadhani A., Sumirat I.","Development of data acquisition and measurement software for neutron triple axis spectrometer at BATAN-Serpong, Indonesia",2017,"Atom Indonesia",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028806855&doi=10.17146%2faij.2017.484&partnerID=40&md5=d43ce2a21a197a7785ffa252c4469aec","The Neutron Scattering Laboratory at the National Nuclear Energy Agency of Indonesia (BATAN) possesses several neutron beam instruments for materials science research. One of the instruments is a neutron triple-axis spectrometer (TAS). Due to the malfunction of the main computer, the original main control system had to be replaced with a new one. For this reason, a new data acquisition and measurement software program based on GNU C++ programming language was developed for restoring the spectrometer's functionality. However, using the resulting control system, triple-axis mode experiments were very difficult to perform and their types that can be performed were limited. In order to conduct the experiments more effectively and efficiently, several improvements in both hardware and software have been developed. The Visual Basic programming language was used in developing the data acquisition and measurement software that makes it possible for all motors to move simultaneously, so that the time spent for the experiments is reduced significantly. Also, programmable motor controller cards were used for driving all the 23 motors of the instrument. All the 23 axes can be controlled by clicking the appropriate buttons or inputting text command in the main window of the software's user interface. The software has also been used to perform an elastic experiment, as well as an inelastic experiment for investigating the phenomenon of phonon. The software developed is more user friendly than the older ones, since the spectrometer status and the experiment results can be displayed in real time at the windows, and it also makes experiments more effective and efficient since the experiments can be automated and run without any user intervention until the experiments finish. © 2017 Atom Indonesia.","Data acquisition; Neutron; Scattering; Software; Spectrometer",,2-s2.0-85028806855
"Min M., Wu C., Li C., Liu H., Xu N., Wu X., Chen L., Wang F., Sun F., Qin D., Wang X., Li B., Zheng Z., Cao G., Dong L.","Developing the science product algorithm testbed for Chinese next-generation geostationary meteorological satellites: Fengyun-4 series",2017,"Journal of Meteorological Research",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028341305&doi=10.1007%2fs13351-017-6161-z&partnerID=40&md5=0f600436e1cf01355ecf47374162764a","Fengyun-4A (FY-4A), the first of the Chinese next-generation geostationary meteorological satellites, launched in 2016, offers several advances over the FY-2: more spectral bands, faster imaging, and infrared hyperspectral measurements. To support the major objective of developing the prototypes of FY-4 science algorithms, two science product algorithm testbeds for imagers and sounders have been developed by the scientists in the FY-4 Algorithm Working Group (AWG). Both testbeds, written in FORTRAN and C programming languages for Linux or UNIX systems, have been tested successfully by using Intel/g compilers. Some important FY-4 science products, including cloud mask, cloud properties, and temperature profiles, have been retrieved successfully through using a proxy imager, Himawari-8/Advanced Himawari Imager (AHI), and sounder data, obtained from the Atmospheric InfraRed Sounder, thus demonstrating their robustness. In addition, in early 2016, the FY-4 AWG was developed based on the imager testbed—a near real-time processing system for Himawari-8/AHI data for use by Chinese weather forecasters. Consequently, robust and flexible science product algorithm testbeds have provided essential and productive tools for popularizing FY-4 data and developing substantial improvements in FY-4 products. © 2017, The Chinese Meteorological Society and Springer-Verlag GmbH Germany.","algorithm testbed; cloud properties; FY-4; geostationary meteorological satellite",,2-s2.0-85028341305
"Muroya K., Ghica D.R.","The dynamic geometry of interaction machine: A call-by-need graph rewriter",2017,"Leibniz International Proceedings in Informatics, LIPIcs",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028700852&doi=10.4230%2fLIPIcs.CSL.2017.32&partnerID=40&md5=a147d048b458c74f75af70168f3a4668","Girard's Geometry of Interaction (GoI), a semantics designed for linear logic proofs, has been also successfully applied to programming languages. One way is to use abstract machines that pass a token in a fixed graph, along a path indicated by the GoI. These token-passing abstract machines are space efficient, because they handle duplicated computation by repeating the same moves of a token on the fixed graph. Although they can be adapted to obtain sound models with regard to the equational theories of various evaluation strategies for the lambda calculus, it can be at the expense of significant time costs. In this paper we show a token-passing abstract machine that can implement evaluation strategies for the lambda calculus, with certified time efficiency. Our abstract machine, called the Dynamic GoI Machine (DGoIM), rewrites the graph to avoid replicating computation, using the token to find the redexes. The flexibility of interleaving token transitions and graph rewriting allows the DGoIM to balance the trade-off of space and time costs. This paper shows that the DGoIM can implement call-by-need evaluation for the lambda calculus by using a strategy of interleaving token passing with as much graph rewriting as possible. Our quantitative analysis confirms that the DGoIM with this strategy of interleaving the two kinds of possible operations on graphs can be classified as ""efficient"" following Accattoli's taxonomy of abstract machines. © Koko Muroya and Dan R. Ghica.","Call-by-need reduction; Cost analysis; Geometry of Interaction","Calculations; Computation theory; Computational mechanics; Computer circuits; Costs; Differentiation (calculus); Economic and social effects; Geometry; Semantics; Call-by-need; Cost analysis; Equational theory; Evaluation strategies; Geometry of Interaction; Girard's geometry of interactions; Linear logic proof; Time efficiencies; Cost benefit analysis",2-s2.0-85028700852
"Yao X., Zhu D., Yun W., Peng F., Li L.","A WebGIS-based decision support system for locust prevention and control in China",2017,"Computers and Electronics in Agriculture",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020284965&doi=10.1016%2fj.compag.2017.06.001&partnerID=40&md5=dad4bd725fc02c6c4966898d18034277","Locust swarms are destructive agricultural and biological disasters in China. The green prevention and control (GPC, such as ecological regulation and physical control) of locusts is a comprehensive and complex process, especially in information technology. In this study, a web-based decision support system (DSS) integrated with geographic information system (GIS) is developed to prevent and control locusts efficiently, accurately, and rapidly. The locust prevention and control DSS (LPCDSS) is developed to assist farmers and local government agencies in Chinese provinces with high incidence of locust by providing spatial decision-making information. LPCDSS offers online access to county, city, provincial, and national level data queries and is capable of storing, spatial analyzing, and displaying geographically referenced information of locust data. The system can also provide the real-time tracking of global positioning system (GPS) location, as well as goods scheduling of locust plagues prevention. Six types of web service, real-time data synchronization model, and locust population estimation model are developed and implemented to improve the decision-making usability and feasibility of LPCDSS by adopting a three-layer system architecture. The system is developed by using several programming languages, libraries, and software components. As a result, this system has been running successfully for several years and has improved efficiency of the locust prevention and control in China with high efficiency and great accuracy. The approaches and methodologies presented in this paper can serve as a reference for those who are interested in developing integrated pest control system applications. © 2017 Elsevier B.V.","DSS; Geo-processing service; Locust population estimation; Real-time data synchronization; WebGIS","Agriculture; Decision making; Efficiency; Global positioning system; Population statistics; Web services; Websites; Geoprocessing; Population estimations; Prevention and controls; Real time tracking; Real-time data; Three-layer systems; Web-based decision support systems; Web-GIS; Decision support systems; control system; decision making; decision support system; GIS; integrated pest management; local government; locust; pest control; population estimation; software; spatial analysis; World Wide Web; China; Orthoptera",2-s2.0-85020284965
"Steinberg O.B.","Circular shift of loop body - Programme transformation, promoting parallelism",2017,"Bulletin of the South Ural State University, Series: Mathematical Modelling, Programming and Computer Software",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028761508&doi=10.14529%2fmmp170310&partnerID=40&md5=6aa1f210e298ec3500ff7fb90c82b855","The article deals with the programme transformation executing the circular shift of loop body statements. It can be used for vectorizing or parallelizing. This becomes possible due to the fact that when the order of loop body statements is changed, some of the bottom-up arcs become top-down arcs. Besides, sometimes loop carried dependence arcs are substituted by loop independent ones. It should be pointed out that in executing the circular shift the number of loop iterations is reduced by one. The transformation can be used both independently and in conjunction with other transformations promoting parallelism. These could be ""forward substitution"", ""scalar expansion"", ""privatization"", ""array expansion"", etc. The transformation under consideration in this article can be used both in hand parallelization and added to a paralleling (optimizing) compiler. Moreover, the application of the transformation results in the equivalent code only for the loops where loop unrolling is the equivalent transformation. Thus, they can contain nested loops, if statements and other programming language statements.","Dependence graph; Loop distribution; Parallel computations; Programme transformations; Scalar expansion",,2-s2.0-85028761508
"Sylwestrzak M., Szlag D., Marchand P.J., Kumar A.S., Lasser T.","Massively parallel data processing for quantitative total flow imaging with optical coherence microscopy and tomography",2017,"Computer Physics Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018777986&doi=10.1016%2fj.cpc.2017.03.008&partnerID=40&md5=400eb5177790a3daf3e51c5f5d46226c","We present an application of massively parallel processing of quantitative flow measurements data acquired using spectral optical coherence microscopy (SOCM). The need for massive signal processing of these particular datasets has been a major hurdle for many applications based on SOCM. In view of this difficulty, we implemented and adapted quantitative total flow estimation algorithms on graphics processing units (GPU) and achieved a 150 fold reduction in processing time when compared to a former CPU implementation. As SOCM constitutes the microscopy counterpart to spectral optical coherence tomography (SOCT), the developed processing procedure can be applied to both imaging modalities. We present the developed DLL library integrated in MATLAB (with an example) and have included the source code for adaptations and future improvements. Program summary Program title: CudaOCMproc Catalogue identifier: AFBT_v1_0 Program summary URL: http://cpc.cs.qub.ac.uk/summaries/AFBT_v1_0.html Program obtainable from: CPC Program Library, Queen's University, Belfast, N. Ireland Licensing provisions: GNU GPLv3 No. of lines in distributed program, including test data, etc.: 913552 No. of bytes in distributed program, including test data, etc.: 270876249 Distribution format: tar.gz Programming language: CUDA/C, MATLAB. Computer: Intel x64 CPU, GPU supporting CUDA technology. Operating system: 64-bit Windows 7 Professional. Has the code been vectorized or parallelized?: Yes, CPU code has been vectorized in MATLAB, CUDA code has been parallelized. RAM: Dependent on users parameters, typically between several gigabytes and several tens of gigabytes Classification: 6.5, 18. Nature of problem: Speed up of data processing in optical coherence microscopy Solution method: Utilization of GPU for massively parallel data processing Additional comments: Compiled DLL library with source code and documentation, example of utilization (MATLAB script with raw data) Running time: 1,8 s for one B-scan (150 × faster in comparison to the CPU data processing time) © 2017","CUDA; Flow diagnostics; GPU data processing; Optical coherence tomography; Three-dimensional microscopy","Codes (symbols); Computer graphics; Data handling; Delay lock loops; Image processing; MATLAB; Open source software; Optical tomography; Program processors; Signal processing; Software testing; Tomography; Windows operating system; Catalogue identifiers; CUDA; Flow diagnostics; Massively parallel processing; Optical coherence microscopy; Processing procedures; Spectral Optical Coherence Tomography; Three-dimensional microscopy; Graphics processing unit",2-s2.0-85018777986
"Kawamura M., Yoshimi K., Misawa T., Yamaji Y., Todo S., Kawashima N.","Quantum lattice model solver HΦ",2017,"Computer Physics Communications",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019048621&doi=10.1016%2fj.cpc.2017.04.006&partnerID=40&md5=7b6ec0a81002239b7405991da354872d","HΦ [aitch-phi] is a program package based on the Lanczos-type eigenvalue solution applicable to a broad range of quantum lattice models, i.e., arbitrary quantum lattice models with two-body interactions, including the Heisenberg model, the Kitaev model, the Hubbard model and the Kondo-lattice model. While it works well on PCs and PC-clusters, HΦ also runs efficiently on massively parallel computers, which considerably extends the tractable range of the system size. In addition, unlike most existing packages, HΦ supports finite-temperature calculations through the method of thermal pure quantum (TPQ) states. In this paper, we explain theoretical background and user-interface of HΦ. We also show the benchmark results of HΦ on supercomputers such as the K computer at RIKEN Advanced Institute for Computational Science (AICS) and SGI ICE XA (Sekirei) at the Institute for the Solid State Physics (ISSP). Program summary Program Title:HΦ Program Files doi: http://dx.doi.org/10.17632/vnfthtyctm.1 Licensing provisions: GNU General Public License, version 3 or later Programming language: C External routines/libraries: MPI, BLAS, LAPACK Nature of problem: Physical properties (such as the magnetic moment, the specific heat, the spin susceptibility) of strongly correlated electrons at zero- and finite-temperature. Solution method: Application software based on the full diagonalization method, the exact diagonalization using the Lanczos method, and the microcanonical thermal pure quantum state for quantum lattice model such as the Hubbard model, the Heisenberg model and the Kondo model. Restrictions: System size less than about 20 sites for an itinerant electronic system and 40 site for a local spin system. Unusual features: Finite-temperature calculation of the strongly correlated electronic system based on the iterative scheme to construct the thermal pure quantum state. This method is efficient for highly frustrated system which is difficult to treat with other methods such as the unbiased quantum Monte Carlo. © 2017 The Author(s)","Lattice fermion models; Numerical linear algebra; Quantum spin liquids","Application programs; Crystal lattices; Eigenvalues and eigenfunctions; Hubbard model; Iterative methods; Linear algebra; Magnetic moments; Magnetic susceptibility; Microcomputers; Monte Carlo methods; Open source software; Software packages; Specific heat; Supercomputers; User interfaces; Correlated electronic systems; Diagonalization method; GNU general public license; Lattice fermion models; Massively parallel computers; Numerical Linear Algebra; Quantum spin liquid; Strongly correlated electrons; Quantum theory",2-s2.0-85019048621
"Li L., Bissyandé T.F., Papadakis M., Rasthofer S., Bartel A., Octeau D., Klein J., Traon L.","Static analysis of android apps: A systematic literature review",2017,"Information and Software Technology",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017357042&doi=10.1016%2fj.infsof.2017.04.001&partnerID=40&md5=ec038ece5c4aab07337fe0f29a24c565","Context Static analysis exploits techniques that parse program source code or bytecode, often traversing program paths to check some program properties. Static analysis approaches have been proposed for different tasks, including for assessing the security of Android apps, detecting app clones, automating test cases generation, or for uncovering non-functional issues related to performance or energy. The literature thus has proposed a large body of works, each of which attempts to tackle one or more of the several challenges that program analyzers face when dealing with Android apps. Objective We aim to provide a clear view of the state-of-the-art works that statically analyze Android apps, from which we highlight the trends of static analysis approaches, pinpoint where the focus has been put, and enumerate the key aspects where future researches are still needed. Method We have performed a systematic literature review (SLR) which involves studying 124 research papers published in software engineering, programming languages and security venues in the last 5 years (January 2011–December 2015). This review is performed mainly in five dimensions: problems targeted by the approach, fundamental techniques used by authors, static analysis sensitivities considered, android characteristics taken into account and the scale of evaluation performed. Results Our in-depth examination has led to several key findings: 1) Static analysis is largely performed to uncover security and privacy issues; 2) The Soot framework and the Jimple intermediate representation are the most adopted basic support tool and format, respectively; 3) Taint analysis remains the most applied technique in research approaches; 4) Most approaches support several analysis sensitivities, but very few approaches consider path-sensitivity; 5) There is no single work that has been proposed to tackle all challenges of static analysis that are related to Android programming; and 6) Only a small portion of state-of-the-art works have made their artifacts publicly available. Conclusion The research community is still facing a number of challenges for building approaches that are aware altogether of implicit-Flows, dynamic code loading features, reflective calls, native code and multi-threading, in order to implement sound and highly precise static analyzers. © 2017 Elsevier B.V.",,"Android (operating system); Codes (symbols); Engineering research; Mobile security; Software engineering; Intermediate representations; Program properties; Program source codes; Research communities; Security and privacy issues; Systematic literature review; Systematic literature review (SLR); Test cases generation; Static analysis",2-s2.0-85017357042
"Barsali S., Giglioli R., Lutzemberger G., Poli D., Valenti G.","Optimised operation of storage systems integrated with MV photovoltaic plants, considering the impact on the battery lifetime",2017,"Journal of Energy Storage",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019055934&doi=10.1016%2fj.est.2017.05.003&partnerID=40&md5=2056a76f04966e27ca27d14617c8bc42","Nowadays, the energy storage technology is bringing new opportunities to the power systems, not only providing the electric grid with regulation, reserve and backup services, but also filling the gap between the timing of production and consumption. This enables price arbitrage techniques, aimed at maximising the economic revenue obtained by charging or discharging the storage, based on the time variation of electricity prices. This paper shows how to optimise the operation of a storage device in presence of a PV generating plant, possibly combined with a local load. An optimisation technique based on a dynamic programming tool implemented with the open source Modelica language is here proposed and tested on different case studies. In particular, different storage sizes and losses models have been considered, as well as the dependence of the storage lifetime on the depth of discharge of its operational cycles. Finally, a payback analysis calibrated on present and future cost scenarios is presented and discussed. © 2017 Elsevier Ltd","Control strategy; Energy storage; Optimisation; Photovoltaic plant; Price arbitrage",,2-s2.0-85019055934
"Li J., Gao Z., Li T., Yang J., Xu A., Wang B.","Information integration management system for spiral bevel gear networked manufacturing process",2017,"Nongye Gongcheng Xuebao/Transactions of the Chinese Society of Agricultural Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031037672&doi=10.11975%2fj.issn.1002-6819.2017.15.029&partnerID=40&md5=f592ba42cfa559eb44924c935cffbd41","In order to more effectively support the information interaction and integration operation in spiral bevel gears networked manufacturing process, and implement the integrated management and control of manufacturing information data, we combined the characteristics of spiral bevel gears manufacturing process and information integration with management technologies, and proposed an architecture of information integration management system for spiral bevel gears networked manufacturing process in this paper based on the hierarchical thoughts. The architecture consisted of the access layer, management layer, information layer, activity layer, and resource layer which were integrated to form a whole information management system to realize the effective management and integration of entire manufacturing process form the initial spiral bevel gear orders to the final products delivery. Based on this and from the system overall operation perspective, the integration operation mode for spiral bevel gears networked manufacturing was established. Subsequently, according to the integration and sharing requirement of various information resources, the information description and integration framework of spiral bevel gear networked manufacturing process was set up based on the XML (extensible markup language) and Web service technologies, and the XML description, and Web service encapsulation mechanism of various information resources in spiral bevel gears networked manufacturing process were researched. Through making the XML Schema as the data exchange specification, the standard structures of manufacturing process information data were specifically defined, which mainly included the content, format, and attributes. According to the XML Schema standard specification definition, the XML document mapping conversion and Web service encapsulation of manufacturing process information data were finally achieved. Afterwards, by means of the Web service application integration mechanism, the information description and integration of whole spiral bevel gear networked manufacturing process was realized. Based on the service oriented architecture, the loosely-coupled and openness function model of information integration management system was built, which was divided into the application layer, interface layer, business layer, service layer, and system layer. Meanwhile, the information management and Web service called mechanism of entire function model, as well as the role of each layer and the logical relationship between the layers were elaborated. In Windows 2003 Enterprise Server, Microsoft Visual Basic.NET, and SQL Server 2005 development environment, and based on Browser/Server architecture pattern, the prototype system as well as the all corresponding function service and management interfaces of information integration management system were planned and developed. The information integration and unified management of entire spiral bevel gears networked manufacturing process were realized, which formed the gear order receipt, project planning, design and calculation of gears, process programming, task scheduling, procedure machining to the product delivery. Finally, through the enterprise application experiment of spiral bevel gears networked manufacturing, the validity of information integration management system in improving the production and management efficiency, shortening the gear production cycle, reducing the production costs were verified. Actual application results showed that the proposed architecture and implementation method of information integration management system were feasible and practical. It can effectively improve the operation and management efficiency of whole spiral bevel gears networked manufacturing process. Taking the networked manufacturing process of spiral bevel gear orders in this paper as an example, in the whole enterprise application test process, we compared with the traditional distributed manufacturing and information management mode. The productivity of application enterprise was increased about 8%, the management efficiency was improved around 25%, and the production costs were reduced more than 3%. This research presents an effective method for realizing the informatization and integration of spiral bevel gears networked manufacturing process. It may also provide a reference for the further research and application implementation of spiral bevel gears networked manufacturing mode. © 2017, Editorial Department of the Transactions of the Chinese Society of Agricultural Engineering. All right reserved.","Architecture; Gears; Information integration; Information management; Management system; Manufacturing",,2-s2.0-85031037672
"Mayer-Lindenberg F.","A programming language for embedded processor networks",2017,"2016 13th IEEE International Conference on Solid-State and Integrated Circuit Technology, ICSICT 2016 - Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028663288&doi=10.1109%2fICSICT.2016.7999036&partnerID=40&md5=33f402c40b17d07de97ed3e0772e2b50","A simple language for numeric computations on heterogeneous networks of programmable processors is described, in particular networks implemented in an ASIC, an FPGA or an SoC integrating hardwired processors and an FPGA. It relies on an infrastructure providing memory, communications, and various system services. The language supports the use of the multiple non-standard data types typically found in resource-aware FPGA and ASIC applications, and networking, and provides structures for reconfiguration. Application systems can be simulated on a PC. An experimental computer comprising 50 SoC nodes has been designed for further developing the programming concept and the infrastructure. © 2016 IEEE.",,"Computer programming; Field programmable gate arrays (FPGA); Heterogeneous networks; Application systems; ASIC application; Embedded processors; Numeric computation; Programmable processors; Programming concepts; Resource aware; System services; System-on-chip",2-s2.0-85028663288
"Chang K.-P., Wang J.-C., Chen C.-H., Li L.-J., Lai C.-S.","Monolayer MoS2 for nonvolatile memory applications",2017,"2016 13th IEEE International Conference on Solid-State and Integrated Circuit Technology, ICSICT 2016 - Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028680558&doi=10.1109%2fICSICT.2016.7998959&partnerID=40&md5=99433e634fb50500653cad10b762d9c2","In this work, two-dimensional MoS2 has been performed for nonvolatile memory application as charge storage layer. The capacitance-voltage (C-V) hysteresis and programming characteristics of MoS2-NVMs with blocking oxide layer of various thicknesses have been further investigated. The MoS2-NVMs with 9-nm-thck blocking oxide layer exhibits a large hysteresis in the C-V sweeping and the fastest speed in programming characteristics. In addition, both electrons and holes can store in MoS2 monolayer, contributing to a promising application in future high-performance NVMs. © 2016 IEEE.",,"Capacitance; Hysteresis; Integrated circuits; Monolayers; Nonvolatile storage; Capacitance voltage; Charge storage; Electrons and holes; Large hysteresis; Non-volatile memory application; Oxide layer; C (programming language)",2-s2.0-85028680558
"Lyubchenko A., Shiler A., Kopytov E.Y., Maystrenko V.A.","Computer-Aided analysis of reliability and preventive maintenance optimization of radio communication equipment based on multivariate Monte Carlo simulation",2017,"2017 International Siberian Conference on Control and Communications, SIBCON 2017 - Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028518598&doi=10.1109%2fSIBCON.2017.7998459&partnerID=40&md5=c03c8e3085c3ec32c2619bac3c2de5b8","In the paper, mathematical support and software of a computer-Aided design system of preventive maintenance schedule of radio communication equipment are proposed. Mathematical support is based on a Monte Carlo simulation model of an operational process that realizes multivariate approach of reliability indices estimation. System's software was implemented using C++ language and Matlab instruments. The developed system determines in an automated mode the recommended value of rational maintenance periodicity and reliability measures such as operational efficiency and availability for the selected device. The proposed computer-Aided instrument was used for the estimation of the abovementioned characteristics for a real transmitter. The obtained value of the rational service periodicity compares favorably to the valid experimental data regarding failures of the transmitter. © 2017 IEEE.","availability; computer-Aided design system; Monte Carlo simulation; operational efficiency; preventive maintenance","Availability; C++ (programming language); Computer aided analysis; Computer aided design; Computer control; Computer software; Computer software maintenance; Efficiency; Estimation; Intelligent systems; Maintenance; MATLAB; Monte Carlo methods; Radio communication; Reliability; Reliability analysis; Transmitters; Computer aided design systems; Maintenance optimization; Multivariate approach; Multivariate monte carlo simulations; Operational efficiencies; Operational process; Radio communication equipment; Reliability measure; Preventive maintenance",2-s2.0-85028518598
"Shvetsov-Shilovskiy I.I., Boruzdina A.B., Ulanova A.V., Orlov A.A., Amburkin K.M., Nikiforov A.Y.","Measurement system for test memory cells based on keysight B1500A semiconductor device analyzer running LabVIEW software",2017,"2017 International Siberian Conference on Control and Communications, SIBCON 2017 - Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028504507&doi=10.1109%2fSIBCON.2017.7998542&partnerID=40&md5=842ea9b8a9dce3949dbb9dccd3f394ed","The Keysight B1500A semiconductor device analyzer based measurement system for test memory cells research is introduced. The connection of a device under test is described as well as the full list of the utilized equipment. The features of the Keysight equipment remote control by means of Keysight VISA are demonstrated; code examples in LabVIEW environment are also presented. © 2017 IEEE.","B1500A; B1530A; GPIB; memory cells; VISA","Computer programming languages; Remote control; Semiconductor devices; Semiconductor storage; B1500A; B1530A; GPIB; Memory cell; VISA; Software testing",2-s2.0-85028504507
"Xu Y., Wang W., Li W., Wu D., He L.","A wideband LC VCO with small gain variation for 24GHz FMCW frequency synthesizer",2017,"2016 13th IEEE International Conference on Solid-State and Integrated Circuit Technology, ICSICT 2016 - Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028639494&doi=10.1109%2fICSICT.2016.7998762&partnerID=40&md5=e68e3e87db18417588423ad813b8553f","This paper proposed a wideband LC voltage-controlled oscillator (VCO) for FMCW frequency synthesizer with a large KVCO but small gain variation. An unequally biased varactor bank is used to ease gain variation problem, and a novel compensation circuit using a tunable negative-inductance cell is applied to further reduce gain variation over the whole tuning range without adjusting dead zones. Implemented in TSMC 65nm CMOS technology, the proposed VCO employs a single tuning curve to cover the required 23.65GHz∼26.10GHz and achieves less than 4.3% gain variation with KVCO varies from 1.980GHz/V to 2.066GHz/V. Drawing 5.36mA-7.42mA from 1.2V, the phase noise is-95.9dBc/Hz to-98.5dBc/Hz at 1MHz offset across the tuning range by operating the transistors in Class-C mode. © 2016 IEEE.",,"C (programming language); Circuit oscillations; Frequency modulation; Frequency synthesizers; Oscillators (electronic); Oscillistors; Tuning; 65nm CMOS technology; Compensation circuits; Dead zones; Gain variations; Lc voltagecontrolled oscillator (VCO); Small gain; Tuning curve; Tuning ranges; Variable frequency oscillators",2-s2.0-85028639494
"Pugovkin A.A., Telyshev D.V.","Automated pediatric cardiovascular simulator for left ventricular assist device evaluation",2017,"2017 International Siberian Conference on Control and Communications, SIBCON 2017 - Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028511430&doi=10.1109%2fSIBCON.2017.7998543&partnerID=40&md5=cf2b904f7a3168e0ef68cc708d8f47bb","An automated pediatric cardiovascular simulator for left ventricular assist device evaluation and simulation of different heart failure states that includes pediatric mock circulation loop, pneumatic system, data acquisition system based on NI cDAQ and software developed in LabVIEW is described in this work. © 2017 IEEE.","cardiovascular; heart failure; mock circulation loop; NI cDAQ; NI LabVIEW; ventricular assist device","Cardiology; Computer programming languages; Computer software; Data acquisition; Fiber optic sensors; Pediatrics; cardiovascular; Heart failure; LabViEW; Mock circulation; Ventricular assist device; Left ventricular assist devices",2-s2.0-85028511430
"Sansyzbaevich I.S., Sansyzbaevich I.Z., Nurzhanuly N.N., Amergalievich M.S.","Development of algorithm flow graph, mealy automaton graph and mathematical models of microprogram control mealy automaton for microprocessor control device",2017,"2017 International Siberian Conference on Control and Communications, SIBCON 2017 - Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028512498&doi=10.1109%2fSIBCON.2017.7998502&partnerID=40&md5=caaa8718388064a71f6b438e45b01730","New specialized microprocessor means allowed a new approach to the building of automated control systems. Thus, there is a need to describe internal processes in a microprocessor device controlling a multimotor drive. The work contains the findings of the application of the finite automata theory that resulted in the development of mathematical models of automated control system for the asynchronous multimotor drive using Mealy apparatus. The work also proposes how to vividly describe the sequence of logical operations-underlying the creation of a programming language-of a digital control device with the use of an algorithm language and Boolean algebra for the automated operation of a microprocessor device, which allows raising the level of automatization of the asynchronous multimotor drive control system. © 2017 IEEE.","Mealy automaton; Microprocessor control system; multimotor asynchronous electrical drive","Automation; Boolean algebra; Control systems; Control theory; Digital control systems; Microprogramming; Automated control systems; Automated operations; Electrical drives; Mealy automatons; Microprocessor control; Microprocessor control system; Microprocessor devices; Specialized microprocessor; Flow graphs",2-s2.0-85028512498
"Benli A., Karataş M., Bakir Y.","An experimental study of different curing regimes on the mechanical properties and sorptivity of self-compacting mortars with fly ash and silica fume",2017,"Construction and Building Materials",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017132526&doi=10.1016%2fj.conbuildmat.2017.03.228&partnerID=40&md5=365fe9ed154c3fa0208af30e0ff183e8","This paper aims to investigate the effect of four different curing regimes namely; tap water curing (WC), wet sack curing (WSC), air curing (AC), and liquid paraffin wax curing (LPWC) and different curing times (3, 7, 28, 56 and 180 days) on the mechanical properties of self-compacting Mortars (SCMs). Binary mixtures of SCMs were prepared by replacing Portland cement with 10%, 20%, and 30% by weight of C class fly ash (FA) and 6%, 10%, 14% by weight of silica fume (SF). In ternary mixes, provided that mineral additive ratio doesn't exceed 30% of cement, 10% of FA with 6%, %10, % 14 of SF and %20 of FA with %6, %10 of SF were produced. The water-to-binder (w/b) ratio ranges from 0.37 to 0.48. A sum of 12 different mixtures with 630 kg/m3 binder were prepared to observe SCMs behaviour in fresh and hardened conditions. Mini slump flow diameter, viscosity and mini V-funnel flow time tests were performed to assess the fresh properties of SCMs containing FA and SF. Sorptivity tests were performed on cube specimens with the dimensions of 50 × 50 × 50 mm. Compressive and flexural tensile strengths of the hardened mortars were measured at 3, 7, 28, 56 and 180 days at different curing conditions. The best results for compressive strength at the end of 180 d were determined with 10% FA in binary combination at water curing and with %10FA + %6SF in ternary combination at wet sack curing. The best results for flexural strength at the end of 180 d were determined with control samples at LPWC curing and with %10 SF in binary combination at LPWC. SF10 has the lowest sorptivity coefficient with w/b ratio of 0.40. © 2017 Elsevier Ltd","Curing conditions; Fly ash; Fresh properties; Mechanical properties; Self-compacting mortar; Silica fume; Sorptivity","Binary mixtures; Binders; Bins; C (programming language); Cements; Compressive strength; Fly ash; Hardening; Mechanical properties; Mixtures; Mortar; Portland cement; Silica; Silica fume; Tensile strength; Binary combinations; Curing condition; Fresh properties; Liquid paraffins; Mineral additives; Self-compacting mortars; Sorptivity; Sorptivity coefficients; Curing",2-s2.0-85017132526
"Xia X., Bao L., Lo D., Xing Z., E. Hassan A., Li S.","Measuring Program Comprehension: A Large-Scale Field Study with Professionals",2017,"IEEE Transactions on Software Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028931582&doi=10.1109%2fTSE.2017.2734091&partnerID=40&md5=fca07ad04aede7b5d3ce0f7ff22fd4df","During software development and maintenance, developers spend a considerable amount of time on program comprehension activities. Previous studies show that program comprehension takes up as much as half of a developer&#x0027;s time. However, most of these studies are performed in a controlled setting, or with a small number of participants, and investigate the program comprehension activities only within the IDEs. However, developers&#x0027; program comprehension activities go well beyond their IDE interactions. In this paper, we extend our ActivitySpace framework to collect and analyze Human-Computer Interaction (HCI) data across many applications (not just the IDEs). We follow Minelli et al.&#x0027;s approach to assign developers&#x0027; activities into four categories: navigation, editing, comprehension, and other. We then measure the comprehension time by calculating the time that developers spend on program comprehension, e.g. inspecting console and breakpoints in IDE, or reading and understanding tutorials in web browsers. Using this approach, we can perform a more realistic investigation of program comprehension activities, through a field study of program comprehension in practice across a total of seven real projects, on 78 professional developers, and amounting to 3,148 working hours. Our study leverages interaction data that is collected across many applications by the developers. Our study finds that on average developers spend &#x223C;58% of their time on program comprehension activities, and that they frequently use web browsers and document editors to perform program comprehension activities. We also investigate the impact of programming language, developers&#x0027; experience, and project phase on the time that is spent on program comprehension, and we find senior developers spend significantly less percentages of time on program comprehension than junior developers. Our study also highlights the importance of several research directions needed to reduce program comprehension time, e.g., building automatic detection and improvement of low quality code and documentation, construction of software-engineering-specific search engines, designing better IDEs that help developers navigate code and browse information more efficiently, etc. IEEE","Browsers; Debugging; Field Study; Inference Model; Maintenance engineering; Navigation; Program Comprehension; Programming; Software; Time measurement","Air navigation; Computer debugging; Computer programming; Computer software; Computer software maintenance; Human computer interaction; Integrodifferential equations; Maintainability; Mathematical programming; Navigation; Program documentation; Search engines; Software design; Software engineering; Time measurement; Web browsers; Automatic Detection; Browsers; Field studies; Human computer interaction (HCI); Inference models; Program comprehension; Software development and maintenances; Working hours; Program debugging",2-s2.0-85028931582
"Shi X., Zhang J., Cui G., Deng N., Wang W., Wang Q., Tang B.","Photocatalytic H2 evolution improvement for H free-radical stabilization by electrostatic interaction of a Cu-BTC MOF with ZnO/GO",2017,"Nano Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026458932&doi=10.1007%2fs12274-017-1710-4&partnerID=40&md5=3f5c005f7ed7209fcb6d11325c1ad12d","Metal-organic frameworks (MOFs) are self-assembled molecular containers that can encapsulate and stabilize short-lived reaction intermediates. In this study, the Cu-benzene-1,3,5-tricarboxylate (BTC) MOF was incorporated in a ZnO/graphene oxide (GO) photocatalytic system by electrostatic interaction, and the obtained assembly showed improved hydrogen evolution activity. Electron spin resonance analysis was used to detect and monitor free radicals in the photocatalytic system, and demonstrated that Cu-BTC MOF could stabilize and extend the lifetime of free radicals, increasing the chance of H· radical recombination to form H2. This work provides a new strategy for designing highly efficient photocatalysts. [Figure not available: see fulltext.] © 2017 Tsinghua University Press and Springer-Verlag GmbH Germany","electrostatic interaction assembly; free radical stabilization; H2 evolution; metal-organic framework; photocatalysis","Crystalline materials; Electrostatic separators; Electrostatics; Java programming language; Magnetic moments; Photocatalysis; Reaction intermediates; Stabilization; H<sub>2</sub> evolution; Hydrogen evolution; Metal organic framework; Metalorganic frameworks (MOFs); Molecular containers; Photocatalytic H2 evolution; Photocatalytic systems; Radical recombination; Free radicals",2-s2.0-85026458932
"Tolkachev M.M., Lobov E.M., Kandaurov N.A.","Algorithm elaboration of iterative processing of M-CPFSK signals in the ionospheric channel with selective interferences",2017,"2017 Systems of Signal Synchronization, Generating and Processing in Telecommunications, SINKHROINFO 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028536393&doi=10.1109%2fSINKHROINFO.2017.7997564&partnerID=40&md5=59bbaa57d921d8986d9d99f09a029767","In the report signal and code constructions (SCC) on the basis of continuous phase frequency shift key (CPFSK-64, CPFSK-256, CPFSK-1024) using low-speed turbo codes are provided. In the course of simulation program models of the modulator, demodulator, coder and decoder on a high-level language C++ were developed for application in system of simulation modeling of the digital communication systems Spectr-2. Codes were selected with the following code relations 5/16, 6/32, 7/64. The modulator and the demodulator has the user window from which it is supposed to select a type of modulation, modulation index and code rate. Sequences of synchronization was used during transmission of an information block in model of the system M-FSK of signal's synchronization. By transmission of a sequence of synchronization, it is supposed to transfer the sectional M-sequences. When carrying out the analysis it was supposed to research SCC in Watterson's channel with additive white Gaussian noise, and in the presence of selective interferences. Built-in models of the generator of white Gaussian noise, model of the channel of a Waterson and measuring units for data output were used in the diagram of the program complex Spectr-2. In this paper, the signal occupied bandwidth of the channel 40000 kHz. Selective interferences made 25 percent from bandwidth of all signal. Processing of SKK includes an algorithm of normalization of output responses of filters for reduction of influence of selective interferences in case of detection and restoration of a signal. With growth of number of frequencies in CPFSK, there was a difficulty of processing of a signal in a receiving part. For the solution of this problem of using frequency shift-keying 256 is change of the reference generator in the demodulator, which makes calculation of values of a complex signal. It allowed to reduce the number of the operations calculated for 1 clock period of the system Spectr-2. However, for modulation of CPFSK-1024 it was required to completely, change digital processing of the accepted signal. The solution was found in application digital the filter of bank. As a prototype the filter with band pass range of 150 Hz and a band of a barrage of 300 Hz with suppression 70 dB was selected. The order of the filter prototype is 32768. Characteristics of bit error rate and frame error rate in different conditions were received because of simulation. © 2017 IEEE.","CPFSK; digital signal processing; noise immunity; SPECTRUM-2","Application programs; Bandwidth; Bit error rate; C++ (programming language); Codes (symbols); Computer programming languages; Computer simulation languages; Computer software; Demodulators; Digital communication systems; Digital signal processing; Frequency shift keying; High level languages; Iterative methods; Modeling languages; Modulation; Modulators; Signal interference; Signal processing; Synchronization; Trellis codes; Turbo codes; White noise; Additive White Gaussian noise; CPFSK; Ionospheric channels; Iterative processing; Noise immunity; Reference generator; SPECTRUM-2; White Gaussian Noise; Gaussian noise (electronic)",2-s2.0-85028536393
"Chen J., Liu X.","A fast and accurate logarithm accelerator for scientific applications",2017,"Proceedings of the International Conference on Application-Specific Systems, Architectures and Processors",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028073331&doi=10.1109%2fASAP.2017.7995283&partnerID=40&md5=ff1d2d648de47a7f396641a24066a9b1","Many scientific applications rely on evaluation of elementary functions. Nowadays, high-level programming languages provide their own elementary function libraries in software by using lookup table and/or polynomial approximation. However, one downside is slow since lookup tables could keep cache thrashing and polynomial approximations require a number of iterations to converge. Thus, elementary functions evaluation becomes bottleneck for most scientific applications. With this motivation, we propose a generalized pipelined hardware architecture for elementary functions to accelerate scientific applications. This paper presents a pipelined, single precision logarithm hardware accelerator (SP-LHA). Throughput of SP-LHA is at least 2.5GFLOPS in 65nm ASICs, while the circuit consists of ≈60,000 logic gates. Average accuracy of SP-LHA is 22.5 out of 23 bits, which is achieved by using 7.8KB lookup table and parabolic interpolation. © 2017 IEEE.",,"Computer architecture; Function evaluation; Hardware; High level languages; Polynomial approximation; Table lookup; Elementary function; Hardware accelerators; High-level programming language; Number of iterations; Parabolic interpolation; Pipelined hardware; Scientific applications; Single precision; Pipeline processing systems",2-s2.0-85028073331
"Dang V., Skadron K.","Acceleration of Frequent Itemset Mining on FPGA using SDAccel and Vivado HLS",2017,"Proceedings of the International Conference on Application-Specific Systems, Architectures and Processors",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028071671&doi=10.1109%2fASAP.2017.7995279&partnerID=40&md5=33cc40334ad0649c59a27fee2d42b796","Frequent itemset mining (FIM) is a widely-used data-mining technique for discovering sets of frequently-occurring items in large databases. However, FIM is highly time-consuming when datasets grow in size. FPGAS have shown great promise for accelerating computationally-intensive algorithms, but they are hard to use with traditional HDL-based design methods. The recent introduction of Xilinx SDAccel development environment for the C/C++/OpenCL languages allows developers to utilize FPGA's potential without long development periods and extensive hardware knowledge. This paper presents an optimized implementation of an FIM algorithm on FPGA using SDAccel and Vivado HLS. Performance and power consumption are measured with various datasets. When compared to state-of-the-art solutions, this implementation offers up to 3.2× speedup over a 6-core CPU, and has a better energy efficiency as compared with a GPU. Our preliminary results on the new XCKU115 FPGA are even more promising: they demonstrate a comparable performance with a state-of-the-art HDL FPGA implementation and better performance compared to the GPU. © 2017 IEEE.","field-programmable gate array (FPGA); Frequent itemset mining; hardware acceleration; hardware description language (HDL); high-level synthesis (HLS)","C (programming language); Computer architecture; Data mining; Energy efficiency; Field programmable gate arrays (FPGA); Graphics processing unit; Hardware; High level languages; High level synthesis; Computationally intensive algorithms; Development environment; FPGA implementations; Frequent itemset mining; Hardware acceleration; Large database; Optimized implementation; State of the art; Computer hardware description languages",2-s2.0-85028071671
"Skrypnik O.N., Arefyeveva N.G.","Construction of an optimal flight trajectory in the glonass accuracy field",2017,"2017 24th Saint Petersburg International Conference on Integrated Navigation Systems, ICINS 2017 - Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028508152&doi=10.23919%2fICINS.2017.7995606&partnerID=40&md5=d73fe6f45477f4a19e58e75a245f1a27","Advanced technologies of air traffic management suggest changing-over to free routing (procedures for dynamic change in the flight route) in order to improve the efficiency of aviation transport. These technologies are based on the Performance-based Navigation (PBN) concept and the use of satellite navigation systems. However, the accuracy of such systems depends on the position of navigation satellites with respect to the user and is different in the provided airspace. That is why the optimal flight trajectory must be constructed with account of its reliability in the varying accuracy field of the satellite navigation system. The accuracy field can be defined by the values of the geometrical dilution of precision (GDOP). To construct the trajectory the authors relied on the optimization criterion and chose the A∗ algorithm (A star) implemented in the LabView graphical programming environment. The software package for simulating the GLONASS orbital movement and computing the accuracy fields within the provided airspace was implemented in the LabView as well. Using the mathematical modelling the authors constructed optimal flight trajectories in the GLONASS accuracy field with some prohibited zones within the provided airspace. © 2017 Concern CSRI Elektropribor, JSC.","accuracy field; an optimal trajectory; GLONASS; the geometrical dilution of precision","Air navigation; Air traffic control; Computer graphics; Computer programming languages; Free flight; Navigation systems; Orbits; Satellite navigation aids; Satellites; accuracy field; Air Traffic Management; Geometrical dilution of precision; GLONASS; Labview graphical programming; Optimal trajectories; Optimization criteria; Satellite navigation systems; Flight paths",2-s2.0-85028508152
"Lee M., Green B., Xie F., Tabellion E.","Vectorized production path tracing",2017,"Proceedings of High Performance Graphics, HPG 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028576915&doi=10.1145%2f3105762.3105768&partnerID=40&md5=28d7cde1738351a5d59e943454f235f8","This paper presents MoonRay, a high performance production rendering architecture using Monte Carlo path tracing developed at DreamWorks Animation. MoonRay is the first production path tracer, to our knowledge, designed to fully leverage Single Instruction/Multiple Data (SIMD) vector units throughout. To achieve high SIMD efficiency, we employ Embree for tracing rays and vectorize the remaining compute intensive components of the renderer: the integrator, the shading system and shaders, and the texturing engine. Queuing is used to help keep all vector lanes full and improve data coherency. We use the ISPC programming language [Intel 2011; Pharr and Mark 2012] to achieve improved performance across SSE, AVX/AVX2 and AVX512 instruction sets. Our system includes two functionally equivalent uni-directional CPU path tracing implementations: a C++ scalar depth-first version and an ISPC vectorized breadth-first wavefront version. Using side by side performance comparisons on complex production scenes and assets we show our vectorized architecture, running on AVX2, delivers between a 1.3× to 2.3× speed-up in overall render time, and up to 3×, 6×, and 4×, speed-ups within the integration, shading, and texturing components, respectively. © 2017 ACM.","Computer graphics; Monte Carlo; Path tracing; Production rendering; Vectorization","C++ (programming language); Computer graphics; Knowledge management; Monte Carlo methods; Complex production; Instruction set; Monte Carlo path tracing; Path tracing; Performance comparison; Shading systems; Single instruction/multiple datum; Vectorization; Rendering (computer graphics)",2-s2.0-85028576915
"Biswal D., Kusalik P.G.","Molecular simulations of self-assembly processes in metal-organic frameworks: Model dependence",2017,"Journal of Chemical Physics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026321284&doi=10.1063%2f1.4994700&partnerID=40&md5=d1e5a1d250a94ed103feb5ab8ecca897","Molecular simulation is a powerful tool for investigating microscopic behavior in various chemical systems, where the use of suitable models is critical to successfully reproduce the structural and dynamic properties of the real systems of interest. In this context, molecular dynamics simulation studies of self-assembly processes in metal-organic frameworks (MOFs), a well-known class of porous materials with interesting chemical and physical properties, are relatively challenging, where a reasonably accurate representation of metal-ligand interactions is anticipated to play an important role. In the current study, we both investigate the performance of some existing models and introduce and test new models to help explore the self-assembly in an archetypal Zn-carboxylate MOF system. To this end, the behavior of six different Zn-ion models, three solvent models, and two ligand models was examined and validated against key experimental structural parameters. To explore longer time scale ordering events during MOF self-assembly via explicit solvent simulations, it is necessary to identify a suitable combination of simplified model components representing metal ions, organic ligands, and solvent molecules. It was observed that an extended cationic dummy atom (ECDA) Zn-ion model combined with an all-atom carboxylate ligand model and a simple dipolar solvent model can reproduce characteristic experimental structures for the archetypal MOF system. The successful use of these models in extensive sets of molecular simulations, which provide key insights into the self-assembly mechanism of this archetypal MOF system occurring during the early stages of this process, has been very recently reported. © 2017 Author(s).",,"Assembly; Carboxylation; Crystalline materials; Java programming language; Ligands; Metal ions; Metals; Molecular dynamics; Molecular structure; Porous materials; Solvents; Zinc; Chemical and physical properties; Metal organic framework; Metal-ligand interactions; Metalorganic frameworks (MOFs); Molecular dynamics simulations; Molecular simulations; Self assembly process; Structural and dynamic properties; Self assembly",2-s2.0-85026321284
"Feng C., Li T., Chen Z., Pan Y., Zhou M.","A rule-based system to support carbon resource planning under C&T conditions",2017,"14th International Conference on Services Systems and Services Management, ICSSSM 2017 - Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028604260&doi=10.1109%2fICSSSM.2017.7996174&partnerID=40&md5=feabe910fdf58b413813134b5670b590","As part of a larger research project, this study addresses issues of risk-based decision-making based on different decision-makers in carbon resource planning for manufacturers under the constraints of C&T, we specify their characterization of behavior, attitude to the C&T program, and design their rule-based expert system (RBS) respectively. we develop discrete-event simulation models for conservative decision-maker and proactive decision-maker to conduct experimental analyzes. More than three years of efforts have been made on extensive literature review and empirical studies (such as site-visits and meetings) to identify the problem and define system models for intended analysis. A baseline model has been implemented with ARENA © and limited experiments were conducted to verify the basic functions. While the preliminary results confirmed with the expectations about the system behavior and validated the original ideas, tremendous work remains in terms of model implementation, modification and experiments. © 2017 IEEE.",,"Decision making; Discrete event simulation; Expert systems; Resource allocation; Baseline models; Carbon resources; Decision makers; Empirical studies; Literature reviews; Risk based decision making; Rule based expert systems; System models; C (programming language)",2-s2.0-85028604260
"Konigsmark S.T.C., Chen D., Wong M.D.F.","High-Level Synthesis for side-channel defense",2017,"Proceedings of the International Conference on Application-Specific Systems, Architectures and Processors",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028084773&doi=10.1109%2fASAP.2017.7995257&partnerID=40&md5=55e77e5003014fb9dc8a050239e736ef","The Internet of Things (IoT) and cloud computing rely on strong confidence in security of confidential or highly privacy sensitive data. Therefore, side-channel leakage is an important threat, but countermeasures require expert-level security knowledge for efficient application, limiting adoption. This work addresses this need by presenting the first High-Level Synthesis (HLS) flow with primary focus on side-channel leakage reduction. Minimal security annotation to the high-level C-code is sufficient to perform automatic analysis of security critical operations with corresponding insertion of countermeasures. Additionally, imbalanced branches are detected and corrected. For practicality, the flow can meet both resource and information leakage constraints. The presented flow is extensively evaluated on established HLS benchmarks and a general IoT benchmark. Under identical resource constraints, leakage is reduced between 32% and 72% compared to the reference. Under leakage target, the constraints are achieved with 31% to 81% less resource overhead. © 2017 IEEE.","High-Level Synthesis; Security; Side-Channel Leakage","C (programming language); Computer architecture; Internet of things; Side channel attack; Automatic analysis; Information leakage; Internet of thing (IOT); Resource Constraint; Security; Security-critical; Sensitive datas; Side-channel; High level synthesis",2-s2.0-85028084773
"Tsai C.-J., Lin C.-J., Chen C.-Y., Lin Y.-H., Ji W.-J., Hong S.-D.","Hardwiring the OS kernel into a Java application processor",2017,"Proceedings of the International Conference on Application-Specific Systems, Architectures and Processors",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028063968&doi=10.1109%2fASAP.2017.7995259&partnerID=40&md5=23dc493663efa15c30bf0359b61a3b0f","This paper presents the design and implementation of a hardwired OS kernel circuitry inside a Java application processor to provide the system services that are traditionally implemented in software. The hardwired system functions in the proposed SoC include the thread manager, the memory manager, and the I/O subsystem interface. There are many advantages in making the OS kernel a hardware component, such as a fast system boot time, highly efficient single-core multi-Thread context-switching performance, and a better potential for supporting a complex multi-level memory subsystem. In addition, since the target application processor used in this paper is based on a Java processor, the system is not susceptible to the stack and pointer-based security attacks that are common to the register-based processors. Full-system performance evaluations on an FPGA show that the proposed system is very promising for deeply-embedded multi-Thread applications. © 2017 IEEE.","Embedded application processors; Hardware memory managers; Hardware thread mangers; Java processors","Application programs; Computer software; Hardware; Java programming language; Managers; Memory architecture; System-on-chip; Design and implementations; Embedded application; Hardware components; Hardware threads; Java processors; Memory manager; System performance evaluation; Target application; Computer architecture",2-s2.0-85028063968
"Chew M.T., Demidenko S., Ooi M.P.-L., Kuang Y.C.","Family of low-cost NI ELVIS/LabVIEW-based semiconductor testers for engineering education",2017,"2017 IEEE International Conference on Computational Intelligence and Virtual Environments for Measurement Systems and Applications, CIVEMSA 2017 - Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028509118&doi=10.1109%2fCIVEMSA.2017.7995320&partnerID=40&md5=6f4b671bebc13945a3633734d8ac54d6","This paper presents a set of low-cost desktop IC test systems developed for engineering education. The set is implemented using the National Instrument (NI) Educational Laboratory Virtual Instrumentation Suite (ELVIS) and custom-made load boards. The software is based on the NI LabVIEW development environment. The set has been developed and employed for teaching electronic testing, instrumentation and measurement, and advanced electronic circuits courses within several undergraduate and graduate engineering programs at three universities in Malaysia, Vietnam, and New Zealand. © 2017 IEEE.","Analog Test; Digital Test; Electronic Testing; Engineering Education; Memory Test; Virtual Instrumentation","Artificial intelligence; Computer programming languages; Cost engineering; Distance education; Education; Engineering education; Teaching; Virtual reality; Analog test; Digital tests; Electronic testing; Memory tests; Virtual Instrumentation; E-learning",2-s2.0-85028509118
"Leo Kumar S.P.","Automation of tool path generation in multi-process micromachine tool for micromachining of prismatic and rotational parts",2017,"International Journal of Computer Integrated Manufacturing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026359109&doi=10.1080%2f0951192X.2017.1356471&partnerID=40&md5=e4510f224ebac7096aef49cb02782929","Computer numerical control (CNC) code generation is an inimitable activity of a Computer-aided manufacturing (CAM) system. Tool path formulation is considered as a machine-dependent activity, and expertise is essential to make attuned for a specific micromachine tool. This paper describes research for retrofitting of a multi-process micromachine tool for automatic CNC code generation for 2.5D micromachining. Micro turning, micro drilling and micro end milling processes are all considered. The proposed system comprises of three main elements: (i) part feature extraction through an extensible mark-up language (XML) schema, (ii) manufacturing logic formulation and CNC code generation by means of mathematical logic and (iii) online integration. XML-based feature extraction ensures trouble-free integration with the decision-making system. Automation of CNC code generation eliminates the need of human expertise, avoids compatibility issues and minimises program creation time. The developed system integrated with the micromachine tool through communication interface for real-time micromachining. The proposed system is intended for 2.5D machining of miniature and micro parts with external step, hole and slot features. The developed system performance has been validated through case study implementations. © 2017 Informa UK Limited, trading as Taylor & Francis Group","automation; computer numerical control; Micromachining; part program","Automatic programming; Automation; Codes (symbols); Composite micromechanics; Computer aided manufacturing; Extraction; Feature extraction; Integration; Manufacture; Micromachining; Milling (machining); Numerical control systems; XML; Communication interface; Computer numerical control; Decision-making systems; Extensible Mark-Up language (XML); Micromachine tools; Online integration; Part programs; Tool path generation; Computer control systems",2-s2.0-85026359109
"Chen L., Cui M., Huang K., Xuanyuan Z.","Real-Time scene flow on COTS embedded systems by coarse-grained software pipeline",2017,"IEEE Intelligent Vehicles Symposium, Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028078244&doi=10.1109%2fIVS.2017.7995870&partnerID=40&md5=210f31a22f466798a09b2d309d671d53","Scene flow is a key function of stereo-based environment perception system for mobile robotics and autonomous vehicle. Due to the heavy computing requirement and the limited computing resource, parallelized and embedded algorithms become quite important for the application of the mobile robotics. This paper develops a cross-platform embedded scene flow algorithm by using a coarse-grained software pipeline and OpenCL programming language. Our OpenCL algorithm is tested on 10 video streams from different datasets with different scenarios on different commercial-off-The-shelf (COTS) hardware. The average frame rates for the 10 videos can reach about 50 fps on both GPU and mobile device. The peak frame rates for certain videos on GPU can reach almost 450 fps. We also demonstrate that the COTS platform can provide sufficient computing power for stereo-based perception algorithm potentially by using OpenCL programming. © 2017 IEEE.",,"Computer hardware description languages; Intelligent vehicle highway systems; Mobile devices; Pipelines; Real time systems; Robotics; Vehicles; Video streaming; Autonomous Vehicles; Commercial off-the-shelf hardwares; Computing power; Computing resource; Embedded algorithms; Environment perceptions; Mobile robotic; Software pipeline; Embedded systems",2-s2.0-85028078244
"Fibich C., Horauer M., Obermaisser R.","HLshield: A reliability enhancement framework for high-level synthesis",2017,"2017 12th IEEE International Symposium on Industrial Embedded Systems, SIES 2017 - Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028562677&doi=10.1109%2fSIES.2017.7993378&partnerID=40&md5=24352dcc61fcf3032f6b24dfe4b4e737","High-Level Synthesis (HLS) is more and more becoming an important part of the digital logic design flow. Rapid development of hardware offloading designs implemented in FPGA accelerators or in the programmable logic area of modern SoC FPGAs is facilitated by the ability of today's HLS tools to generate logic from generic programming languages such as C and C++. When such accelerators are used in applications requiring high reliability, such as safety-critical systems, the designer has to consider the possibility of soft errors occurring during run time. In this paper, the HLShield framework is proposed that aims at integrating approaches from previous work and novel techniques into the HLS process to eliminate the need to add fault tolerance functionality to the generated Hardware Description Language (HDL) code by hand. The proposed framework provides means for profiling the reliability of the original high-level source code. It allows to direct the generation of reliability-enhanced hardware descriptions by specifying the desired protection methods using source code annotations. Means for evaluating the reliability of the selected solution are also included in the framework. A proof of concept implementation for the proposed framework is presented which is able to protect registers and memories corresponding to selected variables in the original high-level source code with errorcorrecting codes. This process is supported by a profiling tool that suggests especially critical variables. The achieved reliability improvements were evaluated using fault injection experiments carried out on multiple protection levels of three use case designs. Evaluations showed that significant gains in reliability can be made when using the presented profiling approach to protect storage elements in the generated hardware. © 2017 IEEE.",,"Codes (symbols); Computer circuits; Computer hardware description languages; Computer programming languages; Embedded systems; Fault tolerance; Field programmable gate arrays (FPGA); Hardware; High level synthesis; Network function virtualization; Radiation hardening; Reliability; Safety engineering; System-on-chip; Critical variables; Digital logic design; Error correcting code; Generic programming languages; Hardware descriptions; Reliability enhancement; Reliability improvement; Safety critical systems; C++ (programming language)",2-s2.0-85028562677
"Lin F.Y.-S., Hsiao C.-H., Wen Y.-F., Chien P.-C.","Dynamical cloud hosts assignment to achieve cost-effectiveness in cloud radio access networks",2017,"International Conference on Ubiquitous and Future Networks, ICUFN",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028068029&doi=10.1109%2fICUFN.2017.7993799&partnerID=40&md5=f4815797108ffeb0744ae51a20b2cd80","Cloud radio access network (C-RAN) has been proposed as a core network in the fifth-gene rati on mobile communications system. The computing resources are clustered as a pool that is centralised management as a cloud. The pool provides flexible capabilities to satisfy variant demands with large scale processing. This work stands on an operator perspective to analyse a centralised management mechanism. The research problem is a type of knapsack and bin packing problems that is formulated as a mathematical formulation. The objective is to increase the revenue with minimal server operations cost. Two-phase approximation method is proposed. In phase I, a dynamic programming method is utilized for finding a set of tasks with maximum revenue. In Phase II, three modified Next-Fit, First-Fit, and Best-Fit schemes are developed for solving and evaluating the resource allocations to reduce the number of power-on servers. It presents a way to support operators determine how to allocate the cloud hosts by leveraging cloud technology. The finding can be used to improve resource utilization and achieve cost-effectiveness in C-RANs. © 2017 IEEE.","Approximation; C-RAN; Cost-effectiveness; Dynamic programming; Resource allocation","C (programming language); Cost effectiveness; Costs; Economics; Resource allocation; Approximation; Dynamic programming methods; Large-scale processing; Management mechanisms; Mathematical formulation; Mobile communications systems; Radio access networks; Resource utilizations; Dynamic programming",2-s2.0-85028068029
"Wang S., Deng W., Yang L., Tan Y., Xie Q., Yao S.","Copper-Based Metal-Organic Framework Nanoparticles with Peroxidase-Like Activity for Sensitive Colorimetric Detection of Staphylococcus aureus",2017,"ACS Applied Materials and Interfaces",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026310995&doi=10.1021%2facsami.7b07307&partnerID=40&md5=c312753771d2aa0fc99800931d18a5a3","Cu-MOF nanoparticles with an average diameter of 550 nm were synthesized from 2-aminoterephthalic acid and Cu(NO3)2 by a mixed solvothermal method. The Cu-MOF nanoparticles can show peroxidase-like activity that can catalyze 3,3′,5,5′-tetramethylbenzidine to produce a yellow chromogenic reaction in the presence of H2O2. The presence of abundant amine groups on the surfaces of Cu-MOF nanoparticles enables facile modification of Staphylococcus aureus (S. aureus) aptamer on Cu-MOF nanoparticles. By combining Cu-MOF-catalyzed chromogenic reaction with aptamer recognition and magnetic separation, a simple, sensitive, and selective colorimetric method for the detection of S. aureus was developed. © 2017 American Chemical Society.","chromogenic reaction; metal-organic framework; pathogenic bacteria; peroxidase-like activity; Staphylococcus aureus","Bacteria; Chromogenics; Colorimetry; Crystalline materials; Java programming language; Magnetic separation; Nanoparticles; Synthesis (chemical); Chromogenic reaction; Metal organic framework; Pathogenic bacterium; Peroxidase-like activities; Staphylococcus aureus; Metal nanoparticles",2-s2.0-85026310995
"Al-Falahy N., Alani O.Y.K.","The impact of base station antennas configuration on the performance of millimetre wave 5G networks",2017,"International Conference on Ubiquitous and Future Networks, ICUFN",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028084052&doi=10.1109%2fICUFN.2017.7993869&partnerID=40&md5=c41f75e52ff65ccac8ad3aa138b16a54","In this paper, two scenarios have been considered for millimetre wave base station configuration. In the first scenario, the approach of Distributed Base Station (DBS) with remote radio units (RRU) is chosen as the envisioned architecture for future 5G network. This approach is compatible with cloud radio access network (C-RAN), as it has easier scalability and compatibility with future network expansions and upgrades. RRU has been used in this work as a way to sidestep the limited coverage and poor channel condition, which characterise millimetre wave band. This will minimise the number of required sites installation for the same quality of service (QoS). The results of this approach have shown significant improvements in terms of User Equipment (UE) throughput, average cell throughput, and spectral efficiency. In the second scenario, optimising antenna element spacing is considered in the base station array. The results show significant improvement in the network performance and provide better performance for cell-edge users in terms of data throughput. © 2017 IEEE.","5G network; Antenna spacing; Distributed base station; Millimetre wave; RRH","5G mobile communication systems; Antenna arrays; Antennas; Base stations; C (programming language); Mobile telecommunication systems; Quality of service; Queueing networks; Throughput; Antenna spacings; Base station antennas; Channel conditions; Future networks; G-networks; Millimetre waves; Radio access networks; Spectral efficiencies; Millimeter waves",2-s2.0-85028084052
"Bae J., Choi J.S., Hwang S., Yun W.S., Song D., Lee J., Jeong N.C.","Multiple Coordination Exchanges for Room-Temperature Activation of Open-Metal Sites in Metal-Organic Frameworks",2017,"ACS Applied Materials and Interfaces",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026302752&doi=10.1021%2facsami.7b07299&partnerID=40&md5=0a2772f712a9e55d404eadce9cf96745","The activation of open coordination sites (OCSs) in metal-organic frameworks (MOFs), i.e., the removal of solvent molecules coordinated at the OCSs, is an essential step that is required prior to the use of MOFs in potential applications such as gas chemisorption, separation, and catalysis because OCSs often serve as key sites in these applications. Recently, we developed a ""chemical activation"" method involving dichloromethane (DCM) treatment at room temperature, which is considered to be a promising alternative to conventional thermal activation (TA), because it does not require the application of external thermal energy, thereby preserving the structural integrity of the MOFs. However, strongly coordinating solvents such as N,N-dimethylformamide (DMF), N,N-diethylformamide (DEF), and dimethyl sulfoxide (DMSO) are difficult to remove solely with the DCM treatment. In this report, we demonstrate a multiple coordination exchange (CE) process executed initially with acetonitrile (MeCN), methanol (MeOH), or ethanol (EtOH) and subsequently with DCM to achieve the complete activation of OCSs that possess strong extracoordination. Thus, this process can serve as an effective ""chemical route"" to activation at room temperature that does not require applying heat. To the best of our knowledge, no previous study has demonstrated the activation of OCSs using this multiple CE process, although MeOH and/or DCM has been popularly used in pretreatment steps prior to the TA process. Using MOF-74(Ni), we demonstrate that this multiple CE process can safely activate a thermally unstable MOF without inflicting structural damage. Furthermore, on the basis of in situ 1H nuclear magnetic resonance (1H NMR) and Raman studies, we propose a plausible mechanism for the activation behavior of multiple CE. © 2017 American Chemical Society.","chemical activation; dichloromethane treatment; in situ NMR; in situ Raman; metal-organic frameworks; multiple coordination exchange; open-metal sites; room-temperature activation","Crystalline materials; Dichloromethane; Dimethyl sulfoxide; Java programming language; Metals; Nuclear magnetic resonance; Organic solvents; Coordinating solvents; Dimethyl sulfoxide (DMSO); Metal organic framework; Metal sites; Metalorganic frameworks (MOFs); N ,N-Dimethylformamide; Situ nmr; Situ Raman; Chemical activation",2-s2.0-85026302752
"Sachdeva S., Koper S.J.H., Sabetghadam A., Soccol D., Gravesteijn D.J., Kapteijn F., Sudhölter E.J.R., Gascon J., De Smet L.C.P.M.","Gas Phase Sensing of Alcohols by Metal Organic Framework-Polymer Composite Materials",2017,"ACS Applied Materials and Interfaces",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026231900&doi=10.1021%2facsami.7b02630&partnerID=40&md5=c9b4c1d916f8d55c6c8a9fd0b242c6e8","Affinity layers play a crucial role in chemical sensors for the selective and sensitive detection of analytes. Here, we report the use of composite affinity layers containing Metal Organic Frameworks (MOFs) in a polymeric matrix for sensing purposes. Nanoparticles of NH2-MIL-53(Al) were dispersed in a Matrimid polymer matrix with different weight ratios (0-100 wt %) and drop-casted on planar capacitive transducer devices. These coated devices were electrically analyzed using impedance spectroscopy and investigated for their sensing properties toward the detection of a series of alcohols and water in the gas phase. The measurements indicated a reversible and reproducible response in all devices. Sensor devices containing 40 wt % NH2-MIL-53(Al) in Matrimid showed a maximum response for methanol and water. The sensor response time slowed down with increasing MOF concentration until 40 wt %. The half time of saturation response (τ0.5) increased by ∼1.75 times for the 40 wt % composition compared to devices coated with Matrimid only. This is attributed to polymer rigidification near the MOF/polymer interface. Higher MOF loadings (≥50 wt %) resulted in brittle coatings with a response similar to the 100 wt % MOF coating. Cross-sensitivity studies showed the ability to kinetically distinguish between the different alcohols with a faster response for methanol and water compared to ethanol and 2-propanol. The observed higher affinity of the pure Matrimid polymer toward methanol compared to water allows also for a higher uptake of methanol in the composite matrices. Also, as indicated by the sensing studies with a mixture of water and methanol, the methanol uptake is independent of the presence of water up to 6000 ppm of water. The NH2-MIL-53(Al) MOFs dispersed in the Matrimid matrix show a sensitive and reversible capacitive response, even in the presence of water. By tuning the precise compositions, the affinity kinetics and overall affinity can be tuned, showing the promise of this type of chemical sensors. © 2017 American Chemical Society.","capacitive detection; composites; gas sensors; impedance spectroscopy; metal organic frameworks; mixed matrix membranes","Aluminum; Capacitive sensors; Chemical analysis; Chemical detection; Chemical sensors; Coatings; Composite materials; Gases; Java programming language; Metallic matrix composites; Methanol; MOS devices; Organic polymers; Organometallics; Plastic coatings; Propanol; Spectroscopy; Capacitive detection; Capacitive transducers; Impedance spectroscopy; Metal organic framework; Metalorganic frameworks (MOFs); Mixed matrix membranes; Polymer composite materials; Sensor response time; Polymer matrix composites",2-s2.0-85026231900
"Chen D.-M., Zhang N.-N., Liu C.-S., Du M.","Dual-Emitting Dye@MOF Composite as a Self-Calibrating Sensor for 2,4,6-Trinitrophenol",2017,"ACS Applied Materials and Interfaces",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026322489&doi=10.1021%2facsami.7b07901&partnerID=40&md5=db60d5749b7e6b154cde6a4b73ca79f5","An anionic metal-organic framework (MOF) {(NH2Me2)[Zn3(μ3-OH)(tpt)(TZB)3](DMF)12}n (1, tpt = 2,4,6-tri(4-pyridyl)-1,3,5-triazine, H2TZB = 4-(1H-tetrazol-5-yl)benzoic acid and DMF = N,N-dimethylformamide), with both nanosized cages and partitions, has been solvothermally synthesized, which can serve as a crystalline vessel to encapsulate the fluorescent dye rhodamine 6G (Rh6G) via a ""bottle around ship"" approach. As a result, the obtained dye@MOF composite system features a blue emission of the ligand at 373 nm and a red emission of Rh6G at 570 nm when dispersed in solution, which could be used for decoding the trace amount of 2,4,6-trinitrophenol (TNP) by referring the peak-height ratio of each emission, even in coexistence with other potentially competitive nitroaromatic analytes. Furthermore, the observed fluorescence responses of the composite toward TNP are highly stable and reversible after recycling experiments. To the best of our knowledge, this is the first example of an MOF-implicated self-calibrated sensor for TNP detection. © 2017 American Chemical Society.","composite; dual-emitting; metal-organic framework; self-calibrated sensor; TNP detection","Aromatic compounds; Benzoic acid; Bottles; Calibration; Composite materials; Crystalline materials; Fluorescence; Organic solvents; Anionic metals; dual-emitting; Fluorescent dyes; Highly stables; Metal organic framework; N ,N-Dimethylformamide; Recycling experiments; Self-calibrating; Java programming language",2-s2.0-85026322489
"Klumperink E.A.M., Westerveld H.J., Nauta B.","N-path filters and mixer-first receivers: A review",2017,"Proceedings of the Custom Integrated Circuits Conference",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030450557&doi=10.1109%2fCICC.2017.7993643&partnerID=40&md5=a129d396c662c6c355f5060597d28453","To realize a Software Defined Radio covering the mainstream 0.5-6 GHz wireless communication bands, new SAW-less radio receiver architectures are being explored which realize selectivity in a more flexible and programmable fashion. N-path filters and mixer-first receivers can offer high-linearity high-Q RF-filtering around a center frequency defined by a digital clock, which offers the desired flexible programmability. This paper reviews recent research on N-path filters and mixerfirst receivers, identifies advances in performance analysis, circuit performance and applications. © 2017 IEEE.","CMOS; Frequency Translated filtering; Mixer-first reeceiver; N-path filter; passive mixer; reconfigurable radio; RF; software defined radio; switch-R-C circuit; wireless","Analog circuits; Bandpass filters; C (programming language); CMOS integrated circuits; Electric network analysis; Integrated circuit manufacture; Mixers (machinery); Radio; Radio receivers; Software radio; Switched filters; Wireless telecommunication systems; Circuit performance; Passive mixers; Performance analysis; Receiver architecture; Recent researches; Reconfigurable radios; Software-defined radios; Wireless communication bands; Mixer circuits",2-s2.0-85030450557
"Wang S., McGuirk C.M., Ross M.B., Wang S., Chen P., Xing H., Liu Y., Mirkin C.A.","General and Direct Method for Preparing Oligonucleotide-Functionalized Metal-Organic Framework Nanoparticles",2017,"Journal of the American Chemical Society",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026305804&doi=10.1021%2fjacs.7b05633&partnerID=40&md5=0a885d9f63e6833e33f9a3a85da3c11f","Metal-organic frameworks (MOFs) are a class of modular, crystalline, and porous materials that hold promise for storage and transport of chemical cargoes. Though MOFs have been studied in bulk forms, ways of deliberately manipulating the external surface functionality of MOF nanoparticles are less developed. A generalizable approach to modify their surfaces would allow one to impart chemical functionality onto the particle surface that is independent of the bulk MOF structure. Moreover, the use of a chemically programmable ligand, such as DNA, would allow for the manipulation of interparticle interactions. Herein, we report a coordination chemistry-based strategy for the surface functionalization of the external metal nodes of MOF nanoparticles with terminal phosphate-modified oligonucleotides. The external surfaces of nine distinct archetypical MOF particles containing four different metal species (Zr, Cr, Fe, and Al) were successfully functionalized with oligonucleotides, illustrating the generality of this strategy. By taking advantage of the programmable and specific interactions of DNA, 11 distinct MOF particle-inorganic particle core-satellite clusters were synthesized. In these hybrid nanoclusters, the relative stoichiometry, size, shape, and composition of the building blocks can all be independently controlled. This work provides access to a new set of nucleic acid-nanoparticle conjugates, which may be useful as programmable material building blocks and as probes for measuring and manipulating intracellular processes. © 2017 American Chemical Society.",,"Association reactions; Coordination reactions; Crystalline materials; Java programming language; Metals; Nanoparticles; Nucleic acids; Oligonucleotides; Porous materials; Chemical functionality; Co-ordination chemistries; Inter-particle interaction; Metal organic framework; Metalorganic frameworks (MOFs); Modified oligonucleotides; Nanoparticle conjugate; Surface Functionalization; Metal nanoparticles; DNA; metal organic framework; nanoparticle; phosphate; Article; interactions with DNA; phosphorus nuclear magnetic resonance; proton nuclear magnetic resonance; stoichiometry; synthesis; transmission electron microscopy",2-s2.0-85026305804
"Deepika K., Usha J.","Design & development of location identification using RFID with WiFi positioning systems",2017,"International Conference on Ubiquitous and Future Networks, ICUFN",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028090730&doi=10.1109%2fICUFN.2017.7993832&partnerID=40&md5=7fab8bb3acf2cc0c53733f70de71a9e0","Localization of an article in a bounded area can be attained by WiFi Positioning System (WPS). WPS is used to identify entities inside the human habitation area using radio waves collected by smart devices. The proposed system focuses to track an individual in a bounded environment. The recognition of the entity can be achieved by Radio Frequency Identification (RFID) transponders. The RFID trackers accomplish fingerprinting with the Unique Device Identification (UDI). The procedure is deployed using an RFID sensor based application which pinpoints the location of the personnel inside architectural frameworks. The position co-ordinates in the indoor area can be using the WiFi technology. The mechanism is split into two sections - Data Collection and Position Identification. The data collection combines the location information acquired from the sensor technologies. The identification of an individual with RFID transponders which results in the tracking of the entity. The location information obtained from the sensors are without time constraints and is updated in the RFID readers and databases including the last time zone. Design and development of the application from connecting to the sensor devices, distance estimation between the sensor devices and the entities, retrieval of the exact position information are deliberated. The pseudo code to connect to the nearest sensor device and obtain the location information is stated. The mechanism of the position estimation algorithm is executed using LabVIEW system design and development software. © 2017 IEEE.","Communication; Electromagnetic interference; Global positioning systems; Radio frequency; Satellite navigational system; Satellite network; Spread spectrum communications","Communication; Computer programming languages; Data acquisition; Electromagnetic pulse; Global positioning system; Location; Radio waves; Satellite communication systems; Signal interference; Spread spectrum communication; Transponders; Wireless local area networks (WLAN); Architectural frameworks; Location identification; Navigational systems; Radio frequencies; Radio frequency identification transponders; Satellite network; System design and development; Wi-Fi positioning system; Radio frequency identification (RFID)",2-s2.0-85028090730
"Ewert P.","Use of axial flux in the detection of electrical faults in induction motors",2017,"2017 International Symposium on Electrical Machines, SME 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028612680&doi=10.1109%2fISEM.2017.7993571&partnerID=40&md5=f914a087896253108337e52f5d9cac57","The article presents the possibility of using an axial flux in the detection of electrical faults in induction motors. The work presents results obtained for a faulty rotor squirrel cage and a stator winding short-circuit. Fault detection and identification is based on the analysis of symptoms obtained from the Fast Fourier Transform of a voltage induced by an axial flux in a measurement coil. The laboratory research was conducted on a small power induction motor using the LabView software. © 2017 IEEE.","axial flux; diagnostics; induction motor; rotor faults; stator faults","Computer programming languages; Electric fault location; Electric machinery; Fast Fourier transforms; Fault detection; Plasma diagnostics; Squirrel cage motors; Stators; Axial flux; Electrical faults; Fault detection and identification; Lab-view softwares; Measurement coils; Rotor fault; Stator fault; Stator winding short; Induction motors",2-s2.0-85028612680
"Hasan D., Lee C.","Hybrid metamatarial absorber enhanced sensing of Co2 gas in the 5-8 μm mid IR spectral window",2017,"TRANSDUCERS 2017 - 19th International Conference on Solid-State Sensors, Actuators and Microsystems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029396645&doi=10.1109%2fTRANSDUCERS.2017.7994136&partnerID=40&md5=1f47fd563483c6f5531671a14a44fee6","A novel hybrid polymer-metamaterial absorber approach is proposed for enhanced and selective optical sensing of CO2 gas in the 5-8 μm mid IR spectral window. By leveraging the mid IR dynamics of the chemical reactions of Polyethylenimine (PEI) CO2 recognition layer, we demonstrate a new class of sensor with ppm level limit of detection, fast response time (∼2 minutes) and small foot print (30μm by 30μm) at ambient temperature (25°C). The metamaterial route further offers large differential change of optical signal at the sensing wavelength. As a proof-of-concept, we report net absorption enhancement of 0.0282%/ppm and wavelength shift of 0.5319 nm/ppm by the scheme. The scheme holds promise for ultra-compact integration with CMOS compatible read out electronics and all-optical reset with low hysteresis and high reliability. © 2017 IEEE.",,"Actuators; C (programming language); Carbon dioxide; Chemical detection; Metamaterials; Microsystems; Transducers; Absorption enhancement; Fast response time; High reliability; Limit of detection; Metamaterial absorbers; Polyethylenimines; Readout Electronics; Recognition layer; Solid-state sensors",2-s2.0-85029396645
"Atilgan A., Islamoglu T., Howarth A.J., Hupp J.T., Farha O.K.","Detoxification of a Sulfur Mustard Simulant Using a BODIPY-Functionalized Zirconium-Based Metal-Organic Framework",2017,"ACS Applied Materials and Interfaces",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026315242&doi=10.1021%2facsami.7b05494&partnerID=40&md5=958f33f82327b2872ad1e1cfa9e5bdd0","Effective detoxification of chemical warfare agents is a global necessity. As a powerful photosensitizer, a halogenated BODIPY ligand is postsynthetically appended to the Zr6 nodes of the metal-organic framework (MOF), NU-1000, to enhance singlet oxygen generation from the MOF. The BODIPY/MOF material is then used as a heterogeneous photocatalyst to produce singlet oxygen under green LED irradiation. The singlet oxygen selectively detoxifies the sulfur mustard simulant, 2-chloroethyl ethyl sulfide (CEES), to the less toxic sulfoxide derivative (2-chloroethyl ethyl sulfoxide, CEESO) with a half-life of approximately 2 min. © 2017 American Chemical Society.","BODIPY; CEES; chemical warfare agents; heterogeneous catalysis; metal-organic framework; mustard gas; photocatalyst; singlet oxygen; sulfur mustard","Catalysis; Chemical warfare; Crystalline materials; Detoxification; Gas generators; Java programming language; Photocatalysts; Photosensitizers; Sulfur; BODIPY; CEES; Chemical warfare agents; Metal organic framework; Mustard Gas; Singlet oxygen; Sulfur mustard; Oxygen",2-s2.0-85026315242
"Dickerson T., Gazzillo P., Herlihy M., Koskinen E.","Adding concurrency to smart contracts",2017,"Proceedings of the Annual ACM Symposium on Principles of Distributed Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027842381&doi=10.1145%2f3087801.3087835&partnerID=40&md5=f3536b4ebd775784eabef068f4ed31a5","Modern cryptocurrency systems, such as Ethereum, permit complex financial transactions through scripts called smart contracts. These smart contracts are executed many, many times, always without real concurrency. First, all smart contracts are serially executed by miners before appending them to the blockchain. Later, those contracts are serially re-executed by validators to verify that the smart contracts were executed correctly by miners. Serial execution limits system throughput and fails to exploit today's concurrent multicore and cluster architectures. Nevertheless, serial execution appears to be required: contracts share state, and contract programming languages have a serial semantics. This paper presents a novel way to permit miners and validators to execute smart contracts in parallel, based on techniques adapted from software transactional memory. Miners execute smart contracts speculatively in parallel, allowing non-conflicting contracts to proceed concurrently, and ""discovering"" a serializable concurrent schedule for a block's transactions, This schedule is captured and encoded as a deterministic fork-join program used by validators to re-execute the miner's parallel schedule deterministically but concurrently. Smart contract benchmarks run on a JVM with ScalaSTM show that a speedup of 1.33x can be obtained for miners and 1.69x for validators with just three concurrent threads. © 2017 Association for Computing Machinery.",,"Distributed computer systems; Semantics; Block-chain; Cluster architecture; Concurrent threads; Financial transactions; Parallel schedules; Serial execution; Software transactional memory; System throughput; Miners",2-s2.0-85027842381
"Funabiki N., Wang Y., Ishihara N., Kao W.-C.","An offline answering function for code writing problem in Java Programming Learning Assistant System",2017,"2017 IEEE International Conference on Consumer Electronics - Taiwan, ICCE-TW 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028505363&doi=10.1109%2fICCE-China.2017.7991085&partnerID=40&md5=4d2e65aabd90c1f44ba599229e842ef0","In order to promote Java programming educations, the Web-based Java Programming Learning Assistant System (JPLAS) has been implemented. JPLAS provides the code writing problem, where students write Java codes that satisfy the given specifications and submit them to the JPLAS server to obtain the marks using test codes instantly. Unfortunately, JPLAS could be accessed simply when the Internet connections are available. In this study, we perform the offline answering function for the code writing problem for use of JPLAS even in places without the Internet connections. First, the teacher downloads the assignment files from the server and delivers them to the students using USB memories. Next, students solve the assignments on Eclipse including code writing and testing, then submit the results to the teacher. Finally, the teacher uploads the results to the server. To evaluate the proposed function, the questionnaire will be collected after giving five assignments to six students in our group. © 2017 IEEE.",,"Codes (symbols); Computer programming; Encoding (symbols); Java programming language; Students; Teaching; Code-writing; Internet connection; Java codes; Java programming; Offline; Test code; Web based; Education",2-s2.0-85028505363
"Allen R.B.","Rich Semantics and Direct Representation for Digital Collections",2017,"Proceedings of the ACM/IEEE Joint Conference on Digital Libraries",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027999308&doi=10.1109%2fJCDL.2017.7991623&partnerID=40&md5=8ff6c3aaa1d9f7ccf01fcf5b935c80fc","It is now possible to envision the close integration of rich knowledge structures and knowledgebases with digital libraries. Yet, there are many challenges to the implementation of this vision. Chief among these is finding comprehensive and rigorous, but also flexible, representations. Such representations need to go beyond semantics strictly construed to include discourse, the evolution of knowledge, and support for alternate explanations. In this endeavor there are many traditions to draw from such as LIS, linguistics, programming languages, philosophy, jurisprudence, sociology, and systems analysis. While the most obvious application is to develop highly-structured scientific research reports, rich semantic information organization could be applied to areas including law, history, and biography. We propose a community-wide exploration of these issues and the development of a new generation of digital libraries. © 2017 IEEE.","Causation; Discourse; Events; Frames; Highly-Structured Repositories; History; Models; Ontologies; Programming Languages; Scholarly Resources; Science; Systems","Computer programming languages; Computer systems; History; Models; Ontology; Semantics; Systems analysis; Causation; Discourse; Events; Frames; Highly-Structured Repositories; Scholarly Resources; Science; Digital libraries",2-s2.0-85027999308
"Yin J., Pan C., Xiao K., Ye Y., Liu X., Xiao D.","Remote Monitoring System for Farmland Based on Wireless Image Sensor Network",2017,"Nongye Jixie Xuebao/Transactions of the Chinese Society for Agricultural Machinery",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029872296&doi=10.6041%2fj.issn.1000-1298.2017.07.036&partnerID=40&md5=3c09055f9e3d5e39c989598ad927c044","A remote monitoring system for farmland based on wireless image sensor network was put forward in order to obtain the farmland image and video information in real time. Aiming at the shortcomings of the current image sensor nodes, a low-cost high-resolution wireless image sensor node was designed based on CMOS image sensor chip and S3C6410 embedded processor. To ensure the stability and reliability of the node, the powerful embedded Linux operating system was employed as the software development platform. And based on this platform, a modular designing method was adopted to program the software system of the node in C/C++ language. Especially, a resolution adjustment algorithm based on driver and application layer cooperation was studied, which made the node had 10 different resolutions and the highest resolution was up to 5 mega pixels. More importantly, the resolution can be adjusted in real time according to the requirements of users when it was working, which made the node can meet the needs of users for different image accuracies. A wireless image sensor network was constructed by utilizing WiFi technology as well as the images and videos captured by the nodes were remotely transmitted to the server through the 4 G network. In order to prolong the life cycle of the node, a solar power supply system was designed. A visual farmland information management software Web-based was developed in order to effectively store, manage and use the data captured by the nodes, and a convenient method was provided for a user to remotely access the acquisition networks and the data stored in the server. The system was deployed and tested for a long time. The test results showed that the system could work stably, as well as capture and transmit images with different resolutions according to the remote instruction. Moreover, the average time to capture and transmit one image with size of about 126 KB was about 5.36 s, and the average packet loss ratio of the network was about 1.67%. In the tests, the average delay for the client to open video monitoring was about 3.48 s, and the video playing was smooth. Finally, the power supply system based on the solar energy could provide a stable power supply for the nodes in the long work. The tests validated that the remote monitoring system designed in this work can automatically capture images and videos of farmland in real time, transmit them to the server remotely, and satisfy the requirement of users for remote monitoring farmland. © 2017, Chinese Society of Agricultural Machinery. All right reserved.","Remote monitoring system; Resolution adjustment algorithm; Visual management software; Wireless image sensor network","C (programming language); Computer integrated manufacturing; Computer operating systems; Electric power systems; Farms; Image sensors; Information management; Life cycle; Pixels; Remote control; Sensor networks; Sensor nodes; Software design; Software reliability; Solar energy; Wi-Fi; Wireless sensor networks; Adjustment algorithms; Different resolutions; Embedded linux operating systems; Highest resolutions; Information management software; Remote monitoring system; Stability and reliabilities; Visual management; Monitoring",2-s2.0-85029872296
"Wang J., Niu X., Xu Z., Zheng C., Wang Y.","Monitoring System for CO2 Concentration in Greenhouse Based on Wireless Sensor Network",2017,"Nongye Jixie Xuebao/Transactions of the Chinese Society for Agricultural Machinery",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029836104&doi=10.6041%2fj.issn.1000-1298.2017.07.035&partnerID=40&md5=0298d76595facb2a9121835e2d1f365b","A CO2 concentration monitoring system targeting greenhouse application was designed, which included sensor nodes, CO2 concentration regulation node, wireless communication and PC terminals. A remote real-time CO2 concentration measurement was realized by using an infrared CO2 model S300 as the core model in sensor node. Environmental information derived by sensor nodes was transmitted to the PC software panel based on LabVIEW through wireless sensor networks. Received signal strength indication (RSSI) was sampled in transmission to ensure link quality and extend the service lives of sensor nodes by reasonably adjusting the transmission power. The designed and fabricated sensor node was calibrated and characterized by the standard CO2 samples distributed under laboratory conditions. The experiment results indicated that the limitation of detection of the selected sensor was lower than 5×10-5. The fluctuations for the long-term stability measurements on a 3×10-4 CO2 sample and a 6.5×10-4 CO2 sample were less than 2.6%. This designed monitoring system was deployed in the Guoxin picking garden in the town of Sheling, Shuangyang District, Changchun City, Jilin Province, and the field experiment was carried out in a solar greenhouse whose area was 640 m2. The desired CO2 concentration in greenhouse was set to 8×10-4, the fluctuation range under controlled CO2 concentration was nearly (8±0.42)×10-4. The designed sensor node had advantages, including miniaturization, cost-effective and high precision, which realized intelligent management, remote synchronization of greenhouse factors and smart regulation of CO2 concentration in greenhouse. © 2017, Chinese Society of Agricultural Machinery. All right reserved.","CO2 concentration sensor; Greenhouse; Monitoring system; Wireless sensor network","Carbon dioxide; Computer programming languages; Cost effectiveness; Greenhouses; Monitoring; Wireless sensor networks; Wireless telecommunication systems; CO2 concentration; Environmental information; Intelligent management; Laboratory conditions; Long term stability; Monitoring system; Received signal strength indication; Wireless communications; Sensor nodes",2-s2.0-85029836104
"Dou W., Xu X., Meng S., Zhang X., Hu C., Yu S., Yang J.","An energy-aware virtual machine scheduling method for service QoS enhancement in clouds over big data",2017,"Concurrency Computation ",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978417766&doi=10.1002%2fcpe.3909&partnerID=40&md5=45bc25a2459603c233f30583139a694c","Because of the strong demands of physical resources of big data, it is an effective and efficient way to store and process big data in clouds, as cloud computing allows on-demand resource provisioning. With the increasing requirements for the resources provisioned by cloud platforms, the Quality of Service (QoS) of cloud services for big data management is becoming significantly important. Big data has the character of sparseness, which leads to frequent data accessing and processing, and thereby causes huge amount of energy consumption. Energy cost plays a key role in determining the price of a service and should be treated as a first-class citizen as other QoS metrics, because energy saving services can achieve cheaper service prices and environmentally friendly solutions. However, it is still a challenge to efficiently schedule Virtual Machines (VMs) for service QoS enhancement in an energy-aware manner. In this paper, we propose an energy-aware dynamic VM scheduling method for QoS enhancement in clouds over big data to address the above challenge. Specifically, the method consists of two main VM migration phases where computation tasks are migrated to servers with lower energy consumption or higher performance to reduce service prices and execution time. Extensive experimental evaluation demonstrates the effectiveness and efficiency of our method. Copyright © 2016 John Wiley & Sons, Ltd. Copyright © 2016 John Wiley & Sons, Ltd.","cloud; energy-aware VM scheduling method; execution time; price; QoS enhancement","Cloud computing; Clouds; Costs; Data handling; Energy conservation; Energy utilization; Information management; Java programming language; Power management; Quality of service; Scheduling; Effectiveness and efficiencies; Execution time; Experimental evaluation; On-demand resource provisioning; Physical resources; Price; Scheduling methods; Virtual machine scheduling; Big data",2-s2.0-84978417766
"Guzmán P., Yate L., Sandoval M., Caballero J., Aperador W.","Characterization of the micro-abrasive wear in coatings of TaC-HfC/Au for biomedical implants",2017,"Materials",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026370594&doi=10.3390%2fma10080842&partnerID=40&md5=f1fca307ea4dbad7adb85209b1e3465a","The object of this work was the deposition of a Ta-Hf-C thin film with a gold interlayer on stainless steel, via the physical vapor deposition (PVD) technique, in order to evaluate the properties of different systems subjected to micro-abrasive wear phenomena generated by alumina particles in Ringer's solution. The surface characterization was performed using a scanning electron microscope (SEM) and atomic force microscope (AFM). The crystallographic phases exhibited for each coating were obtained by X-ray diffraction (XRD). As a consequence of modifying the composition of Ta-Hf there was evidence of an improvement in the micro-abrasive wear resistance and, for each system, the wear constants that confirm the enhancement of the surface were calculated. Likewise, these surfaces can be bioactive, generating an alternative to improve the biological fixation of the implants, therefore, the coatings of TaC-HfC/Au contribute in the development of the new generation of orthopedic implants. © 2017 by the authors.","Gold; Hafnium carbide; Micro-abrasion; Tantalum carbide; Wear","Abrasion; Abrasives; Alumina; Atomic force microscopy; Binary alloys; Biological implants; C (programming language); Carbides; Coatings; Deposition; Gold; Hafnium; Physical vapor deposition; Scanning electron microscopy; Stainless steel; Tantalum carbide; Vapor deposition; Wear of materials; Wear resistance; X ray diffraction; Biological fixation; Biomedical implants; Crystallographic phasis; Hafnium carbide; Microabrasion; Orthopedic implant; Ringer's solution; Surface characterization; Abrasive coatings",2-s2.0-85026370594
"Vanek J., Michalek J., Psutka J.","A GPU-Architecture Optimized Hierarchical Decomposition Algorithm for Support Vector Machine Training",2017,"IEEE Transactions on Parallel and Distributed Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028954180&doi=10.1109%2fTPDS.2017.2731764&partnerID=40&md5=0d61ba8917cfb08a9c7f07d2c19d31d3","In the last decade, several GPU implementations of Support Vector Machine (SVM) training with nonlinear kernels were published. Some of them even with source codes. The most effective ones are based on Sequential Minimal Optimization (SMO). They decompose the restricted quadratic problem into a series of smallest possible subproblems, which are then solved analytically. For large datasets, the majority of elapsed time is spent by a large amount of matrix-vector multiplications that cannot be computed efficiently on current GPUs because of limited memory bandwidth. In this paper, we introduce a novel GPU approach to the SVM training that we call Optimized Hierarchical Decomposition SVM (OHD-SVM). It uses a hierarchical decomposition iterative algorithm that fits better to actual GPU architecture. The low decomposition level uses a single GPU multiprocessor to efficiently solve a local subproblem. Nowadays a single GPU multiprocessor can run thousand or more threads that are able to synchronize quickly. It is an ideal platform for a single kernel SMO-based local solver with fast local iterations. The high decomposition level updates gradients of entire training set and selects a new local working set. The gradient update requires many kernel values that are costly to compute. However, solving a large local subproblem offers an efficient kernel values computation via a matrix-matrix multiplication that is much more efficient than the matrix-vector multiplication used in already published implementations. Along with a description of our implementation, the paper includes an exact comparison of five publicly available C++ SVM training GPU implementations. In this paper, the binary classification task and RBF kernel function are taken into account as it is usual in most of the recent papers. According to the measured results on a wide set of publicly available datasets, our proposed approach excelled significantly over the other methods in all datasets. The biggest difference was on the largest dataset where we achieved speed-up up to 12 times in comparison with the fastest already published GPU implementation. Moreover, our OHD-SVM is the only one that can handle dense as well as sparse datasets. Along with this paper, we published the source-codes at https://github.com/OrcusCZ/OHD-SVM. IEEE","CUDA; GPU; Graphics processing units; Kernel; Libraries; Open source software; Optimization; Optimization; Support vector machines; Support Vector Machines; SVM Training; Training","C++ (programming language); Computer graphics; Graphics processing unit; Iterative methods; Libraries; Multiprocessing systems; Open source software; Open systems; Optimization; Personnel training; Program processors; Publishing; Software engineering; Vectors; Binary classification; CUDA; Hierarchical decompositions; Kernel; Matrix matrix multiplications; Matrix vector multiplication; RBF kernel function; Sequential minimal optimization; Support vector machines",2-s2.0-85028954180
"Zheng J., Yu H., Guo Z., Cao W.","Numerical Analysis of the Stability of Widened Embankment under Rainfall Conditions",2017,"Hunan Daxue Xuebao/Journal of Hunan University Natural Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030623251&doi=10.16339%2fj.cnki.hdxbzkb.2017.07.019&partnerID=40&md5=29efc58be542a7acdf48c8216452f0e6","The simulation of saturated and unsaturated seepage under rainfall conditions was carried out by self-programming system using the built-in FISH language based on the seepage module of finite difference software FLAC3D and the unsaturated seepage theory. The pore water pressure and degree of saturation of the widened embankment under rainfall conditions were analyzed. The effects of geogrid reinforcement and permeability coefficient on the stability of the widened embankment were also investigated. The results show that the soil matric suction decreases rapidly and the slope reaches to saturated state and forms the transient saturated zone firstly. The safety factor of the widened embankment decreases obviously, considering the effect of rainfall infiltration. The geogrid reinforcement reduces the effect of rainfall infiltration on the stability of the widened embankment. Meanwhile, the permeability coefficient of the newly constructed embankment has large effect on the stability of the widened embankment under rainfall conditions. In practical engineering, the degree of compaction of the embankment fill should be guaranteed and the measures of slope protection should be taken to reduce the effect of the rainfall infiltration. © 2017, Editorial Department of Journal of Hunan University. All right reserved.","Numerical simulation; Pore water pressure; Rainfall infiltration; Stability; Widened embankment","Computer simulation; Computer simulation languages; Computer software; Convergence of numerical methods; Embankments; Geosynthetic materials; Pore pressure; Pressure distribution; Rain; Reinforcement; Safety factor; Seepage; Slope protection; Stability; Water; Degree of compaction; Degree of saturations; Geogrid reinforcement; Pore-water pressures; Practical engineering; Rainfall infiltration; Saturated and unsaturated seepage; Transient saturated zones; Infiltration",2-s2.0-85030623251
"Mondrus V., Sizov D.","Features of the solution of a problem of dynamics of a plate with use of the Python programming language",2017,"MATEC Web of Conferences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026370602&doi=10.1051%2fmatecconf%2f201711700126&partnerID=40&md5=1fc4f0983e4be39a2468b1b9312e9441","The article describes the features of the application of the modern general-purpose language Python for solving the dynamic problem of oscillations of a rectangular plate. The focus is often on libraries used for numerical computation and visualization of results. © The Authors, published by EDP Sciences, 2017.",,"High level languages; Dynamic problem; General purpose languages; Numerical computations; Python programming language; Rectangular plates; Plates (structural components)",2-s2.0-85026370602
"Jiménez-Gómez C.P., Cecilia J.A., Moreno-Tost R., Maireles-Torres P.","Nickel Phosphide/Silica Catalysts for the Gas-Phase Hydrogenation of Furfural to High–Added–Value Chemicals",2017,"ChemCatChem",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020419544&doi=10.1002%2fcctc.201700312&partnerID=40&md5=92dd4aac489873e87ee466b6f55de3e5","A series of Ni2P-based catalysts supported on a commercial silica with a metallic Ni loading of 5–20 wt. % and an initial P/Ni molar ratio of 0–3 was prepared by incipient wetness impregnation. Catalyst precursors were reduced and characterized by using XRD, CO chemisorption, NH3 temperature-programmed desorption, N2 adsorption–desorption at −196 °C, and X-ray photoelectron spectroscopy and then tested in the gas-phase hydrogenation of furfural. Almost full furfural conversion and a 2-methylfuran yield of 73 % can be achieved with the Ni2P-based catalyst with a Ni content of 15 wt. % at 190 °C after 5 h of time on stream. The high selectivity towards 2-methylfuran is attributed to both the high hydrogenating capacity of the metallic sites to lead to furfuryl alcohol and the presence of reduced P species that favor the hydrogenolysis process. However, catalysts undergo deactivation along the catalytic test because of the formation of carbonaceous deposits in the form of coke and adsorption of reactants and/or products. © 2017 Wiley-VCH Verlag GmbH & Co. KGaA, Weinheim","biomass; hydrogenation; nickel; reduction; supported catalysts","Aldehydes; Biomass; C (programming language); Catalysts; Desorption; Furfural; Gases; Hydrogenation; Mesoporous materials; Nickel; Reduction; Temperature programmed desorption; X ray photoelectron spectroscopy; Added-value chemicals; Adsorption desorption; Carbonaceous deposits; Catalyst precursors; Gas-phase hydrogenation; High selectivity; Incipientwetness impregnation; Nickel phosphide; Catalyst supports",2-s2.0-85020419544
"Li J., O'Donnell R.","Bounding laconic proof systems by solving CSPs in parallel",2017,"Annual ACM Symposium on Parallelism in Algorithms and Architectures",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027863512&doi=10.1145%2f3087556.3087557&partnerID=40&md5=d3aaf1535dc04d70acde4e7ef5f91418","We show that the basic semidefinite programming relaxation value of any constraint satisfaction problem can be computed in NC; that is, in parallel polylogarithmic time and polynomial work. As a complexity-theoretic consequence we get that MIP1[k, c, s] ⊆ PSPACE provided s/c ≤ (.62 - o(1))k/2k, resolving a question of Austrin, Håstad, and Pass. Here MIP1[k, c, s] is the class of languages decidable with completeness c and soundness s by an interactive proof system with k provers, each constrained to communicate just 1 bit. © 2017 Copyright held by the owner/author(s).","Complexity theory; Constraint satisfaction problems; Semidefinite programming",,2-s2.0-85027863512
"Fieker C., Hart W., Hofmann T., Johansson F.","Nemo/Hecke: Computer algebra and number theory packages for the Julia programming language",2017,"Proceedings of the International Symposium on Symbolic and Algebraic Computation, ISSAC",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027701473&doi=10.1145%2f3087604.3087611&partnerID=40&md5=f02452c48fb4d4669ad6e611a167837d","We introduce two new packages, Nemo and Hecke, written in the Julia programming language for computer algebra and number theory. We demonstrate that high performance generic algorithms can be implemented in Julia, without the need to resort to a lowlevel C implementation. For specialised algorithms, we use Julia's efficient native C interface to wrap existing C/C++ libraries such as Flint, Arb, Antic and Singular. We give examples of how to use Hecke and Nemo and discuss some algorithms that we have implemented to provide high performance basic arithmetic. © 2017 Copyright held by the owner/author(s).",,"C++ (programming language); Computation theory; Computer programming; Computer programming languages; Number theory; Computer algebra; Generic algorithm; Native c; Algebra",2-s2.0-85027701473
"Archibald B., Maier P., Stewart R., Trinder P., De Beule J.","Towards generic scalable parallel combinatorial search",2017,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029825330&doi=10.1145%2f3115936.3115942&partnerID=40&md5=f2aa3d3d55353c6d0de85a0c1465a5a2","Combinatorial search problems in mathematics, e.g. in finite geometry, are notoriously hard; a state-of-the-art backtracking search algorithm can easily take months to solve a single problem. There is clearly demand for parallel combinatorial search algorithms scaling to hundreds of cores and beyond. However, backtracking combinatorial searches are challenging to parallelise due to their sensitivity to search order and due to the their irregularly shaped search trees. Moreover, scaling parallel search to hundreds of cores generally requires highly specialist parallel programming expertise. This paper proposes a generic scalable framework for solving hard combinatorial problems. Key elements are distributed memory task parallelism (to achieve scale), work stealing (to cope with irregularity), and generic algorithmic skeletons for combinatorial search (to reduce the parallelism expertise required). We outline two implementations: a mature Haskell Tree Search Library (HTSL) based around algorithmic skeletons and a prototype C++ Tree Search Library (CTSL) that uses hand coded applications. Experiments on maximum clique problems and on a problem in finite geometry, the search for spreads in H(4, 22), show that (1) CTSL consistently outperforms HTSL on sequential runs, and (2) both libraries scale to 200 cores, e.g. speeding up spreads search by a factor of 81 (HTSL) and 60 (CTSL), respectively. This demonstrates the potential of our generic framework for scaling parallel combinatorial search to large distributed memory platforms. © 2017 Association for Computing Machinery.","Backtracking; Clique search; Combinatorics; Distributed computing; Finite geometry; Parallelism","C++ (programming language); Distributed computer systems; Geometry; Learning algorithms; Memory architecture; Musculoskeletal system; Parallel programming; Problem solving; Trees (mathematics); Backtracking; Clique search; Combinatorics; Finite geometry; Parallelism; Combinatorial mathematics",2-s2.0-85029825330
"Yang P., Dong F., codreanu V., Williams D., Roerdink J., Liu B., Anvari-Moghaddam A., Min G.","Improving Utility of GPU in Accelerating Industrial Applications with User-centred Automatic Code Translation",2017,"IEEE Transactions on Industrial Informatics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029166260&doi=10.1109%2fTII.2017.2731362&partnerID=40&md5=fc156a4990de885e4a71c7263a27b6be","SMEs (Small and medium-sized enterprises), particularly those whose business is focused on developing innovative produces, are limited by a major bottleneck on the speed of computation in many applications. The recent developments in GPUs have been the marked increase in their versatility in many computational areas. But due to the lack of specialist GPU (Graphics processing units) programming skills, the explosion of GPU power has not been fully utilized in general SME applications by inexperienced users. Also, existing automatic CPU-to-GPU code translators are mainly designed for research purposes with poor user interface design and hard-to-use. Little attentions have been paid to the applicability, usability and learnability of these tools for normal users. In this paper, we present an online automated CPU-to-GPU source translation system, (GPSME) for inexperienced users to utilize GPU capability in accelerating general SME applications. This system designs and implements a directive programming model with new kernel generation scheme and memory management hierarchy to optimize its performance. A web-service based interface is designed for inexperienced users to easily and flexibly invoke the automatic resource translator. Our experiments with non-expert GPU users in 4 SMEs reflect that GPSME system can efficiently accelerate real-world applications with at least 4x and have a better applicability, usability and learnability than existing automatic CPU-to-GPU source translators. IEEE","Acceleration; Automatic Translation; C++ languages; GPU; Graphics processing units; Linux; Parallel Computing; Programming; Tools; Usability; Usability",,2-s2.0-85029166260
[No author name available],"Proceedings of the International Symposium on Symbolic and Algebraic Computation, ISSAC",2017,"Proceedings of the International Symposium on Symbolic and Algebraic Computation, ISSAC",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027708662&partnerID=40&md5=4cee8107ba5cd91056011d7c74ee8b0b","The proceedings contain 61 papers. The topics discussed include: Aautomated geometric reasoning with geometric algebra: theory and practice; algorithmic approaches for lattice path combinatorics; on the extended Hensel construction and its application to the computation of limit points; an algorithm for computing minimal associated primes of binomial ideals without producing redundant components; rational points on the unit sphere: approximation complexity and practical constructions; a case study on the parametric occurrence of multiple steady states; projection and quantifier elimination using non-uniform cylindrical algebraic decomposition; discriminants of complete intersection space curves; criteria for finite difference GroÄbner bases of normal binomial difference ideals; Gcd modulo a primary triangular set of dimension zero; calculating the power residue symbol and Ibeta: applications of computing the group structure of the principal units of a p-adic number field completion; polynomial time interactive proofs for linear algebra with exponential matrix dimensions and scalars given by polynomial time circuits; on signature-based GroÄbner bases over Euclidean rings; Nemo/Hecke: computer algebra and number theory packages for the Julia programming language; an algebraic-geometric method for computing Zolotarev polynomials; and early termination in parametric linear system solving and rational function vector recovery with error correction.",,,2-s2.0-85027708662
"Gupta V., Irimia J., Pau I., Rodríguez-Patón A.","BioBlocks: Programming Protocols in Biology Made Easier",2017,"ACS Synthetic Biology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025170322&doi=10.1021%2facssynbio.6b00304&partnerID=40&md5=8659695dff6f8ee64ae1ea38dea56bf5","The methods to execute biological experiments are evolving. Affordable fluid handling robots and on-demand biology enterprises are making automating entire experiments a reality. Automation offers the benefit of high-throughput experimentation, rapid prototyping, and improved reproducibility of results. However, learning to automate and codify experiments is a difficult task as it requires programming expertise. Here, we present a web-based visual development environment called BioBlocks for describing experimental protocols in biology. It is based on Google's Blockly and Scratch, and requires little or no experience in computer programming to automate the execution of experiments. The experiments can be specified, saved, modified, and shared between multiple users in an easy manner. BioBlocks is open-source and can be customized to execute protocols on local robotic platforms or remotely, that is, in the cloud. It aims to serve as a de facto open standard for programming protocols in Biology. © 2017 American Chemical Society.","Blockly; high-level programming language; lab automation; rapid prototyping; reproducibility; Scratch","Article; biology; computer system; Internet; laboratory automation; priority journal; reproducibility; software",2-s2.0-85025170322
"Ferreira L.A., C. Bianchi R.A., Santos P.E., de Mantaras R.L.","Answer set programming for non-stationary Markov decision processes",2017,"Applied Intelligence",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025441238&doi=10.1007%2fs10489-017-0988-y&partnerID=40&md5=0da5b7d985c335b901107d2307c1b24e","Non-stationary domains, where unforeseen changes happen, present a challenge for agents to find an optimal policy for a sequential decision making problem. This work investigates a solution to this problem that combines Markov Decision Processes (MDP) and Reinforcement Learning (RL) with Answer Set Programming (ASP) in a method we call ASP(RL). In this method, Answer Set Programming is used to find the possible trajectories of an MDP, from where Reinforcement Learning is applied to learn the optimal policy of the problem. Results show that ASP(RL) is capable of efficiently finding the optimal solution of an MDP representing non-stationary domains. © 2017 Springer Science+Business Media New York","Action languages; Answer set programming; Markov decision processes; Non-determinism","Computer programming; Education; Logic programming; Markov processes; Action language; Answer set programming; Markov Decision Processes; Non Determinism; Nonstationary; Optimal policies; Optimal solutions; Sequential decision making; Reinforcement learning",2-s2.0-85025441238
"Zhuang Y.Y.","Query customization & trigger optimization on home care systems",2017,"Proceedings of the 2017 IEEE International Conference on Applied System Innovation: Applied System Innovation for Modern Technology, ICASI 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028555666&doi=10.1109%2fICASI.2017.7988514&partnerID=40&md5=5c58b0093d94f3611775e1ee15b8d95c","Epilepsy is a common neural disorder disease, while difficult to cure. There is still a risk of suffering from seizures even though patients have used antiepileptic drugs or had an operation. In such cases, patients must be immediately taken care; on the other hand, how to avoid introducing danger to their family and people around is also a concern. To address this issue, we integrate and develop a health cloud system to detect, record, and further predict epileptic seizure, which includes a dedicated wearable device for detection, a medical-IoT box to avoid heavy computation on the wearable device and provide cross reference to cameras, a cloud computing platform for complex computation, and an application on tablets for health care professionals. We propose a reactive and highly programmable model for such a system to allow health care professionals to easily and quickly query data from different devices and customize the trigger conditions, while optimize computing resource to achieve power saving on devices. We base this research on reactive programming (RP), which recently attracts the interests of researchers and developers, to construct our model, and develop a domain-specific language (DSL) that is applied among the medical-IoT box, cloud computing, and user interface for health care professionals. Such a DSL must be easy-To-write since health care professionals are not necessarily experts in programming, but it must also be powerful enough to allow them to query the logging data, analyze the interaction between different devices, and further configure the setting of devices for individual patients to benefit from our platform. At the same time, it automatically optimizes the communication and computation based the trigger conditions to achieve power saving on devices. © 2017 IEEE.","Domain-specific language; Epileptic seizure detection; Health cloud platform; Reactive programming","Cloud computing; Computer programming languages; Digital subscriber lines; Health care; Innovation; Internet of things; mHealth; Neurodegenerative diseases; Neurophysiology; Problem oriented languages; Search engines; User interfaces; Wearable technology; Antiepileptic drugs; Cloud computing platforms; Complex computation; Domain specific languages; Epileptic seizure detection; Health care professionals; Health clouds; Reactive programming; Distributed computer systems",2-s2.0-85028555666
"Mahmoudi S.A., El Adoui M., Belarbi M.A., Larhmam M.A., Lecron F.","Cloud-based platform for computer vision applications",2017,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030317396&doi=10.1145%2f3128128.3128158&partnerID=40&md5=0bba114593fe99ff3308abbcec4165dc","During last years, images and videos have become widely used in many daily applications. Indeed, they can come from cameras, smartphones, social networks of from medical devices. Generally, these images and videos are used for illustrating people or objects (cars, trains, planes, etc.) in many situations such as airports, train stations, public areas, sport events, hospitals, etc. Thus, image and video processing algorithms have got increasing importance, they are required from various computer visions applications such as motion tracking, real time event detection, database (images and videos) indexation and medical computer aided diagnosis methods.In this paper, we propose a cloud platform that integrates the above-mentioned methods, which are generally developed with popular open source image and video processing libraries (OpenCV1, OpenGL2, ITK3, VTK4, etc.). Theses modules are automatically integrated and configured in the cloud application. Thus, the platform users will have access to different computer vision techniques without the need to download, install and configure the corresponding software. Each guest can select the required application, load its data and get the output results in a safe and simple way. The cloud platform can handle the variety of Operating Systems and programming languages (C++, Java, Python, etc.). Experimentations were conducted within two kinds of applications. The first represents medical methods such as image segmentation in MR images, 3D image reconstruction from 2D radiographs, left ventricle segmentation and tracking from 2D echocardiography. The second kind of applications is related to video processing such as face, people and cars tracking, and abnormal event detection in crowd videos. © 2017 Association for Computing Machinery.","Cloud computing; Image and video processing; Medical image analysis; Video surveillance","Application programming interfaces (API); Biomedical equipment; C++ (programming language); Cloud computing; Computer aided diagnosis; Computer programming; Computer vision; Diagnosis; Distributed computer systems; Echocardiography; Image processing; Image segmentation; Magnetic resonance imaging; Medical image processing; Medical imaging; mHealth; Open source software; Security systems; Video signal processing; 3D image reconstruction; Abnormal event detections; Cloud based platforms; Computer vision applications; Computer vision techniques; Image and video processing; Segmentation and tracking; Video surveillance; Image reconstruction",2-s2.0-85030317396
"Lin C.-H., Liu J.-C., Peng T.-C.","Performance evaluation of cluster algorithms for Big Data analysis on cloud",2017,"Proceedings of the 2017 IEEE International Conference on Applied System Innovation: Applied System Innovation for Modern Technology, ICASI 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028553895&doi=10.1109%2fICASI.2017.7988182&partnerID=40&md5=bb0711a00acec5915ed799728aeb1832","In this study, based on clustering algorithms, we perform data mining on land price data in Taichung City during past ten years. For big data analysis, we combine Hadoop HDFS and MapReduce with R language and visualize results on Google Maps. We also study performances of K-means and Fuzzy C-means clustering algorithms, executed in the Hadoop cloud and a stand-Alone PC. The experimental results show that with a cloud of 9 compute nodes, about 3.5 times of acceleration are attainable; hence Hadoop cloud with R can be applied to solving insufficient memory issues in big data applications. © 2017 IEEE.","Cloud computing; Fuzzy C-Means; K-Means; R Language","Big data; C (programming language); Cloud computing; Data handling; Data mining; Fuzzy clustering; Fuzzy systems; Information analysis; Innovation; Big data applications; Cluster algorithms; Fuzzy C mean; Fuzzy c-means clustering algorithms; Google maps; K-means; R languages; Stand -alone; Clustering algorithms",2-s2.0-85028553895
"Kim S.-K., Likhachev M.","Parts assembly planning under uncertainty with simulation-aided physical reasoning",2017,"Proceedings - IEEE International Conference on Robotics and Automation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027963986&doi=10.1109%2fICRA.2017.7989468&partnerID=40&md5=d629628ccb4a25edbe1c9f13eaf525db","Parts assembly, in a broad sense, is to make multiple objects to be in specific relative poses in contact with each other. One of the major reasons that make it difficult is uncertainty. Because parts assembly involves physical contact between objects, it requires higher precision than other manipulation tasks like collision avoidance. The key idea of this paper is to use simulation-aided physical reasoning while planning with the goal of finding a robust motion plan for parts assembly. Specifically, in the proposed approach, a) uncertainty between object poses is represented as a distribution of particles, b) the motion planner estimates the transition of particles for unit actions (motion primitives) through physics-based simulation, and c) the performance of the planner is sped up using Multi-Heuristic A< (MHA<) search that utilizes multiple inadmissible heuristics that lead to fast uncertainty reduction. To demonstrate the benefits of our framework, motion planning and physical robot experiments for several parts assembly tasks are provided. © 2017 IEEE.",,"C (programming language); Motion planning; Robotics; Uncertainty analysis; Assembly planning; Distribution of particles; Manipulation task; Motion primitives; Multiple objects; Physical contacts; Physics-based Simulation; Uncertainty reduction; Robot programming",2-s2.0-85027963986
"Hnidka J., Rozehnal D.","Strain gauge measurement system with Wi-Fi data transfer in LabVIEW",2017,"ICMT 2017 - 6th International Conference on Military Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029385004&doi=10.1109%2fMILTECHS.2017.7988813&partnerID=40&md5=f3f4a06b0d228be7e8e9385c9d767aa0","A small strain gage measurement system was developed at the University of Defence in Brno. The system relays on N1 CompactDAQ hardware and LabVIEW software. The system serves as a functional demonstrator for larger systems, which will be designed in the future. The wiring can cause significant problems as the physical dimensions expand and, therefore, it was decided to solve the data transfer wirelessly. Two system architectures are introduced, which are then stress-tested and compared with the reference measurement performed via Ethernet. During the test, both architectures had to handle the same signal generated by arbitrary signal generator. Both of them managed the same task with significant differences. Based on the results of the test a system architecture was chosen. The program was written in LabVIEW and not only it displays data, it also logs them into TDMS file for further processing. © 2017 IEEE.","cDAQ; consumer-producer architecture; LabVIEW; National Instruments; time synchronization; Wi-Fi","Computer programming languages; Data transfer; Strain gages; Wi-Fi; Wireless local area networks (WLAN); cDAQ; Gauge measurements; LabViEW; National Instruments; Physical dimensions; Reference measurements; System architectures; Time synchronization; Computer architecture",2-s2.0-85029385004
"Liu Y.-F., Ji P.-Y., Xu J.-W., Hu Y.-Q., Liu Q., Luo W.-P., Guo C.-C.","Transition Metal-Free α-Csp3-H Methylenation of Ketones to Form C=C Bond Using Dimethyl Sulfoxide as Carbon Source",2017,"Journal of Organic Chemistry",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025116770&doi=10.1021%2facs.joc.7b00619&partnerID=40&md5=f51931efc602864e45143dee5b7df251","A direct α-Csp3-H methylenation of arylketones to form C=C bond using dimethyl sulfoxide as one-carbon source is achieved under transition metal-free reaction condition. Various aryl ketone derivatives react readily with DMSO, producing the α,β-unsaturated carbonyl compounds in yields of 42 to 90%. This method features a transition metal-free reaction condition, wide substrate scope and using DMSO as novel one-carbon source to form C=C bond, thus providing an efficient and expeditious approach to an important class of α,β-unsaturated carbonyl compounds. Based on the preliminary experiments, a plausible mechanism of this transformation is disclosed. © 2017 American Chemical Society.",,"Carbonyl compounds; Dimethyl sulfoxide; Ketones; Organic solvents; Transition metals; Unsaturated compounds; Arylketones; Carbon source; Metal-free reactions; Methylenation; Plausible mechanisms; Unsaturated carbonyl compounds; C (programming language); acetaldehyde; acetone; acetophenone derivative; aliphatic ketone; alpha monosubstituted ketone; carbonyl derivative; cyclic ketone; dimethyl sulfoxide; ketone derivative; phenylglyoxylic acid; propiophenone derivative; transition element; unclassified drug; Article; carbon source; chemical bond; chemical modification; controlled study; electron; mass fragmentography; methylenation",2-s2.0-85025116770
"Soni G., Megh G.","Experimental investigation of spectrum sensing for LTE frequency band based on USRP 2920/VST 5644",2017,"2016 International Conference on Control Instrumentation Communication and Computational Technologies, ICCICCT 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028631419&doi=10.1109%2fICCICCT.2016.7988062&partnerID=40&md5=1775ef3b61ab26660030fe58fc44142b","LTE has emerged as the most efficient and high speed 3rd generation mobile communication technology. A Experimental demonstrator has been implemented on a USRP 2920 LABVIEW 2012, It demonstrates the sensing algorithm on a real platform. In this paper, Experiment is conducted on spectrum sensing techniques using USRP 2920 and MIMO implementation based real time simulation set-up. Spectrum band around 2100 MHz at 1 MHz sampling rate has been chosen which falls in LTE down link band. USRP 2920 has been used in the experimental study. The focus of the paper is to bring out the uniqueness of using USRP in Software defined radio. The work presented in the paper primarily focuses on the concept of spectrum sensing using practical set-up based on USRP 2920/ VST 5644 and LabVIEW software platform for a LTE bases system at frequency of 2.1 GHz. © 2016 IEEE.","LabVIEW; LTE; USRP 2920","Computer programming languages; Frequency bands; Mobile telecommunication systems; Software radio; Experimental investigations; LabViEW; Mimo implementations; Mobile communication technology; Real time simulations; Software-defined radios; Spectrum sensing techniques; USRP 2920; Wireless telecommunication systems",2-s2.0-85028631419
"Ettifouri E.H., Rhouati A., Berrich J., Bouchentouf T.","Toward a merged approach for cross-platform applications (Web, Mobile and Desktop)",2017,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030309787&doi=10.1145%2f3128128.3128160&partnerID=40&md5=cd1ebc1136c6629463ed2b8a69d7b97e","Several approaches are available to create cross-platform applications. The majority of these approaches focus on purely mobile platforms. Their principle is to develop the application once and be able to deploy it to multiple mobile platforms with different operating systems (Android (Java), IOS (Objective C), Windows Phone 7 (C#),etc.). In this article, we propose a merged approach and cross-platform called ZCA ""ZeroCouplage Approach"". Merged to regroup the strong points of approaches: ""Runtime"", ""Component-Based"" and ""Cloud-Based"" thankto a design pattern whichwe created and named M2VC (Model-Virtual-View-Controller). Cross-platform allows creating a unique application that is deployable directly on many platforms: Web, Mobile and Desktop.In this article, we also compare our ZCA approach with others to approveits added value. Our idea, contrary to mobile approaches, consists ofa given technology to implement cross-platform applications. To validate our approach, we have developed anopen sourceframeworknamed ZCF ""ZeroCouplage Framework"" for Java technology. © 2017 Association for Computing Machinery.","Cloud-Based approach; Component-Based approach; Cross-platform (Web -mobile and desktop; M2VC pattern; Runtime approach; ZCA approach; ZCF; ZeroCouplage framework","Cellular telephone systems; Mergers and acquisitions; Mobile phones; Cloud-based; Component based approach; Cross-platform; M2VC pattern; Runtime approach; ZCA approach; ZeroCouplage framework; Java programming language",2-s2.0-85030309787
"Peng C.-J., Nguyen T.A., Rohtlaid K., Plesse C., Chen S.-J., Chassagne L., Cagneau B.","A versatile conducting interpenetrating polymer network for sensing and actuation",2017,"Proceedings - IEEE International Conference on Robotics and Automation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027969662&doi=10.1109%2fICRA.2017.7989497&partnerID=40&md5=4c8b8815c7ae03fcaea451a51676295d","This work deals with a Conducting-Interpenetrating Polymer Network (C-IPN). The C-IPN exhibits very interesting and promising properties which can make it suitable for applications in robotics as a tool to perform tasks in the fields of manipulation, grasping or force measurement. It is known in the literature that such C-IPN may be actuated and bended to interact with other objects. Some of them can also be used as sensors to characterize the interaction. In this paper, we show that actuation and sensing can be performed at the same time. Moreover, we propose analytical models which can be useful for future work to process the C-IPN output and to control them. All results are verified with experimental data. © 2017 IEEE.",,"Robotics; C (programming language)",2-s2.0-85027969662
"Potucek R.","Elementary solution to the jeep problem with one chief and two supporting vehicles",2017,"ICMT 2017 - 6th International Conference on Military Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029366122&doi=10.1109%2fMILTECHS.2017.7988738&partnerID=40&md5=b321da3926c890e7e6fda0291aa101f2","The jeep problem is a well known logistics problem. A jeep must cross a desert wider than it can travel on one tank of fuel with the help of optimal arrangement of fuel dumps along the route. The available resources refer, especially, to solutions of two basic variants-the single jeep problem and the convoy of jeeps problem. This contribution deals with one modification of the jeep problem with 3 vehicles and n cans of fuel (n > 3). Elementary solutions to this modification are detailed derived for small amounts n of cans of fuel. General solution to this problem using harmonic numbers is also stated. Numerical solutions for some of the outstanding amounts of fuel and units of distance, computed by the programming language of the computer algebra system Maple, are presented, too. © 2017 IEEE.","computer algebra system Maple; convoy of jeeps problem; harmonic numbers; Jeep problem","Algebra; Computer programming; Computer systems programming; Fuel tanks; Fuels; Computer algebra systems; convoy of jeeps problem; Elementary solutions; Harmonic number; Jeep problem; Logistics problems; Numerical solution; Optimal arrangement; Problem oriented languages",2-s2.0-85029366122
"Lam A.D.K.-T.","A study on fractal patterns for the textile design of the fashion design",2017,"Proceedings of the 2017 IEEE International Conference on Applied System Innovation: Applied System Innovation for Modern Technology, ICASI 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028568839&doi=10.1109%2fICASI.2017.7988605&partnerID=40&md5=70e8b0a229bff593196079e25f627797","Fractal sets are the geometry of chaos. It is an important branch in modern mathematics, so they are often used in graphic design, pattern design, fashion design and textile industries. The purpose of this paper is to propose a methodology for the generation method of Julia sets to generate fractal patterns for the textile design of the fashion design. The visual aesthetic fractal patterns are generated from Julia sets based on the escape time algorithm on complex plane. A pictorial information system is integrated through the application of Java programming language and development integration environment. Finally, the escape time algorithm has been proposed as the generation tools of highly visual aesthetic Fractal patterns. An example of practical applications will be presented to illustrate the usefulness of the proposed method. The results of the paper provide a powerful tool for the textile design of the fashion design. © 2017 IEEE.","Escape time algorithm; Fashion design; Fractal patterns; Julia sets; Textile design","Computer programming; Computer systems programming; Design; Fractals; Innovation; Set theory; Textiles; Escape time algorithm; Fashion design; Fractal patterns; Julia set; Textile designs; Textile industry",2-s2.0-85028568839
"Nouri-Borujerdi A., Moazezi A.","Investigation of obstacle effect to improve conjugate heat transfer in backward facing step channel using fast simulation of incompressible flow",2017,"Heat and Mass Transfer/Waerme- und Stoffuebertragung",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025450103&doi=10.1007%2fs00231-017-2086-4&partnerID=40&md5=d3026850af34d182bd9bd8ba11411eb6","The current study investigates the conjugate heat transfer characteristics for laminar flow in backward facing step channel. All of the channel walls are insulated except the lower thick wall under a constant temperature. The upper wall includes a insulated obstacle perpendicular to flow direction. The effect of obstacle height and location on the fluid flow and heat transfer are numerically explored for the Reynolds number in the range of 10 ≤ Re ≤ 300. Incompressible Navier-Stokes and thermal energy equations are solved simultaneously in fluid region by the upwind compact finite difference scheme based on flux-difference splitting in conjunction with artificial compressibility method. In the thick wall, the energy equation is obtained by Laplace equation. A multi-block approach is used to perform parallel computing to reduce the CPU time. Each block is modeled separately by sharing boundary conditions with neighbors. The developed program for modeling was written in FORTRAN language with OpenMP API. The obtained results showed that using of the multi-block parallel computing method is a simple robust scheme with high performance and high-order accurate. Moreover, the obtained results demonstrated that the increment of Reynolds number and obstacle height as well as decrement of horizontal distance between the obstacle and the step improve the heat transfer. © 2017 Springer-Verlag GmbH Germany","Flux-difference splitting; Heat transfer; Upwind compact scheme, multi-block approach","Application programming interfaces (API); Facings; Flow of fluids; Heat transfer; Incompressible flow; Laminar flow; Modeling languages; Reynolds number; Artificial compressibility method; Backward facing step channel; Compact finite difference schemes; Conjugate heat transfer; Fluid flow and heat transfers; Flux difference splitting; Incompressible Navier-Stokes; Multi blocks; Navier Stokes equations",2-s2.0-85025450103
"Rafieisakhaei M., Chakravorty S., Kumar P.R.","T-LQG: Closed-loop belief space planning via trajectory-optimized LQG",2017,"Proceedings - IEEE International Conference on Robotics and Automation",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028023472&doi=10.1109%2fICRA.2017.7989080&partnerID=40&md5=01aaec6ae947aa2e75da7ba65ce6ad63","Planning under motion and observation uncertainties requires the solution of a stochastic control problem in the space of feedback policies. In this paper, by restricting the policy class to the linear feedback polices, we reduce the general (n2 + n)-dimensional belief space planning problem to an (n)-dimensional problem. As opposed to the previous literature that search in the space of open-loop optimal control policies, we obtain this reduction in the space of closed-loop policies by obtaining a Linear Quadratic Gaussian (LQG) design with the best nominal performance. Then, by taking the entire underlying trajectory of the LQG controller as the decision variable, we pose a coupled design of the trajectory and estimator (while keeping the design of the controller separate) as a NonLinear Program (NLP) that can be solved by a general NLP solver. We prove that under a first-order approximation and a careful usage of the separation principle, our approximations are valid. We provide an analysis on the existing major belief space planning methods and show that our algorithm keeps the lowest computational burden while searching in the policy space. Finally, we extend our solution to contain general state and control constraints. Our simulation results support our design. © 2017 IEEE.",,"Controllers; Natural language processing systems; Nonlinear programming; Robotics; Stochastic control systems; Stochastic systems; Trajectories; Computational burden; Dimensional problems; First-order approximations; Linear quadratic Gaussian; Observation uncertainties; Open loop optimal control; Separation principle; State and control constraints; Feedback",2-s2.0-85028023472
"Zarra T., Chiheb R., Moumen R., Faizi R., El Afia A.","Topic and sentiment model applied to the colloquial Arabic: A case study of Maghrebi Arabic",2017,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030330181&doi=10.1145%2f3128128.3128155&partnerID=40&md5=84829596d22eee23d4395317b5b6eccc","Recently, the multiplication of communication and sharing platforms such as social networks, personal blogs, forums, etc., has facilitated the expression of views and opinions about products, personalities, and public policy. However, gathering these points of view is a complex task that requires resolution of many problems in different disciplines, especially issues related to our language. Among the research areas, topic modeling and sentiment analysis stimulates interest and curiosity of the scientific community. Lately, the current economic, geo-political and geostrategic trends have made researchers specifically more interested in Arabic language, except that the majority of these studies focus on the classical Arabic; nevertheless it is a language of the elites which is different from what is mainly used on the Web. Our paper focuses on Maghrebi colloquial Arabic since the little research that exists in this area is limited to East colloquial Arabic. On a corpus extracted from different Facebook pages we implemented a supervised approach to extract the sentiments, and an unsupervised approach to extract topic, then we proposed a new, semi-supervised, approach in the Arabic language that combines the topic and the sentiment in a single model, in order to join each topic to a specific sentiment. © 2017 Association for Computing Machinery.","Colloquial Arabic; Latent Dirichlet Allocution; Maghrebi Arabic; Naive Bayes; Sentiment Analysis; Topic modeling","Computer applications; Computer programming; Colloquial arabics; Dirichlet; Maghrebi Arabic; Naive bayes; Sentiment analysis; Topic Modeling; Data mining",2-s2.0-85030330181
"Radaković D., Herceg D.","Metadata specification in a dynamic geometry software",2017,"AIP Conference Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026625240&doi=10.1063%2f1.4992504&partnerID=40&md5=2243e2f9820d552bf067f9abb54ca837","Attributes in C# are a mechanism that provides association of declarative information with C# code such as classes, types, methods, properties, namespaces etc. Once defined and associated with a program entity, an attribute can be queried at run time. However, the attributes have certain restrictions which limit their application to representing complex metadata necessary for development of dynamic geometry software (DGS). We have devised a solution, independent of attributes, which was developed to overcome the limitations, while maintaining the functionality of attributes. Our solution covers a wide range of uses, from providing extensibility to a functional programming language and declaring new data types and operations, to being a foundation for runtime optimizations of expression tree evaluation, and helpful user interface features, such as code completion. © 2017 Author(s).","Attributes; Component development; DGS; Functional languages; Geometry software; Metadata",,2-s2.0-85026625240
"Klemenc M., Markopoulos A., Maršálek P.","Analysing of critical force effects of aircraft seat belt using truss elements",2017,"AIP Conference Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026644591&doi=10.1063%2f1.4992512&partnerID=40&md5=75a22b9f8941d06a2ec11b558ebfa231","This paper deals with the mathematical modelling of an aircraft seat belt crash test. The main goal is determination of a time course of the reactions in a lap belt anchoring points and their maximum values. This work was created on the basis of practical requirements from industry. Results are going to be reflected in developing a new type of aircraft seats. We mainly focus on the mathematical modelling of dynamic problems using the finite element method (FEM). Derived procedures are implemented in the Python programming language and are verified by several examples. A final calculation algorithm is applied on the analysis of the safety belt. We consider that a seat belt bending stiffness is very small compared to a tensile stiffness, therefore we used a 2D plane truss element. © 2017 Author(s).",,,2-s2.0-85026644591
"Duží M., Fait M., Menšík M.","Context recognition for a hyperintensional inference machine",2017,"AIP Conference Proceedings",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026670686&doi=10.1063%2f1.4992502&partnerID=40&md5=bb2321a789753c4195d419db1a28fea1","The goal of this paper is to introduce the algorithm of context recognition in the functional programming language TIL-Script, which is a necessary condition for the implementation of the TIL-Script inference machine. The TIL-Script language is an operationally isomorphic syntactic variant of Tichý's Transparent Intensional Logic (TIL). From the formal point of view, TIL is a hyperintensional, partial, typed λ-calculus with procedural semantics. Hyperintensional, because TIL λ-terms denote procedures (defined as TIL constructions) producing set-theoretic functions rather than the functions themselves; partial, because TIL is a logic of partial functions; and typed, because all the entities of TIL ontology, including constructions, receive a type within a ramified hierarchy of types. These features make it possible to distinguish three levels of abstraction at which TIL constructions operate. At the highest hyperintensional level the object to operate on is a construction (though a higher-order construction is needed to present this lower-order construction as an object of predication). At the middle intensional level the object to operate on is the function presented, or constructed, by a construction, while at the lowest extensional level the object to operate on is the value (if any) of the presented function. Thus a necessary condition for the development of an inference machine for the TIL-Script language is recognizing a context in which a construction occurs, namely extensional, intensional and hyperintensional context, in order to determine the type of an argument at which a given inference rule can be properly applied. As a result, our logic does not flout logical rules of extensional logic, which makes it possible to develop a hyperintensional inference machine for the TIL-Script language. © 2017 Author(s).","betaconversion by value; context recognition; three kinds of context; TIL-Script; Transparent Intensional Logic; λ-calculus",,2-s2.0-85026670686
"Cheng H., Xi C., Liu J., Han X., Wang Y., Liu W.","Design of PC-based quantitative split charging device for hydrogen isotope elemental gases",2017,"International Journal of Hydrogen Energy",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019101191&doi=10.1016%2fj.ijhydene.2017.04.175&partnerID=40&md5=ab4e17d629db3dc78e826abadafa97ef","A quantitative split charging device for hydrogen isotope elemental gases in the operation ranges of 10−5 Pa − 6 bar, 15–40 °C, and 10–500 sccm, controlled by a personal computer (PC) on the workbench of LabVIEW software, was carefully designed and constructed. In the device, volumetric charging mode and flow-controller charging mode can be adopted according to the molar quantity of split charging. The leakage rate and the quantitative split charging accuracy of the set-up were evaluated systemically. According to the experimental results of quantitative split charging from our device and mass comparator, this apparatus is well designed and assembled, and can guarantee 0.001 g quantitative split charging accuracy in the two charging modes. © 2017 Hydrogen Energy Publications LLC","Hydrogen isotopes; LabVIEW; Split charging","C (programming language); Computer programming languages; Personal computers; Charging modes; Flow controllers; Hydrogen isotope; Lab-view softwares; LabViEW; Molar quantity; Operation range; Split charging; Isotopes",2-s2.0-85019101191
"Whitaker T.J.L., Bobda C.","CAPSL: The Component Authentication Process for Sandboxed Layouts",2017,"Proceedings of IEEE Computer Society Annual Symposium on VLSI, ISVLSI",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027282149&doi=10.1109%2fISVLSI.2017.78&partnerID=40&md5=0de3e8c4d29973591a9072a18c0fa849","In this work, we propose a system-on-chip (SoC) design tool for the automatic generation of hardware sandboxes for securing untrusted IP to be integrated into trusted systems. The Component Authentication Process for Sandboxed Layouts (CAPSL) is a design flow that incorporates behavioral specifications of IP interfaces in order to generate sandboxes purposed for detecting trojan activation and isolating possible damage to a system at run-time. CAPSL adopts two formal models, interface automata and the Property Specification Language's sequential extended regular expressions (SERE), to generate reference monitors governing interactions of a collection of non-trusted IP. The sandbox partitions an untrusted sector that includes the non-secure IP and appropriate virtualized resources and controllers to isolate sandbox-system interactions upon deviation from the behavioral checkers. We review our design flow with an analysis of behavioral policy versatility and detection and defense mechanisms employed for various Trust-Hub.org benchmarks. Also presented is a brief resource evaluation highlighting CAPSL's reduced overhead compared to other run-time verification techniques. © 2017 IEEE.","CAPSL; Hardware Sandbox; Hardware Trojan","Authentication; Computer hardware; Computer programming languages; Damage detection; Distributed computer systems; Hardware; Hardware security; Programmable logic controllers; Specification languages; Specifications; System-on-chip; VLSI circuits; Automatic Generation; Behavioral specification; CAPSL; Extended regular expressions; Property specification language; Run-time verification; System on chip design; Virtualized resources; Integrated circuit design",2-s2.0-85027282149
"Witherspoon V.J., Yu L.M., Jawahery S., Braun E., Moosavi S.M., Schnell S.K., Smit B., Reimer J.A.","Translational and Rotational Motion of C8 Aromatics Adsorbed in Isotropic Porous Media (MOF-5): NMR Studies and MD Simulations",2017,"Journal of Physical Chemistry C",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026231468&doi=10.1021%2facs.jpcc.7b03181&partnerID=40&md5=6782d8e4c1de9fc8ac4f57e10ef47959","We combined nuclear magnetic resonance (NMR) and molecular dynamics (MD) simulation to study xylene behavior in MOF-5, probing the effects of adsorbate geometry in a weakly interacting model isotropic metal organic framework (MOF) system. We employed NMR diffusometry and relaxometry techniques at low field (13 MHz) to quantify the self-diffusion coefficients (Ds) and the longitudinal relaxation times (T1) of xylenes in MOF-5 as a function of temperature at the saturated loading for each xylene. These experiments reveal the translational motion activation energies to be 15.3, 19.7, and 21.2 kj mol-1 and the rotational activation energies to be 47.26, 12.88, and 11.55 for the (p-, m-, o-) xylene isomers, respectively. Paraxylene exhibits faster translational motion, yet shows four times the activation energy barrier for rotational motion vis-à-vis the other isomers. MD simulations performed on these model systems corroborate the findings for paraxylene and suggest that paraxylene has the lower free energy barrier for hopping away from its binding sites, yet has the slowest rotational motion in the plane of the xylene molecule. © 2017 American Chemical Society.",,"Binding sites; Chemical activation; Energy barriers; Isomers; Java programming language; Molecular dynamics; Nuclear magnetic resonance; Organometallics; Porous materials; Rotational flow; Xylene; Adsorbate-geometry; Longitudinal relaxation; Metal organic framework; Molecular dynamics simulations; Nuclear magnetic resonance(NMR); Rotational motion; Self-diffusion coefficients; Translational motions; Activation energy",2-s2.0-85026231468
"Mohd Sidek H.B., Jo Y.K., Kim T.W., Hwang Y.K., Chang J.-S., Hwang S.-J.","Enhancement of the Water Adsorptivity of Metal-Organic Frameworks upon Hybridization with Layered Double Hydroxide Nanosheets",2017,"Journal of Physical Chemistry C",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026234902&doi=10.1021%2facs.jpcc.7b02560&partnerID=40&md5=e43b31c95b69894b0b9daa668dca8c1c","Efficient water adsorbents with improved hydrostability can be synthesized by the hybridization of metal-organic framework (MOF) compounds with exfoliated layered double hydroxide (LDH) 2D nanosheets. The self-assembly between copper benzene tricarboxylate (Cu-BTC) MOF nanocrystals and exfoliated Mg-Al-LDH nanosheets leads to the nanoscale mixing of the MOF and LDH components, as well as to the prevention of the formation of aggregated secondary MOF particles. In the resulting nanohybrids, spherical Cu-BTC nanocrystals with small particle sizes of ∼5-10 nm are uniformly anchored on the surface of Mg-Al-LDH 2D nanosheets with the dimensions of several hundred nanometers. At the optimal composition, the surface area of the resulting nanohybrid becomes greater than that of pristine Cu-BTC, which is attributable to the suppression of the self-aggregation of MOF nanocrystals and to the formation of the mesoporous stacking structure of the LDH nanosheets. Of prime importance is that both the water adsorption ability and the hydrostability of Cu-BTC become notably improved upon hybridization with LDH nanosheets. The present study clearly demonstrates that exfoliated LDH nanosheets can be used as an effective hybridization matrix for exploring novel efficient MOF-based hybrid water adsorbents. © 2017 American Chemical Society.",,"Aluminum; Crystalline materials; Java programming language; Nanocrystals; Nanostructured materials; Layered double hydroxide nanosheets; Layered double hydroxides; Metal organic framework; Metal-organic framework compounds; Nano-scale mixing; Optimal composition; Small particle size; Stacking structures; Nanosheets",2-s2.0-85026234902
"Bhanja M., Ray B.","A Hierarchical and Programmable OTA-C Filter",2017,"Proceedings of IEEE Computer Society Annual Symposium on VLSI, ISVLSI",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027251929&doi=10.1109%2fISVLSI.2017.95&partnerID=40&md5=714f7fd63dec11da2feab71a27d1eba4","A systematic synthesis approach for designing a voltage-mode multifunction operational transconductance amplifier (OTA)-C biquadratic has been described using programmable first order filter. The proposed filter shows lower sensitivities, high frequency response, lower output noise. The proposed second order filter has been converted to third order butterworth and elliptic filter employing a single capacitor. Hierarchical analysis has been maintained through the synthesis of higher order band pass filter (BPF) and high pass filter (HPF) using the proposed biquadratic. All the proposed theory are validated with SPICE simulations. © 2017 IEEE.","Analog Filter; FPAA; OTA; Systematic Synthesis","Amplifiers (electronic); Bandpass amplifiers; Butterworth filters; C (programming language); Elliptic filters; Frequency response; High pass filters; Operational amplifiers; VLSI circuits; Analog filters; First-order filters; FPAA; Hierarchical analysis; High frequency response; Second order filters; Single capacitor; SPICE simulations; Bandpass filters",2-s2.0-85027251929
"Narmanlioglu O., Zeydan E.","Learning in SDN-based multi-tenant cellular networks: A game-theoretic perspective",2017,"Proceedings of the IM 2017 - 2017 IFIP/IEEE International Symposium on Integrated Network and Service Management",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029431745&doi=10.23919%2fINM.2017.7987414&partnerID=40&md5=ee32cad30fca8b7ac835e054f518e81f","In order to cope with the challenges of increasing user bandwidth demands as well as create new revenues by offering innovative services and applications, Mobile Network Operators (MNOs) are willing to increase their networks' capabilities by making it more flexible, programmable and agile. MNOs are also seeking new technologies to benefit from recent advances in cloud for rapid deployments and elastically scaling services that cloud providers are mostly benefiting today. On one hand, Software-Defined Networking (SDN) concept can be helpful for enabling network infrastructure sharing/slicing and elasticity for ""softwarization"" of network elements. On the other hand, machine learning and game-theoretical concepts can also be utilized to address network management and orchestration needs of services and applications and improve network infrastructure's operational needs. In that regard, joint utilization of machine learning, game theoretical approaches and SDN concepts for network slicing can be beneficial to MNOs as well as infrastructure providers. In this paper, we utilize regret-matching based learning approach for efficient Radio Remote Head (RRH) assignments among MNOs in software-defined based cloud radio access network (C-RAN). Using game-theoretical approach, we demonstrate convergence of RRH allocations to mixed strategy Nash equilibrium and present significant performance improvements compared to traditional assignment approach. © 2017 IFIP.","C-RAN; Game Theory; Machine Learning; Network Slicing; Software-Defined Networking","Artificial intelligence; C (programming language); Learning systems; Mobile telecommunication systems; Network function virtualization; Software defined networking; Telecommunication services; Wireless networks; Game-theoretic perspectives; Infrastructure providers; Mobile network operators; Network infrastructure; Network slicing; Radio access networks; Services and applications; Software defined networking (SDN); Game theory",2-s2.0-85029431745
"Remiro A., Arandia A., Bilbao J., Gayubo A.G.","Comparison of Ni Based and Rh Based Catalyst Performance in the Oxidative Steam Reforming of Raw Bio-Oil",2017,"Energy and Fuels",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025117554&doi=10.1021%2facs.energyfuels.7b00735&partnerID=40&md5=2d0f6de8832ffa1c29261a9418af5a93","The effect of O2 content in the oxidative steam reforming (OSR) of raw bio-oil has been studied, and the kinetic behavior, particularly deactivation, has been compared between two catalysts (Ni/La2O3-αAl2O3 and Rh/CeO2-ZrO2). The experiments have been carried out in an apparatus with two steps in series: (1) thermal treatment (at 500°C, for the controlled deposition of pyrolytic lignin) and (2) catalytic in-line reforming in a fluidized bed. The reaction conditions have been as follows: oxygen/carbon ratio (O/C), 0, 0.17, 0.34, and 0.67; 700°C; steam/carbon ratio (S/C), 6; space time, 0.3 gcatalysth/gbio-oil (for Ni/La2O3-αAl2O3) and 0.15 gcatalysth/gbio-oil (for Rh/CeO2-ZrO2); time on stream, 4 h. The content and morphology of the coke deposited on the catalysts has been determined by temperature-programmed oxidation (TPO), and the deterioration of the metallic properties of the catalysts by temperature-programmed reduction (TPR) and X-ray diffraction (XRD). The results (bio-oil conversion, product yield and their evolution with time on stream) show that for Rh/CeO2-ZrO2 catalyst the decrease in coke deposition as O/C ratio is increased involves attenuation of catalyst deactivation. Consequently, this catalyst is stable after 24 h operation for high O/C ratios, thus keeping constant the activity for reforming reactions and the WGS reaction, with a high yield of H2 and low yields of CO, CH4, and hydrocarbons. However, for the Ni/La2O3-αAl2O3 catalyst of lower activity than the Rh/CeO2-ZrO2, the decrease in coke content as O/C ratio is increased does not involve a noticeable attenuation in catalyst deactivation, which is due to Ni sintering. © 2017 American Chemical Society.",,"Biofuels; C (programming language); Catalyst activity; Catalyst deactivation; Catalysts; Catalytic reforming; Coke; Deposition; Fluidized beds; Nickel; Reforming reactions; Sintering; Water gas shift; X ray diffraction; Controlled deposition; Metallic properties; Oxidative steam reforming; Pyrolytic lignins; Reaction conditions; Rh-based catalyst; Temperature programmed oxidation; Temperature-programmed reduction; Steam reforming",2-s2.0-85025117554
"Uwagbole S.O., Buchanan W.J., Fan L.","Applied Machine Learning predictive analytics to SQL Injection Attack detection and prevention",2017,"Proceedings of the IM 2017 - 2017 IFIP/IEEE International Symposium on Integrated Network and Service Management",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029414065&doi=10.23919%2fINM.2017.7987433&partnerID=40&md5=7c56b0bcfdc14596d351a86cc5fa3efe","The back-end database is pivotal to the storage of the massive size of big data Internet exchanges stemming from cloud-hosted web applications to Internet of Things (IoT) smart devices. Structured Query Language (SQL) Injection Attack (SQLIA) remains an intruder's exploit of choice on vulnerable web applications to pilfer confidential data from the database with potentially damaging consequences. The existing solutions of mostly signature approaches were all before the recent challenges of big data mining and at such lacks the functionality and ability to cope with new signatures concealed in web requests. An alternative Machine Learning (ML) predictive analytics provides a functional and scalable mining to big data in detection and prevention of SQLIA. Unfortunately, lack of availability of readymade robust corpus or data set with patterns and historical data items to train a classifier are issues well known in SQLIA research. In this paper, we explore the generation of data set containing extraction from known attack patterns including SQL tokens and symbols present at injection points. Also, as a test case, we build a web application that expects dictionary word list as vector variables to demonstrate massive quantities of learning data. The data set is pre-processed, labelled and feature hashing for supervised learning. The trained classifier to be deployed as a web service that is consumed in a custom dot NET application implementing a web proxy Application Programming Interface (API) to intercept and accurately predict SQLIA in web requests thereby preventing malicious web requests from reaching the protected back-end database. This paper demonstrates a full proof of concept implementation of an ML predictive analytics and deployment of resultant web service that accurately predicts and prevents SQLIA with empirical evaluations presented in Confusion Matrix (CM) and Receiver Operating Curve (ROC). © 2017 IFIP.","SQL Injection; SQLIA; SQLIA analytics; SQLIA big data; SQLIA hashing","Application programming interfaces (API); Artificial intelligence; Classification (of information); Data mining; Digital storage; Internet of things; Learning systems; Predictive analytics; Query languages; Query processing; Web services; Websites; Applied machine learning; Internet of Things (IOT); Receiver operating curves; SQL injection; SQLIA; SQLIA analytics; SQLIA hashing; Structured query languages; Big data",2-s2.0-85029414065
"Rolim R., Soares G., D'Antoni L., Polozov O., Gulwani S., Gheyi R., Suzuki R., Hartmann B.","Learning syntactic program transformations from examples",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering, ICSE 2017",7,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019549570&doi=10.1109%2fICSE.2017.44&partnerID=40&md5=b3a45063807a0c115be86bd635b81949","Automatic program transformation tools can be valuable for programmers to help them with refactoring tasks, and for Computer Science students in the form of tutoring systems that suggest repairs to programming assignments. However, manually creating catalogs of transformations is complex and time-consuming. In this paper, we present REFAZER, a technique for automatically learning program transformations. REFAZER builds on the observation that code edits performed by developers can be used as input-output examples for learning program transformations. Example edits may share the same structure but involve different variables and subexpressions, which must be generalized in a transformation at the right level of abstraction. To learn transformations, REFAZER leverages state-of-The-Art programming-by-example methodology using the following key components: (a) a novel domain-specific language (DSL) for describing program transformations, (b) domain-specific deductive algorithms for efficiently synthesizing transformations in the DSL, and (c) functions for ranking the synthesized transformations. We instantiate and evaluate REFAZER in two domains. First, given examples of code edits used by students to fix incorrect programming assignment submissions, we learn program transformations that can fix other students' submissions with similar faults. In our evaluation conducted on 4 programming tasks performed by 720 students, our technique helped to fix incorrect submissions for 87% of the students. In the second domain, we use repetitive code edits applied by developers to the same project to synthesize a program transformation that applies these edits to other locations in the code. In our evaluation conducted on 56 scenarios of repetitive edits taken from three large C# open-source projects, REFAZER learns the intended program transformation in 84% of the cases using only 2.9 examples on average. © 2017 IEEE.","Program Synthesis; Program transformation; Refactoring; Tutoring Systems","Codes (symbols); Computer programming; Computer programming languages; Computer systems programming; Costs; Digital subscriber lines; Open source software; Problem oriented languages; Software engineering; Students; Computer science students; Open source projects; Program synthesis; Program transformations; Programming assignments; Programming by Example; Refactorings; Tutoring system; Education",2-s2.0-85019549570
"Coblenz M., Nelson W., Aldrich J., Myers B., Sunshine J.","Glacier: Transitive class immutability for Java",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering, ICSE 2017",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026767161&doi=10.1109%2fICSE.2017.52&partnerID=40&md5=40272f32d77e2a54391f1e511e34dd48","Though immutability has been long-proposed as a way to prevent bugs in software, little is known about how to make immutability support in programming languages effective for software engineers. We designed a new formalism that extends Java to support transitive class immutability, the form of immutability for which there is the strongest empirical support, and implemented that formalism in a tool called Glacier. We applied Glacier successfully to two real-world systems. We also compared Glacier to Java's final in a user study of twenty participants. We found that even after being given instructions on how to express immutability with final, participants who used final were unable to express immutability correctly, whereas almost all participants who used Glacier succeeded. We also asked participants to make specific changes to immutable classes and found that participants who used final all incorrectly mutated immutable state, whereas almost all of the participants who used Glacier succeeded. Glacier represents a promising approach to enforcing immutability in Java and provides a model for enforcement in other languages. © 2017 IEEE.","Empirical Studies Of Programmers; Immutability; Programming Language Usability","Program debugging; Software engineering; Empirical studies of programmers; Immutability; Real-world system; User study; Java programming language",2-s2.0-85026767161
"Behringer B., Palz J., Berger T.","PEoPL: Projectional Editing of Product Lines",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering, ICSE 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027730393&doi=10.1109%2fICSE.2017.58&partnerID=40&md5=913dc25a87721ca296b81c6a001dba3e","The features of a software product line-a portfolio of system variants-can be realized using various implementation techniques (a. k. a., variability mechanisms). Each technique represents the software artifacts of features differently, typically classified into annotative (e.g., C preprocessor) and modular representations (e.g., feature modules), each with distinct advantages and disadvantages. Annotative representations are easy to realize, but annotations clutter source code and hinder program comprehension. Modular representations support comprehension, but are difficult to realize. Most importantly, to engineer feature artifacts, developers need to choose one representation and adhere to it for evolving and maintaining the same artifacts. We present PEoPL, an approach to combine the advantages of annotative and modular representations. When engineering a feature artifact, developers can choose the most-suited representation and even use different representations in parallel. PEoPL relies on separating a product line into an internal and external representation, the latter by providing editable projections used by the developers. We contribute a programming-language-independent internal representation of variability, five editable projections reflecting different variability representations, a supporting IDE, and a tailoring of PEoPL to Java. We evaluate PEoPL's expressiveness, scalability, and flexibility in eight Java-based product lines, finding that all can be realized, that projections are feasible, and that variant computation is fast ( © 2017 IEEE.",,"Java programming language; Software engineering; External representations; Implementation techniques; Internal representation; Modular representations; Program comprehension; Software artifacts; Software Product Line; System variants; C (programming language)",2-s2.0-85027730393
"Christakis M., Emmisberger P., Godefroid P., Muller P.","A General Framework for Dynamic Stub Injection",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering, ICSE 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027683092&doi=10.1109%2fICSE.2017.60&partnerID=40&md5=077a585401f044cc7f22339284dc9cd8","Stub testing is a standard technique to simulate the behavior of dependencies of an application under test such as the file system. Even though existing frameworks automate the actual stub injection, testers typically have to implement manually where and when to inject stubs, in addition to the stub behavior. This paper presents a novel framework that reduces this effort. The framework provides a domain specific language to describe stub injection strategies and stub behaviors via declarative rules, as well as a tool that automatically injects stubs dynamically into binary code according to these rules. Both the domain specific language and the injection are language independent, which enables the reuse of stubs and injection strategies across applications. We implemented this framework for both unmanaged (assembly) and managed (.NET) code and used it to perform fault injection for twelve large applications, which revealed numerous crashes and bugs in error handling code. We also show how to prioritize the analysis of test failures based on a comparison of the effectiveness of stub injection rules across applications. © 2017 IEEE.",,"Codes (symbols); Computer aided software engineering; Computer programming languages; Network function virtualization; Problem oriented languages; Software engineering; Application under tests; Domain specific languages; Error handling codes; Fault injection; File systems; Language independents; Test failure; Program debugging",2-s2.0-85027683092
"Glissa G., Meddeb A.","IEEE 802.15.4 security sublayer for OMNET++",2017,"2017 13th International Wireless Communications and Mobile Computing Conference, IWCMC 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027867277&doi=10.1109%2fIWCMC.2017.7986572&partnerID=40&md5=235f1e4b2fbc33f3f57279460fec6958","Most network simulators do not support security features. In this paper, we introduce a new security module for OMNET++ that implements the IEEE 802.15.4 security suite. This module, developed using the C++ language, can simulate all devices and sensors that implement the IEEE 802.15.4 standard. The OMNET++ security module is also evaluated in terms of quality of services in the presence of physical hop attacks. Results show that our module is reliable and can safely be used by researchers. © 2017 IEEE.","6LoWPAN; AES-CCM; IEEE 802.15.4; Internet of Things; OMNET++; Security; WSNs","C++ (programming language); Computer software; Internet of things; Mobile computing; Wireless telecommunication systems; 6LoWPAN; AES-CCM; IEEE 802.15.4; OMNET; Security; WSNs; Standards",2-s2.0-85027867277
"Nguyen T.D., Nguyen A.T., Phan H.D., Nguyen T.N.","Exploring API embedding for API usages and applications",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering, ICSE 2017",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027719957&doi=10.1109%2fICSE.2017.47&partnerID=40&md5=44df7e4fc677cc3d0641b6902ecdce94","Word2Vec is a class of neural network models that as being trainedfrom a large corpus of texts, they can produce for each unique word acorresponding vector in a continuous space in which linguisticcontexts of words can be observed. In this work, we study thecharacteristics of Word2Vec vectors, called API2VEC or API embeddings, for the API elements within the API sequences in source code. Ourempirical study shows that the close proximity of the API2VEC vectorsfor API elements reflects the similar usage contexts containing thesurrounding APIs of those API elements. Moreover, API2VEC can captureseveral similar semantic relations between API elements in API usagesvia vector offsets. We demonstrate the usefulness of API2VEC vectorsfor API elements in three applications. First, we build a tool thatmines the pairs of API elements that share the same usage relationsamong them. The other applications are in the code migrationdomain. We develop API2API, a tool to automatically learn the APImappings between Java and C# using a characteristic of the API2VECvectors for API elements in the two languages: semantic relationsamong API elements in their usages are observed in the two vectorspaces for the two languages as similar geometric arrangements amongtheir API2VEC vectors. Our empirical evaluation shows that API2APIrelatively improves 22.6% and 40.1% top-1 and top-5 accuracy over astate-of-The-Art mining approach for API mappings. Finally, as anotherapplication in code migration, we are able to migrate equivalent APIusages from Java to C# with up to 90.6% recall and 87.2% precision. © 2017 IEEE.","API embedding; API usages; migration; Word2Vec","Codes (symbols); Semantics; Software engineering; Vector spaces; Vectors; API embedding; API usages; Continuous spaces; Empirical evaluations; migration; Neural network model; Semantic relations; Word2Vec; Java programming language",2-s2.0-85027719957
"Khatchadourian R., Masuhara H.","Automated Refactoring of Legacy Java Software to Default Methods",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering, ICSE 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027716666&doi=10.1109%2fICSE.2017.16&partnerID=40&md5=1e70ebaaf5b72fe1b6621011225a9fcb","Java 8 default methods, which allow interfaces to contain (instance) method implementations, are useful for the skeletal implementation software design pattern. However, it is not easy to transform existing software to exploit default methods as it requires analyzing complex type hierarchies, resolving multiple implementation inheritance issues, reconciling differences between class and interface methods, and analyzing tie-breakers (dispatch precedence) with overriding class methods to preserve type-correctness and confirm semantics preservation. In this paper, we present an efficient, fully-Automated, type constraint-based refactoring approach that assists developers in taking advantage of enhanced interfaces for their legacy Java software. The approach features an extensive rule set that covers various corner-cases where default methods cannot be used. To demonstrate applicability, we implemented our approach as an Eclipse plug-in and applied it to 19 real-world Java projects, as well as submitted pull requests to popular GitHub repositories. The indication is that it is useful in migrating skeletal implementation methods to interfaces as default methods, sheds light onto the pattern's usage, and provides insight to language designers on how this new construct applies to existing software. © 2017 IEEE.","default methods; interfaces; Java; refactoring","Computer software; Interfaces (materials); Semantics; Software architecture; Software design; Software engineering; default methods; Java; Method implementations; Refactorings; Software design patterns; Type constraints; Type correctness; Type hierarchies; Java programming language",2-s2.0-85027716666
"Sultana S., Arif F.","Computational conversion via translation rules for transforming C&#x002B;&#x002B; code into UPPAAL&#x0027;s automata",2017,"IEEE Access",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028909925&doi=10.1109%2fACCESS.2017.2728860&partnerID=40&md5=c525f83c31cb8f5a7c199b97691bdb57","Formal methods help in quantifying the functional and nonfunctional requirements that are later used in the verification process for safety assurance in real-time systems. System formalism is a crucial step in terms of exploring system&#x2019;s behavior and listing the non-functional requirements. In the context of real-time systems, the non-functional requirements refer to the verification properties of the system. Formalism in software development life cycle refines every process, starting from the formalization of system&#x0027;s requirements, analysis of system&#x0027;s behavior and exploring its properties, implementation of the problem&#x0027;s solution under consideration and verification of safety critical properties. Rule-based Expert System helps in inferring unknown on the basis of some known input, that is, knowledge and rule-set. Knowledge comprises of something known by an individual called an expert of that domain. It requires an expert skill set in order to model and verify some system in Model Checkers like UPPAAL. This research contribution has explored a variation of traffic light system&#x0027;s case study, modeled the system in UPPAAL model checker and later verified the safety critical properties of the generated system like safety, live-ness, fairness, reachability and deadlock freeness to cross-check the validity of transformation rule set. This research is focused on providing the rule-based expert system for inferring timed automata (input of UPPAAL Model Checker) on the basis of fact cum input, that is, C&#x002B;&#x002B; code. Structural facts are used along with the transformation rule set to get the timed automata that verify safety properties of selected case studies &#x2013; multiple variations of Traffic Light System. OAPA","Automaton; Formalism; Inference Engine; Knowledge base; Rule-based Expert System; UPPAAL Model Checker; Verification properties","Accident prevention; Automata theory; C (programming language); Computer software; Expert systems; Formal methods; Formal verification; Inference engines; Interactive computer systems; Knowledge based systems; Life cycle; Model checking; Safety engineering; Software design; Traffic signs; Verification; Automata; Automaton; Formalism; Knowledge base; Roads; Rule based expert systems; System recovery; Uppaal model checkers; Verification properties; Real time systems",2-s2.0-85028909925
"Landman D., Serebrenik A., Vinju J.J.","Challenges for static analysis of Java reflection-literature review and empirical study",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering, ICSE 2017",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027721960&doi=10.1109%2fICSE.2017.53&partnerID=40&md5=f7ab8fc7f1f23fe43423e250ce8c191a","The behavior of software that uses the Java Reflection API is fundamentally hard to predict by analyzing code. Only recent static analysis approaches can resolve reflection under unsound yet pragmatic assumptions. We survey what approaches exist and what their limitations are. We then analyze how real-world Java code uses the Reflection API, and how many Java projects contain code challenging state-of-The-Art static analysis. Using a systematic literature review we collected and categorized all known methods of statically approximating reflective Java code. Next to this we constructed a representative corpus of Java systems and collected descriptive statistics of the usage of the Reflection API. We then applied an analysis on the abstract syntax trees of all source code to count code idioms which go beyond the limitation boundaries of static analysis approaches. The resulting data answers the research questions. The corpus, the tool and the results are openly available. We conclude that the need for unsound assumptions to resolve reflection is widely supported. In our corpus, reflection can not be ignored for 78% of the projects. Common challenges for analysis tools such as non-exceptional exceptions, programmatic filtering meta objects, semantics of collections, and dynamic proxies, widely occur in the corpus. For Java software engineers prioritizing on robustness, we list tactics to obtain more easy to analyze reflection code, and for static analysis tool builders we provide a list of opportunities to have significant impact on real Java code. © 2017 IEEE.","Empirical Study; Java; Reflection; Static Analysis; Systematic Literature Review","Codes (symbols); Computer software; Java programming language; Reflection; Semantics; Software engineering; Trees (mathematics); Abstract Syntax Trees; Analysis approach; Descriptive statistics; Empirical studies; Java; Literature reviews; Research questions; Systematic literature review; Static analysis",2-s2.0-85027721960
"Xing S., Bing Q., Qi H., Liu J., Bai T., Li G., Shi Z., Feng S., Xu R.","Rational Design and Functionalization of a Zinc Metal-Organic Framework for Highly Selective Detection of 2,4,6-Trinitrophenol",2017,"ACS Applied Materials and Interfaces",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024904149&doi=10.1021%2facsami.7b06482&partnerID=40&md5=37b6776d3839cedad57c1dcd3f84b731","To develop potential metal-organic frameworks (MOFs) for 2,4,6-trinitrophenol (TNP) detection, an amino-functionalized Zn-MOF, [NH2(CH3)2][Zn4O(bpt)2(bdc-NH2)0.5]·5DMF (where H3bpt = biphenyl-3,4′,5-tricarboxylate, H2bdc-NH2 = 2-aminoterephthalic acid, and DMF = N,N-dimethylformamide), has been designed theoretically and synthesized experimentally. Its structure is composed of Zn4O(CO2)7 secondary building units linked by mixed ligands, exhibiting a three-dimensional framework. Fluorescence exploration revealed that the amino-functionalized Zn-MOF shows high selectivity and sensitivity for TNP, which agrees well with the predictions of theoretical simulations. This work provides a suitable means to develop new potential MOFs for TNP detection performance with a combination of experimental and theoretical perspectives. © 2017 American Chemical Society.","2,4,6-trinitrophenol (TNP); experimental synthesis; metal-organic framework; sensor; theoretical simulation","Crystalline materials; Java programming language; Organic solvents; Sensors; 2,4,6-trinitrophenol (TNP); 2-aminoterephthalic acids; Metal organic framework; Metalorganic frameworks (MOFs); N ,N-Dimethylformamide; Secondary building units; Theoretical simulation; Three-dimensional frameworks; Zinc",2-s2.0-85024904149
"Peng L., Asgari M., Mieville P., Schouwink P., Bulut S., Sun D.T., Zhou Z., Pattison P., Van Beek W., Queen W.L.","Using Predefined M3(μ3-O) Clusters as Building Blocks for an Isostructural Series of Metal-Organic Frameworks",2017,"ACS Applied Materials and Interfaces",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024861923&doi=10.1021%2facsami.7b06041&partnerID=40&md5=294d830808bd35510e8e3877dac82ded","Metal-organic frameworks (MOFs) have attracted much attention in the past decade owing to their unprecedented internal surface areas, tunable topologies, designable surfaces, and various potential applications. One bottleneck in the field regarding MOF synthesis is controlling the metal-containing secondary building unit (SBU) incorporated into the structure. In this work we report the synthesis and characterization of five trimeric [M3(μ3-O)(CH3CO2)6]x clusters (where M = Fe3+, Cr3+, Fe3+/Cr3+, Fe3+/Co2+, or Fe3+/Ni2+ and x = +1 or 0). The monocarboxylate capping ligand, acetate in this case, readily undergoes exchange with several difunctional counterparts, including 1,4-benzenedicarboxylic acid (H2-BDC) and biphenyl-4,4′-dicarboxylic acid (H2-BPDC), for the formation of an isostructural series of MOFs, several of which are newly reported (for M = Fe3+/Cr3+, Fe3+/Co2+, and Fe3+/Ni2+) and show excellent CO2 adsorption properties. In this report, a host of techniques including NMR, ICP, and ESI-MS are used to probe the ligand exchange process and composition of the SBUs, and XAS is used to monitor the Fe3+ and Cr3+ environment throughout the reactions, giving strong evidence that the clusters stay intact throughout the MOF synthesis. This work reveals that predefined SBUs is an effective means to create metal-substituted analogues of known frameworks. Further, CO adsorption and in situ IR are used to probe accessibility of the metals after solvent removal. We show for the first time that the incorporation of the neutral clusters, containing weaker Lewis acids like Ni2+ and Co2+, can promote the formation of open metal sites in the MOF frameworks, structural features known to enhance the binding energy of small guest molecules like CO2. © 2017 American Chemical Society.","cluster; CO2 adsorption; ligand exchange; metal-organic framework; secondary building block","Adsorption; Binding energy; Binding sites; Carbon dioxide; Chelation; Cobalt; Crystalline materials; Java programming language; Ligands; Metals; Nickel; Organic polymers; 1 ,4-benzenedicarboxylic acid; cluster; Ligand exchanges; Metal organic framework; Metalorganic frameworks (MOFs); Secondary building blocks; Secondary building units; Synthesis and characterizations; Cobalt compounds",2-s2.0-85024861923
"Gopalakrishnan R., Sharma P., Mirakhorli M., Galster M.","Can Latent Topics in Source Code Predict Missing Architectural Tactics?",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering, ICSE 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027701767&doi=10.1109%2fICSE.2017.10&partnerID=40&md5=a61cad6aed04d093f1088d2aaf2ca9fd","Architectural tactics such as heartbeat, resource pooling, and scheduling provide solutions to satisfy reliability, security, performance, and other critical characteristics of a software system. Current design practices advocate rigorous up-front analysis of the system's quality concerns to identify tactics and where in the code they should be used. In this paper, we explore a bottom-up approach to recommend architectural tactics based on latent topics discovered in the source code of projects. We present a recommender system developed by building predictor models which capture relationships between topical concepts in source code and the use of specific architectural tactics in that code. Based on an extensive analysis of over 116,000 open source systems, we identify significant correlations between latent topics in source code and the usage of architectural tactics. We use this information to construct a predictor for generating tactic recommendations. Our approach is validated through a series of experiments which demonstrate the ability to generate package-level tactic recommendations. We provide further validation via two large-scale studies of Apache Hive and Hadoop to illustrate that our recommender system predicts tactics that are actually implemented by developers in later releases. © 2017 IEEE.","Architectural design and implementation; emergent design; tactic recommender","Codes (symbols); Computer programming languages; Open source software; Quality control; Recommender systems; Software engineering; Software reliability; Bottom up approach; Design and implementations; Emergent design; Large-scale studies; Open source system; Resource pooling; System's quality; tactic recommender; Open systems",2-s2.0-85027701767
"He L.-B., Zhang L., Tan X.-D., Tang L.-P., Xu T., Zhou Y.-L., Ren Z.-Y., Wang Y., Teng C.-Y., Sun L.-T., Nie J.-F.","Surface Energy and Surface Stability of Ag Nanocrystals at Elevated Temperatures and Their Dominance in Sublimation-Induced Shape Evolution",2017,"Small",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019837857&doi=10.1002%2fsmll.201700743&partnerID=40&md5=a2da953d7c219c00a7f86c5927d5fd54","The surface energy and surface stability of Ag nanocrystals (NCs) are under debate because the measurable values of the surface energy are very inconsistent, and the indices of the observed thermally stable surfaces are apparently in conflict. To clarify this issue, a transmission electron microscope is used to investigate these problems in situ with elaborately designed carbon-shell-capsulated Ag NCs. It is demonstrated that the {111} surfaces are still thermally stable at elevated temperatures, and the victory of the formation of {110} surfaces over {111} surfaces on the Ag NCs during sublimation is due to the special crystal geometry. It is found that the Ag NCs behave as quasiliquids during sublimation, and the cubic NCs represent a featured shape evolution, which is codetermined by both the wetting equilibrium at the Ag–C interface and the relaxation of the system surface energy. Small Ag NCs (≈10 nm) no longer maintain the wetting equilibrium observed in larger Ag NCs, and the crystal orientations of ultrafine Ag NCs (≈6 nm) can rotate to achieve further shape relaxation. Using sublimation kinetics, the mean surface energy of Ag NCs at 1073 K is calculated to be 1.1–1.3 J m−2. © 2017 WILEY-VCH Verlag GmbH & Co. KGaA, Weinheim","Ag nanocrystals; kinetics; sublimation; surface energy; surface stability","C (programming language); Carbon; Crystal orientation; Enzyme kinetics; Interfacial energy; Nanocrystals; Sublimation; Thermodynamic stability; Transmission electron microscopy; Wetting; Ag nanocrystals; Carbon shells; Crystal geometry; Elevated temperature; Shape evolution; Shape relaxations; Surface stability; Thermally stable; Silver",2-s2.0-85019837857
"Adamsen C.Q., Moller A., Karim R., Sridharan M., Tip F., Sen K.","Repairing event race errors by controlling nondeterminism",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering, ICSE 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027720002&doi=10.1109%2fICSE.2017.34&partnerID=40&md5=210054d1845d40c07a556a466d433cf8","Modern web applications are written in an event-driven style, in which event handlers execute asynchronously in response to user or system events. The nondeterminism arising from this programming style can lead to pernicious errors. Recent work focuses on detecting event races and classifying them as harmful or harmless. However, since modifying the source code to prevent harmful races can be a difficult and error-prone task, it may be preferable to steer away from the bad executions. In this paper, we present a technique for automated repair of event race errors in JavaScript web applications. Our approach relies on an event controller that restricts event handler scheduling in the browser according to a specified repair policy, by intercepting and carefully postponing or discarding selected events. We have implemented the technique in a tool called EventRaceCommander, which relies entirely on source code instrumentation, and evaluated it by repairing more than 100 event race errors that occur in the web applications from the largest 20 of the Fortune 500 companies. Our results show that application-independent repair policies usually suffice to repair event race errors without excessive negative impact on performance or user experience, though application-specific repair policies that target specific event races are sometimes desirable. © 2017 IEEE.","Automated Repair; Event-Driven Programming; JavaScript","Errors; High level languages; Software engineering; Application specific; Error prone tasks; Event-driven programming; Javascript; Programming styles; Source Code Instrumentation; User experience; WEB application; Repair",2-s2.0-85027720002
"Zhou Y., Gu R., Chen T., Huang Z., Panichella S., Gall H.","Analyzing APIs Documentation and Code to Detect Directive Defects",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering, ICSE 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027703564&doi=10.1109%2fICSE.2017.11&partnerID=40&md5=b43e2866cf0aec55c093dc0f5391f69a","Application Programming Interface (API) documents represent one of the most important references for API users. However, it is frequently reported that the documentation is inconsistent with the source code and deviates from the API itself. Such inconsistencies in the documents inevitably confuse the API users hampering considerably their API comprehension and the quality of software built from such APIs. In this paper, we propose an automated approach to detect defects of API documents by leveraging techniques from program comprehension and natural language processing. Particularly, we focus on the directives of the API documents which are related to parameter constraints and exception throwing declarations. A first-order logic based constraint solver is employed to detect such defects based on the obtained analysis results. We evaluate our approach on parts of well documented JDK 1.8 APIs. Experiment results show that, out of around 2000 API usage constraints, our approach can detect 1158 defective document directives, with a precision rate of 81.6%, and a recall rate of 82.0%, which demonstrates its practical feasibility. © 2017 IEEE.","API documentation; natural language processing; static analysis","Defects; Formal logic; Natural language processing systems; Software engineering; Static analysis; Automated approach; Constraint solvers; First order logic; Parameter constraints; Precision rates; Program comprehension; Quality of softwares; Source codes; Application programming interfaces (API)",2-s2.0-85027703564
"Floyd B., Santander T., Weimer W.","Decoding the Representation of Code in the Brain: An fMRI Study of Code Review and Expertise",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering, ICSE 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027722823&doi=10.1109%2fICSE.2017.24&partnerID=40&md5=fa5aa140ae6df378d73f56686972598c","Subjective judgments in software engineering tasks are of critical importance but can be difficult to study with conventional means. Medical imaging techniques hold the promise of relating cognition to physical activities and brain structures. In a controlled experiment involving 29 participants, we examine code comprehension, code review and prose review using functional magnetic resonance imaging. We find that the neural representations of programming languages vs. natural languages are distinct. We can classify which task a participant is undertaking based solely on brain activity (balanced accuracy 79%. © 2017 IEEE.","code comprehension; medical imaging; prose review","Brain; Codes (symbols); Imaging techniques; Magnetic resonance imaging; Software engineering; Brain activity; Brain structure; Code comprehension; Controlled experiment; Functional magnetic resonance imaging; Natural languages; Neural representations; Physical activity; Medical imaging",2-s2.0-85027722823
"Chen C., Xing Z., Wang X.","Unsupervised software-specific morphological forms inference from informal discussions",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering, ICSE 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027696498&doi=10.1109%2fICSE.2017.48&partnerID=40&md5=c67ec97656b331538d76ed3a1855ae61","Informal discussions on social platforms (e.g., Stack Overflow) accumulates a large body of programming knowledge in natural language text. Natural language process (NLP) techniques can be exploited to harvest this knowledge base for software engineering tasks. To make an effective use of NLP techniques, consistent vocabulary is essential. Unfortunately, the same concepts are often intentionally or accidentally mentioned in many different morphological forms in informal discussions, such as abbreviations, synonyms and misspellings. Existing techniques to deal with such morphological forms are either designed for general English or predominantly rely on domain-specific lexical rules. A thesaurus of software-specific terms and commonly-used morphological forms is desirable for normalizing software engineering text, but very difficult to build manually. In this work, we propose an automatic approach to build such a thesaurus. Our approach identifies software-specific terms by contrasting software-specific and general corpuses, and infers morphological forms of software-specific terms by combining distributed word semantics, domain-specific lexical rules and transformations, and graph analysis of morphological relations. We evaluate the coverage and accuracy of the resulting thesaurus against community-curated lists of software-specific terms, abbreviations and synonyms. We also manually examine the correctness of the identified abbreviations and synonyms in our thesaurus. We demonstrate the usefulness of our thesaurus in a case study of normalizing questions from Stack Overflow and CodeProject. © 2017 IEEE.","Abbreviation; Morphological Form; Stack Overflow; Synonym; Word embedding","Knowledge based systems; Morphology; Natural language processing systems; Semantics; Thesauri; Abbreviation; Morphological forms; Stack overflow; Synonym; Word embedding; Software engineering",2-s2.0-85027696498
"Sayagh M., Kerzazi N., Adams B.","On cross-stack configuration errors",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering, ICSE 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027717403&doi=10.1109%2fICSE.2017.31&partnerID=40&md5=fa56524dafc8d93876ecd8c56f396da3","Today's web applications are deployed on powerful software stacks such as MEAN (JavaScript) or LAMP (PHP), which consist of multiple layers such as an operating system, web server, database, execution engine and application framework, each of which provide resources to the layer just above it. These powerful software stacks unfortunately are plagued by so-called cross-stack configuration errors (CsCEs), where a higher layer in the stack suddenly starts to behave incorrectly or even crash due to incorrect configuration choices in lower layers. Due to differences in programming languages and lack of explicit links between configuration options of different layers, sysadmins and developers have a hard time identifying the cause of a CsCE, which is why this paper (1) performs a qualitative analysis of 1,082 configuration errors to understand the impact, effort and complexity of dealing with CsCEs, then (2) proposes a modular approach that plugs existing source code analysis (slicing) techniques, in order to recommend the culprit configuration option. Empirical evaluation of this approach on 36 real CsCEs of the top 3 LAMP stack layers shows that our approach reports the misconfigured option with an average rank of 2.18 for 32 of the CsCEs, and takes only few minutes, making it practically useful. © 2017 IEEE.","Empirical Study; Multi-layer Systems; PHP; Qualitative Study; Slicing; Software Configuration; Software Stack","Errors; Software engineering; Empirical studies; Multi-layer system; Qualitative study; Slicing; Software configuration; Software stacks; Application programs",2-s2.0-85027717403
"Galán D., De La Torre L., Dormido S., Heradio R., Esquembre F.","Blockly experiments for EjsS laboratories",2017,"Proceedings of 2017 4th Experiment at International Conference: Online Experimentation, exp.at 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027879854&doi=10.1109%2fEXPAT.2017.7984359&partnerID=40&md5=d34feddf9a2215276d188542148dbd20","This paper presents an experimentation environment to perform automated experiments defined by the users on existing online laboratories. This environment is composed by Blockly, to define the experiments, and Google Charts, to analyze the outputs. The benefits that this tool offers to students, designers and teachers are explained through the paper. It can be used with any existing lab or simulation created with Easy Java(script) Simulations, there are repositories with hundreds of labs created with this tool, so the potential applicability of the tool is considerable. © 2017 IEEE.","Easy Java/Javascript Simulations; Experimentation Language; Experiments; Remote Laboratories; Simulations; Virtual Laboratories","Computer software; Experiments; Java programming language; Teaching; Easy Java/Javascript Simulations; Experimentation Language; Remote laboratories; Simulations; Virtual laboratories; Laboratories",2-s2.0-85027879854
"Bonino D., De Russis L.","Complex Event Processing for City Officers: A Filter and Pipe Visual Approach",2017,"IEEE Internet of Things Journal",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028924212&doi=10.1109%2fJIOT.2017.2728089&partnerID=40&md5=ec1e05c85b953c1683860b15f30ae2d7","Administrators and operators of next generation cities will likely be required to exhibit a good understanding of technical features, data issues, and complex information that, up to few years ago, were quite far from day-to-day administration tasks. In the smart city era, the increased attention to data harvested from the city fosters a more informed approach to city administration, requiring involved operators to drive, direct, and orient technological processes in the city more effectively. Such an increasing need requires tools and platforms that can easily and effectively be controlled by non-technical people. In this paper, an approach for enabling &#x201C;easier&#x201D; composition of real-time data processing pipelines in smart cities is presented, exploiting a visual and block-based design approach, similar to the one adopted in the Scratch programming language for elementary school students. The proposed approach encompasses both a graphical editor and a sound methodology and workflow, to allow city operators to effectively design, develop, test, and deploy their own data processing pipelines. The editor and the workflow are described in the context of a pilot of the ALMANAC European project. IEEE","Big Data Analysis; Block-based programming; Complex Event Processing; Filter and Pipe; Internet of Things; Pipelines; Semantics; Sensors; Smart cities; Smart City; Visual Programming.; Visualization","Bandpass filters; Big data; Computer programming; Data handling; Data visualization; Digital storage; Flow visualization; Internet of things; Pipeline processing systems; Pipelines; Semantics; Sensors; Visual languages; Administration tasks; Block based; Complex event processing; Complex information; Data processing pipelines; Real-time data processing; Technological process; Visual programming; Smart city",2-s2.0-85028924212
"Palma L.B., Brito V., Rosas J., Gil P.","WEB PLC simulator for ST programming",2017,"Proceedings of 2017 4th Experiment at International Conference: Online Experimentation, exp.at 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027839073&doi=10.1109%2fEXPAT.2017.7984410&partnerID=40&md5=a0aa880a811b398685039825b1685994","In this paper, the main functionalities of a WEB Programmable Logic Controller (PLC) Simulator for programming in Structure Text (ST) language, in the context of industrial automation and control, are presented. The available ST identifiers, expressions and statements are described, and some code examples are given. The simulator provides digital input/output channels, analog input/output channels and also the interaction with a dynamic process model of type autoregressive with exogenous input (ARX). The main contributions are a new environment for teaching, for remote learning, as also one more way to motivate the students and to obtain feedback from them. © 2017 IEEE.","Automation; e-learning; PLC; Remote laboratories; Structured Text Language; WEB application","Automation; E-learning; Programmable logic controllers; Simulators; XML; Autoregressive with exogenous inputs; Dynamic process modeling; Industrial automation; Programmable logic controllers (PLC); Remote laboratories; Remote learning; Structured text; WEB application; Education",2-s2.0-85027839073
"Bermúdez-Ortega J., Besada-Portas E., López-Orozco J.A., De La Cruz J.M.","A new open-source and smart-device accessible remote control laboratory",2017,"Proceedings of 2017 4th Experiment at International Conference: Online Experimentation, exp.at 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027846131&doi=10.1109%2fEXPAT.2017.7984376&partnerID=40&md5=bc9c19aaa1345202658e831a9ec1620e","In this paper we show a new remote lab software architecture for Automatic Control Education. This architecture is based on Node.js and Easy Java/JavaScript Simulations, which make it lightweight and accessible from smart devices like smartphones or tablets. It is easily adaptable to different types of controllers and experiments, as the existing labs at the University Complutense of Madrid show. © 2017 IEEE.","Control Education; Easy Java/JavaScript Simulations; Node.js; Open-source; Remote laboratories","Automation; Computer software; Java programming language; Laboratories; Open source software; Remote control; Control education; Easy Java/JavaScript Simulations; Node.js; Open sources; Remote laboratories; Distance education",2-s2.0-85027846131
"Tadjine K., Rekioua D.","Photovoltaic panels characteristics under shadows",2017,"Proceedings of 2016 International Renewable and Sustainable Energy Conference, IRSEC 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027846187&doi=10.1109%2fIRSEC.2016.7983889&partnerID=40&md5=2f4bafe5f4e239d1c900558706b6420c","In this paper electrical characteristics of photovoltaic panel under different weather conditions and under partial shading conditions are presented. We use two methods, the forst a mathematical one using Matlab-Simulink and the second one is an experimental method based on LabVIEW Software. We made a comparison between the results obtained under the two methods. Obtained results show how the shading can effect on the efficiency of photovoltaic panels and the experimental results follow the simulation ones. © 2016 IEEE.","Characteristics; LabVIEW; Partial shading; Photovoltaic Panels","Computer programming languages; Energy conservation; MATLAB; Photovoltaic cells; Characteristics; Electrical characteristic; Experimental methods; Lab-view softwares; LabViEW; MATLAB/ SIMULINK; Partial shading; Photovoltaic panels; Photovoltaic effects",2-s2.0-85027846187
"Singh A.K., Thota B.N.S., Schade B., Achazi K., Khan A., Böttcher C., Sharma S.K., Haag R.","Aggregation Behavior of Non-ionic Twinned Amphiphiles and Their Application as Biomedical Nanocarriers",2017,"Chemistry - An Asian Journal",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020481913&doi=10.1002%2fasia.201700450&partnerID=40&md5=a8ba0e984b3d7539007f885705fad948","A new class of twinned amphiphiles was developed by conjugating a pair of hydrophilic head groups from mPEG chains (Mn: 350 or 1000) and a pair of hydrophobic segments from linear alkyl chains (C11 or C18) through a novel spacer synthesized from glycerol and p-hydroxybenzoic acid. The aggregation phenomena of the amphiphiles were proven by DLS and fluorescence experiments, whereas size and morphology of the aggregates were evaluated by cryo-TEM. The measurements proved the formation of globular, thread-like or rod-like micelles as well as planar double-layer assemblies, depending on the amphiphile's molecular structure. The applicability of these non-ionic amphiphilic systems as nanocarriers for hydrophobic guest molecules was demonstrated by encapsulating a hydrophobic dye, Nile Red, and a hydrophobic drug, Nimodipine. The transport capacity results for both Nimodipine and Nile Red prove them as a promising candidate for drug delivery. © 2017 Wiley-VCH Verlag GmbH & Co. KGaA, Weinheim","cryo-TEM; nanocarriers; Nile Red; nimodipine; self-assembly; twinned amphiphiles","C (programming language); Carboxylic acids; Hydrophobicity; Motion Picture Experts Group standards; Pyridine; Self assembly; Aggregation behavior; Aggregation phenomena; cryo-TEM; Nano-carriers; Nile red; Nimodipine; P-Hydroxybenzoic acid; Planar double layers; Amphiphiles",2-s2.0-85020481913
"MacEra G., Marotta V.","A low close-in phase noise class-C differential clapp VCO topology in 180 nm Si-Ge HBT technology",2017,"2017 28th Irish Signals and Systems Conference, ISSC 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027845336&doi=10.1109%2fISSC.2017.7983600&partnerID=40&md5=d371f6f07141768d2ff020015a260836","This paper reports a new improved Clapp VCO topology designed in 180 nm Si-Ge HBT technology for operations around 5 GHz. The designed topology uses a series-tuned resonator, a back-to-back series varactor configuration for tuning the output frequency and a filtering tail current designed for shunting to ground the second harmonic noise component. At the supply voltage of 3.3V, and across Process, Voltage and Temperature (PVT), the resulting VCO exhibits a very low phase noise (-113 dBc/Hz at 100 kHz offset from the carrier frequency), a high tuning range (25%), a power consumption of 6 mW and a Tuning Range based Figure Of Merit (FOM) equal to 211 dB, classifying itself as a challenging VCO and suggesting the opportunity to be considered for further investigations and implementations in Si-Ge HBT Technology. © 2017 IEEE.",,"C (programming language); Germanium; Phase noise; Silicon; Silicon alloys; Topology; Tuning; Vanadium alloys; Variable frequency oscillators; Carrier frequency; Figure of merit (FOM); HBT technology; Low phase noise; Output frequency; Process , voltage and temperatures; Second harmonics; Supply voltages; Si-Ge alloys",2-s2.0-85027845336
"Sklyar K.V., Ignatovich S.Y., Sklyar G.M.","Verification of feedback linearizability conditions for control systems of the class C1",2017,"2017 25th Mediterranean Conference on Control and Automation, MED 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028513087&doi=10.1109%2fMED.2017.7984112&partnerID=40&md5=8a6e28502f99ec9434c6ad9c85a0b25b","We consider the feedback linearizability problem for control systems of the class C1 with one-dimensional control, i.e., the problem of the existence of a change of variables of the class C and a change of the control of the class C1 which map a given nonlinear system to a linear one. We discuss conditions of feedback linearizability and give an algorithm for their verification. © 2017 IEEE.",,"Control systems; Feedback; Change of variables; Linearizability; One-dimensional control; C (programming language)",2-s2.0-85028513087
"Breitwieser C., Tavella M., Schreuder M., Cincotti F., Leeb R., Muller-Putz G.R.","TiD &#x2013; Introducing and Benchmarking an Event-Delivery System for Brain-Computer Interfaces",2017,"IEEE Transactions on Neural Systems and Rehabilitation Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028865510&doi=10.1109%2fTNSRE.2017.2728199&partnerID=40&md5=ef5d30e574d0fb88b782533a248af05c","In this paper, we present and analyze an event distribution system for brain-computer interfaces (BCIs). Events are commonly used to mark and describe incidents during an experiment and are therefore critical for later data analysis or immediate real-time processing. The presented approach, called TiD (Tools for brain-computer interaction - interface D), delivers messages in XML format via a bus-like system using TCP (transmission control protocol) connections or shared memory. A dedicated server dispatches TiD messages to distributed or local clients. The TiD message is designed to be flexible and contains time stamps for event synchronization, whereas events describe incidents which occur during an experiment. TiD was tested extensively towards stability and latency. The effect of an occurring event jitter was analyzed and benchmarked on a reference implementation under different conditions as GBit and 100 MBit Ethernet or WiFi with a different number of event receivers. A 3 dB signal attenuation, which occurs when averaging jitter influenced trials aligned by events, is starting to become visible at around 1&#x2013;2 kHz in case of a GBit connection. Mean event distribution times across operating systems are ranging from 0.3 ms to 0.5 ms for aGBit network connection for 106 events. Results for other environmental conditions are available in the paper. References already using TiD for event distribution are provided showing the applicability of TiD for event delivery with distributed or local clients. IEEE","Brain-Computer Interface; Brain-computer interfaces; C&#x002B;&#x002B;; Electronic mail; event; Jitter; jitter; marker; open source; Ports (Computers); protocol; Real-time systems; Timing; transmission; Universal Serial Bus","C (programming language); Computer control systems; Electronic mail; Interactive computer systems; Interfaces (computer); Jitter; Network protocols; Open systems; Real time systems; Standards; System buses; Transmission control protocol; Transmissions; event; marker; Open sources; Ports (Computers); Timing; Universal serial bus; Brain computer interface",2-s2.0-85028865510
"Snajdarova M., Borik S., Cap I.","Features extraction from impedance cardiography signal",2017,"2017 11th International Conference on Measurement, MEASUREMENT 2017 - Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027832738&doi=10.23919%2fMEASUREMENT.2017.7983577&partnerID=40&md5=b6ec1deb234b829dd0ca5a9b98b81432","Many cardiovascular diseases can be detected using a non-invasive measurement of thoracic impedance. For this purpose, a device was designed and constructed, allowing the simultaneous evaluation of both impedance cardiography (ICG) and electro-cardiographic (ECG) signals. The acquired data is displayed online and further processed within the ICGstudio software application. The mentioned software allows the calculation of basic hemodynamic parameters based on the localization of characteristic points B, X and C on the ICG curve. Localization of the R wave within the ECG recordings was performed using the Pan-Thompkins algorithm. © 2017 Institute of Measurement Science SAS.","Cardiac Output; Detection of Characteristic Points; Impedance Cardiography; Impedance Curve; Stroke Volume","Application programs; C (programming language); Cardiography; Cardiac output; Characteristic point; Impedance cardiography; Impedance curves; Stroke volumes; Electrocardiography",2-s2.0-85027832738
"Hemza A., Abdeslam H., Chenni R., Narimene D.","Photovoltaic system output simulation under various environmental conditions",2017,"Proceedings of 2016 International Renewable and Sustainable Energy Conference, IRSEC 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027835451&doi=10.1109%2fIRSEC.2016.7983900&partnerID=40&md5=0a7ce141a2a8bb3cf83ce1beccc13b5d","This study presents a simulation procedure to describe the current-voltage and power-voltage characteristics of photovoltaic (PV) solar cell or module of different types of technologies; mono-crystalline silicon, multi-crystalline silicon and Thin film under various level of irradiation and different value of temperature based on LabVIEW software. The desired parameters of PV module including short circuit current, open circuit voltage, and max power point are calculated. All details of the modeling are shown in this paper and validated by the experimental data. © 2016 IEEE.","Current and Power Voltage Characteristic; LabVIEW; Photovoltaic (PV)","Computer programming languages; Computer software; Crystalline materials; Energy conservation; Open circuit voltage; Photovoltaic cells; Solar cells; Solar power generation; Environmental conditions; Lab-view softwares; LabViEW; Multi-crystalline silicon; Photovoltaic; Photovoltaic systems; Power voltage characteristics; Simulation procedures; Monocrystalline silicon",2-s2.0-85027835451
"Luo M., Luo Y., Li H., Xia Z., Yongkui Y.","Design and implementation of high resolution face image acquisition system under low illumination based on the open source computer vision library",2017,"2017 2nd International Conference on Image, Vision and Computing, ICIVC 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029382532&doi=10.1109%2fICIVC.2017.7984642&partnerID=40&md5=281b93aacd5e9ef04e857caeeaab4969","Super-resolution face image acquisition system is indispensable in people's life. Under the condition of low illumination, the illumination environment difference is too big or the light is insufficient, which leads to the traditional image acquisition system can not collect the high quality face image, and the limitation is poor. Based on open source computer vision library (OpenCV) in the C++ environment configuration, the use of Three Dimension (3D) face recognition technology algorithm, design a set of low illumination conditions of the super resolution face image acquisition system. Experiments show that the design scheme with real-time focusing speed), fast (single acquisition 0.05 seconds), accurate (facial recognition rate of 99.3%) etc. characteristics, be able to fully meet the needs of low illumination conditions for super-resolution of face image acquisition. © 2017 IEEE.","C++ environment; Facial recognition technology 3D algorithm; OpenCV","C++ (programming language); Computer vision; Face recognition; Open systems; Optical resolving power; Computer vision library; D-algorithm; Design and implementations; Face recognition technologies; Facial recognition; Image acquisition systems; Low illuminations; OpenCV; Image acquisition",2-s2.0-85029382532
"Wu S., Wei J., Yang S.","Analysis of strain localization by energy equivalence: II. finite element solution",2017,"Lixue Xuebao/Chinese Journal of Theoretical and Applied Mechanics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028427792&doi=10.6052%2f0459-1879-16-330&partnerID=40&md5=47587788e7905eed3e56f7fe90915c0f","Founded on the nonlocal plasticity and the state space theories, a new approach is proposed to find the meshindependent solution of the strain localization problems by equating the rates of plastic energy dissipation in the local and nonlocal state spaces. Following the previous paper by the authors, general formulas are developed for the solution of the nonlocal internal variables in the two- and more than two-dimensional problems. A stress updating algorithm is proposed to integrate the rate form constitutive equations in the finite element context. To verify the proposed approach, a one-dimensional model problem and three two-dimensional plane strain problems are solved numerically by the finite element method. Numerical results show that the plastic strain distributions and the load-displacement curves stably converge with refinement of the finite element mesh. The size of the localization zone depends only on the internal length scale and is insensitive to the mesh size. For the one-dimensional problem, numerical solutions converge to the analytical ones. For the two-dimensional problems, although no analytical solutions are available, the numerical solutions converge toward the unique ones. The width and the inclination are almost not changed as the mesh size is reduced. Also, the distribution of the plastic strains and the deformation patterns are smooth in the entire domain. A slope stability problem and a plane strain test of a coal specimen are also solved numerically to demonstrate the robustness of the proposed approach. It is well shown that the proposed approach can overcome the drawbacks of the classical continuum theory and lead to physically meaningful, mesh-independent solution of strain softening problems. Because only C0 continuity is needed between element boundaries, the proposed approach is easy to be incorporated into the existing finite element code without substantial modification. © 2017, Editorial Office of Chinese Journal of Theoretical and Applied Mechanics. All right reserved.","Finite element; Internal length scale; Mesh-dependence; Nonlocal plasticity; Strain localization","C (programming language); Constitutive equations; Continuum mechanics; Energy dissipation; Mesh generation; Plastic deformation; Plasticity; Slope stability; Strain; Classical continuum theory; Internal length scale; Mesh dependence; Non-local plasticity; One dimensional problems; Plastic energy dissipation; Strain localization problem; Strain localizations; Finite element method",2-s2.0-85028427792
"Damnjanović D., Krneta R., Živković D.","Online identification of unknown system in adaptive filtering laboratory",2017,"Proceedings of 2017 4th Experiment at International Conference: Online Experimentation, exp.at 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027839787&doi=10.1109%2fEXPAT.2017.7984349&partnerID=40&md5=5ae4e08a1a44824aeffe9c5caeca4534","This paper presents realization of adaptive filtering laboratory aimed to identification of unknown system. Whole process is realized by using LabVIEW software package and it can be controlled online through CEyeClon viewer. Application provides learning curves for used adaptive algorithm and records all results in the form of Excel report on the server side of experiment. Report can be sent automatically to the e-mail address defined by user at the beginning of experiment. Whole documentation of experiment is provided to the user within CEyeClon viewer. © 2017 IEEE.","Adaptive filtering; CEyeClon viewer; LabVIEW; online report","Adaptive algorithms; Adaptive filtering; Computer programming languages; CEyeClon viewer; E-mail address; Identification of unknowns; Lab-view softwares; LabViEW; Learning curves; On-line identification; Online reports; Adaptive filters",2-s2.0-85027839787
"Belyavskyi A.O., Tomashevich S.I., Andrievsky B.","Application of 2DOF Quadrotor-based Laboratory Testbed for engineering education",2017,"2017 25th Mediterranean Conference on Control and Automation, MED 2017",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028502090&doi=10.1109%2fMED.2017.7984240&partnerID=40&md5=77b1bb9da6438e01e2ddd37aaa46d6fb","The paper is devoted to application of the novel 2DOF Quadrotor-based Laboratory Testbed for engineering education in the such the disciplines as Automatic Control, Adaptation and Identification, Real-time Control Systems, Data and Signal Processing, Telecommunications, Information Theory, Flight Dynamics, high- and low-level Programming Languages. The testbed is based on a quadrotor, mounted in the gimbals. Testbed is aimed for debugging and pre-flight testing the quadrotor control algorithms, for scientific research and education. In the paper, construction of the Testbed is briefly described and the experience of its usage for engineering education in the ITMO University is outlined. © 2017 IEEE.",,"Automation; Computer control systems; Computer systems programming; Data handling; Engineering education; Flight dynamics; High level languages; Identification (control systems); Information theory; Real time control; Real time systems; Signal processing; Testbeds; Data and signals; Low level programming; Pre-flight; Quad rotors; Scientific researches; Flight control systems",2-s2.0-85028502090
"Petrovic G., Simic I., Bosnic J.A., Mostarac P.","Power quality meter based on FPGA and LabVIEW",2017,"2017 11th International Conference on Measurement, MEASUREMENT 2017 - Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027888187&doi=10.23919%2fMEASUREMENT.2017.7983558&partnerID=40&md5=03392e4aca500e2ecc9a37108b5e22ff","This paper proposes a relatively simple program for measuring currents and voltages in electrical power system. Real-Time processing is achieved by using CompactRIG programmable automation controller which combines embedded Real-Time and FPGA modules. The device also enables users to quickly develop program code via LabVIEW graphical programming language. The process of data exchange between FPGA and RT modules using FIFG registers is described in details. In the end, some Power Quality algorithms are presented, according to IEC standard and attractive Graphical User Interface for PQ monitoring is displayed. © 2017 Institute of Measurement Science SAS.","FPGA Programming; Power Quality; Signal Processing","Computer graphics; Electric power systems; Electronic data interchange; Graphical user interfaces; Power quality; Signal processing; Standards; User interfaces; Currents and voltages; Electrical power system; Fpga programming; IEC standards; Labview graphical programming; Program code; Programmable automation controllers; Realtime processing; Field programmable gate arrays (FPGA)",2-s2.0-85027888187
"Luković V., Krneta R., Damnjanović D., Peulić A.","The remote lab 'Nexys 2 FPGA platform' aimed for learning design of digital circuits",2017,"Proceedings of 2017 4th Experiment at International Conference: Online Experimentation, exp.at 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027848069&doi=10.1109%2fEXPAT.2017.7984350&partnerID=40&md5=5b5dde3eabbc99da6c458d3a34b855ba","The application of remote lab 'Nexys 2 FPGA platform' for learning digital circuits design is described in this paper. The experiment requires installation of Xilinx ISE Design Suite software on students' PCs for designing digital circuits and generating.bit file. There are three ways of designing digital circuits in Xilinx ISE Design Suite software: by programming in VHDL language, by programming in Verilog language or by using schematic diagrams. Working environment of the remote lab consists of Digilent Nexys 2 FPGA platform that is connected with PC. Students connect with the remote lab PC through CEyeClon viewer which also needs to be installed on their PCs together with.Net Framework 4.5. Generated.bit file is loaded through Digilent Adept2 software that is installed on the remote lab PC and used for the FPGA programming. The usage of this experiment enable engineering students to achieve practical experiences and skills for designing and simulating digital circuits using FPGA and to better understand and learn theory of designing digital circuits. © 2017 IEEE.","designing; digital circuits; FPGA; Nexys 2 platform; remote experiment; simulating; Xilinx ISE Design Suite","Computer hardware description languages; Digital circuits; Education; Field programmable gate arrays (FPGA); Integrated circuit design; Laboratories; Microcomputers; Schematic diagrams; Software design; Students; Timing circuits; designing; Nexys 2 platform; Remote experiments; simulating; Xilinx ISE Design Suite; E-learning",2-s2.0-85027848069
"Ji H., Zeng F., Xu Y., Lu H., Zhang Z.","KPIC2: An Effective Framework for Mass Spectrometry-Based Metabolomics Using Pure Ion Chromatograms",2017,"Analytical Chemistry",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025119029&doi=10.1021%2facs.analchem.7b01547&partnerID=40&md5=67fed4f949b9b52f7e591d111c503d0d","Distilling accurate quantitation information on metabolites from liquid chromatography coupled with mass spectrometry (LC-MS) data sets is crucial for further statistical analysis and biomarker identification. However, it is still challenging due to the complexity of biological systems. The concept of pure ion chromatograms (PICs) is an effective way of extracting meaningful ions, but few toolboxes provide a full processing workflow for LC-MS data sets based on PICs. In this study, an integrated framework, KPIC2, has been developed for metabolomics studies, which can detect pure ions accurately, align PICs across samples, group PICs to identify isotope and potential adducts, fill missing peaks and do multivariate pattern recognition. To evaluate its performance, MM48, metabolomics quantitation, and Soybean seeds data sets have been analyzed using KPIC2, XCMS, and MZmine2. KPIC2 can extract more true ions with fewer detecting features, have good quantification ability on a metabolomics quantitation data set, and achieve satisfactory classification on a soybean seeds data set through kernel-based OPLS-DA and random forest. It is implemented in R programming language, and the software, user guide, as well as example scripts and data sets are available as an open source package at https://github.com/hcji/KPIC2. © 2017 American Chemical Society.",,"Chromatographic analysis; Decision trees; Ions; Liquid chromatography; Mass spectrometry; Open source software; Open systems; Pattern recognition; Photonic integration technology; Spectrometry; Biomarker identification; Integrated frameworks; Ion chromatogram; Metabolomics; Multivariate patterns; Open source package; Random forests; Soybean seeds; Classification (of information)",2-s2.0-85025119029
"Leupolz J., Knapp A., Habermaier A., Reif W.","Qualitative and quantitative analysis of safety-critical systems with [InlineEquation not available: see fulltext.]",2017,"International Journal on Software Tools for Technology Transfer",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024492226&doi=10.1007%2fs10009-017-0464-3&partnerID=40&md5=ec301559c2f0a8dd4d24abc69fcb3f2b","We give an overview of the [InlineEquation not available: see fulltext.] (pronounced “safety sharp”) framework for rigorous, model-based analysis of safety-critical systems. We introduce [InlineEquation not available: see fulltext.]’s expressive modeling language based on the [InlineEquation not available: see fulltext.] programming language, showing how [InlineEquation not available: see fulltext.]’s fault modeling and flexible model composition capabilities can be used to model a case study from the transportation sector with multiple design variants. A formal semantics for executable probabilistic models is given. Fully automated qualitative and quantitative safety analyses are conducted for the case study using algorithms of the model checkers LTSmin and MRMC. The results of the quantitative analyses are discussed in comparison with results obtained by using traditional techniques. © 2017 Springer-Verlag GmbH Germany","Executable models; Formal methods; Model checking; Quantitative analysis; Safety analysis","Chemical analysis; Formal methods; Modeling languages; Safety engineering; Security systems; Semantics; Executable model; Probabilistic models; Qualitative and quantitative analysis; Quantitative safety analysis; Safety analysis; Safety critical systems; Traditional techniques; Transportation sector; Model checking",2-s2.0-85024492226
"Yoo S.","Embedding genetic improvement into programming languages",2017,"GECCO 2017 - Proceedings of the Genetic and Evolutionary Computation Conference Companion",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026879500&doi=10.1145%2f3067695.3082516&partnerID=40&md5=591fc56e14c7534387d57424f897e4a5","We present a vision of genetic improvement firmly embedded in, and supported by, programming languages. Genetic improvement has already been envisioned as the next compiler, which would take human wrifien programs as input and return versions optimised with respect to various objectives. As an intermediate stage, or perhaps to complement the fully automated vision, we imagine genetic improvement processes that are hinted at and directed by humans but understood and undertaken by programming languages and their runtimes, via interactions through the source code. We examine existing similar ideas and examine the benefits of embedding them within programming languages.","Genetic Improvement; Programming Language; Self Adaptation","Computer programming languages; Program compilers; Fully automated; Genetic improvements; Intermediate stage; Runtimes; Self adaptation; Source codes; Genetic programming",2-s2.0-85026879500
"Pantridge E., Spector L.","PyshGP: PushGP in python",2017,"GECCO 2017 - Proceedings of the Genetic and Evolutionary Computation Conference Companion",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026876774&doi=10.1145%2f3067695.3082468&partnerID=40&md5=4be39c662293966aff049984961dd648","The PushGP genetic programming system, which evolves programs expressed in the Push programming language, has been used for a variety of research projects and applications over its sixteen-year history. PushGP relies on an implementation of the Push language in a host language, and it is generally easiest to use PushGP in projects in which most other components, such as fitness functions and data access instructions, are written in the same host language. While versions of Push have been written in nearly a dozen different languages, a full-featured implementation in Python would make it available to a particularly large user base, and facilitate its integration with a wide range of existing data science tools. This paper presents pyshgp as an open-source PushGP framework implemented in the Python programming language, and describes some of its features for data science applications. © 2017 ACM.","Genetic programming; Machine Learning","Application programs; Computer programming languages; Computer systems programming; Evolutionary algorithms; Genetic algorithms; High level languages; Learning systems; Open source software; Data access; Fitness functions; Genetic programming system; Large users; Open sources; Python programming language; Science applications; Science tools; Genetic programming",2-s2.0-85026876774
"Kriegman S., Cappelle C., Corucci F., Bernatskiy A., Cheney N., Bongard J.C.","Simulating the evolution of soft and rigid-body robots",2017,"GECCO 2017 - Proceedings of the Genetic and Evolutionary Computation Conference Companion",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026883651&doi=10.1145%2f3067695.3082051&partnerID=40&md5=4f72406c648447625fb640332285fa0b","In evolutionary robotics, evolutionary methods are used to optimize robots to di.erent tasks. Because using physical robots is costly in terms of both time and money, simulated robots are generally used instead. Most physics engines are wri.en in C++ which can be a barrier for new programmers. In this paper we present two Python wrappers, Pyrosim and Evosoro, around two well used simulators, Open Dynamics Engine (ODE) and Voxelyze/VoxCAD, which respectively handle rigid and so. bodied simulation. Python is an easier language to understand so more time can be spent on developing the actual experiment instead of programming the simulator. © 2017 ACM.","Evolutionary robotics; Physical simulation","C++ (programming language); Computer programming; Engines; High level languages; Robotics; Robots; Actual experiments; Evolutionary method; Evolutionary robotics; Open dynamics engines; Physical robots; Physical simulation; Physics engine; Simulated robot; Computer software",2-s2.0-85026883651
"White D.R.","GI in no time",2017,"GECCO 2017 - Proceedings of the Genetic and Evolutionary Computation Conference Companion",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026880958&doi=10.1145%2f3067695.3082515&partnerID=40&md5=940bee6b38a4eb17b842966aaf8ebeea","We describe a small, simple, and lightweight microframework for the Genetic Improvement of Java code. We call the framework ""GI in no time"", or ""Gin"". Gin is designed to be a straightforward, hackable, GI tool for Java. It currently lacks large features found in comparable program repair tools, but nonetheless it is capable of performing optimisation of a Java class via local search. We hope that providing this contribution will encourage researchers to collaborate on GI tool development, whilst lowering the barrier to entry for those interested in experimenting with GI. It is intended to serve both as a toolkit to be extended, and also an example of how GI can be implemented. We discuss some of the design principles behind Gin, and outline observations made during its development.","Automated Programming; Genetic Improvement; Optimisation","Computer software; Genetic programming; Optimization; Automated programming; Design Principles; Genetic improvements; Java codes; Local search; Optimisations; Repair tools; Tool development; Java programming language",2-s2.0-85026880958
"Berny A.","In hypercubo nigrae capsulae optimum",2017,"GECCO 2017 - Proceedings of the Genetic and Evolutionary Computation Conference Companion",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026882334&doi=10.1145%2f3067695.3082472&partnerID=40&md5=fbb1d7323de9cde508ab53883ccbf4cb","HNCO consists of a C++ library, command-line tools, and scripts for the optimization of black box functions defined on fixed-length bit vectors. It aims at being fiexible, fast, simple, and robust. The library provides classes for functions, populations, neighborhoods, and algorithms. It currently includes 22 concrete functions and 18 concrete algorithms. The command-line tools expose most of the library to the user without the need for programming. One of the goals of HNCO is to automate experiments and favor reproducible research. HNCO comes with experiments designed to tune or compare algorithms. Scripts run all the simulations in an experiment and generate a report. The source code of HNCO is published under the GNU LGPL 3 license. © 2017 ACM.","Benchmarking; Bit vectors; Black box optimization; C++ framework; Evolutionary algorithms; Local search","Benchmarking; C++ (programming language); Concretes; Evolutionary algorithms; Open source software; Bit vector; Black-box functions; Black-box optimization; C++ libraries; Command line; Local search; Reproducible research; Source codes; Optimization",2-s2.0-85026882334
"Dhahri M., Dhahri J., Hlil E.K.","Critical behavior near the ferromagnetic to paramagnetic phase transition temperature in polycrystalline La0.5Sm0.1Sr0.4Mn1−xInxO3 (0 ≤ x ≤ 0.1)",2017,"Journal of Magnetism and Magnetic Materials",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016426588&doi=10.1016%2fj.jmmm.2017.03.059&partnerID=40&md5=4930206103bea83a1e5a104a3cdd6a88","In this paper we report on the critical analysis of the La0.5Sm0.1Sr0.4Mn1−xInxO3 (0⩽x⩽0.1) manganites near the ferromagnetic-paramagnatic phase transition temperature. Various techniques such as modified Arrott plot, Kouvel–Fisher method and critical isotherm were used to analyze the magnetic-field dependence of magnetization. The Curie temperature (TC) could be tuned over a wide temperature range, from 251 K to 310 K, with varying in content. Though the nature of this transition is found to be of second order, the estimated critical exponents β, γ, and δ obtained for different values of x are close to the theoretically predicted values for the three-dimensional (3D)-Ising interaction model (β = 0.324 ± 0.01, γ = 1.240 ± 0.13 at TC = 310 K for x = 0.00); (β = 0.329 ± 0.04, γ = 1.241 ± 0.001 at TC = 294 K for x = 0.05); (β = 0.332 ± 0.01, γ = 1.250 ± 0.04 at TC = 251 K for x = 0.10) and are very far away from any other known universality class. The critical isotherm M (TC, µ0H) gives δ = 5.02 ± 0.01 for x = 0.00. Thus, the scaling law δ=1+γ/β is fulfilled. The critical exponents obey the single scaling equation of M(μ0H,ε)=εβf±(μ0H/εβ+γ); where f+ for T &gt; TC and f− for T &lt; TC. © 2017 Elsevier B.V.","Arrott plots; Critical behavior; Phase transition","Ferromagnetic materials; Ferromagnetism; Isotherms; Manganese; Phase transitions; Temperature; Arrott plots; Critical behavior; Magnetic field dependences; Modified arrott plots; Paramagnetic phase transitions; Threedimensional (3-d); Universality class; Wide temperature ranges; C (programming language)",2-s2.0-85016426588
"Beatini V., Royer-Carfagni G., Tasora A.","A regularized non-smooth contact dynamics approach for architectural masonry structures",2017,"Computers and Structures",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017533684&doi=10.1016%2fj.compstruc.2017.02.002&partnerID=40&md5=2081d7efb5bfc2d86be60567d8041279","A Non-Smooth Contact Dynamic (NSCD) formulation is used to analyze complex assemblies of rigid blocks, representative of real masonry structures. A model of associative friction sliding is proposed, expressed through a Differential Variational Inequality (DVI) formulation, relying upon the theory of Measure Differential Inclusion (MDI). A regularization is used in order to select a unique solution and to avoid problems of indeterminacy in redundant contacts. This approach, complemented with an optimized collision detection algorithm for convex contacts, results to be reliable for dynamic analyses of masonry structures under static and dynamic loads. The approach is comprehensive, since we implement a custom NSCD simulator based on the Project Chrono C++ framework, and we design custom tools for pre- and post-processing through a user-friendly parametric design software. Representative examples confirm that the method can handle 3-D complex structures, as typically are architectural masonry constructions, under both static and dynamic loading. © 2017 Elsevier Ltd","Associative friction; Dynamic analysis; Masonry; Measure Differential Inclusion (MDI); Non-Smooth Contact Dynamic (NSCD); Rigid blocks","C++ (programming language); Computer software; Differential equations; Dynamic analysis; Dynamic loads; Friction; Masonry materials; Variational techniques; Collision detection algorithm; Differential variational inequality; Masonry; Measure differential inclusions; Non-smooth contact dynamics; Rigid block; Static and dynamic loading; Static and dynamic loads; Rigid structures",2-s2.0-85017533684
"Otero F.E.B.","MYRA: A Java ant colony optimization framework for classification algorithms",2017,"GECCO 2017 - Proceedings of the Genetic and Evolutionary Computation Conference Companion",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026861338&doi=10.1145%2f3067695.3082471&partnerID=40&md5=9821bdb92b2773aa81eab58db735da1a","This paper introduces MYRA, an open-source Java framework that provides the implementation of several ant colony optimization classification algorithms. The algorithms are ready to be used from the command-line or can be easily called from custom Java code. The framework is implemented using a modular architecture, therefore algorithms can be easily extended to incorporate different procedures and/or use different parameter values. The paper gives particular attention to the common architecture from which the algorithms are built on, highlighting the shared classes among the different implemented algorithms. Thesource code and documentation of MYRA are available for download at https://github.com/febo/myra. © 2017 ACM.","Ant colony optimization; Classification; Data mining","Ant colony optimization; Artificial intelligence; Classification (of information); Evolutionary algorithms; Java programming language; Open source software; Optimization; Classification algorithm; Command line; Common architecture; Java codes; Modular architectures; Open sources; Data mining",2-s2.0-85026861338
"Cody-Kenny B., Fenton M., O'Neill M.","From problem landscapes to language landscapes: Questions in genetic improvement",2017,"GECCO 2017 - Proceedings of the Genetic and Evolutionary Computation Conference Companion",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026872185&doi=10.1145%2f3067695.3082522&partnerID=40&md5=88f483c9d3253bf3e0cba99955336cc6","Managing and curating software is a time consuming process particularly as programming languages, libraries, and execution environments change. To support the engineering of software, we propose applying a GP-based continuous learning system to all ""useful"" software. We take the position that search-based itemization and analysis of all commonly used software is feasible, in large part, because the requirements that people place on software can be used to bound the search space to software which is of high practical use. By repeatedly reusing the information generated during the search process we hope to attain a higher-level, but also more rigorous, understanding of our engineering material-source code.","Learning; Search; Software Engineering","Genetic programming; Software engineering; Continuous learning; Engineering materials; Execution environments; Genetic improvements; Learning; Practical use; Search; Search process; Search engines",2-s2.0-85026872185
"Pantridge E., Helmuth T., McPhee N.F., Spector L.","On the difficulty of benchmarking inductive program synthesis methods",2017,"GECCO 2017 - Proceedings of the Genetic and Evolutionary Computation Conference Companion",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026888151&doi=10.1145%2f3067695.3082533&partnerID=40&md5=6e24cc2c67c94010ef0aa6f2547bc87f","A variety of inductive program synthesis (IPS) techniques have recently been developed, emerging from di.erent areas of computer science. However, these techniques have not been adequately compared on general program synthesis problems. In this paper we compare several methods on problems requiring solution programs to handle various data types, control structures, and numbers of outputs. .e problem set also spans levels of abstraction; some would ordinarily be approached using machine code or assembly language, while others would ordinarily be approached using highlevel languages. .e presented comparisons are focused on the possibility of success; that is, on whether the system can produce a program that passes all tests, for all training and unseen testing inputs. .e compared systems are Flash Fill, MagicHaskeller, TerpreT, and two forms of genetic programming. .e two genetic programming methods chosen were PushGP and Grammar Guided Genetic Programming. .e results suggest that PushGP and, to an extent, TerpreT and Grammar Guided Genetic Programming are more capable of finding solutions than the others, albeit at a higher computational cost. A more salient observation is the dificulty of comparing these methods due to drastically di.erent intended applications, despite the common goal of program synthesis.","Benchmarking; Genetic programming; Inductive Program Synthesis; Machine Learning","Application programs; Benchmarking; Genetic algorithms; Learning systems; Software testing; Assembly language; Computational costs; Control structure; Finding solutions; Grammar guided genetic programming; Inductive Program Synthesis; Levels of abstraction; Program synthesis; Genetic programming",2-s2.0-85026888151
"Fenton M., McDermott J., Fagan D., Forstenlechner S., Hemberg E., O'Neill M.","PonyGE2: Grammatical evolution in python",2017,"GECCO 2017 - Proceedings of the Genetic and Evolutionary Computation Conference Companion",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026876613&doi=10.1145%2f3067695.3082469&partnerID=40&md5=062ff95104e7e1b752f2da98b45a1f46","Grammatical Evolution (GE) is a population-based evolutionary algorithm, where a formal grammar is used in the genotype to phenotype mapping process. PonyGE2 is an open source implementation of GE in Python, developed at UCD's Natural Computing Research and Applications group. It is intended as an advertisement and a starting-point for those new to GE, a reference for students and researchers, a rapid-prototyping medium for our own experiments, and a Python workout. As well as providing the characteristic genotype to phenotype mapping of GE, a search algorithm engine is also provided. A number of sample problems and tutorials on how to use and adapt PonyGE2 have been developed. © 2017 ACM.","Genetic Programming; Grammatical Evolution","Computational grammars; Genetic algorithms; Genetic programming; High level languages; Mapping; Open source software; Open systems; Formal grammars; Grammatical evolution; Mapping process; Natural Computing; Number of samples; Open source implementation; Search Algorithms; Evolutionary algorithms",2-s2.0-85026876613
"García-Valdez M., Merelo J.J.","Evospace-js: Asynchronous pool-based execution of heterogeneous metaheuristics",2017,"GECCO 2017 - Proceedings of the Genetic and Evolutionary Computation Conference Companion",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026850475&doi=10.1145%2f3067695.3082473&partnerID=40&md5=75001baa9b629fd7d9d94fdc05f922d8","This paper is part of a continuing effort in the field of EC to develop algorithms that follow an opportunistic approach to computing, allowing the exploitation of freely available services over the Internet by using free tiers of cloud services or volunteer computing resources; the EvoSpace model is able to tap from both kind of resources, using asynchronous evolutionary algorithms. We present its design, which follows an an event-driven architecture and asynchronous I/O model, and its implementation, with a server-side tier programmed in Node.js that uses Redis as an in-memory and high performance data store for the population. This population store is exposed to clients running population-based and nature-inspired metaheuristics through a REST API. Additional capabilities where implemented in this version to allow the logging of experiments where heterogeneous algorithms are executed in parallel. These logs can then be transformed to other formats. As a case study an hybrid global optimization algorithm has been implemented mixing two algorithms: A PSO algorithm from the EvoloPy library and a GA using the DEAP framework. The result was transformed to files compatible to the Comparing Continuous Optimizer platform in order to use their post-processing code. Clients in this case have been developed in the Python language, the language used to implement both libraries. The results from this case study suggest, first, that EvoSpace can be used as a paradigm-and language-Agnostic platform for population-based optimization algorithms, and also that this software can yield performance improvements and a viable platform to execute and compare asynchronous pool-based metaheuristics. © 2017 ACM.","Distributed Evolutionary Algorithms; Nature-inspired metaheuristics","Application programming interfaces (API); Distributed computer systems; Global optimization; Heuristic algorithms; Heuristic programming; Optimization; Particle swarm optimization (PSO); Population statistics; Web services; Asynchronous I/O; Distributed evolutionary algorithms; Event-driven architectures; Global optimization algorithm; Meta heuristics; Performance data; Population-based optimization; Volunteer computing; Evolutionary algorithms",2-s2.0-85026850475
"Orlov M.","Evolving software building blocks with FINCH",2017,"GECCO 2017 - Proceedings of the Genetic and Evolutionary Computation Conference Companion",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026851508&doi=10.1145%2f3067695.3082521&partnerID=40&md5=03e8396665eb4445451b4e07ba48a5b0","This paper proposes to explore the following question: can software evolution systems like FINCH, that evolve linear representations originating from a higher-level structural language, take advantage of building blocks inherent to that original language?","Genetic improvement; Genetic programming; Java bytecode","Genetic algorithms; Building blockes; Genetic improvements; Java byte codes; Linear representation; Software building blocks; Software Evolution; Genetic programming",2-s2.0-85026851508
"Mueller-Bady R., Kappes M., Atkinson L., Medina-Bulo I.","Multijob: A framework for efiicient distribution of evolutionary algorithms for parameter tuning",2017,"GECCO 2017 - Proceedings of the Genetic and Evolutionary Computation Conference Companion",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026856661&doi=10.1145%2f3067695.3082476&partnerID=40&md5=5b7961659647a1069200c92d4794f9b1","An important challenge in designing evolutionary search heuristics is the statistically significant evaluation of different configurations. The goal is to find an optimal algorithm design with respect to its parameters, i.e., parameter tuning. In this paper, we propose an open source software framework, called Multijob, allowing to simplify and automate EA configuration and parameter tuning. Additionally, the framework offers a workflow for distributed execution of the preconfigured algorithms in heterogeneous computing clusters or grids. The framework uses features of the Unix-based command line utility GNU Parallel, which enables the pausing and resuming of jobs, estimation of experiment completion time, etc. It is highly dynamic due to its language-Agnosticism and flexible with respect to parameters and configurations of specific EAs. The possibility of distributing computing time among (heterogeneous) hardware, only requiring access over secure shell (SSH) and a proper environment for job execution, makes Multijob a noteworthy utility for improving efficiency of statistically significant parameter testing and tuning. © 2017 ACM.","Evolutionary computation; Grid computing; Parameter tuning","Calculations; Clustering algorithms; Computer programming; Evolutionary algorithms; Grid computing; Heuristic algorithms; Network function virtualization; Open source software; Open systems; Software engineering; Completion time; Distributing computing; Evolutionary search; Heterogeneous computing; Improving efficiency; Job execution; Optimal algorithm; Parameter-tuning; Parameter estimation",2-s2.0-85026856661
"Hanster C., Kerschke P.","Flaccogui: Exploratory landscape analysis for everyone",2017,"GECCO 2017 - Proceedings of the Genetic and Evolutionary Computation Conference Companion",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026864440&doi=10.1145%2f3067695.3082477&partnerID=40&md5=8170ceae54da5b77830849c0a37f8dff","Finding the optimal solution for a given problem has always been an intriguing goal and a key for reaching this goal is sound knowledge of the problem at hand. In case of single-objective, continuous, global optimization problems, such knowledge can be gained by Exploratory Landscape Analysis (ELA), which computes features that quantify the problem's landscape prior to optimization. Due to the various backgrounds of researches that developed such features, there nowadays exist numerous implementations of feature sets across multiple programming languages, which is a blessing and burden at the same time. Therecently developed R-package flacco takes multiple of these feature sets (from the different packages and languages) and combines them within a single R-package. While this is very beneficial for R-users, users of other programming languages are left out. Within this paper, we introduce flaccogui, a graphical user interface that does not only make flacco more user-friendly, but due to a platform-independent web-Application also allows researchers that are not familiar with R to perform ELA and benefit of the advantages of flacco. © 2017 ACM.","Automated Algorithm Selection; Continuous Optimization; Exploratory Landscape Analysis; Graphical User Interface; R-Package","Global optimization; Graphical user interfaces; Optimization; Problem oriented languages; Automated algorithms; Continuous optimization; Global optimization problems; Landscape analysis; Optimal solutions; Platform independent; Single objective; WEB application; User interfaces",2-s2.0-85026864440
"Greco A., Cannizzaro F., Pluchino A.","Seismic collapse prediction of frame structures by means of genetic algorithms",2017,"Engineering Structures",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018476661&doi=10.1016%2fj.engstruct.2017.03.075&partnerID=40&md5=9564bdb8213e649218bb366577d38463","This paper presents an automatic approach for the evaluation of the plastic loads and failure modes of planar frames. The method, based on the generation of elementary collapse mechanisms and on their linear combination aimed at minimizing the collapse load factor, is here originally extended to account for the contemporary presence of permanent and incremental loads. The presence of permanent distributed loads acting on beams, which affects the occurrence and the location of along-axis plastic hinges, is here evaluated by means of an exact formulation. Each elementary mechanism is built and studied through an original code developed in the agent-based programming language NetLogo, which is here employed for the first time with structural engineering purposes. The developed software interface is very user-friendly and has a great versatility. The minimization procedure is efficiently performed by means of genetic algorithms, which allow to compute both the collapse load factor and the correspondent failure mode with great accuracy and in a very short computing time. The possibility of taking into account both incremental horizontal load distributions at each floor level and permanent vertical loads on beams provides, for the first time, an automatic method which allows to obtain fast and reliable information on the resistance and collapse mechanisms of frame structures subjected to seismic loads. Many applications have been performed, either with reference to the classical plastic analysis approach, in which all the loads increase proportionally, or with seismic load scenarios. In the latter case, the numerical results have been compared to those obtained with pushover analysis, showing, in a shorter computing time, a very good correspondence even for large structures. Finally, a parametric study has also been performed, aiming at evaluating the influence of some geometric, mechanical and load distribution parameters on the ultimate collapse load of planar frames subjected to seismic loads. © 2017 Elsevier Ltd","Elementary mechanisms method; Genetic algorithms; Limit analysis; NetLogo; Seismic behaviour","Electric power plant loads; Failure modes; Genetic algorithms; Structural frames; Automatic approaches; Collapse predictions; Elementary mechanisms method; Limit analysis; Linear combinations; Minimization procedures; NetLogo; Seismic behaviour; Seismology; collapse; failure analysis; genetic algorithm; limit analysis; loading; prediction; seismicity; structural response",2-s2.0-85018476661
"Hishinuma T., Sakakibara T., Fujii A., Tanaka T., Hirasawa S.","Xev-GMP: Automatic Code Generation for GMP Multiple-Precision Code from C Code",2017,"Proceedings - 19th IEEE International Conference on Computational Science and Engineering, 14th IEEE International Conference on Embedded and Ubiquitous Computing and 15th International Symposium on Distributed Computing and Applications to Business, Engineering and Science, CSE-EUC-DCABES 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026679380&doi=10.1109%2fCSE-EUC-DCABES.2016.200&partnerID=40&md5=60b77b3fcc1fec55e4da9952c477ce64","We propose directive-based automatic code generation for a multiple-precision code from a C code with double precision. The multiple-precision code uses the GNU Multiple Precision Arithmetic Library (GMP). Our code generation functions can be separated into binary operations by automatically creating a temporary variable, transforming C mathematical functions into corresponding GMP functions, and managing functions that return a double-precision value. Our proposed system enables users to check the accuracy dependency of many algorithms by adding a few directives to C codes with double precision. © 2016 IEEE.","Code generation; Floating point arithmetic operations; Multiple precision arithmetic","Automatic programming; Codes (symbols); Digital arithmetic; Distributed computer systems; Functions; Ubiquitous computing; Automatic code generations; Binary operations; C codes; Code Generation; Double precision; Floating point arithmetic operation; Mathematical functions; Multiple precision arithmetic; C (programming language)",2-s2.0-85026679380
"Wakatani A., Maeda T.","Evaluation of Software Education Using Auto-generated Exercises",2017,"Proceedings - 19th IEEE International Conference on Computational Science and Engineering, 14th IEEE International Conference on Embedded and Ubiquitous Computing and 15th International Symposium on Distributed Computing and Applications to Business, Engineering and Science, CSE-EUC-DCABES 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026640661&doi=10.1109%2fCSE-EUC-DCABES.2016.269&partnerID=40&md5=12f4f958b745e5636e60c01384eb5796","Programming language is one of fundamental issues on software education. Not only knowledge such as grammar but also practical programming experiences are important to the learning of programming languages. In this paper, we classify programming exercises into the following two types: 1) syntax practices for understanding the grammar and 2) semantics practices for understanding the flow of a program, and then we develop a web-base application that automatically generates programming exercises by using templates and PHP language. We also evaluate the effectiveness of the system composed of both our web-based system and an electronic materials for learning programming languages by several experiments, and find that the semantic practices require more time than the syntax practices to enhance the understanding of programming languages thoroughly. © 2016 IEEE.",,"Application programs; Computer programming; Distributed computer systems; Education; Semantic Web; Semantics; Syntactics; Electronic materials; Learning-of-programming; Programming exercise; Programming experience; Software education; Web-based system; Ubiquitous computing",2-s2.0-85026640661
"Yu X., Wen W., Cheng Z., Shengzhi G.","Developing a novel environment friendly epoxy solventless impregnating resin without anhydride for high voltage motor",2017,"ICEMPE 2017 - 1st International Conference on Electrical Materials and Power Equipment",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027833184&doi=10.1109%2fICEMPE.2017.7982150&partnerID=40&md5=649fec9ea628376412477882613de245","In this article, a novel environmentally friendly anhydride free, solventless free epoxy impregnating resin was developed by synthesizing a novel epoxy resin with high reactivity and heat resistance, then combining with environment friendly epoxy cross-linking monomers and effective initiator-inhibitor. The new resin has excellent processing abilities and moisture resistance, suitable for VPI processing. The comprehensive performance of the new resin was investigated systematically, including curing reaction, volatile material content, storage stability, glass transition temperature, heat resistance, electric insulation performance of simulated coils and compared with similar properties using a conventional epoxy anhydride VPI resin. The results indicate that the new resin has many excellent characteristics, such as fast curing at 150°C, very low volatile material content (<3%), heat resistance; greater than Class H, excellent storage stability: without the need for drying and cooling, i.e. The viscosity increase was lower than 0.3 times when stored for 96h at 60°C. More important are the results from the simulated coils impregnated with the developed resin. They have low dielectric loss, dielectric loss increment and high breakdown voltage strength; equal to that of epoxy an anhydride VPI resin. The new resin can be used in any high voltage rotating motors. It is an excellent substitute for common unsaturated polyester and epoxy impregnating resins, and complies with the global environmental policy. Finally, the new resin offers a significant improvement on high voltage VPI resin products and environmental of insulation impregnating for motors and electrical equipment industry. © 2017 IEEE.","Environmental; Epoxy; High voltage; Motors; VPI resin","C (programming language); Curing; Dielectric devices; Dielectric losses; Electric insulation; Electric resistance; Environmental protection; Equipment; Glass transition; Heat resistance; Heterojunction bipolar transistors; Motors; Polyester resins; Specific heat; Unsaturated polymers; Comprehensive performance; Crosslinking monomers; Environmental; Epoxy; High breakdown voltage; High voltage; Insulation performance; Unsaturated polyester; Epoxy resins",2-s2.0-85027833184
"Ermakov A.D., Prokopenko S.A., Yevtushenko N.V.","Checking software security using EFSMs",2017,"International Conference of Young Specialists on Micro/Nanotechnologies and Electron Devices, EDM",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027172607&doi=10.1109%2fEDM.2017.7981714&partnerID=40&md5=ee6903dde5b85296db23449a45161429","The paper is devoted to analyzing unsafe features of an Extended Finite State Machine such as the exceeding of the value of a context variable and/or an output parameter, the reachability of critical states, etc. As the ordinary simulation of an EFSM is very complex, the well known verifier Java Path Finder is used for this purpose. The EFSM is implemented as a template Java code that is checked for critical situations by the above verifier. The efficiency of a proposed approach is illustrated by an example. © 2017 IEEE.","EFSM; Software testing; Telecommunications","Computer aided software engineering; Computer software; Electron devices; Java programming language; Telecommunication; Context variables; Critical state; EFSM; Extended finite state machine; Java PathFinder; Output parameters; Software security; Unsafe features; Software testing",2-s2.0-85027172607
"Song R., Hou L., Wang Y., Li Y., Wang X., Zang Y., Zang Y., Wang X., Yan S.","Fluorescence Zn-based metal-organic frameworks for the detection of hydrogen sulfide in natural gas",2017,"Analytical Methods",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021980350&doi=10.1039%2fc7ay01193h&partnerID=40&md5=14f9f3b8416b2f00db81b632b4e1734a","Fluorescent zinc-based metal-organic frameworks (Zn-MOFs) were synthesized via the solvothermal method. The materials were characterized by scanning electron microscopy, Brunauer-Emmett-Teller analysis, X-ray diffraction, Fourier transform infrared spectroscopy, fluorescence spectroscopy and fluorescence photography. The results illustrated that the synthesized Zn-MOFs were highly porous with a maximum surface area of 5755 m2 g-1. These MOFs had excellent fluorescence properties, which could be efficiently quenched by trace amounts of hydrogen sulfide (H2S). The experimental results indicated that Zn-MOFs were responsive to H2S at the nmol mL-1 level, which is advantageous for fluorescent Zn-MOF-based sensing materials. The synthesized Zn-MOFs also displayed high adsorption abilities toward H2S. It was illustrated that adsorption played an important role in the preconcentration of H2S, which can further increase the fluorescence quenching efficiency and improve the sensitivity for H2S. Under optimized conditions, this Zn-MOF probe exhibited rapid response, excellent selectivity and sensitivity in detection of H2S. The decrease in FL intensity was linearly related to the H2S concentration between 0.094 μmol mL-1 and 18 μmol mL-1. The developed strategy was applied to real natural gas well samples. These results indicated that Zn-MOF is a usable functional material for H2S detection in natural gas, and potentially useful in monitoring natural gas quality and removing H2S. © 2017 The Royal Society of Chemistry.",,"Crystalline materials; Fluorescence; Fluorescence spectroscopy; Fourier transform infrared spectroscopy; Functional materials; Hydrogen sulfide; Java programming language; Natural gas; Quenching; Scanning electron microscopy; Sulfur determination; X ray diffraction; Zinc; Adsorption ability; Brunauer Emmett Teller analysis; Fluorescence properties; Fluorescence quenching; Metal organic framework; Optimized conditions; Selectivity and sensitivity; Solvothermal method; Zinc sulfide",2-s2.0-85021980350
"Ratiu D., Ulrich A.","Increasing usability of spin-based C code verification using a harness definition language: Leveraging model-driven code checking to practitioners",2017,"SPIN 2017 - Proceedings of the 24th ACM SIGSOFT International SPIN Symposium on Model Checking of Software",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027691155&doi=10.1145%2f3092282.3092283&partnerID=40&md5=6ea08f18584631a7c4e92c807156508c","Due to its capabilities to integrate well with C code, Spin has been used for C code verification based on environment models that describe the context, in which the software under verification is expected to run. In practice this approach requires an in-depth knowledge of Promela and the underlying technology. Moreover environment models tend to be verbose and exhibit heavily intertwined statements of Promela and C code. Thereby, writing and understanding such hybrid models is dificult and error-prone. Alleviating this problem we develop a specialized language for expressing environment models used in verification harnesses. Our language harmonizes the use of Promela and C in a homogeneous way that is suitable for practitioners. We show how a small number of language concepts is suficient to define environments for a wide variety of commonly encountered software components written in C. The approach is integrated in the development platform mbeddr, a technology stack for embedded programming and formal verification developed on top of JetBrains' MPS language workbench. © 2017 Association for Computing Machinery.","Domain-specific languages; Model checking; Spin; Testing","Codes (symbols); Computer programming languages; Formal methods; Formal verification; Model checking; Problem oriented languages; Testing; Verification; Development platform; Domain specific languages; Embedded programming; Environment models; In-depth knowledge; Language workbenches; Software component; Spin; C (programming language)",2-s2.0-85027691155
"Consel C., Kabac M.","Internet of Things: From Small-to Large-Scale Orchestration",2017,"Proceedings - International Conference on Distributed Computing Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027255273&doi=10.1109%2fICDCS.2017.314&partnerID=40&md5=86493675cd662a09101837b312c0180b","The domain of Internet of Things (IoT) is rapidly expanding beyond research, and becoming a major industrial market with such stakeholders as major manufacturers of chips and connected entities (i.e., things), and fast-growing operators of wide-area networks. Importantly, this emerging domain is driven by applications that leverage an IoT infrastructure to provide users with innovative, high-value services. IoT infrastructures range from small scale (e.g., homes and personal health) to large scale (e.g., cities and transportation systems). In this paper, we argue that there is a continuum between orchestrating connected entities in the small and in the large. We propose a unified approach to application development, which covers this spectrum. To do so, we examine the requirements for orchestrating connected entities and address them with domainspecific design concepts. We then show how to map these design concepts into dedicated programming patterns and runtime mechanisms.Our work revolves around domain-specific concepts and notations, integrated into a tool-based design methodology and dedicated to develop IoT applications. We have applied our work across a spectrum of infrastructure sizes, ranging from an automated pilot in avionics, to an assisted living platform for the home of seniors, to a parking management system in a smart city. © 2017 IEEE.","Domain-specific languages; Internet of things; MapReduce; Orchestration; Programming frameworks","Computer programming languages; Distributed computer systems; Industrial research; Problem oriented languages; Smart city; Transportation; Wide area networks; Application development; Domain specific languages; Internet of Things (IOT); Map-reduce; Orchestration; Parking management systems; Programming framework; Transportation system; Internet of things",2-s2.0-85027255273
"Pirapuraj P., Perera I.","Analyzing source code identifiers for code reuse using NLP techniques and WordNet",2017,"3rd International Moratuwa Engineering Research Conference, MERCon 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027839003&doi=10.1109%2fMERCon.2017.7980465&partnerID=40&md5=bd5ba6a2c1d572ff4f24486d1082b1de","Massive amount of source codes are available free and open. Reusing those open source codes in projects can reduce the project duration and cost. Even though several Code Search Engines (CSE) are available, finding the most relevant code can be challenging. In this paper we propose a framework that can be used to overcome the above said challenge. The proposed solution starts with a Software Architecture (Class Diagram) in XML format and extracts information from the XML file, and then, it fetches relevant projects using three types of crawlers from GitHub, SourceForge, and GoogleCode. Then it finds the most relevant projects among the vast amount of downloaded projects. This research considers only Java projects. All java files in every project will be represented in Abstract Syntax Tree (AST) to extract identifiers (class names, method names, and attributes name) and comments. Action words (verbs) are extracted from comments using Part of Speech technique (POS). Those identifiers and XML file information need to be analyzed for matching. If identifiers are matched, marks will be given to those identifiers, likewise marks will be added together and then if the total mark is greater than 50%, the.java file will be considered as a relevant code. Otherwise, WordNet will be used to get synonym of those identifiers and repeat the matching process using those synonyms. For connected word identifiers, camel case splitter and N-gram technique are used to separate those words. The Stanford Spellchecker is used to identify abbreviated words. The results indicate successful identification of relevant source codes. © 2017 IEEE.","Class Diagram; Code reuse; N-gram technique; PoS Tagging; Software Architecture; Source code identification; WordNet","Computational linguistics; Computer programming languages; Computer software reusability; Engineering research; Java programming language; Ontology; Open source software; Search engines; Semantics; Software architecture; XML; Class diagrams; Code reuse; N-grams; PoS tagging; Source codes; Wordnet; Codes (symbols)",2-s2.0-85027839003
"Wang Z., Cadambe V.R.","Multi-Version Coding - An Information-Theoretic Perspective of Consistent Distributed Storage",2017,"IEEE Transactions on Information Theory",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028910037&doi=10.1109%2fTIT.2017.2725273&partnerID=40&md5=ff08424880f7da20ab75853903fa7bee","In applications of distributed storage systems to distributed computing and implementation of key-value stores, the following property, usually referred to as consistency in computer science and engineering, is an important requirement: as the data stored changes, the latest version of the data must be accessible to a client that connects to the storage system. Motivated by technological trends where key-value stores are increasingly implemented in highspeed memory, an information theoretic formulation called multi-version coding is introduced in the paper, in order to understand and minimize the memory footprint, or storage overhead, of consistent distributed storage. Multi-version coding is characterized by &#x03BD; totally ordered versions of a message, and a storage system with n servers. At each server, values corresponding to an arbitrary subset of the &#x03BD; versions are received and encoded. For any subset of c servers in the storage system, the value corresponding to the latest common version, or a later version as per the total ordering, among the c servers is required to be decodable. An achievable multi-version code construction via linear coding and a converse result that shows that the construction is asymptotically tight when &#x03BD;&#x007C;(c &#x2013; 1), are provided. An implication of the converse is that there is an inevitable price, in terms of storage cost, to ensure consistency in distributed storage systems. IEEE","Computational modeling; Decoding; Distributed databases; Encoding; Market research; Servers","C (programming language); Codes (symbols); Decoding; Digital storage; Encoding (symbols); Information theory; Multiprocessing systems; Programming theory; Servers; Computational model; Computer science and engineerings; Distributed database; Distributed storage; Distributed storage system; High-speed memory; Market researches; Technological trends; Distributed computer systems",2-s2.0-85028910037
"Mehta A., Baddour R., Svensson F., Gustafsson H., Elmroth E.","Calvin Constrained - A Framework for IoT Applications in Heterogeneous Environments",2017,"Proceedings - International Conference on Distributed Computing Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027276378&doi=10.1109%2fICDCS.2017.181&partnerID=40&md5=f7dadf03e255fdc34adb03b46f768ec8","Calvin is an IoT framework for application development, deployment and execution in heterogeneous environments, that includes clouds, edge resources, and embedded or constrained resources. Inside Calvin, all the distributed resources are viewed as one environment by the application. The framework provides multi-tenancy and simplifies development of IoT applications, which are represented using a dataflow of application components (named actors) and their communication. The idea behind Calvin poses similarity with the serverless architecture and can be seen as Actor as a Service instead of Function as a Service. This makes Calvin very powerful as it does not only scale actors quickly but also provides an easy actor migration capability. In this work, we propose Calvin Constrained, an extension to the Calvin framework to cover resource-constrained devices. Due to limited memory and processing power of embedded devices, the constrained side of the framework can only support a limited subset of the Calvin features. The current implementation of Calvin Constrained supports actors implemented in C as well as Python, where the support for Python actors is enabled by using MicroPython as a statically allocated library, by this we enable the automatic management of state variables and enhance code re-usability. As would be expected, Python-coded actors demand more resources over C-coded ones. We show that the extra resources needed are manageable on current off-the-shelve micro-controller-equipped devices when using the Calvin framework. © 2017 IEEE.","Dataflow Application Development Model; Distributed Cloud; IoT; Serverless Architecture","C (programming language); Data flow analysis; High level languages; Internet of things; Network function virtualization; Application components; Application development; Constrained resources; Distributed clouds; Distributed resources; Heterogeneous environments; Resourceconstrained devices; Serverless architecture; Distributed computer systems",2-s2.0-85027276378
"Hua J., Khurshid S.","EdSketch: Execution-driven sketching for Java",2017,"SPIN 2017 - Proceedings of the 24th ACM SIGSOFT International SPIN Symposium on Model Checking of Software",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027694183&doi=10.1145%2f3092282.3092285&partnerID=40&md5=08379e47f4f33c7e24ce0914619a8353","Sketching is a relatively recent approach to program synthesis, which has shown much promise. The key idea in sketching is to allow users to write partial programs that have ""holes"" and provide test harnesses or reference implementations, and let synthesis tools create program fragments that fill the holes such that the resulting complete program has the desired functionality. Traditional solutions to the sketching problem perform a translation to SAT and employ CEGIS. While effective for a range of programs, when applied to real applications, such translation-based approaches have a key limitation: they require either translating all relevant libraries that are invoked directly or indirectly by the given sketch - which can lead to impractical SAT problems - or creating models of those libraries - which can require much manual effort. This paper introduces execution-driven sketching, a novel approach for synthesis of Java programs with respect to the given test suite using a backtracking search that is commonly employed in software model checkers. The key novelty of our work is to introduce effective pruning strategies to eficiently explore the actual program behaviors in presence of libraries and to provide a practical solution to sketching small parts of real-world applications, which may use complex constructs of modern languages, such as reflection or native calls. Our tool EdSketch embodies our approach in two forms: a stateful search based on the Java PathFinder model checker; and a stateless search based on re-execution inspired by the VeriSoft model checker. Experimental results show that EdSketch's performance compares well with the well-known SAT-based Sketch system for a range of small but complex programs, and moreover, that EdSketch can complete some sketches that require handling complex constructs. © 2017 Association for Computing Machinery.","Backtracking search; Execution-driven synthesis; Program sketching","Application programs; Computer software; Java programming language; Libraries; Program translators; Software testing; Backtracking search; Practical solutions; Program fragments; Program sketching; Program synthesis; Real applications; Reference implementation; Software model checkers; Model checking",2-s2.0-85027694183
"Bayram M.B., Sefa I., Balci S.","A static exciter with interleaved buck converter for synchronous generators",2017,"International Journal of Hydrogen Energy",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016400891&doi=10.1016%2fj.ijhydene.2017.03.062&partnerID=40&md5=e56756b8c4dd31f23d932768df9d4a2e","In this study, an interleaved buck converter based static excitation system is proposed for large-scale synchronous generators where thyristor controlled systems are widely used. The proposed system removes the slow response drawback of the thyristor controlled systems even for dynamic load conditions. The finite element analysis based model of the synchronous generator's electromagnetic system is obtained and co-simulations of the modeled generator and proposed interleaved buck converter are performed. Results obtained from simulation results show that, the proposed system offers better performance in terms of step response and inductor current ripple. The simulation results are validated with experimental studies. All measurement, monitoring and control processes have been performed with field programmable gate array called NI CompactRIO platform and LabVIEW software. © 2017 Hydrogen Energy Publications LLC","Co-simulation; CompactRIO; Interleaved buck converter; LabVIEW; Static excitation; Synchronous generator","Computer programming languages; Dynamic loads; Electric generators; Field programmable gate arrays (FPGA); Finite element method; Static electricity; Synchronous generators; Thyristors; CompactRIO; Cosimulation; Interleaved buck converters; LabViEW; Static excitation; DC-DC converters",2-s2.0-85016400891
"Botha H., Tkachuk O., Van Der Merwe B., Visser W.","Addressing challenges in obtaining high coverage when model checking android applications",2017,"SPIN 2017 - Proceedings of the 24th ACM SIGSOFT International SPIN Symposium on Model Checking of Software",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027702734&doi=10.1145%2f3092282.3092302&partnerID=40&md5=ee2c7c388a2ec335f7faf22d0ab9d44f","Current dynamic analysis tools for Android applications do not get good code coverage since they can only explore a subset of the behaviors of the applications and do not have full control over the environment in which they execute. In this work we use model checking to systematically explore application paths while reducing the analysis size using state matching and backtracking. In particular, we extend the Java PathFinder (JPF) model checking environment for Android. We describe the difficulties one needs to overcome to make this a reality as well as our current approaches to handling these issues. We obtain significantly higher coverage using shorter event sequences on a representative sample of Android apps, when compared to Dynodroid and Sapienz, the current state-of-the-art dynamic analysis tools for Android applications. © 2017 ACM.","Android applications; Dynamic analysis; Java PathFinder; Model checking","Android (operating system); Dynamic analysis; Java programming language; Android applications; Current dynamics; Dynamic analysis tools; Event sequence; Full control; Java PathFinder; Representative sample; State of the art; Model checking",2-s2.0-85027702734
"Lv D., Chen Y., Li Y., Shi R., Wu H., Sun X., Xiao J., Xi H., Xia Q., Li Z.","Efficient Mechanochemical Synthesis of MOF-5 for Linear Alkanes Adsorption",2017,"Journal of Chemical and Engineering Data",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024379456&doi=10.1021%2facs.jced.7b00049&partnerID=40&md5=9ca9d216cb66a5ae84ba2161e72ab28b","An efficient mechanochemical method was proposed to synthesize MOF-5 with high BET area within minutes. The effects of parameters such as solvents activation, the metal/ligand ratio, grinding speed and time were carefully studied and the optimized MOF-5-B was used to investigate its adsorption properties of linear alkanes (C1-nC7). The results showed that solvents activation played an important role in the formation of MOF-5. Besides, the Zn2+/BDC ratio had a great impact on the formation of crystalline MOF-5, and the appropriate Zn2+/BDC ratio was 3:1 for mechanochemical synthesis of MOF-5. Grinding for 60 min could lead to a better crystallinity and the highest surface area of MOF-5-B. The resulting MOF-5-B possessed BET area of 3465.9 m2·g-1. More importantly, MOF-5-B showed a preferential adsorption for long alkanes over short alkanes at low pressures. The saturated adsorption capacities of nC4-nC7 decreased with the increase of hydrocarbon chain length. The isosteric heats of C1-nC7 increased with the increase of the alkyl chain length. Furthermore, the adsorption capacities of the alkanes (C3-nC7) on MOF-5-B were much higher than those of conventional activated carbons and zeolites. (Graph Presented). © 2017 American Chemical Society.",,"Activated carbon; Adsorption; Chain length; Chemical activation; Grinding (machining); Paraffins; Zinc; Adsorption capacities; Adsorption properties; Alkyl chain lengths; Hydrocarbon chain length; Mechano-chemical methods; Mechanochemical synthesis; Preferential adsorption; Saturated adsorption capacity; Java programming language",2-s2.0-85024379456
"Pinisetty S., Roop P.S., Smyth S., Tripakis S., Von Hanxleden R.","Runtime enforcement of reactive systems using synchronous enforcers",2017,"SPIN 2017 - Proceedings of the 24th ACM SIGSOFT International SPIN Symposium on Model Checking of Software",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027712820&doi=10.1145%2f3092282.3092291&partnerID=40&md5=1b09affba7b1444fefc2a3744d64b31e","Synchronous programming is a paradigm of choice for the design of safety-critical reactive systems. Runtime enforcement is a technique to ensure that the output of a black-box system satisfies some desired properties. This paper deals with the problem of runtime enforcement in the context of synchronous programs. We propose a framework where an enforcer monitors both the inputs and the outputs of a synchronous program and (minimally) edits erroneous inputs/outputs in order to guarantee that a given property holds. We define enforceability conditions, develop an online enforcement algorithm, and prove its correctness. We also report on an implementation of the algorithm on top of the KIELER framework for the SCCharts synchronous language. Experimental results show that enforcement has minimal execution time overhead, which decreases proportionally with larger benchmarks. © 2017 Copyright held by the owner/author(s).","Automata; Runtime enforcement; Runtime monitoring; Safety properties; SCCharts; Synchronous programming","Safety engineering; Automata; Runtime enforcements; Runtime Monitoring; Safety property; SCCharts; Synchronous programming; Model checking",2-s2.0-85027712820
"Rao B., Mishra S., Mishra S.","An approach to mining information from telephone graph using graph mining techniques",2017,"Graph Theoretic Approaches for Analyzing Large-Scale Social Networks",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028844737&doi=10.4018%2f978-1-5225-2814-2.ch003&partnerID=40&md5=f225d1852bc236c65c635697586b4cd2","This chapter focuses on methods to study communication in a real world social network using the basic concepts of graph theory. The initial section of this chapter starts with a general introduction consisting of related literature and definitions towards understanding the basic concepts of graph mining and graph theory, defining a telephone graph and use of telephone graph for social contexts. The authors have proposed an algorithm for extracting different network provider's sub-graphs, weak and strong connected sub-graphs and extracting incoming and outgoing calls of subscribers which have direct application for studying the human behavior in telephone network. The authors have considered two examples. The authors have implemented the proposed algorithm in C++ programming language and obtained satisfactory results. Finally, the authors have included the snapshots of the output in the chapter to enhance the interest of the readers. © 2018 IGI Global. All rights reserved.",,,2-s2.0-85028844737
"Jing Y., Wang H., Huang Y., Zhang L., Cao Y.","Towards Formalizing of MapReduce",2017,"Proceedings - 3rd IEEE International Conference on Big Data Security on Cloud, BigDataSecurity 2017, 3rd IEEE International Conference on High Performance and Smart Computing, HPSC 2017 and 2nd IEEE International Conference on Intelligent Data and Security, IDS 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027438936&doi=10.1109%2fBigDataSecurity.2017.32&partnerID=40&md5=6c2302dd11294f8d9536f27115476d66","As a powerful distributed computing model, MapReduce has been widely used in many domains to process massive amounts of data. To ensure its correctness, one of the appropriate ways is formal methods. In this paper, we will propose a formal language to model MapReduce Programs based on our previous work. The language describes the MapReduce programming model from a view of files and blocks. So the details of data processing during a MapReduce computation can be clearly demonstrated. Certainly some parallel commands are introduced to reflect the parallelization of the computation. Based on this language, the correctness verification of the MapReduce programming model can be developed. © 2017 IEEE.","Big Data Processing; Concurrency; Formal Methods; MapReduce; Modeling Langugage",,2-s2.0-85027438936
"Cochez M., Huser D., Decker S.","The Future of the Semantic Web: Prototypes on a Global Distributed Filesystem",2017,"Proceedings - International Conference on Distributed Computing Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027261177&doi=10.1109%2fICDCS.2017.270&partnerID=40&md5=d369ef94f3411b28f048b367cd512e8b","An important part of the Semantic Web vision is the idea that data is shared seamlessly and that world wide distributed, accessible, and interlinked knowledge bases can be created. However, the current incarnation of the Semantic Web falls short of this vision: while some necessary infrastructure (e.g., Linked Data) has been put in place, the current use of Linked Data in the Semantic Web is still happening in data silos, and sharing and reusing of knowledge is cumbersome and not straightforward. Recently the idea of prototypical objects was proposed to remedy this situation. This concept, known as Prototypes originates from early Frame systems and is also adopted in programming languages such as Javascript. In this vision paper we describe how a distributed file system forms a natural habitat for prototype knowledge representation, advancing the Semantic Web. In particular, we describe how we envision the deployment of Linked Data and Prototype Knowledge bases atop of the InterPlanetary File System (IPFS), which has several useful features matching the needs for knowledge representation based on prototypes. © 2017 IEEE.",,"Data handling; Distributed computer systems; File organization; Knowledge representation; Distributed file systems; Distributed file-system; Features matching; Frame systems; Knowledge basis; Linked datum; Natural habitat; Semantic web vision; Semantic Web",2-s2.0-85027261177
"Trost A., Žemva A.","Pipeline circuit synthesis from Python code",2017,"2017 6th Mediterranean Conference on Embedded Computing, MECO 2017 - Including ECYPS 2017, Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027049803&doi=10.1109%2fMECO.2017.7977227&partnerID=40&md5=6f0c913c4cf11bedda38213887d0904a","This paper presents methodology and tools for generating pipeline digital circuits from an algorithm specification in Python programming language. The Python language provides a feature rich environment for the algorithm design. Conversion of the algorithm to a register-level code, such as Verilog, requires substantial hardware design and skills. We present a tool for automatic pipeline circuit synthesis from a function in pure Python code and example case. © 2017 IEEE.","high level synthesis; pipeline circuit; Python; Verilog","Codes (symbols); Computer hardware description languages; High level languages; High level synthesis; Pipelines; Timing circuits; Algorithm design; Circuit synthesis; Hardware design; Python; Python code; PYTHON language; Python programming language; Pipeline codes",2-s2.0-85027049803
"Vandin A.","Language-based abstractions for dynamical systems",2017,"Electronic Proceedings in Theoretical Computer Science, EPTCS",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030158000&doi=10.4204%2fEPTCS.250.2&partnerID=40&md5=4d2b154a2b31804ad6cf7c683fe825ce","Ordinary differential equations (ODEs) are the primary means to modelling dynamical systems in many natural and engineering sciences. The number of equations required to describe a system with high heterogeneity limits our capability of effectively performing analyses. This has motivated a large body of research, across many disciplines, into abstraction techniques that provide smaller ODE systems while preserving the original dynamics in some appropriate sense. In this paper we give an overview of a recently proposed computer-science perspective to this problem, where ODE reduction is recast to finding an appropriate equivalence relation over ODE variables, akin to classical models of computation based on labelled transition systems. © Valentina Castiglioni & Simone Tini.",,"Abstracting; Computer programming languages; Differential equations; Dynamical systems; Abstraction techniques; Classical model; Engineering science; Equivalence relations; High heterogeneity; Labelled transition systems; Ordinary differential equations",2-s2.0-85030158000
"Liang B.-J., Lin Y.-J.","A web-based mobile medical image reading system",2017,"Proceedings - 2016 8th International Conference on Information Technology in Medicine and Education, ITME 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027731840&doi=10.1109%2fITME.2016.0021&partnerID=40&md5=f8d5028c88105307cb9728ea063a9012","This paper presents a solution of a cross platform medical image reading system which supports access medical image on mobile platform based on WEB. In the web front-end, jQuery Mobile open source library is used for interface programming and gesture recognition. In the web server side, we develop Web Service with Visual C++ program language and use DICOM-WADO protocol to convert DICOM image to JPEG image. Finally, the client browser uses AJAX technology to get the server side JPEG image in an asynchronous way and display it. Tested on the Google Android, Apple IOS and other mobile platforms, the system can display medical images, adjust the images window width and window level, zoom image and other operation etc... The results show that the system has achieved its stated design goal. © 2016 IEEE.","B/S Architecture; DICOM; DICOM-WADO; Medical Image; Mobile Health","C++ (programming language); Computer software; mHealth; Mobile phones; Open source software; Visual languages; Web services; Websites; AJAX technology; B/S architecture; Cross-platform; DICOM; DICOM-WADO; Mobile platform; Open-source libraries; Program language; Medical imaging",2-s2.0-85027731840
"Sundharam S.M., Fejoz L., Navet N.","Connected motorized riders - A smart mobility system to connect two and three-wheelers",2017,"Proceedings - 2016 6th International Symposium on Embedded Computing and System Design, ISED 2016",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027584601&doi=10.1109%2fISED.2016.7977110&partnerID=40&md5=75ac2ac1afe8f02ee6f486f3f9c7b3e1","The Smart Cities Mission has been launched in India in 2015 to develop 100 cities, with smart mobility being one of the main topics in the mission. As urban areas are flooded with two (motorcycles) and three wheelers (auto-rickshaws), introducing smart control of such vehicles may reduce the congestions on the roads and the number of accidents. Indeed, over-speeding and drunken driving are common traffic violations. In this project we propose an IoT-based smart mobility system which tracks data, such as the vehicle location, vehicle speed, alcohol level of the driver, etc. efficiently over the internet. Our system has been conceived with CPAL, a high-level language meant to simulate and execute Cyber Physical Systems including IoT applications. A prototype running on ARM mbed IoT hardware, shows the feasibility of our concept. We believe that more efficient and interactive traffic management, more disciplined driving behaviors, reduction in accident rate, more controlled pollution, increased passenger safety can be achieved if systems like the one prototyped in this work deployed contributing to smarter cities. © 2016 IEEE.",,"Accidents; Computer programming languages; Embedded systems; High level languages; Highway traffic control; Internet of things; Systems analysis; Vehicles; Alcohol levels; Driving behavior; Interactive traffics; IOT applications; Mobility systems; Passenger safety; Traffic violation; Vehicle location; Smart city",2-s2.0-85027584601
"Canale P., Fontanella A., Torti E., Danese G., Leporati F.","Development of a real-time heart rate estimation algorithm on a low-power device",2017,"2017 6th Mediterranean Conference on Embedded Computing, MECO 2017 - Including ECYPS 2017, Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027066443&doi=10.1109%2fMECO.2017.7977199&partnerID=40&md5=d722848736f897bb7b45d372787a4e6b","This paper introduces an algorithm for the estimation of heart rate during physical activities through photoplethysmographic signals, acquired by a wearable device. Firstly, the algorithm has been developed in Matlab and then ported in C language. In this way, it has been possible to test it on a low-power micro-controller (STM32F4DISCOVERY) and to check the similarity of the results, given by the two algorithm versions. Moreover, tests conducted on a public dataset show that the algorithm is real-time compliant. Finally, the power consumption estimation conducted proves the feasibility of a wearable device since the micro-controllers requires less than 20 mW. © 2017 IEEE.","component; embedded device; hearth-rate; photoplethysmogram; realtime digital signal elaboration","Heart; MATLAB; Microcontrollers; Statistical tests; Wearable technology; component; Digital signals; Embedded device; Low-power devices; Photo-plethysmogram; Photoplethysmographic signals; Physical activity; Power consumption estimation; C (programming language)",2-s2.0-85027066443
"Ding Y., Chen Y.-P., Zhang X., Chen L., Dong Z., Jiang H.-L., Xu H., Zhou H.-C.","Controlled Intercalation and Chemical Exfoliation of Layered Metal-Organic Frameworks Using a Chemically Labile Intercalating Agent",2017,"Journal of the American Chemical Society",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024389853&doi=10.1021%2fjacs.7b04829&partnerID=40&md5=6bed229e548215213de4c25abf044d77","Creating ordered two-dimensional (2D) metal-organic framework (MOF) nanosheets has attracted extensive interest. However, it still remains a great challenge to synthesize ultrathin 2D MOF nanosheets with controlled thickness in high yields. In this work, we demonstrate a novel intercalation and chemical exfoliation approach to obtain MOF nanosheets from intrinsically layered MOF crystals. This approach involves two steps: first, layered porphyrinic MOF crystals are intercalated with 4,4′-dipyridyl disulfide through coordination bonding with the metal nodes; subsequently, selective cleavage of the disulfide bond induces exfoliation of the intercalated MOF crystals, leading to individual freestanding MOF nanosheets. This chemical exfoliation process can proceed efficiently at room temperature to produce ultrathin (∼1 nm) 2D MOF nanosheets in ∼57% overall yield. The obtained ultrathin nanosheets exhibit efficient and far superior heterogeneous photocatalysis performance compared with the corresponding bulk MOF. © 2017 American Chemical Society.",,"Chemical bonds; Covalent bonds; Crystalline materials; Java programming language; Nanosheets; Chemical exfoliations; Controlled thickness; Coordination bonding; Heterogeneous photocatalysis; Intercalating agents; Metal organic framework; Two Dimensional (2 D); Ultrathin nanosheets; Intercalation; disulfide; intercalating agent; metal organic framework; nanosheet; Article; chemical exfoliation; chemical procedures; crystal; elemental analysis; energy dispersive X ray spectroscopy; intercalation complex; synthesis; X ray diffraction; X ray photoelectron spectroscopy",2-s2.0-85024389853
"Chen C., Li B., Zhou L., Xia Z., Feng N., Ding J., Wang L., Wan H., Guan G.","Synthesis of Hierarchically Structured Hybrid Materials by Controlled Self-Assembly of Metal-Organic Framework with Mesoporous Silica for CO2 Adsorption",2017,"ACS Applied Materials and Interfaces",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024127726&doi=10.1021%2facsami.7b08117&partnerID=40&md5=8a8f6be26efa8dde90b50959eafd6e65","The HKUST-1@SBA-15 composites with hierarchical pore structure were constructed by in situ self-assembly of metal-organic framework (MOF) with mesoporous silica. The structure directing role of SBA-15 had an obvious impact on the growth of MOF crystals, which in turn affected the morphologies and structural properties of the composites. The pristine HKUST-1 and the composites with different content of SBA-15 were characterized by XRD, N2 adsorption-desorption, SEM, TEM, FT-IR, TG, XPS, and CO2-TPD techniques. It was found that the composites were assembled by oriented growth of MOF nanocrystals on the surfaces of SBA-15 matrix. The interactions between surface silanol groups and metal centers induced structural changes and resulted in the increases in surface areas as well as micropore volumes of hybrid materials. Besides, the additional constraints from SBA-15 also restrained the expansion of HKUST-1, contributing to their smaller crystal sizes in the composites. The adsorption isotherms of CO2 on the materials were measured and applied to calculate the isosteric heats of adsorption. The HS-1 composite exhibited an increase of 15.9% in CO2 uptake capacity compared with that of HKUST-1. Moreover, its higher isosteric heats of CO2 adsorption indicated the stronger interactions between the surfaces and CO2 molecules. The adsorption rate of the composite was also improved due to the introduction of mesopores. Ten cycles of CO2 adsorption-desorption experiments implied that the HS-1 had excellent reversibility of CO2 adsorption. This study was intended to provide the possibility of assembling new composites with tailored properties based on MOF and mesoporous silica to satisfy the requirements of various applications. © 2017 American Chemical Society.","CO2 adsorption; composite; hierarchical structure; mesoporous silica; metal-organic framework; self-assembly","Adsorption; Adsorption isotherms; Carbon dioxide; Composite materials; Crystal structure; Crystalline materials; Desorption; Hybrid materials; Hydraulic structures; Java programming language; Metals; Self assembly; Silica; Structural properties; Controlled self-assembly; Hierarchical pore structures; Hierarchical structures; Isosteric heats of adsorptions; Mesoporous Silica; Metal organic framework; Structure-directing roles; Tailored properties; Mesoporous materials",2-s2.0-85024127726
"Ranasinghe S.N., Middleton P.H.","Modelling of single cell solid oxide fuel cells using COMSOL multiphysics",2017,"Conference Proceedings - 2017 17th IEEE International Conference on Environment and Electrical Engineering and 2017 1st IEEE Industrial and Commercial Power Systems Europe, EEEIC / I and CPS Europe 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026746136&doi=10.1109%2fEEEIC.2017.7977790&partnerID=40&md5=40b28a9e9aa5cbb7f6ede3f1e9b4b58d","Solid oxide fuel cells (SOFCs) have the potential to become one of the efficient and cost effective systems for direct conversion of a wide variety of fuels to electricity. In this study, we developed a three-dimensional multiphysics model for a single cell SOFC using COMSOL multiphysics (version 5.2) software and performed simulations to examine the effect of gas flow patterns (radial flow and counter flow) in different operating temperatures (700° C, 800° C and 1000° C) for a planar anode supported SOFC. With the help of the simulation results, we have analyzed the electrical characteristics of the single cell SOFCs. From the simulation results, it is observable that the radial gas flow pattern yields higher performance compared to the counter flow pattern and the performance also increases with operating temperature of the cell. © 2017 IEEE.",,"C (programming language); Cost effectiveness; Flow of gases; Flow patterns; Fuel cells; Radial flow; Temperature; Anode-supported SOFCs; Comsol multiphysics; Cost effective systems; Direct conversion; Electrical characteristic; Multi-physics modeling; Operating temperature; Solid oxide fuel cells (SOFCs); Solid oxide fuel cells (SOFC)",2-s2.0-85026746136
"Rodríguez N.A., Savateev A., Grela M.A., Dontsova D.","Facile Synthesis of Potassium Poly(heptazine imide) (PHIK)/Ti-Based Metal-Organic Framework (MIL-125-NH2) Composites for Photocatalytic Applications",2017,"ACS Applied Materials and Interfaces",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024099815&doi=10.1021%2facsami.7b04745&partnerID=40&md5=21f3a587f6d891866c151a802e202576","Photocatalytically active composites comprising potassium poly(heptazine imide) (PHIK) and a Ti-based metal-organic framework (MOF, MIL-125-NH2) are prepared in situ by simply dispersing both materials in water. The driving forces of composite formation are the electrostatic interactions between the solids and the diffusion of potassium ions from PHIK to MIL-125-NH2. This mechanism implies that other composites of poly(heptazine imide) salts and different MOFs bearing positive surface charge can potentially be obtained in a similar fashion. The suggested strategy thus opens a new avenue for the facile synthesis of such materials. The composites are shown to have a superior photocatalytic activity in Rhodamine B degradation under blue light irradiation. The reaction rate is doubled compared to that of pure MOF compound and is 7 times higher than the activity of the pristine PHIK. The results of the electron paramagnetic resonance (EPR) investigations and the analysis of the electronic structures of the solids suggest the electron transfer from MIL-125-NH2 to PHIK in the composite. The possible pathways for the dye degradation and the rationalization of the increased activity of the composites are elaborated. © 2017 American Chemical Society.","carbon nitride; composite; metal-organic framework; MIL-125-NH2; photocatalysis; photochromic effect; poly(heptazine imide)","Carbon; Carbon nitride; Composite materials; Crystalline materials; Electron spin resonance spectroscopy; Electronic structure; Java programming language; Magnetic resonance; Photocatalysis; Electron paramagnetic resonances (EPR); Metal organic framework; MIL-125-NH<sub>2</sub>; Photocatalytic activities; Photocatalytic application; Photochromic effects; poly(heptazine imide); Positive surface charge; Paramagnetic resonance",2-s2.0-85024099815
"Shu Y., Yan Y., Chen J., Xu Q., Pang H., Hu X.","Ni and NiO Nanoparticles Decorated Metal-Organic Framework Nanosheets: Facile Synthesis and High-Performance Nonenzymatic Glucose Detection in Human Serum",2017,"ACS Applied Materials and Interfaces",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024096506&doi=10.1021%2facsami.7b07501&partnerID=40&md5=2150e9a9b4de11983b2116093a4a2771","Ni-MOF (metal-organic framework)/Ni/NiO/carbon frame nanocomposite was formed by combing Ni and NiO nanoparticles and a C frame with Ni-MOF using an efficient one-step calcination method. The morphology and structure of Ni-MOF/Ni/NiO/C nanocomposite were characterized by transmission electron microscopy (TEM), X-ray photoelectron spectroscopy (XPS), X-ray diffraction (XRD), and energy disperse spectroscopy (EDS) mapping. Ni-MOF/Ni/NiO/C nanocomposites were immobilized onto glassy carbon electrodes (GCEs) with Nafion film to construct high-performance nonenzymatic glucose and H2O2 electrochemical sensors. Cyclic voltammetric (CV) study showed Ni-MOF/Ni/NiO/C nanocomposite displayed better electrocatalytic activity toward glucose oxidation as compared to Ni-MOF. Amperometric study indicated the glucose sensor displayed high performance, offering a low detection limit (0.8 μM), a high sensitivity of 367.45 mA M-1 cm-2, and a wide linear range (from 4 to 5664 μM). Importantly, good reproducibility, long-time stability, and excellent selectivity were obtained within the as-fabricated glucose sensor. Furthermore, the constructed high-performance sensor was utilized to monitor the glucose levels in human serum, and satisfactory results were obtained. It demonstrated the Ni-MOF/Ni/NiO/C nanocomposite can be used as a good electrochemical sensing material in practical biological applications. © 2017 American Chemical Society.","electrocatalytic activity; glucose; human serum; Ni-MOF/Ni/NiO/C nanocomposite","Biological materials; Body fluids; Carbon; Crystalline materials; Electrochemical sensors; Electrodes; Glass membrane electrodes; Glucose; Glucose sensors; High resolution transmission electron microscopy; Java programming language; Metal nanoparticles; Nanocomposite films; Nanocomposites; Nanoparticles; Synthesis (chemical); Transmission electron microscopy; X ray diffraction; X ray photoelectron spectroscopy; Biological applications; Electrocatalytic activity; Electrochemical sensing; Glassy carbon electrodes; High performance sensors; Human serum; Metal organic framework; Morphology and structures; Nickel",2-s2.0-85024096506
"Luo T.-Y., Liu C., Eliseeva S.V., Muldoon P.F., Petoud S., Rosi N.L.","Rare Earth pcu Metal-Organic Framework Platform Based on RE4(μ3-OH)4(COO)6 2+ Clusters: Rational Design, Directed Synthesis, and Deliberate Tuning of Excitation Wavelengths",2017,"Journal of the American Chemical Society",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024370415&doi=10.1021%2fjacs.7b04532&partnerID=40&md5=ecdf6a8b8c28970dea897d0f8ff7feb0","The Td point group symmetry of rare earth (RE3+) metal clusters RE4(μ3-OH)4(COO)6 2+ makes them attractive building blocks for creating metal-organic frameworks (MOFs) with controllable topologies. Herein, we describe the design and synthesis of a series of isoreticular MOFs featuring pcu topology [MOF-1114(RE) and MOF-1115(RE)] with variable rare earth metal ions (RE3+ = Y3+, Sm3+, Eu3+, Gd3+, Tb3+, Dy3+, Ho3+, Er3+, Tm3+, Yb3+) and linear amino-functionalized dicarboxylate linkers of different lengths. In total, we report 22 MOFs that vary in both composition and structure yet share the same RE4(μ3-OH)4 cluster motif. We demonstrate that these pcu MOFs are cationic and that anion exchange can be used to affect the MOF properties. We also investigate the luminescence properties of a representative member of this MOF series [MOF-1114(Yb)] that exhibits near-infrared emission. We show that the excitation energy for Yb3+ sensitization can be carefully adjusted to lower energy via covalent postsynthetic modification at the amino group sites within the MOF. © 2017 American Chemical Society.",,"Carboxylation; Crystalline materials; Dysprosium; Dysprosium compounds; Erbium; Erbium compounds; Europium; Europium compounds; Gadolinium; Java programming language; Luminescence; Metal ions; Metals; Rare earths; Samarium; Thulium; Topology; Excitation wavelength; Luminescence properties; Metal organic framework; Metalorganic frameworks (MOFs); Near-infrared emissions; Point group symmetry; Postsynthetic modification; Rare earth metal ions; Ytterbium; lanthanide; metal organic framework; adsorption; alcoholysis; anion exchange; Article; chemical structure; hydrolysis; luminescence; synthesis; X ray diffraction",2-s2.0-85024370415
"Liang X., Zheng B., Chen L., Zhang J., Zhuang Z., Chen B.","MOF-Derived Formation of Ni2P-CoP Bimetallic Phosphides with Strong Interfacial Effect toward Electrocatalytic Water Splitting",2017,"ACS Applied Materials and Interfaces",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024105224&doi=10.1021%2facsami.7b06152&partnerID=40&md5=d23acde553c2c4acb775fc588744a14d","Bimetallic phosphides have attracted research interest for their synergistic effect and superior electrocatalytic activities for electrocatalytic water splitting. Herein, a MOF-derived phosphorization approach was developed to produce Ni2P-CoP bimetallic phosphides as bifunctional electrocatalysts for both hydrogen and oxygen evolution reactions (HER and OER). Ni2P-CoP shows superior electrocatalytic activities to both pure Ni2P and CoP toward HER and OER, revealing a strong synergistic effect. High-resolution transmission electron microscopy and energy dispersive X-ray spectroscopy elemental mapping analysis show that, in the sample Ni2P-CoP, the Ni2P and CoP nanoparticles with an average particle size 10-20 nm were mixed closely on the nanoscale, creating numerous Ni2P/CoP interfaces. By comparison with the sample Ni2P+CoP, in which seldom Ni2P/CoP interfaces exist, we documented that the Ni2P/CoP interface is an essential prerequisite to realize the synergistic effect and to achieve the enhanced electrocatalytic activities in Ni2P-CoP bimetallic phosphides. This finding is meaningful for designing and developing bicomponent and even multicomponent electrocatalysts. © 2017 American Chemical Society.","bimetallic phosphides; electrocatalysis; interfaces; synergistic effect; water splitting","Electrocatalysis; Electrocatalysts; Hydrogen production; Interfaces (materials); Java programming language; Particle size analysis; Phosphorus compounds; Transmission electron microscopy; X ray spectroscopy; Bifunctional electrocatalysts; Bimetallic phosphide; Electrocatalytic activity; Elemental mapping analysis; Energy dispersive X ray spectroscopy; Oxygen evolution reaction; Synergistic effect; Water splitting; High resolution transmission electron microscopy",2-s2.0-85024105224
"Kapoor A., Singhal A.","A comparative study of K-Means, K-Means++ and Fuzzy C-Means clustering algorithms",2017,"3rd IEEE International Conference on ",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027504795&doi=10.1109%2fCIACT.2017.7977272&partnerID=40&md5=3e7263d0be4c8feb40abf42a916cdbb5","Clustering is essentially a procedure of grouping a set of objects in such a manner that items within the same clusters are more akin to each other compared with those data point or objects in different amassments or clusters. This paper discusses partition-predicated clustering techniques, such as K-Means, K-Means++ and object predicated Fuzzy C-Means clustering algorithm. This paper proposes a method for getting better clustering results by application of sorted and unsorted data into the algorithms. Elapsed time & total number of iterations are the factors on which, the behavioral patterns are analyzed. The experimental results shows that passing the sorted data instead of unsorted data not only effects the time complexity but withal ameliorates performance of these clustering techniques. © 2017 IEEE.","Clustering; Elapsed time; Euclidean distance; Fuzzy C-Means","Artificial intelligence; C (programming language); Cluster analysis; Fuzzy clustering; Fuzzy systems; Behavioral patterns; Clustering; Clustering techniques; Elapsed time; Euclidean distance; Fuzzy C mean; Fuzzy c-means clustering algorithms; Number of iterations; Clustering algorithms",2-s2.0-85027504795
"Fazzinga B., Furfaro F., Flesca S., Masciari E.","Wfinger: A Joint-decoder for very short tardos fingerprinting codes",2017,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028061039&doi=10.1145%2f3105831.3105860&partnerID=40&md5=6dd34a6caa9e6158c7aa2ebd248a0667","Protection of copyrighted contents is a crucial activity for digital content producers in order to avoid unauthorized use of the artifacts or worse in order to prevent sensible information to be stealth (e.g. private documents of an administrative board). A common solution is to uniquely identify each copy by embedding some distinguishing features into it. This activity is usually known as fingerprinting (a.k.a. watermarking) and the embedded content is referred as fingerprinting code. In order to make this process robust against possible malicious users attacks, it is mandatory to hide the positions where the code is embedded. However, even in the case that the positions where the code is embedded are hidden to the users, a group of malicious users (referred in what follows as pirates) may establish a coalition in order to compare their copies and identify the positions where they differ as a positions where the fingerprinting code has been embedded. This kind of attack is named coalition attack. If the coalition succeeds in this identification process, pirates can then arbitrarily change the fingerprint code embedded in the distributed copy so that it does not correspond to any of the original fingerprinting codes of the pirates. However, for the purpose of designing proper protection strategies, it can be assumed that they do not know the positions of the hidden code where the bits of their codes agreed and therefore they cannot alter these positions. This assumption is referred as the marking condition. A (collusion resistant) fingerprinting code can be built by a randomized procedure to choose codewords (the code generation) and a tracing algorithm tailored for tracing one of the pirates based on all these codewords and the forged codeword read from the unauthorized copy distributed by the pirates. Obviously, we should avoid two type of errors: 1) accusing an innocent user and 2) not accusing a pirate. In this respect, the tracing algorithm fails if it falsely accuses an innocent user or outputs no accused user at all. The above mentioned errors should occur with small probability. This problem have been largely investigated in the literature and all the approaches proposed so far shares a common terminology that we introduce here in order to ease the reading of next sections. More in detail, we briefly recall the following key terms: • Alphabet size. The codewords are sequences over a fixed alphabet Σ. Usually, fingerprinting codes are built by leveraging the binary alphabet Σ = {0,1}, however larger alphabets can be used thus the size Σ of the alphabet is an important parameter; • Codelength. This parameter refers to the length of the codewords, usually denoted by n; • Number of users. Usually denoted by N, it coincides with the number of codewords. • Pirate Coalition Size. This parameter takes into account the actual size of the coalition that could be lower than the expected one (say it c), in such a case, the accusation algorithm should achieve a small error probability1; • Error probability. A code is ∈-secure against a coalition of c pirates if the probability of the error of the accusation algorithm is at most e for any set of at most c pirates performing an arbitrary pirate strategy to produce the forged codeword under the marking assumption; • Code rate. The rate R of a fingerprinting code is computed as r = log(N)/n, where the logarithm is binary. The goal of fingerprinting schemes is to find efficient and secure fingerprinting codes while taking into account the high cost of embedding every single digit of the code. In several real world applications fingerprinting codes may be short, such as the case of fingerprinting text documents due to the intrinsic difficulty of embedding information in text. However, in literature many proposal have been defined based on the seminal work of Tardos[11, 12] that state many interesting theoretical results on the generation of short codes that under some conditions guarantees the possibility of finding guilty users. Tardos fingerprinting scheme is optimum as it generates fingerprinting codes sufficient to deal with n users and c pirates with the guarantee that the probability of accusing an innocent is bounded by a constant e, and having a length which is asymptotically minimum. Moreover, the accusation algorithm allows to detect a traitor by looking only at the code they have been assigned to him, disregarding both the codes assigned to other users and the type of attack that have been performed. It is worth noticing that in literature have been defined many other approaches that slightly outperforms Tardos scheme while having the same asymptotic complexity [9, 10]. Unfortunately, Tardos based fingerprinting are not effective in accusation processes when the leveraged code is too short [1, 13]. For instance, in the case that the code has to be embedded in a textual document by applying some modification of words, phrases or generally speaking tokens appearing in the text of the document as described in [3, 5, 6], and the document is about 20 pages long it is expected that the longest fingerprint that can be embedded is at most 200 bit long. In such a case, the Tardos accusation algorithm fails in accusing any user with a suitable probability of being guilty. For instance, in the case that the maximum coalition size is 2 and the desired probability of being guilty is 90% it requires a code of length at least 800 bits to accuse an user. This code length could be impractical in many scenarios. In order to overcome the above mentioned limitations, new approaches have been proposed and one of the most interesting is joint-decoding. Joint-decoders compute the guilty probability for a set of users instead of a single one. A first proposal has been made in [7, 8], however those algorithms are tailored for small coalition and do not scale-up properly. This drawback occurs as the search space computation grows up exponentially w.r.t. the number of users (or the maximum expected number of users that we may conjecture that could form a coalition for spreading the pirated copy). To ameliorate this problem, joint-decoding has been investigated from the theoretical viewpoint in order to define efficient approaches that work properly for real life situations. In this respect, a Markov Chain Monte Carlo (MCMC) based approach has been proposed in [2]. The proposed approach leverages Gibbs sampling for estimating the marginal probability that a user joined a coalition for generating a pirated copy. However, this approach turns to be ineffective for code length greater than 1024 bit due to the low quality of the probability estimation (as noted by the authors themselves). The main limitation of the above mentioned Tardos based approaches is that they perform satisfactorily when dealing with image or video fingerprinting[4] while their use for textual documents turns to be ineffective. More in detail, textual document watermarking is prone to several types of attacks, even very simple ones like the so called cut & paste attack. This attack allows to completely strip the watermark and the corresponding fingerprinting code by simply extracting the text in the source document and inserting it in a brand new document. The latter cause the deletion of eventual watermark inserted in the source text. This type of attack causes the fingerprint of the pirated copy to be empty, thus avoiding any accuse to users by using Tardos based schemes. In order to overcome such limitations, we propose a simpler but still effective accusation model based on Metropolis-Hastings (MH) sampling. Next sections are devoted to describe our proposal. © 2017 ACM.",,"Bins; Codes (symbols); Copyrights; Database systems; Decoding; Errors; Markov processes; Palmprint recognition; Probability; Watermarking; Administrative Board; Asymptotic complexity; Embedding information; Fingerprinting schemes; Identification process; Marginal probability; Markov chain Monte Carlo; Probability estimation; C (programming language)",2-s2.0-85028061039
"Sava Gallis D.F., Rohwer L.E.S., Rodriguez M.A., Barnhart-Dailey M.C., Butler K.S., Luk T.S., Timlin J.A., Chapman K.W.","Multifunctional, Tunable Metal-Organic Framework Materials Platform for Bioimaging Applications",2017,"ACS Applied Materials and Interfaces",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024132543&doi=10.1021%2facsami.7b05859&partnerID=40&md5=a74d945de072110d128387c88b435309","Herein, we describe a novel multifunctional metal-organic framework (MOF) materials platform that displays both porosity and tunable emission properties as a function of the metal identity (Eu, Nd, and tuned compositions of Nd/Yb). Their emission collectively spans the deep red to near-infrared (NIR) spectral region (∼614-1350 nm), which is highly relevant for in vivo bioimaging. These new materials meet important prerequisites as relevant to biological processes: they are minimally toxic to living cells and retain structural integrity in water and phosphate-buffered saline. To assess their viability as optical bioimaging agents, we successfully synthesized the nanoscale Eu analog as a proof-of-concept system in this series. In vitro studies show that it is cell-permeable in individual RAW 264.7 mouse macrophage and HeLa human cervical cancer tissue culture cells. The efficient discrimination between the Eu emission and cell autofluorescence was achieved with hyperspectral confocal fluorescence microscopy, used here for the first time to characterize MOF materials. Importantly, this is the first report that documents the long-term conservation of the intrinsic emission in live cells of a fluorophore-based MOF to date (up to 48 h). This finding, in conjunction with the materials' very low toxicity, validates the biocompatibility in these systems and qualifies them as promising for use in long-term tracking and biodistribution studies. © 2017 American Chemical Society.","bioimaging; emission; lanthanide; metal-organic framework; near-infrared","Biocompatibility; Biological materials; Cells; Crystalline materials; Cytology; Fluorescence microscopy; Infrared devices; Java programming language; Metals; Neodymium; Neutron emission; Rare earth elements; Saline water; Tissue culture; Toxic materials; Bio-imaging; Biological process; Confocal fluorescence microscopy; Long-term conservation; Metal organic framework; Metal organic framework materials; Near Infrared; Phosphate-buffered salines; Europium",2-s2.0-85024132543
"Ke W., Cui T., Yu Q., Wang M., Lv L., Wang H., Jiang Z., Li X., Chen J.","Mesoporous H-ZSM-5 nanocrystals with programmable number of acid sites as “solid ligands” to activate Pd nanoparticles for C–C coupling reactions",2017,"Nano Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023194991&doi=10.1007%2fs12274-017-1698-9&partnerID=40&md5=baab4919c57af9f0133f3accc672ec11","In this work, we described a proof-of-concept method to promote the activity and selectivity of Pd nanoparticles for heterogeneous catalysis (exemplified by C–C coupling reactions) by using acid sites within a zeolite framework. The Pd nanoparticles were encapsulated inside the crystalline walls of mesoporous H-ZSM-5 leading to hybrid samples (denoted as Pd@mZ-x-H) with controlled number of acid sites. A linear relationship between the number of acid sites of the zeolite nanocrystals and the catalytic activities of the Pd nanoparticles in organic reactions was established. Moreover, the shape-dependent selectivity of Pd@mZ-x-H was not sacrificed when the final activity was enhanced. [Figure not available: see fulltext.] © 2017 Tsinghua University Press and Springer-Verlag GmbH Germany","Brønsted acidity; HZSM-5; mesopores; palladium; Suzuki coupling","Catalysis; Catalyst activity; Chemical reactions; Nanocrystals; Nanoparticles; Palladium; Zeolites; C-coupling reactions; Crystalline walls; H-ZSM-5; Linear relationships; Meso-pores; Proof of concept; Suzuki couplings; Zeolite nanocrystals; C (programming language)",2-s2.0-85023194991
"Plata R.E., Hill D.E., Haines B.E., Musaev D.G., Chu L., Hickey D.P., Sigman M.S., Yu J.-Q., Blackmond D.G.","A Role for Pd(IV) in Catalytic Enantioselective C-H Functionalization with Monoprotected Amino Acid Ligands under Mild Conditions",2017,"Journal of the American Chemical Society",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024400886&doi=10.1021%2fjacs.7b03716&partnerID=40&md5=256f969876678c0f82f4d039bad7252f","Kinetic and mechanistic studies of the desymmetrization of benzhydrylamine using Pd/monoprotected amino acid ligands (Pd/MPAA) via C-H functionalization with molecular iodine provide mechanistic insight into the rate-determining step and the oxidation state of Pd in the C-H functionalization step. Enantiomeric excess is strikingly insensitive to temperature from ambient temperature up to over 70 °C, and reaction rate is insensitive to the electronic characteristics of the ligand's benzoyl protecting group. The reaction is highly robust with no evidence of catalyst deactivation. Intriguingly, C-H bond breaking does not occur prior to the addition of I2 to the reaction mixture. Electrochemical experiments demonstrate the viability of oxidative addition of I2 to Pd(II). Together with 19F NMR studies, these observations suggest that iodine oxidizes Pd prior to addition of the amine substrate. This work may lead to a better general understanding of the subtle variations in the reaction mechanisms for C-H functionalization reactions that may be extant for this ligand class depending on substrate, amino acid ligand and protecting group, and reaction conditions. © 2017 American Chemical Society.",,"Addition reactions; Amino acids; Catalyst deactivation; Iodine; Ligands; Substrates; C-H functionalization; Electrochemical experiments; Electronic characteristics; Enantiomeric excess; Mechanistic studies; Oxidative additions; Rate determining step; Reaction conditions; C (programming language); amino acid derivative; functional group; ligand; palladium; Article; catalysis; catalyst; comparative study; controlled study; electrochemical analysis; enantiomer; enantioselectivity; environmental temperature; high temperature; hydrogen bond; nuclear magnetic resonance; oxidation; oxidation reduction potential; reaction analysis",2-s2.0-85024400886
"Valerievich B.A., Anatolievna P.T., Alekseevna B.M., Vladimirovich S.S., Aleksandrovich K.M., Ivanovich H.V.","Modern approaches to the development parallel programs for modern multicore processors",2017,"2017 6th Mediterranean Conference on Embedded Computing, MECO 2017 - Including ECYPS 2017, Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027027374&doi=10.1109%2fMECO.2017.7977232&partnerID=40&md5=62be8cfdd543fac488bbfb45cdafd48c","The possibilities of prospective programming technologies for multicore processors aimed at automatic adaptation of existing serial software within the frames of imperative approach and the development of multithreaded applications by means of modern functional languages are considered. © 2017 IEEE.","functional paradigm; multi-core processors; parallel algorithms; speculative multithreading","Application programs; Functional programming; Multitasking; Parallel algorithms; Parallel processing systems; Automatic adaptation; Functional languages; functional paradigm; Multi-core processor; Multi-threaded application; Parallel program; Programming technology; Speculative multithreading; Multicore programming",2-s2.0-85027027374
"Li S., Qian X., Chengtao C.","ABB freelance control system application program interface communication technology research and application",2017,"Proceedings of the 29th Chinese Control and Decision Conference, CCDC 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028062469&doi=10.1109%2fCCDC.2017.7979056&partnerID=40&md5=a7878946e5fbb5d4ea6e2ffafc9acfc4","In the ABB Freelance process control system, it is difficult to compose the complex intelligent control algorithm using industrial programming language. In order to realize the intelligent control algorithm applied in ABB Freelance quickly, Proposed the use of the system application interface to achieve VC + +, MATLAB and other environmental development of customer applications directly with the ABB Freelance system communication, making VC++, MATLAB and other environmental development intelligent control algorithm can be quickly and easily applied in the ABB Freelance control system. © 2017 IEEE.","ABB Freelance; ActiveX controls; Application Programming Interface; Communication; Configuration",,2-s2.0-85028062469
"Carnì D.L., Grimaldi D., Sciammarella P.F., Lamonaca F., Martirano L.","Towards a unified approach for Distributed Measurement System technologies",2017,"Conference Proceedings - 2017 17th IEEE International Conference on Environment and Electrical Engineering and 2017 1st IEEE Industrial and Commercial Power Systems Europe, EEEIC / I and CPS Europe 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026777859&doi=10.1109%2fEEEIC.2017.7977530&partnerID=40&md5=9521f48b417c3b3c70123a3e1df93781","Many applications Internet-of-things (loT) based exploit Distributed Measurement System (DMS) to acquire data from sensors equipping objects or measurement instruments constituting the DMS nodes. The heterogeneity of the smart objects used to develop IoT applications has become a challenge in the design of the DMS, and very strong is the need to move towards new paradigm for programming and managing such systems. In fact, a current major limitation in the DMS development is the requirement of a deep knowledge about the different programming language and communication protocols. Aim of this paper is to provide an overview on DMS, focusing on the issues and the different technologies used, highlighting the software and architectural limits to the large diffusion for home automation, with a proposal to overcome them. © 2017 IEEE.","Communication delay; Distributed Measurement Systems; IoT; Network; Synchronization","Internet of things; Networks (circuits); Synchronization; Communication delays; Deep knowledge; Distributed measurement systems; Home automation; IOT applications; Measurement instruments; Smart objects; Unified approach; Computer systems programming",2-s2.0-85026777859
"Barsali S., Giglioli R., Lutzemberger G., Poli D., Valenti G.","Optimal operation of storage systems integrated with MV photovoltaic plants, using Jmodelica",2017,"Conference Proceedings - 2017 17th IEEE International Conference on Environment and Electrical Engineering and 2017 1st IEEE Industrial and Commercial Power Systems Europe, EEEIC / I and CPS Europe 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026788234&doi=10.1109%2fEEEIC.2017.7977620&partnerID=40&md5=5fb2b5236c59cba28314c2d0873f32fb","In modern power systems, the energy storage technology provides new business opportunities to producers, consumers and to their combination (prosumers). In fact, storage not only enables them to provide the electric grid with regulation, reserve and backup services, but actually fills the gap between the timing of production and consumption. This gives concrete economic value to price arbitrage techniques, aimed at maximizing the profit obtained by properly charging or discharging the storage, based on the time variation of electricity prices and the local consumption/generation profile. This paper shows how to optimize the operation of a storage device in presence of a PV generating plant combined with a local industrial load. An optimization technique based on a dynamic programming tool, implemented with the open source Modelica language, is here proposed and tested on different case studies. Three patterns of electricity prices and two different losses models have been considered, as well as the dependence of the storage lifetime on the depth of discharge of its operational cycles. Finally, a payback analysis calibrated on present and future cost scenarios is presented and discussed. © 2017 IEEE.","Control strategy; Energy storage; Optimisation; Photovoltaic plant; Price arbitrage","Costs; Electric energy storage; Energy storage; Open source software; Virtual storage; Business opportunities; Control strategies; Energy storage technologies; Optimisations; Optimization techniques; PhotoVoltaic plant; Price arbitrage; Production and consumption; Dynamic programming",2-s2.0-85026788234
"Básaca-Preciado L.C., Moreno-Partida A.S., Terrazas-Gaynor J.M., Ponce M., López J., Rodríguez-Quiñonez J.C., Fuentes W.F., Sergiyenko O.","Home and building automation through social networks",2017,"Conference Proceedings - 2017 17th IEEE International Conference on Environment and Electrical Engineering and 2017 1st IEEE Industrial and Commercial Power Systems Europe, EEEIC / I and CPS Europe 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026891127&doi=10.1109%2fEEEIC.2017.7977858&partnerID=40&md5=cfeac422529eaa92204e4069fdfd71ac","People are using social networks for every aspect of their lives, and what this project does is to take advantage of it to develop a scalable platform in which the user could monitor their home, interacting with a virtual assistant running on a server listening to all events fired by the user. Therefore this paper propose a different use of social networks, to manage your home or building through them. The entire platform has been tested with multiple users, scenarios, and also it has been migrated to various frameworks and programming languages to ensure portability. © 2017 IEEE.","Arduino; Facebook; Intel edison; Internet of Things (IoT); Node js","Intelligent buildings; Internet of things; Arduino; Facebook; Intel edison; Internet of Things (IOT); Node js; Social networking (online)",2-s2.0-85026891127
"Cheng F., Deng M., Wang C.","Kinect-based gait recognition system design via deterministic learning",2017,"Proceedings of the 29th Chinese Control and Decision Conference, CCDC 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028077206&doi=10.1109%2fCCDC.2017.7978227&partnerID=40&md5=c72a41b87bde7644eeaa841bccb51009","This paper proposes an effective and rapid human gait recognition system based on deterministic learning and Microsoft sensor. In order to deal with the difficulties of feature extraction in the gait recognition system, Kinect sensor is used for realtime skeleton detection and tracking. Dynamical deterministic learning algorithm implementation is achieved and a rapid gait recognition scheme is proposed. The graphical programming language of C# and MATLAB GUI controls are combined for building user-friendly and simple interfaces to display the gait training and recognition process. The recognition results and detailed parameters can be displayed on the system panels, which is also helpful for further data analysis and algorithm improvement. The effectiveness of the gait recognition system under multi-pattern is verified on the self-constructed gait database. © 2017 IEEE.","Deterministic Learning; Dynamical pattern recognition; Gait Recognition; Microsoft Kinect2.0",,2-s2.0-85028077206
"Calvo I., Cabanes I., Quesada J., Barambones O.","A Multidisciplinary PBL Approach for Teaching Industrial Informatics and Robotics in Engineering",2017,"IEEE Transactions on Education",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023600688&doi=10.1109%2fTE.2017.2721907&partnerID=40&md5=aafc40f4f119eb457dbc428c9dd78722","This paper describes the design of an industrial informatics course, following the project-based learning methodology, and reports the experience of four academic years (from 2012-13 to 2015-16). Industrial Informatics is a compulsory course taught in the third year of the B.Sc. degree in industrial electronics and automation engineering at the University of the Basque Country (UPV/EHU), Spain. The course had students develop an embedded controller for a 2DoF SCARA robot that drew a specific trajectory. The robot was built with the LEGO Mindstorms kit and the controller was implemented with NXC, a C-like programming language for the NXT brick. In this activity, students became aware of their learning needs and had to work proactively, both autonomously and in teams. The course design achieved several objectives: 1) students learned the course material; 2) soft skills demanded by employers were reinforced; and 3) the material was structured into project tasks for students to perform. The article analyses two indicators: 1) qualification marks and 2) student satisfaction. IEEE","Computing skills; embedded systems; engineering curriculum; industrial engineering; project-based learning; robotics; student assessment.",,2-s2.0-85023600688
"König B., Küpper S., Mika C.","PAWS: A tool for the analysis of weighted systems",2017,"Electronic Proceedings in Theoretical Computer Science, EPTCS",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030178104&doi=10.4204%2fEPTCS.250.5&partnerID=40&md5=edc986448748f1dd972feb320d4fd283","PAWS is a tool to analyse the behaviour of weighted automata and conditional transition systems. At its core PAWS is based on a generic implementation of algorithms for checking language equivalence in weighted automata and bisimulation in conditional transition systems. This architecture allows for the use of arbitrary user-defined semirings. New semirings can be generated during run-Time and the user can rely on numerous automatisation techniques to create new semiring structures for PAWS' algorithms. Basic semirings such as distributive complete lattices and fields of fractions can be defined by specifying few parameters, more exotic semirings can be generated from other semirings or defined from scratch using a built-in semiring generator. In the most general case, users can define new semirings by programming (in C#) the base operations of the semiring and a procedure to solve linear equations and use their newly generated semiring in the analysis tools that PAWS offers. © Valentina Castiglioni & Simone Tini.",,"Equivalence classes; Analysis tools; Bisimulations; Complete lattices; Generic implementation; Semi-ring; Semirings; Transition system; Weighted automata; Automata theory",2-s2.0-85030178104
"Garg S., Kumar S.","JOSN: JAVA oriented question-answering system combining semantic web and natural language processing techniques",2017,"India International Conference on Information Processing, IICIP 2016 - Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027447178&doi=10.1109%2fIICIP.2016.7975361&partnerID=40&md5=a9b6f01cc305d8dc5d8ee6bea8e703bd","Question-Answering (QA) system is improved version of search engines or can be stated as specific Search engines because search engines deliver data in the form of URLs whereas Question-Answering system produces direct answer to the query asked. That's why more focus has been put on developing better Question Answering systems that could respond to large variety of user query. Semantic Web Technology has aided to the development of such systems from past many years because it could add meaning to the query being asked. Such systems are more efficient than the systems developed in other languages. In this paper, we have proposed a QA system of JAVA Programming Language, where knowledge will be represented in the form of Ontology and based on relations derived from domain knowledge to obtained final answer. Information present in Ontology is represented in the form of tables to feed in knowledge base. It combines the techniques of Natural Language Processing and Semantic Web. © 2016 IEEE.","Information Extraction; Question Answering; Semantic Technologies","Artificial intelligence; Computer programming; Information retrieval; Java programming language; Knowledge based systems; Ontology; Query processing; Search engines; Semantic Web; Domain knowledge; Knowledge base; Natural languages; Question Answering; Question answering systems; Semantic technologies; Semantic Web technology; User query; Natural language processing systems",2-s2.0-85027447178
"Hassan N.M.","Analysis and implementation of the minimum route issues between some governorates of Iraq using Bellman-Ford algorithm",2017,"2017 Annual Conference on New Trends in Information and Communications Technology Applications, NTICT 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027580486&doi=10.1109%2fNTICT.2017.7976097&partnerID=40&md5=74e43c82b8d1605022a753d3eb8a3307","The Bellman-Ford algorithm provide a dynamic programming solution from source to all nodes in the given diagram for the minimum route Issue for single-source shortest paths in graphs with negative edges but no negative cycles. The main advantage of the algorithm is their simplicity and it does not need complex data structures for implementations and also find minimum path weight efficiently and high accuracy. Minimum route issues are inevitable in road network applications. The conclusion of simulation is to show the mathematics and C++ programming. So the problem has been resolved successfully negative weights with minimum route. © 2017 IEEE.","Bellman-Ford Algorithm; Graph algorithms; Planar separators; Programming computing; Shortest paths","C++ (programming language); Computer software; Dynamic programming; Bellman-Ford algorithms; C++ programming; Complex data structures; Graph algorithms; Planar separators; Programming solutions; Shortest path; Single source shortest paths; Graph theory",2-s2.0-85027580486
"Ǵomez-Luna J., Hajj I.E., Chang L.-W., Garćia-Flores V., De Gonzalo S.G., Jablin T.B., Pẽna A.J., Hwu W.-M.","Chai: Collaborative heterogeneous applications for integrated-Architectures",2017,"ISPASS 2017 - IEEE International Symposium on Performance Analysis of Systems and Software",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019024615&doi=10.1109%2fISPASS.2017.7975269&partnerID=40&md5=9f66dfc7b3e152ee6224c104d0a08eb2","Heterogeneous system architectures are evolving towards tighter integration among devices, with emerging features such as shared virtual memory, memory coherence, and systemwide atomics. Languages, device architectures, system specifications, and applications are rapidly adapting to the challenges and opportunities of tightly integrated heterogeneous platforms. Programming languages such as OpenCL 2.0, CUDA 8.0, and C++ AMP allow programmers to exploit these architectures for productive collaboration between CPU and GPU threads. To evaluate these new architectures and programming languages, and to empower researchers to experiment with new ideas, a suite of benchmarks targeting these architectures with close CPU-GPU collaboration is needed. In this paper, we classify applications that target heterogeneous architectures into generic collaboration patterns including data partitioning, fine-grain task partitioning, and coarse-grain task partitioning. We present Chai, a new suite of 14 benchmarks that cover these patterns and exercise different features of heterogeneous architectures with varying intensity. Each benchmark in Chai has seven different implementations in different programming models such as OpenCL, C++ AMP, and CUDA, and with and without the use of the latest heterogeneous architecture features. We characterize the behavior of each benchmark with respect to varying input sizes and collaboration combinations, and evaluate the impact of using the emerging features of heterogeneous architectures on application performance. © 2017 IEEE.",,"Benchmarking; C++ (programming language); Computer programming; Data handling; Distributed computer systems; High level languages; Memory architecture; Specifications; Application performance; Collaboration patterns; Device architectures; Heterogeneous architectures; Heterogeneous platforms; Heterogeneous systems; Integrated architecture; Shared virtual memory; Computer architecture",2-s2.0-85019024615
"Marques L.F., Correia R.C.M., Spadon G., Eler D.M., Olivete-Jr C., Garcia R.E.","Data bases available through APIs using Restify: Characteristics, programming models, and benchmarks [Banco de Dados disponível por APIs usando Restify: Características, Modelos de Programação e Análise de Desempenho]",2017,"Iberian Conference on Information Systems and Technologies, CISTI",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027009850&doi=10.23919%2fCISTI.2017.7975715&partnerID=40&md5=b99d7efe66da00ce8dd20809f8d2e62d","The volume of data exchanged by computer networks is gradually increasing over time, which provides the need for performance and interoperability between different platforms and systems. In this line, there are several studies dedicated to service-oriented software architectures and resource consumption models. However, a few of them are focused on the development of generic tools for the dynamic creation of data provisioning services. This article presents the analysis of a tool called Restify, which is able to dynamically create web services to provide an online database as a service. Restify achieved the system interoperability requirements regarding heterogeneous operations, programming languages, and server infrastructures. As a result, we observed that the performance of this tool was comparable, if not better, than other evaluated web services, such as REST and SOAP. Finally, Restify excels by behaving like an interface tool, allowing the management and integration of multiple online system tools with various relational databases. © 2017 AISTI.","Database as a Service; REST; Web Service","Application programming interfaces (API); Electronic data interchange; Information systems; Service oriented architecture (SOA); Web services; Websites; Database as a service; Programming models; Relational Database; Resource consumption; REST; Server infrastructure; Service-Oriented Software Architectures; System interoperability; Interoperability",2-s2.0-85027009850
"Barba-Guaman L., Calderon-Cordova C., Quezada-Sarmiento P.A.","Detection of moving objects through color thresholding [Detección de objetos en movimiento a través de la umbralización del color]",2017,"Iberian Conference on Information Systems and Technologies, CISTI",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026998492&doi=10.23919%2fCISTI.2017.7975755&partnerID=40&md5=55617ca01d3a9ae01d86e39d77f4ab5a","In image processing area and segmentation algorithms based on thresholding, the intensity of the image (grayscale) is usually obtained in order to differentiate the regions of the objects and the background. The segmentation based on the threshold works well when the image has a high intensity in the contrast, this characteristic is key to make a good classification of the pixels. This document will explain some theoretical concepts to identify objects by means of their color (thresholding), this technique was implemented in the development of a game program. Furthermore, the thresholding range for the red, yellow and green colors was found in order to achieve a better approach in the object detection. This project used the python programming language, Pygame graphical interface libraries and the OpenCV library free open source about artificial vision. © 2017 AISTI.","Image processing; OpenCV; Pygame; Python; Thresholding","Color; High level languages; Image processing; Image segmentation; Information systems; Open source software; Detection of moving object; Graphical interface; OpenCV; Pygame; Python; Python programming language; Segmentation algorithms; Thresholding; Object detection",2-s2.0-85026998492
"Guaman D., Quezada-Sarmiento P.A., Barba-Guaman L., Enciso L.","Use of SQALE and tools for analysis and identification of code technical debt through static analysis [Uso de SQALE y herramientas para análisis e identificación de deuda técnica de código a través de análisis estático]",2017,"Iberian Conference on Information Systems and Technologies, CISTI",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027061720&doi=10.23919%2fCISTI.2017.7975677&partnerID=40&md5=eef8d93e827e3f21df85796fa2c60e9b","Technical Debt (TD), also known as technical debt design or technical debt code, analyze the consequence that could have a system once it has been designed architecturally, coding or implemented. TD refers to work to be performed rather than software design or coding is considered complete or correct. Static analysis is a technique to identify and analyze software characteristics from source code; through static analysis we can identify elements such as packages, classes, relationships, lines of code (LOC's), bugs, complexity, coding violations and others. In addition subsystems, components and their relationships supported by tools, algorithms, frameworks to analyze the code were identified. SQALE[1] is a quality and analysis model contains the internal properties expected from the code in the context of the evaluation, it has been used to perform many assessments of software source code, of various sizes in different application domains and programming language. SonarQube[2], Kiuwan[3] and PMD[4] are an open source platform to manage the source code quality, this cover seven axes of code quality among which stand: architecture and design, duplications, unit test, complexity, potential bugs, codifications rules, comments, among others; this platform work with over 20 programming languages. This paper, use as input the source code of the software applications written in different programming language for through static analysis identify metrics, characteristics, and technical debt with the aim to improve the quality when writing code, also supported in static analysis identify aspects such as correct apply of quality attributes, standards and best practices of programming that based in ISO 9126 and SQALE ensure the correct software development in terms of design and coding. © 2017 AISTI.","Quality attributes; SonarQube; Source code; SQALE; Static analysis; Technical debt","Application programs; Codes (symbols); Computer programming languages; Computer software selection and evaluation; Information systems; Open source software; Open systems; Program debugging; Quality control; Software design; Software engineering; Standards; Quality attributes; SonarQube; Source codes; SQALE; Technical debts; Static analysis",2-s2.0-85027061720
"Boiroux D., Jorgensen J.B.","C code generation applied to nonlinear model predictive control for an artificial pancreas",2017,"Proceedings of the 2017 21st International Conference on Process Control, PC 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027530378&doi=10.1109%2fPC.2017.7976235&partnerID=40&md5=d3fb30fec889b663e46d70ef73fd907e","In this paper, we introduce a Matlab-based toolbox called OPTIPLAN, which is intended to formulate, solve and simulate problems of obstacle avoidance based on model predictive control (MPC). The main goal of the toolbox is that it allows the users to simply set up even complex control problems without loss in efficiency only in few lines of code. Slow mathematical and technical details are fully automated allowing researchers to focus on problem formulation. It can easily perform MPC based closed-loop simulations followed by fetching visualizations of the results. From the theoretical point of view, non-convex obstacle avoidance constraints are tackled in two ways in OPTIPLAN: Either by solving mixed-integer program using binary variables, or using time-varying constraints, which leads to a suboptimal solution, but the problem remains convex. © 2017 IEEE.",,"Artificial organs; C (programming language); Integer programming; MATLAB; Model predictive control; Predictive control systems; Problem solving; Artificial pancreas; Closed-loop simulations; Complex control problems; Mixed-integer programs; Nonlinear model predictive control; Problem formulation; Suboptimal solution; Theoretical points; Process control",2-s2.0-85027530378
"Kanashiro L., Ribeiro A., Silva D., Meirelles P., Terceiro A.","A study on low complexity models to predict flaws in the Linux source code",2017,"Iberian Conference on Information Systems and Technologies, CISTI",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027059238&doi=10.23919%2fCISTI.2017.7975747&partnerID=40&md5=d412693663c52bb62309d5c5019d3899","Due to the constant evolution of technology, each day brings new programming languages, development paradigms, and ways of evaluating processes. This is no different with source code metrics, where there is always new metric classes. To use a software metric to support decisions, it is necessary to understand how to perform the metric collection, calculation, interpretation, and analysis. The tasks of collecting and calculating source code metrics are most often automated, but how should we monitor them during the software development cycle? Our research aims to assist the software engineer to monitor metrics of vulnerability threats present in the source code through a reference prediction model, considering that real world software have non-functional security requirements, which implies the need to know how to monitor these requirements during the software development cycle. As a first result, this paper presents an empirical study on the evolution of the Linux project. Based on static analysis data, we propose low complexity models to study flaws in the Linux source code. About 391 versions of the project were analyzed by mining the official Linux repository using an approach that can be reproduced to perform similar studies. Our results show that it is possible to predict the number of warnings triggered by a static analyzer for a given software project revision as long as the software is continuously monitored. © 2017 AISTI.","Common Weakness Enumeration; Linux; Prediction; Source Code Metrics; Source Code Static Analysis","Codes (symbols); Computer operating systems; Computer programming languages; Forecasting; Information systems; Linux; Software design; Technology transfer; Common Weakness Enumeration; Empirical studies; Evolution of technology; Security requirements; Software development cycles; Software metrices; Source code metrics; Source code static analysis; Static analysis",2-s2.0-85027059238
"Vikas A., Sreenivasan A., Sudha K.L.","Fuzzy C-means clustering and Criminisi algorithm based shadow removal scheme for side scan sonar images",2017,"IEEE International Conference on Innovative Mechanisms for Industry Applications, ICIMIA 2017 - Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027464777&doi=10.1109%2fICIMIA.2017.7975647&partnerID=40&md5=6d6080ab40331a501cabbb44b566c06e","This paper proposes the Fuzzy C-Means and Criminisi Algorithm Based Shadow removal scheme for the Side Scan Sonar Images. Side Scan Sonar is widely used in the underwater ocean investigations like mining, pipelining, object detection, underwater communications etc. This paper make use of Fuzzy C-Means clustering algorithm for shadow Region segmentation and Criminisi Algorithm for filling the shadow region. Thus one can get clear view of detected object. © 2017 IEEE.","Criminisi algorithm; Fuzzy C-means algorithm; Ocean investigations; Side Scan Sonar","C (programming language); Copying; Fuzzy clustering; Fuzzy systems; Object detection; Sonar; Underwater acoustics; Fuzzy C means clustering; Fuzzy C-means algorithms; Fuzzy c-means clustering algorithms; Ocean investigations; Shadow regions; Side scan sonar; Side scan sonar image; Underwater communication; Clustering algorithms",2-s2.0-85027464777
"Sheng H., Chen D., Li N., Xu Q., Li H., He J., Lu J.","Urchin-Inspired TiO2@MIL-101 Double-Shell Hollow Particles: Adsorption and Highly Efficient Photocatalytic Degradation of Hydrogen Sulfide",2017,"Chemistry of Materials",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022331535&doi=10.1021%2facs.chemmater.7b01243&partnerID=40&md5=52a9f01d8d07216b3abbd22dd4ec9749","Titanium dioxide (TiO2) is a commonly used photocatalysis for the oxidation of hydrogen sulfide (H2S). However, the low surface area and adsorption ability of TiO2 limit the photocatalytic decomposition rate. Here, a tunable metal-organic framework (MOF) coating is applied to hollow TiO2 nanoparticles using a versatile step-by-step self-assembly strategy. The hollow structure provides a high surface area, and the selected MIL-101 (Cr) MOF has a high and regenerable adsorption ability for H2S. The TiO2@MIL-101 double-shell hollow particles enable a catalytic cycle involving simultaneous adsorption and degradation of H2S, with considerably enhanced photocatalytic reaction rate. This work provides a method for improving photocatalytic performance through the design of hollow MOF-based materials that rationally combine the power of MOF and TiO2. © 2017 American Chemical Society.",,"Adsorption; Crystalline materials; Java programming language; Metal nanoparticles; Sulfur determination; Metal organic framework; Oxidation of hydrogen; Photo catalytic degradation; Photocatalytic decomposition; Photocatalytic performance; Photocatalytic reactions; TiO2 nano-particles; Titanium dioxides (TiO2); Hydrogen sulfide",2-s2.0-85022331535
"Ene L.-V., Sǎnǎtescu D.-R., Sandu C., Bibiricǎ T.-C., Iordache M.","Simulation of magnetically coupled coils in ansoft Q3D extractor program",2017,"Proceedings - 2017 International Conference on Optimization of Electrical and Electronic Equipment, OPTIM 2017 and 2017 Intl Aegean Conference on Electrical Machines and Power Electronics, ACEMP 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027707659&doi=10.1109%2fOPTIM.2017.7974971&partnerID=40&md5=b79fad63b81830797a31b16cff54ad68","The purpose of calculation of parameters of magnetically coupled coils using Ansoft Q3D Extractor program is to find out the electric parameters: R, L, C and G. © 2017 IEEE.","Analysis of high frequency; Ansoft Q3D; C; Coil; G; L; Matrix; R; Wireless","Cesium; Electric machinery; Electronic equipment; Matrix algebra; Oscillators (electronic); Power electronics; Radio; Ansoft Q3D; Coil; Electric parameters; High frequency HF; Magnetically coupled coils; C (programming language)",2-s2.0-85027707659
"Cotfas D.T., Cotfas P.A., Floroian L., Floroian D.I.","Study of combined photovoltaic cell/thermoelectric element/solar collector in medium concentrated light",2017,"Proceedings - 2017 International Conference on Optimization of Electrical and Electronic Equipment, OPTIM 2017 and 2017 Intl Aegean Conference on Electrical Machines and Power Electronics, ACEMP 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027682873&doi=10.1109%2fOPTIM.2017.7975058&partnerID=40&md5=d1fcedcc2f91705141d72bde74dfdb31","The performance of the hybrid structures PV/TEG/STC which consist of photovoltaic cells PV, thermoelectric elements TEG and solar collector STC is studied in this paper function of different levels of illumination from 30 suns to 130 suns (1 sun = 1000 W/m2). The concentrated light is obtained using a solar simulator with four parabolic xenon lamps and an optical mixer to ensure the quasi homogenous illumination of the hybrid system. The important parameters of the photovoltaic cells and of the thermoelectric generators are determined using the current-voltage characteristics. The measurements and control are realized using the NI-cRIO platform and the software is developed in LabVIEW. © 2017 IEEE.","Concentrated light; Photovoltaic cell; Solar collector; Solar simulator; Thermoelectric generator","Cells; Computer programming languages; Current voltage characteristics; Cytology; Electric lamps; Electric machinery; Electronic equipment; Hybrid systems; Oscillators (electronic); Photoelectrochemical cells; Photovoltaic cells; Power electronics; Solar collectors; Thermoelectric equipment; Hybrid structure; LabViEW; Optical mixers; Solar simulator; Thermoelectric element; Thermoelectric generators; Xenon lamps; Solar power generation",2-s2.0-85027682873
"Cotfas P.A., Cotfas D.T., Gerigan C., Machidon O.M.","System design to study hybrid systems in concentrated light using Fresnel lens",2017,"Proceedings - 2017 International Conference on Optimization of Electrical and Electronic Equipment, OPTIM 2017 and 2017 Intl Aegean Conference on Electrical Machines and Power Electronics, ACEMP 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027710208&doi=10.1109%2fOPTIM.2017.7975059&partnerID=40&md5=923320c1c63e4a9cf60b73dac7285229","This paper presents the design of a system for studying photovoltaic cells PV, thermoelectric generators TEG, a solar collector SC and different hybrid structures comprising two or three of them in concentrated light. The concentrated light is obtained using a Fresnel lens and a sun tracker. The advantages of the system are: The reduction of the photovoltaic cells area, the use of the photovoltaic cells with high efficiency and the possibility to vary the levels of illumination up to 56 suns. The system control is achieved using the NI-cRIO and NI-myRIO embedded hardware and the software is developed in LabVIEW, using a mathematical algorithm for the sun tracker system. © 2017 IEEE.",,"Computer programming languages; Electric machinery; Hybrid systems; Optical instrument lenses; Oscillators (electronic); Photoelectrochemical cells; Photovoltaic cells; Power electronics; Solar power generation; Thermoelectric equipment; Embedded hardware; Fresnel lens; High-efficiency; Hybrid structure; Mathematical algorithms; Sun trackers; System control; Thermoelectric generators; Electronic equipment",2-s2.0-85027710208
"Sartor J.B., Bois K.D., Eyerman S., Eeckhout L.","Analyzing the scalability of managed language applications with speedup stacks",2017,"ISPASS 2017 - IEEE International Symposium on Performance Analysis of Systems and Software",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027445122&doi=10.1109%2fISPASS.2017.7975267&partnerID=40&md5=4614c2d70f87794b8f80d3528ced001e","Understanding the reasons why multi-Threaded applications do not achieve perfect scaling on modern multicore hardware is challenging. Furthermore, more and more modern programs are written in managed languages, which have extra service threads (e.g., to perform memory management), which may retard scalability and complicate performance analysis. In this paper, we extend speedup stacks, a previously-presented visualization tool to analyze multi-Threaded program scalability, to managed applications. Speedup stacks are comprehensive bar graphs that break down an application's execution to explain the main causes of sublinear speedup, i.e., when some threads are not allowing the application to progress, and thus increasing the execution time. We not only expand speedup stacks to analyze how the managed language's service threads affect overall scalability, but also implement speedup stacks while running on native hardware. We monitor the application and service threads' scheduling behavior using light-weight OS kernel modules, incurring under 1% overhead running unmodified Java benchmarks. We add two performance delimiters targeting managed applications: garbage collection and main initialization activities. We analyze the scalability limitations of these benchmarks and the impact of using both a stop-The-world and a concurrent garbage collector with speedup stacks. Our visualization tool facilitates the identification of scalability bottlenecks both between application threads and of service threads, pointing developers to whether optimization should be focused on the language runtime or the application. Speedup stacks provide better program understanding for both program and system designers, which can help optimize multicore processor performance. © 2017 IEEE.",,"Application programs; Hardware; Multicore programming; Program processors; Scalability; Visualization; Application threads; Concurrent garbage collectors; Multi- threaded applications; Multi-core processor; Multi-threaded programs; Performance analysis; Program understanding; Scheduling behavior; Benchmarking",2-s2.0-85027445122
"Almeida R.A.S.S., De Almeida M.E.B.","All in scratch project [Projeto All in Scratch]",2017,"Iberian Conference on Information Systems and Technologies, CISTI",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027219108&doi=10.23919%2fCISTI.2017.7975891&partnerID=40&md5=a4e799ddb63f08a3693ea067a90e5b2a","The present article refers a project developed in the area of programming and robotics aiming to promote the school success through the implementation of a pedagogy associated with problem solving based on the fundamentals of Scratch language programming and using structural components that aims students development in different areas of education. The All in Scratch project is a combination of several different subprojects, whose target audience ranges from kindergarten children to higher education students. © 2017 AISTI.","Learning; School Success; Scratch; TIC","Information systems; Problem solving; Robot programming; Students; Higher education students; Learning; School Success; Scratch; Structural component; Target audience; Education",2-s2.0-85027219108
"Stephan J.J., Abdullah S.A., Resan R.D.","Use fingerprint technology in developing country security",2017,"2017 Annual Conference on New Trends in Information and Communications Technology Applications, NTICT 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027569637&doi=10.1109%2fNTICT.2017.7976150&partnerID=40&md5=13dfa063d649b3b8728de7e42170c7fc","For over a century, fingerprints (FP) have been considered one of the most highly used methods for human recognition; automated biometric systems have only been available in recent years. FP recognition is becoming indispensable part of many identification systems in the world. This research present a proposed authentication system based on FP as biometric type and some of static credential personal information such as name and address date. The system generates a Unique Identification Number (ID) by combining FP features with user's personal information for accessing the system. One-To-one and one to more verification is used to verify user's identity for the application with high security level. The design model has been trained and tested using DB consisting of 100 images with selected FP's images for 30 persons. Result of FPs Matching rate is (100%) for end point by using SVM algorithm. The experimental work of the proposed system in this paper is that implementing a fingerprint-based investigation system for the Iraq country. The software was designed using Visual Studio 2013, ASP.net with C#, SQL server 2012, Windows Server 2012, and Microsoft Access 2010 programming language. © 2017 IEEE.","ASP.net C#; Biometric; Database; Fingerprint; Government","Biometrics; Database systems; Developing countries; Visual languages; ASP.NEt; Authentication systems; Fingerprint; Fingerprint technologies; Government; High security levels; Personal information; Unique identifications; Windows operating system",2-s2.0-85027569637
"Supriya S.M., Rajeev R., Pawankumar B.","Design and implementation of 4096 point FFT for satellite communication",2017,"IEEE International Conference on Innovative Mechanisms for Industry Applications, ICIMIA 2017 - Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027465428&doi=10.1109%2fICIMIA.2017.7975604&partnerID=40&md5=44873a8d6d34956eb0095daa9b3541b8","FFT is one of the essential tools used in applications such as video processing, image processing and multi carrier systems. But due to its intensive operation, it takes more area along with increased power consumption. Hence, a hardware efficient FFT algorithm is a prime requirement. After a survey of various FFT algorithms, because of its pipeline architecture Radix-22 SDF algorithm is chosen as the optimum hardware efficient FFT algorithm. Since the resolution increases with increase in number of samples, a length of 4096 is preferred for the acquisition system (one of the applications of FFT for satellite communication). The system level simulation is performed using MATLAB-Simulink. The algorithm is simulated using HDL programming language. The simulated HDL code is validated using Xilinx ISE synthesizer using Virtex-4 FPGA (XC4VSX35-10FF668). The real time testing of the algorithm is performed with an OFDM system. With inputs of 8 bit, it was found that an accuracy of 99.86% can be obtained. Also for 4096 points, the hardware consumed was 81%. Which implies the algorithm used favors hardware efficiency. © 2017 IEEE.","Acquisition system; DSP; FFT; FPGA; Satellite communication; SDF","Computer hardware description languages; Field programmable gate arrays (FPGA); Hardware; Image processing; MATLAB; Satellite communication systems; Satellites; Video signal processing; Acquisition systems; Design and implementations; Hardware efficiency; Multi carrier systems; Pipeline architecture; Resolution increase; Satellite communications; System level simulation; Fast Fourier transforms",2-s2.0-85027465428
"De Oliveira F.K., De Oliveira M.B., Gomes A.S., Queiros L.M.","RECREIO: Floss as SAAS for sharing of educational resources",2017,"Iberian Conference on Information Systems and Technologies, CISTI",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027034633&doi=10.23919%2fCISTI.2017.7975929&partnerID=40&md5=cc18c2817c73d365e4f2b1a08a2e4958","The objective of this study was to verify if a development model of Units of Learning (UoLs), supported by UoLs authoring tools, that meet the usability criteria and abstract advanced knowledge in programming language by the developers, effectively provides the use and implementation of such resources by teachers in all areas of high school (in this first phase of the research) with few skills with technology. This is also due to the fact that many teachers consume much more resources and also the difficulties faced by teachers and developers in reusing their resources in other environments because they were initially designed for a specific environment. The method was based on the paradigm of Design Science Research (DSR), which allowed us to understand the problem and solve it creatively from useful artifacts. The three cycles of the research used questionnaires, interviews and documentary collection as instruments of data collection of the first cycle of survey and survey of the problem under study, while the non-participant observation and questionnaires were used in the second and third cycles at the time of evaluations of the system interfaces by users. Suggestions for improvements were implemented in the Recreio, while integrations to the Learning Management Systems (LMS) are being developed. Preliminary results showed the importance of Recreio incorporate tools of authorship of UoLs, preferably, free and online. In addition, users' reports made explicit the need for a space for sharing and dissemination of the resources developed directly in LMS, as well as another space destined for exchanging experiences and learning with courses among users. © 2017 AISTI.","Authoring tool; Exchanges of experiences; Repository; Resource sharing","Education; Information systems; Management information systems; Problem oriented languages; Teaching; Authoring tool; Design science researches (DSR); Educational resource; Learning management system; Participant observations; Repository; Resource sharing; System interfaces; Surveys",2-s2.0-85027034633
"Tavares J., Mamede H.S., Amaral P., Pinto P.","Software-defined controllers: Where are we?",2017,"Iberian Conference on Information Systems and Technologies, CISTI",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027040734&doi=10.23919%2fCISTI.2017.7975683&partnerID=40&md5=dd2a55baa239abc5628fb421476d0193","The number of software-defined controllers available in the market has increased greatly in the last few years. Nowadays, it is possible to find proprietary controllers as well as open source controllers. Examples are companies as HPE and Cisco that offer those two types of controllers to their clients simultaneously. It is also important to note that in both, the open source version is a commercial distribution of OpenDaylight. In the current market it is possible to find controllers for different areas of deployment, with a different programming language and supporting different southbound protocols. Therefore, we considered worth providing a description and a comparison of the main existing controllers. © 2017 AISTI.","Controller; Open Source; Protocols; Software defined Networks","Commerce; Controllers; Information systems; Network protocols; Open systems; Software defined networking; Existing controllers; Open sources; Open source software",2-s2.0-85027040734
"Rio A., E Abreu F.B.","Analyzing web applications quality evolution",2017,"Iberian Conference on Information Systems and Technologies, CISTI",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027022980&doi=10.23919%2fCISTI.2017.7975959&partnerID=40&md5=71d3844ba969311dc360be09000783a5","Software evolution is a well-established research topic, but not in the web applications area. Web projects are normally more complex than other software development projects because they have both server and client code, encompass a variety of programming languages, and are multidisciplinary. We aim to produce a catalog of web smells to help mitigating quality problems in web apps implementation, thus saving time and reducing cost. By means of longitudinal studies, we plan to analyze the impact of these web smells in web apps maintainability and reliability. This paper describes several particularities of the proposed research work, as well as introduce procedures and techniques to be used. © 2017 AISTI.","Irregular time series; Longitudinal studies; Software evolution; Software quality; Web code smells; Web engineering","Computer software selection and evaluation; Engineering research; Information systems; Odors; Software design; Code smell; Irregular time series; Longitudinal study; Software Evolution; Software Quality; Web engineering; Application programs",2-s2.0-85027022980
"Neto C.G.F.","Using CAATs in security audits: Web server access log analysis [Utilização de CAATs em auditorias de segurança: análise de logs de acesso a servidor web]",2017,"Iberian Conference on Information Systems and Technologies, CISTI",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027015253&doi=10.23919%2fCISTI.2017.7976070&partnerID=40&md5=63518b56922c1a00eff9635faf957e34","Given the justified increase in concern with information security and since auditors are simultaneously in a privileged position and responsibility towards it, this article is intended to demonstrate how CAATs can be used for analysing web servers access log files in a security context. Normally reserved to information security experts, this approach allows the non-technical auditor, using tools he masters and uses on a day-to-day basis, to analyze data that may indicate attempts of unauthorized access. This way the auditor gains valuable information, both for him and for his client, that otherwise in the event of being a smaller company and without the necessary resources, would not be discovered. Therefore, this paper also addresses the fact that any auditor may do the proposed verification tasks, with no need of additional background in programming languages. © 2017 AISTI.","CAATs; Information security; Server intrusion","Information systems; Security of data; Web services; Access log; CAATs; Security audit; Security context; Unauthorized access; Verification task; Web servers; Electronic document exchange",2-s2.0-85027015253
"Dwivedi J., Tiwary A.","Plagiarism detection on bigdata using modified map-reduced based SCAM algorithm",2017,"IEEE International Conference on Innovative Mechanisms for Industry Applications, ICIMIA 2017 - Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027451168&doi=10.1109%2fICIMIA.2017.7975533&partnerID=40&md5=1d49abe6fe112c5ee7f0c693265b358d","Plagiarism is one of the biggest problems of scientific research and engineering. Plagiarism is understood as presenting, intentionally or otherwise, someone else's words, thoughts, analyses, argumentation, pictures, techniques, computer programmers etc. Plagiarism has a wider meaning, paraphrasing someone else's texts by replacing a few words by synonyms or interchanging some sentences in own way is also plagiarism. Even reproducing in your own words a reasoning or analysis made by someone else may constitute plagiarism if you do not add any content of your own; in so doing, you create the opinion that you have invented the argumentation yourself while this is not the case. The same still applies if you bring together bits of work by various authors without mentioning the sources. Plagiarism has also increased with the use of internet and large amount of big data available. Plagiarism detection techniques are applied by making a distinction between natural and programming languages. A similarity score is determined for each pair of documents which match significantly. We have a SCAM (Standard Copy Analysis Mechanism) plagiarism detection algorithm which calculates relative measure to detect overlap by making comparison on asset of words that are common between test document and registered document. Our proposed detection process is based on natural language by comparing documents. We have implemented Map-Reduce based SCAM algorithm for processing big data using Hadoop and detect plagiarism in big data. Normal Scam algorithm is suitable for normal data processing not for big data processing. © 2017 IEEE.","Big data; Hadoop; MapReduce; Plagiarism; Scam","Data handling; Facsimile; Intellectual property; Computer programmers; Hadoop; Map-reduce; Plagiarism; Plagiarism detection; Scam; Scientific researches; Similarity scores; Big data",2-s2.0-85027451168
"Rodchenko A., Kotselidis C., Nisbet A., Pop A., Lujan M.","MaxSim: A simulation platform for managed applications",2017,"ISPASS 2017 - IEEE International Symposium on Performance Analysis of Systems and Software",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027467091&doi=10.1109%2fISPASS.2017.7975286&partnerID=40&md5=e8429e475b7d89f3f9002f85560ee3d4","Managed applications, written in programming languages such as Java, C# and others, represent a significant share of workloads in the mobile, desktop, and server domains. Microarchitectural timing simulation of such workloads is useful for characterization and performance analysis, of both hardware and software, as well as for research and development of novel hardware extensions. This paper introduces MaxSim, a simulation platform based on the Maxine VM, the ZSim simulator, and the McPAT modeling framework. MaxSim is able to simulate fast and accurately managed workloads running on top of Maxine VM and its capabilities are showcased with novel simulation techniques for: 1) low-intrusive microarchitectural profiling via pointer tagging on the x86-64 platforms, 2) modeling of hardware extensions related, but not limited to, tagged pointers, and 3) modeling of complex software changes via address-space morphing. Low-intrusive microarchitectural profiling is achieved by utilizing tagged pointers to collect type-And allocation-site- related hardware events. Furthermore, MaxSim allows, through a novel technique called address space morphing, the easy modeling of complex object layout transformations. Finally, through the codesigned capabilities of MaxSim, novel hardware extensions can be implemented and evaluated. We showcase MaxSim's capabilities by simulating the whole set of the DaCapo-9.12-bach benchmarks in less than a day while performing an up-To-date microarchitectural power and performance characterization. Furthermore, we demonstrate a hardware/software co-designed optimization that performs dynamic load elimination for array length retrieval achieving up to 14% L1 data cache loads reduction and up to 4% dynamic energy reduction. MaxSim is available at https://github.com/arodchen/ MaxSim released as free software. © 2017 IEEE.",,"Benchmarking; Computer hardware; Dynamic loads; Hardware; Hardware-software codesign; Space platforms; Dynamic energy reduction; Hardware and software; Hardware extension; Performance analysis; Performance characterization; Research and development; Simulation platform; Simulation technique; Computer software",2-s2.0-85027467091
"Pinto A., Escudeiro P.","The promotion of the century learning skills through the development of games using scratch",2017,"Iberian Conference on Information Systems and Technologies, CISTI",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027226239&doi=10.23919%2fCISTI.2017.7975870&partnerID=40&md5=0642110631bbdf564f12ed71c97804df","The work described in this paper addresses the development of a game focused on a teaching strategy in the context of action-research study. The strategy established aimed at testing the impact of the student's participation in í collaborative project. The project aimed to motivate students t(use and learn foreign languages and also to develop their intercultural communicative competence. The team consisted o 14 teachers from 11 different countries and 167 students in an international educational context. Regarding the Portuguese participation, we have introduced the Area of Study namely Discovery in a class from the 7th grade students (23 students). Al the work was based in three premises: use Scratch online, web 2.0 and ETwinning platform. Students from different countries have worked together to develop their own games using programming Scratch. During the project, partners collaborated using web 2.0 tools and at the end, they have share their game and get feedback. This work identified the benefits and challenge of global education and intercultural interaction amongs students. Fourteen schools from 11 European countries have participated in this eTwinning project. Six schools had won the European quality eTwinning label. The methodology applied in this learning environment motivated the students and improved their learning process. It also contributed to a higher level o concentration and promoted collaborative learning. Additionally it facilitates creativity, dialogue and the overall relationship among students. The results demonstrate that teachers perceive eTwinning as contributing towards the enhancement and development of global education through intercultura interaction. The pedagogic model based on the collaborativ construction of knowledge was easily understood by the teachers. © 2017 AISTI.","Collaborative learning; Education games developed; Etwinning; Learning; Scratch","Computer aided instruction; Education computing; Information systems; Students; Teaching; Collaborative learning; Education game; Etwinning; Learning; Scratch; Education",2-s2.0-85027226239
"Krpan D., Mladenovic S., Zaharija G.","Mediated transfer from visual to high-level programming language",2017,"2017 40th International Convention on Information and Communication Technology, Electronics and Microelectronics, MIPRO 2017 - Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027715592&doi=10.23919%2fMIPRO.2017.7973531&partnerID=40&md5=5d21e9f7cc3691523c80938c57a4dc47","Visual programming languages (VPLs) are becoming more popular and making the transition from the informal to conventional educational settings. One of the important features of VPL is that novices are not required to remember a list of commands or complex syntax since everything they need is just there in the environment. The objective of introductory computer programming courses at the university is to teach students how to develop solutions in high-level computer programming languages such as C#. However, they also need to acquire problem-solving skills. Since computer programming and problem-solving are both challenging, schools and universities often make use of VPLs combined with game-based programming. Students will eventually need to transfer programming concepts learnt from VPL into a high-level programming language. A transition from VPL to the text-based high-level programming language is not seamless and additional tools and efforts are required. This paper presents prototypes we have developed for undergraduate university students to enable mediated transfer from VPL to high-level programming language by using the idea of mini-languages. © 2017 Croatian Society MIPRO.",,"Ada (programming language); Computer games; Computer programming; Computer programming languages; Education; Microelectronics; Problem oriented languages; Problem solving; Students; Teaching; Visual languages; Educational settings; High-level programming language; Important features; Introductory computer programming; Problem solving skills; Programming concepts; University students; Visual programming languages; High level languages",2-s2.0-85027715592
"Lahari M.V.P., Vedula S.V., Rao V.U.","Real time models for FPGA based control of power electronic converters: A graphical programming approach",2017,"Proceedings - 2015 IEEE IAS Joint Industrial and Commercial Power Systems / Petroleum and Chemical Industry Conference, ICPSPCIC 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027453732&doi=10.1109%2fCICPS.2015.7974054&partnerID=40&md5=468e554a9c7b196c64a8bb89da2d1d63","Power Electronic converters and systems require precise timing control. Field Programmable Gate Array (FPGA) has the advantages of reconfigurability, determinism and precise timing control over other digital controllers. Models for real-time switching pulse generation for power electronic converters namely AC to DC, DC to AC, AC to AC, DC to DC converters are built using a real time environment-NI's CompactRIO - a hardware module which combines an FPGA and various I/O modules. The FPGA has been programmed graphically using the software module Labview-FPGA (2014 version) Control signals have been validated with AC to DC converters with R, RL, RLE loads and real time control of these converters has been achieved. Open loop speed control of Converter-fed DC motor has been achieved, with the controller in the system being FPGA of CompactRIO. Speed control with closed loop current control has also been tested with the same real time environment. © 2015 IEEE.","AC to DC power converters; digital control; field programmable gate array (FPGA); phase control; power electronics; pulse width modulation","AC-AC power converters; Chemical industry; Computer graphics; Computer programming; Computer programming languages; Controllers; DC motors; DC-DC converters; Digital control systems; Electric inverters; Field programmable gate arrays (FPGA); Logic gates; Phase control; Power control; Power converters; Power electronics; Pulse width modulation; Real time control; Rectifying circuits; Speed control; Voltage control; Ac-to-dc; Closed-loop current controls; Digital control; Digital controllers; Fpga based controls; Graphical programming; Power electronic converters; Real-time environment; Electric machine control",2-s2.0-85027453732
"Casalnuovo C., Suchak Y., Ray B., Rubio-González C.","GitcProc: A tool for processing and classifying GitHub commits",2017,"ISSTA 2017 - Proceedings of the 26th ACM SIGSOFT International Symposium on Software Testing and Analysis",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026671393&doi=10.1145%2f3092703.3098230&partnerID=40&md5=483c194dae9f5a0957018390c292842d","Sites such as GitHub have created a vast collection of software artifacts that researchers interested in understanding and improving software systems can use. Current tools for processing such GitHub data tend to target project metadata and avoid source code processing, or process source code in a manner that requires significant effort for each language supported. This paper presents GitcProc, a lightweight tool based on regular expressions and source code blocks, which downloads projects and extracts their project history, including fine-grained source code information and development time bug fixes. GitcProc can track changes to both single-line and block source code structures and associate these changes to the surrounding function context with minimal set up required from users. We demonstrate GitcProc's ability to capture changes in multiple languages by evaluating it on C, C++, Java, and Python projects, and show it finds bug fixes and the context of source code changes effectively with few false positives. © 2017 Association for Computing Machinery.","Git Mining Tool; Information Extraction; Language Independence","Codes (symbols); Computer programming; Computer programming languages; Data handling; Data mining; Information retrieval; Software testing; Development time; Language independence; Multiple languages; Regular expressions; Software artifacts; Software systems; Source code changes; Source code information; C++ (programming language)",2-s2.0-85026671393
"Kaya D., Türk M., Kaya T.","Wavelet-based analysis method for heart rate detection of ECG signal using LabVIEW",2017,"2017 40th International Convention on Information and Communication Technology, Electronics and Microelectronics, MIPRO 2017 - Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027714633&doi=10.23919%2fMIPRO.2017.7973441&partnerID=40&md5=6ac812ee4a1928ccd535550cb7f0c485","LabVIEW is a graphical programming language that uses a dataflow model instead of sequential lines of text code. LabVIEW allows multiple operations to work in parallel. So, designers spend less time than a text based programming language. Application areas such as signal processing, image processing and data analysis are available. In this paper, wavelet analysis is used for the elimination of undesired frequency noise. In the obtained noise-free signal, the accurate heart rate was determined with helping of the program developed in the LabVIEW environment. The performance of the system was tested with different wavelet types and satisfactory results were obtained. © 2017 Croatian Society MIPRO.","bioelectrical signal; ECG; heart rate detection; LabVIEW; wavelet analysis","Computer graphics; Computer programming languages; Data flow analysis; Data handling; Electrocardiography; Heart; Image processing; Microelectronics; Signal processing; Wavelet analysis; Bioelectrical signals; Different wavelets; Graphical programming language; Heart-rate detection; LabViEW; Multiple operations; Noise free signals; Wavelet based analysis; Biomedical signal processing",2-s2.0-85027714633
"Serrano E., Blas J.G., Carretero J., Abella M., Desco M.","Medical Imaging Processing on a Big Data Platform Using Python: Experiences with Heterogeneous and Homogeneous Architectures",2017,"Proceedings - 2017 17th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing, CCGRID 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027444246&doi=10.1109%2fCCGRID.2017.56&partnerID=40&md5=b98a875459d42759c73dad5e42479233","The apparition of new paradigms, programming models, and languages that offer better programmability and better performance turns the implementation of current scientific applications into a less time-consuming task than years ago. One significant example of this trend is the MapReduce programming model and its implementation using Apache Spark. Nowadays, this programming model is mainly used for data analysis and machine learning applications, although it has been expanded to its usage in the HPC community. On the side of programming languages, Python has positioned itself as an alternative to other scientific programming languages, such as Matlab or Julia. In this work we explore the capabilities of Python and Apache Spark as partners in the implementation of the backprojection operator of a CT reconstruction application. We present two interesting approaches with two different types of architectures: A heterogeneous architecture including NVIDIA GPUS and a full performance CPU mode with the compatibility with C/C++ native source code. We experimentally demonstrate that current CPU-based implementations scale with the number of computational units. © 2017 IEEE.","Apache Spark; Backprojection; Big Data; CT; CUDA; Python","Big data; Cluster computing; Computerized tomography; Distributed computer systems; Grid computing; High level languages; Learning systems; MATLAB; Medical imaging; Object oriented programming; Back-projection; Backprojection operators; CUDA; Heterogeneous architectures; Machine learning applications; Python; Scientific applications; Scientific programming; C (programming language)",2-s2.0-85027444246
"Le X.-B.D., Chu D.-H., Lo D., Le Goues C., Visser W.","JFIX: Semantics-based repair of Java programs via symbolic PathFinder",2017,"ISSTA 2017 - Proceedings of the 26th ACM SIGSOFT International Symposium on Software Testing and Analysis",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026642553&doi=10.1145%2f3092703.3098225&partnerID=40&md5=3577906b5bf8827c8b88e6ee0979c6e0","Recently there has been a proliferation of automated program repair (APR) techniques, targeting various programming languages. Such techniques can be generally classified into two families: syntacticand semantics-based. Semantics-based APR, on which we focus, typically uses symbolic execution to infer semantic constraints and then program synthesis to construct repairs conforming to them. While syntactic-based APR techniques have been shown successful on bugs in real-world programs written in both C and Java, semantics-based APR techniques mostly target C programs. This leaves empirical comparisons of the APR families not fully explored, and developers without a Java-based semantics APR technique. We present JFix, a semantics-based APR framework that targets Java, and an associated Eclipse plugin. JFix is implemented atop Symbolic PathFinder, a well-known symbolic execution engine for Java programs. It extends one particular APR technique (Angelix), and is designed to be sufficiently generic to support a variety of such techniques. We demonstrate that semantics-based APR can indeed efficiently and effectively repair a variety of classes of bugs in large real-world Java programs. This supports our claim that the framework can both support developers seeking semantics-based repair of bugs in Java programs, as well as enable larger scale empirical studies comparing syntactic-and semantics-based APR targeting Java. © 2017 Association for Computing Machinery.","Automatic Program Repair; Program Synthesis; Symbolic Execution","C (programming language); Computer software; Model checking; Program debugging; Repair; Semantics; Software testing; Syntactics; Automatic programs; Eclipse plugin; Empirical - comparisons; Empirical studies; Program synthesis; Real world projects; Semantic constraints; Symbolic execution; Java programming language",2-s2.0-85026642553
"Vilcek T., Jakopec T.","Comparative analysis of tools for development of native and hybrid mobile applications",2017,"2017 40th International Convention on Information and Communication Technology, Electronics and Microelectronics, MIPRO 2017 - Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027717200&doi=10.23919%2fMIPRO.2017.7973662&partnerID=40&md5=879ff37efb72b6a84ba47e0ac884022a","One of the main reasons for wide acceptance of smartphones are mobile applications that offer a wide variety of features. This paper deals with types of mobile applications: hybrid and native, as well as tools that enable their development. For purposes of this paper, a total of eight simple, identical applications were made for Android, iOS and Windows Phone. Native applications for Android, iOS and Windows Phone were made in integrated development environment, or so-called IDEs: Android Studio, Xcode and Visual Studio. Hybrid applications for Android and iOS were made in Ionic, PhoneGap and NativeScript framework. The paper compares tools used for development through following criteria: supported computer operating system, supported mobile platforms, programming languages, official documentations and community of programmers, installation and development. Goal is to research the advantages and disadvantages of the tools used for development of native and hybrid mobile applications and to find out which applications are the most profitable. © 2017 Croatian Society MIPRO.",,"Computer operating systems; Computer programming; Computer programming languages; Computer systems programming; iOS (operating system); Microelectronics; Mobile computing; Mobile telecommunication systems; Studios; Telephone sets; Comparative analysis; Hybrid applications; Integrated development environment; Mobile applications; Mobile platform; Visual studios; Windows phones; Android (operating system)",2-s2.0-85027717200
"Lekić V., Babić Z.","Neneta: Heterogeneous computing complex-valued neural network framework",2017,"2017 40th International Convention on Information and Communication Technology, Electronics and Microelectronics, MIPRO 2017 - Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027688669&doi=10.23919%2fMIPRO.2017.7973416&partnerID=40&md5=9601ea8371b6d13b3ecc7a5db5b06393","Due to increased demand for computational efficiency for the training, validation and testing of artificial neural networks, many open source software frameworks have emerged. Almost exclusively GPU programming model of choice in such software frameworks is CUDA. Symptomatic is also lack of the support for complex-valued neural networks. With our research going exactly in that direction, we developed and made publicly available yet another software framework, completely based on C++ and OpenCL standards with which we try to solve problems we identified with already existing solutions. © 2017 Croatian Society MIPRO.",,"C++ (programming language); Complex networks; Computational efficiency; Computer programming; Computer software; Microelectronics; Neural networks; Open systems; Software engineering; Software testing; Complex-valued neural networks; GPU programming; Heterogeneous computing; Software frameworks; Open source software",2-s2.0-85027688669
"Bach L.M., Mihaljevic B., Radovan A.","Exploring HTTP/2 advantages and performance analysis using Java 9",2017,"2017 40th International Convention on Information and Communication Technology, Electronics and Microelectronics, MIPRO 2017 - Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027703973&doi=10.23919%2fMIPRO.2017.7973663&partnerID=40&md5=dd8bbdd3fcd693b5ad162156f87c0052","As websites have become bulkier and serve more larger files to end users, it has become harder for the HTTP/1.1 protocol to provide adequately short page load times. The HTTP protocol, in its previous versions, is a generic stateless application protocol most often used for distributed, collaborative, hypermedia information systems. The newest version, HTTP/2, introduced an updated protocol feature set based on Google's SPDY/2 protocol, aimed at improving the speed at which modern web resources load, reducing network congestion and additionally enforcing security standards. With header compression, new server push responses, and fully multiplexed connections, HTTP/2 solves the major issues previous versions were unable to overcome. This paper presents performance analysis results comparing both protocol versions in the upcoming release of Java 9 programming language, as well as describes key differences in development between versions. Analysis was run on the open source Jetty web server and benchmark code was compiled using JDK 9 Early Access. This paper shows benchmark results using different scenarios and typical usage performance gains. It outlines the major improvements and recommendations switching to the newer protocol version provides, specifically in general use object-oriented programming languages such as the new version of Java language. © 2017 Croatian Society MIPRO.",,"Benchmarking; HTTP; Hypertext systems; Microelectronics; Network protocols; Network security; Object oriented programming; Open source software; Open systems; Application protocols; Benchmark codes; Header compression; Hypermedia information systems; Network congestions; Performance analysis; Performance Gain; Security standards; Java programming language",2-s2.0-85027703973
"Mostafa S., Rodriguez R., Wang X.","Experience paper: A study on behavioral backward incompatibilities of Java software libraries",2017,"ISSTA 2017 - Proceedings of the 26th ACM SIGSOFT International Symposium on Software Testing and Analysis",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026640967&doi=10.1145%2f3092703.3092721&partnerID=40&md5=6634ae4da3dbee052d6902db7228333e","Nowadays, due to the frequent technological innovation and market changes, software libraries are evolving very quickly. Backward compatibility has always been one of the most important requirements during the evolution of software platforms and libraries. However, backward compatibility is seldom fully achieved in practice, and many relevant software failures are reported. Therefore, it is important to understand the status, major reasons, and impact of backward incompatibilities in real world software. This paper presents an empirical study to understand behavioral changes of APIs during evolution of software libraries. Specifically, we performed a large-scale cross-version regression testing on 68 consecutive version pairs from 15 popular Java software libraries. Furthermore, we collected and studied 126 real-world software bugs reports on backward incompatibilities of software libraries. Our major findings include: (1) 1,094 test failures / errors and 296 behavioral backward incompatibilities are detected from 52 of 68 consecutive version pairs; (2) there is a distribution mismatch between incompatibilities detected by library-side regression testing, and bug-inducing incompatibilities; (3) the majority of behavioral backward incompatibilities are not well documented in API documents or release notes; and (4) 67% of fixed client bugs caused by backward incompatibilities in software libraries are fixed by client developers, through several simple change patterns made to the backward incompatible API invocation. © 2017 Association for Computing Machinery.","Behavior Backward Incompatibilities; Library Evolution","Application programming interfaces (API); Computer software; Java programming language; Program debugging; Backward compatibility; Behavior Backward Incompatibilities; Behavioral changes; Empirical studies; Regression testing; Software libraries; Software platforms; Technological innovation; Software testing",2-s2.0-85026640967
"Bokan D., Temerinac M., Lukac Z., Ocovaj S.","C based laboratory for teaching Digital Signal Processing to Computer Engineering undergraduates",2017,"2017 40th International Convention on Information and Communication Technology, Electronics and Microelectronics, MIPRO 2017 - Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027685551&doi=10.23919%2fMIPRO.2017.7973526&partnerID=40&md5=61e95fc6954db3213abbb2e3b79bdab5","This paper describes experience and lessons learned from teaching introductory Digital Signal Processing course as a part of Computer Engineering curricula using C based laboratory exercises. Matlab based laboratory exercises are substituted with a series of hands-on experiments which include implementation of signal processing algorithms using programing language C and DSP development boards, and the analyses of implemented systems. The theoretical content of the course and the topics covered by the laboratory exercises have remained unchanged. Main goal of a new set of exercises was to enhance student performance, motivation, as well as their understanding of theory. Results are measured by comparing student final grades on this course with grades of students who enrolled in Matlab based course. After finishing the course both student groups were given a survey on experience and satisfaction with the course. Survey results indicated that students who enrolled in C based laboratory course rated the course better and were more interested in Digital Signal Processing topics. © 2017 Croatian Society MIPRO.",,"C (programming language); Curricula; Digital signal processing; E-learning; Laboratories; MATLAB; Microelectronics; Signal processing; Students; Surveys; Computer engineering; Computer engineering curricula; Digital signals; Laboratory course; Laboratory exercise; Signal processing algorithms; Student groups; Student performance; Teaching",2-s2.0-85027685551
"Li R., Yang M., Liu Y., Zhang H.","An Uniform Simplification Algorithm for Scattered Point Cloud",2017,"Guangxue Xuebao/Acta Optica Sinica",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028378719&doi=10.3788%2fAOS201737.0710002&partnerID=40&md5=d77564579ea3e3ee615dda47e710e57c","Aiming at the problems of high density, long reconstruction time and low reconstruction efficiency for scattered point cloud data, a new uniform simplification algorithm for scattered point cloud data is proposed. This algorithm is based on the open-source C++ programming library point cloud library (PCL). Firstly, a K-nearest neighborhood voxel grid is built by voxel grid class in PCL. Next, according to the bounding box algorithm the K-nearest neighborhood distance of the point cloud data is calculated and the normal of the point cloud data is estimated. Then the barycenter of each small voxel grid is established, which replaces all point cloud data in the voxel grid to achieve point cloud simplification. Finally, the simplified point cloud data is reconstructed and displayed with triangular mesh by greedy projection triangulation class. The experimental results show that in the premise of fully retaining geometric characteristics of point cloud data, the proposed algorithm can effectively remove partial redundancy of the point cloud data and simplify the data uniformly without large-scale blank area, and the reconstruction efficiency is improved. © 2017, Chinese Lasers Press. All right reserved.","Image processing; Point cloud library; Point cloud simplification; Triangular mesh; Voxel grid","Efficiency; Image processing; Mesh generation; Nearest neighbor search; Open source software; Geometric characteristics; K-nearest neighborhoods; Point cloud; Point cloud simplifications; Reconstruction efficiency; Simplification algorithms; Triangular meshes; Voxel grid; C++ (programming language)",2-s2.0-85028378719
"Wang Y., Wang L., Yu T., Zhao J., Li X.","Automatic detection and validation of race conditions in interrupt-driven embedded software",2017,"ISSTA 2017 - Proceedings of the 26th ACM SIGSOFT International Symposium on Software Testing and Analysis",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026674345&doi=10.1145%2f3092703.3092724&partnerID=40&md5=24426b790cd33eb7ddf41bbd19a2daaa","Interrupt-driven programs are widely deployed in safety-critical embedded systems to perform hardware and resource dependent data operation tasks. The frequent use of interrupts in these systems can cause race conditions to occur due to interactions between application tasks and interrupt handlers. Numerous program analysis and testing techniques have been proposed to detect races in multithreaded programs. Little work, however, has addressed race condition problems related to hardware interrupts. In this paper, we present SDRacer, an automated framework that can detect and validate race conditions in interrupt-driven embedded software. It uses a combination of static analysis and symbolic execution to generate input data for exercising the potential races. It then employs virtual platforms to dynamically validate these races by forcing the interrupts to occur at the potential racing points. We evaluate SDRacer on nine real-world embedded programs written in C language. The results show that SDRacer can precisely detect race conditions. © 2017 Association for Computing Machinery.","Embedded Software; Interrupts; Race Condition; Software Testing","Embedded software; Embedded systems; Hardware; Hazards and race conditions; Multitasking; Safety engineering; Software testing; Static analysis; Testing; Application tasks; Automatic Detection; Interrupts; Multi-threaded programs; Program analysis; Safety-critical embedded systems; Symbolic execution; Virtual platform; C (programming language)",2-s2.0-85026674345
"Fan X., Sui Y., Liao X., Xue J.","Boosting the precision of virtual call integrity protection with partial pointer analysis for C++",2017,"ISSTA 2017 - Proceedings of the 26th ACM SIGSOFT International Symposium on Software Testing and Analysis",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026680524&doi=10.1145%2f3092703.3092729&partnerID=40&md5=d546c0a4e270f8ce179f969b931a4b54","We present, Vip, an approach to boosting the precision of Virtual call Integrity Protection for large-scale real-world C++ programs (e.g., Chrome) by using pointer analysis for the first time. Vip introduces two new techniques: (1) a sound and scalable partial pointer analysis for discovering statically the sets of legitimate targets at virtual callsites from separately compiled C++ modules and (2) a lightweight instrumentation technique for performing (virtual call) integrity checks at runtime. Vip raises the bar against vtable hijacking attacks by providing stronger security guarantees than the CHA-based approach with comparable performance overhead. Vip is implemented in LLVM-3.8.0 and evaluated using SPEC programs and Chrome. Statically, Vip protects virtual calls more effectively than CHA by significantly reducing the sets of legitimate targets permitted at 20.3% of the virtual callsites per program, on average. Dynamically, Vip incurs an average (maximum) instrumentation overhead of 0.7% (3.3%), making it practically deployable as part of a compiler tool chain. © 2017 Association for Computing Machinery.","CFI; Pointer Analysis; VTable Hijacking Attacks","Computer software; Software testing; Instrumentation techniques; Integrity check; Integrity protection; Pointer analysis; Real-world; Runtimes; Vtable hijacking; C++ (programming language)",2-s2.0-85026680524
"El-Hokayem A., Falcone Y.","THEMIS: A tool for decentralized monitoring algorithms",2017,"ISSTA 2017 - Proceedings of the 26th ACM SIGSOFT International Symposium on Software Testing and Analysis",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026631388&doi=10.1145%2f3092703.3098224&partnerID=40&md5=908248fae4c2118e54d858133c4fd98a","THEMIS is a tool to facilitate the design, development, and analysis of decentralized monitoring algorithms; developed using Java and AspectJ. It consists of a library and command-line tools. THEMIS provides an API, data structures and measures for decentralized monitoring. These building blocks can be reused or extended to modify existing algorithms, design new more intricate algorithms, and elaborate new approaches to assess existing algorithms. We illustrate the usage of THEMIS by comparing two variants of a monitoring algorithm. © 2017 Association for Computing Machinery.","AspectJ; Java; Monitoring; Runtime Verification; Tool","Java programming language; Monitoring; Tools; Aspect-J; Building blockes; Command line; Decentralized monitoring; Java; Monitoring algorithms; New approaches; Run-time verification; Software testing",2-s2.0-85026631388
"Pejcinovic B.","Active learning, labs and maker-spaces in microwave circuit design courses",2017,"2017 40th International Convention on Information and Communication Technology, Electronics and Microelectronics, MIPRO 2017 - Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027712209&doi=10.23919%2fMIPRO.2017.7973380&partnerID=40&md5=d6e6e215aa3f973ec3f0808b48e46181","Circuit design courses in general, and microwave circuit design courses as a subspecialty, have been taught over many decades. It is relatively recently, however, that instructors have started experimenting with more modern approaches to in-class and out-of-class instruction. In our attempt to make instruction more effective we have turned to: a) utilizing classroom interaction systems and collaborative work in class, b) studio-like approach to labs where students are encouraged to explore a problem through design, simulation, building and testing of simple structures, c) makerspaces that enable full design-build-test-redesign cycle of fairly sophisticated designs, and d) systematic literature reviews for graduate students taking the courses. We describe our experiences in designing and implementing a sequence of two courses, present assessment data, discuss obstacles to student learning, and propose additional ways to improve student learning. © 2017 Croatian Society MIPRO.",,"C (programming language); Curricula; Distributed computer systems; Integrated circuit manufacture; Microelectronics; Microwave circuits; Students; Teaching; Timing circuits; Active Learning; Circuit designs; Classroom interaction; Collaborative Work; Graduate students; Simple structures; Student learning; Systematic literature review; Education",2-s2.0-85027712209
"Mariani G., Anghel A., Jongerius R., Dittmann G.","Predicting Cloud Performance for HPC Applications: A User-Oriented Approach",2017,"Proceedings - 2017 17th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing, CCGRID 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027444992&doi=10.1109%2fCCGRID.2017.11&partnerID=40&md5=e1815e37517fd924bb133afa76715cb9","Cloud computing enables end users to execute high-performance computing applications by renting the required computing power. This pay-for-use approach enables small enterprises and startups to run HPC-related businesses with a significant saving in capital investment and a short time to market. When deploying an application in the cloud, the users may a) fail to understand the interactions of the application with the software layers implementing the cloud system, b) be unaware of some hardware details of the cloud system, and c) fail to understand how sharing part of the cloud system with other users might degrade application performance. These misunderstandings may lead the users to select suboptimal cloud configurations in terms of cost or performance. To aid the users in selecting the optimal cloud configuration for their applications, we suggest that the cloud provider generate a prediction model for the provided system. We propose applying machine-learning techniques to generate this prediction model. First, the cloud provider profiles a set of training applications by means of a hardware-independent profiler and then executes these applications on a set of training cloud configurations to collect actual performance values. The prediction model is trained to learn the dependencies of actual performance data on the application profile and cloud configuration parameters. The advantage of using a hardware-independent profiler is that the cloud users and the cloud provider can analyze applications on different machines and interface with the same prediction model. We validate the proposed methodology for a cloud system implemented with OpenStack. We apply the prediction model to the NAS parallel benchmarks. The resulting relative error is below 15% and the Pareto optimal cloud configurations finally found when maximizing application speed and minimizing execution cost on the prediction model are also at most 15% away from the actual optimal solutions. © 2017 IEEE.","Cloud; Design of experiments; High performance computing; Machine learning; Performance prediction; Random forest","Application programs; Artificial intelligence; C (programming language); Clouds; Cluster computing; Decision trees; Design of experiments; Forecasting; Grid computing; Hardware; Investments; Learning systems; Pareto principle; Application performance; Configuration parameters; High performance computing; High-performance computing applications; Machine learning techniques; NAS parallel benchmarks; Performance prediction; Random forests; Distributed computer systems",2-s2.0-85027444992
"Gupta A., Singh D.K., Kulathu G., Vinod M.P.","A coordinated solution for the network wide circuit breaker synchronization using IEC 1",2017,"Proceedings - 2015 IEEE IAS Joint Industrial and Commercial Power Systems / Petroleum and Chemical Industry Conference, ICPSPCIC 2015",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027465056&doi=10.1109%2fCICPS.2015.7974058&partnerID=40&md5=d99b12b98f49a8da7d7275405ef5909a","Synchronization of two live power networks has always been a challenge. Mostly this has been accomplished by manual operation. The problem becomes more severe when the number of circuit breakers to synchronize, power sources and the complexity of the electrical network increases. The IEC 1 communication standard is widely accepted and is now used extensively for realizing substation applications involving multiple protection and control devices. In this paper an intelligent solution for the automatic synchronization of the live power networks using IEC 1 is proposed. © 2015 IEEE.","Automatic oltage Regulator (AVR); Bus Coupler (BC); Generator (EN); Generic Object Oriented Substation Event (GOOSE); IEC 1 communication proüles; Merging nit (M); overnor (O); rogrammable ogic Controller (C); Sampled Analogue alue (SA); Synchronizable Circuit Breaker (SCB); Synchronization; ublic tility ()","C (programming language); Chemical industry; Electric equipment protection; Electric network analysis; Electric power transmission networks; Surge protection; Synchronization; Timing circuits; Automatic oltage Regulator (AVR); Generator (EN); Generic object oriented sub-station events; overnor (O); rogrammable ogic Controller (C); Sampled Analogue alue (SA); Synchronizable Circuit Breaker (SCB); ublic tility (); Electric circuit breakers",2-s2.0-85027465056
"Meznaric D., Nikolic K.K., Franjkovic D.","System for acquisition and processing of pressure data around body in airflow",2017,"2017 40th International Convention on Information and Communication Technology, Electronics and Microelectronics, MIPRO 2017 - Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027732266&doi=10.23919%2fMIPRO.2017.7973671&partnerID=40&md5=f5ae24085c5d0516d7f043d172a5a6a1","The article deals with the system and methods for determination of the pressure distribution around aerodynamically shaped body immersed in airflow and further calculations of aerodynamic characteristics. Measurements are conducted in the subsonic closed-loop wind tunnel AT-1, in Aerodynamics Laboratory of Department of Aeronautics at Faculty of Transport and Traffic Sciences. Pressure distribution around airfoil NACA 2421 is sensed by the system for acquisition of pressure data Intelligent Pressure Scanner 9016, produced by the Pressure Systems Company. Data are digitalized and transferred to the computer through the Ethernet link. Data are processed by NUSS and LabVIEW software. Measurement results are displayed and compared to those obtained from piezometric harp. Results of experiments are commented and recommendations for further research are given. © 2017 Croatian Society MIPRO.",,"Aerodynamics; Computer programming languages; Microelectronics; Pressure distribution; Wind tunnels; Aerodynamic characteristics; Closed loops; Ethernet link; Lab-view softwares; Pressure data; Pressure system; Data handling",2-s2.0-85027732266
"Zhang X., Zhang Y., Ma Y., Gao Y.","RealSense: Real-time compressive spectrum sensing testbed over TV white space",2017,"18th IEEE International Symposium on A World of Wireless, Mobile and Multimedia Networks, WoWMoM 2017 - Conference",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027555972&doi=10.1109%2fWoWMoM.2017.7974334&partnerID=40&md5=9d2435e741136435210cd5e995e556a8","Nowadays, wideband spectrum sensing, as one of the vital technologies of cognitive radio (CR), has the potential to find more temporarily available frequency bands to meet the growing demands of wireless services. As the vast number of samples are required to be collected and processed, traditional wideband spectrum sensing methods become inefficient and cause large energy consumption. Therefore, many theoretical work focus on applying compressive sensing (CS) into wideband spectrum sensing to alleviate this issue. In this paper, to verify the CS-based spectrum sensing scheme in real-world scenarios, a real-time compressive spectrum sensing testbed is proposed to process the real-time data collected from the TV white space (TVWS) spectrum. The proposed testbed consists of two parts: a senor node, and a real-time signal processing platform based on National Instruments (NI) LabVIEW software to process the spectral data and control the sensor. © 2017 IEEE.","Cognitive Radio; Compressive Spectrum Sensing; TV white space","Compressed sensing; Computer programming languages; Energy utilization; Frequency bands; Signal processing; Testbeds; Compressive sensing; Lab-view softwares; National Instruments; Real-time signal processing; Real-world scenario; Spectrum sensing; Tv white spaces; Wideband spectrum sensing; Cognitive radio",2-s2.0-85027555972
"Kucherov B., Přibyl O., Artyushenko V.","Increasing efficiency of getting results of satellite remote sensing for smart cities",2017,"2017 Smart Cities Symposium Prague, SCSP 2017 - IEEE Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027681513&doi=10.1109%2fSCSP.2017.7973854&partnerID=40&md5=805bb78b63c8b191d0aed9581cbc7bce","Satellite Earth remote sensing data are widely used in Smart Cities in various areas, such as energy industry, transportation area, or disaster monitoring. Real time remote sensing data from some region could help to parry various extraordinary (emergency) situations (forest fires, floods, emergency situations on roads, etc.). It could be used in control centers to support decision making able to promptly inform citizens about current situation. In order to have the actual data, it is necessary to perform Earth observations as soon as possible after an emergency situation arises. But before the data from a satellite can be provided for its processing, a number of tasks must be solved. One of such tasks is changing a schedule of tracking, telemetry and command (TT&C) ground stations to carry out a communication session with remote sensing satellite for sending on it program of target equipment work (to observe the region and downlink sensing data to receiving ground stations). In this paper, the authors propose approaches to increase the efficiency of changing a schedule of TT&C ground station in order to increase the efficiency of getting satellite remote sensing data. Such issues as organization information exchanges between subscribers, prompt notification of planning department specialist about changing the current situation, increase efficiency of including in schedule additional communication sessions, the informative representation of data about current situation are discussed. The proposed approaches can increase the efficiency and reasonableness of the decision making in control centers to parry various extraordinary (emergency) situations. In turn, it can make cities more sustainable and safe, in other words smart. © 2017 IEEE.",,"C (programming language); Data communication equipment; Decision making; Deforestation; Satellite ground stations; Satellites; Smart city; Telemetering; Communication sessions; Earth remote sensing; Emergency situation; Information exchanges; Remote sensing satellites; Satellite remote sensing; Satellite remote sensing data; Telemetry and command; Remote sensing",2-s2.0-85027681513
"Yaneva V., Rajan A., Dubach C.","Compiler-assisted test acceleration on GPUs for embedded software",2017,"ISSTA 2017 - Proceedings of the 26th ACM SIGSOFT International Symposium on Software Testing and Analysis",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026655074&doi=10.1145%2f3092703.3092720&partnerID=40&md5=ee791aa570d63d0bc997d3c32d74d25b","Embedded software is found everywhere from our highly visible mobile devices to the confines of our car in the form of smart sensors. Embedded software companies are under huge pressure to produce safe applications that limit risks, and testing is absolutely critical to alleviate concerns regarding safety and user privacy. This requires using large test suites throughout the development process, increasing time-to-market and ultimately hindering competitivity. Speeding up test execution is, therefore, of paramount importance for embedded software developers. This is traditionally achieved by running, in parallel, multiple tests on large-scale clusters of computers. However, this approach is costly in terms of infrastructure maintenance and energy consumed, and is at times inconvenient as developers have to wait for their tests to be scheduled on a shared resource. We propose to look at exploiting GPUs (Graphics Processing Units) for running embedded software testing. GPUs are readily available in most computers and offer tremendous amounts of parallelism, making them an ideal target for embedded software testing. In this paper, we demonstrate, for the first time, how test executions of embedded C programs can be automatically performed on a GPU, without involving the end user. We take a compiler-assisted approach which automatically compiles the C program into GPU kernels for parallel execution of the input tests. Using this technique, we achieve an average speedup of 16×when compared to CPU execution of input tests across nine programs from an industry standard embedded benchmark suite. © 2017 Association for Computing Machinery.","Automated testing; Compilers; Embedded software; Functional testing; GPUs","Application programs; C (programming language); Computer graphics; Computer software; Embedded software; Embedded systems; Graphics processing unit; Program compilers; Program processors; Safety testing; Automated testing; Development process; Embedded benchmarks; Functional testing; GPUs; Infrastructure maintenance; Large-scale clusters; Parallel executions; Software testing",2-s2.0-85026655074
"Rezmerita G., Bobaru L., Stanculescu M., Iordache M., Niculae D.","A self and mutual inductance calculation resonators with finite element analysis",2017,"Proceedings - 2017 International Conference on Modern Power Systems, MPS 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026681472&doi=10.1109%2fMPS.2017.7974422&partnerID=40&md5=36f04e848402a51687d2a76e07d53f87","This paper presents how to implement the finite element method (FEM) to determine the magnetically coupled coils parameters. The method is applied for computing the parameters of the two resonators used in wireless power transfer (WPT). To compute the parameters corresponding to the resistance, self inductance, capacity and mutual inductance (R, L, C and M), we used CEDRAT Flux 2D software. The results of the 2D analyses are used to calculate the circuit's parameters in order to compute the wireless power transferred to a load. Using FEM we realized two models: the first one in order to determine the values corresponding to L1, R1, L2, R2 and M and the second model to test its functioning in steady state. The two models differs by an electric circuit used to realize the coupling and the numerical models are modeled using the magnetic quasi-stationary state. The wireless power transfer efficiency depends on the coil's shape which can play an important role in the operation of such devices. © 2017 IEEE.","efficiency; finite elements method; steady state; wireless power transfer","C (programming language); Efficiency; Energy transfer; Inductance; Inductive power transmission; Resonators; 2D analysis; Magnetically coupled coils; Mutual inductance; Quasi-stationary state; Steady state; Wireless power; Wireless power transfer; Wireless power transfer (WPT); Finite element method",2-s2.0-85026681472
"Guo Y., Yang L., Gao X., Wu K.","The static detection analysis technology of Android source codes",2017,"Proceedings of 2016 5th International Conference on Network Infrastructure and Digital Content, IEEE IC-NIDC 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027502654&doi=10.1109%2fICNIDC.2016.7974582&partnerID=40&md5=5487531a3a2a9f8ae78f06c6872ffc65","With the increasingly rampant malicious attacks of Android terminal, this paper proposes a detection technology of Android platform source code security based on static analysis. The technology uses the existing static analysis technology of Java source code, and joins Android implicit methods invocation processing, at last gets the control flow graph and data flow graph, which are based on Android source code and have no breakpoint. The technology analysis the malicious behavior of Android source code depending on the information flow graph, and then get the main loophole and flaw existed in Android project. Using this technology to detect multiple open source Android projects, the experimental results show that this technology can effectively detect the main loophole and flaw existing in Android source code. What's more, the technology can display complete attack path, which is convenient for developers to modify and maintain the project. Therefore, this technology has high practical value. © 2016 IEEE.","Android implicit methods invocation; Android intelligent terminal; Malicious attacks; Malicious behavior analysis; Static analysis","Android (operating system); Codes (symbols); Computer programming languages; Data flow graphs; Digital integrated circuits; Flow graphs; Graphic methods; Network security; Open source software; Open systems; Static analysis; Control flow graphs; Detection technology; Implicit methods; Information flow graphs; Intelligent terminal; Malicious attack; Malicious behavior; Technology analysis; Data flow analysis",2-s2.0-85027502654
"Lacaita N., Bassi M., Mazzanti A., Svelto F.","A low-noise K-band class-C VCO for E-band 5G backhaul systems in 55nm BiCMOS technology",2017,"PRIME 2017 - 13th Conference on PhD Research in Microelectronics and Electronics, Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027556387&doi=10.1109%2fPRIME.2017.7974140&partnerID=40&md5=093eb741ea55650aedfef72cfcacac09","Next-generation 5G communication systems require adaptive high-order modulations to increase spectral efficiency. To limit EVM, very low phase noise levels are required - i.e. less than -117dBc/Hz at 1MHz offset for 64QAM at f=20GHz. In this paper, the design and measurements of a low-noise K-Band VCO are presented. The challenges of achieving such a low phase noise are discussed in detail, with particular emphasis on the minimization of L/Q, inductor versus quality factor ratio. Prototypes have been realized in a 55nm BiCMOS technology. Operated at 2.5V supply with the largest amplitude allowed by reliability constraints, measurements show a phase noise as low as -119dBc/Hz at 1MHz from a 20GHz carrier offset with a tuning range (TR) of 19% and FoM=-187dBc/Hz. Power consumption is 56mW. To the best of authors' knowledge, the presented VCO shows the lowest reported phase noise among state-of-the-art BiCMOS VCOs with TR>10%. © 2017 IEEE.","5G; BiCMOS; E-Band; mm-Wave; Phase Noise; VCO","5G mobile communication systems; BiCMOS technology; C (programming language); Microelectronics; Millimeter waves; Variable frequency oscillators; Bi-CMOS; E-bands; High order modulation; Low phase noise; Mm waves; Reliability constraints; Spectral efficiencies; State of the art; Phase noise",2-s2.0-85027556387
"Kiselev A.S., Smirnov E.A.","Determination of the plasma impedance of a glow discharge in carbon dioxide",2017,"Journal of Physics: Conference Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025816938&doi=10.1088%2f1742-6596%2f872%2f1%2f012050&partnerID=40&md5=e33608a8f1f1b20ce414e4be74060e71","In this work an expression for the dynamic resistance of a glow discharge flowing in long tubes is obtained and analyzed. The expression describes the physical processes occurring in the positive column of a glow discharge. The frequency dependences of the active and reactive components as well as the dynamic resistance module for the discharge conditions corresponding to CO2-lasers have been calculated. Based on the simulation results developed a computer program in the C# programming language for modeling the dynamic resistance discharge of glow discharge lasers. © Published under licence by IOP Publishing Ltd.",,"Carbon; Carbon dioxide; Computer programming; Computer simulation languages; Modeling languages; Discharge conditions; Dynamic resistance; Frequency dependence; Long tubes; Physical process; Plasma impedance; Positive column; Reactive components; Glow discharges",2-s2.0-85025816938
"AbdelBaky M., Diaz-Montes J., Unuvar M., Romanus M., Rodero I., Steinder M., Parashar M.","Enabling distributed software-defined environments using dynamic infrastructure service composition",2017,"Proceedings - 2017 17th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing, CCGRID 2017",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027261922&doi=10.1109%2fCCGRID.2017.104&partnerID=40&md5=6b31f20d0f2f2b766480e09c7ddcc4d2","Service-based access models coupled with emerging application deployment technologies are enabling opportunities for realizing highly customized software-defined environments, which can support dynamic and data-driven applications. However, this requires rethinking traditional resource federation models to support dynamic resource compositions, which can adapt to evolving application needs and the dynamic state of underlying resources. In this paper, we present a programmable approach that leverages software-defined techniques to create a dynamic space-Time infrastructure service composition. We propose the use of Constraint Programming as a formal language to allow users, applications, and service providers to define the desired state of the execution environment. The resulting distributed software-defined environment continually adapts to meet objectives/constraints set by the users, applications, and/or resource providers. We present the design and prototype implementation of such distributed software-defined environment. We use a cancer informatics workflow to demonstrate the operation of our framework using resources from five different cloud providers, which are aggregated on-demand based on dynamic user and resource provider constraints. © 2017 IEEE.","Distributed Software-Defined Environments; Programmable Infrastructure; Programmable Service Composition","Application programs; Cluster computing; Computer programming; Constraint theory; Formal languages; Grid computing; Quality of service; Software prototyping; Constraint programming; Data-driven applications; Distributed software; Execution environments; Infrastructure services; Programmable Infrastructure; Prototype implementations; Service compositions; Distributed computer systems",2-s2.0-85027261922
"Tuncer T., Avaroǧlu E.","Random number generation with LFSR based stream cipher algorithms",2017,"2017 40th International Convention on Information and Communication Technology, Electronics and Microelectronics, MIPRO 2017 - Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027714894&doi=10.23919%2fMIPRO.2017.7973412&partnerID=40&md5=6c0b6e6ac9604dfa991efc8e61e35fbd","Random numbers have a wide range of usage area such as simulation, games of chance, sampling and computer science (cryptography, game programming, data transmission). In order to use random numbers in computer science, they must have three basic requirements. First, the numbers generated must be unpredictable. Second, the numbers generated should have good statistical properties. Finally, the generated number streams must not be reproduced. Random number generators (RNGs) have been developed to obtain random numbers with these properties. These random number generators are classified into true random number generators (TRNG) and pseudo random number generators (PRNG). One of the PRNGs used for generate random numbers is Stream Encryption algorithms. In this paper, random number generation of LFSR based stream encryption algorithms and their hardware implementations are presented. LFSR based stream encryption algorithms have been implemented on Altera's FPGA based 60-nm EP4CE115F29C7 development boards by using VHDL language. The obtained random numbers passed the NIST statistical tests, accepted as standard for cryptographic applications. © 2017 Croatian Society MIPRO.",,"Computer games; Computer hardware description languages; Computer programming; Cryptography; Hardware; Microelectronics; Number theory; Cryptographic applications; Encryption algorithms; Game Programming; Hardware implementations; LFSR-based stream ciphers; Pseudo random number generators; Random number generators; Statistical properties; Random number generation",2-s2.0-85027714894
"Radonic M., Mekterovic I.","ETLator - A scripting ETL framework",2017,"2017 40th International Convention on Information and Communication Technology, Electronics and Microelectronics, MIPRO 2017 - Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027679033&doi=10.23919%2fMIPRO.2017.7973632&partnerID=40&md5=c4ea53e6607449889f9fad9dd0c74f8d","ETL (Extract Transform Load) process is the industry standard term for data extraction, transformation and loading into the Data Warehouse (DW). ETL process is the most resource demanding process in DW implementation and typically has to be evolved and maintained for the duration of the DW. To facilitate the development and maintenance of ETL processes many ETL tools have been developed featuring Graphical User Interfaces and various built-in functionalities (parallelism, logging, rich transformation libraries, documentation generation, etc.). The downside of such GUI ETL tools is that development is carried out heavily using mouse operations and less by writing programming code, which feels unnatural for some developers, especially with many similar, repetitive tasks. In this paper we present an alternative approach - an ETL framework ETLator based on Python scripting language where ETL tasks are defined by writing Python code. ETLator implements various typical ETL transformations and allows the user to simply and efficiently define complex ETL tasks with multiple sources and parallel tasks whilst leveraging full flexibility of Python. ETLator also provides logging and can document ETL tasks by generating data flow images. On a test case we show that ETLator simplifies ETL development and rivals the GUI approach. © 2017 Croatian Society MIPRO.",,"Data warehouses; High level languages; Metadata; Microelectronics; User interfaces; Data extraction; Extract transform loads; Industry standards; Mouse operations; Multiple source; Programming codes; Python scripting languages; Repetitive task; Graphical user interfaces",2-s2.0-85027679033
"Cuvic M.A., Maras J., Mladenovic S.","Extending the object-oriented notional machine notation with inheritance, polymorphism, and GUI events",2017,"2017 40th International Convention on Information and Communication Technology, Electronics and Microelectronics, MIPRO 2017 - Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027684558&doi=10.23919%2fMIPRO.2017.7973530&partnerID=40&md5=e5db86fc0f472c89d2a154d94d4b3ef8","Learning to program is a challenging task. Novices need to have an accurate understanding of the program execution at the conceptual level provided by the programming language. This level of execution is often referred to as the notional machine, which is often easier to understand through program visualizations. © 2017 Croatian Society MIPRO.",,"Microelectronics; Conceptual levels; Object oriented; Program execution; Program visualization; Object oriented programming",2-s2.0-85027684558
"Santos W.D., Carvalho L.F.M., Avelar G.D.P., Silva A., Ponce L.M., Guedes D., Meira W.","Lemonade: A scalable and efficient spark-based platform for data analytics",2017,"Proceedings - 2017 17th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing, CCGRID 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027453978&doi=10.1109%2fCCGRID.2017.142&partnerID=40&md5=940d984388927acec75a0e94bb195143","Data Analytics is a concept related to pattern and relevant knowledge discovery from large amounts of data. In general, the task is complex and demands knowledge in very specific areas, such as massive data processing and parallel programming languages. However, analysts are usually not versed in Computer Science, but in the original data domain. In order to support them in such analysis, we present Lemonade-Live Exploration and Mining Of a Non-Trivial Amount of Data from Everywhere-a platform for visual creation and execution of data analysis workflows. Lemonade encapsulates storage and data processing environment details, providing higher-level abstractions for data source access and algorithms coding. The goal is to enable batch and interactive execution of data analysis tasks, from basic ETL to complex data mining algorithms, in parallel, in a distributed environment. The current version supports HDFS (the Hadoop filesystem), local filesystems and distributed environments such as Apache Spark, the state-of-Art framework for Big Data analysis. © 2017 IEEE.","Cloud; Data analytics; Spark","Beverages; Clouds; Cluster computing; Data handling; Data mining; Digital storage; Distributed computer systems; Electric sparks; File organization; Grid computing; Information analysis; Parallel programming; Complex data; Data analytics; Data domains; Distributed environments; Higher-level abstraction; Large amounts of data; Processing environments; Specific areas; Big data",2-s2.0-85027453978
"Tabuchi A., Nakao M., Murai H., Boku T., Sato M.","Implementation and Evaluation of One-Sided PGAS Communication in XcalableACC for Accelerated Clusters",2017,"Proceedings - 2017 17th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing, CCGRID 2017",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027436149&doi=10.1109%2fCCGRID.2017.81&partnerID=40&md5=038342e44ef717508b8fac581128c9ae","Clusters equipped with accelerators such as graphics processing unit (GPU) and Many Integrated Core (MIC) are widely used. For such clusters, programmers write programs for their applications by combining MPI with one of the available accelerator programming models. In particular, OpenACC enables programmers to develop their applications easily, but with lower productivity owing to complex MPI programming. XcalableACC (XACC) is a new programming model, which is an 'orthogonal' integration of a partitioned global address space (PGAS) language XcalableMP (XMP) and OpenACC. While XMP enables distributed-memory programming on both global-view and local-view models, OpenACC allows operations to be offloaded to a set of accelerators. In the local-view model, programmers can describe communication with the coarray features adopted from Fortran 2008, and we extend them to communication between accelerators. We have designed and implemented an XACC compiler for NVIDIA GPU and evaluated its performance and productivity by using two benchmarks, Himeno benchmark and NAS Parallel Benchmarks CG (NPB-CG). The performance of the XACC version with the Himeno benchmark and NPB-CG are over 85% and 97% in the local-view model against the MPI+OpenACC version, respectively. Moreover, using non-blocking communication makes the performance of local-view version over 89% with the Himeno benchmark. From the viewpoint of productivity, the local-view model provides an intuitive form of array assignment statement for communication. © 2017 IEEE.","Accelerator; Cluster; Coarray; GPU; OpenACC; PGAS","Acceleration; Application programs; Benchmarking; Cluster computing; Computer graphics; Computer graphics equipment; Graphics processing unit; Grid computing; Particle accelerators; Productivity; Program processors; Accelerator programming; Cluster; Coarray; Distributed Memory; NAS parallel benchmarks; Openacc; Partitioned Global Address Space; PGAS; Distributed computer systems",2-s2.0-85027436149
"Pesic D.J., Radivojevic Z., Cvetanovic M.","A survey and evaluation of free and open source simulators suitable for teaching courses in wireless sensor networks",2017,"2017 40th International Convention on Information and Communication Technology, Electronics and Microelectronics, MIPRO 2017 - Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027709258&doi=10.23919%2fMIPRO.2017.7973549&partnerID=40&md5=684e08e1c3f29ef3d56b8b371cdac24e","This paper attempts to give a survey of some free software tools for wireless sensor networks. It targets teachers and students who might have the need for education in this area. As a first stage in creating this survey, a process of software collection is presented. First collection step is search through the Shanghai list for the first 50 universities. From these universities, available information about used software for wsn-related courses is collected. Additionally, other wsn software surveys are considered. Then, only free, open source and available software are kept, because they are the easiest for students to get it. Then evaluation based on topics coverage and software features is done. Topics are selected from IEEE Curriculum guidelines, while features give emphasis on practical usage from user aspect. Selected topics are embedded systems, computer networks, operating system and system resource management. Features used in the evaluation are support for GUI and command line, programming language learning overhead, ease of installation, extensibility, and platform portability. As a result, following software tools are described: TinyOS, Prowler, Riot, Castalia, Avrora, Shawn, TRMSim-WSN, and Shox. © 2017 Croatian Society MIPRO.",,"Computer operating systems; Computer resource management; Computer software; Curricula; Education; Embedded systems; Microelectronics; Open source software; Open systems; Surveys; Teaching; Command line; Curriculum guidelines; Free software tools; Open sources; Platform portability; Software features; System resource management; Wireless sensor networks",2-s2.0-85027709258
"Ore J.-P., Detweiler C., Elbaum S.","Phriky-units: A lightweight, annotation-free physical unit inconsistency detection tool",2017,"ISSTA 2017 - Proceedings of the 26th ACM SIGSOFT International Symposium on Software Testing and Analysis",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026634220&doi=10.1145%2f3092703.3098219&partnerID=40&md5=7e380b6cca7fdfe409bac8834999b9d2","Systems that interact with the physical world use software that represents and manipulates physical quantities. To operate correctly, these systems must obey the rules of how quantities with physical units can be combined, compared, and manipulated. Incorrectly manipulating physical quantities can cause faults that go undetected by the type system, likely manifesting later as incorrect behavior. Existing approaches for inconsistency detection require code annotation, physical unit libraries, or specialized programming languages. We introduce Phriky-Units1, a static analysis tool that detects physical unit inconsistencies in robotic software without developer annotations. It does so by capitalizing on existing shared libraries that handle standardized physical units, common in the cyber-physical domain, to link class attributes of shared libraries to physical units. In this work, we describe how Phriky-Units works, provide details of the implementation, and explain how Phriky-Units can be used. Finally we present a summary of an empirical evaluation showing it has an 87% true positive rate for a class of inconsistencies we detect with high-confidence. © 2017 Association for Computing Machinery.","Dimensional analysis; Physical units; Program analysis; Robotic systems; Static analysis; Type checking; Unit consistency","Libraries; Robotics; Software testing; Dimensional analysis; Physical units; Program analysis; Robotic systems; Typechecking; Unit consistency; Static analysis",2-s2.0-85026634220
"Odiete O., Jain T., Adaji I., Vassileva J., Deters R.","Recommending programming languages by identifying skill gaps using analysis of experts. A study of stack overflow",2017,"UMAP 2017 - Adjunct Publication of the 25th Conference on User Modeling, Adaptation and Personalization",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026884507&doi=10.1145%2f3099023.3099040&partnerID=40&md5=90cc3d86dca8c79a1543d7ae92283b7b","e increasing variety of programming languages available to computer programmers has led to the discussion of what language(s) should be learned. A key point in the choice of a programming language is the availability of support from experienced programmers. In this paper, we explore the use of graph theory in recommending programming languages to novice and expert programmers in a question and answer collaborative learning environment, Stack Overflow. Using social network analysis techniques, we investigate the relationship between experts (using an expertise graph) in different programming languages to identify what languages can be recommended to novice and experienced programmers. In addition, we explore the use of the expertise graph in inferring the importance of a programming language to the community. Our results suggest that programming languages can be recommended within organizational borders and programming domains. In addition, a high number of experts in a programming language does not always mean that the language is popular. Furthermore, disconnected nodes in the expertise graph suggest that experts in some programming languages are primarily on Stack Overflow to support that language only and do not contribute to questions or answers in other languages. Finally, developers are comfortable with mastering a single, general purpose language. .e results of our study can help educators and stakeholders in computer education to understand what programming languages can be suggested to students and what languages can be taught and learned together. © 2017 ACM.","Learning; Recommendation; Stack overflow","Ada (programming language); Computer aided instruction; Computer programming; Education; Graph theory; Collaborative learning environment; Computer education; Computer programmers; General purpose languages; Learning; Novice and expert programmers; Recommendation; Stack overflow; Computer programming languages",2-s2.0-85026884507
"Holmen J.K., Humphrey A., Sunderland D., Berzins M.","Improving uintah's scalability through the use of portable kokkos-based data parallel tasks",2017,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025832467&doi=10.1145%2f3093338.3093388&partnerID=40&md5=7659b9b09e3baa5790a504e30b1b56ac",".e University of Utah's Carbon Capture Multidisciplinary Simulation Center (CCMSC) is using the Uintah Computational Framework to predict performance of a 1000 MWe ultra-supercritical clean coal boiler. .e center aims to utilize the Intel Xeon Phi-based DOE systems, .eta and Aurora, through the Aurora Early Science Program by using the Kokkos C++ library to enable node-level performance portability. .is paper describes infrastructure advancements and portability improvements made possible by the integration of Kokkos within Uintah. .is integration marks a step towards consolidating Uintah's MPI+P.reads and MPI+CUDA hybrid parallelism approaches into a single MPI+Kokkos approach. Scalability results are presented that compare serial and data parallel task execution models for a challenging radiative heat transfer calculation, central to the center's predictive boiler simulations. .ese results demonstrate both good strong-scaling characteristics to 256 Knights Landing (KNL) processors on the NSF Stampede system, and show the KNL-based calculation to compete with prior GPU-based results for the same calculation. © 2017 ACM.","Hybrid Parallelism; Knights Landing; Kokkos; Many-Core; MIC; Parallel; Portability; Radiation Modeling; Reverse Monte-Carlo Ray Tracing; Scalability; Stampede; Uintah; Xeon Phi","Boilers; C++ (programming language); Carbon; Computer software; Computer software portability; Heat transfer; Landing; Hybrid parallelisms; Kokkos; Many core; Parallel; Radiation modeling; Reverse Monte Carlo; Stampede; Uintah; Xeon Phi; Scalability",2-s2.0-85025832467
"Malaya N., McDougall D., Michoski C., Lee M., Simmons C.S.","Experiences porting scientific applications to the intel (KNL) xeon phi platform",2017,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025818711&doi=10.1145%2f3093338.3104172&partnerID=40&md5=93afb61976a966b2ceb7ed0bda7de148","This paper presents experiences using Intel's KNL MIC platform on hardware that will be available in the Stampede 2 cluster launching in Summer 2017. We focus on 1) porting of existing scientific software; 2) observing performance of this software. Additionally, we comment on both the ease of use of KNL and observed performance of KNL as compared to previous generation ""Knights Ferry"" and ""Knights Corner"" Xeon Phi MICs [32]. Fortran, C, and C++ applications are chosen from a variety of scientific disciplines including computational fiuid dynamics, numerical linear algebra, uncertainty quantification, finite element methods, and computational chemistry. © 2017 Copyright is held by the owner/author(s).",,"C++ (programming language); Linear algebra; Microwave integrated circuits; Numerical methods; Computational fiuid dynamics; Ease-of-use; Numerical Linear Algebra; Scientific applications; Scientific discipline; Scientific softwares; Uncertainty quantifications; Computational chemistry",2-s2.0-85025818711
"Wu J., Deng L., Jeon G.","Image Autoregressive Interpolation Model using GPU-Parallel Optimization",2017,"IEEE Transactions on Industrial Informatics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023207638&doi=10.1109%2fTII.2017.2724205&partnerID=40&md5=25c7a99c9f57972531865e439252531b","With the growth in the consumer electronics industry, it is vital to develop an algorithm for ultra high definition products that is more effective and has lower time complexity. Image interpolation, which is based on autoregressive model, has achieved significant improvements compared with the traditional algorithm with respect to image reconstruction, including a better peak signal-to-noise ratio and improved subjective visual quality of the reconstructed image. However, the time-consuming computation involved has become a bottleneck in those autoregressive algorithms. Because of the high time cost, image autoregressive-based interpolation algorithms are rarely used in industry for actual production. In this study, in order to meet the requirements of real-time reconstruction, we use diverse CUDA optimization strategies to make full use of the GPU, including a shared memory and register and multi-GPU optimization. To be more suitable for GPU-parallel optimization, we modify the training window to obtain more concise matrix operation. Experimental results show that, while maintaining a high PSNR and subjective visual quality and taking into account the I/O transfer time, our algorithm achieves a high speedup of 147.3 times for a Lena image and 174.8 times for a 720p video, compared to the original single-threaded C CPU code with -O2 compiling optimization. IEEE","autoregressive model; Computational modeling; CUDA; GPU; Graphics processing units; Image interpolation; Informatics; Interpolation; Optimization; parallel optimization; Training","C (programming language); Computer graphics; Electronics industry; Graphics processing unit; Image processing; Image reconstruction; Interpolation; Personnel training; Program processors; Signal to noise ratio; Auto regressive models; Computational model; CUDA; Image interpolations; Informatics; Parallel optimization; Optimization",2-s2.0-85023207638
"Liu X., Jia J., Rueping M.","Nickel-Catalyzed C-O Bond-Cleaving Alkylation of Esters: Direct Replacement of the Ester Moiety by Functionalized Alkyl Chains",2017,"ACS Catalysis",4,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024928997&doi=10.1021%2facscatal.7b00941&partnerID=40&md5=cb9b719768069a64cc6fc9ab73ff6fc9","Two efficient protocols for the nickel-catalyzed aryl-alkyl cross-coupling reactions using esters as coupling components have been established. The methods enable the selective oxidative addition of nickel to acyl C-O and aryl C-O bonds and allow the aryl-alkyl cross-coupling via decarbonylative bond cleavage or through cleavage of a C-O bond with high efficiency and good functional group compatibility. The protocols allow the streamlined, unconventional utilization of widespread ester groups and their precursors, carboxylic acids and phenols, in synthetic organic chemistry. © 2017 American Chemical Society.","alkylation; C-O activation; cross-coupling; decarbonylation; nickel catalysis","Alkylation; Catalysis; Chemical bonds; Chemical reactions; Esters; Functional groups; Nickel; Organometallics; Cross coupling reactions; Cross-couplings; Decarbonylations; Direct replacements; Efficient protocols; Nickel catalysis; Oxidative additions; Synthetic organic chemistry; C (programming language)",2-s2.0-85024928997
"McAfee P., Wiem Mkaouer M., Krutz D.E.","CATE: Concolic Android Testing Using Java PathFinder for Android Applications",2017,"Proceedings - 2017 IEEE/ACM 4th International Conference on Mobile Software Engineering and Systems, MOBILESoft 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027022510&doi=10.1109%2fMOBILESoft.2017.35&partnerID=40&md5=36f059f8d89d1200d458974f42a1dacf","Like all software, Android applications are not immune to bugs, security vulnerabilities, and a wide range of other issues. Concolic analysis, a hybrid software verification technique which performs symbolic execution along with a concrete execution path, has been used for a variety of purposes including software testing, code clone detection, and security-related activities. We created a new publicly available concolic analysis tool for analyzing Android applications: Concolic Android TEster (CATE). Building on Java Path Finder (JPF-SPF), this tool performs concolic analysis on a raw Android application file (or source code) and provides output in a useful and easy to understand format. © 2017 IEEE.",,"Android (operating system); Application programs; Concrete testing; Java programming language; Program debugging; Software engineering; Software testing; Verification; Analysis tools; Android applications; Code clone detection; Execution paths; Java PathFinder; Security vulnerabilities; Software verification; Symbolic execution; Mobile security",2-s2.0-85027022510
"Kumar P.","Design and implementation of Smart Home control using LabVIEW",2017,"Proceedings of the 3rd IEEE International Conference on Advances in Electrical and Electronics, Information, Communication and Bio-Informatics, AEEICB 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026640362&doi=10.1109%2fAEEICB.2017.7972317&partnerID=40&md5=5f0cc367e33c174c4b935d5a58f5d967","In today's era, technology has advanced to this extent that it can be very useful in domestic purposes. Our house is the center of our domestic life and we can control our daily activities by using technical system. Automating our house activities eases and simplifies the way of living. A house with smart control system is called Smart Home. The control system is built by using information technology to control the electric appliance and security system. Smart home is a result of continuous change in technology and will keep changing with advancement in technology. In this paper we have addressed one of the features of Smart Home which is a sample house environment monitor and control system. This feature has been implemented by using LabVIEW software. The developed system can monitor the temperature, PIR motion sensor, magnetic door sensor and LDR the family security. The system also has internet connection by which it can act as remote system and can be controlled from anywhere in the world. This paper explains the hardware implementation of a multi-platform control system for house automation. The approach is a combination of hardware and software technologies. This system can be easily used for smart home application which is supported by the test results. © 2017 IEEE.","Data Acquisition Card; LabVIEW; Smart Hous","Automation; Computer programming languages; Control systems; Data acquisition; Hardware; Houses; Intelligent buildings; Data acquisition cards; Design and implementations; Environment monitor; Hardware and software; Hardware implementations; Internet connection; LabViEW; Smart control systems; Monitoring",2-s2.0-85026640362
"Habchi S., Hecht G., Rouvoy R., Moha N.","Code Smells in iOS Apps: How Do They Compare to Android?",2017,"Proceedings - 2017 IEEE/ACM 4th International Conference on Mobile Software Engineering and Systems, MOBILESoft 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027036956&doi=10.1109%2fMOBILESoft.2017.11&partnerID=40&md5=facb38e9a4fbd9914e4098a828465cd9","With billions of app downloads, the Apple App Store and Google Play Store succeeded to conquer mobile devices. However, this success also challenges app developers to publish high-quality apps to keep attracting and satisfying end-users. In particular, taming the ever-growing complexity of mobile apps to cope with maintenance and evolution tasks under such a pressure may lead to bad development choices. While these bad choices, a.k.a. code smells, are widely studied in object-oriented software, their study in the context of mobile apps, and in particular iOS apps, remains in its infancy. Therefore, in this paper, we consider the presence of object-oriented and iOS-specific code smells by analyzing 279 open-source iOS apps. As part of this empirical study, we extended the Paprika toolkit, which was previously designed to analyze Android apps, in order to support the analysis of iOS apps developed in Objective-C or Swift. We report on the results of this analysis as well as a comparison between iOS and Android apps. We comment our findings related to the quality of apps in these two ecosystems. Interestingly, we observed that iOS apps tend to contain the same proportions of code smells regardless of the development language, but they seem to be less prone to code smells compared to Android apps. © 2017 IEEE.","Android; code smells; iOS; Mobile apps; software quality","Codes (symbols); Computer software selection and evaluation; iOS (operating system); Object oriented programming; Odors; Open source software; Open systems; Software engineering; Android; Code smell; Empirical studies; High quality; Mobile apps; Object oriented; Object oriented software; Software Quality; Android (operating system)",2-s2.0-85027036956
"Bartók R., Vásárhelyi J.","Two methods for autonomous robot obstacle sensing and application programming interface for Fuzzy Rule Interpolation",2017,"2017 18th International Carpathian Control Conference, ICCC 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027571372&doi=10.1109%2fCarpathianCC.2017.7970376&partnerID=40&md5=8d8c6e3fe75661dc986f8402cf8fdec5","Environment detection is important task for an autonomous robot. Obstacle avoidance is a must when the robot do indoor activity. I this case robot movement is done in corridors and rooms, which is similar to a maze. Distance from the walls can be sensed with different sensors, in the experiment infra-red sensors were used. There are several methods for obstacle detection and calculating the distance from it. In the experiment Fuzzy Rule Interpolation (FRI) and Bayes classifier were used. On the other side a programmer friendly API was created for relive the Declarative Description Language used for different type of hardware. Using the FRI method to obstacle detection a rulebase was defined for each wall position (front, left, right). The Bayes classifier makes use of a big amount of data, which are collected from the sensors. The collected data are clustered for noise reduction and the amount of data is reduced. The method gave 7 classes according to possible wall positions, which appear in the maze around the robot. Both methods were tested on a robot. The results were compared and described in this paper. © 2017 IEEE.","behavior based detection; embedded system; fuzzy interpolation; fuzzy logic; mobile robot","Application programming interfaces (API); Computer hardware description languages; Embedded systems; Fuzzy inference; Fuzzy logic; Fuzzy rules; Interpolation; Mobile robots; Noise abatement; Obstacle detectors; Robot programming; Behavior-based detection; Declarative descriptions; Environment detection; Fuzzy interpolation; Fuzzy rule interpolation; Indoor activities; Infra-red sensor; Obstacle detection; Robots",2-s2.0-85027571372
"Marian M., Stîngǎ F., Kese V., Bǎrbulescu L.","A case study in real time implementations of a predictive control algorithm",2017,"2017 18th International Carpathian Control Conference, ICCC 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027570621&doi=10.1109%2fCarpathianCC.2017.7970389&partnerID=40&md5=ba90c02ede9198117a4add52d6968a8c","In this paper we present a C programming language implementation of a predictive control algorithm. The code was compiled and run under the same set of hypotheses using a standard open-source C compiler, and on three real time platforms, each with different technical specifications. © 2017 IEEE.","model predictive control; software and microcontroller implementation","Model predictive control; Open source software; Open systems; Program compilers; Real time control; C compilers; Open sources; Predictive control algorithm; Real-time implementations; Real-time platform; Technical specifications; C (programming language)",2-s2.0-85027570621
"Hýl R., Wagnerová R.","Fast development of controllers with Simulink Coder",2017,"2017 18th International Carpathian Control Conference, ICCC 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027589543&doi=10.1109%2fCarpathianCC.2017.7970434&partnerID=40&md5=a3b9fbdce390b365e683587ec8ab2f1a","The aim of this paper is to describe rapid design and realization of a embedded controllers by using MATLAB toolboxes like Simulink Coder. The Simulink Coder generates and executes C and C++ code from Simulink diagrams, Stateflow charts, and MATLAB functions. An automatic code generation enables implementation of Simulink controller models directly to the PLC without manual coding. The generated source code it is possible to use for real-time and non-real-time applications, including rapid prototyping and hardware-in-the-loop testing. The code can be tuned and monitored using Simulink or run and interact with the code outside MATLAB and Simulink. The integration of I/O cards in the model enables the simulation of data acquisition, so that control system can be performed directly from Simulink. The controls deployed to the real-time target can be used for communication with Simulink using the external mode, and also can provide data exchange of process variables and block parameters to other applications on the PLC system (IEC 61131, C, C++, Java). The controllers' implementation was tested with climate unit laboratory model and predictive controllers and decentralized PID controllers were used. © 2017 IEEE.","Laboratory model; PLC; Rapid prototyping; Simulink Coder","Automatic programming; C++ (programming language); Climate models; Codes (symbols); Data acquisition; Electronic data interchange; MATLAB; Programmable logic controllers; Rapid prototyping; Three term control systems; Automatic code generations; Decentralized PID controller; Embedded controllers; Hardware-in-the-loop testing; Laboratory models; MATLAB and SIMULINK; Predictive controller; Simulink; Controllers",2-s2.0-85027589543
"Czebe J., Škuta J.","Usage of single-chip computers for control MIMO systems",2017,"2017 18th International Carpathian Control Conference, ICCC 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027542699&doi=10.1109%2fCarpathianCC.2017.7970428&partnerID=40&md5=54ed4c2120c11f2b93304253f80c0480","This paper deals with usage of single-chip computers for controlling MIMO systems. The aim is to design a general control system, which is easy to use and easy to implement for other MIMO systems. The performance of control system is limited by the performance of used MCU (PIC 16F876A) and its peripherals (2×PWM, 8×A/D, MAC,...). The key tasks of MCU are communication with upper level and implementation of required control action together with data collection. The serial interface provides communication between control system (PC) and MCU. SCADA/HMI system monitors a controlled system. The application is accessible via Internet browser in local area network (LAN). © 2017 IEEE.","C language; Communication interface; Data processing; Eagle; MCU; Measurement; mikroC; MPLAB X IDE; SCADA/HMI; Signal processing","C (programming language); Control systems; Data handling; Data processing; Local area networks; Measurements; Microcontrollers; MIMO systems; Signal processing; C language; Communication interface; Eagle; mikroC; MPLAB X IDE; SCADA/HMI; Monitoring",2-s2.0-85027542699
"Patrascoiu N., Ioana C.R., Barbu C.","Virtual instrumentation for Data Acquisition and remote control",2017,"2017 18th International Carpathian Control Conference, ICCC 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027542659&doi=10.1109%2fCarpathianCC.2017.7970378&partnerID=40&md5=f5166c0954111f38136db851ed9f4a70","In this paper we present an application, written in LabVIEW, through which it can observe, by means of webcam, the effects of commands placed via TCP / IP. As example, we considered a system of a traffic light intersection. To achieve application is used NI USB6008 module placed behind a Web server in order to simulate and in the future to create the smart grids. Using the capabilities of the Web servers and the LabVIEW software it can be possible to train users into a virtual lab. © 2017 IEEE.","LabVIEW; TCP/IP; virtual lab; Web server","Computer programming languages; Remote control; Transmission control protocol; Web services; Lab-view softwares; LabViEW; Smart grid; TCP/IP; Traffic light; Virtual Instrumentation; Virtual lab; Web servers; Data acquisition",2-s2.0-85027542659
"Zhu C., Ding T., Gao W., Ma K., Tian Y., Li X.","CuO/CeO2 catalysts synthesized from Ce-UiO-66 metal-organic framework for preferential CO oxidation",2017,"International Journal of Hydrogen Energy",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014571557&doi=10.1016%2fj.ijhydene.2017.02.088&partnerID=40&md5=c8233643145fd5c64117ea78512a4b48","We synthesized a CuO/CeO2 catalyst using a copper ions encapsulated ceria metal-organic framework (MOF) Ce-UiO-66 as the precursor. The CuO/CeO2 catalysts derived by calcining the MOF precursor (the x-CuCe catalysts) showed the better activity and selectivity for the preferential CO oxidation in the H2-rich stream than the CuO/CeO2 catalyst prepared by wetness impregnation (CuCe-im). A temperature window to match the CO conversion and O2 to CO2 selectivity higher than 99.5% at the same time appeared using the x-CuCe catalysts as the catalyst. Raman and XPS results indicated that more oxygen vacancies were formed in the bulk of ceria in the x-CuCe catalysts than that in the CuCe-im catalyst, which could promote the mobility of oxygen. Our results indicated that the surface lattice oxygen and the oxygen vacancies in the bulk of ceria could enhance the catalytic performance of the CuO/CeO2 catalysts. © 2017 Hydrogen Energy Publications LLC","CeO2; CO preferential oxidation; CuO; MOF","Carbon dioxide; Catalyst activity; Catalysts; Cerium; Copper oxides; Crystalline materials; Java programming language; Metal ions; Organometallics; Oxidation; Oxygen; Oxygen vacancies; Catalytic performance; CeO<sub>2</sub>; CO preferential oxidation; Metal organic framework; Preferential CO oxidation; Surface lattice; Temperature window; Wetness impregnation; Catalyst selectivity",2-s2.0-85014571557
"Ivanov S.I., Liokumovich L.B., Medvedev A.V.","Estimation of the parameters of the phase modulated signal in presence of the background noise using complete sufficient statistics",2017,"Proceedings of 2017 20th IEEE International Conference on Soft Computing and Measurements, SCM 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027154868&doi=10.1109%2fSCM.2017.7970480&partnerID=40&md5=0a9ffc31dfc75faaccd5a842bfbc8669","The results of the statistical estimation of the phase modulated signal parameters in white Gaussian noise are given. Measurable functions of the complete sufficient statistics for the phase parameters' estimates under the conditions of a priori uncertainty of the signal amplitude and noise variance were found. The simulation results of the demodulation process using LabVIEW software environment and the synthesized algorithm showed the asymptotic efficiency of the estimates. © 2017 IEEE.","a priori non-certainty; demodulation; estimation of parameters; Gaussian noise; phase modulated signal; sufficient statistics","Computer programming languages; Computer software; Demodulation; Gaussian noise (electronic); Optical variables measurement; Phase modulation; Soft computing; Uncertainty analysis; a priori non-certainty; Asymptotic efficiency; Estimation of parameters; Lab-view softwares; Phase modulated signals; Statistical estimation; Sufficient statistics; White Gaussian Noise; Parameter estimation",2-s2.0-85027154868
"Sajad M.A.","Development of the circuit elements knowledgebase on Horn clauses and description logic",2017,"Proceedings of 2017 20th IEEE International Conference on Soft Computing and Measurements, SCM 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027191194&doi=10.1109%2fSCM.2017.7970637&partnerID=40&md5=766d369d03169fba4d991b683399c0c1","The report focuses on the development of a knowledgebase (based on ontology) for automated classification of circuit elements and for finding suitable items under the required specification of the customer. During the development the following methods and technologies were used: knowledge engineering of circuit elements (for example transistors), ontology engineering in Protégé environment, rules for inferring the implicit knowledge, based on first-order logic (in the form of Horn clauses) and elements of description logic. The result of the works is created knowledgebase, which allows to classify bipolar and field transistors according to such characteristics as: frequency, power, structure, material of manufacture. The obtained knowledgebase can be used in the decision-making system for selection of suitable circuit elements for complex devices. © 2017 IEEE.","circuit elements; description logic; Horn clause; knowledgebase; ontology","Computation theory; Data description; Decision making; Formal languages; Formal logic; Logic circuits; Logic programming; Ontology; Soft computing; Timing circuits; Automated classification; Circuit elements; Decision-making systems; Description logic; Horn clause; Implicit knowledge; Knowledge base; Ontology engineering; Computer circuits",2-s2.0-85027191194
"Mondal M., Rahman M.S., Roy C.K., Schneider K.A.","Is cloned code really stable?",2017,"Empirical Software Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021825826&doi=10.1007%2fs10664-017-9528-y&partnerID=40&md5=32db0aeeefb77f19a5348806d77c7a82","Clone has emerged as a controversial term in software engineering research and practice. The impact of clones is of great importance from software maintenance perspectives. Stability is a well investigated term in assessing the impacts of clones on software maintenance. If code clones appear to exhibit a higher instability (i.e., higher change-proneness) than non-cloned code, then we can expect that code clones require higher maintenance effort and cost than non-cloned code. A number of studies have been done on the comparative stability of cloned and non-cloned code. However, these studies could not come to a consensus. While some studies show that code clones are more stable than non-cloned code, the other studies provide empirical evidence of higher instability of code clones. The possible reasons behind these contradictory findings are that different studies investigated different aspects of stability using different clone detection tools on different subject systems using different experimental setups. Also, the subject systems were not of wide varieties. Emphasizing these issues (with several others mentioned in the motivation) we have conducted a comprehensive empirical study where we have - (i) implemented and investigated seven existing methodologies that explored different aspects of stability, (ii) used two clone detection tools (NiCad and CCFinderX) to implement each of these seven methodologies, and (iii) investigated the stability of three types (Type-1, Type-2, Type-3) of clones. Our investigation on 12 diverse subject systems covering three programming languages (Java, C, C#) with a list of 8 stability assessment metrics suggest that (i) cloned code is often more unstable (change-prone) than non-cloned code in the maintenance phase, (ii) both Type 1 and Type 3 clones appear to exhibit higher instability than Type 2 clones, (iii) clones in Java and C programming languages are more change-prone than the clones in C#, and (iv) changes to the clones in procedural programming languages seem to be more dispersed than the changes to the clones in object oriented languages. We also systematically replicated the original studies with their original settings and found mostly equivalent results as of the original studies. We believe that our findings are important for prioritizing code clones from management perspectives. © 2017 Springer Science+Business Media New York","Code clones; Code stability; Software maintenance and evolution","Codes (symbols); Computer software maintenance; Inspection equipment; Java programming language; Maintenance; Object oriented programming; Software engineering; Stability; System stability; Change proneness; Clone detection; Code clone; Empirical studies; Maintenance efforts; Procedural programming languages; Software maintenance and evolution; Stability assessment; Cloning",2-s2.0-85021825826
"Hopkins M.B., Lee P.","Efficient logarithmic conversion on an ARM microcontroller for real time acoustic monitoring",2017,"I2MTC 2017 - 2017 IEEE International Instrumentation and Measurement Technology Conference, Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026799848&doi=10.1109%2fI2MTC.2017.7969974&partnerID=40&md5=515e3873f468278b41905bec28717dc0","Measuring instrumentation products incorporating embedded microcontrollers are frequently required to perform logarithmic conversions both accurately and efficiently-in this case the application is a high precision acoustic monitoring system. Many contemporary microcontrollers (such as those based on ARM Cortex M4 or M7 cores), incorporate an optional 'on board' Floating Point Unit (FPU), providing very rapid floating point arithmetic calculations leading some programmers to abandon integer variables in favour floating point types. This paper demonstrates how this facet of the microcontrollers may be employed, in an alternative approach, to efficiently compute logarithms using classical mathematical power series working in radix ten format. This is compared and contrasted with traditional iterative binary algorithms and 'Look up Table' techniques. The paper then develops the mathematical background and subsequently presents an efficient practical algorithm for such computations, which may be simply implemented (and adapted) in a high level language such as 'C'. An accuracy of better than 0.0005% has been attained with mean execution times of 350 nS for the mantissa calculation, and 830 nS for an overall common logarithmic conversion for single precision floating point numbers. © 2017 IEEE.","Logarithic conversion; Logarithm algorithm","Acoustic measuring instruments; ARM processors; C (programming language); Computer programming languages; Controllers; High level languages; Iterative methods; Microcontrollers; Real time control; Table lookup; Acoustic monitoring; ARM microcontrollers; Binary algorithms; Embedded microcontroller; Floating point units; Instrumentation products; Integer variables; Logarithm algorithm; Digital arithmetic",2-s2.0-85026799848
"Vracević M., Vranješ M., Kovačević M., Teslić N.","Realization of graphical user interface for TV application electronic program guide",2017,"2017 Zooming Innovation in Consumer Electronics International Conference: Galvanize Your Creativity, ZINC 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027415542&doi=10.1109%2fZINC.2017.7968667&partnerID=40&md5=4c415aab910b45f4d44205e0098f1b0a","Electronic program guide (EPG) is an application that provides information about current and upcoming events on all available channels to the digital television (DTV) users. This article presents design and implementation of one EPG application based on metadata from DTV transport stream (TS). The application is interactive and displays the data in Graphical User Interface (GUI). GUI is implemented using Qt framework while data obtaining and processing are realized in C/C++ programming languages. Target platform is Linux based system. © 2017 IEEE.","digital television; EPG; GUI; Linux; Qt","Application programs; C (programming language); Computer operating systems; Data handling; Digital television; Graphical user interfaces; Linux; Television broadcasting; Zinc; Available channels; Design and implementations; Digital televisions (DTV); Electronic program guide; Graphical user interfaces (GUI); Linux-based system; Transport streams; User interfaces",2-s2.0-85027415542
"Iacob R., Rebedea T., Trausan-Matu S.","NLCP: Towards a Compiler for Natural Language",2017,"Proceedings - 2017 21st International Conference on Control Systems and Computer, CSCS 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027510738&doi=10.1109%2fCSCS.2017.42&partnerID=40&md5=93051746e0840c6a1c4184e6569fa4ca","NLCP - The Natural Language Compiler - is a new programming environment, which features a strong type system and support for a natural language interface. Additionally, it provides an interactive interpreter that can assist in the process of designing an algorithm. This is achieved by allowing the user to embed information about the objectives of algorithms within the type system. We provide an overview of the main design considerations behind NLCP and list several simple examples of algorithms translated from natural language statements to code. © 2017 IEEE.",,"Control systems; Natural language processing systems; Program compilers; Design considerations; Natural language interfaces; Natural languages; Programming environment; Strong-type system; Type systems; Computer control systems",2-s2.0-85027510738
"Wei M., Song Z., Li P., Lin J., Zhang J., Hao J., Chi B.","A fully integrated reconfigurable low-power Sub-GHz transceiver for 802.11ah in 65nm CMOS",2017,"Digest of Papers - IEEE Radio Frequency Integrated Circuits Symposium",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026864209&doi=10.1109%2fRFIC.2017.7969062&partnerID=40&md5=e3735ac436a02caf08bd050da7cc1ad0","A fully integrated reconfigurable low-power Sub-GHz transceiver for 802.11ah is presented. The receiver uses the low-IF/zero-IF reconfigurable architecture to support 1, 2 and 8MHz signal bandwidth, and the needed number of the Op-Amps in the analog baseband is reduced to 3 while providing 4th-order channel filtering and programmable gain amplification. The transmitter uses the digital polar architecture, with the open-loop phase modulator to support wide signal bandwidth and the inverse Class-D digital power amplifier to enhance the power efficiency. A Class-C VCO with dynamic gate bias technique for robust start-up and AFC-assisted oscillation amplitude control technique is used in the fractional-N PLL frequency synthesizer. The transceiver has been implemented in 65nm CMOS. The measured results show that the receiver achieves &lt;3.89dB NF and 47dB image rejection, and the frequency synthesizer achieves -127.8dBc/Hz phase noise at 1MHz offset and -94.6dBc/Hz in-band phase noise from a 1.536GHz carrier. The transmitter demonstrates 6.98% EVM for 900MHz pi/4-DQPSK signals at 6.3 dBm output power without pre-distortion. The receiver and the frequency synthesizer consume 6.4mA and 5.5mA current from a 1.2V power supply, respectively, and the DPA in the transmitter achieves 51.7% drain efficiency at 17.1dBm peak output power. © 2017 IEEE.","802.11ah; analog baseband; Class-C VCO; DPA; low power; polar transmitter; Transceiver","Bandwidth; CMOS integrated circuits; Drain current; Efficiency; Frequency synthesizers; Operational amplifiers; Phase noise; Power amplifiers; Radio waves; Reconfigurable architectures; Signal receivers; Transceivers; Transmitters; Variable frequency oscillators; 802.11ah; Analog baseband; Digital power amplifiers; In-band phase noise; Low Power; Oscillation amplitude; Polar transmitter; Programmable gain amplification; C (programming language)",2-s2.0-85026864209
"Lai W.-C., Jang S.-L., Chiou J.-S.","A dynamic-biased armstrong class-C voltage-controlled oscillator",2017,"2017 6th International Symposium on Next Generation Electronics, ISNE 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027125105&doi=10.1109%2fISNE.2017.7968730&partnerID=40&md5=b58954a5b395d040bfdb3a3719d0e670","A class-C Armstrong oscillator was implemented in the TSMC 0.18 μm 1P6M CMOS process, and it uses a cross-coupled inductive coupling to provide differential outputs and two RF amplifiers to replenish the energy loss caused by the tank. The oscillator uses the varactors for frequency tuning. The VCO uses dynamic bias to lower the power consumption in steady state and the core current and power consumption of the oscillator are 2.3mA and 2.53mW, respectively at the dc drain-source bias of 1.1V. The oscillator can generate differential signals in the frequency range of 5.64-5.74GHz. The die area of the oscillator is 0.874×0.789 mm2. © 2017 IEEE.","0.18 μm CMOS; differential oscillator; dynamic gate bias; transformer feedback","C (programming language); Circuit oscillations; CMOS integrated circuits; Drain current; Electric power utilization; Electromagnetic induction; Energy dissipation; Oscillistors; Power amplifiers; Radio frequency amplifiers; Differential oscillators; Differential output; Differential signal; Dynamic gate bias; Frequency ranges; Frequency-tuning; Inductive couplings; Transformer feedback; Variable frequency oscillators",2-s2.0-85027125105
"Mu C., Li C., Liu Y., Sun M., Jiao L., Qu R.","Change detection in SAR images based on the salient map guidance and an accelerated genetic algorithm",2017,"2017 IEEE Congress on Evolutionary Computation, CEC 2017 - Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028514177&doi=10.1109%2fCEC.2017.7969436&partnerID=40&md5=8c3f4209bb460aa80a0a57ed4c33586c","This paper proposes a change detection algorithm in synthetic aperture radar (SAR) images based on the salient image guidance and an accelerated genetic algorithm (S-aGA). The difference image is first generated by logarithm ratio operator based on the bi-temporal SAR images acquired in the same region. Then a saliency detection model is applied in the difference image to extract the salient regions containing the changed class pixels. The salient regions are further divided by fuzzy c-means (FCM) clustering algorithm into three categories: changed class (set of pixels with high gray values), unchanged class (set of pixels with low gray values) and undetermined class (set of pixels with middle gray value, which are difficult to classify). Finally, the proposed accelerated GA is applied to explore the reduced search space formed by the undetermined-class pixels according to an objective function considering neighborhood information. In S-aGA, an efficient mutation operator is designed by using the neighborhood information of undetermined-class pixels as the heuristic information to determine the mutation probability of each undetermined-class pixel adaptively, which accelerates the convergence of the GA significantly. The experimental results on two data sets demonstrate the efficiency of the proposed S-aGA. On the whole, S-aGA outperforms five other existing methods including the simple GA in terms of detection accuracy. In addition, S-aGA could obtain satisfying solution within limited generations, converging much faster than the simple GA. © 2017 IEEE.","Change detection; Fuzzy c-means (FCM); Genetic algorithm (GA); Saliency map; Synthetic Aperture Radar (SAR) image","C (programming language); Clustering algorithms; Evolutionary algorithms; Fuzzy systems; Genetic algorithms; Pixels; Radar; Synthetic aperture radar; Change detection; Change detection algorithms; Fuzzy C mean; Fuzzy c-means clustering algorithms; Heuristic information; Neighborhood information; Saliency map; Synthetic aperture radar (SAR) images; Radar imaging",2-s2.0-85028514177
"Lemaire P.C., Lee D.T., Zhao J., Parsons G.N.","Reversible Low-Temperature Metal Node Distortion during Atomic Layer Deposition of Al2O3 and TiO2 on UiO-66-NH2 Metal-Organic Framework Crystal Surfaces",2017,"ACS Applied Materials and Interfaces",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021964937&doi=10.1021%2facsami.7b05214&partnerID=40&md5=5dd2ede7e4849435ce63da1e8b0102db","Metal-organic frameworks (MOFs) are chemically functionalized micro- and mesoporous materials with high surface areas and are attractive for multiple applications including filtration, gas storage, and catalysis. Postsynthetic modification (PSM), via solution or vapor-based techniques, is a way to impart additional complexity and functionality into these materials. There is a desire to shift toward vapor-phase methods in order to ensure more controlled modification and more efficient reagent and solvent removal from the modified MOF material. In this work we explore how the metal precursors titanium tetrachloride (TiCl4) and trimethylaluminum (TMA), commonly used in atomic layer deposition, react with UiO-66-NH2 MOF. Using in situ quartz crystal microbalance (QCM) and Fourier transform infrared spectroscopy (FTIR) at 150 and 250 °C, we find that the ALD precursors react with μ3-OH hydroxyl and μ3-O bridging oxygen groups on Zr6 nodes, as well as oxygen from carboxylate linker groups. The reactions occur predominantly at the crystal surface at μ3-OH hydroxyl sites, with TiCl4 exhibiting greater diffusion into the MOF subsurface. FTIR analysis suggests that, at 150 °C, both TiCl4 and TMA reversibly dehydroxylate the hydroxylated UiO-66-NH2, which is accompanied by distortion of the zirconium metal clusters. Finally, we show that TiCl4 is able to react with the dehydroxylated UiO-66-NH2 structure, suggesting that TiCl4 is also able to react directly with the bridging oxygens in the metal clusters or carboxylate groups on the organic ligand. A better understanding of chemical and thermally driven MOF dehydroxylation reactions can be important for improved postsynthetic modification of MOFs. © 2017 American Chemical Society.","atomic layer deposition; Fourier transform infrared spectroscopy; metal organic framework; post-synthetic modification; quartz crystal microbalance; UiO-66-NH2","Atoms; Carboxylation; Chemical modification; Crystalline materials; Deposition; Fourier transform infrared spectroscopy; Java programming language; Mesoporous materials; Metals; Organometallics; Oxygen; Quartz; Quartz crystal microbalances; Controlled modification; Dehydroxylation reactions; Metal organic framework; Metalorganic frameworks (MOFs); Postsynthetic modification; Situ quartz crystal microbalance; Titanium tetrachlorides; UiO-66-NH<sub>2</sub>; Atomic layer deposition",2-s2.0-85021964937
"Lai W.-C., Jang S.-L., Ciou Y.-L., Lee H.-C., Su Y.-J.","Low power transformer coupled VCO for wearable sensor applications",2017,"2017 6th International Symposium on Next Generation Electronics, ISNE 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027184756&doi=10.1109%2fISNE.2017.7968733&partnerID=40&md5=917f46432bce74ef229e780a543a5e0d","This article presents a voltage-controlled oscillator (VCO) utilizing transformer coupling method and combining the efficiency of the class-C oscillator to improve the phase noise performance by increasing the negative-conductance (-Gm) of the VCO core and reduce the power consumption. Implemented in 0.18um SiGe BiCMOS process, the proposed VCO operates between 5.27 GHz and 5.56 GHz and matches 802.11a standard. At the supply voltage of 1.55 V, the core power consumption is 4.9 mW. The measured phase noise and the figure of merit (FOM) of the proposed VCO operating at 5.27 GHz are-119.86 dBc/Hz at 1 MHz offset frequency and-187.39 dBc/Hz, respectively. © 2017 IEEE.","0.18-um SiGe BiCMOS; class-C; negative-conductance (-Gm); Voltage-Controlled oscillator (VCO)","BiCMOS technology; Bismuth alloys; C (programming language); Circuit oscillations; Electric power utilization; Energy efficiency; Oscillistors; Phase noise; Power transformers; Semiconducting silicon; Si-Ge alloys; Silicon alloys; Vanadium alloys; Wearable sensors; Wearable technology; Figure of merit (FOM); Negative conductance; Phase noise performance; Sensor applications; SiGe BICMOS; Sige bicmos process; Transformer coupled; Transformer coupling; Variable frequency oscillators",2-s2.0-85027184756
"Mukherjee S., Babarao R., Desai A.V., Manna B., Ghosh S.K.","Polar Pore Surface Guided Selective CO2 Adsorption in a Prefunctionalized Metal-Organic Framework",2017,"Crystal Growth and Design",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022064343&doi=10.1021%2facs.cgd.7b00141&partnerID=40&md5=c901da0160230da358de871ab3321b1d","Selective CO2 adsorption over other small gases has been realized in an ultra-microporous metal-organic framework (MOF). In the quest of manifesting such selective carbon capture performance, the prefunctionalized linker strategy has been espoused. A new Zn(II)-based three-dimensional, 3-fold interpenetrated metal-organic framework material [Zn(PBDA)(DPNI)]n·xG (PBDA: 4,4′-((2-(tert-butyl)-1,4-phenylene)bis(oxy))dibenzoic acid; DPNI: N,N′-di(4-pyridyl)-1,4,5,8-naphthalenetetracarboxydiimide; xG: x number of guest species) with unusual rob topology is synthesized following a typical solvothermal synthesis protocol, which gleans a modest CO2-selective adsorption trend over its congener gases (saturation CO2 uptake capacity: 2.39 and 3.44 mmol g-1, at 298 and 273 K; volumetric single component isotherm based separation ratios at 0.2 bar: 189.4 (CO2/N2, 256.5 (CO2/H2), 12.3 (CO2/CH4); at 1 bar: 6.8 (CO2/N2, 17.1 (CO2/H2), 7.1 (CO2/CH4)). The compound also exhibits selective benzene sorption over its aliphatic C6-analogue cyclohexane. The structure-property correlation guided results supported by theoretical introspection further emphasize the omnipresent role of crystal engineering principles behind culmination of such targeted properties in the nanoporous MOF domain, to realize selective sorption facets. © 2017 American Chemical Society.",,"Adsorption; Carbon; Crystal structure; Crystalline materials; Java programming language; Zinc; Zinc compounds; Engineering principles; Metal organic framework; Metal organic framework materials; Microporous metal organic frameworks; Selective adsorption; Selective sorption; Solvothermal synthesis; Structure-property correlation; Carbon dioxide",2-s2.0-85022064343
"Mun J.H., Lee J., Lim H.","A new Bloom filter structure for identifying true positiveness of a Bloom filter",2017,"IEEE International Conference on High Performance Switching and Routing, HPSR",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027282707&doi=10.1109%2fHPSR.2017.7968676&partnerID=40&md5=382f779be39df8af8975670365c55db2","Bloom filters have been employed in various fields because of its simple and effective structure in identifying the membership of an input. Since a Bloom filter can produce false positives, the positive results of a Bloom filter should be identified whether the positives are true or not by accessing the original database. A complement Bloom filter (C-BF) was introduced to identify the true positiveness of a given Bloom filter without accessing the original database. A critical problem of the C-BF is that every element included in the complement set of the given set should be programmed into the C-BF. Since the number of elements included in the complement set can be considerably large, the C-BF would require the significant amount of memory. In this paper, we claim that the elements that produce negative results from the given Bloom filter are not necessarily programmed into the C-BF, since Bloom filters never produce false negatives. In other words, we propose the Petit-BF (P-BF) which programs only the elements that cause false positives from the given Bloom filter. Simulation results and theoretical analysis show that the proposed method can achieve the same performance using a considerably smaller amount of memory. © 2017 IEEE.",,"Bandpass filters; Data structures; Bloom filters; Complement sets; Critical problems; False negatives; False positive; C (programming language)",2-s2.0-85027282707
"Tregubov A., Boehm B., Rodchenko N., Lane J.A.","Impact of task switching andwork interruptions on software development processes",2017,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025819127&doi=10.1145%2f3084100.3084116&partnerID=40&md5=5781202dca59306b7e6d25fe28cd0f4e","Software developers often work on multiple projects and tasks throughout a work day, which may affect their productivity and quality of work. Knowing how working on several projects at a time affects productivity can improve cost and schedule estimations. It also can provide additional insights for better work scheduling and the development process. We want to achieve a better productivity without losing the benefits of work interruptions and multitasking for developers involved in the process. To understand howthe development process can be improved, first, we identify work interruptions that mostly have a negative effect on productivity, second, we need to quantitatively evaluate impact of multitasking (task switching, work context switching) and work interruptions on productivity. In this research we study cross-project multitasking among the developers working on multiple projects in an educational setting. We propose a way to evaluate the number of cross-project interruptions among software developers using self-reported work logs. This paper describes the research that found: A) software developers involved in two or more projects on average spend 17% of their development effort on cross-project interruptions, b) the amount of effort spent on interruptions is overestimated by the G. Weinberg's heuristic, c) the correlation between the number of projects and effort spent by developers on cross-project interruptions is relatively weak, and d) there is strong correlation between the number of projects and the number of interruptions developers reported. © 2017 ACM.","Cost Estimation; Effort Estimation; Multitasking Overhead; Software Development; Work Interruptions","C (programming language); Cost estimating; Multitasking; Productivity; Scheduling; Software engineering; Cost estimations; Development process; Educational settings; Effort Estimation; Software developer; Software development process; Strong correlation; Work Interruptions; Software design",2-s2.0-85025819127
"Ma X., Zhao X., Huang J., Sun L., Li Q., Yang X.","Fine Co Nanoparticles Encapsulated in a N-Doped Porous Carbon Matrix with Superficial N-Doped Porous Carbon Nanofibers for Efficient Oxygen Reduction",2017,"ACS Applied Materials and Interfaces",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022202936&doi=10.1021%2facsami.7b02490&partnerID=40&md5=a67d49b45135bfa90de38ba3140e2109","Herein, we develop a novel method to synthesize evenly dispersed fine Co nanoparticles (CoNPs) (particle size of ∼42 nm) encapsulated in a N-doped porous carbon matrix (NPCM) with superficial N-doped porous carbon nanofibers (NPCNF) (denoted as Co@NPCM/CNF-850) as an oxygen reduction reaction (ORR) electrocatalyst. Such an electrocatalyst is the direct pyrolysis product of the novel pine needle-like ZIF-67-based metal-organic framework nanowire array (MOFNWA) prepared using an inorganic cobalt carbonate hydroxide (Co(CO3)0.5(OH)·0.11H2O) nanowire array as a linear sacrificial template, which is totally different from the traditional method, that is, using inorganic salts to synthesize MOF particles. Because of the high dispersibility of the effective fine N-doped carbon-wrapped CoNPs (rather than the overlarge CoNP aggregates); the unique linear MOF-derived assemblies, which are beneficial to electronic transmission; the high degree of graphitization, which is attributed to the superficial NPCNF and carbon layers wrapping the CoNPs; as well as the high porosity, our catalyst showed remarkable ORR activity (Eonset of 1.033 V vs the reversible hydrogen electrode) in alkaline solution. Besides, our catalyst revealed excellent stability and tolerance of methanol. Furthermore, on the basis of the X-ray absorption near-edge structure, extended X-ray absorption fine structure, and linear sweep voltammetry data, we first provided proof that a catalyst devoid of obvious Co-Nx can have superior ORR activity. © 2017 American Chemical Society.","cobalt carbonate hydroxide; linear sacrificial template; metal-organic framework; nonprecious metal catalyst; oxygen reduction reaction","Carbon nanofibers; Catalyst activity; Catalysts; Cobalt; Crystalline materials; Doping (additives); Electrocatalysts; Electrolytic reduction; Extended X ray absorption fine structure spectroscopy; Java programming language; Nanofibers; Nanoparticles; Nanowires; Oxygen; Porous materials; Synthesis (chemical); X ray absorption; Extended X-ray absorption fine structures; Linear sweep voltammetry; Metal organic framework; Non-precious metal catalysts; Oxygen reduction reaction; Reversible hydrogen electrodes; Sacrificial templates; X ray absorption near edge structure; Matrix algebra",2-s2.0-85022202936
"Adamo F., Andria G., Di Nisio A., Lucia Lanzolla A.M., Spadavecchia M., Cotecchia F., Miccoli D., Sollecito F., Todaro F., Vitone C.","Development of an automatic system for geotechnical testing",2017,"I2MTC 2017 - 2017 IEEE International Instrumentation and Measurement Technology Conference, Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026777376&doi=10.1109%2fI2MTC.2017.7969743&partnerID=40&md5=3560959be2d5662626c97145dd3eb8de","Geotechnical tests are of vital importance in several contexts related to civil and environmental engineering. In this paper, the implementation of an integrated system (both hardware and software) is described. It permits on one hand to reduce the probability of human mistakes often made during manual operations and, on the other, to increase speed, accuracy, and productivity in geotechnical engineering laboratory tests. The software suite was developed in LabVIEW in order to both communicate with different DAQ platforms and to simplify software reconfiguration when laboratory activities change. © 2017 IEEE.","Data acquisition; Direct share test; Geotechnics; Measurement characterization and validation; Oedometer test; Soil characterization; Triaxial test","Computer programming languages; Data acquisition; Geotechnical engineering; Laboratories; Soil mechanics; Engineering laboratories; Geotechnical testing; Geotechnics; Hardware and software; Measurement characterization; Oedometer tests; Software reconfiguration; Soil characterization; Soil surveys",2-s2.0-85026777376
"Indirayanti P., Reynaert P.","A 32 GHz 20 dBm-PSAT transformer-based Doherty power amplifier for multi-Gb/s 5G applications in 28 nm bulk CMOS",2017,"Digest of Papers - IEEE Radio Frequency Integrated Circuits Symposium",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026855295&doi=10.1109%2fRFIC.2017.7969013&partnerID=40&md5=5d8b05513f8de27274d48485467d21a2","This paper presents a 32 GHz transformer-based Doherty power amplifier (PA) in a 28 nm bulk CMOS process. There are two techniques proposed: linearization by means of AM-PM and AM-AM compensation of the class AB and the class C amplifiers; and parallel-series-parallel power power combiner, wherein a current-mode parallel combiner complements the Doherty's voltage-mode series combiner to boost the output power. A saturated output power (PSAT ) of 19.8 dBm and an OP1dB of 16 dBm are accomplished from 1V supply while supporting 15 Gb/s 64-QAM amplification at 11.7 dBm average output power. The chip achieves 21% PAE at PSAT and occupies 0.59 mm2 active area. © 2017 IEEE.","5G; AM-PM distortion; CMOS; Doherty power amplifier; transformer power combiner","5G mobile communication systems; Amplitude modulation; C (programming language); CMOS integrated circuits; Power amplifiers; Radio waves; Average output power; Current mode; Doherty power amplifier; Power combiner; Saturated output power (Psat); Series-parallel; Transformer power; Voltage mode; Doherty amplifiers",2-s2.0-85026855295
"Lai W.-C., Jang S.-L., Shih B.-S., Su Y.-J.","Low power class-C VCO using dynamic body biasing",2017,"2017 6th International Symposium on Next Generation Electronics, ISNE 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027187761&doi=10.1109%2fISNE.2017.7968734&partnerID=40&md5=a97f95d262fb489e621b3187bb625046","This article proposes a 3 GHz class-C VCO with dynamic body-biased MOSFET. The dynamic biasing circuit is used to reduce power consumption by switching NMOS from initial class-AB to class-C operation in steady state and this is obtained by switching the body bias of switching transistors to control threshold voltage of switching MOSFET. The dynamic body-biased Class-C VCO is implemented in TSMC 0.18 μm BiCMOS process. The measured phase noise of-119.92dBc/Hz at 1MHz offset frequency from 2.65 GHz carrier while power consuming 2.0mW from a 0.8V supply. Tuning range of VCO is 0.75 GHz, from 2.66 GHz to 3.41 GHz, while the control voltage was tuned from 0V to 2V. The VCO occupies a chip area of 941.22×625.2μm2 and calculated a figure of merit of-185.35 dBc/Hz. © 2017 IEEE.","Class-C VCO; CMOS; dynamic body bias; phase noise","Bias voltage; CMOS integrated circuits; MOSFET devices; Phase noise; Switching; Threshold voltage; Variable frequency oscillators; Bi-CMOS process; Control voltages; Dynamic biasing; Dynamic body bias; Figure of merits; Offset frequencies; Power consuming; Switching transistor; C (programming language)",2-s2.0-85027187761
"Postolache O., Lourenco F., Dias Pereira J.M., Girao P.S.","Serious game for physical rehabilitation: Measuring the effectiveness of virtual and real training environments",2017,"I2MTC 2017 - 2017 IEEE International Instrumentation and Measurement Technology Conference, Proceedings",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019261771&doi=10.1109%2fI2MTC.2017.7969978&partnerID=40&md5=60df0f4afa87570b6707fedcce50a9a9","Recent advances in low-cost natural user interfaces such as Microsoft Kinect and Leap Motion controller allow the Virtual Reality implementation of 3D serious games for, posture, upper limb and lower limb rehabilitation purposes. However, it is very important to compare the results obtained by the users that train in virtual and real environments. This paper presents a virtual reality serious game for upper limb rehabilitation using a natural user interface expressed by Leap Motion controller. One of the developed virtual reality serious game for rehabilitation is converted to a real scenario with the same elements and rules and the same aims of physical rehabilitation. In order to extract appropriate information from the serious game based on real objects a RFID technology was used together with software components developed in LabVIEW. The evaluation of hand muscles' activity during the training session is based on the usage of thermography that permits to measure in an unobtrusive way the distribution of the temperature on the hands' level. Based on analysis of thermographic images obtained before and after serious game practice, the level of activity of specific muscles associated with training for virtual and real scenario is extracted. Experimental results that are also included in the paper underline the effectiveness of the proposed method for the comparison of the training in virtual and real scenarios. © 2017 IEEE.","Leap motion controller; Natural user interface; RFID; Serious game; Thermography","Biological organs; Computer programming languages; Controllers; E-learning; Motion control; Muscle; Neuromuscular rehabilitation; Radio frequency identification (RFID); Thermography (imaging); Thermography (temperature measurement); User interfaces; Virtual reality; Microsoft kinect; Motion controller; Natural user interfaces; Physical rehabilitation; Real environments; Software component; Training sessions; Upper-limb rehabilitation; Serious games",2-s2.0-85019261771
"Andrich C., Ihlow A., Kotterman W., Beuster N., Del Galdo G.","Using software defined radios for baseband phase measurement and frequency standard calibration",2017,"I2MTC 2017 - 2017 IEEE International Instrumentation and Measurement Technology Conference, Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026740040&doi=10.1109%2fI2MTC.2017.7969657&partnerID=40&md5=0e4ac0627c1d7b86c0dd9299cc4671ba","We devise a novel phase and time error measurement technique for 10 MHz and 1 PPS reference signals, based on Software Defined Radios (SDR) and Digital Signal Processing (DSP). The proposed measurement setup allows us to employ two synchronized type N210 Universal Software Radio Peripheral (USRP) devices with LFRX daughterboards to realize an economically priced and easy-to-use quad-channel measurement setup. Our real-time C++ DSP software is based on the USRP Hardware Driver and enables flexible long-term measurements with verified sub-nanosecond precision. We demonstrate our intended use case, the calibration of two off-the-shelf rubidium standards (SRS FS725) against each other, using their RS 232 interface. By means of two 120 hour long-term measurements with a power cycle and cold start in between, we verify it is possible to reproducibly maintain a relative drift of ±5 parts-per-trillion, which is an order of magnitude better than specified by the FS725 data sheet. Additionally, we investigate the influence of the ambient temperature on short-term stability. © 2017 IEEE.",,"C++ (programming language); Calibration; Computer software; Digital signal processing; Frequency standards; Phase measurement; Radio; Radio communication; Radio receivers; Signal processing; Channel measurements; Digital signal processing (DSP); Error measurement techniques; Long-term measurements; Short term stability; Software-defined radios; Standard calibration; Universal software radio peripherals (USRP); Software radio",2-s2.0-85026740040
"Oppermann J., Sommer L., Koch A.","SpExSim: assessing kernel suitability for C-based high-level hardware synthesis",2017,"Journal of Supercomputing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021840060&doi=10.1007%2fs11227-017-2101-z&partnerID=40&md5=71d972df93073f6ac66b664247e02f21","We present SpExSim, a software tool for quickly surveying legacy code bases for kernels that could be accelerated by FPGA-based compute units. We specifically aim for low development effort by considering the use of C-based high-level hardware synthesis, instead of complex manual hardware designs. SpExSim not only exploits the spatially distributed model of computation commonly used on FPGAs, but can also model the effect of two different microarchitectures commonly used in C-to-hardware compilers, including pipelined architectures with modulo scheduling. The estimations have been validated against actual hardware generated by two current HLS tools. © 2017 Springer Science+Business Media, LLC","Estimation; FPGA; Hardware acceleration; High-level synthesis; Legacy code; Reconfigurable computing","Computer hardware; Estimation; Field programmable gate arrays (FPGA); Hardware; High level synthesis; Reconfigurable architectures; Hardware acceleration; High-level hardware synthesis; Legacy code; Micro architectures; Modulo scheduling; Pipelined architecture; Reconfigurable computing; Spatially distributed modeling; C (programming language)",2-s2.0-85021840060
"Burnett A.W., Parkes A.J.","Exploring the landscape of the space of heuristics for local search in SAT",2017,"2017 IEEE Congress on Evolutionary Computation, CEC 2017 - Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027850696&doi=10.1109%2fCEC.2017.7969611&partnerID=40&md5=a777e98171cffb11bc5083aa1dbc7e8a","Local search is a powerful technique on many combinatorial optimisation problems. However, the effectiveness of local search methods will often depend strongly on the details of the heuristics used within them. There are many potential heuristics, and so finding good ones is in itself a challenging search problem. A natural method to search for effective heuristics is to represent the heuristic as a small program and then apply evolutionary methods, such as genetic programming. However, the search within the space of heuristics is not well understood, and in particular little is known of the associated search landscapes. In this paper, we consider the domain of propositional satisfiability (SAT), and a generic class of local search methods called 'WalkSAT'. We give a language for generating the heuristics; using this we generated over three million heuristics, in a systematic manner, and evaluated their associated fitness values. We then use this data set as the basis for an initial analysis of the landscape of the space of heuristics. We give evidence that the heuristic landscape exhibits clustering. We also consider local search on the space of heuristics and show that it can perform quite well, and could complement genetic programming methods on that space. © 2017 IEEE.",,,2-s2.0-85027850696
"Busson A.J.G., De Damasceno A.L.B., De Azevedo R.G.A., De Salles Soares Neto C., De Sousa Lima T., Colcher S.","A hypervideo model for learning objects",2017,"HT 2017 - Proceedings of the 28th ACM Conference on Hypertext and Social Media",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026395468&doi=10.1145%2f3078714.3078739&partnerID=40&md5=67324d9f5c3bb56803722df3fa5e8d56","Learning Objects (LOs) are entities that can be used, reused, or referred during the teaching process. They are commonly embedded into documents that establish spatial and temporal relationships on their contents. Hypervideos LOs allow students to individualize their learning experience with non-linear browsing mechanisms and content adaptation. This paper presents a survey of features for a set of documents representing such LOs as well as desirable aspects that should be expressed during the authoring phase. Also, this paper presents a conceptual model that fits such requirements. The model is implemented by SceneSync, a domain specific language focused on the synchronization and temporal behavior of LOs. As a result of the work, we present a set of LOs specified in SceneSync and a discussion about the identified features, which confirm the expressiveness and applicability of the model. © 2017 ACM.","Hypervideos; Learning Objects; SceneSync","Computer programming languages; Hypertext systems; Social networking (online); Content adaptation; Domain specific languages; Hypervideos; Learning experiences; Learning objects; SceneSync; Temporal behavior; Temporal relationships; Education",2-s2.0-85026395468
"da Silva M.P., Obelheiro R.R., Koslovski G.P.","Adaptive Remus: adaptive checkpointing for Xen-based virtual machine replication",2017,"International Journal of Parallel, Emergent and Distributed Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961393656&doi=10.1080%2f17445760.2016.1162302&partnerID=40&md5=f877920c8e8f834ac73027b073f33df8","With the ever increasing dependence on computers and networks, many systems are required to be continuously available in order to fulfil their mission. Virtualization technology enables high availability to be offered in a convenient, cost-effective manner: with the encapsulation provided by virtual machines (VMs), entire systems can be replicated transparently in software, obviating the need for expensive fault-tolerant hardware. Remus is a VM replication mechanism for the Xen hypervisor that provides high availability despite crash failures. Replication is performed by checkpointing the VM at fixed intervals. However, there is an antagonism between processing and communication regarding the optimal checkpoint interval: while longer intervals benefit processor-intensive applications, shorter intervals favour network-intensive applications. Thus, any chosen interval may not always be suitable for the hosted applications, limiting Remus usage in many scenarios. This work introduces Adaptive Remus, a proposal for adaptive checkpointing in Remus that dynamically adjusts the replication frequency according to the characteristics of running applications. Experimental results indicate that our proposal improves performance for applications that require both processing and communication, without harming applications that use only one type of resource. © 2016 Informa UK Limited, trading as Taylor & Francis Group.","checkpointing; primary-backup; Remus; Replication; virtual machines; Xen","Cost effectiveness; Check pointing; Primary-backup; Remus; Replication; Virtual machines; Java programming language",2-s2.0-84961393656
"Samsonov S.V., d'Oreye N.","Multidimensional Small Baseline Subset (MSBAS) for Two-Dimensional Deformation Analysis: Case Study Mexico City",2017,"Canadian Journal of Remote Sensing",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025117230&doi=10.1080%2f07038992.2017.1344926&partnerID=40&md5=bed4c47955869b34ba5eaa06d2d4a1d8","Time series of ground deformation are used to describe motion produced by various natural and anthropocentric processes, such as earthquakes, volcanic eruptions, landslides, subsidence due to resource exploitation, and uplift due to fluid injection. Presented here, the multidimensional small baseline subset (MSBAS) technique simultaneously processes multiple ascending and descending DInSAR datasets and produces 2-D, horizontal east-west and vertical, deformation time series with combined temporal resolution over overlapped area. The set of linear equations that comprises MSBAS is usually rank deficient and is solved in the least-square sense by applying the singular value decomposition (SVD) and the zero-, first-, or second-order Tikhonov regularization. The MSBAS source code is written in C++ and is linked to the linear algebra package (LAPACK) library that provides SVD support. For demonstration of capabilities, MSBAS is used to compute 2-D deformation time series of Mexico City by simultaneously processing ascending and descending RADARSAT-2 data acquired during October 2008–December 2012. This area is known to subside due to excessive groundwater extraction that produces pore water pressure drop and compaction of highly compressible clays. During the studied period we observed subsidence with rates over 35 cm/year and horizontal motion of up to 5 cm/year. The MSBAS software can be downloaded from http://insar.ca/. © 2017, Copyright © Crown copyright.",,"C++ (programming language); Deformation; Groundwater; Linear algebra; Linear equations; Subsidence; Time series; Volcanoes; Deformation analysis; Deformation time-series; Groundwater extraction; Linear algebra package; Pore-water pressures; Small baseline subsets; Temporal resolution; Tikhonov regularization; Singular value decomposition",2-s2.0-85025117230
"Girard L.-C., Pingault J.-B., Doyle O., Falissard B., Tremblay R.E.","Expressive language and prosocial behaviour in early childhood: Longitudinal associations in the UK Millennium Cohort Study",2017,"European Journal of Developmental Psychology",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84980034356&doi=10.1080%2f17405629.2016.1215300&partnerID=40&md5=2644ff7150149ecb57a3972a8724240e","Background: Early childhood is a crucial period for language development and building social skills. While distinct, these two processes may impact upon each other. Aims: The current study aimed to identify the directional associations between expressive language ability and prosocial behaviour between three and five years of age. Methods: Participants included 14, 004 children and their families enrolled in the UK Millennium Cohort Study. Children’s expressive language and prosocial behaviour were assessed at three and five years of age utilizing standardized assessments and parent reports. Cross-lagged models were used for data analysis. Results: Better expressive language at three years was associated with increased prosocial behaviour by five years. No support for the inverse direction of association was found. Conclusions: Children’s early ability to effectively express themselves with others may help in building better social relationships by entry into formal schooling. Programming efforts that are tailored towards enhancing positive behavioural growth and social skills in the toddler years are likely to be effective when expressive language is also a targeted component of the toddler’s skill development. © 2016 Informa UK Limited, trading as Taylor & Francis Group.","early childhood; expressive language ability; Millennium Cohort Study; Prosocial behaviour",,2-s2.0-84980034356
"Fraccaroli E., Piccolboni L., Fummi F.","A homogeneous framework for AMS languages instrumentation, abstraction and simulation",2017,"Proceedings of the European Test Workshop",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026898753&doi=10.1109%2fETS.2017.7968212&partnerID=40&md5=4085ad5231245e17627dcdb1697b8692","In the last years an inversion of trend has brought new interest to the analog domain. Its integration within modern digital designs has led to the birth of the so called Analog and Mixed-Signal (AMS) systems. Functional safety assessment of such systems must be evaluated by instrumenting both the analog and digital parts. Such an activity can be simplified if these parts can be considered as an unique layer. Based on such an idea, this work brings them to a common ground by unifying the description language. Such a process is performed through settled procedures that abstract the AMS description to a common abstraction level (behavioral) and to a homogeneous high-level language (C++). This provides a speedup of two orders of magnitude in the fault simulation of an AMS platform. © 2017 IEEE.","analog and mixed-signal; digital; fault coverage; Homogeneous fault injection; safety","Abstracting; Accident prevention; Computer programming languages; Fault detection; High level languages; Abstraction level; Analog and mixed signals; Description languages; digital; Fault coverages; Fault injection; Functional Safety; Orders of magnitude; C++ (programming language)",2-s2.0-85026898753
"Williams G., Mahmoud A.","Copper: Bringing Flexible Components to the.NET Framework",2017,"Proceedings - 2017 IEEE/ACM 1st International Workshop on Establishing the Community-Wide Infrastructure for Architecture-Based Software Engineering, ECASE 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027452256&doi=10.1109%2fECASE.2017.1&partnerID=40&md5=dcb38c2213fdc5c9929c7e514023d541","Component-oriented programming languages(COPLs) bridge the gap between architecture descriptionlanguages (ADLs) and general purpose programming languages. COPLs emphasize designing software systems out of reusablecomponents which are connected by communication ports. These ports facilitate the design of highly modular softwarearchitecture. The flexibility of a component-based system, however, is partly dependent on the variety of ports andconnections that are available. More port and connectionfeatures enable system architects to design more loosely coupledand reusable software components. This paper introduces aprototype language extension to C#, called Copper, which addscomponent-oriented programming features to the developer'srepertoire. Copper is based on the Mono C# compiler, andprovides convenient syntax for connecting incompatible ports, connecting ports to multiple senders, embedding ports statically, and connecting ports to non-component services. Copper'sbackward compatibility with C# permits existing C# code to beincrementally refactored into a component-oriented style. © 2017 IEEE.","Architecture; Component-oriented Programming","Architecture; Computer software reusability; Software engineering; Communication ports; Component based systems; Component oriented programming; Designing softwares; Flexible components; General-purpose programming language; Language extensions; Reusable software components; Copper",2-s2.0-85027452256
"Krijt F., Jiracek Z., Bures T., Hnetynka P., Gerostathopoulos I.","Intelligent Ensembles - A Declarative Group Description Language and Java Framework",2017,"Proceedings - 2017 IEEE/ACM 12th International Symposium on Software Engineering for Adaptive and Self-Managing Systems, SEAMS 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027161702&doi=10.1109%2fSEAMS.2017.17&partnerID=40&md5=94db754d8cc818c0e042f16402aa6709","Smart cyber-physical systems (sCPS) is a growing research field focused on scenarios such as smart cities or smart mobility, where autonomous components are deployed in a physical environment, and are expected to cooperate with one another, as well as with humans. As these systems typically operate in a highly uncertain and dynamically changing environment, being able to cooperate and adapt in groups to cope with various (possibly unanticipated) situations becomes a crucial and challenging task. In this artifact, we respond to this challenge by presenting the Intelligent Ensembles framework, consisting of a high-level declarative language for describing dynamic cooperation groups, and a Java runtime library for automatically forming groups that best satisfy the given specification. The framework provides dynamic architecture adaptation (i.e., forming groups of components and exchanging data between them) based on the state of components and situation in their environment. Further, the framework can be used as a first step of a group-wise adaptation (i.e., identifying components that are to negotiate and coordinate in an adaptation). The framework is built on top of the Z3 SMT solver and the Eclipse Modelling Framework. © 2017 IEEE.","adaptive architecture; autonomic systems; distributed cooperation; ensemble-based component system; group-wise adaptation; smart cyber-physical systems","Cyber Physical System; Dynamics; Embedded systems; High level languages; Memory architecture; Network function virtualization; Smart city; Software engineering; Adaptive architecture; Autonomic Systems; Component systems; Distributed cooperation; group-wise adaptation; Java programming language",2-s2.0-85027161702
"Bae S., Park J., Ryu S.","Partition-based coverage metrics and type-guided search in concolic testing for JavaScript applications",2017,"Proceedings - 2017 IEEE/ACM 5th International FME Workshop on Formal Methods in Software Engineering, FormaliSE 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027435693&doi=10.1109%2fFormaliSE.2017.10&partnerID=40&md5=9b76ff233aa00ee69d56644ac84f789b","JavaScript extends its uses from client-side web applications to mobile applications, but testing JavaScript applications is not yet satisfactory. Researchers have not spent much attention on testing JavaScript programs, and existing coverage metrics and testing mechanisms for C and Java may not be applicable to JavaScript because of its extremely dynamic semantics without any compile-time checks. Because, in JavaScript, any variable may have any kinds of types during evaluation, and because varying types change program execution flows, testing JavaScript programs requires more cases to cover different execution flows. Thus, test cases with 100% coverage levels in terms of the existing coverage metrics for statically typed languages may miss faults in JavaScript. Moreover, existing search strategies for statically typed languages may not exercise increased test requirements by dynamic languages effectively. In this paper, we identify JavaScript characteristics that make thorough testing of JavaScript programs more difficult than testing C and Java programs. To address such characteristics, we propose new partition-based coverage metrics that expose implicit execution flows using varying types. To generate test cases satisfying the coverage metrics effectively, we develop type-guided search strategies for concolic testing using program analysis results. We evaluate the new coverage metrics and search strategies for concolic testing with open-source web applications, and the preliminary experimental results show that their practical uses in JavaScript testing are promising. © 2017 IEEE.",,"Computer programming; Computer software; Formal methods; High level languages; Open source software; Semantics; Software engineering; Software testing; Concolic testing; Coverage metrics; Dynamic languages; JavaScript programs; Mobile applications; Search strategies; Test requirements; Testing mechanism; C (programming language)",2-s2.0-85027435693
"Murr F., Mauerer W.","McFSM: Globally taming complex systems",2017,"Proceeding - 2017 IEEE/ACM 3rd International Workshop on Software Engineering for Smart Cyber-Physical Systems, SEsCPS 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027437179&doi=10.1109%2fSEsCPS.2017.7&partnerID=40&md5=1cf3f9d3ac708476b943316127b5fd4a","Industrial computing devices, in particular cyber-physical, real-time andsafety-critical systems, focus on reacting to external events and the need tocooperate with other devices to create a functional system. They are oftenimplemented with languages that focus on a simple, local description of how acomponent reacts to external input data and stimuli. Despite the trend inmodern software architectures to structure systems into largely independentcomponents, the remaining interdependencies still create rich behaviouraldynamics even for small systems. Standard and industrial programming approachesdo usually not model or extensively describe the global properties of an entiresystem. Although a large number of approaches to solve this dilemma have beensuggested, it remains a hard and error-prone task to implement systems withcomplex interdependencies correctly. We introduce multiple coupled finite state machines (McFSMs), a novelmechanism that allows us to model and manage such interdependencies. It isbased on a consistent, well-structured and simple global description. A soundtheoretical foundation is provided, and associated tools allow us to generateefficient low-level code in various programming languages using model-driventechniques. We also present a domain specific language to express McFSMs andtheir connections to other systems, to model their dynamic behaviour, and toinvestigate their efficiency and correctness at compile-time. © 2017 IEEE.","Automata; Combined automata; Complex systems; Composite systems; Cyber-physical systems; Model-driven development; Systems description; Systems engineering","Automata theory; Computer programming languages; Cyber Physical System; Embedded systems; Large scale systems; Problem oriented languages; Software engineering; Systems engineering; Automata; Combined automata; Domain specific languages; Dynamic behaviours; Functional systems; Industrial computing; Model driven development; Systems description; Real time systems",2-s2.0-85027437179
"Trindade R.P.F., Orfanó T.S., Ferreira K.A.M., Wanner E.F.","The Dance of Classes - A Stochastic Model for Software Structure Evolution",2017,"International Workshop on Emerging Trends in Software Metrics, WETSoM",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026862547&doi=10.1109%2fWETSoM.2017.5&partnerID=40&md5=94ec333e613b06984159563b35c5e202","In this study, we investigate software structure evolution and growth. We represent software structure by means of a generic macro-topology called Little House, which models the dependencies among classes of object-oriented software systems. We, then, define a stochastic model to predict the way software architectures evolve. The model estimates how the classes of object-oriented programs get connected one to another along the evolution of the systems. To define the model, we analyzed data from 81 versions of six Java based projects. We analyzed each pair of sequential versions, for each project, in order to depict a pattern of software structure evolution based on Little House. To evaluate the model, we performed two experiments: one with the data used to derive the model, and another with data of 35 releases, in total, of four open-source Java project. In both experiments, we found a very low rate of error for the application of the proposed model. The evaluation of the model suggests it is able to predict how a software structure will evolve. © 2017 IEEE.","code history comprehension; complex networks; software evolution; software structure; stochastic model","Complex networks; Java programming language; Open source software; Stochastic models; Stochastic systems; code history comprehension; Low rates; Model estimates; Object-oriented program; Object-oriented software systems; Open sources; Software Evolution; Software structures; Object oriented programming",2-s2.0-85026862547
"Scripcariu L., Mǎtǎsaru P.-D.","Complex approach in telecommunication engineering education: Develop engineering skills by a team project",2017,"MATEC Web of Conferences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023607062&doi=10.1051%2fmatecconf%2f201711208003&partnerID=40&md5=9a056d662e48103765dcb38da56855e0","This paper provides an overview of the educational process of telecommunication engineering students by presenting the preparation of a team project focused on information security. Our educational approach combines basic knowledge such as mathematics with specialized engineering notions and various skills. The project theme is to design, implement and test an encryption algorithm. Students are provided with online courses, specific software programs and Internet access. They have to choose an encryption algorithm, to study its details and to write the script of the encryption algorithm in MATLAB program. The algorithm is implemented in C/C++ programming language and tested. Finally, a concurrent team tries to break the algorithm by finding the decryption key. It is an interactive approach which combines various education methods including gaming concepts. The covered topics provide students professional outcomes such as knowledge and use of specific mathematical tools and software environments (C/C ++ programming languages, MATLAB), abilities to design, develop, implement and test software algorithms. The project also provides transversal outcomes such as ability to team work, skills of computer use and information technology and capability to take responsibilities. Creativity is also encouraged by extending the algorithm to other encryption key lengths than the usual ones. © 2017 The Authors, published by EDP Sciences.",,"C++ (programming language); Education; Engineering education; Manufacture; MATLAB; Security of data; Software testing; Students; Educational approach; Educational process; Encryption algorithms; Engineering skills; Interactive approach; Mathematical tools; Software environments; Telecommunication engineering; Cryptography",2-s2.0-85023607062
"Idjis K., Ourbih-Tari M., Baghdali-Ourbih L.","Variance reduction in M/M/1 retrial queues using refined descriptive sampling",2017,"Communications in Statistics: Simulation and Computation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014529644&doi=10.1080%2f03610918.2016.1140778&partnerID=40&md5=05cf76bd4c533ba780205b4d28f5ed4d","This article simulates the stationary M/M/1 retrial queues using Simple Random Sampling (SRS) and Refined Descriptive Sampling (RDS) to generate input variables. We design and realize a software under Linux using C language which establishes the performance measures of the M/M/1 retrial queues, computes their relative deviation and their variance reductions in order to compare both sampling methods. The simulation results demonstrate that RDS produces more accurate and efficient point estimates of the true parameters and can significantly improves performance sometimes by an important variance reduction factor in the M/M/1retrial queue compared to SRS. © 2017 Taylor & Francis Group, LLC.","Queues; Retrial Monte Carlo; Sampling; Simulation; Variance reduction","C (programming language); Computer operating systems; Monte Carlo methods; Sampling; Descriptive sampling; Performance measure; Queues; Relative deviations; Sampling method; Simple random sampling; Simulation; Variance reductions; Queueing theory",2-s2.0-85014529644
"Shimizu K., Yamaguchi T., Nakai T., Ueda T., Kobayashi N., Boyer B.","A trusted approach to design a network monitor",2017,"Proceedings - 2017 IEEE/ACM 5th International FME Workshop on Formal Methods in Software Engineering, FormaliSE 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027466497&doi=10.1109%2fFormaliSE.2017.3&partnerID=40&md5=b9c95b0e8b5e7bd3bf4ec716a19b4bf4","Cyber security has been an issue in industrial control systems (ICS) of critical infrastructures. Existing security measures for ordinary enterprise systems are hardly applicable to ICS because they have different requirements. In contrast, whitelisting network monitors attract wide attention as a security measure for ICS that meets the demand for availability during a long lifetime, as well as to exploit the static nature of system configuration. Once defined, the whitelist of allowed packets can detect ever-increasing new attacks without requiring any update. This paper presents a framework for developing reliable and secure whitelisting network monitors for ICS networks such as used in SCADA systems. The proposed approach relies on a model-based development combined with formal verification and proof steps, such that the normal communication model can be verified, the whitelist can be automatically generated from the model and the soundness of the network monitor program can be proven. © 2017 IEEE.","C code generation; Cyber security; Model-based design; Network monitoring; SCADA; Simulink; Verification; Whitelisting","C (programming language); Formal methods; Formal verification; Intelligent control; SCADA systems; Software engineering; Verification; C codes; Cyber security; Model- based designs; Network Monitoring; SCADA; Simulink; Whitelisting; Network security",2-s2.0-85027466497
"Liu X., Zhang J., Guo T., Yang G., Tu T.","Effect of different materials on metal foam magnetorheological fluid damper",2017,"Soft Materials",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020741965&doi=10.1080%2f1539445X.2017.1329153&partnerID=40&md5=2b54d456cb60b4eddc85d5e095936939","The paper mainly investigates the effect of different materials on metal foam magnetorheological (MR) fluid damper by simulation and experiment. The damper, with MR fluid stored in the metal foam, has the advantages of low cost and long lifetime. First the software ANSYS FEM is used to simulate the magnetic field in the different metal foams, and the magnetic flux density in the working gap and magnetic field distribution are obtained in the different excited current. Besides, a testing system, including the metal foam MR fluid damper, DC motor with speed controller, force sensor with amplifier, DAQ card and PC with LabVIEW software, is built to investigate its performance. Next the relationship between damping force and current is also obtained by changing the excited currents. As the applied samples, metal foam Ni (nickel) and metal foam Cu (cuprum) are selected to store MR fluid. The results show that, compared to metal foam Cu, metal foam Ni can provide a larger magnetic flux density. And the experimental results show that metal foam Cu MR fluid damper has a larger damping force, which implies that, for the metal foam MR dampers, the extracted volume of magnetorheological fluid (MR fluid) has a greater influence than the magnetic flux density. © 2017 Taylor & Francis Group, LLC.","Damping force; magnetic field simulation; magnetic flux density; magnetorheological fluid damper; metal foam","Computer programming languages; Damping; DC motors; Electric machine control; Foams; Magnetic fields; Magnetic flux; Magnetism; Magnetorheological fluids; Metal testing; Metal working; Nickel; Software testing; Damping forces; Lab-view softwares; Magnetic field distribution; Magnetic field simulation; Magnetorheological fluid damper; Metal foams; Speed controller; Testing systems; Metals",2-s2.0-85020741965
"Panichella A., Molina U.R.","Java unit testing tool competition - Fifth round",2017,"Proceedings - 2017 IEEE/ACM 10th International Workshop on Search-Based Software Testing, SBST 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027439534&doi=10.1109%2fSBST.2017.7&partnerID=40&md5=e57e47989c42c826222f40c3fc466d45","After four successful JUnit tool competitions, we report on the achievements of a new Java Unit Testing Tool Competition. This 5th contest introduces statistical analyses in the benchmark infrastructure and has been validated with significance against the results of the previous 4th edition. Overall, the competition evaluates four automated JUnit testing tools taking as baseline human written test cases from real projects. The paper details the modifications performed to the methodology and provides full results of the competition. © 2017 IEEE.","Automated unit testing; Benchmark; Java; Mutation testing; Statistical analysis; Tool competition","Benchmarking; Java programming language; Statistical methods; Automated unit testing; Java; Mutation testing; Test case; Testing tools; Unit testing; Software testing",2-s2.0-85027439534
"Nelson M.A., Anderson B.P., Cai H.","Selection Methods and Procedure for Evaluation of LED Roadway Luminaires",2017,"LEUKOS - Journal of Illuminating Engineering Society of North America",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85002244084&doi=10.1080%2f15502724.2016.1256782&partnerID=40&md5=8f2419ac948b16c8cdf7623c153abf70","This study evaluated the existing light emitting diode (LED) roadway luminaires available in the U.S. market for field implementation to displace the high intensity discharge (HID) luminaires. Four methods were proposed for selection of qualified LED luminaires, including, in order, specification evaluation, computer simulation, implementation cost-effectiveness analysis, and field mock-up tests. A total of 148 LED roadway luminaires were collected and evaluated over 28 factors. Those luminaires were tested in computer simulations for optimized roadway layout and preferred lighting performance in compliance with the codes and standards. An approved products list (APL) of 88 luminaires was selected for potential field implementation. A lighting economics calculator was developed for cost-effectiveness analysis on their implementation. Guidance on the field mock-up tests was also proposed. The present study then evaluated the selection methods in an assumed replacement project of 1000 luminaires in Kansas. In this project, the APL was shortened to a short list of 13 standard pole and three high-mast LED luminaires based on their efficacy, year released, availability of manufacturer sales representatives, and simple payback time period for roadway implementation. The short-list products were compared to their equivalent existing HID luminaire counterparts for cost–benefit analysis that revealed significant 12-year life cycle cost savings with an average payback time period less than 3 years. The present study then evaluated the four selection methods in their effective procedure for future uses in the selection of qualified replacement LED luminaires with expected adjustments and timely update. Copyright © Illuminating Engineering Society.","computer simulation; lighting economics; roadway lighting","APL (programming language); Computer simulation; Cost benefit analysis; Cost effectiveness; Costs; Life cycle; Lighting; Mockups; Regulatory compliance; Codes and standards; Cost effectiveness analysis; Field implementation; High intensity discharges; Implementation cost; Replacement projects; Roadway lighting; Sales representatives; Light emitting diodes",2-s2.0-85002244084
"Sinha D., Sharma D.","Iterated local transitivity model for signed social networks",2017,"Applicable Algebra in Engineering, Communications and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021813286&doi=10.1007%2fs00200-017-0333-z&partnerID=40&md5=49193124f40f357dc71f1feef5a55f62","In this paper, we generalize the iterated local transitivity (ILT) model for online social networks for signed networks. Signed networks focus on the type of relations (friendship or enmity) between the vertices (members of online social networks). The ILT model for signed networks provide an insight into how networks react to the addition of clone vertex. In this model, at each time step t and for already existing vertex x, a new vertex (clone) (Formula presented.) is added which joins to x and neighbors of x. The sign of new edge (Formula presented.) neighborhood of x is defined by calculating the number of positive and negative neighbors of x. We also discuss properties such as balance and clusterability, sign-compatibility and C-sign-compatibility. © 2017 Springer-Verlag GmbH Germany","Algorithm; Balance; Clusterability; Local transitivity model; Marked signed graph; Neighborhood; Sign-compatibility; Signed social network; Social network","Algorithms; Balancing; C (programming language); Cloning; Clusterability; Neighborhood; On-line social networks; Sign-compatibility; Signed graphs; Signed networks; Time step; Social networking (online)",2-s2.0-85021813286
"Tahara Y., Ohsuga A., Honiden S.","Formal Verification of Dynamic Evolution Processes of UML Models Using Aspects",2017,"Proceedings - 2017 IEEE/ACM 12th International Symposium on Software Engineering for Adaptive and Self-Managing Systems, SEAMS 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027185337&doi=10.1109%2fSEAMS.2017.4&partnerID=40&md5=d061e805d5cf0cd24121f145c121b61f","The rapidly changing requirements and environments of system operation demand dynamic changes to systems with as short downtimes as possible. System availability is a relevant feature for such dynamic changes, which we call dynamic evolution. One of the most promising approaches to highly available dynamic evolution is dynamic aspect weaving, a technique of aspect-oriented programming technology. It enables part of a program to dynamically change without stopping its execution. Another feature relevant to dynamic evolution is the assurance of correctness of evolution. However, this is not easy for dynamic evolution, mainly because the evolution process is rather complicated. Formal modeling and verification (specifically, model checking) are other promising technologies. Many researchers have proposed various approaches to model and verify dynamic evolution. However, highly available dynamic evolution processes tend to be too complicated to verify with existing techniques because such processes need to be simultaneously controlled with system functionalities and the operations for evolution that include dynamic aspect weaving. We propose a formal verification tool called CAMPer that analyzes the unified modeling language (UML) models of dynamic evolution processes that consist of multiple steps with sophisticated control that includes dynamic aspect weaving. This tool is able to verify functional requirements for the processes that would be complicated to attain high availability. Our approach uses the Maude specification language to systematically express dynamic evolution and dynamic aspect weaving by using reflection. We also used a model checker for Maude to verify the evolution processes. We conducted experiments using an example Tele Assistance System (TAS) to demonstrate the advantages of our approach and evaluate its feasibility. © 2017 IEEE.","algebraic specifications; aspect-oriented software development; CAM (Component Aspect Model); dynamic aspect weaving; dynamic evolution; formal verification; Maude; model checking; reflection; UML","Aspect oriented programming; Availability; Computer simulation languages; Computer systems programming; Formal methods; Formal verification; Modeling languages; Reflection; Software design; Software engineering; Specification languages; Specifications; Textile industry; Unified Modeling Language; Verification; Weaving; Algebraic specifications; Aspect model; Aspect oriented software development; Dynamic aspects; Dynamic evolution; Maude; Model checking",2-s2.0-85027185337
"Lachgar M., Abdali A.","Modeling and generating native code for cross-platform mobile applications using DSL",2017,"Intelligent Automation and Soft Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992061428&doi=10.1080%2f10798587.2016.1239392&partnerID=40&md5=e3d8120a934dda28760321fd3d219e84","A few years ago, mobile development technology has been quickly growing, and it has also been an emerging trend. Furthermore, different smartphones use diverse operating systems, which support different programming languages. Therefore, developing native applications individually for each platform turns out to be an arduous and expensive effort to undertake. The concept of “write once, deploy everywhere”, will massively reduce the cost of creating, maintaining and versioning mobile applications. In this paper, we suggest the automatic MDA (Model Driven Architecture) transformations to develop embedded heterogeneous software. Then we present our works in terms of defining a new target platform independent model (PIM), and the transformation rules for generating native code for such applications. Thus, we singled out domain specific language (DSL), in order to increase the productivity of software engineers, in terms of abstracting low-level boilerplate code. © 2016 TSI® Press.","automatic code generation; domain specific language; mobile development; Model driven architecture; templates",,2-s2.0-84992061428
"Campinhos J., Seco J.C., Cunha J.","Type-Safe Evolution of Web Services",2017,"Proceedings - 2017 IEEE/ACM 2nd International Workshop on Variability and Complexity in Software Design, VACE 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027163930&doi=10.1109%2fVACE.2017.6&partnerID=40&md5=8209994d57ebbeed05b5dc13a70b56f2","Applications based on micro or web services have had significant growth due to the exponential increase in the use of mobile devices. However, using such kind of loosely coupled interfaces provides almost no guarantees to the developer in terms of evolution. Changes to service interfaces can be introduced at any moment, which may cause the system to fail due to mismatches between communicating parts. In this paper, we present a programming model that allows the development of web service applications, server end-points and their clients, in such a way that the evolution of services' implementation does not cause the disruption of the client. Our approach is based on a type based code slicing technique that ensures that each version only refers to type compatible code, of the same version or of a compatible version, and that each client request is redirected to the most recent type compatible version implemented by the server. We abstract the notion of version and parametrize type compatibility on the relation between versions. The relation between versions is tagged with compatibility levels, so to capture the common conventions used in software development. Our implementation allows multiple versions of a service to be deployed simultaneously, while reusing code between versions in a type safe way. We describe a prototype framework, based on code transformation, for server-side JavaScript code, and using Flow as verification tool. © 2017 IEEE.","API evolution; JavaScript; type safe; web services","Codes (symbols); Cosine transforms; High level languages; Software design; Websites; API evolution; Code transformation; Compatibility levels; Exponential increase; Javascript; Service interfaces; type safe; Web service applications; Web services",2-s2.0-85027163930
"Nightingale A., Antunes R., Alpi E., Bursteinas B., Gonzales L., Liu W., Luo J., Qi G., Turner E., Martin M.","The Proteins API: Accessing key integrated protein and genome information",2017,"Nucleic Acids Research",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023206532&doi=10.1093%2fnar%2fgkx237&partnerID=40&md5=ca4bd955134336c15985678b259fc646","The Proteins API provides searching and programmatic access to protein and associated genomics data such as curated protein sequence positional annotations from UniProtKB, as well as mapped variation and proteomics data from large scale data sources (LSS). Using the coordinates service, researchers are able to retrieve the genomic sequence coordinates for proteins in UniProtKB. This, the LSS genomics and proteomics data for UniProt proteins is programmatically only available through this service. A Swagger UI has been implemented to provide documentation, an interface for users, with little or no programming experience, to â € talk' to the services to quickly and easily formulate queries with the services and obtain dynamically generated source code for popular programming languages, such as Java, Perl, Python and Ruby. Search results are returned as standard JSON, XML or GFF data objects. The Proteins API is a scalable, reliable, fast, easy to use RESTful services that provides a broad protein information resource for users to ask questions based upon their field of expertise and allowing them to gain an integrated overview of protein annotations available to aid their knowledge gain on proteins in biological processes. © The Author(s) 2017. Published by Oxford University Press on behalf of Nucleic Acids Research.",,"amino acid sequence; Article; computer interface; documentation; gene sequence; genome analysis; information retrieval; phenotype; priority journal; protein analysis; proteomics; software",2-s2.0-85023206532
"Dieste O., Fonseca E.R.C., Raura G., Rodríguez P.","Professionals Are Not Superman: Failures beyond Motivation in Software Experiments",2017,"Proceedings - 2017 IEEE/ACM 5th International Workshop on Conducting Empirical Studies in Industry, CESI 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027134711&doi=10.1109%2fCESI.2017.8&partnerID=40&md5=523e56832716f7c4eeb194ce49e9c7dd","Background: Industry experiments are typically associated with higher external validity compared to academic experiments. However, when conducting industry experiments, dropouts and incomplete experimental tasks are quite common, which is unusual in academic experiments. To the best of our knowledge, this phenomenon has not been reported in the literature. Aim: Identify the circumstances that explain why some experimental subjects exhibit poor or null participation during experimental sessions. Method: An industry experiment with experienced programmers at the Universidad de las Fuerzas Armadas ESPE of Ecuador was performed. Several post hoc analyses of the experimental data revealed relationships that could explain the subjects' behavior. Results: A high percentage of older experienced programmers did not perform meaningful work in their task assignments, even though they were present during the entire experiment. Longer overall (i.e., not only programing) experience and poor knowledge of the programming language and integrated development environment have a negative influence in the degree of task completion as well. Conclusions: Several experienced professionals were found to live a two, mixed-factors reality: old age and technological lapse. This negatively influenced (to a greater or lesser extent, depending on the person) attitudes regarding performance of activities that differ from daily professional work. © 2017 IEEE.","Experiments; Old age; Performance; Professionals; Students; Technological lapse","Students; Experimental subjects; External validities; Integrated development environment; Meaningful works; Old age; Performance; Professionals; Technological lapse; Experiments",2-s2.0-85027134711
"Sagendorf J.M., Berman H.M., Rohs R.","DNAproDB: An interactive tool for structural analysis of DNA-protein complexes",2017,"Nucleic Acids Research",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023174344&doi=10.1093%2fnar%2fgkx272&partnerID=40&md5=3e410eeed569f745c116b6b1bd839cce","Many biological processes are mediated by complex interactions between DNA and proteins. Transcription factors, various polymerases, nucleases and histones recognize and bind DNA with different levels of binding specificity. To understand the physical mechanisms that allow proteins to recognize DNA and achieve their biological functions, it is important to analyze structures of DNA-protein complexes in detail. DNAproDB is a web-based interactive tool designed to help researchers study these complexes. DNAproDB provides an automated structure-processing pipeline that extracts structural features from DNA-protein complexes. The extracted features are organized in structured data files, which are easily parsed with any programming language or viewed in a browser. We processed a large number of DNA-protein complexes retrieved from the Protein Data Bank and created the DNAproDB database to store this data. Users can search the database by combining features of the DNA, protein or DNA-protein interactions at the interface. Additionally, users can upload their own structures for processing privately and securely. DNAproDB provides several interactive and customizable tools for creating visualizations of the DNA-protein interface at different levels of abstraction that can be exported as high quality figures. © The Author(s) 2017. Published by Oxford University Press on behalf of Nucleic Acids Research.",,,2-s2.0-85023174344
"Mackinney E.","More than a name: Spanish-speaking youth articulating bilingual identities",2017,"Bilingual Research Journal",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025805287&doi=10.1080%2f15235882.2017.1342716&partnerID=40&md5=311758652007284429638a50b6c8c9fd","This article explores how middle school Latina/o youth articulate their intersecting language identities as part of larger institutional and transnational experiences. Students navigated the multiple labels ascribed to them as members of the English for Speakers of Other Languages (ESOL) program as they shaped perspectives of their bilingual selves. Findings from this ethnographic case study show how youth resisted the institutional identities that the ESOL label reified and how students repositioned themselves as language balancers, border crossers, and marketable bilinguals. Implications for educational language policy and programming are provided. © 2017 the National Association for Bilingual Education.",,,2-s2.0-85025805287
"Tyuryumina E.Y., Neznanov A.A.","On consolidated predictive model of the natural history of breast cancer: Primary tumor and secondary metastases in patients with lymph nodes metastases",2017,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025469824&doi=10.1145%2f3079452.3079461&partnerID=40&md5=0f7dbf32cff1a67848129bfb2f16b392","This paper is devoted to mathematical modelling of the progression and stages of breast cancer. The âǍIJ Consolidated mathematical growth Model of primary tumor (PT) and secondary distant metastases (MTS) in patients with lymph nodes MTS (Stage III)"" (CoM-III) is proposed as a new research tool. The CoM-III rests on an exponential tumor growth model and consists of a system of determinate nonlinear and linear equations. The CoM-III describes correctly primary tumor growth (parameter T) and distant metastases growth (parameter M, parameter N). The CoM-III model and predictive software: a) detect different growth periods of primary tumor and distant metastases in patients with lymph nodes MTS; b) make forecast of the period of the distant metastases appearance in patients with lymph nodes MTS; c) have higher average prediction accuracy than the other tools; d) can improve forecasts on survival of breast cancer and facilitate optimisation of diagnostic tests. The CoM-III enables us, for the first time, to predict the whole natural history of PT and secondary distant MTS growth of patients with/without lymph nodes MTS on each stage relying only on PT sizes. © 2017 Association for Computing Machinery.","Breast cancer; Exponential model; Lymph nodes metastases; Mathematical modelling; Predictor; Primary tumor; Secondary metastases; Survival","Body fluids; C (programming language); Diseases; Forecasting; Mathematical models; Nonlinear equations; Pathology; Software testing; Tumors; Breast Cancer; Exponential models; Lymph node; Predictor; Secondary metastases; Survival; Diagnosis",2-s2.0-85025469824
"Hu W., Zhan J.","Mixed-language programming with Fortran and VB.NET",2017,"Zhongshan Daxue Xuebao/Acta Scientiarum Natralium Universitatis Sunyatseni",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028881345&doi=10.13471%2fj.cnki.acta.snus.2017.04.001&partnerID=40&md5=25bfa756155887d24b3e4a6192003bcc","Fortran language has high execution efficiency. It is widely used in the field of numerical calculation. And it has accumulated a lot of high-efficient and reliable source codes. For example, The Microsoft IMSL-Fortran Library can give powerful mathematical and statistical analysis. VB.NET is a fully object-oriented language. Compared against VB language, VB.NET is quicker and easier to develop a more powerful Windows program. Mixed-language programming of VB.NET calling Fortran through dynamic link library mode is studied. It gives the corresponding calling method for variable, string, array, structure and structure array. Also the typical examples are offered. It provides technical support for the development of software with both advantages of Fortran and VB.NET: high execution efficiency and quick and easy development ability. Copyright © 2017 by the Chinese Medical Association.","Fortran; Mixed-language programming; VB.NET",,2-s2.0-85028881345
"Feng A., Gardner M., Feng W.-C.","Parallel programming with pictures is a Snap!",2017,"Journal of Parallel and Distributed Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013935727&doi=10.1016%2fj.jpdc.2017.01.018&partnerID=40&md5=a8e9487625f9872eae01ad983e6da7e7","For decades, computing speeds seemingly doubled every 24 months by increasing the processor clock speed, thus giving software a “free ride” to better performance. This free ride, however, effectively ended by the mid-2000s. With clock speeds having plateaued and computational horsepower instead increasing due to increasing the number of cores per processor, the vision for parallel computing, which started more than 40 years ago, is a revolution that has now (ubiquitously) arrived. In addition to traditional supercomputing clusters, parallel computing with multiple cores can be found in desktops, laptops, and even mobile smartphones. This ubiquitous parallelism in hardware presents a major challenge: the difficulty in easily extracting parallel performance via current software abstractions. Consequently, this paper presents an approach that reduces the learning curve to parallel programming by introducing such concepts into a visual (but currently sequential) programming language called Snap!, which was inspired by MIT's Scratch project. Furthermore, our proposed visual abstractions can automatically generate parallel code for the end user to run in parallel on a variety of platforms from personal computing devices to supercomputers. Ultimately, this work seeks to increase parallel programming literacy so that users, whether novice or experienced, may leverage a world of ubiquitous parallelism to enhance productivity in all walks of life, including the sciences, engineering, commerce, and liberal arts. © 2017 Elsevier Inc.","Block-based programming; Computer science education; Explicit parallel computing; Languages for PDC and HPC; Parallel computational patterns; Pedagogical tools; Programming environments; Visual programming","Abstracting; Clocks; Computer programming; Computer programming languages; Education computing; Humanities computing; Parallel programming; Personal computing; Supercomputers; Ubiquitous computing; Visual languages; Block based; Computational patterns; Computer Science Education; Pedagogical tools; Programming environment; Visual programming; Parallel processing systems",2-s2.0-85013935727
"Lamy J.-B.","Owlready: Ontology-oriented programming in Python with automatic classification and high level constructs for biomedical ontologies",2017,"Artificial Intelligence in Medicine",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028840221&doi=10.1016%2fj.artmed.2017.07.002&partnerID=40&md5=99d955e4d0feb2f63ba59aa53841f2e7","Objective Ontologies are widely used in the biomedical domain. While many tools exist for the edition, alignment or evaluation of ontologies, few solutions have been proposed for ontology programming interface, i.e. for accessing and modifying an ontology within a programming language. Existing query languages (such as SPARQL) and APIs (such as OWLAPI) are not as easy-to-use as object programming languages are. Moreover, they provide few solutions to difficulties encountered with biomedical ontologies. Our objective was to design a tool for accessing easily the entities of an OWL ontology, with high-level constructs helping with biomedical ontologies. Methods From our experience on medical ontologies, we identified two difficulties: (1) many entities are represented by classes (rather than individuals), but the existing tools do not permit manipulating classes as easily as individuals, (2) ontologies rely on the open-world assumption, whereas the medical reasoning must consider only evidence-based medical knowledge as true. We designed a Python module for ontology-oriented programming. It allows access to the entities of an OWL ontology as if they were objects in the programming language. We propose a simple high-level syntax for managing classes and the associated “role-filler” constraints. We also propose an algorithm for performing local closed world reasoning in simple situations. Results We developed Owlready, a Python module for a high-level access to OWL ontologies. The paper describes the architecture and the syntax of the module version 2. It details how we integrated the OWL ontology model with the Python object model. The paper provides examples based on Gene Ontology (GO). We also demonstrate the interest of Owlready in a use case focused on the automatic comparison of the contraindications of several drugs. This use case illustrates the use of the specific syntax proposed for manipulating classes and for performing local closed world reasoning. Conclusion Owlready has been successfully used in a medical research project. It has been published as Open-Source software and then used by many other researchers. Future developments will focus on the support of vagueness and additional non-monotonic reasoning feature, and automatic dialog box generation. © 2017 Elsevier B.V.","Automatic classification; Biomedical ontology; Local closed world reasoning; Ontology-oriented programming; OWL; Semantic web","Application programming interfaces (API); Birds; Computer programming; Computer programming languages; High level languages; Open source software; Open systems; Query languages; Semantic Web; Software engineering; Syntactics; Automatic classification; Biomedical domain; Biomedical ontologies; Local closed world reasoning; Medical reasonings; Non-monotonic reasoning; Open world assumption; Programming interface; Ontology; Article; automation; classification algorithm; computer language; evidence based medicine; gene ontology; knowledge base; medical ontology; priority journal",2-s2.0-85028840221
"Zhang H., Lin F.","Characterizing causal action theories and their implementations in answer set programming",2017,"Artificial Intelligence",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015792804&doi=10.1016%2fj.artint.2017.02.008&partnerID=40&md5=5be9d1b6e13da5abd221875473a1d92e","We consider a simple language for writing causal action theories, and postulate several properties for the state transition models of these theories. We then consider some possible embeddings of these causal action theories in some other action formalisms, and their implementations in logic programs with answer set semantics. In particular, we propose to consider what we call permissible translations from these causal action theories to logic programs. We identify two sets of properties, and prove that for each set, there is only one permissible translation, under strong equivalence, that can satisfy all properties in the set. We also show that these two sets of conditions are minimal in that removing any condition from each of them will result in multiple permissible mappings. Furthermore, as it turns out, for one set, the unique permissible translation is essentially the same as Balduccini and Gelfond's translation from Gelfond and Lifschitz's action language B to logic programs. For the other, it is essentially the same as Lifschitz and Turner's translation from the action language C to logic programs. This work provides a new perspective on understanding, evaluating and comparing action languages by using sets of properties instead of examples. The results in this paper provide a characterization of two representative action languages B and C in terms of permissible mappings from our causal action theories to logic programs. It will be interesting to see if other action languages can be similarly characterized, and whether new action formalisms can be defined using different sets of properties. © 2017 Elsevier B.V.","Action languages; Causal action theories; Logic programming","Computer circuits; Computer programming; Logic programming; Mapping; Program translators; Semantics; Translation (languages); Action language; Action theory; Answer set programming; Answer set semantics; Embeddings; Logic programs; State transition models; C (programming language)",2-s2.0-85015792804
"Le T., Son T.C., Pontelli E., Yeoh W.","Solving distributed constraint optimization problems using logic programming",2017,"Theory and Practice of Logic Programming",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021278760&doi=10.1017%2fS147106841700014X&partnerID=40&md5=2c4122440fc2108492de4627b6710576","This paper explores the use of Answer Set Programming (ASP) in solving Distributed Constraint Optimization Problems (DCOPs). The paper provides the following novel contributions: (1) it shows how one can formulate DCOPs as logic programs; (2) it introduces ASP-DPOP, the first DCOP algorithm that is based on logic programming; (3) it experimentally shows that ASP-DPOP can be up to two orders of magnitude faster than DPOP (its imperative programming counterpart) as well as solve some problems that DPOP fails to solve, due to memory limitations; and (4) it demonstrates the applicability of ASP in a wide array of multi-agent problems currently modeled as DCOPs. Copyright © 2017 Cambridge University Press.","ASP; DCOP; DPOP; logic programming","Computer circuits; Computer programming; Computer programming languages; Constrained optimization; Logic programming; Optimization; Answer set programming; DCOP; Distributed constraint optimizations; DPOP; Imperative programming; Logic programs; Multi-agent problems; Orders of magnitude; Problem solving",2-s2.0-85021278760
"Pellerin J., Botella A., Bonneau F., Mazuyer A., Chauvin B., Lévy B., Caumon G.","RINGMesh: A programming library for developing mesh-based geomodeling applications",2017,"Computers and Geosciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015422772&doi=10.1016%2fj.cageo.2017.03.005&partnerID=40&md5=3a18833fd616cda92cfabc6d1c92c046","RINGMesh is a C++ open-source programming library for manipulating discretized geological models. It is designed to ease the development of applications and workflows that use discretized 3D models. It is neither a geomodeler, nor a meshing software. RINGMesh implements functionalities to read discretized surface-based or volumetric structural models and to check their validity. The models can be then exported in various file formats. RINGMesh provides data structures to represent geological structural models, either defined by their discretized boundary surfaces, and/or by discretized volumes. A programming interface allows to develop of new geomodeling methods, and to plug in external software. The goal of RINGMesh is to help researchers to focus on the implementation of their specific method rather than on tedious tasks common to many applications. The documented code is open-source and distributed under the modified BSD license. It is available at https://www.ring-team.org/index.php/software/ringmesh. © 2017 Elsevier Ltd","BRep; C++; Geology; Open-source; Structural model; Unstructured meshes","C++ (programming language); Cesium; Computer programming; Geology; Open systems; Structural geology; Three dimensional computer graphics; Boundary surfaces; BRep; Open sources; Open-source programming; Programming interface; Programming library; Structural modeling; Unstructured meshes; Open source software; data set; geology; numerical model; software; three-dimensional modeling",2-s2.0-85015422772
"Bogaerts S.A.","One step at a time: Parallelism in an introductory programming course",2017,"Journal of Parallel and Distributed Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009826121&doi=10.1016%2fj.jpdc.2016.12.024&partnerID=40&md5=71f4a847e203c7b652806886627b530b","By introducing parallelism in introductory programming courses, all computer science students can receive a basic understanding of this crucial topic. Such an early introduction, however, has many challenges. This paper first presents a fall 2013 comparison of two Computer Science I (CS1) sections, leading to a conclusion emphasizing the importance of devoting sufficient time to a sufficiently small set of parallelism topics. Six additional CS1 sections are then considered, offered from spring 2014 through spring 2016 by three different instructors. Five of these removed coverage of Java thread programming due to challenges found in fall 2013, only to show measurably reduced effectiveness of the parallelism module. Thus a new thread programming integration strategy is presented, as done in spring 2016. This strategy includes active out-of-class activities that split the disparate challenges of Java thread programming into distinct exercises. Results demonstrate improved student interest and learning. © 2017 Elsevier Inc.","CS1; Education; Introductory programming; Java; Multi-threading; Parallelism","Computer programming; Education; Computer science students; Integration strategy; Introductory programming; Introductory programming course; Java; Java thread; Multi-threading; Parallelism; Java programming language",2-s2.0-85009826121
"Wang L.-G., Song H.-Q., Bi L., Chen X.","Optimization of Open Pit Multielement Ore Blending Based on Goal Programming",2017,"Dongbei Daxue Xuebao/Journal of Northeastern University",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030645981&doi=10.12068%2fj.issn.1005-3026.2017.07.025&partnerID=40&md5=372e7727c47281d44b6debd3460060c2","On account of long-time ore blending with multi elements & ore dropping points, and rough ore blending upon the uneven grade distribution of blast heaps, so an open pit automation ore blending method based on goal programming was put forward. Blasting heap was discretized into a number of cell block, then based on the sampling data of rock powder, the accurate prediction the grade of blasting heaps was realized by use of the geostatistics method. Considering the priority of ore blending and taking the minimum grade deviation as the objective function, the optimization model of the open pit ore blending based on goal programming was established. Using C++ language programming and solving the model by the LPSlove, then output the open pit ore blending optimization scheme and enclose the areas of mining area automatically. The method is applied to a large polymetallic open pit in Inner Mongolia, resulting in a quick ore blending computation time, a good ore blending result within the range of allowable error, and a high-efficiency of ore blending. © 2017, Editorial Department of Journal of Northeastern University. All right reserved.","Accurate prediction; Automatic enclosing; Goal programming; Multielement; Ore blending","Blasting; Blending; C++ (programming language); Linear programming; Multiobjective optimization; Optimization; Ores; Accurate prediction; Automatic enclosing; Goal programming; Multi-element; Ore blending; Open pit mining",2-s2.0-85030645981
"Hundt C., Schlarb M., Schmidt B.","SAUCE: A web application for interactive teaching and learning of parallel programming",2017,"Journal of Parallel and Distributed Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011101723&doi=10.1016%2fj.jpdc.2016.12.028&partnerID=40&md5=8409725a5c66a493ebf948558c3971e3","Prevalent hardware trends towards parallel architectures and algorithms create a growing demand for graduate students familiar with the programming of concurrent software. However, learning parallel programming is challenging due to complex communication and memory access patterns as well as the avoidance of common pitfalls such as dead-locks and race conditions. Hence, the learning process has to be supported by adequate software solutions in order to enable future computer scientists and engineers to write robust and efficient code. This paper discusses a selection of well-known parallel algorithms based on C++11 threads, OpenMP, MPI, and CUDA that can be interactively embedded in an HPC or parallel computing lecture using a unified framework for the automated evaluation of source code—namely the “System for AUtomated Code Evaluation” (SAUCE). SAUCE is free software licensed under AGPL-3.0 and can be downloaded at https://github.com/moschlar/SAUCE free of charge. © 2017 Elsevier Inc.","Black box testing; Parallel programming; Teaching and learning; Web application","Application programming interfaces (API); Black-box testing; Codes (symbols); HTTP; Memory architecture; Parallel architectures; Parallel programming; Students; Teaching; Automated evaluation; Computer scientists; Concurrent software; Graduate students; Memory access patterns; Teaching and learning; Unified framework; WEB application; C (programming language)",2-s2.0-85011101723
"Lu X.-J., Liu L., Jia H.-P., Feng X.-B., Wu C.-G.","ParaC: A Domain Programming Framework of Image Processing on GPU Accelerators",2017,"Ruan Jian Xue Bao/Journal of Software",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027960329&doi=10.13328%2fj.cnki.jos.005241&partnerID=40&md5=36a60f381af1032fed93cb18bfc9baf1","Image processing algorithms take the GPU accelerators as the main speedup solution. However, the performance difference between a naïve implementation and a highly optimized one on the same GPU accelerators is frequently an order of magnitude or more. The GPGPU platform features complicated hardware architecture characteristics, such as the large amount of multi-dimension and multi -level threads and the deep hierarchy memory system, while the different part of the latter features different capacity, bandwidth, latency and access authority. Additionally, image processing algorithms have complex operations, border data accessing rules and memory accessing patterns. Therefore, parallel execution model of tasks, organization of threads and parallel tasks to device mapping not only have big impact on the scalability, scheduling, communication and synchronization, but also affect the efficiency of memory accessing. In a word, the algorithm optimization methods on GPGPU platforms are difficult, complicated and less efficient. This paper proposes a domain specific language, ParaC, which can provide high level program semantics through the new language extensions. It obtains the applications' software characteristics, such as the operation information, the data reuse among parallel tasks and the memory access patterns, along with hardware platform information and the domain pre-knowledge driven optimization mechanism, to generate high performance GPGPU code automatically. The source-to-source compiler is then used to output the standard OpenCL programs. Experiment results on test cases show that ParaC automatically generated optimization version has gained 3.22 speedup compared to the hand-tuned version for the best case, while the number of lines of the former is just 1.2% to 39.68% of the latter. © Copyright 2017, Institute of Software, the Chinese Academy of Sciences. All rights reserved.","Compiler optimization, source-to-source translation; Domain specific language; GPGPU accelerator; Image processing","Application programs; Automatic test pattern generation; Computer architecture; Computer programming languages; Computer software reusability; Graphics processing unit; Hardware; High level languages; Memory architecture; Optimization; Problem oriented languages; Program compilers; Program processors; Semantics; Algorithm optimization; Automatically generated; Communication and synchronizations; Domain specific languages; Image processing algorithm; Memory access patterns; Software characteristic; Source-to-source translations; Image processing",2-s2.0-85027960329
"Mayer P.","A taxonomy of cross-language linking mechanisms in open source frameworks",2017,"Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006716883&doi=10.1007%2fs00607-016-0528-3&partnerID=40&md5=0bc25cd64750872ae33313ea31ba96c6","Non-trivial software systems are written using multiple programming languages. While the logic of a system is encoded using one or several general-purpose languages, more specialized parts of the systems are realized using domain-specific languages for aspects such as the user interface, configuration mechanisms, querying of databases, or support for internationalization. To bind all of these different parts together, the artifacts in individual languages are connected by using cross-language links which address artifacts across language boundaries. Many different ways for specifying and using such links have been conceived, and developers have to adhere to the concrete rules mandated by the runtime, framework or library which later performs the link resolution. In this paper, we present a taxonomy of the mechanisms of encoding cross-language linking in well-known open source frameworks from a developers perspective, which shows the choices that have been made and the options available in practice. We describe the process we followed, which is based in part on a survey of language combinations on GitHub and a survey of professional developers, list the dimensions and characteristics of our taxonomy in full, show the classifications of 22 frameworks and mechanisms, four of which are described in detail, and discuss the impact of the choices on application developers. © 2016, Springer-Verlag Wien.","Classification; Cross-language linking; DSLs; Frameworks; GPLs; Multi-language development; Open-source software; Polyglot programming; Software maintenance; Taxonomy","Classification (of information); Computer programming languages; Computer software; Computer software maintenance; Linguistics; Open systems; Problem oriented languages; Software engineering; Surveys; Taxonomies; User interfaces; Cross languages; DSLs; Frameworks; GPLs; Multi languages; Polyglot programming; Open source software",2-s2.0-85006716883
"Gurin I.A., Lavrov V.V., Spirin N.A., Nikitin A.G.","Web technology in automated information and modeling systems for metallurgical processes",2017,"Steel in Translation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032300816&doi=10.3103%2fS096709121707004X&partnerID=40&md5=871acfdd92ee1d1fd7fb2d023bbc8a2f","The software in information systems used by engineering personnel at metallurgical enterprises is considered. Such software operates automated workstations, support systems for decision making, information and modeling systems, expert systems, and so on. Typically, the software takes the form of desktop applications written in high-level programming languages (Visual C#, Visual Basic, etc.). The analysis of technological information from the enterprise’s database-management server entails the solution of programming problems, systems of differential equations, and mathematical-physics problems, for example. Such problems are unsolvable by the standard general-purpose programming languages. Therefore, the development of information and modeling systems requires access to outside software, such as Microsoft Excel and MATLAB. Interaction with Microsoft Excel depends on COM Interop technology, which requires the installation of Microsoft Office on each client computer. Interaction with MATLAB requires the preliminary assembly of a library in MATLAB Compiler and its connection to the program. MATLAB Runtime freeware must be installed on the client computer. However, desktop applications using Windows Forms do not meet the requirements of industrial information systems in terms of functionality, accessibility, and cross-platform compatibility. Accordingly, new technologies must be found for the creation of information systems. The best approach is the construction of web applications based on the ASP.NET MVC framework, which permits the transfer of mathematical libraries and modules for interaction with Microsoft Excel and MATLAB from Windows Forms, without modification. The structure of the web application employed in the development of information-system software is described. The web page employed has the following functional regions: the logo and title of the current page, the session-status menu, the function menu, group operations, notifications, and the working area. © 2017, Allerton Press, Inc.","architecture; ASP.NET MVC; design; information systems; mathematical library; MATLAB Runtime; software; web programming; Windows Forms","Application programs; Architecture; Computer software; Decision making; Design; Differential equations; Expert systems; High level languages; Information systems; MATLAB; Metallurgy; Problem oriented languages; Problem solving; Program compilers; Visual BASIC; Visual languages; Web services; Websites; ASP.NEt; General-purpose programming language; High-level programming language; Industrial information systems; Mathematical library; Runtimes; Systems of differential equations; Web programming; Information management",2-s2.0-85032300816
"Scanniello G., Risi M., Tramontana P., Romano S.","Fixing faults in C and Java Source Code: Abbreviated vs. full-word identifier names",2017,"ACM Transactions on Software Engineering and Methodology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027103491&doi=10.1145%2f3104029&partnerID=40&md5=6e2c54b58fc57ff82423b9b8aac92d06","We carried out a family of controlled experiments to investigate whether the use of abbreviated identifier names, with respect to full-word identifier names, affects fault fixing in C and Java source code. This family consists of an original (or baseline) controlled experiment and three replications.We involved 100 participants with different backgrounds and experiences in total. Overall results suggested that there is no difference in terms of effort, effectiveness, and efficiency to fix faults, when source code contains either only abbreviated or only full-word identifier names. We also conducted a qualitative study to understand the values, beliefs, and assumptions that inform and shape fault fixing when identifier names are either abbreviated or full-word.We involved in this qualitative study six professional developers with 1-3 years of work experience. A number of insights emerged from this qualitative study and can be considered a useful complement to the quantitative results from our family of experiments. One of the most interesting insights is that developers, when working on source code with abbreviated identifier names, adopt a more methodical approach to identify and fix faults by extending their focus point and only in a few cases do they expand abbreviated identifiers. © 2017 ACM.",,"Codes (symbols); Computer programming languages; Java programming language; Controlled experiment; Focus points; Java source codes; Methodical approach; Qualitative study; Quantitative result; Source codes; Work experience; C (programming language)",2-s2.0-85027103491
"Korkmaz Ö., Çakir R., Özden M.Y.","A validity and reliability study of the computational thinking scales (CTS)",2017,"Computers in Human Behavior",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015675979&doi=10.1016%2fj.chb.2017.01.005&partnerID=40&md5=647ed2fbdc8d725318d8440c5d1ec7f9","It is possible to define Computational Thinking briefly as having the knowledge, skill and attitudes necessary to be able to use the computers in the solution of the life problems for production purposes. In this study, a scale has been developed for the purpose of determining the levels of computational thinking skills (CTS) of the students. CTS is a five-point likert type scale and consists of 29 items that could be collected under five factors. The study group of this work consists of 726 students educated at the levels of associate degree and undergraduate degree with formal education in Amasya University for the first application. For the second application 580 students who were educated in pedagogical formation education via distance education in Amasya University. The validity and reliability of the scale have been studied by conducting exploratory factor analysis, confirmatory factor analysis, item distinctiveness analyses, internal consistency coefficients and constancy analyses. As a result of the conducted analyses, it has been concluded that the scale is a valid and reliable measurement tool that could measure the computational thinking skills of the students. In addition; the digital age individuals are expected to have the computational thinking skill, and at what degree they have these skills, the revelation of whether the levels they have are sufficient or not are a requirement. Within this frame, it could be said that the scale could make significant contributions to the literature. © 2017 Elsevier Ltd","Computer-mediated communication; Pedagogical issues; Programming and programming languages; Teaching/learning strategies; Valuation methodologies","Computational methods; Computer programming; Computer programming languages; Distance education; Education; Factor analysis; Multivariant analysis; Reliability analysis; Teaching; Computational thinkings; Computer mediated communication; Confirmatory factor analysis; Exploratory factor analysis; Pedagogical issues; Programming and programming languages; Teaching/learning strategy; Undergraduate degrees; Students; computer language; confirmatory factor analysis; exploratory factor analysis; human; instrument validation; internal consistency; learning; Likert scale; major clinical study; skill; teaching; thinking; university; validity",2-s2.0-85015675979
"Clark D.B., Godat E., Olness F.I.","ManeParse: A Mathematica reader for Parton Distribution Functions",2017,"Computer Physics Communications",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016409437&doi=10.1016%2fj.cpc.2017.03.004&partnerID=40&md5=7ed92e32b7e451c6ff7b5617919c1ffa","Parton Distribution Functions (PDFs) are essential non-perturbative inputs for calculation of any observable with hadronic initial states. These PDFs are released by individual groups as discrete grids as a function of the Bjorken-x and energy scale Q. The LHAPDF project maintains a repository of PDFs from various groups in a new standardized LHAPDF6 format, additionally older formats such as the CTEQ PDS grid format are still in use. ManeParse is a package that provides access to PDFs within Mathematica to facilitate calculation and plotting. The program is self-contained so there are no external links to any FORTRAN, C or C++ programs. The package includes the option to use the built-in Mathematica interpolation or a custom cubic Lagrange interpolation routine which allows for flexibility in the extrapolation (particularly at small x-values). ManeParse is fast enough to enable simple calculations (involving even one or two integrations) in the Mathematica framework. Program summary Program Title: ManeParse Program Files doi: http://dx.doi.org/10.17632/knbsccggg4.1 Licensing provisions: MIT Programming language: Mathematica Nature of problem: PDFs are currently read and interpolated via a FORTRAN or C++ interface. No method exist to read the LHAPDF6 or CTEQ PDFs directly in Mathematica. Solution method: A Mathematica package reads in LHAPDF6 and CTEQ PDF files. The PDFs are parsed into a three-dimensional array in Bjorken-x, scattering energy Q, and parton flavor, and are stored in memory. Provided functions give access to the PDF, the PDF uncertainty, the PDF correlations, and the parton–parton Luminosities. The LHAPDF6 info files are converted from YAML format into Mathematica rules. © 2017 Elsevier B.V.","Hadron collider; Hadronic cross section; Mathematica; Parton Distribution Functions; PDF; PDF errors; PDFs; QCD","C++ (programming language); Computer software; FORTRAN (programming language); High level languages; Interpolation; Hadron colliders; Hadronic cross section; Mathematica; Parton distribution functions; PDFs; Distribution functions",2-s2.0-85016409437
"Maher M.J.","Contractibility for open global constraints",2017,"Theory and Practice of Logic Programming",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021275776&doi=10.1017%2fS1471068417000126&partnerID=40&md5=7c25e03052c05773303e95f41a6cacec","Open forms of global constraints allow the addition of new variables to an argument during the execution of a constraint program. Such forms are needed for difficult constraint programming problems, where problem construction and problem solving are interleaved, and fit naturally within constraint logic programming. However, in general, filtering that is sound for a global constraint can be unsound when the constraint is open. This paper provides a simple characterization, called contractibility, of the constraints, where filtering remains sound when the constraint is open. With this characterization, we can easily determine whether a constraint has this property or not. In the latter case, we can use it to derive a contractible approximation to the constraint. We demonstrate this work on both hard and soft constraints. In the process, we formulate two general classes of soft constraints. © 2017 Cambridge University Press.","KEYWORDS: Global constraints; open constraints; soft constraints","Computer programming; Constraint theory; Logic programming; Problem solving; Constraint Logic Programming; Constraint programming; Constraint programs; General class; Global constraints; Hard and soft constraints; open constraints; Soft constraint; Computer programming languages",2-s2.0-85021275776
"Ghorani M., Zahedi M.M.","Coding tree languages based on lattice-valued logic",2017,"Soft Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84956856539&doi=10.1007%2fs00500-016-2031-3&partnerID=40&md5=917893ecb92d6605ad98b284dc478e69","We consider tree automata based on complete residuated lattice-valued (for simplicity we write L-valued) logic. First, we define the concepts of response function and accessible states (with threshold c) of an L-valued tree automaton. Thereafter, we consider coding of trees and investigate the relation between response function on trees and their coding. Using the provided theorems, we give a pumping lemma for recognizable coding tree languages with threshold c. Moreover, we consider closure properties of recognizable coding tree languages. In this regard, we show that the class of recognizable coding tree languages with threshold c is closed under projection, intersection and union. © 2016, Springer-Verlag Berlin Heidelberg.","Closure property; Coding tree language; Lattice-valued tree automata; Pumping lemma","Automata theory; Codes (symbols); Computational linguistics; Computer circuits; Forestry; Reconfigurable hardware; Closure property; Coding of trees; Complete residuated lattices; Lattice valued logic; Pumping lemma; Response functions; Tree automata; Tree languages; C (programming language)",2-s2.0-84956856539
"Sant’Anna F., Ierusalimschy R., Rodriguez N., Rossetto S., Branco A.","The design and implementation of the synchronous language CÉU",2017,"ACM Transactions on Embedded Computing Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026513870&doi=10.1145%2f3035544&partnerID=40&md5=c3c9d21a87fbd3a619609691890912f8","CÉU is a synchronous language targeting soft real-time systems. It is inspired by Esterel and has a simple semantics with fine-grain control over program execution. CÉU uses an event-triggered notion of time that enables compile-time checks to detect conflicting concurrent statements, resulting in deterministic and concurrency-safe programs. We present the particularities of our design in comparison to Esterel, such as stack-based internal events, concurrency checks, safe integration with C, and first-class timers. We also present two implementation back ends: one aiming for resource efficiency and interoperability with C, and another as a virtual machine that allows remote reprogramming. © 2017 ACM","Concurrency; Determinism; Embedded systems; Esterel; Reactivity; Synchronous","Concurrency control; Embedded systems; Esters; Interactive computer systems; Reactivity (nuclear); Real time systems; Semantics; Concurrency; Design and implementations; Determinism; Esterel; Resource efficiencies; Soft real-time systems; Synchronous; Synchronous languages; C (programming language)",2-s2.0-85026513870
"Banbara M., Kaufmann B., Ostrowski M., Schaub T.","Clingcon: The next generation",2017,"Theory and Practice of Logic Programming",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021438955&doi=10.1017%2fS1471068417000138&partnerID=40&md5=5226ecb441785f6cc4ce77e279e8db76","We present the third generation of the constraint answer set system clingcon, combining Answer Set Programming (ASP) with finite domain constraint processing (CP). While its predecessors rely on a black-box approach to hybrid solving by integrating the CP solver gecode, the new clingcon system pursues a lazy approach using dedicated constraint propagators to extend propagation in the underlying ASP solver clasp. No extension is needed for parsing and grounding clingcon's hybrid modeling language since both can be accommodated by the new generic theory handling capabilities of the ASP grounder gringo. As a whole, clingcon 3 is thus an extension of the ASP system clingo 5, which itself relies on the grounder gringo and the solver clasp. The new approach of clingcon offers a seamless integration of CP propagation into ASP solving that benefits from the whole spectrum of clasp's reasoning modes, including, for instance, multi-shot solving and advanced optimization techniques. This is accomplished by a lazy approach that unfolds the representation of constraints and adds it to that of the logic program only when needed. Although the unfolding is usually dictated by the constraint propagators during solving, it can already be partially (or even totally) done during preprocessing. Moreover, clingcon's constraint preprocessing and propagation incorporate several well-established CP techniques that greatly improve its performance. We demonstrate this via an extensive empirical evaluation contrasting, first, the various techniques in the context of CSP solving and, second, the new clingcon system with other hybrid ASP systems. © 2017 Cambridge University Press.","Answer Set Programming (ASP); Constraint Answer Set Programming (CASP); Constraint Programming (CP); Sat Modulo Theories (SMT)","Computer programming; Computer simulation languages; Constraint theory; Logic programming; Modeling languages; Answer set programming; Constraint preprocessing; Constraint programming; Constraint propagators; Finite domain constraints; Hybrid modeling language; Optimization techniques; Sat modulo theories; Constraint satisfaction problems",2-s2.0-85021438955
"Cody-Kenny B., Fenton M., Ronayne A., Considine E., McGuire T., O'Neill M.","A search for improved performance in regular expressions",2017,"GECCO 2017 - Proceedings of the 2017 Genetic and Evolutionary Computation Conference",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026392686&doi=10.1145%2f3071178.3071196&partnerID=40&md5=c46940ee1b175908185e4b9676883bc3","The primary aim of automated performance improvement is to reduce the running time of programs while maintaining (or improving on) functionality. In this paper, Genetic Programming is used to find performance improvements in regular expressions for an array of target programs, representing the first application of automated software improvement for run-time performance in the Regular Expression language. This particular problem is interesting as there may be many possible alternative regular expressions which perform the same task while exhibiting subtle differences in performance. A benchmark suite of candidate regular expressions is proposed for improvement. We show that the application of Genetic Programming techniques can result in performance improvements in all cases. As we start evolution from a known good regular expression, diversity is critical in escaping the local optima ofthe seed expression. In order to understand diversity during evolution we compare an initial population consisting of only seed programs with a population initialised using a combination of a single seed individual with individuals generated using PI Grow and Ramped-half-and-half initialisation mechanisms. © 2017 ACM.","Genetic Programming; Performance; Regular Expressions","Application programs; Computer programming languages; Genetic algorithms; Pattern matching; Benchmark suites; Genetic programming technique; Initial population; Local optima; Performance; Regular expressions; Run-time performance; Running time; Genetic programming",2-s2.0-85026392686
"Balderas A., Berns A., Palomo-Duarte M., Dodero J.M., Ruiz-Rube I.","Retrieving objective indicators from student logs in virtual worlds",2017,"Journal of Information Technology Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020855904&doi=10.4018%2fJITR.2017070105&partnerID=40&md5=c985c1ee4f2d00ea79ce0991d48b04e0","Virtual Worlds (VWs) have been widely used to support learning processes. One main advantage is providing valuable data on student behaviour and interaction. Nonetheless, most platforms provide only limited access to student logs. Moreover, accessing logs usually requires technical skills most teachers do not have. In this context, the authors present a Domain Specific Language (DSL) designed to allow teachers to generate queries for retrieving valuable log information with a view to obtain evidence on learner behaviour and interaction; hence, to aid in the analysis of in-world behaviour and learning processes. Since this data is automatically retrieved, the teacher can easily run new queries to refine indicators or contrast hypotheses. The authors describe a case study carried out with undergraduate German language students using a VW-based video game. The results provide a set of indicators for analysing individual and group behaviour measuring student competence to communicate in the target language.. Copyright © 2017, IGI Global.","Assessment; Computer-Supported Foreign Language Learning; Domain Specific Language; Learning Analytics; Virtual Worlds","Computer programming languages; Education; Interactive computer graphics; Problem oriented languages; Teaching; Virtual reality; Assessment; Domain specific languages; Foreign language learning; Learning Analytics; Virtual worlds; Students",2-s2.0-85020855904
"Gerber F., Mösinger K., Furrer R.","Extending R packages to support 64-bit compiled code: An illustration with spam64 and GIMMS NDVI3g data",2017,"Computers and Geosciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013413976&doi=10.1016%2fj.cageo.2016.11.015&partnerID=40&md5=32d2d2d93cd3e70afb65504305e9d88d","Software packages for spatial data often implement a hybrid approach of interpreted and compiled programming languages. The compiled parts are usually written in C, C++, or Fortran, and are efficient in terms of computational speed and memory usage. Conversely, the interpreted part serves as a convenient user-interface and calls the compiled code for computationally demanding operations. The price paid for the user friendliness of the interpreted component is—besides performance—the limited access to low level and optimized code. An example of such a restriction is the 64-bit vector support of the widely used statistical language R. On the R side, users do not need to change existing code and may not even notice the extension. On the other hand, interfacing 64-bit compiled code efficiently is challenging. Since many R packages for spatial data could benefit from 64-bit vectors, we investigate strategies to efficiently pass 64-bit vectors to compiled languages. More precisely, we show how to simply extend existing R packages using the foreign function interface to seamlessly support 64-bit vectors. This extension is shown with the sparse matrix algebra R package spam. The new capabilities are illustrated with an example of GIMMS NDVI3g data featuring a parametric modeling approach for a non-stationary covariance matrix. © 2017 The Authors","Compactly supported covariance function; dotCall64; Foreign function interface; Huge dataset; Non-stationarity; Sparse matrix","Codes (symbols); Computer programming; Covariance matrix; Matrix algebra; User interfaces; Vectors; Covariance function; DotCall64; Foreign function interface; Huge dataset; Non-stationarities; Sparse matrices; C++ (programming language); data set; matrix; numerical model; software; spatial data; vector",2-s2.0-85013413976
"Balduccini M., Lierler Y.","Constraint answer set solver EZCSP and why integration schemas matter",2017,"Theory and Practice of Logic Programming",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021401248&doi=10.1017%2fS1471068417000102&partnerID=40&md5=9885bdb8827fb8b37a4d657b0a4adb65","Researchers in answer set programming and constraint programming have spent significant efforts in the development of hybrid languages and solving algorithms combining the strengths of these traditionally separate fields. These efforts resulted in a new research area: Constraint answer set programming. Constraint answer set programming languages and systems proved to be successful at providing declarative, yet efficient solutions to problems involving hybrid reasoning tasks. One of the main contributions of this paper is the first comprehensive account of the constraint answer set language and solver ezcsp, a mainstream representative of this research area that has been used in various successful applications. We also develop an extension of the transition systems proposed by Nieuwenhuis et al. in 2006 to capture Boolean satisfiability solvers. We use this extension to describe the ezcsp algorithm and prove formal claims about it. The design and algorithmic details behind ezcsp clearly demonstrate that the development of the hybrid systems of this kind is challenging. Many questions arise when one faces various design choices in an attempt to maximize system's benefits. One of the key decisions that a developer of a hybrid solver makes is settling on a particular integration schema within its implementation. Thus, another important contribution of this paper is a thorough case study based on ezcsp, focused on the various integration schemas that it provides. © 2017 Cambridge University Press.","Constraint Answer Set Programming; Knowledge Representation; Nonmonotonic Reasoning","Aluminum alloys; Computer programming; Constraint theory; Hybrid systems; Integration; Logic programming; Answer set programming; Boolean satisfiability; Constraint programming; Hybrid reasonings; Languages and systems; Non-monotonic reasoning; Solving algorithm; Transition system; Knowledge representation",2-s2.0-85021401248
"Böhnlein T., Kratsch S., Schaudt O.","Revenue maximization in stackelberg pricing games: Beyond the combinatorial setting",2017,"Leibniz International Proceedings in Informatics, LIPIcs",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027264584&doi=10.4230%2fLIPIcs.ICALP.2017.46&partnerID=40&md5=c2da002120e7d225f681424371a515a5","In a Stackelberg Pricing Game a distinguished player, the leader, chooses prices for a set of items, and the other players, the followers, each seeks to buy a minimum cost feasible subset of the items. The goal of the leader is to maximize her revenue, which is determined by the sold items and their prices. Most previously studied cases of such games can be captured by a combinatorial model where we have a base set of items, some with fixed prices, some priceable, and constraints on the subsets that are feasible for each follower. In this combinatorial setting, Briest et al. and Balcan et al. independently showed that the maximum revenue can be approximated to a factor of Hk ∼ log k, where k is the number of priceable items. Our results are twofold. First, we strongly generalize the model by letting the follower minimize any continuous function plus a linear term over any compact subset of ℝ ≤ 0 n; the coefficients (or prices) in the linear term are chosen by the leader and determine her revenue. In particular, this includes the fundamental case of linear programs. We give a tight lower bound on the revenue of the leader, generalizing the results of Briest et al. and Balcan et al. Besides, we prove that it is strongly NP-hard to decide whether the optimum revenue exceeds the lower bound by an arbitrarily small factor. Second, we study the parameterized complexity of computing the optimal revenue with respect to the number k of priceable items. In the combinatorial setting, given an efficient algorithm for optimal follower solutions, the maximum revenue can be found by enumerating the 2k subsets of priceable items and computing optimal prices via a result of Briest et al., giving time O(2k|I|c) where |I| is the input size. Our main result here is a W[1]-hardness proof for the case where the followers minimize a linear program, ruling out running time f(k)|I|c unless FPT = W[1] and ruling out time |I|o(k) under the Exponential-Time Hypothesis. © Toni Böhnlein, Stefan Kratsch, and Oliver Schaudt;.","Algorithmic pricing; Approximation algorithms; Parameterized complexity; Revenue maximization; Stackelberg games","Aluminum; Approximation algorithms; Automata theory; C (programming language); Computational complexity; Costs; Linear programming; Optimization; Parallel processing systems; Parameter estimation; Polynomials; Set theory; Algorithmic pricing; Combinatorial modeling; Continuous functions; Exponential time hypothesis; Parameterized complexity; Revenue maximization; Stackelberg Games; Strongly NP-hard; Economics",2-s2.0-85027264584
"Weber A.","Assembly lines 12: MIT robots teach other robots",2017,"Assembly",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025802060&partnerID=40&md5=2f6667a8cae4fd662da342f9c7c708e8","Engineers at the Massachusetts Institute of Technology (MIT) recently developed a system that aims to bridge the two techniques. C-LEARN allows people to teach robots a range of tasks simply by providing some information about how objects are typically manipulated and then showing the robot a single demo of the task. This enables users to teach robots skills that can be automatically transferred to other robots that have different ways of moving. By combining the intuitiveness of learning from demonstration with the precision of motion planning algorithms, this approach can help robots do new types of tasks that they haven't been able to learn before, like multistep assembly using both of their arms. With C-LEARN, the user first gives the robot a knowledge base of information on how to reach and grasp various objects that have different constraints. The operator then uses a 3D interface to show the robot a single demonstration of the specific task, which is represented by a sequence of relevant moments known as 'keyframes.' By matching these keyframes to the different situations in the knowledge base, the robot can automatically suggest motion plans for the operator to approve or edit as needed.",,"C (programming language); Knowledge based systems; Motion planning; Robots; 3D interface; Assembly line; Knowledge base; Learning from demonstration; Massachusetts Institute of Technology; Motion planning algorithms; Reach and grasp; Specific tasks; Robot programming",2-s2.0-85025802060
"Lin J., Milligan I., Wiebe J., Zhou A.","Warcbase: Scalable analytics infrastructure for exploring Web archives",2017,"Journal on Computing and Cultural Heritage",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026845396&doi=10.1145%2f3097570&partnerID=40&md5=9d2145293bd9e0edabe5269da5652c87","Web archiving initiatives around the world capture ephemeralWeb content to preserve our collective digital memory. However, unlocking the potential of Web archives for humanities scholars and social scientists requires a scalable analytics infrastructure to support exploration of captured content. We present Warcbase, an open-source Web archiving platform that aims to fill this need. Our platform takes advantage of modern open-source ""big data"" infrastructure, namely Hadoop, HBase, and Spark, that has been widely deployed in industry. Warcbase provides two main capabilities: support for temporal browsing and a domain-specific language that allows scholars to interrogate Web archives in several different ways. This work represents a collaboration between computer scientists and historians, where we have engaged in iterative codesign to build tools for scholars with no formal computer science training. To provide guidance, we propose a process model for scholarly interactions with Web archives that begins with a question and proceeds iteratively through four main steps: filter, analyze, aggregate, and visualize. We call this the FAAV cycle for short and illustrate with three prototypical case studies. This article presents the current state of the project and discusses future directions. © 2017 ACM.","Apache Hadoop; Apache HBase; Apache spark; ARC; Big data; WARC","Computer programming languages; Computer software; Problem oriented languages; Apache Hadoop; Apache HBase; Computer scientists; Domain specific languages; Process Modeling; Provide guidances; Social scientists; WARC; Big data",2-s2.0-85026845396
"Ghosh S., Suryanarayana P.","SPARC: Accurate and efficient finite-difference formulation and parallel implementation of Density Functional Theory: Extended systems",2017,"Computer Physics Communications",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015801718&doi=10.1016%2fj.cpc.2017.02.019&partnerID=40&md5=ecc0004848d93a7cf1bb71cd9cc90309","As the second component of SPARC (Simulation Package for Ab-initio Real-space Calculations), we present an accurate and efficient finite-difference formulation and parallel implementation of Density Functional Theory (DFT) for extended systems. Specifically, employing a local formulation of the electrostatics, the Chebyshev polynomial filtered self-consistent field iteration, and a reformulation of the non-local force component, we develop a finite-difference framework wherein both the energy and atomic forces can be efficiently calculated to within desired accuracies in DFT. We demonstrate using a wide variety of materials systems that SPARC achieves high convergence rates in energy and forces with respect to spatial discretization to reference plane-wave result; exponential convergence in energies and forces with respect to vacuum size for slabs and wires; energies and forces that are consistent and display negligible ‘egg-box’ effect; accurate properties of crystals, slabs, and wires; and negligible drift in molecular dynamics simulations. We also demonstrate that the weak and strong scaling behavior of SPARC is similar to well-established and optimized plane-wave implementations for systems consisting up to thousands of electrons, but with a significantly reduced prefactor. Overall, SPARC represents an attractive alternative to plane-wave codes for performing DFT simulations of extended systems. Program summary Program title: SPARC Catalogue identifier: AFBR_v1_0 Program summary URL:http://cpc.cs.qub.ac.uk/summaries/AFBR_v1_0.html Program obtainable from: CPC Program Library, Queen's University, Belfast, N. Ireland Licensing provisions: GNU GPL v3 No. of lines in distributed program, including test data, etc.: 93822 No. of bytes in distributed program, including test data, etc.: 1386659 Distribution format: tar.gz Programming language: C/C++. Computer: Any system with C/C++ compiler. Operating system: Linux. RAM: Problem dependent. Ranges from 80 GB to 800 GB for a system with 2500 electrons. Classification: 7.3. External routines: PETSc 3.5.3 (http://www.mcs.anl.gov/petsc), MKL 11.2 (https://software.intel.com/en-us/intel-mkl), and MVAPICH2 2.1 (http://mvapich.cse.ohio-state.edu/). Does the new version supersede the previous version?: Yes Nature of problem: Calculation of the static and dynamic properties of isolated and extended systems in the framework of Kohn–Sham Density Functional Theory (DFT). Solution method: High-order finite-difference discretization. Local reformulation of the electrostatics in terms of the electrostatic potential and pseudocharge densities. Application of Bloch-periodic and zero-Dirichlet boundary conditions on the orbitals in the direction of periodicity and vacuum, respectively. Application of periodic and Dirichlet boundary conditions on the electrostatic potential in the direction of periodicity and vacuum, respectively. Integration over the Brillouin zone for extended systems using the Monkhorst–Pack grid. Calculation of the electronic ground-state using the Chebyshev polynomial filtered self-consistent field iteration in conjunction with Anderson based extrapolation/mixing schemes. Reformulation of the non-local component of the force. Geometry optimization using the Polak–Ribiere variant of non-linear conjugate gradients with secant line search. NVE molecular dynamics using the leapfrog method. Parallelization via domain decomposition and over Brillouin zone integration. Reasons for new version: To enable the study of extended systems like crystals, slabs, and wires using SPARC. Summary of revisions: Incorporated the ability to study the static and dynamic properties of crystals, slabs, and wires. Restrictions: System size less than ∼4000 electrons. Local Density Approximation (LDA). Troullier–Martins pseudopotentials without relativistic or non-linear core corrections. Domain has to be cuboidal. Running time: Problem dependent. Timing results for selected examples provided in the paper. © 2017 Elsevier B.V.","Atomic forces; Electronic structure; Electrostatics; Finite-differences; Parallel computing; Real-space","Boundary conditions; C (programming language); Calculations; Computation theory; Computer operating systems; Crystal atomic structure; Design for testability; Dissociation; Domain decomposition methods; Elastic waves; Electronic structure; Electrostatics; Ground state; Iterative methods; Local density approximation; Molecular dynamics; Open source software; Optimization; Parallel processing systems; Polynomials; Problem oriented languages; Single mode fibers; Software testing; Time varying systems; Vacuum applications; Wave propagation; Wire; Atomic force; Dirichlet boundary condition; Finite-differences; High-order finite differences; Kohn-Sham density-functional theory; Molecular dynamics simulations; Real-space; Self-consistent-field iterations; Density functional theory",2-s2.0-85015801718
"Schunck N., Dobaczewski J., Satuła W., Bączyk P., Dudek J., Gao Y., Konieczka M., Sato K., Shi Y., Wang X.B., Werner T.R.","Solution of the Skyrme-Hartree–Fock–Bogolyubovequations in the Cartesian deformed harmonic-oscillator basis. (VIII) HFODD (v2.73y): A new version of the program",2017,"Computer Physics Communications",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017340584&doi=10.1016%2fj.cpc.2017.03.007&partnerID=40&md5=73df682b5784bcde1f3f0ce10c1cc074","We describe the new version (v2.73y) of the code HFODD which solves the nuclear Skyrme Hartree–Fock or Skyrme Hartree–Fock–Bogolyubov problem by using the Cartesian deformed harmonic-oscillator basis. In the new version, we have implemented the following new features: (i) full proton–neutron mixing in the particle–hole channel for Skyrme functionals, (ii) the Gogny force in both particle–hole and particle–particle channels, (iii) linear multi-constraint method at finite temperature, (iv) fission toolkit including the constraint on the number of particles in the neck between two fragments, calculation of the interaction energy between fragments, and calculation of the nuclear and Coulomb energy of each fragment, (v) the new version 200d of the code HFBTHO, together with an enhanced interface between HFBTHO and HFODD, (vi) parallel capabilities, significantly extended by adding several restart options for large-scale jobs, (vii) the Lipkin translational energy correction method with pairing, (viii) higher-order Lipkin particle-number corrections, (ix) interface to a program plotting single-particle energies or Routhians, (x) strong-force isospin-symmetry-breaking terms, and (xi) the Augmented Lagrangian Method for calculations with 3D constraints on angular momentum and isospin. Finally, an important bug related to the calculation of the entropy at finite temperature and several other little significant errors of the previous published version were corrected. Program summary Title of the program:HFODD (v2.73y) Program Files doi: http://dx.doi.org/10.17632/3b28fs62wc.1 Licensing provisions: GPL v3 Programming language: FORTRAN-90 Journal reference of previous version: N. Schunck, J. Dobaczewski, J. McDonnell, W. Satuła, J. Sheikh, A. Staszczak, M. Stoitsov, and P. Toivanen, Comput. Phys. Comm. 183 (2012) 166-192. Does the new version supersede the previous one: Yes Nature of problem: The nuclear mean field and an analysis of its symmetries in realistic cases are the main ingredients of a description of nuclear states. For the density functional generated by a zero-range velocity-dependent Skyrme interaction, the nuclear mean field is quasilocal. This allows for an effective and fast solution of the self-consistent Hartree–Fock equations, even for heavy nuclei, and for various nucleonic (n-particle n-hole) configurations, deformations, excitation energies, or angular momenta. Similarly, the local particle–particle density functional, generated by a zero-range interaction, allows for a simple implementation of pairing effects within the Hartree–Fock–Bogolyubov method. For finite-range interactions, like Coulomb, Yukawa, or Gogny interaction, the nuclear mean field becomes nonlocal, but using the spatial separability of the deformed harmonic-oscillator basis in three Cartesian directions, the self-consistent calculations can be efficiently performed. Solution method: The program uses the Cartesian harmonic oscillator basis to expand single-particle or single-quasiparticle wave functions of neutrons and protons interacting by means of the Skyrme or Gogny effective interactions and zero-range or finite-range pairing interactions. The expansion coefficients are determined by the iterative diagonalization of the mean-field Hamiltonians or Routhians which depend non-linearly on the local or nonlocal neutron, proton, or mixed proton–neutron densities. Suitable constraints are used to obtain states corresponding to a given configuration, deformation or angular momentum. The method of solution has been presented in: J. Dobaczewski and J. Dudek, Comput. Phys. Comm. 102 (1997) 166. Summary of revisions: 1. Full proton–neutron mixing in the particle–hole channel for Skyrme functionals was implemented.2. The Gogny force was implemented in both particle–hole and particle–particle channels.3. Linear multi-constraint method based on the cranking approximation of the QRPA matrix was extended at finite temperature.4. Fission toolkit includes the constraint on the number of particles in the neck between two fragments, calculation of the interaction energy between fragments, and calculation of the nuclear and Coulomb energy of each fragment.5. The HFBTHO module was updated to version 200d, and an enhanced interface between HFBTHO and HFODD was implemented.6. Parallel capabilities were significantly extended by adding several restart options for large-scale jobs.7. The Lipkin translational energy correction method with pairing was implemented.8. Higher-order Lipkin particle-number corrections were implemented.9. Interface to a program plotting single-particle energies or Routhians was added.10. Strong-force isospin-symmetry-breaking terms were implemented.11. The Augmented Lagrangian Method for calculations with 3D constraints on angular momentum and isospin was implemented.12. An important bug related to the calculation of the entropy at finite temperature and several other little significant errors of the previous published version were corrected.Unusual features of the program: The user must have access to (i) the LAPACK subroutines ZHPEV, ZHPEVX, ZHEEVR, or ZHEEVD, which diagonalize complex hermitian matrices, (ii) the LAPACK subroutines dgetri and dgetrf which invert arbitrary real matrices, (iii) the LAPACK subroutines DSYEVD, DSYTRF and DSYTRI which compute eigenvalues and eigenfunctions of real symmetric matrices and (iv) the LINPACK subroutines ZGEDI and ZGECO, which invert arbitrary complex matrices and calculate determinants, (v) the BLAS routines DCOPY, DSCAL, DGEEM and DGEMV for double-precision linear algebra and ZCOPY, ZDSCAL, ZGEEM and ZGEMV for complex linear algebra, or provide another set of subroutines that can perform such tasks. The BLAS and LAPACK subroutines can be obtained from the Netlib Repository at the University of Tennessee, Knoxville: http://netlib2.cs.utk.edu/. © 2017 Elsevier B.V.","Angular-momentum projection; Energy density functional theory; Gogny force; Hartree–Fock–Bogolyubov; Nuclear density functional theory; Pairing correlations; Self-consistent mean-field; Skyrme interaction","Algebra; Angular momentum; Constrained optimization; Deformation; Density functional theory; Eigenvalues and eigenfunctions; Electromagnetic wave attenuation; Entropy; Equations of motion; FORTRAN (programming language); Hamiltonians; Harmonic analysis; Lagrange multipliers; Linear algebra; Matrix algebra; Microwave oscillators; Mixing; Molecular physics; Momentum; Neutrons; Optimization; Oscillators (mechanical); Problem oriented languages; Subroutines; Time varying systems; Wave functions; Energy density functional theory; Gogny force; Hartree-fock; Nuclear densities; Pairing correlations; Self-consistent mean field; Skyrme interaction; Iterative methods",2-s2.0-85017340584
"Ghadimi P., Feizi Checkab M.A., Bolghasi A.","Simulation of wind-generated surface waves and effects of bubbles on scattering, transmission, and attenuation of low frequency sound at the sea surface",2017,"Journal of the Brazilian Society of Mechanical Sciences and Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020763781&doi=10.1007%2fs40430-016-0676-6&partnerID=40&md5=1c301bcaf03752fab884b6d1a9eb0b5e","Sea surface virtual acoustic simulator lab (SSVASL) is a software based on a newly presented reformed Helmholtz-Kirchhoff-Fresnel method developed in FORTRAN programming language. Based on the resonance dispersion model (RDM), bubbles deformation at frequency range below 200 Hz can cause different physical features such as dynamic density and resonance dependence of phase velocity in bubbly water medium. Therefore, the initial Helmholtz-Kirchhoff-Fresnel (HKF) method which only considers the surface roughness effects is optimized as reformed HKF to entail the influence of subsurface bubble population on the arrival of sound to the sea surface. Considering an acoustical system in which scattering, transmission, and attenuation phenomena occur, effects of sea surface on the emitted sound are simulated by SSVASL. The SSVASL code, by considering the RDM model and void fraction of bubbly medium in frequency range below 1000 Hz and wind-generated surface waves, is capable of providing surface scattering strengths, transmission change, and damping coefficients of rough bubbly air–water interface for a localized point source. For verification purposes, experimental results of critical sea tests, FLIPEX software, and prominent Tolstoy’s approach are considered in sound scattering, transmission, and attenuation phenomena at the sea surface, respectively. The obtained procedure and results can be very helpful in many acoustics-related studies in the ocean environment including acoustic Doppler current profiler, sonar performance, marine life, and oceanography among others. © 2016, The Brazilian Society of Mechanical Sciences and Engineering.","Attenuation; Scattering; Sea surface; Subsurface bubble plumes; Transmission; Wind-generated surface waves","Computer software; Doppler effect; FORTRAN (programming language); Phase interfaces; Scattering; Software testing; Surface roughness; Surface scattering; Surface waters; Surface waves; Transmissions; Underwater acoustics; Verification; Void fraction; Water waves; Acoustic Doppler Current Profilers; Attenuation; Bubble plumes; Damping coefficients; Low-frequency sounds; Scattering strength; Sea surfaces; Surface roughness effects; Acoustic wave scattering",2-s2.0-85020763781
"Zhang X., Peng J., Chen J., Bo K., Yin K., Wu D.","The effect of actuator parameters on the performance of a liquid-jet hammer associated with its jet behavior",2017,"Proceedings of the Institution of Mechanical Engineers, Part C: Journal of Mechanical Engineering Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023781398&doi=10.1177%2f0954406216685350&partnerID=40&md5=ce26df5de003ff50afb08194165bbb8a","Bi-stable fluidic amplifier containing no moving parts was used for switching fluid flow passing through it into an actuator in a liquid-jet hammer. So far, there has been no design basis for developing a liquid-jet hammer with high performance. To provide a guidance, this paper elaborates on the computational fluid dynamics simulation method for investigating the effect of actuator parameters on the performance of a liquid-jet hammer associated with its jet behavior. Given that couple mechanism exists between the flow field in the bi-stable fluidic amplifier and the actuator, dynamic mesh technique and a user-defined function written in C programming language were used to update the mesh in the simulations. Two evaluation criteria - pressure recovery and flux utilization ratio - for a liquid-jet hammer were used in this study. Experimental tests were conducted to verify the simulation results, by which the accuracy and reliability of this computational fluid dynamics simulation method was proved. Besides, comprehensive analysis of the flow behavior in the fluidic amplifier of a liquid-jet hammer was performed by the use of computational fluid dynamics visualization method. © IMechE 2016.","Bi-stable fluidic amplifier; computational fluid dynamics; flux utilization ratio; liquid-jet hammer; pressure recovery","Actuators; C (programming language); Computational fluid dynamics; Dynamics; Flow fields; Flow of fluids; Fluid dynamics; Fluidic amplifiers; Hammers; Liquids; Mesh generation; Non Newtonian flow; Bistables; Comprehensive analysis; Computational fluid dynamics simulations; Dynamic mesh technique; Liquid jets; Pressure recovery; User Defined Functions; Utilization ratios; Fluids",2-s2.0-85023781398
"Lavoie T., Mérineau M., Merlo E., Potvin P.","A case study of TTCN-3 test scripts clone analysis in an industrial telecommunication setting",2017,"Information and Software Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012888858&doi=10.1016%2fj.infsof.2017.01.008&partnerID=40&md5=28dab00945ff072145fc865cdcfdd27f","Context: This paper presents a novel experiment focused on detecting and analyzing clones in test suites written in TTCN-3, a standard telecommunication test script language, for different industrial projects. Objective: This paper investigates frequencies, types, and similarity distributions of TTCN-3 clones in test scripts from three industrial projects in telecommunication. We also compare the distribution of clones in TTCN-3 test scripts with the distribution of clones in C/C++ and Java projects from the telecommunication domain. We then perform a statistical analysis to validate the significance of differences between these distributions. Method: Similarity is computed using CLAN, which compares metrics syntactically derived from script fragments. Metrics are computed from the Abstract Syntax Trees produced by a TTCN-3 parser called Titan developed by Ericsson as an Eclipse plugin. Finally, clone classification of similar script pairs is computed using the Longest Common Subsequence algorithm on token types and token images. Results: This paper presents figures and diagrams reporting TTCN-3 clone frequencies, types, and similarity distributions. We show that the differences between the distribution of clones in test scripts and the distribution of clones in applications are statistically significant. We also present and discuss some lessons that can be learned about the transferability of technology from this study. Conclusion: About 24% of fragments in the test suites are cloned, which is a very high proportion of clones compared to what is generally found in source code. The difference in proportion of Type-1 and Type-2 clones is statistically significant and remarkably higher in TTCN-3 than in source code. Type-1 and Type-2 clones represent 82.9% and 15.3% of clone fragments for a total of 98.2%. Within the projects this study investigated, this represents more and easier potential re-factoring opportunities for test scripts than for code. © 2017","Clone detection; Telecommunications software; Test","C++ (programming language); Codes (symbols); Software testing; Syntactics; Testing; Abstract Syntax Trees; Clone analysis; Clone classifications; Clone detection; Industrial projects; Longest common subsequences; Similarity distribution; Test script languages; Cloning",2-s2.0-85012888858
"Palmer B., Connolly B., Read M.","Activity computer program for calculating ion irradiation activation",2017,"Computer Physics Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017339649&doi=10.1016%2fj.cpc.2017.02.025&partnerID=40&md5=d1e9a7fd4ca347ac2cc7aa0717067065","A computer program, Activity, was developed to predict the activity and gamma lines of materials irradiated with an ion beam. It uses the TENDL (Koning and Rochman, 2012) [1] proton reaction cross section database, the Stopping and Range of Ions in Matter (SRIM) (Biersack et al., 2010) code, a Nuclear Data Services (NDS) radioactive decay database (Sonzogni, 2006) [2] and an ENDF gamma decay database (Herman and Chadwick, 2006) [3]. An extended version of Bateman's equation is used to calculate the activity at time t, and this equation is solved analytically, with the option to also solve by numeric inverse Laplace Transform as a failsafe. The program outputs the expected activity and gamma lines of the activated material. Program summary Program title: Activity Catalogue identifier: AFBS_v1_0 Program summary URL: http://cpc.cs.qub.ac.uk/summaries/AFBS_v1_0.html Program obtainable from: CPC Program Library, Queen's University, Belfast, N. Ireland Licensing provisions: GNU GPL v3 No. of lines in distributed program, including test data, etc.: 688828 No. of bytes in distributed program, including test data, etc.: 71056048 Distribution format: tar.gz Programming language: Fortran. Computer: PCs or HPCs. Operating system: Linux (tested on Debian). Has the code been vectorized or parallelized?: OpenMPI RAM: 250MB per process + 200MB overhead Classification: 2.2, 17.8. Nature of problem: To calculate the predicted activity of an ion irradiated target. The expected range of ion energies is between 1MeV and 200MeV; this is the range of the available ion cross section data. Solution method: The program loads cross section data from the TENDL database and trajectory data from a SRIM [1] simulation exyz data file. It uses this data to calculate the production/loss rate of each isotope in the simulated target. Radioactive decay equations are used to calculate the amounts and activity of each radioactive isotope at the set time. Running time: Typically the Activity program runs each input from seconds to no more than several minutes. References: [1] SRIM — The stopping and range of ions in matter (2010). Ziegler, James F., Ziegler, M.D. and Biersack, J.P. 2010, Nuclear Instruments and Methods in Physics Research Section B, Vol. 268, pp. 1818–1823. © 2017 Elsevier B.V.",,"Computer operating systems; Database systems; FORTRAN (programming language); Inverse problems; Ion beams; Ion bombardment; Ions; Isotopes; Laplace transforms; Linux; Open source software; Radioactivity; Activated materials; Catalogue identifiers; Cross section data; Distributed program; Inverse Laplace transform; Nuclear instruments; Radioactive decay; Stopping and range of ions in matters; Software testing",2-s2.0-85017339649
"Pandey B., Das B., Kaur A., Kumar T., Khan A.M., Akbar Hussain D.M., Tomar G.S.","Performance Evaluation of FIR Filter After Implementation on Different FPGA and SOC and Its Utilization in Communication and Network",2017,"Wireless Personal Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84996554529&doi=10.1007%2fs11277-016-3898-0&partnerID=40&md5=13099ef45200efc8e2e272d03e1f3c66","There are many areas of communication and network, which have open scope to use FIR filter. Therefore, energy efficient FIR filter will increase lifetime of network and FIR filter with less delay and latency will increase performance of network. In this work, we are going to design an FIR filter that will energy efficient as well as faster than traditional design. Three different FPGA and SOC are taken under consideration and our design is implemented on these four ICs and we find the most energy efficient architecture and also find the architecture that will deliver highest performance among these four architectures taken under consideration. There is 47.74% reduction in latency when we migrate our FIR Filter design from 28 nm process technology based seven series architecture to 20 nm process technology based ultrascale architecture. When we analyze power dissipation of Artix-7, Kintex-7, Zynq and Ultrascale FPGA then we conclude that Zynq 7000 All programmable SOC is power hungry architecture and Kintex ultrascale architecture is the most energy efficient architecture that dissipates 20.86% less power than Zynq 700 All programmable SOC. For performance evaluation, we have taken benchmark C code of FIR provide by Xilinx. We transform that C code into HDL using Vivado HLS 2016.2 before power analysis on Vivado 2016.2. Ultrascale FPGA is generally used for packet processing in 100G networking and heterogeneous wireless infrastructure. © 2016, Springer Science+Business Media New York.","Delay; Energy efficient; FIR filter; FPGA; High performance; Latency; Power dissipation; SOC; Verilog","Bandpass filters; Benchmarking; C (programming language); Computer hardware description languages; Electric losses; Energy dissipation; Energy efficiency; Field programmable gate arrays (FPGA); Integrated circuit design; Network architecture; System-on-chip; Delay; Energy efficient; Energy-efficient architectures; High performance; Latency; Lifetime of networks; Process Technologies; Wireless infrastructures; FIR filters",2-s2.0-84996554529
"Oeck S., Malewicz N.M., Hurst S., Al-Refae K., Krysztofiak A., Jendrossek V.","The Focinator v2-0-Graphical Interface, Four Channels, Colocalization Analysis and Cell Phase Identification",2017,"Radiation Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021865115&doi=10.1667%2fRR14746.1&partnerID=40&md5=d11152e923326d9254d42808abc41b60","The quantitative analysis of foci plays an important role in various cell biological methods. In the fields of radiation biology and experimental oncology, the effect of ionizing radiation, chemotherapy or molecularly targeted drugs on DNA damage induction and repair is frequently performed by the analysis of protein clusters or phosphorylated proteins recruited to so called repair foci at DNA damage sites, involving for example γ-H2A.X, 53BP1 or RAD51. We recently developed ""The Focinator"" as a reliable and fast tool for automated quantitative and qualitative analysis of nuclei and DNA damage foci. The refined software is now even more user-friendly due to a graphical interface and further features. Thus, we included an R-script-based mode for automated image opening, file naming, progress monitoring and an error report. Consequently, the evaluation no longer required the attendance of the operator after initial parameter definition. Moreover, the Focinator v2-0 is now able to perform multi-channel analysis of four channels and evaluation of protein-protein colocalization by comparison of up to three foci channels. This enables for example the quantification of foci in cells of a specific cell cycle phase. © 2017 by Radiation Research Society.",,"checkpoint kinase Rad3; double stranded DNA; gamma h2a.x; peptides and proteins; phosphoprotein; Rad51 protein; replication factor A; tumor suppressor p53 binding protein 1; unclassified drug; A-549 cell line; animal cell; Article; cell culture; cell cycle arrest; cell cycle G1 phase; cell cycle M phase; cell cycle S phase; cell differentiation; DNA binding; DNA damage; DNA damage response; DNA repair; DNA replication; flow cytometry; immunofluorescence; immunofluorescence microscopy; ionizing radiation; molecular biology; mouse; nonhuman; priority journal; protein localization; protein phosphorylation; protein protein interaction; protein subunit; qualitative analysis; quantitative analysis; radiobiology; algorithm; cell cycle checkpoint; cell nucleus; computer assisted diagnosis; computer graphics; computer interface; computer language; fluorescence microscopy; genetics; human; procedures; radiation response; software; ultrastructure; A549 Cells; Algorithms; Cell Cycle Checkpoints; Cell Nucleus; Computer Graphics; DNA Damage; Flow Cytometry; Humans; Image Interpretation, Computer-Assisted; Microscopy, Fluorescence; Programming Languages; Software; User-Computer Interface",2-s2.0-85021865115
"Usmani S.S., Bedi G., Samuel J.S., Singh S., Kalra S., Kumar P., Ahuja A.A., Sharma M., Gautam A., Raghava G.P.S.","THPdb: Database of FDA-approved peptide and protein therapeutics",2017,"PLoS ONE",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026469826&doi=10.1371%2fjournal.pone.0181748&partnerID=40&md5=fce1f3538f6e708a45d277c00083cdf7","THPdb (http://crdd.osdd.net/raghava/thpdb/) is a manually curated repository of Food and Drug Administration (FDA) approved therapeutic peptides and proteins. The information in THPdb has been compiled from 985 research publications, 70 patents and other resources like DrugBank. The current version of the database holds a total of 852 entries, providing comprehensive information on 239 US-FDA approved therapeutic peptides and proteins and their 380 drug variants. The information on each peptide and protein includes their sequences, chemical properties, composition, disease area, mode of activity, physical appearance, category or pharmacological class, pharmacodynamics, route of administration, toxicity, target of activity, etc. In addition, we have annotated the structure of most of the protein and peptides. A number of user-friendly tools have been integrated to facilitate easy browsing and data analysis. To assist scientific community, a web interface and mobile App have also been developed. © 2017 Usmani et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",,"peptide derivative; protein derivative; peptide; protein; amino acid sequence; Article; computer interface; drug activity; drug administration route; drug database; drug information; drug targeting; drug toxicity; food and drug administration; information retrieval; mobile application; pharmacodynamic parameters; pharmacological parameters; protein analysis; protein structure; THPdb database; web browser; chemistry; computer language; Internet; protein database; software; United States; Databases, Protein; Internet; Mobile Applications; Peptides; Programming Languages; Proteins; Software; United States; United States Food and Drug Administration; User-Computer Interface",2-s2.0-85026469826
"Lee T.-F., Hsiao C.-H., Hwang S.-H., Lin T.-H.","Enhanced smartcard-based password-authenticated key agreement using extended chaotic maps",2017,"PLoS ONE",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026486443&doi=10.1371%2fjournal.pone.0181744&partnerID=40&md5=cf2731ef276a6eaa56612c53b8b11f65","A smartcard based password-authenticated key agreement scheme enables a legal user to log in to a remote authentication server and access remote services through public networks using a weak password and a smart card. Lin recently presented an improved chaotic maps-based password-authenticated key agreement scheme that used smartcards to eliminate the weaknesses of the scheme of Guo and Chang, which does not provide strong user anonymity and violates session key security. However, the improved scheme of Lin does not exhibit the freshness property and the validity of messages so it still fails to withstand denial-of-service and privileged-insider attacks. Additionally, a single malicious participant can predetermine the session key such that the improved scheme does not exhibit the contributory property of key agreements. This investigation discusses these weaknesses and proposes an enhanced smartcard-based password-authenticated key agreement scheme that utilizes extended chaotic maps. The session security of this enhanced scheme is based on the extended chaotic map-based Diffie-Hellman problem, and is proven in the real-or-random and the sequence of games models. Moreover, the enhanced scheme ensures the freshness of communicating messages by appending timestamps, and thereby avoids the weaknesses in previous schemes. © 2017 Lee et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",,"human; model; smart card; validity; algorithm; computer language; computer security; computer system; confidentiality; information system; nonlinear system; smart card; telemedicine; Algorithms; Computer Security; Computer Systems; Confidentiality; Health Smart Cards; Information Systems; Nonlinear Dynamics; Programming Languages; Telemedicine",2-s2.0-85026486443
"Zhao Y., Guo J., Mao K., Xiang Y., Li Y., Han J., Wu N.","Spatio-temporal distribution of typical natural disasters and grain disaster losses in china from 1949 to 2015",2017,"Dili Xuebao/Acta Geographica Sinica",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029159891&doi=10.11821%2fdlxb201707011&partnerID=40&md5=686d3ffe2abe2066a88163072bfaa78a","Prone to natural disasters, China badly needs a research into its spatio-temporal distribution of natural disasters and the corresponding grain loss to improve grain security and achieve sustainable development. By means of Python Programming Language and on the basis of grain production loss over Chinese 31 provinces from 1949 to 2015, this paper first constructed disaster intensity index to analyze temporal features of different natural disasters, and with trend analysis as well as ESDA to analyze spatial characteristics in different provinces. Then the paper collected crop planting data to calculate and test the spatio-temporal characteristics in grain loss through estimation model on grain loss, defining grain loss rate and geodetector. The conclusions of paper are: (1) compared with the curve of disaster-affected areas, disaster intensity index constructed in this paper could better present temporal changes of natural disasters; (2) China alternately suffered from flood and drought between 1949 and 2015 and in the coming 5 to 10 years the main suffering would be flood; (3) the ranking of natural disasters is: drought>flood>low temperature >hail> typhoon, among which, the areas affected by drought and flood occupied more than half of the total; (4) natural disasters show clear spatial characteristics and the ranking of regional areas prone to disasters is: eastern region> western region; northern region > southern region. Generally speaking, northern region is prone to only one particular natural disaster while southern region tends to suffer from several natural disasters in the meantime; (5) the sum of natural disasters, drought, hail and low temperature, with their random distribution in space, presented unclear spatial autocorrelation, while flood and typhoon, with their clustering model in space distribution, showed clear spatial autocorrelation; (6) from 1949 to 2015, the general temporal changes of disasters, grain loss amount and loss rate showed a feature that the figures would rise first, and then dropped with the critical point in 2000. Meanwhile, they had significant heterogeneity in spatial distribution, great difference in single-factor explanation power, and multi-factor interaction showed a nonlinear enhancement relation. The distribution of hot and cold spots on both sides of the Hu Line presented a polarization pattern and the gravity center of grain loss gradually moved northward. Accordingly, this paper proposes that our government should adopt different precautionary measures in different regions of China: measures against drought and hail in Northwest China; measures against drought and waterlogging in Northeast China; measures against flood and low temperature in Central China; measures against waterlogging and typhoon in coastal areas of Southeast China. And our government should show more concern to and formulate feasible protection plans for hostile-environment Northwest China and highgrain-production Northeast China so that a good harvest in grains could be guaranteed. © 2017, Science Press. All right reserved.","China; Disaster intensity index; ESDA; Grain disaster losses; Natural disaster; Q- statistic","Autocorrelation; Drought; Flood control; Floods; Hurricanes; Precipitation (meteorology); Spatial variables measurement; Sustainable development; Temperature; China; ESDA; Natural disasters; Python programming language; Q statistics; Spatial autocorrelations; Spatiotemporal characteristics; Spatiotemporal distributions; Disasters; drought; flood; index method; low temperature; natural disaster; software; spatiotemporal analysis; sustainable development; trend analysis; typhoon; waterlogging; China",2-s2.0-85029159891
"Zhang X., Wang X., Hu C., Jiang C., Xie Y., Zhao Y.","The development of data acquisition and processing application system for RF ion source",2017,"Plasma Science and Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020294167&doi=10.1088%2f2058-6272%2faa61f5&partnerID=40&md5=a59d4e55c3bcc54a76eeda9624b65cfd","As the key ion source component of nuclear fusion auxiliary heating devices, the radio frequency (RF) ion source is developed and applied gradually to offer a source plasma with the advantages of ease of control and high reliability. In addition, it easily achieves long-pulse steady-state operation. During the process of the development and testing of the RF ion source, a lot of original experimental data will be generated. Therefore, it is necessary to develop a stable and reliable computer data acquisition and processing application system for realizing the functions of data acquisition, storage, access, and real-time monitoring. In this paper, the development of a data acquisition and processing application system for the RF ion source is presented. The hardware platform is based on the PXI system and the software is programmed on the LabVIEW development environment. The key technologies that are used for the implementation of this software programming mainly include the long-pulse data acquisition technology, multi-threading processing technology, transmission control communication protocol, and the Lempel-Ziv-Oberhumer data compression algorithm. Now, this design has been tested and applied on the RF ion source. The test results show that it can work reliably and steadily. With the help of this design, the stable plasma discharge data of the RF ion source are collected, stored, accessed, and monitored in real-time. It is shown that it has a very practical application significance for the RF experiments. © 2017 Hefei Institutes of Physical Science, Chinese Academy of Sciences and IOP Publishing.","data acquisition; data processing; LZO algorithm; RF ion source; TCP","Computer programming languages; Data handling; Data processing; Digital storage; Electric discharges; Ion sources; Nuclear instrumentation; Plasma stability; Technology transfer; Computer data acquisition; Data compression algorithms; Development and testing; Development environment; Processing applications; Processing technologies; Rf ion sources; Steady-state operation; Data acquisition",2-s2.0-85020294167
"Goessens T., Constales D.","Characteristic times in a three scale model with overlapping domain decomposition",2017,"Journal of Computational and Applied Mathematics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84975784278&doi=10.1016%2fj.cam.2016.01.031&partnerID=40&md5=7fa910fb9c88dc0905568038c48bf839","A three-scale diffusion model for textiles was given in Goessens et al. (2015): consisting of a fiber, yarn and room model. To analyze and simplify the model, its characteristic times were investigated in Goessens et al. (2015) [8, 9]. At these times the fiber and yarn model, and the yarn and room model, respectively, tend to reach a partial equilibrium concentration. Here an addition will be made to the model based upon the previous work. An overlap zone is considered between the yarn and room level. Then the overlapping domain decomposition technique is used to calculate the exchange of active ingredient from one level to another in this zone. The mass balance for the system with the overlap zone is calculated and tested in C-language. © 2016 Elsevier B.V.","Characteristic time; Controlled release; Diffusion; Multiscale modeling; Textile modeling","Diffusion; Domain decomposition methods; Textiles; Wool; Yarn; Active ingredients; Characteristic time; Controlled release; Diffusion model; Model-based OPC; Multi-scale Modeling; Overlapping domain decomposition; Partial equilibrium; C (programming language)",2-s2.0-84975784278
"Zahera H.M., El-Sisi A.B.","Accelerating training process in logistic regression model using OpenCL framework",2017,"International Journal of Grid and High Performance Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028709597&doi=10.4018%2fIJGHPC.2017070103&partnerID=40&md5=a14c51071265ea90b83a5dbc954061e9","In this paper, the authors propose a new parallel implemented approach on Graphics Processing Units (GPU) for training logistic regression model. Logistic regression has been applied in many machine learning applications to build building predictive models. However, logistic training regularly requires a long time to adapt an accurate prediction model. Researchers have worked out to reduce training time using different technologies such as multi-threading, Multi-core CPUs and Message Passing Interface (MPI). In their study, the authors consider the high computation capabilities of GPU and easy development onto Open Computing Language (OpenCL) framework to execute logistic training process. GPU and OpenCL are the best choice with low cost and high performance for scaling up logistic regression model in handling large datasets. The proposed approach was implement in OpenCL C/C++ and tested by different size datasets on two GPU platforms. The experimental results showed a significant improvement in execution time with large datasets, which is reduced inversely by the available GPU computing units. Copyright © 2017, IGI Global.","GPU; High Performance Computation; Logistic Regression; OpenCL; Parallel Processing","C++ (programming language); Computer graphics; Graphics processing unit; Learning systems; Message passing; Program processors; Accurate prediction; High performance computation; Logistic Regression modeling; Logistic regressions; Machine learning applications; Message passing interface; OpenCL; Parallel processing; Regression analysis",2-s2.0-85028709597
"Szoke M., Józsa T., Koleszár Á., Moulitsas I., Könözsy L.","Performance evaluation of a two-dimensional lattice Boltzmann solver using CUDA and PGAS UPC based parallelisation",2017,"ACM Transactions on Mathematical Software",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025153257&doi=10.1145%2f3085590&partnerID=40&md5=ff0e75cbfc365677132a5605dcbbb778","The Unified Parallel C (UPC) language from the Partitioned Global Address Space (PGAS) family unifies the advantages of shared and local memory spaces and offers a relatively straightforward code parallelisation with the Central Processing Unit (CPU). In contrast, the Computer Unified Device Architecture (CUDA) development kit gives a tool to make use of the Graphics Processing Unit (GPU). We provide a detailed comparison between these novel techniques through the parallelisation of a two-dimensional lattice Boltzmann method based fluid flow solver. Our comparison between the CUDA and UPC parallelisation takes into account the required conceptual effort, the performance gain, and the limitations of the approaches from the application oriented developers' point of view. We demonstrated that UPC led to competitive efficiency with the local memory implementation. However, the performance of the shared memory code fell behind our expectations, and we concluded that the investigated UPC compilers could not efficiently treat the shared memory space. The CUDA implementation proved to be more complex compared to the UPC approach mainly because of the complicated memory structure of the graphics card which also makes GPUs suitable for the parallelisation of the lattice Boltzmann method. © 2017 ACM.","CFD; Computational fluid dynamics; Compute unified device architecture; CUDA; Lattice Boltzmann method; LBM; NVIDIA; Partitioned global address space; PGAS; Unified parallel C; UPC","C (programming language); Computer graphics; Computer graphics equipment; Flow of fluids; Graphics processing unit; Memory architecture; Program processors; Compute unified device architectures; CUDA; Lattice Boltzmann method; NVIDIA; Partitioned Global Address Space; PGAS; Unified parallel C; Computational fluid dynamics",2-s2.0-85025153257
"Lin Y.-D., Chien Y.-H., Chen Y.-S.","Wavelet-based embedded algorithm for respiratory rate estimation from PPG signal",2017,"Biomedical Signal Processing and Control",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017371344&doi=10.1016%2fj.bspc.2017.03.009&partnerID=40&md5=725397088e92ae29e551d467d347e18b","Photoplethysmography (PPG) is a popular technique utilized in pulse oximeter. Several researches have shown that PPG signal possesses the respiratory-induced intensity variation (RIIV) component, which implies that arterial oxygen saturation, heart rate (HR) and respiratory rate (RR) can be acquired by a single device. The commercial pulse oximeter generally provides the values of arterial oxygen saturation (SpO2) and HR. To successfully add the function of RR estimation to pulse oximeter, an algorithm requiring fewer resources plays a critical role. This paper presents a wavelet-based algorithm for RR estimation from PPG signal that can be implemented in the micro-controller (MCU) of pulse oximeter. The algorithm has been coded in C language and tested in a 32-bit MCU. The estimation results derived by the algorithm agree well with those from usual spectrum analysis methods. The RR estimations derived by PPG and respiratory signal are analyzed by Bland–Altman method. The RR estimations for long-term trace, breath-holding and paced-breathing experiments are also conducted to verify the performance of the proposed algorithm. The experimental results indicate that the proposed algorithm is highly reliable and is feasible to be incorporated in the commercial pulse oximeter. © 2017 Elsevier Ltd","Complex Morlet wavelet; Photoplethysmography (PPG); Pulse oximeter; Respiratory rate (RR); Respiratory-induced intensity variation (RIIV)","C (programming language); Computational complexity; Microcontrollers; Oximeters; Photoplethysmography; Spectrum analysis; Wavelet analysis; Complex Morlet Wavelet; Intensity variations; Photoplethysmography (PPG); Pulse oximeters; Respiratory rate; Noninvasive medical procedures; algorithm; Article; breath holding; breathing pattern; breathing rate; human; photoelectric plethysmography; priority journal; pulse oximeter; signal processing; waveform; wavelet analysis",2-s2.0-85017371344
"Feng W., Wu S., Yin Y., Zhang J., Zhang K.","A training image evaluation and selection method based on minimum data event distance for multiple-point geostatistics",2017,"Computers and Geosciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017294613&doi=10.1016%2fj.cageo.2017.04.004&partnerID=40&md5=5d81e89d308d76c3f6d7acc18647885f","A training image (TI) can be regarded as a database of spatial structures and their low to higher order statistics used in multiple-point geostatistics (MPS) simulation. Presently, there are a number of methods to construct a series of candidate TIs (CTIs) for MPS simulation based on a modeler's subjective criteria. The spatial structures of TIs are often various, meaning that the compatibilities of different CTIs with the conditioning data are different. Therefore, evaluation and optimal selection of CTIs before MPS simulation is essential. This paper proposes a CTI evaluation and optimal selection method based on minimum data event distance (MDevD). In the proposed method, a set of MDevD properties are established through calculation of the MDevD of conditioning data events in each CTI. Then, CTIs are evaluated and ranked according to the mean value and variance of the MDevD properties. The smaller the mean value and variance of an MDevD property are, the more compatible the corresponding CTI is with the conditioning data. In addition, data events with low compatibility in the conditioning data grid can be located to help modelers select a set of complementary CTIs for MPS simulation. The MDevD property can also help to narrow the range of the distance threshold for MPS simulation. The proposed method was evaluated using three examples: a 2D categorical example, a 2D continuous example, and an actual 3D oil reservoir case study. To illustrate the method, a C++ implementation of the method is attached to the paper. © 2017 Elsevier Ltd","Candidate training images; Evaluation and optimal selection; Minimum data event distance; Multiple-point geostatistics","C++ (programming language); Grid computing; Petroleum reservoir engineering; Petroleum reservoirs; Minimum data event distance; Multiple-point geostatistics; Number of methods; Oil reservoirs; Optimal selection; Selection methods; Spatial structure; Training image; Higher order statistics; computer simulation; database; geostatistics; software",2-s2.0-85017294613
"Ghanbari F., Nasarzadeh P., Seydi E., Ghasemi A., Taghi Joghataei M., Ashtari K., Akbari M.","Mitochondrial oxidative stress and dysfunction induced by single- and multiwall carbon nanotubes: A comparative study",2017,"Journal of Biomedical Materials Research - Part A",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019205142&doi=10.1002%2fjbm.a.36063&partnerID=40&md5=0a60cad03e4b47afa14e899972b781a4","With the ever-increasing use of carbon nanotubes (CNTs) in health-related and engineering applications, the hazardous risks of this material have become a major concern. It is well known that CNTs accumulate with cytotoxic and genotoxic levels within vital organs. It has also been shown that treating cell cultures with CNTs resulted in cell-cycle arrest and increased apoptosis/necrosis. The goal of this pilot study is to perform a comprehensive comparative study on the toxicity of single-wall (SW) and multiwall (MW) CNTs in rat skin cells. Our results confirm a dose-dependent toxicity of SWCNTs and MWCNTs due to the loss of mitochondrial activity, increase in mitochondrial reactive oxygen species (ROS) formation, and mitochondrial membrane potential collapse before mitochondrial swelling. Moreover, disturbance in the oxidative phosphorylation is observed by a decrease in ATP level. These events induced the release of cytochrome c via outer membrane rupture or MPT pore opening and subsequently programmed cell death of all doses compared to control group. Our results demonstrate that although MWCNTs can be very toxic, SWCNTs cause more mitochondrial damage to the cells. © 2016 Wiley Periodicals, Inc. J Biomed Mater Res Part A: 105A: 2047–2055, 2017. © 2017 Wiley Periodicals, Inc.","mitochondria; mitochondrial dysfunction; multiwalled carbon nanotubes; oxidative stress; single-wall nanotube","C (programming language); Carbon; Carbon nanotubes; Cell culture; Cell death; Cell membranes; Cells; Cytology; Health risks; Mitochondria; Nanotubes; Oxidative stress; Single-walled carbon nanotubes (SWCN); Toxicity; Yarn; Engineering applications; Mitochondrial activity; Mitochondrial dysfunction; Mitochondrial membrane potential; Oxidative phosphorylation; Programmed cell deaths; Reactive oxygen species; Single wall nanotubes; Multiwalled carbon nanotubes (MWCN); adenosine triphosphate; cytochrome c; glutathione; multi walled nanotube; reactive oxygen metabolite; single walled nanotube; succinate dehydrogenase; animal cell; animal experiment; animal model; animal tissue; apoptosis; Article; comparative study; controlled study; disorders of mitochondrial functions; enzyme activity; enzyme release; lipid peroxidation; male; mitochondrial biogenesis; mitochondrial membrane potential; mitochondrial respiration; mitochondrion swelling; mouse; nanotoxicology; nonhuman; outer membrane; oxidative phosphorylation; pilot study; rat; skin cell; skin toxicity",2-s2.0-85019205142
"Duan C.-J., Huang M.-Y., Pang H., Zhao J., Wu C.-X., Feng J.-X.","Characterization of a novel theme C glycoside hydrolase family 9 cellulase and its CBM-chimeric enzymes",2017,"Applied Microbiology and Biotechnology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019762258&doi=10.1007%2fs00253-017-8320-7&partnerID=40&md5=08e94e1c95487dbd5b8bfaeb0070c761","In bacterial cellulase systems, glycoside hydrolase family 9 (GH9) cellulases are generally regarded as the major cellulose-degrading factors besides GH48 exoglucanase. In this study, umcel9A, which was cloned from uncultured microorganisms from compost, with the encoded protein being theme C GH9 cellulase, was heterologously expressed in Escherichia coli, and the biochemical properties of the purified enzyme were characterized. Hydrolysis of carboxylmethylcellulose (CMC) by Umcel9A led to the decreased viscosity of CMC solution and production of reducing sugars. Interestingly, cellobiose was the major product when cellulosic materials were hydrolyzed by Umcel9A. Six representative carbohydrate-binding modules (CBMs) from different CBM families (CBM1, CBM2, CBM3, CBM4, CBM10, and CBM72) were fused with Umcel9A at the natural terminal position, resulting in significant enhancement of the binding capacity of the chimeric enzymes toward four different insoluble celluloses as compared with that of Umcel9A. Catalytic activity of the chimeric enzymes against insoluble celluloses, including phosphoric acid-swollen cellulose (PASC), alkali-pretreated sugarcane bagasse (ASB), filter paper powder (FPP), and Avicel, was higher than that of Umcel9A, except for Umcel9A-CBM3. In these chimeric enzymes, CBM4-Umcel9A exhibited the highest activity toward the four tested insoluble celluloses and displayed 4.2-, 3.0-, 2.4-, and 6.6-fold enhanced activity toward PASC, ASB, FPP, and Avicel, respectively, when compared with that of Umcel9A. CBM4-Umcel9A also showed highest Vmax and catalytic efficiency (kcat/KM) against PASC. Construction of chimeric enzymes may have potential applications in biocatalytic processes and provides insight into the evolution of the molecular architecture of catalytic module and CBM in GH9 cellulases. © 2017, Springer-Verlag Berlin Heidelberg.","Binding capacity; Carbohydrate-binding module; Catalytic activity; Cellulase; Chimeric enzyme; Glycoside hydrolase family 9","Bins; C (programming language); Carbohydrates; Cellulose; Cloning; Composting; Enzymes; Escherichia coli; Hydrolases; Hydrolysis; Sugars; Binding capacities; Carbohydrate binding modules; Cellulase; Chimeric enzymes; Glycoside hydrolases; Catalyst activity; carbohydrate binding protein; carboxymethylcellulose; cellobiose; cellulase; chimeric protein; glucan synthase; glycoside hydrolase family 9; umcel9A protein; unclassified drug; biochemical composition; carbohydrate; catalysis; cellulose; chemical binding; coliform bacterium; compost; enzyme activity; hydrolysis; microorganism; protein; Article; binding assay; compost; enzyme activity; enzyme analysis; enzyme binding; enzyme degradation; enzyme kinetic assay; enzyme purification; enzyme specificity; Escherichia coli; gene expression; hydrolysis; metagenomics; molecular cloning; nonhuman; nucleotide sequence; pH; phylogenetic tree; protein determination; protein expression; sequence analysis; temperature; viscometry; Bacteria (microorganisms); Escherichia coli",2-s2.0-85019762258
"Bisogni S., Di Serego Alighieri S., Goldoni P., Ho L.C., Marconi A., Ponti G., Risaliti G.","Simultaneous detection and analysis of optical and ultraviolet broad emission lines in quasars at z ∼ 2.2",2017,"Astronomy and Astrophysics",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022195593&doi=10.1051%2f0004-6361%2f201630143&partnerID=40&md5=07326b842477e21faf6e5b2d10d13b72","We studied the spectra of six z ∼ 2.2 quasars obtained with the X-shooter spectrograph at the Very Large Telescope. The redshift of these sources and the X-shooter's spectral coverage allow us to cover the rest of the spectral range ∼1200-7000 Å for the simultaneous detection of optical and ultraviolet lines emitted by the broad-line region. Simultaneous measurements, avoiding issues related to quasars variability, help us understand the connection between the different broad-line region line profiles generally used as virial estimators of black hole masses in quasars. The goal of this work is to compare the different emission lines for each object to check on the reliability of Hα, Mg ii and C iv with respect to Hβ. Hα and Mg ii linewidths correlate well with Hβ, while C iv shows a poorer correlation, due to the presence of strong blueshifts and asymmetries in the profile. We compared our sample with the only other two whose spectra were taken with the same instrument and for all examined lines our results are in agreement with the ones obtained with X-shooter at z ∼ 1.5-1.7. We finally evaluate C iii] as a possible substitute of C iv in the same spectral range and find that its behaviour is more coherent with those of the other lines: we believe that, when a high quality spectrum such as the ones we present is available and a proper modelization with the Fe ii and Fe iii emissions is performed, it is more appropriate to use this line than that of C iv if not corrected for the contamination by non-virialized components. © ESO, 2017.","Galaxies: active; Galaxies: nuclei; Galaxies: Seyfert; Quasars: emission lines; Quasars: general","C (programming language); Electromagnetic wave emission; Galaxies; Quality control; Galaxies : active; Galaxies: nuclei; Galaxies: seyfert; Quasars: emission line; Quasars: general; Astronomy",2-s2.0-85022195593
"Silva F.R.O., Lima N.B., Yoshito W.K., Bressiani A.H.A., Gomes L.","Development of novel upconversion luminescent nanoparticle of Ytterbium/Thulium–doped beta tricalcium phosphate",2017,"Journal of Luminescence",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015827063&doi=10.1016%2fj.jlumin.2017.03.029&partnerID=40&md5=308ed09fda6f5196aaca5e8aae407f80","A novel class of upconversion luminescent nanocrystals of Yb/Tm:calcium deficient hydroxyapatite were synthesized by co-precipitation method in aqueous solution (pH adjusted to 6) and specially heat-treated with microwave radiation at different temperatures (from 900 °C to 1000 °C) and times (2–10 min) to produce small nanocrystals of Yb/Tm:β-tricalcium phosphate (β-TCP). As a result, we report for the first time, a single-phase Yb/Tm-doped β-TCP nanocrystals with a mean crystallite size of 55.3 nm. This material has an efficient visible luminescence from the 1G4 (blue emission) and 3F2 (red emission) and near infrared emission from the 3H4 excited states of Tm3+ induced by the Yb3+→Tm3+ energy transfer under laser excitation (Yb3+) at 972 nm. This β-TCP activated by Yb3+ and Tm3+ ions constitutes a new nano-fluoroprobe that can be used as optical contrast agents, affording high resolution and sensitivity for visible-near infrared applications. © 2017 Elsevier B.V.","Beta-tricalcium phosphate; Nanoparticle; Thulium; Upconversion luminescence; Visible and near-infrared emitting materials; Ytterbium","Biomaterials; C (programming language); Crystallite size; Doping (additives); Energy transfer; Infrared devices; Laser excitation; Luminescence; Nanocrystals; Nanoparticles; Precipitation (chemical); Solutions; Thulium; Transmission control protocol; Beta tricalcium phosphate; Calcium deficient hydroxyapatite; Emitting material; Luminescent nanocrystals; Luminescent nanoparticle; Near-infrared emissions; Optical contrast agent; Up-conversion luminescence; Ytterbium",2-s2.0-85015827063
"Kuleshova E.A., Gurovich B.A., Bukina Z.V., Frolov A.S., Maltsev D.A., Krikun E.V., Zhurko D.A., Zhuchkov G.M.","Mechanisms of radiation embrittlement of VVER-1000 RPV steel at irradiation temperatures of (50–400)°C",2017,"Journal of Nuclear Materials",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018928022&doi=10.1016%2fj.jnucmat.2017.04.035&partnerID=40&md5=52c6b64bd1d4fb441b553bfbbd399727","This work summarizes and analyzes our recent research results on the effect of irradiation temperature within the range of (50–400)°C on microstructure and properties of 15Kh2NMFAA class 1 steel (VVER-1000 reactor pressure vessel (RPV) base metal). The paper considers the influence of accelerated irradiation with different temperature up to different fluences on the carbide and irradiation-induced phases, radiation defects, yield strength changes and critical brittleness temperature shift (ΔTK) as well as on changes of the fraction of brittle intergranular fracture and segregation processes in the steel. Low temperature irradiation resulted solely in formation of radiation defects – dislocation loops of high number density, the latter increased with increase in irradiation temperature while their size decreased. In this regard high embrittlement rate observed at low temperature irradiation is only due to the hardening mechanism of radiation embrittlement. Accelerated irradiation at VVER-1000 RPV operating temperature (∼300 °C) caused formation of radiation-induced precipitates and dislocation loops, as well as some increase in phosphorus grain boundary segregation. The observed ΔTK shift being within the regulatory curve for VVER-1000 RPV base metal is due to both hardening and non-hardening mechanisms of radiation embrittlement. Irradiation at elevated temperature caused more intense phosphorus grain boundary segregation, but no formation of radiation-induced precipitates or dislocation loops in contrast to irradiation at 300 °C. Carbide transformations observed only after irradiation at 400 °C caused increase in yield strength and, along with a contribution of the non-hardening mechanism, resulted in the lowest ΔTK shift in the studied range of irradiation temperature and fluence. © 2017 Elsevier B.V.","15Kh2NMFAA class 1 steel; AES; APT; Elevated temperature irradiation; Fractographic studies; Grain boundary segregation; Hardening and non-hardening mechanisms; Low temperature irradiation; Mechanical properties; Reactor pressure vessel; TEM","Brittle fracture; C (programming language); Carbides; Defects; Dental alloys; Embrittlement; Fracture mechanics; Grain boundaries; Hardening; Irradiation; Mechanical properties; Nuclear reactors; Phosphorus; Pressure vessels; Radiation hardening; Segregation (metallography); Steel research; Temperature; Transmission electron microscopy; Unmanned aerial vehicles (UAV); Yield stress; Class 1; Elevated temperature irradiations; Fractographic; Grain boundary segregation; Hardening mechanism; Low temperature irradiations; Reactor Pressure Vessel; Radiation",2-s2.0-85018928022
"Demirçivi P., Saygili G.N.","Response surface modeling of boron adsorption from aqueous solution by vermiculite using different adsorption agents: Box-Behnken experimental design",2017,"Water Science and Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030178976&doi=10.2166%2fwst.2017.200&partnerID=40&md5=ebe91fe5d7ea77c7c084f24b0aee7b56","In this study, a different method was applied for boron removal by using vermiculite as the adsorbent. Vermiculite, which was used in the experiments, was not modified with adsorption agents before boron adsorption using a separate process. Hexadecyltrimethylammonium bromide (HDTMA) and Gallic acid (GA) were used as adsorption agents for vermiculite by maintaining the solid/liquid ratio at 12.5 g/L. HDTMA/GA concentration, contact time, pH, initial boron concentration, inert electrolyte and temperature effects on boron adsorption were analyzed. A three-factor, threelevel Box-Behnken design model combined with response surface method (RSM) was employed to examine and optimize process variables for boron adsorption from aqueous solution by vermiculite using HDTMA and GA. Solution pH (2-12), temperature (25-60 °C) and initial boron concentration (50-8,000 mg/L) were chosen as independent variables and coded x1, x2 and x3 at three levels (-1, 0 and 1). Analysis of variance was used to test the significance of variables and their interactions with 95% confidence limit (α= 0.05). According to the regression coefficients, a second-order empirical equation was evaluated between the adsorption capacity (qi) and the coded variables tested (xi). Optimum values of the variables were also evaluated for maximum boron adsorption by vermiculite-HDTMA (HDTMA-Verm) and vermiculite-GA (GA-Verm). © 2017 IWA Publishing.","Adsorption; Boron; Box-Behnken experimental design; Response surface modeling; Vermiculite","Boron; C (programming language); Electrolytes; Solutions; Statistics; Surface properties; Adsorption capacities; Box-Behnken experimental design; Hexadecyl trimethyl ammonium bromide; Independent variables; Regression coefficient; Response surface method; Response surface modeling; Vermiculite; Adsorption; adsorbent; boron; cetrimide; electrolyte; gallic acid; vermiculite; aluminum silicate; boron; vermiculite; water pollutant; adsorption; aqueous solution; boron; chemical process; electrolyte; experimental design; experimental study; inorganic salt; modeling; organic compound; pollutant removal; response surface methodology; temperature; vermiculite; adsorption; aqueous solution; Article; concentration (parameters); pH; process optimization; response surface method; temperature sensitivity; adsorption; analysis; chemistry; procedures; temperature; theoretical model; water management; water pollutant; Adsorption; Aluminum Silicates; Boron; Cetrimonium Compounds; Hydrogen-Ion Concentration; Models, Theoretical; Temperature; Water Pollutants, Chemical; Water Purification",2-s2.0-85030178976
"Viktoratos I., Tsadiras A., Bassiliades N.","Modeling human daily preferences through a context-aware web-mapping system using semantic technologies",2017,"Pervasive and Mobile Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009195006&doi=10.1016%2fj.pmcj.2016.08.002&partnerID=40&md5=3b0a100192c5aa250235de111238c94e","In this paper, a novel geosocial networking service called “G-SPLIS” (Geosocial Semantic Personalized Location Information System) is presented. The paper provides a methodology to design, implement and share in a formal way human daily preferences regarding points of interest (POIs) and POI owners’ group targeted offering policies, via user-defined preferences and policy rules. By adding rules at run time users have more flexibility and they do not rely on the pre-determined application's methods to get personalized information. Furthermore, G-SPLIS provides a large knowledge base for other systems in the web, because rules are easily sharable. To achieve the above, the presented system is compatible with Semantic Web standards such as the schema.org ontology and uses RuleML for rules that define regular users’ preferences and POI owner's group-targeted offers. Finally, it combines at run-time the above to match user context with related information and visualizes personalized information. © 2016 Elsevier B.V.","Context; Group-targeted offers; Location based services; Rules; Semantic web","Computer programming languages; Knowledge based systems; Location based services; Telecommunication services; Context; Group-targeted offers; Location information; Networking services; Personalized information; Rules; Semantic technologies; Semantic web standards; Semantic Web",2-s2.0-85009195006
"Watanabe S.-I., Tsuda Y., Yoshikawa M., Tanaka S., Saiki T., Nakazawa S.","Hayabusa2 Mission Overview",2017,"Space Science Reviews",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020703359&doi=10.1007%2fs11214-017-0377-1&partnerID=40&md5=c4abe056d6ab120cb4b2c69ea312bdc0","The Hayabusa2 mission journeys to C-type near-Earth asteroid (162173) Ryugu (1999 JU3) to observe and explore the 900 m-sized object, as well as return samples collected from the surface layer. The Haybusa2 spacecraft developed by Japan Aerospace Exploration Agency (JAXA) was successfully launched on December 3, 2014 by an H-IIA launch vehicle and performed an Earth swing-by on December 3, 2015 to set it on a course toward its target Ryugu. Hayabusa2 aims at increasing our knowledge of the early history and transfer processes of the solar system through deciphering memories recorded on Ryugu, especially about the origin of water and organic materials transferred to the Earth’s region. Hayabusa2 carries four remote-sensing instruments, a telescopic optical camera with seven colors (ONC-T), a laser altimeter (LIDAR), a near-infrared spectrometer covering the 3-μm absorption band (NIRS3), and a thermal infrared imager (TIR). It also has three small rovers of MINERVA-II and a small lander MASCOT (Mobile Asteroid Surface Scout) developed by German Aerospace Center (DLR) in cooperation with French space agency CNES. MASCOT has a wide angle imager (MasCam), a 6-band thermal radiator (MARA), a 3-axis magnetometer (MasMag), and a hyperspectral infrared microscope (MicrOmega). Further, Hayabusa2 has a sampling device (SMP), and impact experiment devices which consist of a small carry-on impactor (SCI) and a deployable camera (DCAM3). The interdisciplinary research using the data from these onboard and lander’s instruments and the analyses of returned samples are the key to success of the mission. © 2017, Springer Science+Business Media Dordrecht.","Aqueous alteration; Formation of the solar system; Hayabusa2; Near-Earth asteroid; Ryugu; Sample return mission","Aneroid altimeters; Asteroids; C (programming language); Cameras; Crashworthiness; Infrared devices; Infrared spectrometers; Optical radar; Remote sensing; Solar system; Space flight; Space research; Aqueous alteration; Hayabusa2; Near-earth asteroids; Ryugu; Sample return; Earth (planet)",2-s2.0-85020703359
"Zhong Z., Pang S., Wu Y., Jiang S., Ouyang J.","Synthesis and characterization of mesoporous Cu–MOF for laccase immobilization",2017,"Journal of Chemical Technology and Biotechnology",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012970291&doi=10.1002%2fjctb.5189&partnerID=40&md5=e4c07298e136e79d12ae44b5c818dcaa","BACKGROUND: Mesoporous metal–organic frameworks (MOFs) have been widely researched for enzyme immobilization, however, most are unstable in the aqueous phase. This paper reports the synthesis of a Cu–MOF for the immobilization of copper contained laccase via a surfactant-templating method with various surfactant/chelating agent mass ratios. RESULTS: The Brunauer–Emmett–Teller (BET) surface area and pore diameter of the nanoscale Cu–MOF were 366–1154 m2 g−1 and 15.2–20.7 nm, respectively. The adsorption concentration and time were optimized to be 5 mg laccase mL−1 and 1 h. This immobilized system exhibited adsorption capacity up to 502 mg g−1 and activity recovery rate of 95.2%. The optimum reaction conditions for immobilizing laccase on Cu–MOF were pH 4 and 50°C. According to the Lineweaver–Burk plot, the Km of the immobilized laccase was 0.157 mmol L−1, indicating that the affinity of immobilized laccase to its substrate was higher than that of free laccase (0.290 mmol L−1). The activity of immobilized laccase after seven iterations of reuse remained approximately 50%. CONCLUSION: The mesoporous Cu–MOF showed favorable adsorption capability and can be utilized in laccase immobilization. © 2017 Society of Chemical Industry. © 2017 Society of Chemical Industry","Cu–metal organic framework; immobilization; laccase; mesoporous","Adsorption; Crystalline materials; Enzyme immobilization; Java programming language; Mesoporous materials; Organic polymers; Organometallics; Radioactive waste vitrification; Surface active agents; Adsorption capacities; Brunauer-emmett-teller surface areas; Laccase immobilizations; Laccases; Mesoporous; Metal organic framework; Optimum reaction conditions; Synthesis and characterizations; Enzymes; copper; laccase; metal organic framework; adsorption; Article; catalysis; chemical reaction; concentration (parameters); controlled study; desorption; enzyme immobilization; enzyme kinetics; enzyme stability; enzyme substrate; infrared spectroscopy; particle size; pH; process optimization; surface area; synthesis; thermogravimetry; transmission electron microscopy; X ray diffraction",2-s2.0-85012970291
"Fortea-Pérez F.R., Mon M., Ferrando-Soria J., Boronat M., Leyva-Pérez A., Corma A., Herrera J.M., Osadchii D., Gascon J., Armentano D., Pardo E.","The MOF-driven synthesis of supported palladium clusters with catalytic activity for carbene-mediated chemistry",2017,"Nature Materials",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021403711&doi=10.1038%2fnmat4910&partnerID=40&md5=79443a5298b3b8dcc12c62fb49b7262b","The development of catalysts able to assist industrially important chemical processes is a topic of high importance. In view of the catalytic capabilities of small metal clusters, research efforts are being focused on the synthesis of novel catalysts bearing such active sites. Here we report a heterogeneous catalyst consisting of Pd4 clusters with mixed-valence 0/+1 oxidation states, stabilized and homogeneously organized within the walls of a metal-organic framework (MOF). The resulting solid catalyst outperforms state-of-the-art metal catalysts in carbene-mediated reactions of diazoacetates, with high yields (&gt;90%) and turnover numbers (up to 100,000). In addition, the MOF-supported Pd4 clusters retain their catalytic activity in repeated batch and flow reactions (&gt;20 cycles). Our findings demonstrate how this synthetic approach may now instruct the future design of heterogeneous catalysts with advantageous reaction capabilities for other important processes. © 2017 Macmillan Publishers Limited, part of Springer Nature. All rights reserved.",,"Catalysts; Crystalline materials; Java programming language; Organic compounds; Solid state reactions; Catalytic capability; Heterogeneous catalyst; Mediated reactions; Metal organic framework; Research efforts; Small metal clusters; Supported palladium; Synthetic approach; Catalyst activity",2-s2.0-85021403711
"Sadati S., Arezoumandi M., Khayat K.H., Volz J.S.","Bond performance of sustainable reinforced concrete beams",2017,"ACI Materials Journal",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024472629&doi=10.14359%2f51689776&partnerID=40&md5=81820c50923bcba849a3a56525fe598e","Proper force transfer between reinforcement and surrounding concrete is one of the most significant factors affecting the structural performance of reinforced concrete. Because of the increasing interest in using fly ash and recycled concrete aggregate (RCA) in structural applications, it is necessary to investigate bond properties of mixtures proportioned with high volume of these materials. The present study investigates bond strength between concrete and reinforcing steel in full-scale beams constructed with various ""green"" concrete mixtures, including high-volume fly ash concrete containing 50% Class C fly ash replacement (FA50), concrete with 50% of coarse RCA replacement (RCA50), as well as a so-called ""sustainable concrete"" (SC) proportioned with 50% Class C fly ash and 50% RCA. Conventional concrete (CC) made without any fly ash and RCA is employed as the Reference mixture. Data obtained from the testing of 11 full-scale spliced beams are analyzed, including one beam per concrete type (except for RCA50) for investigating the top-bar effect. Experimental results are compared to six different analytical models available in literature. Results are also evaluated based on the bond database of specimens fabricated with RCA developed through literature survey as well as the database proposed by ACI Committee 408 for bond in CC. On average, SC specimens exhibited 15% higher normalized bond strength compared to the Reference beams. Performance of SC mixture was similar to that of RCA50, which were both slightly (6%) lower than that of the FA50 beams in terms of bond strength. No sign of top-bar effect was observed for the FA50 and SC beams. © Copyright 2017, American Concrete Institute. All rights reserved.","Bond strength; High-volume fly ash; Recycled concrete aggregate; Reinforced concrete; Structural behavior; Sustainable concrete","Bond strength (materials); C (programming language); Concrete beams and girders; Concrete testing; Concretes; Fly ash; Mixtures; Recycling; Reinforced concrete; Reinforcement; High volume fly ash; High volume fly ash concrete; Recycled concrete aggregates; Reinforced concrete beams; Structural applications; Structural behaviors; Structural performance; Sustainable concretes; Concrete mixtures",2-s2.0-85024472629
"Zhang B., Xiao P., Li Y., Li Z., Zhou W., Luo H., Lu Y.","Microstructures and tribological properties of carbon/carbon-boron nitride composites fabricated by powdered additives and chemical vapor infiltration",2017,"Ceramics International",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015085359&doi=10.1016%2fj.ceramint.2017.03.055&partnerID=40&md5=b548631a3bd7a0d369bf4888b1d547ba","The carbon fiber reinforced/carbon-boron nitride (C/C-BN) dual matrix composites were fabricated via adding hexagonal boron nitride (h-BN) powders into the needled carbon felt and subsequent chemical vapor infiltration (CVI) process. An experimental investigation was performed to study the influences of BN volume content on the microstructures and tribological properties of C/C-BN composites. The results indicate that the pyrolytic carbon (PyC) in the C/C-BN composites is regenerative laminar (ReL) due to the inducement of BN powders during CVI process, whereas the PyC in the C/C composite is classic smooth laminar. Additionally, the friction coefficients of C/C-BN composites with three different BN contents in volume fractions (4.5, 9 and 13.5 vol%) are all higher compared to the reference C/C composite (0.22). Note that the highest coefficient of friction (0.29) is obtained when the BN volume content in the C/C-BN composite is 9 vol%. Moreover, the linear and mass wear rates of C/C-BN composites as well as the 30CrSiMoVA counterparts are significantly decreased with the increase of BN volume content. The favorable friction and wear properties of C/C-BN composites are attributed to the synergistic effect induced by the ReL PyC and BN. The microstructural variation of C/C composites modified by h-BN could improve the compatibility between the C/C-BN composites and 30CrSiMoVA counterpart, resulting in an enhanced adhesive attraction between the wear debris and the surface of 30CrSiMoVA counterpart. Furthermore, the investigations concerning the friction surfaces indicate that the formation of sheet-like friction films with large areas are more easily to occur on the surfaces of 30CrSiMoVA counterparts mating with the C/C-BN composites rather than mating with the C/C composite. © 2017 Elsevier Ltd and Techna Group S.r.l.","C/C; Friction; h-BN; Pyrolytic carbon; Wear","Boron nitride; Carbon carbon composites; Chemical vapor infiltration; Composite films; Friction; Microstructure; Nitrides; Powders; Tribology; Wear of materials; Coefficient of frictions; Experimental investigations; Friction and wear properties; H-BN; Hexagonal boron nitride (h-BN); Microstructural variation; Pyrolytic carbon; Tribological properties; C (programming language)",2-s2.0-85015085359
"Eickmeyer K., Giannopoulou A.C., Kreutzer S., Kwon O.-J., Pilipczuk M., Rabinovich R., Siebertz S.","Neighborhood complexity and kernelization for nowhere dense classes of graphs",2017,"Leibniz International Proceedings in Informatics, LIPIcs",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027247344&doi=10.4230%2fLIPIcs.ICALP.2017.63&partnerID=40&md5=1f80083d4285aabc3df1e9824bf02767","We prove that whenever G is a graph from a nowhere dense graph class C, and A is a subset of vertices of G, then the number of subsets of A that are realized as intersections of A with r-neighborhoods of vertices of G is at most f (r,ϵ)·|A|1+ϵ, where r is any positive integer, ϵ is any positive real, and f is a function that depends only on the class C. This yields a characterization of nowhere dense classes of graphs in terms of neighborhood complexity, which answers a question posed by Reidl et al. [26]. As an algorithmic application of the above result, we show that for every fixed integer r, the parameterized Distance-r Dominating Set problem admits an almost linear kernel on any nowhere dense graph class. This proves a conjecture posed by Drange et al. [9], and shows that the limit of parameterized tractability of Distance-r Dominating Set on subgraph-closed graph classes lies exactly on the boundary between nowhere denseness and somewhere denseness. © Kord Eickmeyer, Archontia C. Giannopoulou, Stephan Kreutzer, O-joung Kwon, Michał Pilipczuk, Roman Rabinovich, and Sebastian Siebertz.","Dominating set; Graph structure theory; Kernelization; Nowhere dense graphs; Parameterized complexity","Automata theory; C (programming language); Parameterization; Dense graphs; Dominating sets; Graph structures; Kernelization; Parameterized complexity; Graph theory",2-s2.0-85027247344
"Gallego G., Hakkarainen M., Almajano M.P.","Stability of O/W emulsions packed with PLA film with incorporated rosemary and thyme",2017,"European Food Research and Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007485757&doi=10.1007%2fs00217-016-2829-3&partnerID=40&md5=7950b9e21318dc7324c3b14f1f758378","Active packaging is a promising technology for food industry. In this study, polylactic acid (PLA) films were prepared with dry or lyophilized plants of thyme and rosemary. These plants are an abundant, inexpensive source of polyphenolic antioxidant. Oil-in-water (O/W) emulsions were made, covered by the different PLA films and stored for 30 days. The lipid oxidation was measured by peroxide value and thiobarbituric acid-reactive substances assays. The lyophilized rosemary extract (LRE) and lyophilized thyme extract used in PLA films, resulted in enhanced oxidative stability of emulsions. PLA film with LRE was the most effective to protect of O/W emulsion at 33 ± 1 °C for 20 days according to guideline by the Codex Alimentarius (<10 meq/kg), regarding the control that exceeds this value to 5 days. The prepared PLA films were characterized to determine the effect of rosemary and thyme on thermal properties and thermo-oxidative stability of the films. In addition, the migration behavior was evaluated in contact with food simulants. PLA antioxidant active packaging could reduce the need of adding antioxidants directly in food products, increasing the shelf life. © 2016, Springer-Verlag Berlin Heidelberg.","Active packaging; Lipid oxidation; Oil-in-water emulsions; PLA; Rosemary; Thyme","Antioxidants; C (programming language); Emulsification; Emulsions; Flavonoids; Food products; Oils and fats; Oxidation resistance; Active packaging; Lipid oxidation; Oil-in-water emulsions; Rosemary; Thyme; Film preparation",2-s2.0-85007485757
"Brogi A., Cifariello P., Soldani J.","DrACO: Discovering available cloud offerings",2017,"Computer Science - Research and Development",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992715405&doi=10.1007%2fs00450-016-0332-5&partnerID=40&md5=b667ebdc4153c5320145b57115647c26","Current cloud technologies suffer from a lack of standardisation, with different providers offering similar resources in a different manner. The aim of this work is to contribute overcoming such heterogeneity, by showing how the OASIS TOSCA standard can be exploited to provide a standard-based representation of the virtual machines and platforms offered by IaaS and PaaS cloud providers. We also present DrACO, an open-source prototype tool that permits to look-up for cloud offerings and to retrieve them in a standardised TOSCA format. © 2016, Springer-Verlag Berlin Heidelberg.","Cloud offerings; Service discovery; TOSCA","Computer science; Cloud providers; Cloud technologies; nocv1; Open sources; Prototype tools; Service discovery; TOSCA; Virtual machines; Java programming language",2-s2.0-84992715405
"Xia L., Liu Q., Wang F., Li Y.","ENHANCEMENT EFFECT of LITHIUM-DOPING FUNCTIONALIZATION on HYDROGEN ADSORPTION in METAL-ORGANIC FRAMEWORK",2017,"Surface Review and Letters",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85001065619&doi=10.1142%2fS0218625X17500676&partnerID=40&md5=9af1fb6aec3554f99eb3a2872e58897a","Grand canonical Monte-Carlo simulation was carried out to study the effect of linker functionalization by Li atoms. In this work, two new Li-doping structures, MOF-808-Li and MOF-808-OLi were theoretically constructed by physical modification and chemical modification, respectively. The results show that both these methods can improve the hydrogen storage performance significantly, owing to the Li atoms increasing the interaction energy between the hydrogen molecules and the Li-doped MOF-808. Furthermore, MOF-808-OLi shows higher hydrogen capacity in comparison to the H2 adsorption in the MOF-808-Li, this can be attributed to the new adsorption sites created by oxygen atom. The gravimetric adsorption capacity of MOF-808-OLi can reach 3.17wt.% at 77K and 1bar, which are significantly higher than the hydrogen adsorption in the unmodified MOF-808. © 2017 World Scientific Publishing Company.","GCMC; hydrogen adsorption; lithium-doping; MOF","Adsorption; Atoms; Chemical modification; Crystalline materials; Gas adsorption; Hydrogen; Hydrogen storage; Intelligent systems; Java programming language; Monte Carlo methods; Organic polymers; Organometallics; Adsorption capacities; GCMC; Grand canonical Monte Carlo simulation; Hydrogen adsorption; Interaction energies; Lithium doping; Metal organic framework; Physical modifications; Lithium",2-s2.0-85001065619
"Zhao X., Xu M., Ding Z., Peng S., Fang P.","Reactive blending toughened PLA by in situ formation of polyurethane crosslinked elastomer",2017,"Polymer Science - Series B",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028557062&doi=10.1134%2fS156009041704011X&partnerID=40&md5=24ba72a9a6d757047c46c028e927b570","Polylactide (PLA)/polyurethane (PU) composites were prepared by reactive blending method with in-situ formation of PU particles via the reaction between polyester polyol (PPG) and toluene-2,4-diisocyanate (TDI). The interfacial compatibility and adhesion between the PLA and PU phases were greatly improved by the reaction of the terminal hydroxyl groups of PLA and N=C=O groups of TDI forming graft copolymer, as confirmed by FTIR spectroscopy. The elongation at break and notch impact strength of PLA/PU composites increased considerably with increasing PU content, and the tensile strength of PLA/PU composites decreased slightly compared with that of pure PLA. The excellent interfacial adhesion, dispersed PU elastomeric particles acting as stress concentration areas and the triggering of large matrix shearing yielding and many fibrils by internal cavitation were the main mechanical toughening mechanisms. © 2017, Pleiades Publishing, Ltd.",,"Adhesion; Blending; Fourier transform infrared spectroscopy; Impact strength; Tensile strength; Cross-linked elastomers; Elongation at break; In-situ formations; Interfacial adhesions; Interfacial compatibility; Internal cavitation; Reactive blending; Toughening mechanisms; C (programming language)",2-s2.0-85028557062
"Zhang Y., Zuo S., Jiang J., Liu Y., Liu Y.","Interactive adjustment of individual orthodontic archwire curve",2017,"Yi Qi Yi Biao Xue Bao/Chinese Journal of Scientific Instrument",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030683824&partnerID=40&md5=4a7b6337d60319e4016077dc44a15b9e","Digital medical technology is inevitable trend in the future orthodontic treatment. The robotic technology is used to assist orthodontics archwire bending clincally, and the digital expression of orthodontic archwire is prerequisite of the robotic bending. Because of the individuation of human tooth arrangement and complexity of archwire shape design, it is difficult to realize the precise digital expression of individual archwire. This paper presents an interactive adjustment method for individual orthodontic archwire. Based on reference points on bracket, the straight line segment for bracket and the transitional curve segment are defined in orthodontic wire curve. And the transitional curve segment is constructed by the mathematical model of 3th order Bezier curve. Referred to process of manual bending wire, the mathematical model and model library about special function arch curve are established based on the discrete and combinatorial method. The interactive adjustment method for individual orthodontics archwire is studied by adjusting position of the straight line segment for bracket, shape changes of the transitional curve segment, selecting the position and type of special function arch curve. The experiments are conducted in the interactive adjustment software designed on the LabVIEW software platform. The result shows that the method is feasible and effective. © 2017, Science Press. All right reserved.","Individual expression; Interactive adjustment; Orthodontic archwire; Robotic bending","Arches; Biomedical engineering; Computer programming languages; Dentistry; Robotics; Combinatorial method; Individual expression; Interactive adjustment; Medical technologies; Orthodontic archwires; Orthodontic treatments; Robotic technologies; Straight-line segments; Functions",2-s2.0-85030683824
"Kumar P., Yurchyshyn V., Cho K.-S., Wang H.","Multiwavelength observations of a flux rope formation by series of magnetic reconnection in the chromosphere∗",2017,"Astronomy and Astrophysics",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021973875&doi=10.1051%2f0004-6361%2f201629295&partnerID=40&md5=4b2b510a42b34720150079dee80658eb","Using high-resolution observations from the 1.6 m New Solar Telescope (NST) operating at the Big Bear Solar Observatory (BBSO), we report direct evidence of merging and reconnection of cool Hα loops in the chromosphere during two homologous flares (B and C class) caused by a shear motion at the footpoints of two loops. The reconnection between these loops caused the formation of an unstable flux rope that showed counterclockwise rotation. The flux rope could not reach the height of torus instability and failed to form a coronal mass ejection. The HMI magnetograms revealed rotation of the negative and positive (N1/P2) polarity sunspots in the opposite directions, which increased the right- and left-handed twist in the magnetic structures rooted at N1/P2. Rapid photospheric flux cancellation (duration 20-30 min, rate 3.44 × 1020 Mx h-1) was observed during and even after the first B6.0 flare and continued until the end of the second C2.3 flare. The RHESSI X-ray sources were located at the site of the loop coalescence. To the best of our knowledge, such a clear interaction of chromospheric loops along with rapid flux cancellation has not been reported before. These high-resolution observations suggest the formation of a small flux rope by a series of magnetic reconnections within chromospheric loops that are associated with very rapid flux cancellation. © 2017 ESO.","Sun: chromosphere; Sun: coronal mass ejections (CMEs); Sun: flares; Sun: magnetic fields; Sun: oscillations; Sun: particle emission","C (programming language); Chromophores; Magnetism; Rope; Sun: Chromosphere; Sun: coronal mass ejection; Sun: flares; Sun: magnetic field; Sun: oscillations; Sun: particle emissions; Magnetic polarity",2-s2.0-85021973875
"Rezaei Kahkha M.R., Daliran S., Oveisi A.R., Kaykhaii M., Sepehri Z.","The Mesoporous Porphyrinic Zirconium Metal-Organic Framework for Pipette-Tip Solid-Phase Extraction of Mercury from Fish Samples Followed by Cold Vapor Atomic Absorption Spectrometric Determination",2017,"Food Analytical Methods",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008474579&doi=10.1007%2fs12161-016-0786-x&partnerID=40&md5=fe1ff22ff7cade4436fbc6b58868dc0b","In this study, the highly stable mesoporous porphyrinic zirconium metal-organic framework, namely PCN-222/MOF-545 (Zr-MOF), was prepared and used for pipette-tip solid-phase extraction of Hg(II). As a high-capacity sorbent, 4 mg of the Zr-MOF was placed into a conventional pipette tip and used, for the first time, for the fast extraction and preconcentration of mercury ions. For desorption, 50 μL of 10% HCl was used by 15 repeated aspirating/dispensing cycles, and Hg ions in elusion were measured by a cold vapor atomic absorption spectrometer. Affecting parameters on extraction efficiency were studied, and optimum conditions were established as amount of sorbent 2 mg, pH was adjusted to 5.0, the eluting volume was 15 μL, and extraction was performed on 1.8 mL of the sample. The optimal number of aspirating/dispensing cycles for extraction and desorption of analytes was found to be 10 and 15 cycles, respectively. The limit of detection of the method was found to be 20 ng L−1 with a relative standard deviation of ≤3.1% (for seven replicate analyses of 20 μg L−1 of mercury). Adsorption capacity and enrichment factor were 35.5 mg g−1 and 120-fold, respectively. The proposed method was successfully applied for the determination of Hg(II) ions in fish samples. © 2017, Springer Science+Business Media New York.","Fish analysis; Mesoporous MOF; Pipette-tip extraction; Porphyrin; Solid-phase extraction; Zirconium metal organic framework (PCN-222/MOF-545)","Crystalline materials; Desorption; Fish; Ions; Java programming language; Mercury (metal); Mesoporous materials; Organometallics; Phase separation; Porphyrins; Zirconium; Adsorption capacities; Cold-vapor atomic absorptions; Extraction efficiencies; Fish analysis; Mesoporous; Relative standard deviations; Solid-phase extraction; Zirconium metal; Extraction",2-s2.0-85008474579
"Abbasi A.R., Karimi M., Daasbjerg K.","Efficient removal of crystal violet and methylene blue from wastewater by ultrasound nanoparticles Cu-MOF in comparison with mechanosynthesis method",2017,"Ultrasonics Sonochemistry",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009128743&doi=10.1016%2fj.ultsonch.2017.01.007&partnerID=40&md5=f083a543ef0aee0d2e4fa528c73101de","The present investigation reports the synthesis of CuBTC (BTC = 1,3,5-benzenetricarboxylate) metal–organic frameworks (MOFs) under solid-state conditions and ultrasound irradiation. Herein, we study uptake and release properties of crystal violet (CV) and methylene blue (MB) from ultrasound nano-CuBTC MOF in comparison with mechanosynthesis method (bulk structure). The ultrasound-assisted methods give a decrease in the surface area as calculated from the reduced nitrogen adsorption capability. In comparison, the uptake of guest molecules on ultrasound nano-CuBTC is remarkable and clearly exceeds that of bulk structure in the aqueous solution of guests. In bulk compound the channel length is increased so that the amount of adsorption is decreased a little. The small guest enters and leaves the cavity rapidly, whereas larger guests enter slowly due to their size relative to the size of the gaps in the capsule. As a result, the uptake and release of MB from CuBTC is faster than that of CV. © 2017","Crystal violet; Metal–organic framework; Methylene blue; Nano; Wastewater","Aromatic compounds; Crystal structure; Gas adsorption; Java programming language; Solutions; Ultrasonics; Wastewater; Crystal violet; Guest molecules; Mechanosynthesis; Methylene Blue; Nano; Reduced nitrogen; Release property; Ultrasound irradiation; Dyes; copper nanoparticle; crystal violet; metal organic framework; methylene blue; nanoparticle; nitrogen; adsorption; aqueous solution; Article; controlled study; desorption; infrared spectroscopy; isotherm; priority journal; scanning electron microscopy; surface area; synthesis; thermogravimetry; ultrasound; waste water; X ray powder diffraction",2-s2.0-85009128743
"Zhang J., Zhao C., Zhao S., Wu X.","A family of single-phase hybrid step-down PFC converters",2017,"IEEE Transactions on Power Electronics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027514615&doi=10.1109%2fTPEL.2016.2604845&partnerID=40&md5=0ec0db9e48cd79273e43788ac7bca61d","Buck power factor correction (PFC) has attracted a lot of research interests for its low output voltage and high efficiency at low input condition. However, the traditional Buck PFC converter usually has low power factor (PF) and poor harmonic performance due to the inherent dead angle of the input current, especially at low input condition. To solve this problem, this paper proposes a family of hybrid PFC converter topologies combining the advantages of step-up PFC and step-down (Buck) PFC converters, which features low output voltage and continuous input current (high PF). The derivation methodology is presented in detail and two topologies are selected as typical examples to explore their performances. With the improved peak current control scheme, the two proposed converters can achieve high PF under universal input range, and their input current harmonics can easily meet the IEC61000-3-2 Class C limits. The optimal design considerations are presented and two 150-W prototypes are built to verify the theoretical analysis. © 1986-2012 IEEE.","Class C; high efficiency; hybrid converters; peak current control; power factor correction (PFC)","C (programming language); DC-DC converters; Efficiency; Electric current control; Electric power factor correction; Topology; Harmonic performance; High-efficiency; Hybrid converters; Input current harmonics; Low output voltage; Peak current control; Power factor corrections; Research interests; Power converters",2-s2.0-85027514615
"Zhu D., Li H., Su Y., Jiang M.","Pyridine-containing metal-organic frameworks as precursor for nitrogen-doped porous carbons with high-performance capacitive behavior",2017,"Journal of Solid State Electrochemistry",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014040236&doi=10.1007%2fs10008-017-3543-1&partnerID=40&md5=aa709e21c8089eff66fb5201e8139820","A novel pyridine-containing metal-organic framework (MOF, [Zn(bpdc)DMA]·DMF, bpdc = 2,2′-bipyridine-5,5′-dicarboxylate) was directly carbonized at different temperature to produce nitrogen-doped porous carbons (NPCs). The as-prepared porous carbons, NPC800 (obtained at 800 °C) and NPC1000 (obtained at 1000 °C), were characterized by scanning electron microscopy, X-ray powder diffraction, N2 sorption isotherms, and X-ray photoelectron spectroscopy (XPS). The results from elemental analysis and XPS confirmed that the pyridine groups in MOF served as nitrogen sources to produce NPCs, and NPC800 possessed the higher nitrogen content than NPC1000. N2 sorption data demonstrated that NPC800 exhibited the larger specific surface area and pore volume than NPC1000. The capacitive properties of NPC800 and NPC1000 were investigated in KOH aqueous electrolyte by cyclic voltammetry and galvanostatic charge–discharge curves. NPC800 showed the higher specific capacitance (226.6 F g−1 at 1 A g−1) than NPC1000 and retained 178.0 F g−1 even at a high current density up to 10 A g−1. It was found that the donation of N species to capacitance was more than the role of porosity in view of their synergetic effect. © 2017, Springer-Verlag Berlin Heidelberg.","Capacitance; Metal-organic framework; Nitrogen-doped porous carbons; Pyridine","Capacitance; Carboxylation; Crystalline materials; Cyclic voltammetry; Doping (additives); Electrolytes; Java programming language; Nitrogen; Organic polymers; Organometallics; Porous materials; Pyridine; Scanning electron microscopy; X ray powder diffraction; Aqueous electrolyte; Capacitive behavior; Galvanostatic charges; High current densities; Metal organic framework; Porous carbons; Sorption isotherms; Specific capacitance; X ray photoelectron spectroscopy",2-s2.0-85014040236
"Nikseresht A., Daniyali A., Ali-Mohammadi M., Afzalinia A., Mirzaie A.","Ultrasound-assisted biodiesel production by a novel composite of Fe(III)-based MOF and phosphotangestic acid as efficient and reusable catalyst",2017,"Ultrasonics Sonochemistry",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009195030&doi=10.1016%2fj.ultsonch.2017.01.011&partnerID=40&md5=9adc99182fb2922c081aaf981ff1f6aa","In this work, esterification of oleic acid by various alcohols is achieved with high yields under ultrasonic irradiation. This reaction performed with a novel heterogeneous catalyst that fabricated by heteropoly acid and Fe(III)-based MOF, namely MIL-53 (Fe). Syntheses of MIL-53 and encapsulation process carry out by ultrasound irradiation at ambient temperature and atmospheric pressure. The prepared composite was characterized by various techniques such as XRD, FT-IR, SEM, BET and ICP that demonstrate excellent catalytic activities, while being highly convenient to synthesize. The obtained results revealed that ultrasound irradiation could be used for the appropriate and rapid biodiesel production. © 2017 Elsevier B.V.","Biodiesel production; Esterification; MOFs; Oleic acid; Phosphotungstic acid","Atmospheric pressure; Biodiesel; Catalysts; Esterification; Esters; Irradiation; Java programming language; Oleic acid; Ultrasonics; Biodiesel production; Encapsulation process; Esterification of oleic acids; Heterogeneous catalyst; MOFs; Phosphotungstic acid; Reusable catalysts; Ultrasound irradiation; Catalyst activity; alcohol; biodiesel; butanol; ferric ion; metal organic framework; oleic acid; phosphotungstic acid; Article; catalyst; catalytic efficiency; encapsulation; esterification; interventional ultrasonography; molecule; morphology; porosity; priority journal; reaction time; scanning electron microscope; spectroscopy; ultrasound",2-s2.0-85009195030
"Castro I., Lamar D.G., Arias M., Hernando M.M., Sebastian J.","Multicell Three-Phase AC-DC Driver for HB-LED Lighting Applications",2017,"IEEE Transactions on Industry Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029576656&doi=10.1109%2fTIA.2017.2686802&partnerID=40&md5=40cdd037c306775b4d2add1bd27924c1","High-brightness light-emitting diodes (HB-LEDs) are becoming omnipresent across all aspects of illumination products, due to their incredible characteristics such as efficiency, reliability, long lifetime, controllability, etc. This paper proposes power conversion topologies to drive medium to high power HB-LEDs in three-phase power grids when these connections are available. For that reason, an evaluation of several drivers for medium to high power HB-LEDs in three-phase power grids is done. Moreover, a new topology is proposed, which complies with IEC 1000-3-2 Class C requirements, achieves high power factor, low total harmonic distortion, and the capability to have a flicker free behavior while disposing of the bulk capacitor and having galvanic isolation. The HB-LED driver is based on a modular approach with several cells working together with their inputs connected to the three-phase network and their outputs connected in parallel generating a dc output. Each one of these cells is a dc-dc converter operating as a loss free resistor. In order to validate the concept, a prototype has been built by the use of flyback converters operating in discontinuous conduction mode. Furthermore, it operates in the full range of the European three-phase line voltage, which varies between 380 and 420 V, and it supplies an output voltage of 48 V with maximum power of 90 W. © 2017 IEEE.","AC-DC power conversion; high-brightness light-emitting diodes (HB-LED) driver; loss free resistor (LFR); power factor (PF) correction; three phase","C (programming language); DC motors; DC-DC converters; Electric inverters; Electric power factor; Electric power system control; Electric power transmission networks; Luminance; Power converters; Rectifying circuits; Resistors; Topology; Ac-dc power conversion; Discontinuous conduction mode; High brightness; Power conversion topologies; Power factors; Three phase; Three phase networks; Total harmonic distortion (THD); Light emitting diodes",2-s2.0-85029576656
"Tell R.","Improved bounds for quantified derandomization of constant-depth circuits and polynomials",2017,"Leibniz International Proceedings in Informatics, LIPIcs",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028754478&doi=10.4230%2fLIPIcs.CCC.2017.13&partnerID=40&md5=f15ff7486de3eadd3935271d50a35b6f","This work studies the question of quantified derandomization, which was introduced by Goldreich and Wigderson (STOC 2014). The generic quantified derandomization problem is the following: For a circuit class C and a parameter B = B(n), given a circuit C 2 C with n input bits, decide whether C rejects all of its inputs, or accepts all but B(n) of its inputs. In the current work we consider three settings for this question. In each setting, we bring closer the parameter setting for which we can unconditionally construct relatively fast quantified derandomization algorithms, and the ""threshold"" values (for the parameters) for which any quantified derandomization algorithm implies a similar algorithm for standard derandomization. For constant-depth circuits, we construct an algorithm for quantified derandomization that works for a parameter B(n) that is only slightly smaller than a ""threshold"" parameter, and is significantly faster than the best currently-known algorithms for standard derandomization. On the way to this result we establish a new derandomization of the switching lemma, which significantly improves on previous results when the width of the formula is small. For constantdepth circuits with parity gates, we lower a ""threshold"" of Goldreich and Wigderson from depth five to depth four, and construct algorithms for quantified derandomization of a remaining type of layered depth-3 circuit that they left as an open problem. We also consider the question of constructing hitting-set generators for multivariate polynomials over large fields that vanish rarely, and prove two lower bounds on the seed length of such generators. Several of our proofs rely on an interesting technique, which we call the randomized tests technique. Intuitively, a standard technique to deterministically find a ""good"" object is to construct a simple deterministic test that decides the set of good objects, and then ""fool"" that test using a pseudorandom generator. We show that a similar approach works also if the simple deterministic test is replaced with a distribution over simple tests, and demonstrate the benefits in using a distribution instead of a single test. © Roei Tell.","Computational complexity; Constant-depth circuits; Derandomization; Hitting-set generator; Quantified derandomization","Computational complexity; Computer circuits; Gold; Parameter estimation; Testing; Timing circuits; Constant-depth circuits; Depth-3 circuits; Derandomization; Hitting set generators; Multivariate polynomial; Parameter setting; Pseudorandom generators; Randomized tests; C (programming language)",2-s2.0-85028754478
"Zhang Y., Lucier B.E.G., Terskikh V.V., Zheng R., Huang Y.","Tracking the evolution and differences between guest-induced phases of Ga-MIL-53 via ultra-wideline 69/71Ga solid-state NMR spectroscopy",2017,"Solid State Nuclear Magnetic Resonance",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012925872&doi=10.1016%2fj.ssnmr.2017.01.008&partnerID=40&md5=ead04c398948e300734dd21d464546e0","Ga-MIL-53 is a metal-organic framework (MOF) that exhibits a “breathing effect,” in which the pore size and overall MOF topology can be influenced by temperature, pressure, and host-guest interactions. The phase control afforded by this flexible framework renders Ga-MIL-53 a promising material for guest storage and sensing applications. In this work, the structure and behavior of four Ga-MIL-53 phases (as, ht, enp and lt), along with CO2 adsorbed within Ga-MIL-53 at various loading levels, has been investigated using 69/71Ga solid-state NMR (SSNMR) experiments at 21.1 T and 9.4 T. 69/71Ga SSNMR spectra are observed to be very sensitive to distortions in the octahedral GaO6 secondary building units within Ga-MIL-53; by extension, Ga NMR parameters are indicative of the particular crystallographic phase of Ga-MIL-53. The evolution of Ga NMR parameters with CO2 loading levels in Ga-MIL-53 reveals that the specific CO2 loading level offers a profound degree of control over the MOF phase, and the data also suggests that a re-entrant phase transition is present. Adsorption of various organic compounds within Ga-MIL-53 has been investigated using a combination of thermal gravimetric analysis (TGA), powder X-ray diffraction (pXRD) and 69/71Ga SSNMR experiments. Notably, pXRD experiments reveal that guest adsorption and host-guest interactions trigger unambiguous changes in the long-range structure of Ga-MIL-53, while 69/71Ga SSNMR parameters yield valuable information regarding the effect of the organic adsorbates on the local GaO6 environments. This approach shows promise for the ultra-wideline investigation of other quadrupolar metal nuclei in MIL-53 (e.g., In-MIL-53) and MOFs in general, particularly in regards to adsorption-related applications. © 2017 Elsevier Inc.",,"Adsorption; Carbon dioxide; Crystalline materials; Digital storage; Gravimetric analysis; Java programming language; Light polarization; Nuclear magnetic resonance spectroscopy; Organometallics; Pore size; Thermogravimetric analysis; X ray diffraction; Crystallographic phase; Host guest interactions; Long-Range Structures; Metal organic framework; Powder X-ray diffraction (pXRD); Secondary building units; Solid-state NMR spectroscopy; Thermal gravimetric analyses (TGA); Gallium",2-s2.0-85012925872
"Song Z.-G., Pu E.-X.","Precipitated phases of superaustenitic stainless steel 654SMO",2017,"Journal of Iron and Steel Research International",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021818865&doi=10.1016%2fS1006-706X%2817%2930112-7&partnerID=40&md5=5b9597c45d078648bf9ed88ee3f8fa55","The phase diagram of superaustenitic stainless steel 654SMO was calculated by thermodynamic software and the precipitated phases in the specimens aged at 800 – 1100 °C for 1 h were studied by methods of physicochemical phase analysis, scanning electron microscopy and transmission electron microscopy. The results showed that the size of precipitated particles increased with increasing the temperature. The amount of second phases reached the maximum value at 900 °C, but decreased above 900 °C. There were about eight kinds of precipitated phases in 654SMO including σ phase, Cr2N, μ phase, χ phase, Laves phase, M23C6, M6C and M3C, in which the σ phase and Cr2 N were the dominant precipitated phases. © 2017 Central Iron and Steel Research Institute","654SMO; Precipitated phase; Precipitation; Second phase; Superaustenitic stainless steel","C (programming language); Cold rolling; Electron microscopy; High resolution transmission electron microscopy; Laser beam welding; Precipitation (chemical); Scanning electron microscopy; Transmission electron microscopy; 654SMO; Chi phase; Laves-phase; Phase analysis; Precipitated phase; Second phase; Sigma phase; Super-austenitic stainless steels; Stainless steel",2-s2.0-85021818865
"Arunachalam S., De Wolf R.","Optimal quantum sample complexity of learning algorithms",2017,"Leibniz International Proceedings in Informatics, LIPIcs",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028750843&doi=10.4230%2fLIPIcs.CCC.2017.25&partnerID=40&md5=bdadbdf59dfc8ea79957439e37bfaf8e","In learning theory, the VC dimension of a concept class C is the most common way to measure its ""richness."" A fundamental result says that the number of examples needed to learn an unknown target concept c 2 C under an unknown distribution D, is tightly determined by the VC dimension d of the concept class C. Specifically, in the PAC model Ω dd ϵ + log(1/δ) ϵ examples are necessary and sufficient for a learner to output, with probability 1-δ, a hypothesis h that is ϵ-close to the target concept c (measured under D). In the related agnostic model, where the samples need not come from a c 2 C, we know that Ω d d ϵ2 + log(1/δ) ϵ2 examples are necessary and sufficient to output an hypothesis h 2 C whose error is at most ϵ worse than the error of the best concept in C. Here we analyze quantum sample complexity, where each example is a coherent quantum state. This model was introduced by Bshouty and Jackson [18], who showed that quantum examples are more powerful than classical examples in some fixed-distribution settings. However, At and Servedio [10], improved by Zhang [55], showed that in the PAC setting (where the learner has to succeed for every distribution), quantum examples cannot be much more powerful: the required number of quantum examples is dd1- ϵ + d + log(1/δ) ϵ for arbitrarily small constant > 0. Our main result is that quantum and classical sample complexity are in fact equal up to constant factors in both the PAC and agnostic models. We give two proof approaches. The first is a fairly simple information-theoretic argument that yields the above two classical bounds and yields the same bounds for quantum sample complexity up to a log(d/ϵ) factor. We then give a second approach that avoids the log-factor loss, based on analyzing the behavior of the ""Pretty Good Measurement"" on the quantum state identification problems that correspond to learning. This shows classical and quantum sample complexity are equal up to constant factors for every concept class C. © Srinivasan Arunachalam and Ronald de Wolf.","Agnostic learning; PAC learning; Quantum computing; VC dimension","Computational complexity; Information theory; Learning algorithms; Probability distributions; Quantum computers; Quantum optics; Quantum theory; Agnostic learning; Constant factors; PAC learning; Pretty-good measurements; Quantum Computing; Sample complexity; Simple informations; VC dimension; C (programming language)",2-s2.0-85028750843
"Chang Z., Ji J., Huang Y., Wang Z., Li Q.","Monte Carlo calculation model for heat radiation of inclined cylindrical flames and its application",2017,"Heat and Mass Transfer/Waerme- und Stoffuebertragung",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011659381&doi=10.1007%2fs00231-017-1981-z&partnerID=40&md5=181f23904ac16382e492c6f97303fe36","Based on Monte Carlo method, a calculation model and its C++ calculating program for radiant heat transfer from an inclined cylindrical flame are proposed. In this model, the total radiation energy of the inclined cylindrical flame is distributed equally among a certain number of energy beams, which are emitted randomly from the flame surface. The incident heat flux on a surface is calculated by counting the number of energy beams which could reach the surface. The paper mainly studies the geometrical evaluation criterion for validity of energy beams emitted by inclined cylindrical flames and received by other surfaces. Compared to Mudan’s formula results for a straight cylinder or a cylinder with 30° tilt angle, the calculated view factors range from 0.0043 to 0.2742 and the predicted view factors agree well with Mudan’s results. The changing trend and values of incident heat fluxes computed by the model is consistent with experimental data measured by Rangwala et al. As a case study, incident heat fluxes on a gasoline tank, both the side and the top surface are calculated by the model. The heat radiation is from an inclined cylindrical flame generated by another 1000 m3 gasoline tank 4.6 m away from it. The cone angle of the flame to the adjacent oil tank is 45° and the polar angle is 0°. The top surface and the side surface of the tank are divided into 960 and 5760 grids during the calculation, respectively. The maximum incident heat flux on the side surface is 39.64 and 51.31 kW/m2 on the top surface. Distributions of the incident heat flux on the surface of the oil tank and on the ground around the fire tank are obtained, too. © 2017, Springer-Verlag Berlin Heidelberg.",,"C++ (programming language); Computer software; Cylinders (shapes); Gasoline; Heat radiation; Heat transfer; Monte Carlo methods; Oil tanks; Tanks (containers); Calculating programs; Calculation models; Changing trends; Evaluation criteria; Gasoline tanks; ITS applications; Monte Carlo calculation; Radiation energy; Heat flux",2-s2.0-85011659381
"Santos J., Dinis D., Riscado D., Anjos G., Belo D., Oliveira A.S.R., Monteiro P., Carvalho N.B.","A flexible physical layer and fronthaul research testbed for C-RAN",2017,"Microprocessors and Microsystems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85000658970&doi=10.1016%2fj.micpro.2016.09.001&partnerID=40&md5=d41be992bc3752308b5085ade17a7954","Mobile networks are subject to an explosive increase in data traffic, in a context of continuous mobility and more stringent levels of QoS, which imposes demanding requirements to telecommunication networks. To cope with this trend, a novel paradigm of radio access networks, known as C-RAN, is being developed, where the physical layer processing is also shifted from the edges of the network to a centralized location. C-RAN provides important benefits and will be one of the cornerstones of 5G communication systems. However, some architectural and implementation tradeoffs need to be further evaluated. Moreover, the modularity and extensibility of research platforms supporting C-RAN is still very restrictive. This paper presents a laboratorial platform aimed for the development and trial of C-RAN compliant features. The proposed testbed is very modular and flexible and it is intended to provide a cost-effective emulation and physical layer implementation platform for the main C-RAN modules, namely the BBU, the fronthaul and the RRHs. Based on open FPGA platforms, it features a high level of flexibility in terms of configurations, waveforms and interfaces, and includes all the components required to build an open and complete C-RAN compliant base station. It is mainly used for the experimentation and evaluation of next generation wireless communication systems, including new fronthaul protocols and interfaces as well as 5G waveforms. It integrates a 25 km optical fronthaul, a software defined multi-mode and multi-band RF front-end and a digital radio compression algorithm associated with the optical fronthaul. The inclusion of low-latency (de)compression algorithms was of paramount importance in order to achieve a 50% reduction in terms of fronthaul bandwidth. © 2016 Elsevier B.V.","BBU; C-RAN; CPRI; FPGA; Fronthaul; Radio over fiber; RRH; Software-Defined radio","Bandwidth compression; Cost effectiveness; Digital radio; Field programmable gate arrays (FPGA); Mobile telecommunication systems; Network layers; Optical communication; Radio-over-fiber; Software radio; Testbeds; Wireless telecommunication systems; Compression algorithms; CPRI; Fronthaul; Next-generation wireless communications; Physical layer processing; Physical-layer implementation; Radio access networks; Software-defined radios; C (programming language)",2-s2.0-85000658970
"Maleknejad K., Saeedipoor E.","An efficient method based on hybrid functions for Fredholm integral equation of the first kind with convergence analysis",2017,"Applied Mathematics and Computation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012126394&doi=10.1016%2fj.amc.2017.01.013&partnerID=40&md5=f603d0b753aff331cfb0ba684df2f3a9","In this article, a numerical direct method based on hybrid Block-Pulse functions and Legendre polynomials is proposed to solve Fredholm integral equation of the first kind. These hybrid basic functions are orthogonal and have compact support on [0, 1]. The properties of the hybrid functions are utilized to convert the integral equations into a system of linear algebraic equations. The main purpose of this paper is to obtain an error estimate and to show the convergence analysis for the numerical direct method based on hybrid functions under the L2-norm. The main characteristic of the method is low cost of setting up the equations without using any projection method. Finally, some numerical examples are provided to illustrate the validity and the efficiency of the proposed scheme especially for problems with non-sufficiently smooth solutions belonging to class C1 or C2. © 2017 Elsevier Inc.","Convergence analysis; Direct method; Fredholm integral equation of the first kind; Hybrid functions","C (programming language); Convergence of numerical methods; Linear algebra; Linear equations; Numerical methods; Orthogonal functions; Block-pulse function; Convergence analysis; Direct method; Fredholm integral equation of the first kind; Hybrid functions; Legendre polynomials; Projection method; System of linear algebraic equations; Integral equations",2-s2.0-85012126394
"Chen P., Zhang J., Sun X.","Real-time kinematic positioning of LEO satellites using a single-frequency GPS receiver",2017,"GPS Solutions",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84996606937&doi=10.1007%2fs10291-016-0586-1&partnerID=40&md5=8f36a29210a50515b0557c3734fca8cb","Due to their low cost and low power consumption, single-frequency GPS receivers are considered suitable for low-cost space applications such as small satellite missions. Recently, requirements have emerged for real-time accurate orbit determination at sub-meter level in order to carry out onboard geocoding of high-resolution imagery, open-loop operation of altimeters and radio occultation. This study proposes an improved real-time kinematic positioning method for LEO satellites using single-frequency receivers. The C/A code and L1 phase are combined to eliminate ionospheric effects. The epoch-differenced carrier phase measurements are utilized to acquire receiver position changes which are further used to smooth the absolute positions. A kinematic Kalman filter is developed to implement kinematic orbit determination. Actual flight data from China’s small satellite SJ-9A are used to test the navigation performance. Results show that the proposed method outperforms traditional kinematic positioning method in terms of accuracy. A 3D position accuracy of 0.72 and 0.79 m has been achieved using the predicted portion of IGS ultra-rapid products and broadcast ephemerides, respectively. © 2016, Springer-Verlag Berlin Heidelberg.","Kinematic Kalman filter; Kinematic positioning; LEO; Real-time; Single-frequency GPS receiver","C (programming language); Kalman filters; Kinematics; Orbits; Satellites; Space applications; Tracking (position); Carrier-phase measurement; GPS receivers; Kinematic positioning; Low-cost space applications; Real time; Real-time kinematic positioning; Single-frequency receivers; Small satellite mission; Global positioning system; accuracy assessment; cost analysis; frequency analysis; GPS; Kalman filter; kinematics; orbit determination; positioning; real time; satellite imagery; satellite mission; China",2-s2.0-84996606937
"Du M., He D., Lou Y., Chen J.","Porous nanostructured ZnCo2O4 derived from MOF-74: High-performance anode materials for lithium ion batteries",2017,"Journal of Energy Chemistry",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014130203&doi=10.1016%2fj.jechem.2017.02.001&partnerID=40&md5=4b075de729606f86e7f98bab37f4694e","Nanostructured metal oxides derived from metal organic frameworks have been shown to be promising materials for application in high energy density lithium ion batteries. In this work, porous nanostructured ZnCo2O4 and Co3O4 were synthesized by a facile and cost-effective approach via the calcination of MOF-74 precursors and tested as anode materials for lithium ion batteries. Compared with Co3O4, the electrochemical properties of the obtained porous nanostructured ZnCo2O4 exhibit higher specific capacity, more excellent cycling stability and better rate capability. It demonstrates a reversible capacity of 1243.2 mAh/g after 80 cycles at 100 mA/g and an excellent rate performance with high average discharge specific capacities of 1586.8, 994.6, 759.6 and 509.2 mAh/g at 200, 400, 600 and 800 mA/g, respectively. The satisfactory electrochemical performances suggest that this porous nanostructured ZnCo2O4 is potentially promising for application as an efficient anode material for lithium ion batteries. © 2017 Science Press","Anodes; Lithium ion batteries; Metal-organic frameworks; Porous ZnCo2O4","Anodes; Cost effectiveness; Crystalline materials; Electric batteries; Electric discharges; Electrodes; Ions; Java programming language; Lithium; Lithium alloys; Lithium compounds; Organometallics; Secondary batteries; Cost-effective approach; Discharge specific capacity; Electrochemical performance; High energy densities; High-performance anode materials; Metal organic framework; Nanostructured metals; Porous ZnCo<sub>2</sub>O<sub>4</sub>; Lithium-ion batteries",2-s2.0-85014130203
"Pet’kov V.I., Alekseev A.A., Asabina E.A., Borovikova E.Y., Koval’skii A.M.","Synthesis, structure formation, and thermal expansion of A+M2+MgE4+(PO4)3",2017,"Russian Journal of Inorganic Chemistry",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026814728&doi=10.1134%2fS0036023617070178&partnerID=40&md5=bfbcca9bcf99677323de2febff178b54","The compounds AMMgE(PO4)3 (A = Na, K, Rb, Cs; M = Sr, Pb, Ba; E = Ti, Zr) were synthesized by the sol–gel procedure followed by heat treatment and studied by X-ray diffraction, differential thermal and electron microprobe analysis, and IR spectroscopy. The phosphates crystallize in the kosnarite (KZr2(PO4)3, space group R3 ¯) and langbeinite (K2Mg2(SO4)3, space group P213) structural types. The structure of KPbMgTi(PO4)3 was refined by full-profile analysis (space group P213, Z = 4, a = 9.8540(3) Å, V = 956.83(4) Å3). The structure is formed by a framework of vertex-sharing MgO6 and TiO6 octahedra and PO4 tetrahedra. The K and Pb atoms fully occupy the extra-framework cavities and are coordinated to nine oxygen atoms. A variable-temperature X-ray diffraction study of KPbMgTi(PO4)3 showed that the compound expands isotropically and refer to medium-expansion class (linear thermal expansion coefficients αa = αb = αc = 8 × 10–6°C–1). The number of stretching and bending modes of the PO4 tetrahedron observed in the IR spectra is in agreement with that predicted by the factor group analysis of vibrations for space groups R3 ¯ and P213. A structural transition from the cubic langbeinite to the rhombohedral kosnarite was found for CsSrMgZr(PO4)3. In the morphotropic series of ASrMgZr(PO4)3 (A = Na, K, Rb, Cs) the kosnarite–langbeinite transition occurs upon the Na → K replacement. The effect of the sizes and electronegativities of cations combined in AMMgE(PO4)3 on the change of the structural type was analyzed. © 2017, Pleiades Publishing, Ltd.",,"C (programming language); Cesium; Electron probe microanalysis; Expansion; Geometry; Lead; Lead compounds; Microanalysis; Sodium compounds; Sols; Structural analysis; Vibration analysis; X ray diffraction; Differential thermals; Factor group analysis; Full profile analysis; Linear thermal expansion coefficients; Structural transitions; Structure formations; Variable temperature; X-ray diffraction studies; Thermal expansion",2-s2.0-85026814728
"Hibino Y., Ikeo H., Ishiura N.","CF3: Test suite for arithmetic optimization of C compilers",2017,"IEICE Transactions on Fundamentals of Electronics, Communications and Computer Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021817677&doi=10.1587%2ftransfun.E100.A.1511&partnerID=40&md5=bbc462d054c6e7b7fe9495731dccb2e5","This letter presents a test suite CF3 designed to find bugs in arithmetic optimizers of C compilers. It consists of 13,720 test programs containing all the expression patterns covering all the permutations of 3 operators from 14 operators. CF3 detected more than 70 errors in GCC 4.2-4.5 within 2 hours. Copyright © 2017 The Institute of Electronics, Information and Communication Engineers.","Arithmetic optimization; C compiler test suite","Program compilers; C compilers; Expression patterns; Optimizers; Test program; C (programming language)",2-s2.0-85021817677
"Bacani R., Toscani L.M., Martins T.S., Fantini M.C.A., Lamas D.G., Larrondo S.A.","Synthesis and characterization of mesoporous NiO2/ZrO2-CeO2 catalysts for total methane conversion",2017,"Ceramics International",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015667903&doi=10.1016%2fj.ceramint.2017.03.101&partnerID=40&md5=8e9f13c50a727b267856e670cd507352","This work reports the synthesis and characterization of mesoporous NiO/ZrO2 -CeO2 composites. These materials are still being developed due to their excellent morphological and structural properties, especially for solid oxide fuel cells (SOFCs) anodes. A soft chemical route using a polymeric template was utilized to synthesize the samples. The structure after two different calcination processes at 400 °C and 540 °C was studied by X-ray diffraction and Rietveld refinement, before and after NiO loading. Nitrogen adsorption, scanning/transmission electron microscopy and small angle X-ray scattering revealed a nanocrystalline bi-phasic porous material. Temperature programmed reduction experiments showed higher Ni and Ce reduction values for samples calcined at 400 °C and 540 °C, respectively. Methane conversion values in the temperature range studied were similar for both calcination temperatures, showing 50% CH4 conversion around 550 °C and 80% around 650 °C. However, a sample calcined at 400 °C exhibited better morphological and textural properties leading to an enhancement in NiO and CeO2 reducibility that might be responsible for an improvement in oxygen surface exchange and gasification of carbon species in catalytic experiments. © 2017 Elsevier Ltd and Techna Group S.r.l.","Anodes; Ceria; Methane oxidation; Nickel; SOFC; Zirconia","Anodes; Calcination; Carbon; Cerium compounds; Characterization; Electrodes; Fuel cells; Gas adsorption; Methane; Nanocrystalline materials; Nanocrystals; Nickel; Porous materials; Rietveld refinement; Scanning electron microscopy; Solid oxide fuel cells (SOFC); X ray diffraction; X ray scattering; Zirconia; Calcination temperature; Gasification of carbon; Methane oxidation; Oxygen surface exchange; Soft-chemical route; Solid oxide fuel cells (SOFCs); Synthesis and characterizations; Temperature-programmed reduction; C (programming language)",2-s2.0-85015667903
"Malhotra G., Kalayappan R., Goel S., Aggarwal P., Sagar A., Sarangi S.R.","ParTejas: A parallel simulator for multicore processors",2017,"ACM Transactions on Modeling and Computer Simulation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027396563&doi=10.1145%2f3077582&partnerID=40&md5=c0262ff26441780da833ecf92d99bc05","In this article, we present the design of a novel parallel architecture simulator called ParTejas. ParTejas is a timing simulation engine that gets its execution traces from instrumented binaries using a fast sharedmemory- based mechanism. Subsequently, the waiting threads simulate the execution of multiple pipelines and an elaborate memory system with support for multilevel coherent caches. ParTejas is written in Java and primarily derives its speedups from the use of novel data structures. Specifically, it uses lock-free slot schedulers to design an entity called a parallel port that effectively models the contention at shared resources in the CPU and memory system. Parallel ports remove the need for fine-grained synchronization and allow each thread to use its local clock. Unlike conventional simulators that use barriers for synchronization at epoch boundaries, we use a sophisticated type of barrier, known as a phaser. A phaser allows threads to perform additional work without waiting for other threads to arrive at the barrier. Additionally, we use a host of Java-specific optimizations and use profiling to effectively schedule the threads. With all our optimizations, we demonstrate a speedup of 11.8× for a multi-issue in-order pipeline and 10.9× for an out-of-order pipeline with 64 threads, for a suite of seven Splash2 and Parsec benchmarks. The simulation error is limited to 2% to 4% as compared to strictly sequential simulation. © 2017 ACM.","Architectural simulator; parallel ports; Parallel simulation; ParTejas; phasers; slot scheduling; Tejas","Cache memory; Integrated circuit design; Java programming language; Pipelines; Scheduling; Simulators; Architectural simulators; Parallel port; Parallel simulations; ParTejas; phasers; Slot scheduling; Tejas; Parallel architectures",2-s2.0-85027396563
"Williams E.D., Stebbins M.J., Cavanagh P.R., Haynor D.R., Chu B., Fassbind M.J., Isvilanonda V., Ledoux W.R.","A preliminary study of patient-specific mechanical properties of diabetic and healthy plantar soft tissue from gated magnetic resonance imaging",2017,"Proceedings of the Institution of Mechanical Engineers, Part H: Journal of Engineering in Medicine",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021820588&doi=10.1177%2f0954411917695849&partnerID=40&md5=9e817d6e9a7e7e4269b682553a0a6b1d","Foot loading rate, load magnitude, and the presence of diseases such as diabetes can all affect the mechanical properties of the plantar soft tissues of the human foot. The hydraulic plantar soft tissue reducer instrument was designed to gain insight into which variables are the most significant in determining these properties. It was used with gated magnetic resonance imaging to capture three-dimensional images of feet under dynamic loading conditions. Custom electronics controlled by LabVIEW software simultaneously recorded system pressure, which was then translated to applied force values based on calibration curves. Data were collected for two subjects, one without diabetes (Subject A) and one with diabetes (Subject B). For a 0.2-Hz loading rate, and strains 0.16, 0.18, 0.20, and 0.22, Subject A's average tangential heel pad stiffness was 10 N/mm and Subject B's was 24 N/mm. Maximum test loads were approximately 200 N. Loading rate and load magnitude limitations (both were lower than physiologic values) will continue to be addressed in the next version of the instrument. However, the current hydraulic plantar soft tissue reducer did produce a data set for healthy versus diabetic tissue stiffness that agrees with previous trends. These data are also being used to improve finite element analysis models of the foot as part of a related project. © Institution of Mechanical Engineers 2017.","diabetes; Heel pad; magnetic resonance imaging compatible; mechanical properties; patient-specific","Biomechanics; Computer programming languages; Dynamic loads; Finite element method; Loads (forces); Magnetic resonance imaging; Magnetism; Mechanical properties; Medical problems; Resonance; Stiffness; Calibration curves; Dynamic loading conditions; Finite element analysis model; Heel pads; Lab-view softwares; Patient specific; Three dimensional images; Tissue stiffness; Tissue",2-s2.0-85021820588
"Guan Y., Li J., Liu Y.","Ablation characteristics and reaction mechanism of insulation materials under slag deposition condition",2017,"Acta Astronautica",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015065319&doi=10.1016%2fj.actaastro.2017.02.001&partnerID=40&md5=477a89a24daddf1e549f6f7fa8c5c54f","Current understanding of the physical and chemical processes involved in the ablation of insulation materials by highly aluminized solid propellants is limited. The study on the heat transfer and ablation principle of ethylene propylene diene monomer (EPDM) materials under slag deposition condition is essential for future design or modification of large solid rocket motors (SRMs) for launch application. In this paper, the alumina liquid flow pattern and the deposition principle in full-scale SRM engines are discussed. The interaction mechanism between the alumina droplets and the wall are analyzed. Then, an experimental method was developed to simulate the insulation material ablation under slag deposition condition. Experimental study was conducted based on a laboratory-scale device. Meanwhile, from the analysis of the cross-sectional morphology and chemical composition of the charring layer after ablation, the reaction mechanism of the charring layer under deposition condition was discussed, and the main reaction equation was derived. The numerical simulation and experimental results show the following. (i) The alumina droplet flow in the deposition section of the laboratory-scale device is similar to that of a full-scale SRM. (ii) The charring layer of the EPDM insulator displays a porous tight/loose structure under high-temperature slag deposition condition. (iii) A seven-step carbothermal reduction in the alumina is derived and established under high-pressure and high-temperature environment in the SRM combustion chamber. (iv) The analysis using thermodynamic software indicates that the reaction of the alumina and charring layer initially forms Al4C3 during the operation. Then, Al element and Al2OC compound are subsequently produced with the reduction in the release of gas CO as well with continuous environmental heating. © 2017","Ablation; Deposition; EPDM insulator; Laboratory-scale device; Solid rocket motor (SRM)","Ablation; Alumina; Aluminum; C (programming language); Carbothermal reduction; Chemical analysis; Combustion chambers; Drops; Ethylene; Flow patterns; Heat transfer; Insulating materials; Insulation; Permafrost; Reluctance motors; Rocket engines; Rockets; Slags; Solid propellants; Aluminized solid propellants; Cross-sectional morphology; EPDM insulator; Ethylene propylene diene monomer; High pressure and high temperature; Interaction mechanisms; Laboratory-scale devices; Solid rocket motors; Deposition",2-s2.0-85015065319
"Askari H., Ghaedi M., Dashtian K., Azghandi M.H.A.","Rapid and high-capacity ultrasonic assisted adsorption of ternary toxic anionic dyes onto MOF-5-activated carbon: Artificial neural networks, partial least squares, desirability function and isotherm and kinetic study",2017,"Ultrasonics Sonochemistry",7,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008319363&doi=10.1016%2fj.ultsonch.2016.10.029&partnerID=40&md5=2fa901f555f3f124c2341eea1f93f20e","The present paper focused on the ultrasonic assisted simultaneous removal of fast green (FG), eosin Y (EY) and quinine yellow (QY) from aqueous media following using MOF-5 as a metal organic framework and activated carbon hybrid (AC-MOF-5). The structure and morphology of AC-MOF-5 was identified by SEM, FTIR and XRD analysis. The interactive and main effects of variables such as pH, initial dyes concentration (mg L−1), adsorbent dosage (mg) and sonication time (min) on removal percentage were studied by central composite design (CCD), subsequent desirability function (DF) permit to achieved real variable experimental condition. Optimized values were found 7.06, 5.68, 7.59 and 5.04 mg L−1, 0.02 g and 2.55 min for pH, FG, EY and QY concentration, adsorbent dosage and sonication time, respectively. Under this conditions removal percentage were obtained 98.1%, 98.1% and 91.91% for FG, EY and QY, respectively. Two models, namely partial least squares (PLS) and multi-layer artificial neural network (ANN) model were used for building up to construct an empirical model to predict the dyes under study removal behavior. The obtained results show that ANN and PLS model is a powerful tool for prediction of under-study dyes adsorption by AC-MOF-5. The evaluation and estimation of equilibrium data from traditional isotherm models display that the Langmuir model indicated the best fit to the equilibrium data with maximum adsorption capacity of 21.230, 20.242 and 18.621 mg g−1, for FG, EY and QY, respectively, while the adsorption rate efficiently follows the pseudo-second-order model. © 2016 Elsevier B.V.","Artificial neural network; Eosin Y; Fast green; MOF-5; Quinine yellow; Ultrasonic assisted adsorption","Activated carbon; Adsorption; Chemicals removal (water treatment); Crystalline materials; Dyes; Isotherms; Java programming language; Least squares approximations; Network layers; Neural networks; Organometallics; Artificial neural network models; Central composite designs; Eosin Y; Fast green; MOF-5; Partial least square (PLS); Pseudo-second order model; Quinine yellow; Stripping (dyes); activated carbon; anion; dye; eosin; malachite green; metal organic framework; quinine yellow; terephthalic acid; unclassified drug; zinc ion; adsorption; aqueous solution; Article; artificial neural network; back propagation; infrared spectroscopy; isotherm; partial least squares regression; perceptron; pH; priority journal; scanning electron microscopy; surface area; ultrasound; water treatment; X ray diffraction",2-s2.0-85008319363
"Du S., Shi X., Ge Y.","Electron probe microanalysis investigation into high-volume fly ash mortars",2017,"Journal of Materials in Civil Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018879387&doi=10.1061%2f%28ASCE%29MT.1943-5533.0001854&partnerID=40&md5=c2893120e919598260e246dcd9942ef6","High-volume fly ash (HVFA) concrete has been widely investigated because of its lower carbon footprint and higher performance than the conventional portland cement concrete. In this work, a total of 21 HVFA mortar mixtures were fabricated using Class C fly ash, limestone powder, asphalt emulsion, and portland cement following a Box-Wilson central composite design scheme. The compressive strength and spitting tensile strength of these mortar specimens were tested at various ages. Based on the results of mechanical test, three representative mixtures were selected for water sorptivity test, surface resistivity test, and electron probe microanalyzer (EPMA) study. HVFA mortars with higher fly ash replacement and higher water to binder (w/b) ratio exhibited higher water absorptivity and lower surface resistivity. With secondary electron imaging (SEI) and back-scattered electron imaging (BSE), the micrographs of three selected HVFA mortars were examined, while the hydration behavior of fly ash particles in them was elucidated through the element mapping and element ratio mapping enabled by EPMA. © 2016 American Society of Civil Engineers.","Electron probe microanalyzer (EPMA); Element mapping; Element ratio mapping; High-volume fly ash","Asphalt mixtures; C (programming language); Carbon; Carbon footprint; Cements; Compressive strength; Concrete beams and girders; Concretes; Electron probe microanalysis; Electrons; Emulsification; Mapping; Mixtures; Mortar; Portland cement; Probes; Secondary emission; Tensile strength; Backscattered electron imaging; Central composite designs; Electron probe micro analyzer; Element mapping; Element ratios; High volume fly ash; Portland cement concretes; Secondary electron imaging; Fly ash; compressive strength; concrete; electron probe analysis; fly ash; mortar; tensile strength",2-s2.0-85018879387
"Haque A., Khan I., Hassan S.I., Khan M.S.","Interaction studies of cholinium-based ionic liquids with calf thymus DNA: Spectrophotometric and computational methods",2017,"Journal of Molecular Liquids",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017962219&doi=10.1016%2fj.molliq.2017.04.068&partnerID=40&md5=fc70981c845b40599b3cd0a1cf467ae2","Ionic liquids (ILs) are emerging class of low-melting solid which have potential to replace conventional solvents. DNA is one of the primary targets of many synthetic agents which are classified as carcinogens; most of them bind to the DNA irreversibly causing mutation of the genome. Thus, it is essential to study the nature and mode of binding of new molecules to predict its toxicity. In the present study, we carried out photo-physical and computational studies on interaction of aqueous cholinium-based ILs (cholinium chloride, cholinium dihydrogen citrate, cholinium bicarbonate, cholinium bromide) with calf thymus DNA (ct-DNA). The experimental (absorption and fluorescence) and docking studies indicated weak interaction between the cholinium-based ILs and double stranded ct-DNA, mainly through minor grooves. Since the strength of binding was quite weak, a safe nature of cholinium-based ILs could be expected. However, COSMO-RS studied carried out using individual DNA bases (A, T, G & C) and cholinium-based ILs showed propensity of the latter class of chemicals with the biomolecules. © 2017 Elsevier B.V.","COSMO-RS; DNA; Docking; Ionic liquids; Photo-physical studies","Bins; C (programming language); DNA; Docking; Ionic liquids; Liquids; Thymus; Calf thymus DNA (ct-DNA); Computational studies; COSMO-RS; Interaction studies; Ionic liquid (ils); Photo-physical studies; Synthetic agents; Weak interactions; Biomolecules",2-s2.0-85017962219
"Gao W., Han J.","Minimum Codegree Threshold for C6 3-Factors in 3-Uniform Hypergraphs",2017,"Combinatorics Probability and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015801127&doi=10.1017%2fS0963548317000104&partnerID=40&md5=c48de57e8c2add620646ced35279c5c9","Let C6 3 be the 3-uniform hypergraph on {1,..., 6} with edges 123,345,561, which can be seen as the analogue of the triangle in 3-uniform hypergraphs. For sufficiently large n divisible by 6, we show that every n-vertex 3-uniform hypergraph H with minimum codegree at least n/3 contains a C6 3-factor, that is, a spanning subhypergraph consisting of vertex-disjoint copies of C6 3. The minimum codegree condition is best possible. This improves the asymptotic result obtained by Mycroft and answers a question of Rödl and Ruciński exactly. © 2017 Cambridge University Press.",,"Graph theory; 3-uniform hypergraphs; Asymptotic results; Hypergraph; Large N; Vertex disjoint; C (programming language)",2-s2.0-85015801127
"Chalmers B.A., Alzahrani A., Hawkins G., Aldabbagh F.","Efficient synthesis and RAFT polymerization of the previously elusive N-[(cycloalkylamino)methyl]acrylamide monomer class",2017,"Journal of Polymer Science, Part A: Polymer Chemistry",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018254205&doi=10.1002%2fpola.28607&partnerID=40&md5=a0fec81149b4c5dac143524abed0bb53",">A new facile room temperature protocol allowed the efficient multigram preparation of acrylamides 1a-1c with methylene Saturated nitrogen heterocycle (SNH) substituents via basification of the respective heterocyclic monomer hydrochloride salts 1a.HCl–1c.HCl. The expedient synthesis motivated researchers to carry out the first controlled/living polymerizations of this previously elusive monomer class, as well as, its hydrochloride salts using the radical polymerization (RAFT) process. Aminals were quaternized using acetyl chloride in dry acetonitrile, which formed in situ the methylene Schiff base salts, along with the N-acetyl cycloamine.","block copolymers; heterocycles; living polymerization; reversible deactivation radical polymerization; Schiff base","Acrylic monomers; Atom transfer radical polymerization; Block copolymers; C (programming language); Monomers; Salts; Synthesis (chemical); Controlled/living polymerization; Efficient synthesis; Heterocycles; Heterocyclic monomers; Nitrogen heterocycles; RAft polymerization; Schiff-base; Temperature protocol; Living polymerization",2-s2.0-85018254205
"Mahdavi S., Maghsoudi Y., Amani M.","Effects of changing environmental conditions on synthetic aperture radar backscattering coefficient, scattering mechanisms, and class separability in a forest area",2017,"Journal of Applied Remote Sensing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028573710&doi=10.1117%2f1.JRS.11.036015&partnerID=40&md5=d6ec5fae6ce7c73a605e460974bcfa02","Environmental conditions have considerable effects on synthetic aperture radar (SAR) imagery. Therefore, assessing these effects is important for obtaining accurate and reliable results. In this study, three series of RADARSAT-2 SAR images were evaluated. In each of these series, the sensor configuration was fixed, but the environmental conditions differed. The effects of variable environmental conditions were also investigated on co- and crosspolarized backscattering coefficients, Freeman-Durden scattering contributions, and the pedestal height in different classes of a forest area in Ottawa, Ontario. It was observed that the backscattering coefficient of wet snow was up to 2 dB more than that of dry snow. The absence of snow also caused a decrease of up to 3 dB in the surface scattering of ground and up to 5 dB in that of trees. In addition, the backscatter coefficients of ground vegetation, hardwood species, and softwood species were more similar at temperatures below 0°C than those at temperatures above 0°C. Moreover, the pedestal height was generally greater at temperatures above 0°C than at temperatures below 0°C. Finally, the highest class separability was observed when the temperature was at or above 0°C and there was no snow on the ground or trees. © 2017 Society of Photo-Optical Instrumentation Engineers (SPIE).","backscattering coefficient; environmental effects; scattering mechanism; synthetic aperture radar; synthetic aperture radar classification","Backscattering; C (programming language); Environmental impact; Forestry; Hardwoods; Radar; Radar imaging; Snow; Surface scattering; Backscatter coefficients; Backscattering coefficients; Class separability; Environmental conditions; Scattering mechanisms; Sensor configurations; Synthetic aperture radar backscatterings; Synthetic Aperture Radar Imagery; Synthetic aperture radar",2-s2.0-85028573710
"Liu H.-B., Liu J.-H., Shen S.-B., Wu B.-W., Ding H., Su X.-F.","Influence of Al content on the characteristics of non-metallic inclusions and precipitation behaviors of AlN inclusions in TWIP steel",2017,"Gongcheng Kexue Xuebao/Chinese Journal of Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029821516&doi=10.13374%2fj.issn2095-9389.2017.07.005&partnerID=40&md5=4cc1dabc8fa3b19d1baf6b5031bbc95a","The morphology, composition, and number of inclusions in Fe-Mn-C(-Al) twining-induced plasticity (TWIP) steels were investigated by scanning electron microscopy, energy-dispersive X-ray spectroscopy, and an automated program called “INCAFeature.” The characteristics of the inclusions in four TWIP steels with different Al contents (0.002%-1.590%) as well as the influence of Al content on the precipitation of AlN inclusions were investigated. In addition, systematic thermodynamics calculations of AlN formed in TWIP steel were carried out using the appropriate thermodynamic data for high-Mn-Al TWIP steel. The results show that AlN would begin to precipitate and locally precipitate around the MnS(Se)-Al2O3 inclusions when the Al content in the steel reaches 0.75%. The thermodynamics calculations show that AlN could already form in the liquid TWIP steel at an Al content of 1.07%. Then, AlN would locally precipitate around the MnS(Se) inclusions, thus forming MnS(Se)-AlN aggregates. When the Al content increases to 1.59%, the precipitation temperature of AlN is 42℃ higher than the liquidus temperature of the TWIP steel. Furthermore, precipitated AlN inclusions in the liquid TWIP steel could act as heterogeneous nuclei for MnS(Se) inclusions, thus forming MnS(Se)-AlN inclusions. Moreover, according to the thermodynamics calculation, the lowest N content for AlN formation in the liquid Fe-18.21%Mn-0.64%C-1.59%Al steel is just 0.0043%. Therefore, the N content should be kept as low as possible to avoid the formation of excessive AlN inclusions during melting of Fe-Mn-C(-Al) TWIP steel. © All right reserved.","Aluminum content; Inclusions; Precipitation behaviors; Thermodynamics; TWIP steel","Aluminum; Aluminum nitride; C (programming language); Energy dispersive spectroscopy; Inclusions; Liquids; Manganese; Scanning electron microscopy; Steel; Thermodynamics; X ray spectroscopy; Aluminum contents; Energy dispersive X ray spectroscopy; Heterogeneous nucleus; Non-metallic inclusions; Precipitation behavior; Precipitation temperature; Thermodynamics calculations; TWIP steel; Plasticity",2-s2.0-85029821516
"Choi J.-J., Lee K.-H.","Lightweight sidewalk with recycled woodchip and low-VOC urethane resin",2017,"Journal of Materials in Civil Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018876111&doi=10.1061%2f%28ASCE%29MT.1943-5533.0001847&partnerID=40&md5=d5a2670150ddcb7ed3ccfc2d1eecac7e","The conventional resin used for woodchip sidewalks contains a significant amount of volatile organic compounds (VOCs), and the potential of air pollution could be high due to the release of VOC materials during the sidewalk's construction. In this paper, a brand new polyurethane resin binder with low VOC levels was developed and used as a binder. Laboratory tests for its flammability, elasticity, permeability, and tensile strength, and as well as tests for freeze and thaw, skid resistance, and field construction, were conducted. The nonvolatile fraction of the newly synthesized resin was measured at approximately 98.8%, whereas that of the previous resin was approximately 93.5%. The measured tensile strength ratios of the woodchip mixtures satisfied guidelines for freeze and thaw. The measured critical heat flux at extinguishment (CFE) satisfied Class C of European flame standards. The permeability remained the same with curing time after field construction. The elasticity of the woodchip pavement increased as time passed due to the hardening of the urethane resin. The woodchip pavement using Resins 2 and 3 satisfied the standard specification of skid resistance. © 2016 American Society of Civil Engineers.","Flammability; Permeability; Sidewalk; Tensile strength; Volatile organic compounds; Woodchip","Air quality; Binders; Bins; C (programming language); Elasticity; Esters; Flame hardening; Flammability; Heat flux; Mechanical permeability; Organic compounds; Pavements; Resins; Skid resistance; Thawing; Volatile organic compounds; Laboratory test; Nonvolatile fraction; Sidewalk; Standard specifications; Synthesized resins; Tensile strength ratios; Urethane resins; Wood chip; Tensile strength; atmospheric pollution; elasticity; pavement; permeability; resin; tensile strength; volatile organic compound",2-s2.0-85018876111
"Fu K., Gu I.Y.-H., Yang J.","Saliency detection by fully learning a continuous conditional random field",2017,"IEEE Transactions on Multimedia",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021270908&doi=10.1109%2fTMM.2017.2679898&partnerID=40&md5=b397847ec595952a4a149cbe3feb6b0c","Salient object detection is aimed at detecting and segmenting objects that human eyes are most focused on when viewing a scene. Recently, conditional random field (CRF) is drawn renewed interest, and is exploited in this field. However, when utilizing a CRF with unary and pairwise potentials having essential parameters, most existing methods only employ manually designed parameters, or learn parameters partly for the unary potentials. Observing that the saliency estimation is a continuous labeling issue, this paper proposes a novel data-driven scheme based on a special CRF framework, the so-called continuous CRF (C-CRF), where parameters for both unary and pairwise potentials are jointly learned. The proposed C-CRF learning provides an optimal way to integrate various unary saliency features with pairwise cues to discover salient objects. To the best of our knowledge, the proposed scheme is the first to completely learn a C-CRF for saliency detection. In addition, we propose a novel formulation of pairwise potentials that enables learning weights for different spatial ranges on a superpixel graph. The proposed C-CRF learning-based saliency model is tested on 6 benchmark datasets and compared with 11 existing methods. Our results and comparisons have provided further support to the proposed method in terms of precision-recall and F-measure. Furthermore, incorporating existing saliency models with pairwise cues through the C-CRF are shown to provide marked boosting performance over individual models. © 1999-2012 IEEE.","Continuous conditional random field (C-CRF); feature integration; learning; saliency map; salient object detection; spatial ranges","C (programming language); Education; Image segmentation; Object detection; Object recognition; Conditional random field; Feature integration; learning; Saliency map; Salient object detection; spatial ranges; Random processes",2-s2.0-85021270908
"Ma C., Wang Q., Zhao M.","LDPC codes based on the space of symmetric matrices over finite fields",2017,"IEEE Transactions on Information Theory",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025438540&doi=10.1109%2fTIT.2017.2685501&partnerID=40&md5=50649e42d6c4581c616caa5994e07231","In this paper, we present a new method for explicitly constructing regular low-density parity-check (LDPC) codes based on Sn(Fq), the space of n × n symmetric matrices over Fq . Using this method, we obtain two classes of binary LDPC codes, C(n, q) and CT (n, q), both of which have grith 8. Then, both the minimum distance and the stopping distance of each class are investigated. It is shown that the minimum distance and the stopping distance of CT (n, q) are both 2q. As for C(n, q), we determine the minimum distance and the stopping distance for some special cases and obtain some lower bounds for other cases. © 2017 IEEE.","LDPC code; Minimum distance; Stopping distance; Symmetric matrix","Codes (symbols); Forward error correction; Matrix algebra; Finite fields; LDPC codes; Low-density parity-check (LDPC) codes; Lower bounds; Minimum distance; Stopping distance; Symmetric matrices; C (programming language)",2-s2.0-85025438540
"McEwan A.A., Komsul M.Z.","Reliability and performance enhancements for SSD RAID",2017,"Microprocessors and Microsystems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008423097&doi=10.1016%2fj.micpro.2016.11.012&partnerID=40&md5=c7bf3e7f2b9187ff637a49c560b86c42","NAND based solid state storage devices are almost ubiquitously used in safety-critical embedded devices, and recent advances have demonstrated RAID architectures specific to solid state storage devices resulting in increased data reliability, with architectural enhancements to solve the age convergence problem. However, these techniques require devices to be taken off-line while components are replaced—consequently these devices are of limited use in hard real time systems. There are further real time issues in that the conventional architectures ignore other characteristics of solid state devices such as garbage collection and meta data management. In this paper we investigate techniques that support the replacement of aged devices in the array in such a way that we provide continuous system reliability. We also improve the performance overhead of the reconstruction process using a novel data migration policy. The techniques are implemented and tested in a trace-driven simulator, and results demonstrate that average I/O response time is improved by up to 39% with improvement by up to 45% in its standard deviation, overheads in terms of device replacement time are negligible, and read performance is improved by an average of 8%. © 2016 Elsevier B.V.","Hotswapping and data migration; Parity distribution; Real time storage; SSD garbage collection; SSD RAID; SSD RAID architecture","Digital storage; Information management; Interactive computer systems; Java programming language; Refuse collection; Reliability; Safety engineering; Solid state devices; Virtual storage; Data migration; Garbage collection; Parity distribution; Real time; SSD RAID; Real time systems",2-s2.0-85008423097
"Borodin A., Jain A., Lee H.C., Ye Y.","Max-sum diversification, monotone submodular functions, and dynamic updates",2017,"ACM Transactions on Algorithms",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026527724&doi=10.1145%2f3086464&partnerID=40&md5=dd3a166e2f0c2b8d75487df466d64d41","Result diversification is an important aspect in web-based search, document summarization, facility location, portfolio management, and other applications. Given a set of ranked results for a set of objects (e.g., web documents, facilities, etc.) with a distance between any pair, the goal is to select a subset S satisfying the following three criteria: (a) the subset S satisfies some constraint (e.g., bounded cardinality), (b) the subset contains results of high “quality,” and (c) the subset contains results that are “diverse” relative to the distance measure. The goal of result diversification is to produce a diversified subset while maintaining high quality as much as possible. We study a broad class of problems where the distances are a metric, where the constraint is given by independence in a matroid, where quality is determined by a monotone submodular function and diversity is defined as the sum of distances between objects in S. Our problem is a generalization of the max-sum diversification problem studied in Gollapudi and Sharma [2009], which in turn is a generalization of the max-sum p-dispersion problem studied extensively in location theory. It is NP-hard even with the triangle inequality. We propose two simple and natural algorithms: a greedy algorithm for a cardinality constraint and a local search algorithm for an arbitrary matroid constraint. We prove that both algorithms achieve constant approximation ratios. © 2017 ACM","Dispersion; Diversification; Greedy algorithms; Local search; Submodular functions","C (programming language); Combinatorial mathematics; Dispersion (waves); Dispersions; Financial data processing; Investments; Local search (optimization); Set theory; Cardinality constraints; Diversification; Document summarization; Greedy algorithms; Local search; Local search algorithm; Portfolio managements; Submodular functions; Approximation algorithms",2-s2.0-85026527724
"Alahmadi A., Glasby S.P., Praeger C.E., Solé P., Yildiz B.","Twisted centralizer codes",2017,"Linear Algebra and Its Applications",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015453641&doi=10.1016%2fj.laa.2017.03.011&partnerID=40&md5=a5c353c1e58073b08a42cadcb3f2fa9f","Given an n×n matrix A over a field F and a scalar a∈F, we consider the linear codes C(A,a):={B∈Fn×n|AB=aBA} of length n2. We call C(A,a) a twisted centralizer code. We investigate properties of these codes including their dimensions, minimum distances, parity-check matrices, syndromes, and automorphism groups. The minimal distance of a centralizer code (when a=1) is at most n, however for a≠0,1 the minimal distance can be much larger, as large as n2. © 2017","Group centralizers; Linear codes; Matrix codes; Minimal distance","Codes (symbols); Matrix algebra; Turbo codes; Automorphism groups; Group centralizers; Linear codes; Matrix codes; Minimal distance; Minimum distance; N-matrix; Parity check matrices; C (programming language)",2-s2.0-85015453641
"Zhao Q., Wang C., Guo J., Yang G., Liao M., Ma H., Liu J.","Enhanced orbit determination for BeiDou satellites with FengYun-3C onboard GNSS data",2017,"GPS Solutions",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011597257&doi=10.1007%2fs10291-017-0604-y&partnerID=40&md5=5b43afb5d1be55734b577439cf7a70fe","A key limitation for precise orbit determination of BeiDou satellites, particularly for satellites in geostationary orbit (GEO), is the relative weak geometry of ground stations. Fortunately, data from a low earth orbiting satellite with an onboard GNSS receiver can improve the geometry of GNSS orbit determination compared to using only ground data. The Chinese FengYun-3C (FY3C) satellite carries the GNSS Occultation Sounder equipment with both dual-frequency GPS (L1 and L2) and BeiDou (B1 and B2) tracking capacity. The satellite-induced variations in pseudoranges have been estimated from multipath observables using an elevation-dependent piece-wise linear model, in which the constant biases, i.e., ambiguities and hardware delays, have been removed. For IGSO and MEO satellites, these variations can be seen in onboard B1 and B2 code measurements with elevation above 40°. For GEO satellites, a different behavior has been observed for these signals. The GEO B2 pseudoranges variations are similar to those of IGSO satellites, but no elevation-dependent variations have been identified for GEO B1. A possible cause is contamination of the larger noise in GEO B1 signals. Two sets of precise orbits were determined for FY3C in March 2015 using onboard GPS-only data and onboard BeiDou-only data, respectively. The 3D RMS (Root Mean Square) of overlapping orbit differences (OODs) is 2.3 cm for GPS-only solution. The 3D RMS of orbit differences between BeiDou-only and GPS-only solutions is 15.8 cm. Also, precise orbits and clocks for BeiDou satellites were determined based on 97 global (termed GN) or 15 regional (termed RN) ground stations. Furthermore, also using FY3C onboard BeiDou data, two additional sets of BeiDou orbit and clock products are determined with the data from global (termed GW) or regional (termed RW) stations. In general, the OODs decrease for BeiDou satellites, particularly for GEO satellites, when the FY3C onboard BeiDou data are added. The 3D OODs reductions are 10.0 and 291.2 cm for GW and RW GEO solution with respect to GN and RN solution, respectively. Since the OODs in the along-track direction dominate the OODs reduction, no improvement has been observed by satellite laser ranging, which mainly validates the accuracy of the radial orbital component. With the GW BeiDou orbit and clock products, the FY3C orbits determined with onboard BeiDou-only data also show improvement in comparison with those determined with BeiDou GN products. © 2017, The Author(s).","BeiDou; Code measurement; FengYun-3C; Multipath combination; Precise orbit determination","C (programming language); Clocks; Geostationary satellites; Global positioning system; Radio navigation; Satellite ground stations; Satellites; Tracking (position); BeiDou; Geostationary orbits; Low earth orbiting satellites; Multipath; Orbit determination; Piecewise linear models; Precise orbit determination; Satellite laser ranging; Orbits; BDS; elevation; FengYun; geostationary satellite; GNSS; GPS; hardware; orbit determination",2-s2.0-85011597257
"Skibbe H., Reisert M.","Spherical Tensor Algebra: A Toolkit for 3D Image Processing",2017,"Journal of Mathematical Imaging and Vision",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014533844&doi=10.1007%2fs10851-017-0715-7&partnerID=40&md5=b49897686fe31330aafc5394ac10cab2","With the advent of novel 3D image acquisition techniques, their efficient and reliable analysis becomes more and more important. In particular in 3D, the amount of data is enormous and requires for an automated processing. The tasks are manifold, starting from simple image enhancement, image reconstruction, image description and object/feature detection to high-level contextual feature extraction. One important property that most of these tasks have in common is their covariance to rotations. Spherical Tensor Algebra (STA) offers a general framework to fulfill these demands. STA transfers theories from mathematical physics and harmonic analysis into the domain of image analysis and pattern recognition. The main objects of interest are orientation fields. The interpretations of the fields are manifold. Depending on the application, they can represent local image descriptors, features, orientation scores or filter responses. STA deals with the processing of such fields in the domain of the irreducible representations of the rotation group. Two operations are fundamental: the extraction/projection of the features by convolution-like procedures and the nonlinear covariant combination by spherical products. In this paper, we propose an open-source toolbox that implements, in addition to fundamental STA operators, advanced functions for feature detection and image enhancement and makes them accessible to the 3D image processing community. The core features are implemented in C (CPU and GPU) with APIs in C++ and MATLAB. As examples, we show applications for medical and biological images. © 2017, Springer Science+Business Media New York.","3D feature detection; Bi-spectrum; Biomedical 3D image processing; Rotational invariance; Spherical tensors","Algebra; C++ (programming language); Extraction; Feature extraction; Image analysis; Image enhancement; Image reconstruction; Medical imaging; Object detection; Pattern recognition; Spheres; Tensors; Three dimensional computer graphics; 3-D image processing; Bispectrum; Feature detection; Irreducible representations; Local image descriptors; Mathematical physics; Open source toolboxes; Rotational invariances; Image processing",2-s2.0-85014533844
"Wang N., Song W.-L., Hu Z.-C., Ma J.-T.","Development of Test Bench for Measuring Performance of Magneto-Rheological Fluid Brake",2017,"Dongbei Daxue Xuebao/Journal of Northeastern University",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030651413&doi=10.12068%2fj.issn.1005-3026.2017.07.016&partnerID=40&md5=e6f9666e21a5237eb1ae160fcd35b65f","Theoretically, the quality of a vehicle braking system is mainly determined by the performance of brake. In order to coordinate the development of new magneto-rheological(MR) brake, a specific test system is developed and discussed in detail. The test apparatus system consists of measuring module and load applied module. For the system, it is a crucial problem to realize real-time measurement and display of data. Based on the LabVIEW software, the measuring module, including the speed torque sensor and the data acquisition card (DAQ card), is ultimately developed. The test system is validated to be reasonable and practical by the successful application of braking performance tests of MRB. © 2017, Editorial Department of Journal of Northeastern University. All right reserved.","Braking time; Braking torque; MR (magneto-rheological) brake; MR (magneto-rheological) fluid; Test bench","Brakes; Computer programming languages; Data acquisition; Magnetorheological fluids; Testing; Braking torque; Data acquisition cards; Magneto-rheological; Magneto-rheological fluid; Magnetorheological brakes; Measuring performance; Real time measurements; Test benches; Braking performance",2-s2.0-85030651413
"Bobik K., McCray T.N., Ernest B., Fernandez J.C., Howell K.A., Lane T., Staton M., Burch-Smith T.M.","The chloroplast RNA helicase ISE2 is required for multiple chloroplast RNA processing steps in Arabidopsis thaliana",2017,"Plant Journal",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018355422&doi=10.1111%2ftpj.13550&partnerID=40&md5=ae2de4da3f541ab22e5df621ebec0937","INCREASED SIZE EXCLUSION LIMIT2 (ISE2) is a chloroplast-localized RNA helicase that is indispensable for proper plant development. Chloroplasts in leaves with reduced ISE2 expression have previously been shown to exhibit reduced thylakoid contents and increased stromal volume, indicative of defective development. It has recently been reported that ISE2 is required for the splicing of group II introns from chloroplast transcripts. The current study extends these findings, and presents evidence for ISE2's role in multiple aspects of chloroplast RNA processing beyond group II intron splicing. Loss of ISE2 from Arabidopsis thaliana leaves resulted in defects in C-to-U RNA editing, altered accumulation of chloroplast transcripts and chloroplast-encoded proteins, and defective processing of chloroplast ribosomal RNAs. Potential ISE2 substrates were identified by RNA immunoprecipitation followed by next-generation sequencing (RIP-seq), and the diversity of RNA species identified supports ISE2's involvement in multiple aspects of chloroplast RNA metabolism. Comprehensive phylogenetic analyses revealed that ISE2 is a non-canonical Ski2-like RNA helicase that represents a separate sub-clade unique to green photosynthetic organisms, consistent with its function as an essential protein. Thus ISE2's evolutionary conservation may be explained by its numerous roles in regulating chloroplast gene expression. © 2017 The Authors The Plant Journal © 2017 John Wiley & Sons Ltd","Arabidopsis thaliana; chloroplast; ISE2, group II intron; plasmodesmata; ribosome; RNA editing; RNA helicase; splicing","C (programming language); Cable jointing; Gene expression; Gene expression regulation; Plants (botany); Proteins; RNA; Arabidopsis thaliana; Chloroplast; ISE2, group II intron; Plasmodesmata; Ribosome; RNA editing; RNA helicases; Nucleic acids",2-s2.0-85018355422
"Chen Z., Chen J., Li Y.","Metal-organic-framework-based catalysts for hydrogenation reactions",2017,"Cuihua Xuebao/Chinese Journal of Catalysis",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021774769&doi=10.1016%2fS1872-2067%2817%2962852-3&partnerID=40&md5=57a1a74cc3515442e94d705a3b6ef37d","Metal-organic-framework (MOF)-based materials with novel physicochemical properties have emerged as promising catalysts for various hydrogenation reactions. In addition to metal clusters and multifunctional organic ligands, MOF-based catalysts can incorporate other functional species, and thus provide various active sites for hydrogenation processes. The structural properties of the catalysts play significant roles in enhancing the interactions among the reactants, products, and catalytic sites, which can be rationally designed. Because of the synergistic effects between the active sites and the structural properties, MOF-based catalysts can achieve higher activities and selectivities in hydrogenation reactions than can be obtained using traditional heterogeneous catalysts. This review provides an overview of recent developments in MOF-based catalysts in the hydrogenation of alkenes, alkynes, nitroarenes, cinnamaldehyde, furfural, benzene, and other compounds. Strategies for improving the catalytic performances of MOF-based catalysts are discussed as well as the different active sites and structural properties of the catalysts. © 2017, Dalian Institute of Chemical Physics, Chinese Academy of Sciences. Published by Elsevier B.V. All rights reserved.","Chemoselectivity; Heterogeneous catalysis; Hydrogenation; Metal-organic framework; Nanoparticle; Synergistic effect","Benzene refining; Catalysis; Catalysts; Crystalline materials; Hydrocarbons; Hydrogenation; Java programming language; Metal nanoparticles; Metals; Nanoparticles; Structural properties; Catalytic performance; Chemo-selectivity; Heterogeneous catalyst; Hydrogenation process; Hydrogenation reactions; Metal organic framework; Physicochemical property; Synergistic effect; Catalyst activity",2-s2.0-85021774769
"Savoldi L., Bonifetto R., Breschi M., Isono T., Martovetsky N., Ozeki H., Zanino R.","Analysis of the ITER central solenoid insert (CSI) coil stability tests",2017,"Cryogenics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019164535&doi=10.1016%2fj.cryogenics.2017.05.001&partnerID=40&md5=4af30e3df2cf7a61a1ecfa4caa8d65cd","At the end of the test campaign of the ITER Central Solenoid Insert (CSI) coil in 2015, after 16,000 electromagnetic (EM) cycles, some tests were devoted to the study of the conductor stability, through the measurement of the Minimum Quench Energy (MQE). The tests were performed by means of an inductive heater (IH), located in the high-field region of the CSI and wrapped around the conductor. The calorimetric calibration of the IH is presented here, aimed at assessing the energy deposited in the conductor for different values of the IH electrical operating conditions. The MQE of the conductor of the ITER CS module 3L can be estimated as ∼200 J ± 20%, deposited on the whole conductor on a length of ∼10 cm (the IH length) in ∼40 ms, at current and magnetic field conditions relevant for the ITER CS operation. The repartition of the energy deposited in the conductor under the IH is computed to be ∼10% in the cable and 90% in the jacket by means of a 3D Finite Elements EM model. It is shown how this repartition implies that the bundle (cable + helium) heat capacity is fully available for stability on the time scale of the tested disturbances. This repartition is used in input to the thermal-hydraulic analysis performed with the 4C code, to assess the capability of the model to accurately reproduce the stability threshold of the conductor. The MQE computed by the code for this disturbance is in good agreement with the measured value, with an underestimation within 15% of the experimental value. © 2017","ITER; Nuclear fusion; Stability; Superconducting magnets; Thermal-hydraulics","C (programming language); Cables; Convergence of numerical methods; Finite element method; Solenoids; Specific heat; Superconducting coils; Superconducting magnets; Calorimetric calibrations; ITER; Minimum quench energy; Nuclear fusion; Operating condition; Stability thresholds; Thermal hydraulics; Thermal-hydraulic analysis; Stability",2-s2.0-85019164535
"Suzuki T., Aoki T., Ogasawara T., Fujita K.","Nonablative lightweight thermal protection system for Mars Aeroflyby Sample collection mission",2017,"Acta Astronautica",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017112942&doi=10.1016%2fj.actaastro.2017.04.001&partnerID=40&md5=05542fa1417e1636bda25f19c95360fe","In this study, the concept of a nonablative lightweight thermal protection system (NALT) were proposed for a Mars exploration mission currently under investigation in Japan. The NALT consists of a carbon/carbon (C/C) composite skin, insulator tiles, and a honeycomb sandwich panel. Basic thermal characteristics of the NALT were obtained by conducting heating tests in high-enthalpy facilities. Thermal conductivity values of the insulator tiles as well as the emissivity values of the C/C skin were measured to develop a numerical analysis code for predicting NALT's thermal performance in flight environments. Finally, a breadboard model of a 600-mm diameter NALT aeroshell was developed and qualified through vibration and thermal vacuum tests. © 2017 IAA",,"C (programming language); Carbon; Heat shielding; Honeycomb structures; Martian surface analysis; Space applications; Structural panels; Thermal insulating materials; Vacuum technology; Emissivity values; Flight environment; Honeycomb sandwich panels; Sample collection; Thermal characteristics; Thermal Performance; Thermal Protection System; Thermal vacuum tests; Thermal conductivity",2-s2.0-85017112942
"Ma W.-J., Yin F.-X., Zhu H.-T., Li X.-R.","Research on Side Impact Test Parameters Based on AEMDB",2017,"Zhongguo Gonglu Xuebao/China Journal of Highway and Transport",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030781872&partnerID=40&md5=46b3105a8bffd6e32798015a4717252a","In order to effectively identify the passive safety performance of the vehicle in terms of the new edition of China New Car Assessment Program (C-NCAP), main parameters influencing safety performances of vehicle side impact were determined and “average” models representing the vehicle characteristics of China were put forward by the statistical analysis of apparent parameters of existing vehicles in China. And then mobile barrier parameters in line with traffic conditions in China were proposed and compared with the parameters prescribed in C-NCAP and Europe New Car Assessment Program (Euro-NCAP) in 2015. Three side impact tests of full-scale vehicle with the same model were carried out based on all three types of mobile barriers. Besides, an evaluation method of the side impact in accordance with the actual situation in China was proposed. The results show that different mobile barriers have considerable influences on the vehicle side door deformation, intrusion rates of the door and the dummy injury. The larger mass the mobile barrier is, the higher the terrain clearance of the lower edge of honeycomb aluminum bumper can be. The door intrusion rate increases with the increasingly serious door deformation. It is clear that dummies in tests get injured much earlier by employing the new type of mobile barrier and the barrier prescribed in Euro-NCAP in 2015. Meanwhile, the peak of the new type of mobile barrier is higher. Hence, the results have great influences on the development of vehicle passive safety in China and the promotion of side safety protection of vehicles. © 2017, Editorial Department of China Journal of Highway and Transport. All right reserved.","AEMDB; Automotive engineering; Movable barrier parameter; Side impact test","Automotive engineering; Deformation; Mercury (metal); Safety engineering; Vehicles; AEMDB; Assessment programs; Movable barriers; Safety performance; Side impact; Terrain clearances; Traffic conditions; Vehicle characteristics; C (programming language)",2-s2.0-85030781872
"Li Y., Zhang L., Xu Y., Yao Y., Lau R.Y.K., Wu Y.","Enhancing Binary Classification by Modeling Uncertain Boundary in Three-Way Decisions",2017,"IEEE Transactions on Knowledge and Data Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020245196&doi=10.1109%2fTKDE.2017.2681671&partnerID=40&md5=7cab9f71cee6b34d13e776ff577ffd3f","Text classification is a process of classifying documents into predefined categories through different classifiers learned from labelled or unlabelled training samples. Many researchers who work on binary text classification attempt to find a more effective way to separate relevant texts from a large data set. However, current text classifiers cannot unambiguously describe the decision boundary between positive and negative objects because of uncertainties caused by text feature selection and the knowledge learning process. This paper proposes a three-way decision model for dealing with the uncertain boundary to improve the binary text classification performance based on the rough set techniques and centroid solution. It aims to understand the uncertain boundary through partitioning the training samples into three regions (the positive, boundary, and negative regions) by two main boundary vectors CP and CN, created from the labeled positive and negative training subsets, respectively, and further resolve the objects in the boundary region by two derived boundary vectors BP and BN, produced according to the structure of the boundary region. It involves an indirect strategy which is composed of two successive steps in the whole classification process: 'two-way to three-way' and 'three-way to two-way'. Four decision rules are proposed from the training process and applied to the incoming documents for more precise classification. A large number of experiments have been conducted based on the standard data sets RCV1 and Reuters-21578. The experimental results show that the usage of boundary vectors is very effective and efficient for dealing with uncertainties of the decision boundary, and the proposed model has significantly improved the performance of binary text classification in terms of F1 measure and AUC area compared with six other popular baseline models. © 2017 IEEE.","decision rule; rough set; text classification; three-way decision; Uncertain decision boundary","Bins; C (programming language); Classification (of information); Information retrieval systems; Rough set theory; Sampling; Binary classification; Classification process; Decision boundary; Decision rules; Text classification; Text feature selections; three-way decision; Uncertain boundaries; Text processing",2-s2.0-85020245196
"Oliveira I.C., Santhanam R.","Conspiracies between learning algorithms, circuit lower bounds, and pseudorandomness",2017,"Leibniz International Proceedings in Informatics, LIPIcs",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028748243&doi=10.4230%2fLIPIcs.CCC.2017.18&partnerID=40&md5=8d8a69e667f46796e42d6e084c87b225","We prove several results giving new and stronger connections between learning theory, circuit complexity and pseudorandomness. Let C be any typical class of Boolean circuits, and C[s(n)] denote n-variable C-circuits of size s(n). We show: Learning Speedups. If C[poly(n)] admits a randomized weak learning algorithm under the uniform distribution with membership queries that runs in time 2n/n!(1), then for every k 1 and ϵ > 0 the class C[nk] can be learned to high accuracy in time O(2nϵ ). There is ϵ > 0 such that C[2nϵ ] can be learned in time 2n/n!(1) if and only if C[poly(n)] can be learned in time 2(log n)O(1) . Equivalences between Learning Models. We use learning speedups to obtain equivalences between various randomized learning and compression models, including sub-exponential time learning with membership queries, sub-exponential time learning with membership and equivalence queries, probabilistic function compression and probabilistic average-case function compression. A Dichotomy between Learnability and Pseudorandomness. In the non-uniform setting, there is non-trivial learning for C[poly(n)] if and only if there are no exponentially secure pseudorandom functions computable in C[poly(n)]. Lower Bounds from Nontrivial Learning. If for each k 1, (depth-d)-C[nk] admits a randomized weak learning algorithm with membership queries under the uniform distribution that runs in time 2n/n!(1), then for each k 1, BPE (depth-d)-C[nk]. If for some ϵ > 0 there are P-natural proofs useful against C[2nϵ ], then ZPEXP C[poly(n)]. Karp-Lipton Theorems for Probabilistic Classes. If there is a k > 0 such that BPE i.o.Circuit[nk], then BPEXP i.o.EXP/O(log n). If ZPEXP i.o.Circuit[2n/3], then ZPEXP i.o.ESUBEXP. Hardness Results for MCSP. All functions in non-uniform NC1 reduce to the Minimum Circuit Size Problem via truth-table reductions computable by TC0 circuits. In particular, if MCSP 2 TC0 then NC1 = TC0. © Igor C. Oliveira and Rahul Santhanam.","Boolean circuits; Learning theory; Pseudorandomness","C (programming language); Computational complexity; Functions; Logic circuits; Random processes; Timing circuits; Boolean circuit; Circuit lower bounds; Learning Theory; Minimum circuit size problem; Probabilistic functions; Pseudo-random functions; Pseudorandomness; Uniform distribution; Learning algorithms",2-s2.0-85028748243
"Deshpande U., Keahey K.","Traffic-sensitive Live Migration of Virtual Machines",2017,"Future Generation Computer Systems",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006742013&doi=10.1016%2fj.future.2016.05.003&partnerID=40&md5=a30a94a279469f915bc05e002a672853","In this paper we address the problem of network contention between the migration traffic and the Virtual Machine (VM) application traffic for the live migration of co-located Virtual Machines. When VMs are migrated with pre-copy, they run at the source host during the migration. Therefore the VM applications with predominantly outbound traffic contend with the outgoing migration traffic at the source host. Similarly, during post-copy migration, the VMs run at the destination host. Therefore the VM applications with predominantly inbound traffic contend with the incoming migration traffic at the destination host. Such contention increases the total migration time of the VMs and degrades the performance of the VM application. Here, we propose a traffic-sensitive live VM migration technique to reduce the contention of migration traffic with the VM application traffic. It uses a combination of pre-copy and post-copy techniques for the migration of the co-located VMs (those located on the same source host), instead of relying on any single pre-determined technique for the migration of all the VMs. We base the selection of migration techniques on the VMs’ network traffic profiles so that the direction of migration traffic complements the direction of the most VM application traffic. We have implemented a prototype of traffic-sensitive migration on the KVM/QEMU platform. In the evaluation, we compare traffic-sensitive migration against the approaches that use only pre-copy or only post-copy for VM migration. We show that our approach minimizes the network contention for migration, thus reducing the total migration time and the application degradation. © 2016 Elsevier B.V.","Live migration; Traffic sensitivity; Virtual Machine","Java programming language; Network security; Co-located; Live migrations; Migration technique; Network contention; Network traffic; Total migration time; Virtual machines; Vm migrations; Virtual addresses",2-s2.0-85006742013
"Dowell A., Darlow B., MacRae J., Stubbe M., Turner N., McBain L.","Childhood respiratory illness presentation and service utilisation in primary care: A six-year cohort study in Wellington, New Zealand, using natural language processing (NLP) software",2017,"BMJ Open",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026734845&doi=10.1136%2fbmjopen-2017-017146&partnerID=40&md5=d4e9cb788c96ed2912774dc5abbc5d52","Objectives To identify childhood respiratory tract-related illness presentation rates and service utilisation in primary care by interrogating free text and coded data from electronic medical records. Design Retrospective cohort study. Data interrogation used a natural language processing software inference algorithm. Setting 36 primary care practices in New Zealand. Data analysed from January 2008 to December 2013. Participants The records from 77 582 children enrolled were reviewed over a 6-year period to estimate the presentation of childhood respiratory illness and service utilisation. This cohort represents 268 919 person-years of data and over 650 000 unique consultations. Main outcome measure Childhood respiratory illness presentation rate to primary care practice, with description of seasonal and yearly variation. Results Respiratory conditions constituted 46% of all child-general practitioner consultations with a stable year-on-year pattern of seasonal peaks. Upper respiratory tract infection was the most common respiratory category accounting for 21.0% of all childhood consultations, followed by otitis media (12.2%), wheeze-related illness (9.7%), throat infection (7.4%) and lower respiratory tract infection (4.4%). Almost 70% of children presented to their general practitioner with at least one respiratory condition in their first year of life; this reduced to approximately 25% for children aged 10-17. Conclusion This is the first study to assess the primary care incidence and service utilisation of childhood respiratory illness in a large primary care cohort by interrogating electronic medical record free text. The study identified the very high primary care workload related to childhood respiratory illness, especially during the first 2 years of life. These data can enable more effective planning of health service delivery. The findings and methodology have relevance to many countries, and the use of primary care 'big data' in this way can be applied to other health conditions. © Article author(s) (or their employer(s) unless otherwise stated in the text of the article) 2017. All rights reserved. No commercial use is permitted unless otherwise expressly granted.","big data; childhood respiratory illness; general practice; natural language software programming; primary care","adolescent; Article; child; clinical feature; cohort analysis; general practitioner; health care utilization; human; lower respiratory tract infection; major clinical study; natural language processing; New Zealand; otitis media; pharyngitis; primary medical care; respiratory tract disease; retrospective study; seasonal variation; wheezing",2-s2.0-85026734845
"Balduccini M., Magazzeni D., Maratea M., Leblanc E.C.","CASP solutions for planning in hybrid domains",2017,"Theory and Practice of Logic Programming",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021819460&doi=10.1017%2fS1471068417000187&partnerID=40&md5=5714eacc93632088ef5444a6093cf532","Constraint answer set programming (CASP) is an extension of answer set programming that allows for numerical constraints to be added in the rules. PDDL+ is an extension of the PDDL standard language of automated planning for modeling mixed discrete-continuous dynamics. In this paper, we present CASP solutions for dealing with PDDL+ problems, i.e., encoding from PDDL+ to CASP, and extensions to the algorithm of the ezcsp CASP solver in order to solve CASP programs arising from PDDL+ domains. An experimental analysis, performed on well-known linear and non-linear variants of PDDL+ domains, involving various configurations of the ezcsp solver, other CASP solvers, and PDDL+ planners, shows the viability of our solution. Copyright © 2017 Cambridge University Press.","Answer set programming; hybrid domains; planning","Computer programming; Logic programming; Planning; Answer set programming; Automated planning; Continuous dynamics; Experimental analysis; Hybrid domain; Non linear; Numerical constraints; Modeling languages",2-s2.0-85021819460
"Juan L.","Online learning platform and network resource application in Japanese translation teaching model innovation",2017,"Boletin Tecnico/Technical Bulletin",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028670891&partnerID=40&md5=b4b9d4efa630fb2816495fce4d37384e","The Japanese multimedia teaching system mainly put content, words, text, syntax and annotation in computer programming, and makes them as teaching resources. Teachers use computers to teach in a multimedia classroom, or through a computer network, spread to different classrooms in the same school, or even different places. In this paper, the author analyzes the online learning platform and network resource application in Japanese translation teaching model innovation. With the emergence of multimedia language learning system, students can accord their interests and needs, through network resources to realize Japanese language self-study. Teachers should make full use of their position, in order to better play the advantages of multimedia Japanese teaching.","Japanese Translation; Network Resource; Online Learning","Computer programming; Computer systems programming; Education; Multimedia systems; Teaching; Translation (languages); Language learning systems; Multimedia-teaching systems; Network resource; Online learning; Teaching resources; Translation teachings; E-learning",2-s2.0-85028670891
"Bart A., Truchet C., Monfroy E.","A global constraint for over-approximation of real-time streams",2017,"Constraints",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020099157&doi=10.1007%2fs10601-017-9268-z&partnerID=40&md5=d3bae11b2f06d0524ff99a6661c1c8f4","Formal verification of real time programs, where variables can change values at every time step, is difficult due to the analyses of loops with time lags. In this paper, we propose a constraint programming model together with a global constraint and a filtering algorithm, for computing over-approximation of real-time streams. The global constraint handles the loop analyses by providing an interval over-approximation of the loop invariant. We apply our method to the FAUST language, a language for processing real-time audio streams. Experiments show that our approach provides accurate results in short times. © 2017, Springer Science+Business Media New York.","Block-diagrams; Constraint modeling; Global constraint; Verification","Approximation algorithms; Computer programming; Constraint theory; Formal verification; Verification; Block diagrams; Constraint model; Constraint programming model; Filtering algorithm; Global constraints; Loop invariants; Real time programs; Real-time streams; Computer hardware description languages",2-s2.0-85020099157
"Shaw C.B., Hui E.S., Helpern J.A., Jensen J.H.","Tensor estimation for double-pulsed diffusional kurtosis imaging",2017,"NMR in Biomedicine",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016398824&doi=10.1002%2fnbm.3722&partnerID=40&md5=5cc500ec7cb8115bba9b16aca92ed5bb","Double-pulsed diffusional kurtosis imaging (DP-DKI) represents the double diffusion encoding (DDE) MRI signal in terms of six-dimensional (6D) diffusion and kurtosis tensors. Here a method for estimating these tensors from experimental data is described. A standard numerical algorithm for tensor estimation from conventional (i.e. single diffusion encoding) diffusional kurtosis imaging (DKI) data is generalized to DP-DKI. This algorithm is based on a weighted least squares (WLS) fit of the signal model to the data combined with constraints designed to minimize unphysical parameter estimates. The numerical algorithm then takes the form of a quadratic programming problem. The principal change required to adapt the conventional DKI fitting algorithm to DP-DKI is replacing the three-dimensional diffusion and kurtosis tensors with the 6D tensors needed for DP-DKI. In this way, the 6D diffusion and kurtosis tensors for DP-DKI can be conveniently estimated from DDE data by using constrained WLS, providing a practical means for condensing DDE measurements into well-defined mathematical constructs that may be useful for interpreting and applying DDE MRI. Data from healthy volunteers for brain are used to demonstrate the DP-DKI tensor estimation algorithm. In particular, representative parametric maps of selected tensor-derived rotational invariants are presented. Copyright © 2017 John Wiley & Sons, Ltd.","brain; DKI; double diffusion encoding; kurtosis; least squares; microscopic diffusion anisotropy; MRI; tensor","Brain; Diffusion; Encoding (symbols); Estimation; Higher order statistics; Magnetic resonance imaging; Quadratic programming; Signal systems; Tensors; Diffusion anisotropy; Diffusional kurtosis imaging; Double diffusion; Kurtosis; Least Square; Mathematical constructs; Quadratic programming problems; Weighted least squares; Diffusion tensor imaging; algorithm; Article; computer language; diffusion weighted imaging; double pulsed diffusional kurtosis imaging; human; human experiment; information processing; mathematical model; molecular dynamics; neuroimaging; normal human; priority journal; radiological parameters",2-s2.0-85016398824
"Filguiera R., Krause A., Atkinson M., Klampanos I., Moreno A.","Dispel4py: A Python framework for data-intensive scientific computing",2017,"International Journal of High Performance Computing Applications",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021296575&doi=10.1177%2f1094342016649766&partnerID=40&md5=f1613a88e9596b94ad2f23217550aaec","This paper presents dispel4py, a new Python framework for describing abstract stream-based workflows for distributed data-intensive applications. These combine the familiarity of Python programming with the scalability of workflows. Data streaming is used to gain performance, rapid prototyping and applicability to live observations. dispel4py enables scientists to focus on their scientific goals, avoiding distracting details and retaining flexibility over the computing infrastructure they use. The implementation, therefore, has to map dispel4py abstract workflows optimally onto target platforms chosen dynamically. We present four dispel4py mappings: Apache Storm, message-passing interface (MPI), multi-threading and sequential, showing two major benefits: a) smooth transitions from local development on a laptop to scalable execution for production work, and b) scalable enactment on significantly different distributed computing infrastructures. Three application domains are reported and measurements on multiple infrastructures show the optimisations achieved; they have provided demanding real applications and helped us develop effective training. The dispel4py.org is an open-source project to which we invite participation. The effective mapping of dispel4py onto multiple target infrastructures demonstrates exploitation of data-intensive and high-performance computing (HPC) architectures and consistent scalability. © The Author(s) 2015.","data streaming; Data-intensive computing; e-infrastructures; programming frameworks; scientific workflows","Data reduction; Distributed computer systems; High level languages; Mapping; Message passing; Open source software; Scalability; Data streaming; Data-intensive computing; E-infrastructures; Programming framework; Scientific workflows; Computer architecture",2-s2.0-85021296575
"Schmidt D., Chen W.-C., Matheson M.A., Ostrouchov G.","Programming with BIG Data in R: Scaling Analytics from One to Thousands of Nodes",2017,"Big Data Research",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006826675&doi=10.1016%2fj.bdr.2016.10.002&partnerID=40&md5=27fb5f08d3471ff0e24c75b8acab3bc5","We present a tutorial overview showing how one can achieve scalable performance with R. We do so by utilizing several package extensions, including those from the pbdR project. These packages consist of high performance, high-level interfaces to and extensions of MPI, PBLAS, ScaLAPACK, I/O libraries, profiling libraries, and more. While these libraries shine brightest on large distributed platforms, they also work rather well on small clusters and often, surprisingly, even on a laptop with only two cores. Our tutorial begins with recommendations on how to get more performance out of your R code before considering parallel implementations. Because R is a high-level language, a function can have a deep hierarchy of operations. For big data, this can easily lead to inefficiency. Profiling is an important tool to understand the performance of an R code for both serial and parallel improvements. The pbdR packages provide a highly scalable capability for the development of novel distributed data analysis algorithms. This level of scalability is unmatched in other analysis software. Interactive speeds (seconds) are achieved for complex analysis algorithms on data 100 GB and more. This is possible because the interfaces add little overhead to the scalable libraries and their extensions. Furthermore, this is often achieved with little or no change to serial R codes. Our overview includes codes of varying complexity, illustrating reading data in parallel, the process of changing a serial code to a distributed parallel code, and how to engage distributed matrix computation from within R. © 2016 Elsevier Inc.","Distributed computing; Principal components analysis; Scalable statistical computing; SPMD",,2-s2.0-85006826675
"Tognazzi S., Tschaikowski M., Tribastone M., Vandin A.","EGAC: A genetic algorithm to compare chemical reaction networks",2017,"GECCO 2017 - Proceedings of the 2017 Genetic and Evolutionary Computation Conference",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026387851&doi=10.1145%2f3071178.3071265&partnerID=40&md5=3363891943bab66946af7bb432d71f5f","Discovering relations between chemical reaction networks (CRNs) is a relevant problem in computational systems biology for model reduction, to explain if a given system can be seen as an abstraction of another one; and for model comparison, useful to establish an evolutionary path from simpler networks to more complex ones. This is also related to foundational issues in computer science regarding program equivalence, in light of the established interpretation of a CRN as a kernel programming language for concurrency. Criteria for deciding iftwo CRNs can be formally related have been recently developed, but these require that a candidate mapping be provided. Automatically finding candidate mappings is very hard in general since the search space essentially consists of all possible partitions of a set. In this paper we tackle this problem by developing a genetic algorithm for a class of CRNs called influence networks, which can be used to model a variety of biological systems including cell-cycle switches and gene networks. An extensive numerical evaluation shows that our approach can successfully establish relations between influence networks from the literature which cannot be found by exact algorithms due to their large computational requirements. © 2017 ACM.","Chemical Reaction Networks; Model Comparison; Ordinary Differential Equations","Bioinformatics; Biological systems; Chemical reactions; Computer programming; Differential equations; Evolutionary algorithms; Genetic algorithms; Mapping; Ordinary differential equations; Problem oriented languages; Candidate mappings; Chemical reaction networks; Computational requirements; Computational Systems Biology; Evolutionary path; Influence networks; Model comparison; Program equivalence; Complex networks",2-s2.0-85026387851
"Jayaram R., Saha B.","Approximating language edit distance beyond fast matrix multiplication: Ultralinear grammars are where parsing becomes hard!",2017,"Leibniz International Proceedings in Informatics, LIPIcs",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027244746&doi=10.4230%2fLIPIcs.ICALP.2017.19&partnerID=40&md5=95bc725ed8619ed21c583f35af6f1397","In 1975, a breakthrough result of L. Valiant showed that parsing context free grammars can be reduced to Boolean matrix multiplication, resulting in a running time of O(nω) for parsing where omega; ≤ 2.373 is the exponent of fast matrix multiplication, and n is the string length. Recently, Abboud, Backurs and V. Williams (FOCS 2015) demonstrated that this is likely optimal; moreover, a combinatorial o(n3) algorithm is unlikely to exist for the general parsing problem1. The language edit distance problem is a significant generalization of the parsing problem, which computes the minimum edit distance of a given string (using insertions, deletions, and substitutions) to any valid string in the language, and has received significant attention both in theory and practice since the seminal work of Aho and Peterson in 1972. Clearly, the lower bound for parsing rules out any algorithm running in o(nomega;) time that can return a nontrivial multiplicative approximation of the language edit distance problem. Furthermore, combinatorial algorithms with cubic running time or algorithms that use fast matrix multiplication are often not desirable in practice. To break this nomega; hardness barrier, in this paper we study additive approximation algorithms for language edit distance. We provide two explicit combinatorial algorithms to obtain a string with minimum edit distance with performance dependencies on either the number of non-linear productions, κ∗, or the number of nested non-linear production, κ, used in the optimal derivation. Explicitly, we give an additive O(κ ∗γ) approximation in time O(|G|(n2 + n3/gamma;3 )) and an additive O(κγ) approximation in time O(|G|(n2 + n3/gamma;2 )), where |G| is the grammar size and n is the string length. In particular, we obtain tight approximations for an important subclass of context free grammars known as ultralinear grammars, for which κ and κ∗ are naturally bounded. Interestingly, we show that the same conditional lower bound for parsing context free grammars holds for the class of ultralinear grammars as well, clearly marking the boundary where parsing becomes hard! © Rajesh Jayaram and Barna Saha;.","Approximation; Context free grammar; Dynamic programming; Edit distance; Hardness","Approximation algorithms; Automata theory; Combinatorial mathematics; Context free grammars; Dynamic programming; Hardness; Approximation; Boolean matrix multiplication; Combinatorial algorithm; Edit distance; Fast matrix multiplication; Minimum edit distance; Multiplicative approximations; Theory and practice; Matrix algebra",2-s2.0-85027244746
"Overton M.A.","The IDAR graph: An improvement over UML",2017,"Communications of the ACM",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021732665&doi=10.1145%2f3079970&partnerID=40&md5=834677f1ee905d62c3ad624f9e28b47b","UNIFIED MODELING LANGUAGE (UML)6 is the de facto standard for representing object-oriented designs. It does a fine job of recording designs, but it has a severe problem: its diagrams don't convey what humans need to know, making the diagrams difficult to understand. This is why most software developers use UML only when forced to.1 For example, the UML diagrams in Figures 1 and 2 portray the embedded software in a fax machine. While these diagrams are attractive, they do not even tell you which objects control which others. Which object is the topmost controller over this fax machine? You don't know. Which object(s) control the Modem object? You don't know. © 2017 ACM.",,"Graphic methods; Modeling languages; Object oriented programming; De facto standard; Fax machines; Object oriented design; Software developer; UML diagrams; Unified Modeling Language",2-s2.0-85021732665
"Sánchez-Alonso R.E., Ortega-Moody J., González-Barbosa J.-J., Reyes-Morales G.","Use of Platforms for the Development of Virtual Applications in the Modeling of Robot Manipulators [Uso de Plataformas para el Desarrollo de Aplicaciones Virtuales en el Modelado de Robot Manipuladores]",2017,"RIAI - Revista Iberoamericana de Automatica e Informatica Industrial",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021232144&doi=10.1016%2fj.riai.2017.04.001&partnerID=40&md5=27c55860c8efd0b59433e0316066929b","This paper describes the use of platforms for the development of virtual applications as tools for modeling of robot manipulators. The proposal is based on take advantage of the potential that these platforms currently have for solving the rigid body dynamics, which easily allows modeling the mechanical aspects of the manipulator. On the other hand, the possibility offered by these platforms of incorporate programming code in conventional languages allows to modeling the dynamic behavior of real physical systems, such as sensors and actuators, which allows implementing the development of the instrumentation and control stage of an industrial robot in the same way as a real one. Using these platforms allows the modeling from the bases of any manipulator robot. The modeling of a reconfigurable parallel robot is presented as a case study. © 2016 CEA. Publicado por Elsevier España, S.L.U.","Dynamic systems; Manipulator Robots; Modeling; Virtual reality","Dynamical systems; Dynamics; Flexible manipulators; Industrial robots; Modeling languages; Models; Modular robots; Robot applications; Robot programming; Robots; Virtual reality; Instrumentation and control; Manipulator robots; Mechanical aspects; Real physical systems; Rigidbody dynamics; Robot manipulator; Sensors and actuators; Virtual application; Manipulators",2-s2.0-85021232144
"Hu K., Zhang T., Shang L.-H., Yang Z.-B., Talpin J.-P.","Parallel Code Generation from Synchronous Specification",2017,"Ruan Jian Xue Bao/Journal of Software",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031327155&doi=10.13328%2fj.cnki.jos.005056&partnerID=40&md5=4111575905c739eea96391e0b71e4433","As functional and non-functional requirements on safety critical real time systems stack up, the development of multi-core technology in these systems has become a trend. How to guarantee the credibility and reliability on the multi-core platform, however, is the key problem in both academic and industry. While many theoretical and applied achievements have been accomplished on the single-core platform, there are still a lot of scientific problems need to be solved on the multi-core platform. Suitable for describing concurrency behaviors, synchronous language SIGNAL is a formalism widely used in the functional design of safety critical real time systems. The SIGNAL compiler supports generating the simulation code from the synchronous specification to verify and analyze the properties of the system model. However, existing studies pay less attention to the generation of multi-platform parallel simulation code from SIGNAL specification. This paper proposes a methodology for automatically generating parallel code from SIGNAL specifications. First, equation dependency graph (EDG) is defined and the specification is translated to analyze the global data dependency relations. Then EDG is partitioned to explore the parallelism of the specification. Finally, altogether with clock relations, parallel tasks are mapped into OpenMP structures. A case study is provided to illustrate the proposed methodology. © Copyright 2017, Institute of Software, the Chinese Academy of Sciences. All rights reserved.","Code generation; OpenMP; Parallel program; SIGNAL; Synchronous specification","Application programming interfaces (API); Codes (symbols); Interactive computer systems; Program compilers; Safety engineering; Signaling; Specifications; Code Generation; Non-functional requirements; OpenMP; Parallel program; Parallel simulations; Signal specifications; Synchronous languages; Synchronous specification; Real time systems",2-s2.0-85031327155
"Lot R., Massaro M.","A Symbolic Approach to the Multibody Modeling of Road Vehicles",2017,"International Journal of Applied Mechanics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027698604&doi=10.1142%2fS1758825117500685&partnerID=40&md5=20080120f6ce9729c166e2f388ea45f2","This paper introduces MBSymba, an object-oriented language for the modeling of multibody systems and the automatic generation of equations of motion in symbolic form. MBSymba has built upon the general-purpose computer algebra software Maple and it is freely available for teaching and research purposes. With MBSymba, objects such as points, vectors, rigid bodies, forces and torques, and the relationships among them may be defined and manipulated both at high and low levels. Absolute, relative or mixed coordinates may be used, as well as combination of infinitesimal and noninfinitesimal variables. Once the system has been modeled, Lagrange's and/or Newton's equations can be derived in a quasi-automatic way, either in an inertial or noninertial reference frame. Equations can be automatically converted into Matlab, C/C++ or Fortan code to produce stand alone, numerically optimized simulation code. MBSymba is particularly suited for the modeling of ground, water or air vehicles; therefore, the mathematical model of a passenger car with trailer is illustrated as a case study. Time domain simulations, steady state analysis and stability results are also presented. © 2017 World Scientific Publishing Europe Ltd.","Symbolic multibody; vehicle dynamics and control","Algebra; Equations of motion; Fighter aircraft; General purpose computers; MATLAB; Object oriented programming; Time domain analysis; Vehicles; Automatic Generation; Modeling of multi-body systems; Multi-body; Optimized simulation; Steady-state analysis; Teaching and researches; Time-domain simulations; Vehicle dynamics; Modeling languages",2-s2.0-85027698604
"Mikhaylyuk M.V., Timokhin P.Y., Maltsev A.V.","A method of Earth terrain tessellation on the GPU for space simulators",2017,"Programming and Computer Software",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025832415&doi=10.1134%2fS0361768817040065&partnerID=40&md5=340d93c535c586d6d0f7c244a2fe5fd2","This paper presents a new distributed method for virtual Earth terrain tessellation on a graphics processing unit (GPU) for space simulator complexes. The method operates in real time in multi-object virtual scenes comprising up to two million polygons. A polygonal terrain model is constructed using triangle patches of different levels of detail on graphics cards with programmable tessellation. Patches of the same level of detail are calculated entirely on the GPU, in parallel and independently, by using a developed shader program written in the OpenGL Shading Language (GLSL). This paper also describes a patch extraction algorithm for visible Earth surface rendering and an algorithm for correcting the barycentric coordinates of tessellated patch vertices that allows triangles in the terrain model to be docked without geometric discontinuities. Based on the distributed methods and algorithms developed, a program complex for virtual Earth surface visualization was created and successfully tested. The proposed solution can also be employed in virtual environment systems, virtual labs, educational geo-applications, etc. © 2017, Pleiades Publishing, Ltd.",,"Application programming interfaces (API); Computer graphics; Computer graphics equipment; Distance education; Earth (planet); Landforms; Program processors; Software testing; Space simulators; Virtual reality; Barycentric coordinates; Distributed methods; Extraction algorithms; Geo applications; Geometric discontinuities; Levels of detail; Shading languages; Terrain Modeling; Graphics processing unit",2-s2.0-85025832415
"Fritz E., Zhao T.","Typing and semantics of asynchronous arrows in JavaScript",2017,"Science of Computer Programming",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016175646&doi=10.1016%2fj.scico.2017.03.003&partnerID=40&md5=d4ac7e059513251280f2b96c2b8853cb","Asynchronous programs in JavaScript using callbacks and promises are difficult to write correctly. Many programs have subtle errors due to the unwanted interaction of event handlers. To fix such errors, the programmer is burdened with explicit registration and de-registration of event handlers. This produces fragile code which is difficult to read and maintain. Arrows, a generalization of monads, are an elegant solution to asynchronous program composition. In this paper, we present the semantics of an arrow-based DSL in JavaScript which can encode asynchronous programs as a state machine where edge transitions are triggered by external events. To ensure that arrows are composed correctly, we provide an optional type checker that reports errors before the machine begins execution. © 2017 Elsevier B.V.","Asynchronous programming; JavaScript; Semantics; Type checking; Type inference","Errors; Semantics; Asynchronous programming; Event-handlers; Javascript; State machine; Type checker; Type inferences; Typechecking; High level languages",2-s2.0-85016175646
"Loreto S., Romano S.P.","How far are we from WebRTC-1.0? An update on standards and a look at what's next",2017,"IEEE Communications Magazine",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020072306&doi=10.1109%2fMCOM.2017.1600283&partnerID=40&md5=6e7da1a0160e46a698c4e1e4fe83342c","Real-time communication between browsers has represented an unprecedented standardization effort involving both the IETF and the W3C. These activities have involved both the real-time protocol suite and the application-level JavaScript APIs to be offered to developers in order to allow them to easily implement interoperable real-time multimedia applications in the web. This article sheds light on the current status of standardization, with special focus on the upcoming final release of the so-called WebRTC-1.0 standard ecosystem. It takes stock of the situation with respect to hot topics such as codecs, session description and stream multiplexing. It also briefly discusses how standard bodies are dealing with seamless integration of the initially competing effort known as ""Object Real Time Communications."" © 2017 IEEE.",,"Application programming interfaces (API); Standardization; Application level; Current status; Hot topics; Real time multimedia applications; Real time protocols; Real-time communication; Seamless integration; Standard bodies; Computer hardware description languages",2-s2.0-85020072306
"Bacquey N., Grandjean E., Olive F.","Definability by horn formulas and linear time on cellular automata",2017,"Leibniz International Proceedings in Informatics, LIPIcs",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027250737&doi=10.4230%2fLIPIcs.ICALP.2017.99&partnerID=40&md5=59b990a8eceffc01233c29e41e2b864c","We establish an exact logical characterization of linear time complexity of cellular automata of dimension d, for any fixed d: a set of pictures of dimension d belongs to this complexity class iff it is definable in existential second-order logic restricted to monotonic Horn formulas with built-in successor function and d+1 first-order variables. This logical characterization is optimal modulo an open problem in parallel complexity. Furthermore, its proof provides a systematic method for transforming an inductive formula defining some problem into a cellular automaton that computes it in linear time. © Nicolas Bacquey and Etienne Grandjean and Frédéric Olive;.","Cellular automata of any dimension; Descriptive complexity; Horn formulas; Linear time; Local induction; Logic programming; Picture languages; Second-order logic","Cellular automata; Computer circuits; Formal logic; Logic programming; Descriptive complexity; Horn formulas; Linear time; Local induction; Picture languages; Second-order logic; Temporal logic",2-s2.0-85027250737
"Peñil P., Díaz A., Posadas H., Medina J., Sánchez P.","High-level design of wireless sensor networks for performance optimization under security hazards",2017,"ACM Transactions on Sensor Networks",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027136766&doi=10.1145%2f3078359&partnerID=40&md5=0f7b45cd72b42080f3f124f1e9e49cff","The increasing complexity of current wireless sensor networks requires efficient methodologies to fulfill the strict constraints typically imposed in terms of power consumption and system performance. Furthermore, security issues are also becoming key features due to their impact on system behavior. As a consequence, new design frameworks are required to enable developers to model and address security risks from the very beginning of the WSN design process, while optimizing system performance. For this purpose, this article presents a design framework for modeling and simulating WSNs under external attacks. In this framework, the WSN is specified by using UML/MARTE models, from which automatic code generation enables fast, host-compiled simulation. The resulting information enables early detection of weaknesses in WSN designs and simplifies further exploration of design solutions. Minor modifications in the UML models are sufficient to automatically simulate and evaluate each design alternative in an iterative way. As a result, designers can develop more secure and optimized WSN systems with reduced design times and effort. © 2017 ACM.",,"Automatic programming; Design; Energy efficiency; Iterative methods; Network security; Unified Modeling Language; Automatic code generations; Design alternatives; Design frameworks; High-level design; Host-compiled simulations; Modeling and simulating; Performance optimizations; Strict constraint; Wireless sensor networks",2-s2.0-85027136766
"Pereira C.M.N.A., Schirru R., Gomes K.J., Cunha J.L.","Development of a mobile dose prediction system based on artificial neural networks for NPP emergencies with radioactive material releases",2017,"Annals of Nuclear Energy",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015694848&doi=10.1016%2fj.anucene.2017.03.017&partnerID=40&md5=6181f53a5612eeddabcc988f6cd9163a","This work presents the approach of a mobile dose prediction system for NPP emergencies with nuclear material release. The objective is to provide extra support to field teams decisions when plant information systems are not available. However, predicting doses due to atmospheric dispersion of radionuclide generally requires execution of complex and computationally intensive physical models. In order to allow such predictions to be made by using limited computational resources such as mobile phones, it is proposed the use of artificial neural networks (ANN) previously trained (offline) with data generated by precise simulations using the NPP atmospheric dispersion system. Typical situations for each postulated accident and respective source terms, as well as a wide range of meteorological conditions have been considered. As a first step, several ANN architectures have been investigated in order to evaluate their ability for dose prediction in hypothetical scenarios in the vicinity of CNAAA Brazilian NPP, in Angra dos Reis, Brazil. As a result, good generalization and a correlation coefficient of 0.99 was achieved for a validation data set (untrained patterns). Then, selected ANNs have been coded in Java programming language to run as an Android application aimed to plot the spatial dose distribution into a map. In this paper, the general architecture of the proposed system is described; numerical results and comparisons between investigated ANN architectures are discussed; performance and limitations of running the Application into a commercial mobile phone are evaluated and possible improvements and future works are pointed. © 2017","Android; Artificial neural network; Atmospheric dispersion of radionuclide; Dose prediction; Mobile; Nuclear emergency; Smartphone","Android (operating system); Atmospheric movements; Cellular telephones; Computer programming; Deep neural networks; Dispersions; Forecasting; Mobile phones; Network architecture; Neural networks; Nuclear reactor accidents; Radioactive materials; Radioisotopes; Telephone sets; Android; Atmospheric dispersion; Commercial mobile phones; Computational resources; Meteorological condition; Mobile; Nuclear emergencies; Plant information systems; Cellular telephone systems",2-s2.0-85015694848
"Chiu Y.-C., Chen C.-H.","Development of on-line apple bruise detection system",2017,"Engineering in Agriculture, Environment and Food",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016071068&doi=10.1016%2fj.eaef.2017.03.003&partnerID=40&md5=b1834c0cc1d22175ce6b1f0beaa438bd","This research aims to develop an on-line apple bruise detection system, using chlorophyll fluorescence images for nondestructive apple bruise detection and analysis. The on-line apple bruise detection system is consisted of a fluorescent image acquisition unit, a fruit carrying revolving tray unit, a conveying unit, and a control unit. The LabVIEW graphical programming language was used to build the control program, and Vision Assistant was used for image processing and analysis. The wavelength of the fluorescence excitation source used was 460 nm. A color camera captured the fluorescence released from Golden Delicious apple, and the wavelength was 680 ± 10 nm. The fruit was revolved by the fruit carrying revolving tray, 60° each time, revolved six times, so as to shoot the complete apple surface. The image processing procedures of bruise recognition include image preprocessing, medium filtering, regional binarization, background removal, noise filtering and hole filling for recognition, and analysis of bruise blocks. This study applied 67.9 ± 4.84N, 82.1 ± 4.57N and 102 ± 8.44N impact forces to apples respectively to make bruises. The test results showed that the proposed on-line apple bruise detection system could recognize the apple bruise 100% after 45 min from the impact on apples. The prototype system could inspect 92 apples for bruise automatically hourly on an average. This study has successfully built an on-line apple bruise detection system, and the inspection of the system may be accelerated in the future for commercial uses. © 2017 Asian Agricultural and Biological Engineering Association","Automation; Chlorophyll fluorescence; Fruit; Image processing; Nondestructive detection","Automation; Chlorophyll; Computer graphics; Fluorescence; Image analysis; Image processing; Background removal; Chlorophyll fluorescence; Fluorescence excitation; Fluorescent images; Image preprocessing; Image processing and analysis; Labview graphical programming; Nondestructive detection; Fruits",2-s2.0-85016071068
"Yoo S., Binkley D., Eastman R.","Observational slicing based on visual semantics",2017,"Journal of Systems and Software",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84967190374&doi=10.1016%2fj.jss.2016.04.009&partnerID=40&md5=dfe06d03c3c294c83ef2fff1e7300cce","Program slicing has seen a plethora of applications and variations since its introduction over 35 years ago. The dominant method for computing slices involves significant complex source-code analysis to model the dependencies in the code. A recently introduced alternative, observation-based slicing, sidesteps this complexity by observing the behavior of candidate slices. Observation-based slicing has several other strengths, including the ability to easily slice multi-language systems. However, the initial implementation of observation-based slicing, ORBS, remains rooted in tradition as it captures semantics by comparing sequences of values. This raises the question of whether it is possible to extend slicing beyond its traditional semantic roots. A few existing projects have attempted this but the extension requires considerable effort. If it is possible to build on the ORBS platform to more easily generalize slicing to languages with non-traditional semantics, then there is the potential to vastly increase the range of programming languages to which slicing can be applied. ORBS supports this by reducing the problem to that of generalizing how semantics are captured. Taking Picture Description Languages as a case study, the challenges and effectiveness of such a generalization are considered. The results show that not only is it possible to generalize the ORBS implementation, but the resulting slicer is quite effective, removing from 8% to 98% of the original source code with an average of 83%. Finally a qualitative look at the slices finds the technique very effective, at times producing minimal slices. © 2016 Elsevier Inc.","Non-traditional semantics; Observation","Application programs; Codes (symbols); Computational linguistics; Complex sources; Multi languages; Non-traditional; Observation; Picture description language; Program slicing; Source codes; Visual semantics; Semantics",2-s2.0-84967190374
"Kumar R.R., Kumar S., Kumar A.","Study on effect of tool geometry on energy and temperature of Friction Stir Welding",2017,"International Journal of Civil Engineering and Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026452806&partnerID=40&md5=18372207dab5bb28634329df6a024628","This paper proposes a mathematical model using five different tool designs to analyze the influences of rotation speed and welding speed on the energy generation and peak temperature. Furthermore, the results obtained from mathematical modeling show that the peak temperature and energy per unit length produced during welding using cylindrical pin profile, while the triangular pin profile has the lowest temperature among all pin profile under the given working conditions. The generated energy and peak temperature models developed analytically and solved by developing a computer program in C++ language. Paper deals with reduction of time and cost of calculating the effective energy and peak temperature of the developed mathematical equations. © 2017 IAEME Publication.","C - programming; Energy and temperature; Heat generation; Mathematical modeling; Tool design",,2-s2.0-85026452806
"Cano E.L., Moguerza J.M., Ermolieva T., Yermoliev Y.","A strategic decision support system framework for energy-efficient technology investments",2017,"TOP",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978758673&doi=10.1007%2fs11750-016-0429-9&partnerID=40&md5=ecd964dceb419860884a5e6c5ef864eb","Energy systems optimization under uncertainty is increasing in its importance due to on-going global de-regulation of the energy sector and the setting of environmental and efficiency targets which generate new multi-agent risks requiring a model-based stakeholders dialogue and new systemic regulations. This paper develops an integrated framework for decision support systems (DSS) for the optimal planning and operation of a building infrastructure under appearing systemic de-regulations and risks. The DSS relies on a new two-stage, dynamic stochastic optimization model with moving random time horizons bounded by stopping time moments. This allows to model impacts of potential extreme events and structural changes emerging from a stakeholders dialogue, which may occur at any moment of the decision making process. The stopping time moments induce endogenous risk aversion in strategic decisions in a form of dynamic VaR-type systemic risk measures dependent on the system’s structure. The DSS implementation via an algebraic modeling language (AML) provides an environment that enforces the necessary stakeholders dialogue for robust planning and operation of a building infrastructure. Such a framework allows the representation and solution of building infrastructure systems optimization problems, to be implemented at the building level to confront rising systemic economic and environmental global changes. © 2016, The Author(s).","Decision support systems; Dynamic stochastic programming; Strategic and operational planning; Uncertainty modelling",,2-s2.0-84978758673
"Seok M.G., Kim T.G., Park D.","An HLA-based formal co-simulation approach for rapid prototyping of heterogeneous mixed-signal SoCs",2017,"IEICE Transactions on Fundamentals of Electronics, Communications and Computer Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021809233&doi=10.1587%2ftransfun.E100.A.1374&partnerID=40&md5=92cf9040ee7325841aaf03b636634a63","The rapid prototyping of a mixed-signal system-on-chip (SoC) has been enabled by reusing predesigned intellectual properties (IPs) and by integrating newly designed IP into the top design of SoC. The IPs have been designed on various hardware description levels, which leads to challenges in simulations that evaluate the prototyping. One traditional solution is to convert these heterogeneous IP models into equivalent mod-els, that are described in a single description language. This conversion approach often requires manual rewriting of existing IPs, and this results in description loss during the model projection due to the absence of au-tomatic conversion tools. The other solutions are co-simulation/emulation approaches that are based on the coupling of multiple simulators/emulators through connection modules. The conventional methods do not have formal theoretical backgrounds and an explicit interface for integrating the simu-lator into their solutions. In this paper, we propose a general co-simulation approach based on the high-level architecture (HLA) and a newly-defined programming language interface for interoperation (PLI-I) between hetero-geneous IPs as a formal simulator interface. Based on the proposed PLI-I and HLA, we introduce formal procedures of integration and interopera-tion. To reduce integration costs, we split these procedures into two parts: a reusable common library and an additional model-dependent signal-to-event (SE) converter to handle differently abstracted in/out signals between the coupled IPs. During the interoperation, to resolve the different time-advance mechanisms and increase computation concurrency between digital and analog simulators, the proposed co-simulation approach performs an advanced HLA-based synchronization using the pre-simulation concepts. The case study shows the validation of interoperation behaviors between the heterogeneous IPs in mixed-signal SoC design, the reduced design effort in integrating, and the synchronization speedup using the proposed approach. Copyright © 2017 The Institute of Electronics, Information and Communication Engineers.","HLA/RTI; Mixed-signal design; Simulator interoperation; System-level verification; System-on-chip design","Computer simulation languages; Electric signal systems; High level languages; Internet protocols; Programmable logic controllers; Rapid prototyping; Signal systems; Simulators; System-on-chip; HLA/RTI; Interoperations; Mixed-signal design; System levels; System on chip design; Integrated circuit design",2-s2.0-85021809233
"Laloo J.Z.A., Laloo N., Rhyman L., Ramasami P.","ExcelAutomat: a tool for systematic processing of files as applied to quantum chemical calculations",2017,"Journal of Computer-Aided Molecular Design",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020504831&doi=10.1007%2fs10822-017-0031-8&partnerID=40&md5=fa2f41c21bbe875b80110e3232e956b1","Abstract: The processing of the input and output files of quantum chemical calculations often necessitates a spreadsheet as a key component of the workflow. Spreadsheet packages with a built-in programming language editor can automate the steps involved and thus provide a direct link between processing files and the spreadsheet. This helps to reduce user-interventions as well as the need to switch between different programs to carry out each step. The ExcelAutomat tool is the implementation of this method in Microsoft Excel (MS Excel) using the default Visual Basic for Application (VBA) programming language. The code in ExcelAutomat was adapted to work with the platform-independent open-source LibreOffice Calc, which also supports VBA. ExcelAutomat provides an interface through the spreadsheet to automate repetitive tasks such as merging input files, splitting, parsing and compiling data from output files, and generation of unique filenames. Selected extracted parameters can be retrieved as variables which can be included in custom codes for a tailored approach. ExcelAutomat works with Gaussian files and is adapted for use with other computational packages including the non-commercial GAMESS. ExcelAutomat is available as a downloadable MS Excel workbook or as a LibreOffice workbook. Graphical abstract: [Figure not available: see fulltext.]. © 2017, Springer International Publishing AG.","Automation; Computational chemistry; Parsing data; Spreadsheet; VBA","Article; automation; calculation; computer interface; computer language; computer model; data processing; electronic spreadsheet; ExcelAutomat tool; information processing; normal distribution; physical parameters; priority journal; program development; quantum chemistry; software; workflow; computer graphics; quantum theory; Computer Graphics; Quantum Theory; Software; User-Computer Interface; Workflow",2-s2.0-85020504831
"Zeigler B.P., Muzy A.","From Discrete Event Simulation to Discrete Event Specified Systems (DEVS)",2017,"IFAC-PapersOnLine",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031823546&doi=10.1016%2fj.ifacol.2017.08.672&partnerID=40&md5=dd391bd28b036d13fbc8e1b78ee45af6","In this presentation we discuss the evolution of simulation from its origin in design of computer and communication systems based on event routines, to the conceptualization of the objects under study as systems, to the behavior generation of DEVS models representing a wide variety of cyber-physical forms. Indeed, the history of computer simulation programming languages parallels, and is intertwined with, the evolution of programming concepts from hardware-dependent binary scripts to successively more abstract model-based generic frameworks. © 2017","Discrete Event Dynamic Systems; Discrete Event System Specification; Systems theory",,2-s2.0-85031823546
"Ogawa K.","Special contribution business innovation in IoT era: Rebuilding business model for monozukuri",2017,"Fujitsu Scientific and Technical Journal",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025147124&partnerID=40&md5=25cbedc39000aef4d892779a77e6e440","A study focuses on a third economic revolution where the use of software-mediated digital format in the design of products is explored. Software is developed using a programing language or an artificial logical system created by humans. The combination of natural laws in new ways requires long-term basic research and substantial funding. Software makes it possible to embody ideas and expectations as product functions as desired through creative programming. These developments will result in the Internet of Things (IoT) playing a key role in the development of innovative business models.",,"Product design; Business innovation; Business modeling; Business models; Design of product; Digital format; Internet of thing (IOT); Logical system; Product functions; Internet of things",2-s2.0-85025147124
"Qamsane Y., El Hamlaoui M., Tajer A., Philippot A.","A Tool Support to Distributed Control Synthesis and Grafcet Implementation for Discrete Event Manufacturing Systems",2017,"IFAC-PapersOnLine",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031766261&doi=10.1016%2fj.ifacol.2017.08.530&partnerID=40&md5=f690bd8e5346f17d146c9ae8f42a08fe","Current production systems are becoming more complex: manufactured products are increasingly technical, production components are more specific, and control specifications are rapidly changing. Thus, formal methods and tools are becoming essential to support the automated development of control systems. We propose to develop a tool for the synthesis and implementation of modular/distributed supervisory control for Automated Manufacturing Systems (AMS). To reduce the computational complexity, we divide the control problem into local and global controls. Local Controllers (LCs) are designed for the individual subsystems, then global dependencies are added to the LCs to cooperatively execute the control actions. The tool provides a distributed control, interpreted as Grafcet (standard IEC 60848), that can be lately converted into any suitable IEC 61131-3 standard programming language for PLC programming purposes. It is based on Model-to-Model (M2M) transformations implemented in an Eclipse Modeling Framework (EMF) environment. © 2017","Automated Manufacturing Systems; Grafcet; Model-Driven Development; Supervisory Control; Synthesis Method",,2-s2.0-85031766261
"Dalege J., Borsboom D., van Harreveld F., van der Maas H.L.J.","Network Analysis on Attitudes: A Brief Tutorial",2017,"Social Psychological and Personality Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028539573&doi=10.1177%2f1948550617709827&partnerID=40&md5=d5f272fb0a6582bde948e2091cd14a89","In this article, we provide a brief tutorial on the estimation, analysis, and simulation on attitude networks using the programming language R. We first discuss what a network is and subsequently show how one can estimate a regularized network on typical attitude data. For this, we use open-access data on the attitudes toward Barack Obama during the 2012 American presidential election. Second, we show how one can calculate standard network measures such as community structure, centrality, and connectivity on this estimated attitude network. Third, we show how one can simulate from an estimated attitude network to derive predictions from attitude networks. By this, we highlight that network theory provides a framework for both testing and developing formalized hypotheses on attitudes and related core social psychological constructs. © 2017, © The Author(s) 2017.","attitudes; network analysis; network estimation; network simulation; network theory",,2-s2.0-85028539573
"Yavuz I., Cooper O.","A dynamic clustering method to improve the coherency of an ANP Supermatrix",2017,"Annals of Operations Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011660591&doi=10.1007%2fs10479-017-2403-9&partnerID=40&md5=0053605f49cde8cc9f321f0efd1b48dd","When making decisions with the Analytic Network Process, coherency testing is an important step in the decision making process. Once an incoherent priority vector is identified it can either be costly or in some cases next to impossible to elicit new pairwise comparisons. Remarkably, there is useful information in the linking estimates that one may have already calculated and used in one of the approaches to measure the coherency of the Supermatrix. A dynamic clustering method is used to automatically identify a cluster of coherent linking estimates from which a new coherent priority vector can be calculated and used to replace the most incoherent priority vector. The decision maker can then accept or revise the proposed new and coherent priority vector. This process is repeated until the entire Supermatrix is coherent. This method can save decision makers valuable time and effort by using the information and relationships that already exist in a weighted Supermatrix that is sufficiently coherent. The method is initially motivated and demonstrated through a simple straightforward example. A group of conceptual charts and a figure provide a visual motivation and explanation of the method. A high level summary of the method is provided in a table before the method is presented in detail. Simulations demonstrate both the application and the robustness of the proposed method. Code is provided, as supplementary material, in the programming language R so the method can be easily applied by the decision maker. © 2017, Springer Science+Business Media New York.","Analytic Network Process (ANP); Coherency testing; Consistency; Linking Coherency Index (LCI); Linking validation",,2-s2.0-85011660591
"Abera K.A., Manahiloh K.N., Motalleb Nejad M.","The effectiveness of global thresholding techniques in segmenting two-phase porous media",2017,"Construction and Building Materials",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015634085&doi=10.1016%2fj.conbuildmat.2017.03.046&partnerID=40&md5=ce474ebcefa88312e043512e573c2f5c","The effectiveness of five global thresholding techniques, to accurately segment different geomaterials, was evaluated in this work. X-ray CT images-taken from two-phase pervious concrete, glass bead, and silica sand specimens-were analyzed for evaluating five chosen methods. The core algorithms for these methods were coded using a Matlab programming language and packaged into a standalone application software. Three hundred and thirty-five image slices were provided for the pervious concrete specimen and the cropped size of this specimen was approximately 68 mm in diameter. The method proposed by Kapur et al. (1985) yielded the best results qualitatively and quantitatively (e = 0.28) to the laboratory and Image-Pro measured void ratios of 0.26 and 0.30, respectively. Eleven image slices were analyzed for a 10 mm in diameter glass bead specimen. Once again, the method proposed by Kapur et al. (1985) gave the best results with a void ratio of 0.91, as compared to the Image-Pro void ratio of 0.89. Ten image slices, with a cropped diameter of 4.48 mm, were used for the analysis of the silica sand specimen and the Otsu (1979) method was the most successful image segmentation technique, yielding a void ratio of 0.85 (Image-Pro e = 0.77). From the results, it can be said that, no single image segmentation technique performs well over a wide range of material and that the performance of each image segmentation technique varies depending on the type and state of the analyzed media. © 2017","Image processing; Porous media; Segmentation; Thresholding; Void ratio; X-ray CT","Application programs; Computerized tomography; Concretes; Glass; Granular materials; Image analysis; Image processing; MATLAB; Porous materials; Sand; Silica; Silica sand; Core algorithms; Global thresholding; Pervious concrete; Segmentation techniques; Standalone applications; Thresholding; Void ratios; X-ray CT; Image segmentation",2-s2.0-85015634085
"Li S., Wan C.-F., Hou Z.","Structural optimization research on superstructure of jib crane",2017,"Journal of the Brazilian Society of Mechanical Sciences and Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020763730&doi=10.1007%2fs40430-017-0718-8&partnerID=40&md5=a9e94c0090654c2288fcd623dcde999c","Because of its characteristics of high operating efficiency and low operating cost, jib crane, mainly used to complete the loading and unloading of cargo and stacking operations, has become indispensable transport equipment on ports and terminals. As the core structural component of jib crane, design of superstructure will affect the stability of machine directly. Based on the unified objective function method, the mathematical model about multi-objective optimal design of superstructure was established which superstructure was served as a whole. Reduction of the maximum of the luffing resistance moment and unbalanced torque, as well as decrease of the fluctuations of hanging point vertical displacement were taken as the objective functions, and the coordinate of the hinge point position, structure length and counterweight were regarded as the design variables. The mixed penalty function of MATLAB was used for the optimization calculation. At the same time, interface for optimization design of jib crane’s superstructure was developed with C # and MATLAB hybrid programming language at the platform of VS. This interface can achieve the visualization of optimal design process. The result after optimization indicates that fluctuations of hanging point vertical displacement, maximum of the luffing resistance moment, as well as unbalanced torque decreased. This means drive power was saved, which has important theoretical significance. © 2017, The Brazilian Society of Mechanical Sciences and Engineering.","Jib crane; Multi-objective optimization; Superstructure; The mixed penalty function","Cranes; Functions; Jib cranes; MATLAB; Multiobjective optimization; Optimal systems; Unloading; Loading and unloading; Operating efficiency; Optimization calculation; Penalty function; Structural component; Superstructure; Transport equipment; Vertical displacements; Structural optimization",2-s2.0-85020763730
"Goudarzi G., Daryanoosh S.M., Godini H., Hopke P.K., Sicard P., De Marco A., Rad H.D., Harbizadeh A., Jahedi F., Mohammadi M.J., Savari J., Sadeghi S., Kaabi Z., Omidi Khaniabadi Y.","Health risk assessment of exposure to the Middle-Eastern Dust storms in the Iranian megacity of Kermanshah",2017,"Public Health",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018443434&doi=10.1016%2fj.puhe.2017.03.009&partnerID=40&md5=118cb4edffb7174767f7edb4c8ed3a79","Objective This study assessed the effects of particulate matter (PM), equal or less than 10 μm in aerodynamic diameter (PM10), from the Middle-Eastern Dust events on public health in the megacity of Kermanshah (Iran). Study design This study used epidemiological modeling and monitored ambient air quality data to estimate the potential PM10 impacts on public health. Methods The AirQ2.2.3 model was used to calculate mortality and morbidity attributed to PM10 as representative of dust events. Using Visual Basic for Applications, the programming language of Excel software, hourly PM10 concentrations obtained from the local agency were processed to prepare input files for the AirQ2.2.3 model. Results Using baseline incidence, defined by the World Health Organization, the number of estimated excess cases for respiratory mortality, hospital admissions for chronic obstructive pulmonary disease, for respiratory diseases, and for cardiovascular diseases were 37, 39, 476, and 184 persons, respectively, from 21st March, 2014 to 20th March, 2015. Furthermore, 92% of mortality and morbidity cases occurred in days with PM10 concentrations lower than 150 μg/m3. The highest percentage of person-days occurred for daily concentrations range of 100–109 μg/m3, causing the maximum health end-points among the citizens of Kermanshah. Conclusions Calculating the number of cumulative excess cases for mortality or morbidity attributed to PM10 provides a good tool for decision and policy-makers in the field of health care to compensate their shortcomings particularly at hospital and healthcare centers for combating dust storms. To diminish these effects, several immediate actions should be managed in the governmental scale to control dust such as spreading mulch and planting new species that are compatible to arid area. © 2017 The Royal Society for Public Health","AirQ software; Health effect; Middle-Eastern Dust; Morbidity; PM10","dust storm; health impact; health risk; megacity; morbidity; particulate matter; risk assessment; software; air quality; Article; cardiovascular disease; chronic obstructive lung disease; dust storm; health hazard; hospital admission; human; Iranian people; morbidity; mortality; particulate matter; public health; respiratory tract disease; risk assessment; weather; adverse effects; city; dust; environmental exposure; epidemiology; Iran; statistics and numerical data; Iran; Kermanshah; dust; particulate matter; Cities; Dust; Environmental Exposure; Humans; Iran; Morbidity; Mortality; Particulate Matter; Public Health; Risk Assessment",2-s2.0-85018443434
"Abdrashitov S.V., Bogdanov O.V., Korotchenko K.B., Pivovarov Y.L., Rozhkova E.I., Tukhfatullin T.A., Eikhorn Y.L.","BCM-2.0 – The new version of computer code “Basic Channeling with Mathematica©”",2017,"Nuclear Instruments and Methods in Physics Research, Section B: Beam Interactions with Materials and Atoms",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016422187&doi=10.1016%2fj.nimb.2017.03.132&partnerID=40&md5=16b1611b7b183ca61eead26f3df9cbaa","The new symbolic-numerical code devoted to investigation of the channeling phenomena in periodic potential of a crystal has been developed. The code has been written in Wolfram Language taking advantage of analytical programming method. Newly developed different packages were successfully applied to simulate scattering, radiation, electron-positron pair production and other effects connected with channeling of relativistic particles in aligned crystal. The result of the simulation has been validated against data from channeling experiments carried out at SAGA LS. © 2017 Elsevier B.V.","Channeling radiation; Cherenkov radiation; Electron-positron pairs creation; Electronuclear reactions; Parametric X-radiation at channeling; Planar channeling","Codes (symbols); Positrons; Channeling radiation; Cherenkov radiations; Electron-positron pairs; Electronuclear reactions; Parametric X radiation; Planar channeling; Radiation effects",2-s2.0-85016422187
"Ma W., Ma C., Zhao P., Liu W., Ma W.","Variation Trend and Climate Response of NDVI3g in Lu'an Mining Area from 1982 to 2013",2017,"Research of Environmental Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027534856&doi=10.13198%2fj.issn.1001-6929.2017.02.35&partnerID=40&md5=57e00d40e0d46413a17da6df822f0636","Research on long time series Normalized Difference Vegetation Index (NDVI) dynamic changes in mining areas is beneficial to clarify the impacts from global change and to reveal the influence of human activities on the mining area ecological environment. The long time series GIMMS AVHRR NDVI3g (1982-2013, 32 a) global vegetation index and climate information (i.e., precipitation and temperature) were selected as data sets. Data synthesis operation, linear regression and trend fitting contrasting the maximum NDVI, average NDVI and the total NDVI of directly affected areas, buffer areas (10 km and 20 km) and checked areas were used to calculate the change trends of the start, end and length of growing season. Three components in time, space and climate were implied using IDL programming language. Analysis of the sequential correlation results indicated that due to global warming, the mining area start of growing season (SOS) has been postponed 3 d, end of growing season (EOS) has advanced 30 d and length of growing season (LOS) has shorten 33 d -a reduction rate of 10.3 d/(10 a). With the increasing of mining years, the annual average of total NDVI declined during the 32 year research period, with a decline rate of 0.18/(10 a). Analysis of the spatial correlation indicated that the LOS in the buffer area (10 km and 20 km) and checked area (CK) have been extended, and the LOS in the mining area has been shortened. The LOS in mining area is 3 days shorter than that in the CK. The annual average NDVI over 32 years was 0.2936, 0.2964, 0.3250 and 0.2918 for the mining area, the 10 km buffer area, the 20 km buffer area and the CK respectively. The relationships of different research districts were as follows: annual NDVI growth rate was followed by mining area (1.09%) < 10 km buffer area (2.16%) < 20 km buffer area (8.86%) < CK (9.87%). The annual NDVI growth rate in the mining area was lower than that in the CK. The total NDVI in the mining area began to decrease since 1995, while the total NDVI in non-mining area showed an increasing trend. This indicated that coal mining has had an obvious effect on regional ecological processes. The analysis of climate change correlation indicated that the NDVI is increasing with the increasing of temperature and decreasing of precipitation. The annual NDVI growth rate in natural ecological CK is higher than that in the mining area; the LOS in the CK showed a trend of extended with increasing of temperature and decreasing of precipitation, while the LOS in the mining area showed a shortening trend. The NDVI in the mining area, in addition to the interference by climate change, is also the result of mining activities. The results show that it is an indisputable fact that mining has a significant impact on regional ecological processes. (1) Human activities interfere with the evolution process of natural ecology over mining area. (2) Climate change has caused the NDVI to increase over the whole area. (3) Mining activities lead to decreasing NDVI in both mining and non-mining area. (4) The NDVI is influenced more seriously by mining activities than climate change. © 2017, Editorial Board, Research of Environmental Sciences. All right reserved.","GIMMS AVHRR NDVI3g; Growing season; Mining disturbed area; Total NDVI; Variation tendency",,2-s2.0-85027534856
"Wang J.-C., Chen C.","Stability analysis for jointed rock slope in an open iron ore mine",2017,"Meitan Xuebao/Journal of the China Coal Society",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028991706&doi=10.13225%2fj.cnki.jccs.2016.1243&partnerID=40&md5=67c9ff26013c08e9382f12d059e03a2e","According to the structure characteristics of the joint rock mass of the east slope of Gongchangling open iron ore mine, using the 3 dimensional rock non-contact measurement system (3GSM), the investigation and statistical analysis of surface structure are performed. Detailed statistics data including surface structure tendency, inclination, joint trace length, and joints pitch are obtained. Based on Monte-Carlo stochastic simulation method, the three-dimensional network model of jointed rock mass is obtained by the structural network simulation software FracSim3D. The rock quality index RQD is obtained by drilling samples on the three-dimensional network model. Then the RMR index is evaluated combined with on-site point load test. The shear strength parameters of jointed rock mass are obtained by Hoek-Brown method. Jointed rock slope is modeled through the FISH language programming, and the stability of the slope using the discrete element software UDEC is performed. The results show that the slope is in a stable state, but the local wedge failure of rock mass occur in the upper areas of slope, which is controlled by the joints along slope direction. The phenomenon of block out also appears in dispersion zone. © 2017, Editorial Office of Journal of China Coal Society. All right reserved.","3D discontinuity network simulation; Jointed rock mass; Slope; Stability analysis","Computer software; Iron ores; Monte Carlo methods; Ore analysis; Rock drilling; Rock mechanics; Rocks; Shear strength; Stochastic models; Stochastic systems; Surface structure; Jointed rock mass; Monte Carlo stochastic simulation method; Network simulation; Non-contact measurement systems; Shear strength parameters; Slope; Stability analysis; Three-dimensional networks; Slope stability",2-s2.0-85028991706
[No author name available],"Leibniz International Proceedings in Informatics, LIPIcs",2017,"Leibniz International Proceedings in Informatics, LIPIcs",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027263765&partnerID=40&md5=53317c91daa1e6a3d9e980e1fae42041","The proceedings contain 138 papers. The topics discussed include: optimal unateness testers for real-valued functions: adaptivity helps; sublinear time estimation of degree distribution moments: the degeneracy connection; deleting and testing forbidden patterns in multi-dimensional arrays; on the value of penalties in time-inconsistent planning; efficient approximations for the online dispersion problem; dynamic beats fixed: on phase-based algorithms for file migration; quantum automata cannot detect biased coins, even in the limit; a new Holant dichotomy inspired by quantum computation; efficient quantum algorithms for simulating lindblad evolution; approximating language edit distance beyond fast matrix multiplication: ultralinear grammars are where parsing becomes hard!; on the fine-grained complexity of one-dimensional dynamic programming; on finding the Jaccard center; dynamic time warping and geometric edit distance: breaking the quadratic barrier; approximating partition functions of bounded-degree Boolean counting constraint satisfaction problems; inapproximability of the independent set polynomial below the shearer threshold; the complexity of Holant problems over Boolean domain with non-negative weights; a QPTAS for the general scheduling problem with identical release dates; reordering buffer management with a logarithmic guarantee in general metric spaces; when the optimum is also blind: a new perspective on universal optimization; reusable garbled deterministic finite automata from learning with errors; and round-preserving parallel composition of probabilistic-termination cryptographic protocols.",,,2-s2.0-85027263765
"Hayat K., Al-Shukaili N.A., Sultan K.","Alice in Oman: A study on object-first approaches in computer science education",2017,"Education and Information Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021264135&doi=10.1007%2fs10639-016-9499-4&partnerID=40&md5=8e6b220ed6571814a07cbaae152554a0","The success of university-level education depends on the quality of underlying school education and any deficiency therein may be detrimental to a student’s career. This may be more glaring with Computer Science education, given its mercurial nature. In the developing countries, the Computer Science school curricula are usually stuffed with obsolete, unnecessary and dry contents. The problem is multiplied by the lack of qualified school teachers and separate media of instruction at the school and the university. In this paper we are focusing on the computer Science pedagogy at schools, with a possibility of introducing approaches, like Alice. The latter may on one hand be appealing to both the students and teachers and on the other hand may require a lot less training. With that in view, an experiment was designed to teach Alice, to sampled K-12 students, and study the ensued effects. The outcomes were realized in two ways. One, the attendees were required to furnish a small project/task in order to judge their understanding of Alice. Two, the students were surveyed for their views on Alice and possible inclusion of such approaches in their course. Given the brief contact time, the results were found to be promising as most of the respondents were in favor of a change in the approach Computer Science teaching. The tasks were well received by the respondents and most of them carried out the tasks assigned to them, enthusiastically. English language Comprehension was the single largest problem and that’s why the students demonstrated reluctance in adding dialogues on part of the characters. As far as the responses to the questionnaire were concerned, an overwhelming majority had a favorable opinion of the approach. They found it easy to use, understand, comprehend and considered it useful in initiating a novice to programming. They even rated it superior to their current syllabus. Some questions were chosen from the futuristic point of view and the responses were more than expected as the students felt motivated towards studying IT after coming across Alice. The only thing the respondents insisted was the inclusion Arabic language support in the future versions of Alice. © 2016, Springer Science+Business Media New York.","Alice; Computer science education; Information technology; K-12; Object-first approaches",,2-s2.0-85021264135
"Coblenz M.","Principles of usable programming language design",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026733716&doi=10.1109%2fICSE-C.2017.24&partnerID=40&md5=a1e5ca9fd0f16735b8c34a145c8bcb76","Tools for software engineers, such as programming languages and IDEs, should reflect the needs of their users. Unfortunately, designers of programming languages lack strong guidance regarding how to make these tools most effective for users. Though there is a well-developed theory of programming languages, there is little evidence regarding how to use this theory to build languages in which software engineers are most productive. I propose to develop methods for programming language design that fuse results from programming language theory with methods from human-computer interaction so that designers can create effective tools for users. © 2017 IEEE.","Programmer tools; Programming language design; Usability of programming languages","Ada (programming language); Computer programming; Computer programming languages; Human computer interaction; Software engineering; Effective tool; Programming language design; Programming language theory; C (programming language)",2-s2.0-85026733716
"Coblenz M.","Obsidian: A safer blockchain programming language",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023163823&doi=10.1109%2fICSE-C.2017.150&partnerID=40&md5=dbcc7a6b8dee850dba438b94692c66cd","Blockchain platforms, such as Ethereum, promise to facilitate transactions on a decentralized computing platform among parties that have not established trust. Recognition of the unique challenges of blockchain programming has inspired developers to create domain-specific languages, such as Solidity, for programming blockchain systems. Unfortunately, bugs in Solidity programs have recently been exploited to steal money. We propose a new programming language, Obsidian, to make it easier for programmers to write correct programs. © 2017 IEEE.","Blockchain programming; Blockchain security; Programming language usability","Ada (programming language); Computer programming languages; Problem oriented languages; Program debugging; Software engineering; Block-chain; Computing platform; Domain specific languages; C (programming language)",2-s2.0-85023163823
"Richie D.A., Ross J.A.","I can has supercomputer? A novel approach to teaching parallel and distributed computing concepts using a meme-based programming language",2017,"Proceedings - 2017 IEEE 31st International Parallel and Distributed Processing Symposium Workshops, IPDPSW 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028026532&doi=10.1109%2fIPDPSW.2017.104&partnerID=40&md5=8fbaa15be5bcdbfc9aeff2ef7610241b","A novel approach is presented to teach the parallel and distributed computing concepts of synchronization and remote memory access. The single program multiple data (SPMD) partitioned global address space (PGAS) model presented in this paper uses a procedural programming language appealing to undergraduate students. We propose that the amusing nature of the approach may engender creativity and interest using these concepts later in more sober environments. Specifically, we implement parallel extensions to LOLCODE within a source-to-source compiler sufficient for the development of parallel and distributed algorithms normally implemented using conventional high-performance computing languages and APIs. © 2017 IEEE.","component; meme-based learning; parallel and distributed computing","Computer programming languages; Education; Students; Supercomputers; component; High performance computing; meme-based learning; Parallel and distributed algorithms; Parallel and distributed computing; Partitioned Global Address Space; Procedural programming languages; Single program multiple data; Distributed computer systems",2-s2.0-85028026532
"Alhalhouli Z.T., Al Obisat F.M., Alshabatat T.E., Alrawashdeh T.I.","Assessing the effectiveness and usability of using pair programming to improve programming language learning, productivity, and code quality",2017,"Journal of Theoretical and Applied Information Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021737271&partnerID=40&md5=1910929d21eba9d98734a3dc5fc1f9aa","Programming is a major challenge faced by universities students at different levels. A significant learning outcome that emerged in recent years is working in teams, wherein two programmers can engage in pair programming to work on a single task as a group. This study examined the usability and effectiveness of using pair programming. We also evaluated the effects of pair programming on student results, time consumed, and number of errors, Big-O notation, and time complexity. The mixed method approach was applied by formulating a questionnaire and three different projects. We applied a novel strategy for creating pairs of students from different levels and courses in Tafila Technical University. Results indicated that pair programming is feasible and effective for educational purposes. Positive results were also obtained for programming learning, time, performance, and code quality. Programming is a major challenge faced by universities students at different levels. A significant learning outcome that emerged in recent years is working in teams, wherein two programmers can engage in pair programming to work on a single task as a group. This study examined the usability and effectiveness of using pair programming. We also evaluated the effects of pair programming on student results, time consumed, and number of errors, Big-O notation, and time complexity. The mixed method approach was applied by formulating a questionnaire and three different projects. We applied a novel strategy for creating pairs of students from different levels and courses in Tafila Technical University. Results indicated that pair programming is feasible and effective for educational purposes. Positive results were also obtained for programming learning, time, performance, and code quality. © 2005 – ongoing JATIT & LLS.","Collaborative learning; Pair programming experience; Teaching methods; Team performance; Usability",,2-s2.0-85021737271
"Wang B.J.L., Zimmer U.R.","Pure concurrent programming",2017,"Proceedings - 2017 IEEE 31st International Parallel and Distributed Processing Symposium Workshops, IPDPSW 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028082350&doi=10.1109%2fIPDPSW.2017.150&partnerID=40&md5=f8667161251becf8baba54fb2fea13f5","Arvo is a new programming language focuses on concurrency. Its primary goal is to provide the programmer with an simple and concise way to design concurrent systems without explicitly identifying and differentiating concurrent and sequential sections. It does this by preventing the programmer from being able to explicitly define an order between statements or expressions. Thus Arvo conceptually launches all function calls concurrently, while preserving existing data dependencies. Required synchronization is driven purely by those data dependencies and unnecessary locks are avoided. Given that Arvo potentially launches large numbers of threads it also needs a simple way to statically determine when threads end. This paper introduces core concepts of Arvo, which constitute the foundation of its concurrency model. We will also investigate how (or if) expressiveness is being affected by Arvo's design choices. © 2017 IEEE.","compilers; Concurrency; programming languages","Computer programming; Computer programming languages; Concurrency; Concurrency modeling; Concurrent programming; Concurrent systems; Data dependencies; Function calls; Program compilers",2-s2.0-85028082350
"Makela J.-M., Forsell M., Leppanen V.","Towards a language framework for thick control flows",2017,"Proceedings - 2017 IEEE 31st International Parallel and Distributed Processing Symposium Workshops, IPDPSW 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028027768&doi=10.1109%2fIPDPSW.2017.119&partnerID=40&md5=41cff3bfa34825ec8829908b1cdb1d51","In the recent years the search for scalability in terms of computing power has led to very complex parallel computer architectures which require greater control of the storage and computation resources to utilize all the available hardware capacity for optimal performance. New solutions in the level of programming languages/models have increased the reliance and need for threads. A system with a huge number of threads can face problems with thread micro-management, smooth scaling between data and task parallelism, portability, and consistency. We present TCF++, a new concurrent C/C++ language extension generalizing on the idea of threads with so called thick control flows. Opposed to threading, thick control flows provide a way to orchestrate computation using lower number of independent actors, dynamically adapting to problem size. The language extension approach is chosen to support mixing with legacy code. We qualitatively analyze the new language's eligibility and explain its idiomatic use with a selection of core parallel algorithm kernels. © 2017 IEEE.","control structures; parallel architecture; Parallel programming; programming examples; programming language; thread","Computer architecture; Computer hardware; Computer programming languages; Concurrency control; Digital storage; Information management; Parallel architectures; Parallel programming; Problem oriented languages; Computation resources; Control structure; Language extensions; Number of threads; Optimal performance; Parallel computer architecture; Thick control flows; thread; C (programming language)",2-s2.0-85028027768
"Jin X., Niu N.","Short-term revisit during programming tasks",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026726243&doi=10.1109%2fICSE-C.2017.93&partnerID=40&md5=2076a9f8328d2c4c20cea9dce5edd1a0","Previous studies of Web page revisitation were only focused on long-term revisit ranging from hours to days. In this paper, we study the short-term revisit of less than one hour such as the revisit behavior during a small programming task. We first perform an exploratory study to observe the short-term revisit phenomenon. We then perform controlled experiments with our designed tool support as treatment by inviting 20 biomedical software developers to perform two software change tasks. Our results show that the participants with tool support used 19.7% less time than the ones without tool support. © 2017 IEEE.","End-user programming; Foraging theory; Revisitation; Software change tasks","Computer programming; Software engineering; Websites; Controlled experiment; End user programming; Exploratory studies; Foraging theory; Programming tasks; Re visitations; Software change; Software developer; C (programming language)",2-s2.0-85026726243
"Srinivasan R.M., Jetcheva J.G., Chander A.","Last mile end-user programmers: programming exposure, influences, and preferences of the masses",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026770890&doi=10.1109%2fICSE-C.2017.129&partnerID=40&md5=f109012d3597f154a51fdb40168ccb99","In this paper, we set out to explore the level of programming experience present among the masses (the last mile end-user programmers), the influence of various factors such as early exposure to software, as well as age, on programming experience, their effects on the types of software people mightwant to create, and the software development approaches they prefer. © 2017 IEEE.","End user programming; Experiences; Software","Computer programming; Computer software; Software design; Software engineering; End user programmers; End user programming; Experiences; Last mile; Programming experience; Software development approach; C (programming language)",2-s2.0-85026770890
"Campusano M.","Live programming the behavioral layer of robots",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026749983&doi=10.1109%2fICSE-C.2017.158&partnerID=40&md5=cf8a3a174d608da94239c68b363c18ad","Robotic development suffers from a long cognitive distance between the code and the resulting behavior. This is due to the several steps necessary to build robotic behaviors: writing the code, compiling it, deploying it and finally testing it on the robot. All this slows down development and can make experimentation prohibitively expensive. In contrast, Live Programming tightens the feedback loop, minimizing the cognitive distance. As a result, programmers benefit from an immediate connection with the program that they are making thanks to an immediate, 'live' feedback of program behavior. This allows for extremely rapid creation, or variation, of robot behavior and for dramatically increased debugging speed. In this research, we fist explore the concept of live programming in the development of robot behaviors. Second, we present how we can validate our approach to improve the development of robotic behaviors. © 2017 IEEE.","Live Programming; Live Robot Programming; Nested State Machines; Robot","Behavioral research; Robot programming; Robotics; Robots; Software engineering; Cognitive distances; Feed-back loop; Program behavior; Robot behavior; Robotic behavior; State machine; C (programming language)",2-s2.0-85026749983
"Salehian S., Liu J., Yan Y.","Comparison of threading programming models",2017,"Proceedings - 2017 IEEE 31st International Parallel and Distributed Processing Symposium Workshops, IPDPSW 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028028245&doi=10.1109%2fIPDPSW.2017.141&partnerID=40&md5=86f5b3e606ff0af6907bc8ce8d35d2f4","In this paper, we provide comparison of languagefeatures and runtime systems of commonly used threadingparallel programming models for high performance computing, including OpenMP, Intel Cilk Plus, Intel TBB, OpenACC, NvidiaCUDA, OpenCL, C++11 and PThreads. We then report ourperformance comparison of OpenMP, Cilk Plus and C++11 fordata and task parallelism on CPU using benchmarks. The resultsshow that the performance varies with respect to factors such asruntime scheduling strategies, overhead of enabling parallelismand synchronization, load balancing and uniformity of taskworkload among threads in applications. Our study summarizesand categorizes the latest development of threading programmingAPIs for supporting existing and emerging computer architec-tures, and provides tables that compare all features of differentAPIs. It could be used as a guide for users to choose the APIsfor their applications according to their features, interface andperformance reported. © 2017 IEEE.","data parallelism; memory abstraction; mutual exclusion; parallel programming; synchronization; task parallelism; threading","Application programming interfaces (API); Parallel programming; Synchronization; Data parallelism; High performance computing; Latest development; Mutual exclusions; Programming models; Scheduling strategies; Task parallelism; threading; C (programming language)",2-s2.0-85028028245
"Zhang W., Guo L.","Hardware design of automatic feeding system in tank area based on PCS7 software",2017,"Proceedings - 2017 32nd Youth Academic Annual Conference of Chinese Association of Automation, YAC 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026757132&doi=10.1109%2fYAC.2017.7967491&partnerID=40&md5=b7547aa2e61961ea4ceab3cbac192409","The purpose of this paper is to introduce a set of automatic feeding system in the tank area, to achieve a variety of material handling precision control. This paper introduces the composition and function of the system and describes the characteristics and application of PCS7 software in the automatic feeding control system. The system was designed and developed based on Siemens PCS7 software. The programming language used for this project is the SFC programming language. The system's lower computer using the Siemens S7-400 PLC, the function is to achieve the automatic delivery of 10 different materials to 47 metering tanks in 16 different positions of 5 production plants quantitatively and automatically. The system is currently in Zibo Xinhua pharmaceutical five ammonia tank area successfully put into use, run well, and applied for the Zibo City Science and Technology Progress Award. © 2017 IEEE.","Automatic Feeding System; SFC Programming Language; Siemens PCS7 Software; Siemens S7-400 PLC","Ada (programming language); Computer programming languages; Feeding; Materials handling; Materials handling equipment; Tanks (containers); Automatic feeding; Automatic feeding systems; Material handling; Precision control; Production plant; Science and technology progress; Siemens; Siemens s7-400plc; Application programs",2-s2.0-85026757132
"Basu S., Foster N., Hojjat H., Palacharla P., Skalka C., Wang X.","Life on the Edge: Unraveling Policies into Configurations",2017,"Proceedings - 2017 ACM/IEEE Symposium on Architectures for Networking and Communications Systems, ANCS 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027697030&doi=10.1109%2fANCS.2017.31&partnerID=40&md5=275e3a410d00053b71843aebe15816a6","Current frameworks for network programming assume that the network contains a collection of homogenous devices that can be rapidly reconfigured in response to changing policies and network conditions. Unfortunately, these assumptions are incompatible with the realities of modern networks, which contain legacy devices that offer diverse functionality and can only be reconfigured slowly. Additionally, network service providers need to walk a fine line between providing flexibility to users, and maintaining the integrity and reliability of their core networks. These issues are particularly evident in optical networks which are used by ISPs and WANs and provide high bandwidth at the cost of limited flexibility and long reconfiguration times. This paper presents a different approach to implementing high-level policies, by pushing functionality to the edge and using the core merely for transit. Building on the NetKAT framework and leveraging linear programming problem solvers, we develop techniques for analyzing and transforming policies into configurations that can be installed at the edge of the network. Furthermore, our approach is extensible to include constraints crucial to optical networks such as path constraints and fault tolerance. We develop a working implementation using off-the-shelf solvers and evaluate our approach on a set of large-scale optical topologies. © 2017 IEEE.","linear programming; optical networks; programming languages; Software-defined networks","Computer programming; Computer programming languages; Fault tolerance; Fiber optic networks; Linear programming; Software defined networking; AS paths; Core networks; High bandwidth; High level policies; Linear programming problem; Network condition; Network programming; Network service providers; Network architecture",2-s2.0-85027697030
"Xu W., Xu D., El Ariss O., Liu Y., Alatawi A.","Statistical Unigram Analysis for Source Code Repository",2017,"Proceedings - 2017 IEEE 3rd International Conference on Multimedia Big Data, BigMM 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027725617&doi=10.1109%2fBigMM.2017.13&partnerID=40&md5=806b321859d13bbdb43052e3d8808b90","Unigram is a fundamental element of n-gram in natural language processing. However, unigrams collected from a natural language corpus are unsuitable for solving problems in the domain of computer programming languages. In this paper, we analyze the properties of unigrams collected from an ultra-large source code repository. Specifically, we have collected 1.01 billion unigrams from 0.7 million open source projects hosted at GitHub.com. By analyzing these unigrams, we have discovered statistical patterns regarding (1) how developers name variables, methods, and classes, and (2) how developers choose abbreviations. Our study describes a probabilistic model for solving a well-known problem in source code analysis: how to expand a given abbreviation to its original indented word. It shows that the unigrams collected from source code repositories are essential resources to solving the domain specific problems. © 2017 IEEE.","abbreviations; n-gram; programming language; source code; ultra-large-scale analysis; unigram","Codes (symbols); Computational linguistics; Computer programming; Computer programming languages; Natural language processing systems; Open source software; Problem oriented languages; Problem solving; abbreviations; Large-scale analysis; N-grams; Source codes; unigram; Big data",2-s2.0-85027725617
"Tan S.H., Yi J., Yulis, Mechtaev S., Roychoudhury A.","Codeflaws: A programming competition benchmark for evaluating automated program repair tools",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026737226&doi=10.1109%2fICSE-C.2017.76&partnerID=40&md5=3b93ea710a3d0cae0fd27eb47a7438a8","Several automated program repair techniques have been proposed to reduce the time and effort spent in bug-fixing. While these repair tools are designed to be generic such that they could address many software faults, different repair tools may fix certain types of faults more effectively than other tools. Therefore, it is important to compare more objectively the effectiveness of different repair tools on various fault types. However, existing benchmarks on automated program repairs do not allow thorough investigation of the relationship between fault types and the effectiveness of repair tools. We present Codeflaws, a set of 3902 defects from 7436 programs automatically classified across 39 defect classes (we refer to different types of fault as defect classes derived from the syntactic differences between a buggy program and a patched program). © 2017 IEEE.","Automated program repair; Benchmark; Defect classes; Empirical evaluation","Automation; Benchmarking; Defects; Repair; Software engineering; Bug-fixing; Defect class; Empirical evaluations; Fault types; Repair techniques; Repair tools; Software fault; C (programming language)",2-s2.0-85026737226
"Rahman M.M., Roy C.K., Lo D.","RACK: Code search in the IDE using crowdsourced knowledge",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026756998&doi=10.1109%2fICSE-C.2017.11&partnerID=40&md5=a0455ac2a80949467bc338369622c074","Traditional code search engines often do not perform well with natural language queries since they mostly apply keyword matching. These engines thus require carefully designed queries containing information about programming APIs for code search. Unfortunately, existing studies suggest that preparing an effective query for code search is both challenging and time consuming for the developers. In this paper, we propose a novel code search tool-RACK-that returns relevant source code for a given code search query written in natural language text. The tool first translates the query into a list of relevant API classes by mining keyword-API associations from the crowdsourced knowledge of Stack Overflow, and then applies the reformulated query to GitHub code search API for collecting relevant results. Once a query related to a programming task is submitted, the tool automatically mines relevant code snippets from thousands of open-source projects, and displays them as a ranked list within the context of the developer's programming environment-the IDE. Tool page: http://www.usask.ca/~masud.rahman/rack. © 2017 IEEE.","API association; Code search; Crowdsourced knowledge; Query reformulation; Stack Overflow","Application programming interfaces (API); Codes (symbols); Computer programming; Integrodifferential equations; Natural language processing systems; Open source software; Open systems; Search engines; Software engineering; Code search; Crowdsourced knowledge; Natural language queries; Natural language text; Open source projects; Programming environment; Query reformulation; Stack overflow; C (programming language)",2-s2.0-85026756998
"Rodeghero P., McMillan C., Shirey A.","API Usage in Descriptions of Source Code Functionality",2017,"Proceedings - 2017 IEEE/ACM 1st International Workshop on API Usage and Evolution, WAPI 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026757933&doi=10.1109%2fWAPI.2017.3&partnerID=40&md5=8174be784cc858427776fac2441a9b29","In this paper, we present a study exploring the use of API keywords within method summaries. We conducted a web-based study where we asked participants to rank Java method summaries based on five levels of detail, from low level to high level. We found that programmers widely use API in both high and low level summaries. Specifically, we found that 76.78% of higher level summaries contain Java API keywords. Additionally, we found that 93.75% of lower level summaries also contain them. This also shows that, in general, as the detail level decreases, the number of API keywords within the summary increases. It is our hope that this line of research will spark a discussion about API usage outside of source code. It is possible that method summaries are not the only form of documentation that API usage plays an important role. We believe these may be important results that could lead to an improvement for API usability design. © 2017 IEEE.","API usage; Levels of detail; Source code summaries","Application programming interfaces (API); Codes (symbols); Computer programming; Computer programming languages; API usage; Java API; Java methods; Levels of detail; Source codes; Usability design; Web based; Java programming language",2-s2.0-85026757933
"Broll B., Ledeczi A., Volgyesi P., Sallai J., Maroti M., Vanags C.","Introducing parallel and distributed computing to K12",2017,"Proceedings - 2017 IEEE 31st International Parallel and Distributed Processing Symposium Workshops, IPDPSW 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028080061&doi=10.1109%2fIPDPSW.2017.81&partnerID=40&md5=6c68617132d41cc9cf2312f0878d9978","The paper introduces a visual programming language and corresponding web- and cloud-based development environment called NetsBlox. NetsBlox is an extension of Snap! and it builds upon its visual formalism as well as its open source code base. NetsBlox adds distributed programming capabilities to Snap! by introducing two simple abstractions: messages and NetsBlox services. Messages containing data can be exchanged by two or more NetsBlox programs running on different computers connected to the Internet. Services are called on a client program and are executed on the NetsBlox server. These two abstractions make it possible to create distributed programs, for example multi-player games or client-server applications. We believe that NetsBlox provides increased motivation to high-school students to become creators and not just consumers of technology. At the same time, it helps teach them basic distributed programming concepts. © 2017 IEEE.","computer science education; distributed programming; visual programming","Abstracting; Application programs; Distributed computer systems; Education computing; Open source software; Open systems; Visual languages; Client-server applications; Computer Science Education; Development environment; Distributed programming; High school students; Parallel and distributed computing; Visual programming; Visual programming languages; Computer programming",2-s2.0-85028080061
"Sankaran A., Aralikatte R., Mani S., Khare S., Panwar N., Gantayat N.","DARVIZ: Deep abstract representation, visualization, and verification of deep learning models",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering: New Ideas and Emerging Results Track, ICSE-NIER 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026730806&doi=10.1109%2fICSE-NIER.2017.13&partnerID=40&md5=8b7d2a471beccbb90ba2ad78df2425a8","Traditional software engineering programming paradigms are mostly object or procedure oriented, driven by deterministic algorithms. With the advent of deep learning and cognitive sciences there is an emerging trend for data-driven programming, creating a shift in the programming paradigm among the software engineering communities. Visualizing and interpreting the execution of a current large scale data-driven software development is challenging. Further, for deep learning development there are many libraries in multiple programming languages such as TensorFlow (Python), CAFFE (C++), Theano (Python), Torch (Lua), and Deeplearning4j (Java), driving a huge need for interoperability across libraries. We propose a model driven development based solution framework, that facilitates intuitive designing of deep learning models in a platform agnostic fashion. This framework could potentially generate library specific code, perform program translation across languages, and debug the training process of a deep learning model from a fault localization and repair perspective. Further we identify open research problems in this emerging domain, and discuss some new software tooling requirements to serve this new age data-driven programming paradigm. © 2017 IEEE.","deep learning; model driven development; model validation; software tools; visualization","Computer aided software engineering; Computer programming; Computer software; Deep learning; Embedded systems; Flow visualization; High level languages; Libraries; Object oriented programming; Program debugging; Program translators; Software design; Software engineering; Visualization; Abstract representation; Deterministic algorithms; Engineering community; Learning and cognitive; Model driven development; Model validation; Program translation; Programming paradigms; C++ (programming language)",2-s2.0-85026730806
"Kechagia M., Sharma T., Spinellis D.","Towards a context dependent Java exceptions hierarchy",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026758384&doi=10.1109%2fICSE-C.2017.134&partnerID=40&md5=60c264d8de3efeb9a3d71fb1aea37e42","The role of exceptions is crucial for the robustness of modern applications and critical systems. Despite this, there is a long debate among researchers, programming language designers, and practitioners regarding the usefulness and appropriateness of the available exception types and their classification. In this paper, we examine Java exceptions and propose a new class hierarchy and compile-time mechanisms that take into account the context in which exceptions can arise. We believe that the increased specificity of exception handling based on our proposal can boost its effectiveness and lead to fewer application failures. © 2017 IEEE.","Exception handling; Java; Reliability","Java programming language; Reliability; Software engineering; Application failure; Class hierarchies; Context dependent; Critical systems; Exception handling; Java; Java exceptions; Modern applications; C (programming language)",2-s2.0-85026758384
"Mostafa S., Rodriguez R., Wang X.","A study on behavioral backward incompatibility bugs in Java software libraries",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026779692&doi=10.1109%2fICSE-C.2017.101&partnerID=40&md5=bc548f6895c644256e8135568addd2fa","Nowadays, due to the frequent technological innovationand market changes, software libraries are evolving veryquickly. To make sure that existing client software applicationsare not broken after a library update, backward compatibilityhas always been one of the most important requirements duringthe evolution of software platforms and libraries. However, due to various reasons, backward compatibility is seldom fullyachieved in practice, and many relevant software failures arereported. Therefore, it is important to understand the status, major reasons, and impact of backward incompatibilities in realworld software. Previous studies on this topic mainly focus onAPI signature changes between consecutive versions of softwarelibraries, but behavioral changes of APIs with untouched signaturesare actually more dangerous and are causing most realworldbugs because they cannot be easily detected. This paperpresents an empirical study on 126 real-world software bugreports on backward incompatibilities of software libraries. Wefind that 67% of fixed client bugs caused by backward incompatibilitiesin software libraries are fixed by client developers, through several simple change patterns made to the backwardincompatible API invocations. © 2017 IEEE.","Backward Incompatibilities; Empirical Study; Java Software","Application programming interfaces (API); Computer software; Java programming language; Program debugging; Software engineering; Backward compatibility; Backward Incompatibilities; Behavioral changes; Empirical studies; Java software; Software failure; Software libraries; Software platforms; C (programming language)",2-s2.0-85026779692
"Pereira R., Carcao T., Couto M., Cunha J., Fernandes J.P., Saraiva J.","Helping programmers improve the energy efficiency of source code",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026734661&doi=10.1109%2fICSE-C.2017.80&partnerID=40&md5=ea265374a4d5df9eb97e720b5c8355f9","This paper briefly proposes a technique to detect energy inefficient fragments in the source code of a software system. Test cases are executed to obtain energy consumption measurements, and a statistical method, based on spectrum-basedfault localization, is introduced to relate energy consumption to the system's source code. The result of our technique is an energy ranking of source code fragments pointing developers to possible energy leaks in their code. © 2017 IEEE.","Fault Localization; Green Computing; Program Optimization","Codes (symbols); Computer programming; Computer programming languages; Energy efficiency; Energy utilization; Green computing; Software engineering; Energy consumption measurements; Fault localization; Program optimization; Software systems; Source codes; Test case; C (programming language)",2-s2.0-85026734661
"Chari G., Garbervetsky D., Marr S.","Fully-reflective VMs for ruling software adaptation",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026750725&doi=10.1109%2fICSE-C.2017.144&partnerID=40&md5=aa74320df4d3035c906911810c465b5a","A recent survey on paradigms for software adaptation at the language level assessed contemporary reflective systems (RS), aspect-oriented programming (AOP), and context-oriented programming (COP) as three well-established approaches. The survey did not find a clear winner. Our opinion is that this is due to the fact that none of these approaches is flexible enough to handle the diversity of possible adaptation scenarios. The reason is that instead of operating directly on the entity that conceptually requires the adaptation, these approaches often require to handle the adaptations in an indirect fashion. In this paper we advocate that a suitable paradigm for software adaptation at the language level must enable direct modification to every concept at both, the application and the execution environment level. This is enabled by a Fully-Reflective Execution Environment (FREE), a flavor of virtual machine in which every component such as the interpreter and the memory is accessible for inspection and modification, programmatically, and at run time. Consequently, we advocate and illustrate how the notion of a FREE extends RS and subsumes AOP and COP. © 2017 IEEE.","Reflection; Software Adaptation; Virtual Machines","Application programs; Aspect oriented programming; Network security; Reflection; Software engineering; Surveys; Virtual machine; Adaptation scenarios; Aspect-Oriented Programming (AOP); Context oriented programming; Direct modification; Execution environments; Language levels; Reflective systems; Software adaptation; C (programming language)",2-s2.0-85026750725
"Kubelka J.","Artifact driven communication to improve program comprehension",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026768911&doi=10.1109%2fICSE-C.2017.47&partnerID=40&md5=9eb553fe57deeb2105f0277864657bc7","Developer communication is an important factor during program comprehension. Live programming environments encourage developers to comprehend applications through manipulation of running instances - liveness. Such application exploration is interrupted whenever programmers need to communicate an issue with dislocated co-workers. Describing the issue becomes challenging as programmers use text based communication mediums, e.g., emails or chats. The issues are magnified during bug day events, where developers around the world meet together in order to improve a project. Communication and coordination need to be increased, but the infrastructure stays the same. We target the research gap by introducing the COLLABORATIVE PLAYGROUND, a tool that exposes liveness into developer communication during programming change tasks and integrates coordination needs during bug day events. We will evaluate our approach by deploying the COLLABORATIVE PLAYGROUND during a series of Bug Day events for Pharo, one of the most active live programming platforms in existence. © 2017 IEEE.","Collaborative Programming; Live Programming Environment; Qualitative Study","Computer programming; Software engineering; Change tasks; Collaborative programming; IMPROVE-A; Liveness; Program comprehension; Programming environment; Qualitative study; Text-based communication; C (programming language)",2-s2.0-85026768911
"Reiss S.P., Xin Q.","A framework for a programmer's minion",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026755088&doi=10.1109%2fICSE-C.2017.54&partnerID=40&md5=2af559edf045c47ec165e123695a2547","Programming environments should help theprogrammer. Today's environments do a lot along these lines, yet more is possible. We are developing facilities within theCode Bubbles environment to proactively assist theprogrammer. These facilities attempt to take care of mundanetasks that the programmer otherwise would need to do, effectively acting as a programmer's minion. This paperdescribes the framework provided by the environment tosupport these tasks and an evaluation of the effectiveness of theinitial minion implementation. © 2017 IEEE.","Automatic correction; Programming environments; Programming tools","Computer programming; Software engineering; Automatic corrections; Programming environment; Programming tools; C (programming language)",2-s2.0-85026755088
"Nguyen A.T., Rigby P.C., Nguyen T.V., Karanfil M., Nguyen T.N.","Statistical translation of english texts to API code templates",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026726997&doi=10.1109%2fICSE-C.2017.81&partnerID=40&md5=61e5a0065f1b4aa8fa48011c9577d4f4","We develop T2API, a context-sensitive, graph-based statisticaltranslation approach that takes as input an English description of aprogramming task and synthesizes the corresponding API code templatefor the task. We train T2API to statistically learn the alignmentsbetween English and APIs and determine the relevant API elements. Thetraining is done on StackOverflow, which is a bilingual corpus onwhich developers discuss programming problems in two types oflanguage: English and programming language. T2API considers both thecontext of the words in the input query and the context of APIelements that often go together in the corpus. The derived APIelements with their relevance scores are assembled into an API usageby GraSyn, our novel graph-based API synthesis algorithm thatgenerates a graph representing an API usage from a large codecorpus. Importantly, T2API is capable of generating new API usagesfrom previously seen sub-usages. © 2017 IEEE.","API Usage Synthesis; Statistical Machine Translation; Text-to-Code Translation","Application programming interfaces (API); Codes (symbols); Computer aided language translation; Graphic methods; Software engineering; Bilingual corpora; Code translation; Context sensitive; Programming problem; Relevance score; Statistical machine translation; Statistical translation; Synthesis algorithms; C (programming language)",2-s2.0-85026726997
"Akhmetova D., Iakymchuk R., Ekeberg O., Laure E.","Performance study of multithreaded MPI and Openmp tasking in a large scientific code",2017,"Proceedings - 2017 IEEE 31st International Parallel and Distributed Processing Symposium Workshops, IPDPSW 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028041248&doi=10.1109%2fIPDPSW.2017.128&partnerID=40&md5=c1bf98da5f101ee155c3d02555120a5f","With a large variety and complexity of existing HPC machines and uncertainty regarding exact future Exascale hardware, it is not clear whether existing parallel scientific codes will perform well on future Exascale systems: they can be largely modified or even completely rewritten from scratch. Therefore, now it is important to ensure that software is ready for Exascale computing and will utilize all Exascale resources well. Many parallel programming models try to take into account all possible hardware features and nuances. However, the HPC community does not yet have a precise answer whether, for Exascale computing, there should be a natural evolution of existing models interoperable with each other or it should be a disruptive approach. Here, we focus on the first option, particularly on a practical assessment of how some parallel programming models can coexist with each other. This work describes two API combination scenarios on the example of iPIC3D [26], an implicit Particle-in-Cell code for space weather applications written in C++ and MPI plus OpenMP. The first scenario is to enable multiple OpenMP threads call MPI functions simultaneously, with no restrictions, using an MPI THREAD MULTIPLE thread safety level. The second scenario is to utilize the OpenMP tasking model on top of the first scenario. The paper reports a step-by-step methodology and experience with these API combinations in iPIC3D; provides the scaling tests for these implementations with up to 2048 physical cores; discusses occurred interoperability issues; and provides suggestions to programmers and scientists who may adopt these API combinations in their own codes. © 2017 IEEE.","API interoperability; Exascale; MPI-THREAD-MULTIPLE thread safety; multithreaded MPI; OpenMP tasks; performance; programming models","C++ (programming language); Codes (symbols); Computer programming; Hardware; Interoperability; Parallel programming; Exascale; Multiple threads; Multithreaded; OpenMP tasks; performance; Programming models; Application programming interfaces (API)",2-s2.0-85028041248
"Denny J.E., Lee S., Vetter J.S.","Language-Based Optimizations for Persistence on Nonvolatile Main Memory Systems",2017,"Proceedings - 2017 IEEE 31st International Parallel and Distributed Processing Symposium, IPDPS 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027700585&doi=10.1109%2fIPDPS.2017.60&partnerID=40&md5=8fc528d3f7d1e6a3b026e2ccf8168b06","Substantial advances in nonvolatile memory (NVM) technologies have motivated wide-spread integration of NVM into mobile, enterprise, and HPC systems. Recently, considerable research has focused on architectural integration of NVM and respective programming systems, exploiting NVM's trait of persistence correctly and efficiently. In this regard, we design several novel language-based optimization techniques for programming NVM and demonstrate them as an extension of our NVL-C system. Specifically, we focus on optimizing the performance of atomic updates to complex data structures residing in NVM. We build on two variants of automatic undo logging: Canonical undo logging, and shadow updates. We show these techniques can be implemented transparently and efficiently, using dynamic selection and other logging optimizations. Our empirical results on several applications gathered on an NVM testbed illustrate that our cost-model-based dynamic selection technique can accurately choose the best logging variant across different NVM modes and input sizes. In comparison to statically choosing canonical undo logging, this improvement reduces execution time to as little as 53% for block-addressable NVM and 73% for emulated byte-addressable NVM on a Fusion-io ioScale device. © 2017 IEEE.","compilers; cost modeling; flash; language-based optimizations; LLVM; non-volatile memory; NVL-C; persistent memory; software transactional memory; SSD","Data storage equipment; Digital storage; Flash memory; Modeling languages; Nonvolatile storage; Program compilers; Cost modeling; flash; LLVM; Non-volatile memory; Persistent memory; Software transactional memory; C (programming language)",2-s2.0-85027700585
"Perez J.M., Beltran V., Labarta J., Ayguade E.","Improving the Integration of Task Nesting and Dependencies in OpenMP",2017,"Proceedings - 2017 IEEE 31st International Parallel and Distributed Processing Symposium, IPDPS 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027704425&doi=10.1109%2fIPDPS.2017.69&partnerID=40&md5=5d5e4b8845331391318102b62f5d6fce","The tasking model of OpenMP 4.0 supports both nesting and the definition of dependences between sibling tasks. A natural way to parallelize many codes with tasks is to first taskify the high-level functions and then to further refine these tasks with additional subtasks. However, this top-down approach has some drawbacks since combining nesting with dependencies usually requires additional measures to enforce the correct coordination of dependencies across nesting levels. For instance, most non-leaf tasks need to include a taskwait at the end of their code. While these measures enforce the correct order of execution, as a side effect, they also limit the discovery of parallelism. In this paper we extend the OpenMP tasking model to improve the integration of nesting and dependencies. Our proposal builds on both formulas, nesting and dependencies, and benefits from their individual strengths. On one hand, it encourages a top-down approach to parallelizing codes that also enables the parallel instantiation of tasks. On the other hand, it allows the runtime to control dependencies at a fine grain that until now was only possible using a single domain of dependencies. Our proposal is realized through additions to the OpenMP task directive that ensure backward compatibility with current codes. We have implemented a new runtime with these extensions and used it to evaluate the impact on several benchmarks. Our initial findings show that our extensions improve performance in three areas. First, they expose more parallelism. Second, they uncover dependencies across nesting levels, which allows the runtime to make better scheduling decisions. And third, they allow the parallel instantiation of tasks with dependencies between them. © 2017 IEEE.","computer languages; OpenMP; runtime library; single dependency domain; task decomposition; task dependencies; task nesting; taskwait; top-down programming; weak dependencies; weakwait","Codes (symbols); Computer programming; Computer programming languages; OpenMP; Run-time library; single dependency domain; Task decomposition; Task dependencies; task nesting; taskwait; Topdown; weak dependencies; weakwait; Application programming interfaces (API)",2-s2.0-85027704425
"Luo C., He F., Yan D., Zhang D., Zhou X., Wang B.-Y.","PSpec: A formal specification language for fine-grained control on distributed data analytics",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026780511&doi=10.1109%2fICSE-C.2017.120&partnerID=40&md5=faf63ee78ccf740e59304524c2396644","Organizations often share business data with third-parties to perform data analytics. However, the business data may contain a lot of customers' private information. One major concern of these organizations is thus to ensure such private information is properly used. In this paper, we present PSpec, a formal language for specifying data usage restrictions in distributed data analytics. Compared with previous works, PSpec specializes in data analytics and provides explicit support for data desensitization and association to balance data privacy and utility. We moreover present redundancy and conflict analysis algorithms to help data owners write PSpec privacy policies. To evaluate PSpec we carry out a case study on TPC-DS benchmark. The results demonstrate applicability and practicality of the PSpec language. © 2017 IEEE.","Data Analytics; Data Use Policy; Specification Languages","C (programming language); Formal languages; Formal specification; Software engineering; Specification languages; Specifications; Business data; Conflict analysis; Data analytics; Distributed data analytics; Fine-grained control; Privacy policies; Private information; Third parties; Data privacy",2-s2.0-85026780511
"Stornaiuolo L., Parravicini A., Durelli G., Santambrogio M.D.","Exploiting FPGAs from higher level languages a signal analysis case study",2017,"Proceedings - 2017 IEEE 31st International Parallel and Distributed Processing Symposium Workshops, IPDPSW 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028058772&doi=10.1109%2fIPDPSW.2017.68&partnerID=40&md5=0b230442287ea124b60239b7b4f55272","Field Programmable Gate Arrays (FPGAs) are usually perceived as difficult to exploit due to the High Level of expertise required to program them. In the last years, the major FPGAs vendors have produced different High Level Synthesis (HLS) tools to help programmers during the flow of acceleration of their algorithms through the hardware architecture. However, these tools often use languages considered low level from the point of view of data scientists and are still much too difficult to use for software developers. This complexity limits their usage in a number of fields, from data science to signal processing, where the computational power offered by FPGAs could be highly beneficial. One way to overcome this problem is to realize libraries of widely used algorithms that transparently offload the computation to the FPGAs device from modern High Level Languages. Our work presents an interface between R, a language commonly used by statisticians and data scientists, and an FPGA connected via PCI-Express (PCIe). We use the Reusable Integration Framework for FPGA Accelerators (RIFFA) to send and receive data from PCIe connection. To showcase the use of the described interface and the improvements given by making use of FPGAs in signal analysis applications we used Xilinx Vivado Design Suite to implement an accelerated and optimized version of the Autocorrelation Function (ACF) present in the default libraries used by R. © 2017 IEEE.",,"Autocorrelation; Computer programming languages; Field programmable gate arrays (FPGA); High level synthesis; Libraries; Signal analysis; Signal processing; Autocorrelation functions; Computational power; Fpga accelerators; Hardware architecture; Higher-level languages; Integration frameworks; PCI-Express (PCIe); Software developer; High level languages",2-s2.0-85028058772
"Mehrabi M., Giacaman N., Sinnen O.","Annotation-based parallelization of Java code",2017,"Proceedings - 2017 IEEE 31st International Parallel and Distributed Processing Symposium Workshops, IPDPSW 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028038316&doi=10.1109%2fIPDPSW.2017.23&partnerID=40&md5=1a8ee776e990a15d3f7d3edb7ba70d96","The majority of mainstream programming languages support parallel computing via extended libraries that require restructuring of sequential code. Library-based features are portable, but tend to be verbose and usually reduce the understandability and modifiability of code. On the contrary, approaches with language constructs promote simple code structures, hide the complexity of parallelization and avoid boilerplate code. However, language constructs normally impose additional development concepts and compilation requirements that may sacrifice the ease-of-use and portability. Therefore, frameworks that offer simple and intuitive concepts and constructs that are recognized by the standard compilers of a language can gain priority over other approaches. In this paper we discuss @PT (Annotation Parallel Task), a parallel programming framework that proposes Java annotations, standard Java components, as its language constructs. @PT takes an intuitive object-oriented approach on asynchronous execution of tasks, and has a special focus on GUI-responsive applications. This paper presents the annotation-based programming interface of the framework and its fundamental parallelization concepts. Furthermore, it studies @PT in different parallel programming patterns, and evaluates its efficiency by comparing @PT with other Java parallelization approaches in a set of standard benchmarks. © 2017 IEEE.","annotation; GUI concurrency; lambda expressions; object-oriented; parallel; parallel tasks","Codes (symbols); Graphical user interfaces; Object oriented programming; Parallel programming; annotation; lambda expressions; Object oriented; parallel; Parallel task; Java programming language",2-s2.0-85028038316
"Ciccozzi F.","Towards a model compilation framework based on a unified model execution semantics",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026780848&doi=10.1109%2fICSE-C.2017.125&partnerID=40&md5=b45123ee6fd36705aee47144d95ce113","Due to the increasing complexity of software systems, model-driven engineering has been introduced to shift the developer's focus from machine-centric program code to human-centric models of the software under development. In model-driven approaches, program code in conventional programming languages (e.g., C++, Java) is commonly generated from models and then compiled or interpreted. Intermediate translation of models to program code raises two fundamental issues: 1) semantic inconsistency and information loss between an executable and its source model, and 2) suboptimality of executables, since compilers are unable to exploit model semantics. These issues are not tolerable in embedded real-time and safety-critical applications. To tame them, we propose direct compilation of models bypassing intermediate translations to conventional programming languages. © 2017 IEEE.","ALF; Compilation; FUML; Model-driven engineering; UML","Codes (symbols); Computer programming; Computer software; Program compilers; Program translators; Safety engineering; Semantics; Software engineering; Translation (languages); Compilation; FUML; Information loss; Model driven approach; Model-driven Engineering; Safety critical applications; Semantic inconsistencies; Software systems; C++ (programming language)",2-s2.0-85026780848
"Zhang N., Driscoll M., Markley C., Williams S., Basu P., Fox A.","Snowflake: A lightweight portable stencil DSL",2017,"Proceedings - 2017 IEEE 31st International Parallel and Distributed Processing Symposium Workshops, IPDPSW 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028042577&doi=10.1109%2fIPDPSW.2017.89&partnerID=40&md5=e8ea8309fb10c6a2d5a963e63e7498c0","Stencil computations are not well optimized by general-purpose production compilers and the increased use of multicore, manycore, and accelerator-based systems makes the optimization problem even more challenging. In this paper we present Snowflake, a Domain Specific Language (DSL) for stencils that uses a 'micro-compiler' approach, i.e., small, focused, domain-specific code generators. The approach is similar to that used in image processing stencils, but Snowflake handles the much more complex stencils that arise in scientific computing, including complex boundary conditions, higher-order operators (larger stencils), higher dimensions, variable coefficients, non-unit-stride iteration spaces, and multiple input or output meshes. Snowflake is embedded in the Python language, allowing it to interoperate with popular scientific tools like SciPy and iPython; it also takes advantage of built-in Python libraries for powerful dependence analysis as part of a just-in-time compiler. We demonstrate the power of the Snowflake language and the micro-compiler approach with a complex scientific benchmark, HPGMG, that exercises the generality of stencil support in Snowflake. By generating OpenMP comparable to, and OpenCL within a factor of 2x of hand-optimized HPGMG, Snowflake demonstrates that a micro-compiler can support diverse processor architectures and is performance-competitive whilst preserving a high-level Python implementation. © 2017 IEEE.","Domain-Specific Language; GPU; Multicore; Python; Scientific Computing","Application programming interfaces (API); Computer programming languages; Digital subscriber lines; Graphics processing unit; High level languages; Image processing; Natural sciences computing; Optimization; Problem oriented languages; Snow; Domain specific languages; Domain-specific codes; Just in time compilers; Multi core; Optimization problems; Processor architectures; Python; Variable coefficients; Program compilers",2-s2.0-85028042577
"Romano S., Scanniello G.","SMUG: A selective MUtant generator tool",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026788723&doi=10.1109%2fICSE-C.2017.12&partnerID=40&md5=e932331caf36b88522efcc796ea8d27e","In this tool demo paper, we present a prototype of a tool for the selective generation of mutants in Java source code. We named this tool as SMUG (Selective MUtant Generator). Given two subsequent versions of a program, SMUG creates mutants by considering only those methods modified in, or added to, the second version. This is why it is a selective generator of mutants. On the basis of created mutants, SMUG generates a specified number of faulty versions of the program. We implemented SMUG as an Eclipse plug-in and employed this plug-in to assess regression test selection approaches. Therefore, SMUG has to be intended as a means to advance research in regression testing. We applied SMUG to create a total number of 200 faulty versions of 7 small-to-medium Java programs. A screencast of SMUG in action is available at www2.unibas.it/sromano/SMUG.html. © 2017 IEEE.","Mutant; Regression testing; Seeded fault; Selective mutant generator tool; SMUG","Computer software; Java programming language; Regression analysis; Software engineering; Software testing; Generator tool; Java program; Java source codes; Mutant; Regression test selection; Regression testing; Selective generation; SMUG; C (programming language)",2-s2.0-85026788723
"Hassan F., Wang X.","Mining readme files to support automatic building of Java projects in software repositories",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026788309&doi=10.1109%2fICSE-C.2017.114&partnerID=40&md5=2a5333f1a948703559c8f7dd099e84b1","Automatic building of software projects providesa desirable foundation to support a large variety of softwareengineering research tasks based on open software repositories. In this paper, we propose the first technique to automaticallyextract software build commands from software readme files andWiki pages, and combine the extracted commands for softwarebuilding. Specifically, we leverage the Named Entity Recognition(NER) technique for build-command extraction, and prioritizethe extracted build commands to identify which one should beused in software build. Our experiment on top Java projectsfrom GitHub reveals that, the proposed technique can correctlyidentify more than 90% of build commands, and can successfullybuild 84% of the projects that can be built successfully throughmanual inspection of software support documents. © 2017 IEEE.",,"Computer software; Java programming language; Software engineering; Automatic buildings; Named entity recognition; Open software; Software project; Software repositories; Software support; C (programming language)",2-s2.0-85026788309
"Pan T., Huang T., Mao J., Li C., Liu Y.","OpenSched: Programmable Packet Queuing and Scheduling for Centralized QoS Control",2017,"Proceedings - 2017 ACM/IEEE Symposium on Architectures for Networking and Communications Systems, ANCS 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027729583&doi=10.1109%2fANCS.2017.19&partnerID=40&md5=14a0a2020e1ca4bac5848bbd59a79397","In this work, we propose OpenSched, a layered architecture that glues the QoS apps, the controller and the switches together to maximally unleash the power of centralized QoS control. Specifically, our design consists of (1) a flexible northbound interface via the ''builder pattern'', (2) one-to-many controller-switch interactions via device abstraction, thread pooling and Java NIO's selector mechanism, and (3) efficient southbound protocol handling as well as QoS policy execution via a producer-consumer model at the switch side. We build a prototype based on ONOS and OVS with 2340 lines of Java code and 1097 lines of c code. OpenSched is expected to facilitate flexible network resource provisioning. © 2017 IEEE.","Linux TC; Quality of Service; Software-Defined Networks","Computer operating systems; Controllers; Java programming language; Network architecture; Quality of service; Software defined networking; C codes; Device abstractions; Flexible networks; Java codes; Layered architecture; QoS control; QoS policy; C (programming language)",2-s2.0-85027729583
"Kevic K.","Using eye gaze data to recognize task-relevant source code better and more fine-grained",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026777338&doi=10.1109%2fICSE-C.2017.152&partnerID=40&md5=45edcda818042326ecbaa97753583c75","Models to assess a source code element's relevancy for a given change task are the basis of many software engineering tools, such as recommender systems, for code comprehension. To improve such relevancy models and to aid developers in finding relevant parts in the source code faster, we studied developer's fine-grained navigation patterns with eye tracking technology. By combining the captured eye gaze data with interaction data of 12 developers working on a change task, we were able to identify relevant methods with high accuracy and improve precision and recall compared to the widely used click frequency technique by 77% and 24% respectively. Furthermore, we were able to show that the captured gaze data enables to retrace which source code lines developers found relevant. Our results thus provide evidence that eye gaze data can be used to improve existing models in terms of accuracy and granularity. © 2017 IEEE.","Eye-gaze; Recommender system; Relevancy model","Codes (symbols); Computer programming languages; Recommender systems; Software engineering; Code comprehension; Eye tracking technologies; Eye-gaze; Frequency techniques; Navigation patterns; Precision and recall; Software engineering tools; Source code lines; C (programming language)",2-s2.0-85026777338
"Nguyen A.T., Nguyen T.N.","Automatic categorization with deep neural network for open-source Java projects",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026765812&doi=10.1109%2fICSE-C.2017.118&partnerID=40&md5=c9addf6e5d93ec098bec31e749ce5c8d","In this work, we introduce a Deep Neural Network model for automated software categorization. The model is ableto form high-level concepts from low-level code tokens andto distinguish important features such as API calls and identifiersin order to support software categorization. Our empirical evaluationshows that DNN outperformed other machine learning approacheswith 15.9-36.4% higher accuracy in software categorization. We plan to expand further our studies to explore more features and variations ofDNN, with different configurations and data sets. © 2017 IEEE.","Application Categorization; Deep Learning; Deep Neural Network; Software Categorization","Application programs; C (programming language); Deep learning; Java programming language; Learning systems; Open source software; Software engineering; API calls; Automatic categorization; Important features; Neural network model; Open sources; Deep neural networks",2-s2.0-85026765812
"Kechagia M., Spinellis D.","Type Checking for Reliable APIs",2017,"Proceedings - 2017 IEEE/ACM 1st International Workshop on API Usage and Evolution, WAPI 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026740228&doi=10.1109%2fWAPI.2017.5&partnerID=40&md5=36783a9d83d2f84f0f613d25db3db428","In this paper, we propose to configure at compiletime the checking associated with Application Programming Interfaces' methods that can receive possibly malformed values (e.g. erroneous user inputs and problematic retrieved recordsfrom databases) and thus cause application execution failures. To achieve this, we design a type system for implementing apluggable checker on the Java's compiler and find at compile timeinsufficient checking bugs that can lead to application crashesdue to malformed inputs. Our goal is to wrap methods whenthey receive external inputs so that the former generate checkedinstead of unchecked exceptions. We believe that our approachcan improve Java developers' productivity, by using exceptionhandling only when it is required, and ensure client applications'stability. We want to evaluate our checker by using it to verifythe source code of Java projects from the Apache ecosystem. Also, we want to analyze stack traces to validate the identifiedfailures by our checker. © 2017 IEEE.","application programming interfaces; exceptions; type systems","Application programming interfaces (API); Java programming language; Program debugging; Application execution; Client applications; Erroneous users; exceptions; External input; Java developers; Source codes; Type systems; Computer systems programming",2-s2.0-85026740228
"Tan T.H., Xue Y., Chen M., Liu S., Yu Y., Sun J.","JSFox: Integrating static and dynamic type analysis of javascript programs",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026765029&doi=10.1109%2fICSE-C.2017.91&partnerID=40&md5=1803efe14711da96dd31f2cdd85444bd","JavaScript is a dynamic programming language that has been widely used nowadays. The dynamism has become a hindrance of type analysis for JavaScript. Existing works use either static or dynamic type analysis to infer variable types for JavaScript. Static type analysis of JavaScript is difficult since it is hard to predict the behavior of the language without execution. Dynamic type analysis is usually incomplete as it might not cover all paths of a JavaScript program. In this work, we propose jsFox, a browser-agnostic approach that provides integrated type analysis, based on both static and dynamic type analysis, which enables us to gain the merits of both types of analysis. We have made use of the integrated type analysis for finding type issues that could potentially lead to erroneous results. jsFox discovers 23 type issues in existing benchmark suites and real-world Web applications. © 2017 IEEE.","Integrated Analysis; JavaScript; Type","Benchmarking; Dynamic programming; High level languages; Software engineering; Benchmark suites; Integrated analysis; Integrated types; Javascript; JavaScript programs; Real world web; Static type analysis; Type; C (programming language)",2-s2.0-85026765029
"Azad A., Buluc A.","Towards a GraphBLAS library in chapel",2017,"Proceedings - 2017 IEEE 31st International Parallel and Distributed Processing Symposium Workshops, IPDPSW 2017",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028079391&doi=10.1109%2fIPDPSW.2017.118&partnerID=40&md5=8516a5b11179e0fd61d35f51646862fd","The adoption of a programming language is positively influenced by the breadth of its software libraries. Chapel is a modern andrelatively young parallel programming language. Consequently, not many domain-specific software libraries exists that are written for Chapel. Graph processing is an important domain with many applications in cyber security, energy, social networking, and health. Implementing graphalgorithms in the language of linear algebra enables many advantages including rapid development, flexibility, high-performance, and scalability. GraphBLAS initiative aims to standardize an interface for linear-algebraic primitives for graph computations. This paper presents initial experiences and findings of implementing a subset of important GraphBLAS operations in Chapel. We analyzed the bottlenecksin both shared and distributed memory. We also providedalternative implementations whenever the default implementation lacked performance or scaling. © 2017 IEEE.","Chapel; GraphBLAS; parallel graph algorithms; PGAS","Computer programming languages; Linear algebra; Parallel programming; Chapel; Distributed Memory; Graph processing; GraphBLAS; Linear-algebraic; Parallel graph algorithms; PGAS; Software libraries; Algebra",2-s2.0-85028079391
"Uguen Y., De Dinechin F., Derrien S.","A high-level synthesis approach optimizing accumulations in floating-point programs using custom formats and operators",2017,"Proceedings - IEEE 25th Annual International Symposium on Field-Programmable Custom Computing Machines, FCCM 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027679703&doi=10.1109%2fFCCM.2017.41&partnerID=40&md5=fa31311dcc5cc7011f8b11667b683437","Many case studies have demonstrated the potential of Field-Programmable Gate Arrays (FPGAs) as accelerators for a wide range of applications. FPGAs offer massive parallelism and programmability at the bit level. This enables programmers to exploit a range of techniques that avoid many bottlenecks of classical von Neumann computing. However, development costs for FPGAs are orders of magnitude higher than classical programming. A solution would be the use of High-Level Synthesis (HLS) tools, which use C as a hardware description language. However, the C language was designed to be executed on general purpose processors, not to generate hardware. Its datatypes and operators are limited to a small number (more or less matching the hardware operators present in mainstream processors), and HLS tools inherit these limitations. To better exploit the freedom offered by hardware and FPGAs, HLS vendors have enriched the C language with integer and fixed-point types of arbitrary size. Still, the operations on these types remain limited to the basic arithmetic and logic ones. In floating point, the current situation is even worse. The operator set is limited, and the sizes are restricted to 32 and 64 bits. Besides, most recent compilers, including the HLS ones, attempt to follow established standards, in particular C11 and IEEE-754. This ensures bit-exact compatibility with software, but greatly reduces the freedom of optimization by the compiler. For instance, a floating point addition is not associative even though its real equivalent is. In the present work we attempt to give the compiler more freedom. For this, we sacrifice the strict respect of the IEEE-754 and C11 standards, but we replace it with the strict respect of a high-level accuracy specification expressed by the programmer through a pragma. The case study in this work is a program transformation that applies to floating-point additions on a loop's critical path. It decomposes them into elementary steps, resizes the corresponding subcomponents to guarantee some user-specified accuracy, and merges and reorders these components to improve performance. The result of this complex sequence of optimizations could not be obtained from an operator generator, since it involves global loop information. For this purpose, we used a compilation flow involving one or several source-to-source transformations operating on the code given to HLS tools (Figure 1).The proposed transformation already works very well on 3 of the 10 FPMarks where it improves both latency and accuracy by an order of magnitude for comparable area. For 2 more benchmarks, the latency is not improved (but not degraded either) due to current limitations of HLS tools. This defines short-term future work. The main result of this work is that HLS tools also have the potential to generate efficient designs for handling floating-point computations in a completely non-standard way. In the longer term, we believe that HLS flows can not only import application-specific operators from the FPGA literature, they can also improve them using high-level, program-level information. © 2017 IEEE.",,"Application programs; Computation theory; Computer hardware description languages; Computers; Digital arithmetic; Field programmable gate arrays (FPGA); General purpose computers; Hardware; High level languages; High level synthesis; Program compilers; Signal receivers; Application specific; Classical programming; Floating-point addition; Floating-point computation; Floating-point programs; General purpose processors; Program transformations; Source-to-source transformations; C (programming language)",2-s2.0-85027679703
"Firmenich S., Bosetti G., Rossi G., Winckler M.","End-user software engineering for the personal web",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026741413&doi=10.1109%2fICSE-C.2017.127&partnerID=40&md5=5f12f422bb3e09612084309bebbc43b1","In this work we present an approach for creatingPersonal Web applications by reusing existing content that canbe extracted even from third-party Web sites. Our approachstarts with the harvesting of content from diverse Web sites, byDOM manipulation. Users without programming skills areempowered with tools for transforming DOM elements intomeaningful classes of objects that can be reused to build otherdomain-specific applications, such as mashups, Webaugmentations, PIM systems, etc. © 2017 IEEE.","End-User Software Engineering; Mashups; Personal Web","Computer systems programming; Software engineering; Websites; End-user software engineering; Mashups; Personal Web; Programming skills; Third parties; WEB application; C (programming language)",2-s2.0-85026741413
"Huppe S., Saied M.A., Sahraoui H.","Mining complex temporal API usage patterns: An evolutionary approach",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026740805&doi=10.1109%2fICSE-C.2017.147&partnerID=40&md5=0eb9e12f12abf440eaee6f12cebb0871","Learning to use existing or new software libraries is a difficult task for software developers, which would impede their productivity. Much existing work has provided different techniques to mine API usage patterns from client programs inorder to help developers on understanding and using existinglibraries. However, these techniques produce incomplete patterns, i.e., without temporal properties, or simple ones. In this paper, we propose a new formulation of the problem of API temporal pattern mining and a new approach to solve it. Indeed, we learn complex temporal patterns using a genetic programming approach. Our preliminary results show that across a considerable variability of client programs, our approach has been able to infer non-trivial patterns that reflect informative temporal properties. © 2017 IEEE.","API documentation; API usage pattern; Genetic programming; Linear temporal logic","C (programming language); Genetic algorithms; Genetic programming; Software engineering; Evolutionary approach; Linear temporal logic; Software developer; Software libraries; Temporal pattern; Temporal pattern minings; Temporal property; Usage patterns; Application programming interfaces (API)",2-s2.0-85026740805
"Mougouei D., Powers D.M.W., Moeini A.","Dependency-aware software release planning",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026765415&doi=10.1109%2fICSE-C.2017.74&partnerID=40&md5=3e0d479a87d01021b296ab25364b97ca","The existing software release planning models aim to find a subset of software requirements with the highest value on the assumption that the value of a selected subset of requirements equals to the Accumulated Value (AV) of that subset. This assumption however, does not hold due to the Value-related Dependencies among software requirements. To address this, we have formulated an integer programming model for software release planning that finds a subset of software requirements with the highest Overall Value (OV) where overall value of a selected subset of requirements captures the impacts of value-related dependencies on the value of that subset. We have demonstrated through several simulations that maximizing the accumulated value of a selected subset of requirements may conflict with maximizing the overall value of that subset. © 2017 IEEE.","Dependency; Software Release Planning; Value","Integer programming; Requirements engineering; Set theory; Software engineering; Dependency; Integer programming models; Requirements Capture; Software release planning; Software requirements; Value; C (programming language)",2-s2.0-85026765415
"Buluc A., Mattson T., McMillan S., Moreira J., Yang C.","Design of the GraphBLAS API for C",2017,"Proceedings - 2017 IEEE 31st International Parallel and Distributed Processing Symposium Workshops, IPDPSW 2017",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028060549&doi=10.1109%2fIPDPSW.2017.117&partnerID=40&md5=cf16a20343f52301824d0926626ccccc","The purpose of the GraphBLAS Forum is to standardize linear-algebraic building blocks for graph computations. An important part of this standardization effort is to translate the mathematical specification into an actual Application Programming Interface (API) that (i) is faithful to the mathematics and (ii) enables efficient implementations on modern hardware. This paper documents the approach taken by the C language specification subcommittee and presents the main concepts, constructs, and objects within the GraphBLAS API. Use of the API is illustrated by showing an implementation of the betweenness centrality algorithm. © 2017 IEEE.",,"C (programming language); Specifications; Betweenness centrality; Building blockes; C language; Efficient implementation; Linear-algebraic; Mathematical specifications; Paper documents; Application programming interfaces (API)",2-s2.0-85028060549
"Lan H., Liu W., Liu Y., Schmidt B.","SWhybrid: A Hybrid-Parallel Framework for Large-Scale Protein Sequence Database Search",2017,"Proceedings - 2017 IEEE 31st International Parallel and Distributed Processing Symposium, IPDPS 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027682973&doi=10.1109%2fIPDPS.2017.42&partnerID=40&md5=4854b7633312fdad4ee089d90a1980a8","Computer architectures continue to develop rapidly towards massively parallel and heterogeneous systems. Thus, easily extensible yet highly efficient parallelization approaches for a variety of platforms are urgently needed. In this paper, we present SWhybrid, a hybrid computing framework for large-scale biological sequence database search on heterogeneous computing environments with multi-core or many-core processing units (PUs) based on the Smith-Waterman (SW) algorithm. To incorporate a diverse set of PUs such as combinations of CPUs, GPUs and Xeon Phis, we abstract them as SIMD vector execution units with different number of lanes. We propose a machine model, associated with a unified programming interface implemented in C++, to abstract underlying architectural differences. Performance evaluation reveals that SWhybrid (i) outperforms all other tested state-of-the-art tools on both homogeneous and heterogeneous computing platforms, (ii) achieves an efficiency of over 80% on all tested CPUs and GPUs and over 70% on Xeon Phis, and (iii) achieves utlization rates of over 80% on all tested heterogeneous platforms. Our results demonstrate that there is enough commonality between vector-like instructions across CPUs and GPUs that one can develop higher-level abstractions and still specialize with close-to-peak performance. SWhybrid is open-source software and freely available at https://github.com/turbo0628/swhybrid. © 2017 IEEE.","Biological sequence comparison; CUDA; Heterogeneous computing; SIMD; Xeon Phi","Bioinformatics; C++ (programming language); Computer programming; Information retrieval; Multicore programming; Open source software; Open systems; Program processors; Search engines; Software engineering; Biological sequences; CUDA; Heterogeneous computing; SIMD; Xeon Phi; Computer architecture",2-s2.0-85027682973
"Schmidt A.G., Weisz G., French M.","Evaluating rapid application development with python for heterogeneous processor-based FPGAs",2017,"Proceedings - IEEE 25th Annual International Symposium on Field-Programmable Custom Computing Machines, FCCM 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027708900&doi=10.1109%2fFCCM.2017.45&partnerID=40&md5=1654b29b12db346100c7df4c6436a5f1","As modern FPGAs evolve to include more heterogeneous processing elements, such as ARM cores, it makes sense to consider these devices as processors first and FPGA accelerators second. As such, the conventional FPGA development environment must also adapt to support more software-like programming functionality. While high-level synthesis tools can help reduce FPGA development time, there still remains a large expertise gap in order to realize highly performing implementations. At a system-level the skill set necessary to integrate multiple custom IP hardware cores, interconnects, memory interfaces, and now heterogeneous processing elements is complex. Rather than drive FPGA development from the hardware up, we consider the impact of leveraging Python to accelerate application development. Python offers highly optimized libraries from an incredibly large developer community, yet is limited to the performance of the hardware system. In this work we evaluate the impact of using PYNQ, a Python development environment for application development on the Xilinx Zynq devices, the performance implications, and bottlenecks associated with it. We compare our results against existing C-based and hand-coded implementations to better understand if Python can be the glue that binds together software and hardware developers. © 2017 IEEE.",,"Computer programming; Computer software; Computers; Field programmable gate arrays (FPGA); Hardware; High level languages; High level synthesis; Application development; Development environment; Development time; Fpga accelerators; Heterogeneous processing; Heterogeneous processors; Rapid application development; Software and hardwares; C (programming language)",2-s2.0-85027708900
"Wang M., Tian C., Duan Z.","Full regular temporal property verification as dynamic program execution",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026758985&doi=10.1109%2fICSE-C.2017.98&partnerID=40&md5=00949aba5441b31f23b2dd12c97ab551","Verification of programs in code-level has attracted more and more attentions since the cost is high to extract models from source code. Most of the approaches available for code-level verification are carried on by inserting assertions into programs and then checking whether the assertions are violated. But in this way, only safety properties can be verified, other temporal properties of programs such as liveness cannot be verified. To tackle this problem, a unified model checking approach is presented in this paper where a program to be verified is written in a Modeling, Simulation and Verification Language (MSVL) program M and a desired property is specified by a Propositional Projection Temporal Logic (PPTL) formula P. Different from the traditional model checking approach, the negation of the desired property is translated into an MSVL program M' first. Then whether P is valid on M can be checked by evaluating whether there exists an acceptable execution of the new MSVL program 'M and M''. This problem can be efficiently conducted with the compiler of MSVL namely MSV. The proposed approach has been implemented in a tool called UMC4MSVL. Experiments show that UMC4MSVL is efficient in verifying temporal properties of real-world programs. © 2017 IEEE.",,"Codes (symbols); Computer simulation languages; Model checking; Modeling languages; Software engineering; Unified Modeling Language; Dynamic programs; Extract models; Real world projects; Safety property; Temporal property; Traditional models; Unified Modeling; Verification language; C (programming language)",2-s2.0-85026758985
"Eshkevari L., Mazinanian D., Rostami S., Tsantalis N.","JSDeodorant: Class-awareness for JavaScript programs",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026730621&doi=10.1109%2fICSE-C.2017.6&partnerID=40&md5=eeb8ef63de9844e056a51e4427648523","Until the recent updates to JavaScript specifications, adding syntactical support for class and namespace declaration, developers used custom solutions to emulate modulardecomposition (e.g., classes and namespaces) and other object-oriented constructs, such as interfaces, and inheritance relationships. However, the lack of standards for severalyears led to a large variation and diversity of custom solutions for emulating object-oriented constructs, making maintenance and comprehension activities rather difficult in JavaScript projects developed based on the previous languagespecifications. In this paper, we present JSDEODORANT, an Eclipse plug-in that enables class-aware maintenance and comprehension for JavaScript programs. (https://youtu.be/k4U2LwkL6JU). © 2017 IEEE.","Class emulation detection; Comprehension; JavaScript","High level languages; Object oriented programming; Software engineering; As interfaces; Comprehension; Custom solutions; Inheritance relationships; Javascript; JavaScript programs; Namespaces; Object oriented; C (programming language)",2-s2.0-85026730621
"Lenarduzzi V., Sillitti A., Taibi D.","Analyzing Forty years of software maintenance models",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026754322&doi=10.1109%2fICSE-C.2017.122&partnerID=40&md5=816626f675a49ee1fa6e734ab0c68843","Software maintenance has dramatically evolved in the last four decades, to cope with the continuously changing software development models, and programming languages and adopting increasingly advanced prediction models. In this work, we present the initial results of a Systematic Literature Review (SLR), highlighting the evolution of the metrics and models adopted in the last forty years. © 2017 IEEE.","Software Maintenance; Systematic Literature Review","Computer software maintenance; Maintenance; Software design; Software engineering; Prediction model; Software development models; Systematic literature review; Systematic literature review (SLR); C (programming language)",2-s2.0-85026754322
"Rau A.","Topic-driven testing",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026739417&doi=10.1109%2fICSE-C.2017.175&partnerID=40&md5=caae720a4f0829d9c9047e139252ff4d","When manually testing Web sites humans can go with vague, yet general instructions, such as 'add the product to shopping cart and proceed to checkout'. Can we teach a robot to follow such instructions as well?In this paper I present a novel model, called semantic usage patterns which allows us to capture the general topics behind the individual steps of interactions. These models can be extracted from existing test descriptions be they in natural language or in form of system tests. Those usage patterns can be applied even on applications they were not designed for. They allow to test applications automatically in order to identify behavioral anomalies in the application model or detect missing functionalities. © 2017 IEEE.","Automated Software Testing; Natural Language Processing; Semantic Analysis","C (programming language); Natural language processing systems; Semantics; Software engineering; Application modeling; Automated software testing; Natural languages; Semantic analysis; Shopping carts; System test; Test applications; Usage patterns; Software testing",2-s2.0-85026739417
"Arndt O.J., Trager F.D., Mob T., Blume H.","Portable implementation of advanced driver-assistance algorithms on heterogeneous architectures",2017,"Proceedings - 2017 IEEE 31st International Parallel and Distributed Processing Symposium Workshops, IPDPSW 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028070021&doi=10.1109%2fIPDPSW.2017.100&partnerID=40&md5=7fc4efbe5ec621cf7e80d7483b11cc8c","The increased use of application-specific computational devices turns even low-power chips into high-performance computers. Not only additional accelerators (e.g., GPU, DSP, or even FPGA), but also heterogeneous CPU clusters form modern computer systems. Programming these chips is however challenging, due to management overhead, data transfer delays, and a missing unification of the programming flow. Moreover, most accelerators require device specific optimizations. Thus, for application developers, fulfilling software's initial intention to serve high portability is one of the most ambitious objectives. In this work, we present a software abstraction layer unifying the programming flow for parallel and heterogeneous platforms. Therefore, we offer a generic C++ API for parallelizing on heterogeneous CPU clusters and offloading to accelerators, specifically addressing applications with strict real-time constraints. At a freeconfigurable choice of parallelization- and offloading-frameworks (e.g., TBB, OpenCL) without affecting the portability, we also include automatic profiling methods. While offering high configurability of the architecture mapping, these methods ease the development of optimum scheduling strategies - e.g., in terms of power, throughput, or latency. To demonstrate the use of theproposed methods, we present heterogeneous implementations of the Semi-Global Matching and Histograms of Oriented Gradients algorithms as exemplary advanced driver-assistance algorithms. We provide an in-depth discussion of scheduling strategies for execution on a Samsung Exynos 5422 MPSoC, an Intel Xeon Phi manycore, and a general-purpose processor equipped with a Nallatech PCIe-385N FPGA accelerator card. © 2017 IEEE.","advanced driver-assistance systems; big. LITTLE; MPSoC; parallelization; real-time applications; Xeon Phi","Abstracting; Application programs; Automobile drivers; C++ (programming language); Computer programming; Computer software portability; Data transfer; Field programmable gate arrays (FPGA); General purpose computers; Multiprocessing systems; Optimization; Parallel flow; Scheduling; System-on-chip; big. LITTLE; MPSoC; Parallelizations; Real-time application; Xeon Phi; Advanced driver assistance systems",2-s2.0-85028070021
"Kruger J.","Lost in source code: Physically separating features in legacy systems",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026725584&doi=10.1109%2fICSE-C.2017.46&partnerID=40&md5=319327efa107be7c8dcac52608ef81a8","Feature-oriented programming allows developers to physically separate and reuse features via composition. This promises several benefits compared to other reuse approaches, for instance, easier traceability and maintenance. However, due to their simplicity cloning and annotation-based product lines are established in practice. We aim to reduce risks and costs of migrating towards composition, lowering the adoption barrier. This includes i) processes, ii) migration approaches, and iii) assessing advantages and disadvantages. Overall, we will facilitate integrating physical separation into legacy applications. © 2017 IEEE.","Extraction; Migration; Software product line","Extraction; Legacy systems; Separation; Software engineering; Source separation; Adoption barriers; Feature-oriented programming; Legacy applications; Migration; Physical separation; Product-lines; Software Product Line; Source codes; C (programming language)",2-s2.0-85026725584
"Koniar D., Taraba M., Adamec J., Danko M.","Design of a system for the brightness control of LEDs",2017,"Proceedings of the 2017 18th International Scientific Conference on Electric Power Engineering, EPE 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026630607&doi=10.1109%2fEPE.2017.7967259&partnerID=40&md5=9a0820bb72ca11716d297682c48f7dce","The article deals with the control of the light level of four-colour RGBA LEDs for illumination of samples of a microscope while the methods of control of the light level are introduced and discussed first. In the next part of the article, four LED drivers for four-colour LEDs are selected. The calculation of a circuit elements of the LED driver and the calculation the peripheral elements of the control loop is also mentioned in this article. Furthermore, this article deals with the creation of the program for the colour mixing and the brightness control of the light emitted by LEDs, while the program itself is implemented in LabVIEW graphical programming software. The last part of this article describes the front panel of the program and its operation. © 2017 IEEE.","Arduino; LabVIEW; LED driver; Lighting control of the light-emitting diode","Color; Computer graphics; Computer programming languages; Luminance; Arduino; Brightness control; Circuit elements; Control loop; LabViEW; Labview graphical programming; LED drivers; Lighting controls; Light emitting diodes",2-s2.0-85026630607
"Moran K., Vasquez M.L., Poshyvanyk D.","Automated GUI testing of android apps: From research to practice",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026752544&doi=10.1109%2fICSE-C.2017.166&partnerID=40&md5=3004e1e75b674f53e67a4c1de240afa6","The last decade has seen tremendous proliferation of mobile computing in our society. Billions of users have access to millions of mobile apps that can be installed directly on their mobile devices, electrical appliances, and watches. Factors such as new monetization/revenue models, programming models, and distribution infrastructures contribute to an 'attractive' movement that captivates new and traditional developers, as well as a crowd of other professionals that explore, design, and implement mobile apps. Also, the need for 'enterprise apps' that support start-ups or serve as a new front-end for traditional companies is pushing software-related professionals to embrace mobile technologies. However, the nature of the economy (devices, apps, markets) imposes new challenges on how mobile apps are envisioned, designed, implemented, tested, released, and maintained. This technology briefing aims to help address the challenges of testing and maintaining mobile apps by providing participants from both academic and industrial backgrounds with information on the state-of-art and state-of-practice mobile testing techniques. Specifically, we aim to (i) highlight new techniques and methodologies for making effective automated testing of mobile apps practical and accessible to developers, and (ii) discuss open academic research questions related to such technology transfer. © 2017 IEEE.","Android; Apps; Automation; GUI; Testing","Application programs; Automation; C (programming language); Graphical user interfaces; Software engineering; Technology transfer; Testing; Academic research; Android; Automated testing; Electrical appliances; Mobile Technology; Mobile testing; Programming models; State of practice; Android (operating system)",2-s2.0-85026752544
"Pham V.V.H., Liu X., Zheng X., Fu M., Deshpande S.V., Xia W., Zhou R., Abdelrazek M.","PaaS - Black or white: An investigation into software development model for building retail industry SaaS",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026751793&doi=10.1109%2fICSE-C.2017.57&partnerID=40&md5=d3d3ea6a57444b697e390c9e36cfb7a3","One of the most important goals for Software Engineering is that end users or those people who understand software requirements but without too much programming experience can build their software products or prototypes easily. The recent success of cloud computing has made a big step towards this goal where Platform as a Service (PaaS) can provide general and comprehensive software development services within an integrated online environment for building Software as a Service (SaaS). However, currently, most PaaS are in a 'white-box' which still requires significant learning efforts for software developers and lets alone inexperienced project managers or end users. Therefore, it is high time that we should comprehensively investigate the challenges for PaaS and provide a suitable development model. In this paper, we firstly identify and analyze the challenges for current White-PaaS through literature review. Afterwards, employing the retail industry as a typical application domain, a novel 'Black-Box' PaaS framework is proposed which requires much less learning time and supports much more flexible and speedy SaaS design and development. © 2017 IEEE.","Cloud Computing; Platform as a Service; Software as a Service; Software Development","C (programming language); Cloud computing; Platform as a Service (PaaS); Software design; Software engineering; Software prototyping; Web services; Building softwares; Design and Development; Online environments; Programming experience; Software developer; Software development models; Software requirements; Typical application; Software as a service (SaaS)",2-s2.0-85026751793
"Maxfield C., Julien C.","Data-directed contextual relevance in the IoT",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026748151&doi=10.1109%2fICSE-C.2017.13&partnerID=40&md5=68b7553ace3b7bc1c547ad8fc300eca9","The relevance of data created in or about the IoT has a strong reliance on the context, especially spatiotemporal context, of the device and application perceiving it. To ensure that applications perceive data items that are relevant to the current context, it is necessary to restrict when each item is available. To control an application's perceptions of data availability, data items are often put in a group with other similar items, and a static rule is applied to determine when that data can be seen by applications. Such rules are fairly rigid, and the burden is on application developers to manage individual data items and their access policies, including making sure data distribution stays up to date relative to the context that influences data availability. We posit that the development of applications that need to access contextually relevant data can be greatly simplified by enabling a data item itself to control how and when it is available to applications. To realize this simplified programming paradigm, we introduce the datalet, an abstraction of a piece of data that understands its contextual relevance and dictates how (i.e., when and where) it is available based on that application's context. The datalet allows the application developer to focus on the application logic that relies on available data, without worrying about how to store, update, and distribute contextually-sensitive data to (distributed) application instances. To show how datalets are used by application developers to construct an application, we create an augmented-reality game that uses datalets to make elements of game play available based on the player's spatiotemporal context. The video of this demonstration is on YouTube at: https://youtu.be/snFhokswWpc. © 2017 IEEE.",,"Augmented reality; Internet of things; Software engineering; Access policies; Application developers; Application logic; Data availability; Data distribution; Game plays; Programming paradigms; Sensitive datas; C (programming language)",2-s2.0-85026748151
"Nunes R., Reboucas M., Soares-Neto F., Castor F.","Visualizing swift projects as cities",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026776049&doi=10.1109%2fICSE-C.2017.115&partnerID=40&md5=06139ce3b5daf15bc3fb4a6a508d27db","Human's natural ability to perform software maintenance is compromised as a project gets bigger, older, and more complex. Software visualization tools can be used to mitigate this problem, easing software understanding. However, no such tools are available for Swift, a new programming language that is experiencing widespread adoption by developers. In this paper we present SwiftCity, a software visualization tool that uses the City Metaphor. Visualizing Swift projects as cities is different from projects in other languages, such as Java and Javascript. Swift employs a number of different units of modularity that are not available in these languages, such as extensions and structs. © 2017 IEEE.","City Metaphor; Software Maintenance; Software Visualization; Swift","Computer aided software engineering; Computer software maintenance; Software engineering; Visualization; City Metaphor; Javascript; Software understanding; Software visualization; Software visualization tool; Swift; C (programming language)",2-s2.0-85026776049
"Nahabedian L.","Dynamic update of business process management",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026764819&doi=10.1109%2fICSE-C.2017.25&partnerID=40&md5=92405b819cdb4d0b93a7b23ac48bb802","Requirements and domain assumptions of Business Process Management (BPM) need to be studied. Most times, they change during BPM life unpredictably at design-time leading to a BPM update. Updating a BPM must take current state into consideration. Update process may vary depending on it. To the best of our knowledge, there is a lack of techniques for updating BPM at run-time and only few of them build BPM from its requirements, which we believe that is the most natural way for designing them. As updating processes at runtime is a critical duty, there is a need of guaranteeing correct dynamic updates. Hence, we are interested in correct-by-construction approaches rather than construct-then-verify approaches in order to automatically provide guarantees of producing only expected BPM for given requirements. Requirements must be specify in an understandable declarative language, so as to easily design BPM by writing requirements in a convenient way. Moreover, we plan to issue efficient tools supporting the developed techniques and languages, and then, evaluate them by 1) modelling known case studies from the software engineering and BPM literature, and 2) solving real BPM problems from companies or any other institution. © 2017 IEEE.","Behavioural Modelling; Business process management; Controller Synthesis; Dynamic Updates","Administrative data processing; Enterprise resource management; Modeling languages; Software engineering; Behavioural modelling; Business process management; Case-studies; Controller synthesis; Correct-by-construction; Declarative Languages; Design time; Dynamic update; C (programming language)",2-s2.0-85026764819
"Nguyen T.A., Csallner C.","Reverse engineering object-oriented applications into high-level domain models with reoom",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026766307&doi=10.1109%2fICSE-C.2017.63&partnerID=40&md5=ca4a914ed0935c1266c6fc0d3a394e8d","Automatically pinpointing those classes in an object-oriented program that implement interesting domain concepts would be valuable for industrial software maintainers. We encode two observations of programmer behavior in Reoom, a novel light-weight static analysis. In a comparison with its most closely related competitor, Womble, on third-party open source applications, Reoom scaled to larger applications and achieved better overall precision and recall. © 2017 IEEE.",,"C (programming language); Open source software; Reverse engineering; Software engineering; Static analysis; Domain concepts; Engineering objects; High-level domain; Industrial software; Object-oriented program; Open source application; Precision and recall; Third parties; Object oriented programming",2-s2.0-85026766307
"Baltes S., Kiefer R., Diehl S.","Attribution required: Stack overflow code snippets in GitHub projects",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026730072&doi=10.1109%2fICSE-C.2017.99&partnerID=40&md5=f150a26c7ace22743bfe213b6992e49e","Stack Overflow (SO) is the largest Q&A website for developers, providing a huge amount of copyable code snippets. Using these snippets raises various maintenance and legal issues. The SO license requires attribution, i.e., referencing the original question or answer, and requires derived work to adopt a compatible license. While there is a heated debate on SO's license model for code snippets and the required attribution, little is known about the extent to which snippets are copied from SO without proper attribution. In this paper, we present the research design and summarized results of an empirical study analyzing attributed and unattributed usages of SO code snippets in GitHub projects. On average, 3.22% of all analyzed repositories and 7.33% of the popular ones contained a reference to SO. Further, we found that developers rather refer to the whole thread on SO than to a specific answer. For Java, at least two thirds of the copied snippets were not attributed. © 2017 IEEE.","Code snippets; Copy-and-paste programming; Empirical study; Github; Licensing; Stack overflow; Survey","Codes (symbols); Copying; Nuclear reactor licensing; Software engineering; Surveying; Code snippets; Copy-and-paste programming; Empirical studies; Github; Stack overflow; C (programming language)",2-s2.0-85026730072
"Phan H.D., Nguyen A.T., Nguyen T.D., Nguyen T.N.","Statistical migration of API usages",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026746338&doi=10.1109%2fICSE-C.2017.17&partnerID=40&md5=e4f915a044f5e03c9518191e4ef7ac74","To support code migration, we introduce JV2CS, a tool to generate asequence of C# API elements and related control units that are neededto migrate a given Java code fragment. First, we mine the mappingsbetween single APIs in Java and C#. To overcome the lexical mismatchbetween the names of Java and C# APIs, we represent an API by itsusages instead of its name. To characterize an API with its contextconsisting of surrounding APIs in its usages, we take advantage ofWord2Vec model to project the APIs of Java JDK and C#.NET intothe corresponding continuous vector spaces. The transformation matrixbetween the two vector spaces is learned from a small set of human-written pairs of mappings. We use the transformation matrix toderive other mappings, and then use the mappings to generate thecorresponding API sequence in C# via a phrase-based translation model. The video demo for JV2CS can be found athttps://www.youtube.com/watch?v=MjTfmr9AmR8&feature=youtu.be. © 2017 IEEE.","API embedding; API usage migration; Word2Vec","Application programming interfaces (API); Java programming language; Linear transformations; Mapping; Software engineering; API embedding; API usage migration; Code migration; Control unit; Java codes; Transformation matrices; Translation models; Word2Vec; Vector spaces",2-s2.0-85026746338
"Shamshiri S., Campos J., Fraser G., McMinn P.","Disposable testing: Avoiding maintenance of generated unit tests by throwing them away",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026768542&doi=10.1109%2fICSE-C.2017.100&partnerID=40&md5=954731471c178ff17aa0d6552e089c3f","Developers write unit tests together with programcode, and then maintain these tests as the program evolves. Sincewriting good tests can be difficult and tedious, unit tests canalso be generated automatically. However, maintaining these tests(e.g., when APIs change, or, when tests represent outdated andchanged behavior), is still a manual task. Because automaticallygenerated tests may have no clear purpose other than coveringcode, maintaining them may be more difficult than maintainingmanually written tests. Could this maintenance be avoided bysimply generating new tests after each change, and disposingthe old ones? We propose disposable testing: Tests are generatedto reveal any behavioral differences caused by a code change, and are thrown away once the developer confirms whetherthese changes were intended or not. However, this idea raisesseveral research challenges: First, are standard automated testgeneration techniques good enough to produce tests that may berelied upon to reveal changes as effectively as an incrementallybuilt regression test suite? Second, does disposable testing reducethe overall effort, or would developers need to inspect moregenerated tests compared to just maintaining existing ones? © 2017 IEEE.","Automated Regression Testing; Automated Test Generation; Coverage-driven Testing; Differential Testing; Disposable Testing; Regression Test Generation; Regression Testing; Unit Test Generation; Unit Testing","Automatic programming; Automatic test pattern generation; Automation; C (programming language); Regression analysis; Software engineering; Testing; Automated regression testing; Automated test generations; Differential testing; Regression testing; Regression tests; Unit test generations; Unit testing; Software testing",2-s2.0-85026768542
"Scalabrino S.","On software odysseys and how to prevent them",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026789027&doi=10.1109%2fICSE-C.2017.157&partnerID=40&md5=2ab15c3295d1f1a72b682b1d4dcec9e4","Acting on a software system developed by someone else may be difficult. Performing any kind of maintenance task requires knowledge about many parts of the system. Therefore, program comprehension plays a lead role in software maintenance, above all when new resources are added to a project. At the same time, acquiring full knowledge about big codebases can be utopian, because it requires a big effort if no sufficient documentation is provided. In this paper I present TIRESIAS, an approach able to suggest a subset of important software artifacts which are good entry points for newcomers. The suggested artifacts can be used in order to acquire knowledge about the system in an initial stage. TIRESIAS uses a knowledge graph to model the references among source code artifacts and to find (i) the artifacts that lead to acquire the widest knowledge about the system and (ii) the most important artifacts that are worth keeping in mind. The approach is validated through a case study conducted on a software system and three professional software developers. © 2017 IEEE.","Program comprehension; Recommender systems; Software maintenance","Computer programming; Computer software; Computer software maintenance; Maintenance; Recommender systems; Software engineering; Entry point; Knowledge graphs; Maintenance tasks; Professional software; Program comprehension; Software artifacts; Software systems; Source codes; C (programming language)",2-s2.0-85026789027
"Hili N., Dingel J., Beaulieu A.","Modelling and code generation for real-time embedded systems with UML-RT and papyrus-RT",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026726710&doi=10.1109%2fICSE-C.2017.168&partnerID=40&md5=fc0e790fb8b85a387067c92ea0ac715d","This paper discusses the Model-Driven Engineering (MDE) of real-time embedded (RTE) systems with soft real-time constraints using UML for Real-Time (UML-RT) and Papyrus-RT. UML-RT is a profile of UML specifically designed for RTE systems. It has a long, successful track record of application and tool support via, e.g., IBM Rational RoseRT, IBM RSA-RTE, and now Papyrus-RT. Papyrus-RT is an Eclipse-based, open-source modelling development environment for UML-RT systems. It allows the generation of complete, executable code from models and advances the state-of-art via support for model representation with mixed graphical/textual notations and an extensible code generator. This paper introduces the central modelling concepts of UML-RT and features of Papyrus-RT. It also presents some advanced features of Papyrus-RT such as import capabilities, mixed graphical/textual modelling, and incremental code generation. © 2017 IEEE.",,"Automatic programming; C (programming language); Codes (symbols); Open source software; Open systems; Program compilers; Real time systems; Software engineering; Code Generation; Code generators; Development environment; Executable codes; Model representation; Model-driven Engineering; Real-time embedded systems; Soft real time; Embedded systems",2-s2.0-85026726710
"Avdiienko V., Kuznetsov K., Rommelfanger I., Rau A., Gorla A., Zeller A.","Detecting behavior anomalies in graphical user interfaces",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026788310&doi=10.1109%2fICSE-C.2017.130&partnerID=40&md5=11ab5fff2e6d8e60d6bba04aa7d77513","When interacting with user interfaces, do users always get what they expect? For each user interface element in thousands of Android apps, we extracted the Android APIs they invoke as well as the text shown on their screen. This association allows us to detect outliers: User interface elements whose text, context or icon suggests one action, but which actually are tied to other actions. In our evaluation of tens of thousands of UI elements, our BACKSTAGE prototype discovered misleading random UI elements with an accuracy of 73%. © 2017 IEEE.","App Mining; Graphical User Interfaces; Machine learning","Android (operating system); Application programming interfaces (API); C (programming language); Graphical user interfaces; Learning systems; Software engineering; Android apps; Interface elements; User interfaces",2-s2.0-85026788310
"Di Sorbo A., Panichella S., Alexandru C.V., Visaggio C.A., Canfora G.","SURF: Summarizer of user reviews feedback",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026739759&doi=10.1109%2fICSE-C.2017.5&partnerID=40&md5=32bf451131c41760375d31101885e014","Continuous Delivery (CD) enables mobile developers to release small, high quality chunks of working software in a rapid manner. However, faster delivery and a higher software quality do neither guarantee user satisfaction nor positive business outcomes. Previous work demonstrates that app reviews may contain crucial information that can guide developer's software maintenance efforts to obtain higher customer satisfaction. However, previous work also proves the difficulties encountered by developers in manually analyzing this rich source of data, namely (i) the huge amount of reviews an app may receive on a daily basis and (ii) the unstructured nature of their content. In this paper, we propose SURF (Summarizer of User Reviews Feedback), a tool able to (i) analyze and classify the information contained in app reviews and (ii) distill actionable change tasks for improving mobile applications. Specifically, SURF performs a systematic summarization of thousands of user reviews through the generation of an interactive, structured and condensed agenda of recommended software changes. An end-to-end evaluation of SURF, involving 2622 reviews related to 12 different mobile applications, demonstrates the high accuracy of SURF in summarizing user reviews content. In evaluating our approach we also involve the original developers of some apps, who confirm the practical usefulness of the software change recommendations made by SURF. Demo URL: https://youtu.be/Yf-U5ylJXvo Demo webpage: http://www.ifi.uzh.ch/en/seal/people/panichella/tools/SURFTool.html. © 2017 IEEE.","Mobile Applications; Natural Language Processing; Software Maintenance; Summarization","Application programs; Classification (of information); Computer software maintenance; Computer software selection and evaluation; Customer satisfaction; Mobile computing; Mobile telecommunication systems; Natural language processing systems; Software engineering; Business outcomes; High-accuracy; Mobile applications; Software change; Software Quality; Summarization; User reviews; User satisfaction; C (programming language)",2-s2.0-85026739759
"Shi G., Gan Y., Shang S., Wang S., Dong Y., Yew P.-C.","A formally verified sequentializer for lustre-like concurrent synchronous data-flow programs",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026739254&doi=10.1109%2fICSE-C.2017.83&partnerID=40&md5=35092f54a6bc1961de69a5737eb9598c","Synchronous data-flow languages (SDFL), such as Lustre [1], is a concurrent language that has been widely used in safety-critical systems. Verified compilers for such languages are crucial in generating trustworthy object code. A good approach is to first translate a concurrent SDFL program to a sequential intermediate representation, such as a Clight [2] code, and then use an existing verified compiler such as CompCert [3] to produce executable object code for the target machine. A verified Sequentializer is crucial in such a verified compiler. It produces a sequential topological order among the program statements that preserve the program dependencies and the dynamic semantics of the original program. In this paper, we show such an approach for a SDFL language such as Lustre. The approach is general enough to be applicable to other SDFLs as well. It first gives a formal specification of the operational semantics, and proves its determinism property for a Lustre-like program. It then formally proves the equivalence of the original concurrent semantics and its target sequential semantics using the well-established proof assistant Coq ([4], [5]), and extracts the certified code for such a sequentializer by Coq. © 2017 IEEE.","Concurrency; Determinism; Semantics; Sequentialization; Synchronous Data-flow Languages; Verification; Verified Compiler","Codes (symbols); Data transfer; Program compilers; Safety engineering; Semantics; Software engineering; Theorem proving; Verification; Concurrency; Determinism; Sequentialization; Synchronous data-flow languages; Verified Compiler; C (programming language)",2-s2.0-85026739254
"Ferme V., Lenhard J., Harrer S., Geiger M., Pautasso C.","Workflow management systems benchmarking: Unfulfilled expectations and lessons learned",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026725979&doi=10.1109%2fICSE-C.2017.126&partnerID=40&md5=d7c4e79cbc3e7c085cf76dd170e3f43d","Workflow Management Systems (WfMSs) are a type of middleware that enables the execution of automated business processes. Users rely on WfMSs to construct flexible and easily maintainable software systems. Significant effort has been invested into standardising languages for business processes execution, with standards such as the Web Services Business Process Execution Language 2.0 or the Business Process Model and Notation 2.0. Standardisation aims at avoiding vendor lock-in and enabling WfMS users to compare different systems. The reality is that, despite standardisation efforts, different independent research initiatives show that objectively comparing WfMSs is still challenging. As a result, WfMS users are likely to discover unfulfilled expectations while evaluating and using these systems. In this work, we discuss the findings of two research initiatives dealing with WfMSs benchmarking, presenting unfulfilled expectations and lessons learned concerning WfMSs' usability, reliability, and portability. Our goal is to provide advice for practitioners implementing or planning to use WfMSs. © 2017 IEEE.","Evaluation Research; Lessons Learned; Standards; Workflow Management Systems","Benchmarking; Engineering research; Middleware; Software engineering; Standardization; Standards; Web services; Work simplification; Business process model; Evaluation research; Independent research; Lessons Learned; Research initiatives; Software systems; Web services business process execution languages; Workflow management systems; C (programming language)",2-s2.0-85026725979
"Pereira R.","Locating energy hotspots in source code",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026784061&doi=10.1109%2fICSE-C.2017.151&partnerID=40&md5=a377542ddc093c4d392eb85c80b98321","This paper briefly presents a new approach for helping developers identify energy hot spots in their applications. Using tests cases, and statistical methods based on Spectrum-based Fault Localization, high energy consumption is related to the system's source code and a ranking of possible energy leaks are pointed. This technique is both language independent, and context level independent. Initial studies have also shown that using this technique helped developers identify and optimize energy problems in half the time while improving the energy efficiency by 18%. © 2017 IEEE.","Fault Localization; Green Computing; Program Optimization","Energy efficiency; Energy utilization; Green computing; Software engineering; Energy problem; Fault localization; High energy consumption; Hotspots; Language independents; New approaches; Program optimization; Source codes; C (programming language)",2-s2.0-85026784061
"Park J., Ryou Y., Park J., Ryu S.","Analysis of JavaScript web applications using SAFE 2.0",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026746503&doi=10.1109%2fICSE-C.2017.4&partnerID=40&md5=4add53e32a318dcafa611ca8e584a040","JavaScript has been the language for web applications, and the growing prevalence of web environments in various devices makes JavaScript web applications even more ubiquitous. However, because JavaScript and web environments are extremely dynamic, JavaScript web applications are often vulnerable to type-related errors and security attacks. To lessen the problem, researchers have developed various analysis techniques in different analyzers, but such analyzers are not especially aimed for ease of use by analysis developers. In this paper, we present SAFE 2.0, a scalable analysis framework for ECMAScript especially designed as a playground for advanced research in JavaScript web applications. SAFE 2.0 is light-weight, which supports pluggability, extensibility, and debuggability. Demo video: https://youtu.be/ZI-emiRMoxQ. © 2017 IEEE.","JavaScript; SAFE; Static analysis; Web applications","C (programming language); High level languages; Software engineering; Static analysis; Advanced researches; Analysis techniques; Javascript; SAFE; Scalable analysis; Security attacks; WEB application; Web environment; HTTP",2-s2.0-85026746503
"Castellana V.G., Minutoli M., Bhatt S., Agarwal K., Bleeker A., Feo J., Chavarria-Miranda D., Haglin D.","High-Performance Data Analytics beyond the Relational and Graph Data Models with GEMS",2017,"Proceedings - 2017 IEEE 31st International Parallel and Distributed Processing Symposium Workshops, IPDPSW 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028077657&doi=10.1109%2fIPDPSW.2017.70&partnerID=40&md5=c619fa41020ea26a65ef85c39a90cb89","Graphs represent an increasingly popular data model for data-analytics, since they can naturally represent relationships and interactions between entities. Relational databases and their pure table-based data model are not well suitable to store and process sparse data. Consequently, graph databases have gained interest in the last few years and the Resource Description Framework (RDF) became the standard data model for graph data. Nevertheless, while RDF is well suited to analyze the relationships between the entities, it is not efficient in representing their attributes and properties. In this work we propose the adoption of a new hybrid data model, based on attributed graphs, that aims at overcoming the limitations of the pure relational and graph data models. We present how we have re-designed the GEMS data-analytics framework to fully take advantage of the proposed hybrid data model. To improve analysts productivity, in addition to a C++ API for applications development, we adopt GraQL as input query language. We validate our approach implementing a set of queries on net-flow data and we compare our framework performance against Neo4j. Experimental results show significant performance improvement over Neo4j, up to several orders of magnitude when increasing the size of the input data. © 2017 IEEE.","Big Data; Data Analytics; Graph Database; Graphs; High Performance Computing","C++ (programming language); Query languages; Query processing; Applications development; Data analytics; Graph database; Graphs; High performance computing; Orders of magnitude; Relational Database; Resource description framework; Big data",2-s2.0-85028077657
"Kuschke T., Mader P.","RapMOD - In situ auto-completion for graphical models",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026737581&doi=10.1109%2fICSE-C.2017.119&partnerID=40&md5=bc3449774d7ad20de6b4291665941db2","Auto-completion of textual inputs benefits software developers using IDEs. However, graphical modeling tools used to design software do not yet provide such functionality. The challenges of recommending auto-completions for graphical modeling activities are largely unexplored. Recommending such auto-completions requires detecting meaningful partly completed activities, tolerating variance in user actions, and determining the most relevant activities that a user wants to perform. We propose RapMOD, an approach that works in the background while a developer is creating or evolving models and handles all these challenges. Users' editing operations are analyzed and matched to a predefined but extensible catalog of common modeling activities for structural UML models. We found RapMOD to significantly reduce modeling effort. © 2017 IEEE.","Auto-completion; Complex-event-processing; Modeling activity; Pattern matching; Recommendation system","Graphic methods; Pattern matching; Recommender systems; Software engineering; Unified Modeling Language; Auto completion; Common models; Complex event processing; Design softwares; Editing operations; Evolving models; GraphicaL model; Software developer; C (programming language)",2-s2.0-85026737581
"Pino S., Pollock L., Chandrasekaran S.","Exploring translation of OpenMP to OpenACC 2.5: Lessons learned",2017,"Proceedings - 2017 IEEE 31st International Parallel and Distributed Processing Symposium Workshops, IPDPSW 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028045102&doi=10.1109%2fIPDPSW.2017.84&partnerID=40&md5=859731a27388385aad1819cdc746277f","Scientists who want to exploit the computing power of the latest parallel architectures are faced with a diverse set of architectures and a number of programming languages, models and approaches. Among several such programming techniques are directive-based programming models, OpenMP and OpenACC. This paper explores the similarities and the functionality gaps between both models and presents insights into the translation process of constructs from OpenMP to OpenACC. An empirical study of performance and portability across multicore platforms and GPU accelerators for varying workload sizes is also presented. © 2017 IEEE.","GPU; Multicore; OpenACC; OpenMP; Translation","Application programming interfaces (API); Graphics processing unit; Translation (languages); Empirical studies; Multi core; Multi-core platforms; Openacc; OpenMP; Programming models; Programming technique; Translation process; Parallel architectures",2-s2.0-85028045102
"Mazinanian D., Tsantalis N.","CSSDev: Refactoring duplication in cascading style sheets",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026750389&doi=10.1109%2fICSE-C.2017.7&partnerID=40&md5=95b3b13592325f9c3a08828b2ae60fda","Cascading Style Sheets (CSS) is a widely-used language for defining the presentation of structured documents and user interfaces. Despite its popularity, CSS still lacks adequate tool support for everyday maintenance tasks, such as debugging and refactoring. In this paper, we present CSSDEV, a tool suite for analyzing CSS code to detect refactoring opportunities.(https://youtu.be/lu3oITi1XrQ). © 2017 IEEE.","Cascading Style Sheets; Preprocessors; Refactoring","Program debugging; Program processors; Software engineering; User interfaces; Cascading style sheets; CSS codes; Maintenance tasks; Refactorings; Structured document; Tool support; Toolsuite; C (programming language)",2-s2.0-85026750389
"Harvey-Lees-Green N., Biglari-Abhari M., Malik A., Salcic Z.","A dynamic memory management unit for real time systems",2017,"Proceedings - 2017 IEEE 20th International Symposium on Real-Time Distributed Computing, ISORC 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026739317&doi=10.1109%2fISORC.2017.4&partnerID=40&md5=419e54182d16a01914d9c1745119afbf","Time predictability is a first class requirement in safety critical system design. Techniques exist for the timing analysis of programs designed in memory managed languages, but these require detailed knowledge of memory allocation. Moreover, enforcing hard real-time guarantees for systems designed in such garbage collected languages is difficult, because of the so called collection pause - however incremental. This paper proposes a novel solution whereby a separate reference counting unit replaces the garbage collector. We present the underlying concepts of the Reference Counting Memory Management Unit (RCMMU) and its use for garbage collection. In addition, we present an implementation that includes a specialized memory arrangement that allows for object management transactions to occur concurrently with program execution, with no resultant impact upon program performance. The RCMMU has been targeted for use with Java but can be adopted to be used with other memory managed languages. The hardware-implemented RCMMU removes all overhead associated with garbage collection operations when compared against a software-only collector. Additionally, it simplifies the static worst-case execution time analysis of programs. © 2017 IEEE.","embedded systems; FPGA; Garbage collection; memory; memory allocation; real-time Java; real-time systems; safety critical systems; time predictability","Data storage equipment; Distributed computer systems; Embedded systems; Field programmable gate arrays (FPGA); Interactive computer systems; Java programming language; Memory architecture; Memory management units; Physical addresses; Program compilers; Refuse collection; Safety engineering; Security systems; Storage allocation (computer); Systems analysis; Dynamic memory management; Garbage collection; Program performance; Real-time Java; Safety critical system design; Safety critical systems; Time predictabilities; Worst-case execution time analysis; Real time systems",2-s2.0-85026739317
"Chaparro O.","Improving bug reporting, duplicate detection, and localization",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026783775&doi=10.1109%2fICSE-C.2017.27&partnerID=40&md5=39d944a9c02c1c9596663f0dbb86297d","Software developers rely on essential textual information from bug reports (such as Observed Behavior, Expected Behavior, and Steps to Reproduce) to triage and fix software bugs. Unfortunately, while relevant and useful, this information is often missing, incomplete, superficial, ambiguous, or complex to follow. Low-quality content in bug reports causes delay and extra effort on bug triage and fixing. Current technology and research are insufficient to support users and developers on providing high-quality content in bug reports. Our research is intended to fill in this gap, as it aims at improving: (1) the quality of natural language content in bug reports, and (2) the accuracy of Text Retrieval (TR)-based bug localization and duplicate detection. To achieve such goals, our research will identify, enforce, and leverage the discourse that reporters use to describe software bugs. © 2017 IEEE.","Bug Localization; Bug Reporting; Discourse Analysis; Duplicate Bug Report Detection","C (programming language); Software engineering; Bug localizations; Bug reporting; Current technology; Discourse analysis; Duplicate bug reports; Duplicate detection; Software developer; Textual information; Program debugging",2-s2.0-85026783775
"Perez D.D., Le W.","Predicate callback summaries",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026773108&doi=10.1109%2fICSE-C.2017.95&partnerID=40&md5=9ba5d90173885731c43126377cf9d252","One of the challenges to analyze, test and debug Android apps is that the potential execution orders of callbacks are missing from the apps' source code, however, bugs, vulnerabilities and refactoring transformations have been found to be related to callback sequences. Existing work on control flow analysis of Android apps focuses on analyzing GUI behaviors. Our observation is that orthogonal to GUI, the Android API methods also play an important role in determining the order of callbacks, and previously, the APIs were modeled manually in an ad-hoc way. This paper presents a complementary solution of constructing program paths for Android apps. We proposed a specification called Predicate Callback Summary (PCS) that represents the callback control flow information (including callback sequences as well as the conditions the callbacks are invoked) in Android API methods. Our experiments show we can compute PCSs with reasonable accuracy and scalability and use them to build inter-callback control flow graphs for apps. Our detailed experimental data are available at: http://www.cs.iastate.edu/~weile/toolsdata/SummarizeAndroidFramework/lithium.html. © 2017 IEEE.","Callbacks; Interprocedural analysis; Mobile; Static analysis; Summaries","C (programming language); Embedded systems; Flow graphs; Graphical user interfaces; Software engineering; Static analysis; Callbacks; Control flow analysis; Control flow graphs; Control flows; Inter-procedural analysis; Mobile; Reasonable accuracy; Summaries; Android (operating system)",2-s2.0-85026773108
"Svajlenko J., Roy C.K.","CloneWorks: A fast and flexible large-scale near-miss clone detection tool",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026733449&doi=10.1109%2fICSE-C.2017.78&partnerID=40&md5=226fe2ab4a17ba578968122b2e3b9bb6","Clone detection within large inter-project source-code repositories has numerous rich applications. CloneWorks is a fast and flexible clone detector for large-scale near-miss clone detection experiments. CloneWorks gives the user full control over the processing of the source code before clone detection, enabling the user to target any clone type or perform custom clone detection experiments. Scalable clone detection is achieved, even on commodity hardware, using our partitioned partial indexes approach. CloneWorks scales to 250MLOC in just four hours on an average workstation with good recall and precision. © 2017 IEEE.","Clone detection; Code clone; Fast; Flexible; Scalable","C (programming language); Codes (symbols); Software engineering; Clone detection; Code clone; Fast; Flexible; Scalable; Cloning",2-s2.0-85026733449
"Li Y., Yang Z., Guo Y., Chen X.","DroidBot: A lightweight UI-guided test input generator for android",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026767745&doi=10.1109%2fICSE-C.2017.8&partnerID=40&md5=755dd0f03a5af80de0c301687350968c","As many automated test input generation tools for Android need to instrument the system or the app, they cannot be used in some scenarios such as compatibility testing and malware analysis. We introduce DroidBot, a lightweight UI-guided test input generator, which is able to interact with an Android app on almost any device without instrumentation. The key technique behind DroidBot is that it can generate UI-guided test inputs based on a state transition model generated on-the-fly, and allow users to integrate their own strategies or algorithms. DroidBot is lightweight as it does not require app instrumentation, thus users do not need to worry about the inconsistency between the tested version and the original version. It is compatible with most Android apps, and able to run on almost all Android-based systems, including customized sandboxes and commodity devices. Droidbot is released as an open-source tool on GitHub, and the demo video can be found at https://youtu.be/3-aHG-SazMY. © 2017 IEEE.","Android; Automated testing; Compatibility testing; Dynamic analysis; Malware detection","C (programming language); Computer crime; Dynamic analysis; Instrument testing; Malware; Open source software; Software engineering; Android; Automated test; Automated testing; Generation tools; Malware analysis; Malware detection; Open source tools; State transition models; Android (operating system)",2-s2.0-85026767745
"Cavalcanti G., Borba P., Accioly P.","Should we replace our merge tools?",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026783524&doi=10.1109%2fICSE-C.2017.103&partnerID=40&md5=6adc8d8958c03fe7a1e1b7773772eec8","While unstructured merge tools try to automatically resolve merge conflicts via textual similarity, semistructured merge tools try to go further by partially exploiting the syntactic structure and semantics of the involved artefacts. Previous studies compare these merge approaches with respect to the number of reported conflicts, showing, for most projects and merge situations, a reduction in favor of semistructured merge. However, these studies do not investigate whether this reduction actually leads to integration effort reduction (Productivity) without negative impact on the correctness of the merging process (Quality). To analyze this, and to better understand how these tools could be improved, we propose empirical studies to identify spurious conflicts reported by one approach but not by the other, and interference reported as conflict by one approach but missed by the other. © 2017 IEEE.","Collaborative development; Empirical studies; Software merging; Version control systems","Mergers and acquisitions; Merging; Semantics; Software engineering; Syntactics; Collaborative development; Empirical studies; Merging process; Semi-structured; Software merging; Syntactic structure; Textual similarities; Version control system; C (programming language)",2-s2.0-85026783524
"Jarvinen J., Huomo T., Mikkonen T.","Running software research programs: An agile approach",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026771688&doi=10.1109%2fICSE-C.2017.59&partnerID=40&md5=7a860ce64c2db1ebcefc896755f290cb","Agile, lean processes have become the de-facto way to operate in the domain of software intensive products. Methodologies such as the lean startup are reshaping the way new companies and even well-established enterprises seek new opportunities in their operations. In contrast, in research, little has changed during that time - organizations that fund research still expect a solid, linear research plan. In this paper, we present an attempt to challenge this model in software research, based on 7 years of experiences in two large, national, industry-led projects that followed a more agile mindset. Furthermore, we also provide an insight to key learnings and best practices of running software research in agile fashion. © 2017 IEEE.","Agile; Experimentation; Lean; Software research","Software engineering; Agile; Agile approaches; Best practices; Experimentation; Lean; Lean process; Research plans; Research programs; C (programming language)",2-s2.0-85026771688
"Nguyen T.V., Nguyen A.T., Phan H.D., Nguyen T.D., Nguyen T.N.","Combining Word2Vec with revised vector space model for better code retrieval",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026759817&doi=10.1109%2fICSE-C.2017.90&partnerID=40&md5=4924df9e9648a25a8ec312d27ac579b9","API example code search is an important applicationin software engineering. Traditional approaches to API codesearch are based on information retrieval. Recent advance inWord2Vec has been applied to support the retrieval of APIexamples. In this work, we perform a preliminary study thatcombining traditional IR with Word2Vec achieves better retrievalaccuracy. More experiments need to be done to study differenttypes of combination among two lines of approaches. © 2017 IEEE.","Code Search; Information Retrieval; Word2Vec","Codes (symbols); Information retrieval; Software engineering; Vector spaces; Code retrievals; Code search; Traditional approaches; Two-line; Vector space models; Word2Vec; C (programming language)",2-s2.0-85026759817
"Nayebi M., Cho H., Farrahi H., Ruhe G.","App store mining is not enough",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026751665&doi=10.1109%2fICSE-C.2017.77&partnerID=40&md5=7c6b18cc0cbf07dfd935b8a97b70e527","App store reviews are currently the main source of information for analyzing different aspects of app development and evolution. However, app users' feedback do not only occur on the app store. In fact, a large quantity of posts about apps are made daily on social media. In this paper, we study how Twitter can provide complementary information to support mobile app development. By analysing a total of 70 apps over a period of six weeks, we show that 22.4% more feature requests and 12.89% more bug reports could be found on Twitter. © 2017 IEEE.","App store mining; Machine learning; Mobile apps; Topic modeling; Twitter","Data mining; Learning systems; Social networking (online); Software engineering; App stores; Bug reports; Feature requests; Mobile app; Mobile apps; Social media; Topic Modeling; Twitter; C (programming language)",2-s2.0-85026751665
"Baset S.A., Li S.-W., Suter P., Tripp O.","Identifying android library dependencies in the presence of code obfuscation and minimization",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026747013&doi=10.1109%2fICSE-C.2017.79&partnerID=40&md5=6561791fa5bf91a9e6319f739b3348e2","The fast growth of the Android app market motivates the need for tools and techniques to analyze and improve Android apps. A basic capability in this context is to identify the libraries present in a given Android app, including their exact version. The problem of identifying library dependencies is made difficult by two common build-time transformations, namely code minimization and obfuscation. Minimization typically incorporates used library fragments into an app, while obfuscation renames symbols globally across an app. In this paper, we tackle both of these challenges via a unified approach, which abstracts app and library classes into summaries of their interactions with system libraries. The summarization technique is resistant to obfuscation, and is amenable to efficient similarity detection (matching). We lift the class-wise matches into a set of library dependencies by encoding this problem as a global constraint/optimization system across all app classes and available libraries. Our techniques identify the exact libraries and their versions used in the apps, for clear apps the recall is almost perfect at 98%. For obuscated/minimized apps it stands at 85%. © 2017 IEEE.","Android; Constraint optimization; Mobile app; Software libraries; TF-IDF","Application programs; C (programming language); Constrained optimization; Software engineering; Android; Constraint optimizations; Mobile app; Software libraries; TF-IDF; Android (operating system)",2-s2.0-85026747013
"Bertolino A., Calabro A., Lonetti F., Marchetti E., Miranda B.","What paper types are accepted at the international conference on software engineering?",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026789417&doi=10.1109%2fICSE-C.2017.50&partnerID=40&md5=193d63df59b2f4b8e68001c4154ddbaa","With the aim of identifying good structures and examples for papers in the software engineering field, we conducted a study of the type of papers accepted along four decades in the Research Track of the International Conference on Software Engineering (ICSE). We used for this purpose a categorization scheme for Software Engineering papers that was obtained by merging, extending and revising a few existing paper scheme proposals. This paper summarizes some outcomes relative to what topics and problems are addressed, what types of contribution are presented and how they are validated. Insights from the study could help ICSE authors, reviewers and conference organizers in focusing and improving future efforts. © 2017 IEEE.","Paper categorization; Paper type; Research contribution; Research problem; Software Engineering conference","C (programming language); Paper products; Paper-type; Research problems; Software engineering; Computer Programs; Engineering; Paper; Problem Solving; Research",2-s2.0-85026789417
"Huang R., Zong W., Towey D., Zhou Y., Chen J.","An empirical examination of abstract test case prioritization techniques",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026773236&doi=10.1109%2fICSE-C.2017.105&partnerID=40&md5=af6252b916e381f1353b16ea7d36c81f","Abstract test case prioritization (ATCP) aims at ordering abstract test case in order to increase the speed at which faults are detected, potentially increasing the fault detection rate. This paper empirically examines possible ATCP techniques, according to the following four categories: non-information-guided prioritization (NIGP), interaction coverage based prioritization (ICBP), input-model mutation based prioritization (IMBP), and similarity based prioritization (SBP). We found that the ICBP category has better testing effectiveness than others, according to fault detection rates. Surprisingly, we found that NIGP can achieve similar performance to IMBP, and that SBP can sometimes achieve even better rates of fault detection than some ICBP techniques. © 2017 IEEE.","Abstract test case prioritization; Empirical examination; Software testing","C (programming language); Fault detection; Software engineering; Empirical examination; Fault detection rate; Input modeling; Prioritization; Test case; Test case prioritization; Testing effectiveness; Software testing",2-s2.0-85026773236
"Moran K., Linares-Vasquez M., Bernal-Cardenas C., Vendome C., Poshyvanyk D.","CrashScope: A practical tool for automated testing of android applications",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026744793&doi=10.1109%2fICSE-C.2017.16&partnerID=40&md5=c60cfe0c9b6341131a101a7089475610","Unique challenges arise when testing mobile applications due to their prevailing event-driven nature and complex contextual features (e.g. sensors, notifications). Current automated input generation approaches for Android apps are typically not practical for developers to use due to required instrumentation or platform dependence and generally do not effectively exercise contextual features. To better support developers in mobile testing tasks, in this demo we present a novel, automated tool called CRASHSCOPE. This tool explores a given Android app using systematic input generation, according to several strategies informed by static and dynamic analyses, with the intrinsic goal of triggering crashes. When a crash is detected, CRASHSCOPE generates an augmented crash report containing screenshots, detailed crash reproduction steps, the captured exception stack trace, and a fully replayable script that automatically reproduces the crash on a target device(s). Results of preliminary studies show that CRASHSCOPE is able to uncover about as many crashes as other state of the art tools, while providing detailed useful crash reports and test scripts to developers. Website: www.android-dev-tools.com/crashscope-home Video url: https://youtu.be/ii6S1JF6xDw. © 2017 IEEE.","Android; Automated testing; Crash reports","Automation; C (programming language); Crashworthiness; Software engineering; Android; Android applications; Automated testing; Contextual feature; Crash reports; Mobile applications; State of the art; Static and dynamic analysis; Android (operating system)",2-s2.0-85026744793
"Vedurada J., Nandivada V.K.","Refactoring opportunities for replacing type code with state and subclass",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026750870&doi=10.1109%2fICSE-C.2017.97&partnerID=40&md5=6c50921e76d85fd36cfbf762dc25bea8","Refactoring restructures a program to improve itsreadability and maintainability, without changing its originalbehavior. One of the key steps in refactoring is the identification ofpotential refactoring opportunities. In this paper, we discuss therelevance of two popular refactorings 'Replace Type Code withSubclass' and 'Replace Type Code with State' in real world Javaapplications and describe some of the challenges in automaticallyidentifying these refactoring opportunities. © 2017 IEEE.","Program Analysis; Refactoring; Replace Conditionals with Polymorphism; Replace Type Code with State; Replace Type Code with Subclass","Codes (symbols); Software engineering; Program analysis; Real-world; Refactorings; Replace Type Code with State; Replace Type Code with Subclass; C (programming language)",2-s2.0-85026750870
"Mendes J., Cunha J., Duarte F., Engels G., Saraiva J., Sauer S.","Towards systematic spreadsheet construction processes",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026752320&doi=10.1109%2fICSE-C.2017.141&partnerID=40&md5=b1edc97340da6401eead9675e6880119","Spreadsheets are used in professional business contexts to make decisions based on collected data. Usually, these spreadsheets are developed by end users (e.g. accountants) in an ad-hoc way. The effect of this practice is that the business logic of a concrete spreadsheet is not explicit to them. Thus, its correctness is hard to assess and users have to trust. We present an approach where structure and computational behavior of a spreadsheet are specified by a model with a process-like notation based on combining pre-defined functional spreadsheet services with typed interfaces. This allows for a consistent construction of a spreadsheet by defining its structure and computational behavior as well as filling it with data and executing the defined computational behavior. Thus, concrete spreadsheets are equipped with a specification of their construction process. This supports their understanding and correct usage, even in case of legacy spreadsheets. The approach has been developed in cooperation with an industrial partner from the automotive industry. © 2017 IEEE.","Construction process; Model-driven engineering; Situational method engineering; Spreadsheet","Automotive industry; C (programming language); Computation theory; Concretes; Construction; Software engineering; Business contexts; Business logic; Construction process; End users; Industrial partners; Model-driven Engineering; Situational Method Engineering; Spreadsheets",2-s2.0-85026752320
"Mills C., Haiduc S.","A machine learning approach for determining the validity of traceability links",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026759833&doi=10.1109%2fICSE-C.2017.86&partnerID=40&md5=ea83362c1d0423daa96ff2c7791bcd74","Traceability Link Recovery (TLR) is a fundamental software maintenance task in which links are established between related software artifacts of different types (e.g., source code, documentation, requirements specifications, etc.) within a system. Existing approaches to TLR often require a human to analyze a long list of potential links and distinguish valid links from invalid ones. Here we present an approach which bypasses this intermediate step and automatically classifies links as valid or invalid using a machine learning approach and features such as text retrieval (TR) rankings and query quality (QQ) metrics. We performed an evaluation on recovering traceability links in three software systems and the results show the potential of our approach, which achieved 95% accuracy on average using both types of features. © 2017 IEEE.","Classification; Supervised machine learning; Text retrieval; Traceability","Artificial intelligence; Classification (of information); Information retrieval; Learning systems; Software engineering; Supervised learning; Text processing; Machine learning approaches; Requirements specifications; Software artifacts; Software-maintenance tasks; Supervised machine learning; Text retrieval; Traceability; Traceability links; C (programming language)",2-s2.0-85026759833
"Moreno L., Marcus A.","Automatic software summarization: The state of the art",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026746492&doi=10.1109%2fICSE-C.2017.169&partnerID=40&md5=682cede448793d8418ba65e7da2145f6","Automatic text summarization has been widely studied for more than fifty years. In software engineering, automatic summarization is an emerging area that shows great potential and poses new and exciting research challenges. This technical briefing provides an introduction to the state of the art and maps future research directions in automatic software summarization. © 2017 IEEE.",,"Software engineering; Automatic summarization; Automatic text summarization; Future research directions; Research challenges; State of the art; C (programming language)",2-s2.0-85026746492
"Zhang W., Liu X., Yang Y.","Let smart ants help you reduce the delay penalty of multiple software projects",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026743834&doi=10.1109%2fICSE-C.2017.56&partnerID=40&md5=03febc681165ca6bb4dda6c62a56d4ac","Delays often occur in real-world software development projects and may cause significant monetary penalties to software companies. Meanwhile, industry lessons have shown that adding inexperienced employees would cause further delays due to the learning curve and communication overhead. However, if employees with same or similar skills and domain knowledge can be rescheduled from other concurrent projects to help with the delayed projects, it may be possible to reduce or even eliminate delay penalties without requesting extra employees. Here, the big challenge is how to conduct employee rescheduling without having employees working overtime, which is an NP hard problem in nature. To address such a problem, this paper proposes a novel employee rescheduling strategy based on improved ant colony optimization algorithm. Specifically, three generic rules are proposed to improve the effectiveness in generating valid solutions. Preliminary results on benchmark projects show that our strategy can achieve much better effectiveness than its genetic algorithm based counterpart in reducing the overall delay penalty of multiple software projects. © 2017 IEEE.","Ant Colony Optimization; Employee Rescheduling; Project Delay Penalty; Software Project","Ant colony optimization; Artificial intelligence; Computational complexity; Genetic algorithms; Optimization; Software design; Software engineering; Communication overheads; Domain knowledge; Improved ant colony optimization; Learning curves; Project delays; Software company; Software development projects; Software project; C (programming language)",2-s2.0-85026743834
"Li Z., Liang P., Li B.","Relating alternate modifications to defect density in software development",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026750655&doi=10.1109%2fICSE-C.2017.132&partnerID=40&md5=981923d4e42c6f5b24bd8a200a0133db","A software developer tends to spend more effort to understand source code written by other developers than code written by herself. Existing research studying the impact of changes made by multiple developers on bug proneness did not consider quantitatively the influence of the order of the changes made by different developers. We found that a significant proportion of source files in many open source software systems had been modified alternately by different developers. We developed a metric, namely alternate modification index (AMI), to indicate the extent to which a source file is modified alternately by multiple developers. Our preliminary case study results show that AMI of source files has a strong positive correlation with their defect density. © 2017 IEEE.","Alternate modification; Alternate modification index; Defect density; Software developer","Computer software; Defect density; Defects; Open source software; Open systems; Software design; Software engineering; Alternate modification; Alternate modification index; Impact of changes; Open source software systems; Positive correlations; Software developer; Source codes; Source files; C (programming language)",2-s2.0-85026750655
"Ferreira G.","Software certification in practice: How are standards being applied?",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026744405&doi=10.1109%2fICSE-C.2017.156&partnerID=40&md5=896275d6d0431622ff3b1be902adf388","Certification schemes exist to regulate software systems and prevent them from being deployed before they are judged fit to use. However, practitioners are often unsatisfied with the efficiency of certification standards and processes. In this study, we analyzed two certification standards, Common Criteria and DO-178C, and collected insights from literature and from interviews with subject-matter experts to identify concepts affecting the efficiency of certification processes. Our results show that evaluation time, reusability of evaluation artifacts, and composition of systems and certified artifacts are barriers to achieve efficient certification. © 2017 IEEE.","Certification standards; Common criteria; Do-178c; Interview study","Efficiency; Reusability; Software engineering; Standards; Certification process; Certification standards; Common criteria; Interview study; Software certification; Software systems; Subject matter experts; C (programming language)",2-s2.0-85026744405
"Rodriguez A.","Reducing energy consumption of resource-intensive scientific mobile applications via code refactoring",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026772446&doi=10.1109%2fICSE-C.2017.33&partnerID=40&md5=b7ffb2ce48ae91d2f2c99591dee7398b","The advent of new computing paradigms such as Mobile Grids and Mobile-edge Clouds, and the increasing number of mobile devices with ever-growing capabilities makes them attractive to users running scientific and HPC applications. However, mobile devices still have limited capabilities when compared to non-mobile devices. More importantly, mobile devices rely on batteries for their power supply. To overcome this problem, this PhD research studies how to reduce energy consumption in mobile devices via code refactoring for such kind of applications. © 2017 IEEE.",,"Energy utilization; Software engineering; Code re-factoring; Computing paradigm; Mobile applications; Mobile grid; Power supply; Reduce energy consumption; Reducing energy consumption; Research studies; C (programming language)",2-s2.0-85026772446
"Pereira J.A.","A collaborative-based recommender system for configuration of extended product lines",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026766709&doi=10.1109%2fICSE-C.2017.36&partnerID=40&md5=1532a567cafdc7d3bb77f433f73796cf","Product Line (PL) configuration practices have been employed by industries as a mass customization process. However, due to the NP-hard nature of the process, performance concerns start to be an issue when facing large-scale configuration spaces. The aim of my doctoral research is therefore to propose an efficient collaborative-based recommender system that provides accurate and scalable solutions to users. To demonstrate the efficiency of the proposed recommender system, I will conduct series of experiments on real-world extended PLs. In addition, I plan empirically to verify through a user case study the usability of the proposed approach. My expected contribution is to support the adoption of PL configuration practices in industrial scenarios. © 2017 IEEE.",,"C (programming language); Software engineering; Configuration space; Doctoral research; Extended product; Industrial scenarios; Mass customization; Product-lines; Real-world; Scalable solution; Recommender systems",2-s2.0-85026766709
"Mohagheghi P., Jorgensen M.","What contributes to the success of IT projects? Success factors, challenges and lessons learned from an empirical study of software projects in the norwegian public sector",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026750833&doi=10.1109%2fICSE-C.2017.146&partnerID=40&md5=58786c8a7f0590f4ab0effe983a4536e","Context. Each year the public sector invests large amounts of money in the development and modifications of their software systems. These investments are not always successful and many public sector software projects fail to deliver the expected benefits. Goal. This study aims at reducing the waste of resources on failed software projects through better understanding of the success factors and challenges. Method. Thirty-five completed software projects in 11 organizations in the public sector of Norway were analyzed. For each project, representatives from the project owners, project management and the user organization were interviewed. Results. Small and large software projects reported different challenges, especially related to project priority. Taking advantage of agile practices such as flexible scope and frequent delivery increased the success rate of the projects. Projects with time and material contracts and involved clients during execution were more successful than other projects. The respondents experienced that extensive involvement and good competence of the client, high priority of the project, good dialogue between client and provider and appliance of agile practices were main success factors. Main challenges were related to technical issues, project planning and management, transition of the product to the user organization, involvement and competence of the client, and benefit management. Conclusions. Success factors tend to focus on human factors, e.g., involvement, competence and collaboration. Challenges focus on human factors as well as issues of technical nature. Both aspects need to be addressed to enable successful and avoid failed software projects. Competence, client involvement and benefit management are among factors that the public sector should focus on for realizing client benefits. © 2017 IEEE.","Agile; Contract type; Empirical study; Software projects; Success","Human engineering; Project management; Software engineering; Agile; Agile practices; Empirical studies; Project planning; Software project; Software systems; Success; Waste of resources; C (programming language)",2-s2.0-85026750833
"Souza A.D.D., Seabra R.D., Ribeiro J.M., Rodrigues L.E.D.S.","SCRUMI: A Board serious virtual game for teaching the SCRUM framework",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026776029&doi=10.1109%2fICSE-C.2017.124&partnerID=40&md5=8e47f211261c0715a2234f99a7e6af9d","The use of serious games has emerged as a differentiated strategy to promote the teaching of essential concepts and techniques in several areas of knowledge. To contribute to the student's formation process in Software Project Management, this research presents the development and validation of an electronic board serious game, named SCRUMI, for teaching concepts inherent to the SCRUM framework. The evaluation of the proposed game was carried out according to some criteria such as usability, quality of questions and activities presentation, applicability and motivation. The main results showed that the game is presented as a good alternative to be explored in the classroom. © 2017 IEEE.","Experimental research; SCRUM framework; SCRUMI; Serious game; Software project management","C (programming language); E-learning; Project management; Research and development management; Software engineering; Teaching; Differentiated strategy; Electronic boards; Experimental research; Formation process; SCRUM framework; SCRUMI; Software project management; Teaching concepts; Serious games",2-s2.0-85026776029
"Cai Y., Kazman R.","Detecting and quantifying architectural debt: Theory and practice",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026760418&doi=10.1109%2fICSE-C.2017.165&partnerID=40&md5=7e254db4452659447ff6f96d75e8f75b","In this technical briefing, we will introduce the theory, practice, and tool support for detecting and quantifying architectural debt. We will introduce the concept of design rule space (DRSpace) - a new architectural model forming the foundation of architectural debt detection, hotspot patterns - recurring architectural flaws leading to architectural debt, and architectural debt quantification. © 2017 IEEE.","Software architecture; Software design; Technical debt","Pattern recognition; Software architecture; Software design; Software engineering; Architectural modeling; Design rules; Hot spot; Technical debts; Theory and practice; Tool support; C (programming language)",2-s2.0-85026760418
"Su F.-H.","Uncovering features in kindred programs",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026730295&doi=10.1109%2fICSE-C.2017.176&partnerID=40&md5=4704296e86105e0d99bd50f953e15e37","The detection of similar code can support many software engineering tasks such as program understanding and API replacement. Many excellent approaches have been proposed to detect programs having similar syntactic features. However, some programs dynamically or statistically close to each other, which we call kindred programs, may be ignored. We believe the detection of kindred programs can enhance or even automate the tasks relevant to program classification. In this proposal, we will discuss our current approaches to mine kindred programs having similar functional features and behavioral features. We will also roadmap our on-going development that integrates program analysis with machine learning models to extract statistical features from codebases. © 2017 IEEE.","Code clone; Code relative; Code similarity; Dynamic analysis; Program feature; Simion; Static analysis","Codes (symbols); Dynamic analysis; Learning systems; Software engineering; Static analysis; Code clone; Code relative; Code similarities; Program feature; Simion; C (programming language)",2-s2.0-85026730295
"Condori-Fernandez N.","HAPPYNESS: An emotion-aware QoS assurance framework for enhancing user experience",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026778373&doi=10.1109%2fICSE-C.2017.137&partnerID=40&md5=19b9deefdf2c3f2ff4816755580e58cb","In this paper, we introduce the idea of exploiting the emotional information as a key element in providing personalized context-aware software services and consequently enhancing quality of User Experience(UX). We argue that emotional measurements can be integrated in Quality of Service (QoS) assurance frameworks. The idea builds on the strength of technological advances in emotion measurement tools, nonobtrusive and ubiquitous monitoring technology. © 2017 IEEE.","Context awareness; Monitoring; QoS; Stress measurement; User Experience","C (programming language); Monitoring; Software engineering; Stress measurement; User interfaces; Context- awareness; Emotional information; Measurement tools; Monitoring technologies; Software services; Technological advances; User experience; User experiences (ux); Quality of service",2-s2.0-85026778373
"Martin S.M., Berger M.J., Baden S.B.","Toucan-A Translator for Communication Tolerant MPI Applications",2017,"Proceedings - 2017 IEEE 31st International Parallel and Distributed Processing Symposium, IPDPS 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027693885&doi=10.1109%2fIPDPS.2017.44&partnerID=40&md5=2fb6584da4d1051900d4d06378a4720b","We discuss early results with Toucan, a source-to-source translatorthat automatically restructures C/C++ MPI applications tooverlap communication with computation. We co-designed thetranslator and runtime system to enable dynamic, dependence-drivenexecution of MPI applications, and require only a modest amount ofprogrammer annotation. Co-design was essential to realizingoverlap through dynamic code block reordering and avoiding the limitations of static code relocation and inlining. We demonstrate that Toucan hides significantcommunication in four representative applications running on up to 24Kcores of NERSC's Edison platform. Using Toucan, we have hidden from 33% to 85% of the communication overhead, with performance meeting or exceeding that of painstakingly hand-written overlap variants. © 2017 IEEE.","Communication/Computation Overlap; Data-Driven; MPI; Source-to-Source Translator","C++ (programming language); Message passing; Co-designs; Code blocks; Communication overheads; Data driven; MPI applications; Runtime systems; Source-to-source translators; Static codes; Program processors",2-s2.0-85027693885
"Guo C., Dong N., Bai G., Ye Q., Dong J., Xu J., Si G.","App genome: Callback sequencing in android",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026744088&doi=10.1109%2fICSE-C.2017.82&partnerID=40&md5=bfabb5322db93c22cc3c9254fbaaeb8a","Recent analysis shows that the callback sequences are of great importance in the analysis of Android applications (apps for short), due to the app's event-driven nature. However, existing works only extract a part of the callback sequences, depending on the need for their specific properties. We propose App Genome sequencing, an automatic fine-grained callback extraction, covering lifecycle and non-lifecycle, inner-and inter-component callback relations, as well as related attributes, including global objects and operations, along the callback sequences. The extracted App Genome facilitates more complete analysis of Android apps, since it contains more callback sequences and data information, than existing works. We use a process algebra called CSP# to represent the App Genome. We implement our method as a tool, which takes an app as input, automatically generates the CSP# model of the App Genome and automatically invokes the model checker to verify a given property. © 2017 IEEE.","Android; Callback graph; Model checking; Security","C (programming language); Genes; Life cycle; Model checking; Software engineering; Android; Android applications; Callback graph; Data informations; Genome sequencing; Process algebras; Security; Specific properties; Android (operating system)",2-s2.0-85026744088
"Stratis P.","Improving test execution time with improved cache locality",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026759039&doi=10.1109%2fICSE-C.2017.153&partnerID=40&md5=0025b4f2054d13c5508e3026d034a0dc","As software systems become more complex, the number of test cases required for effective testing becomes intractable. Cache misses have been identified as a major factor that affects software execution time. In our current work we target the instruction locality problem in the context of testing. © 2017 IEEE.","Cache misses; Instruction locality; Testing","C (programming language); Software engineering; Testing; Cache locality; Cache Miss; Effective testing; Instruction locality; Major factors; Software execution; Software systems; Test execution; Software testing",2-s2.0-85026759039
"Wang L.","Search-based adaptation planning framework for self-adaptive systems",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026753417&doi=10.1109%2fICSE-C.2017.21&partnerID=40&md5=667f01f19a428faf41c4ec1a0827c025","Future-generation Self-Adaptive Systems (SASs) are required to adapt to the multiple, interrelated, and evolving changes. Current adaptation planning methods, which consider only one or two changes at a time and assume that changes are independent and the prioritization of them is static, need to be improved. Arguing that the adaptation planning is a search problem, this thesis highlights the feasibility and potential benefits of adopting Search-Based Optimization as an innovative planning method. A search-based adaptation planning framework is proposed to deal with these changes and make the best decisions for future-generation SASs. © 2017 IEEE.","Search-based optimization; Search-based software engineering; Self-adaptation planning; Self-adaptive systems","C (programming language); Software engineering; Future generations; Planning framework; Planning method; Potential benefits; Search based optimizations; Search-based software engineering; Self adaptation; Self-adaptive system; Adaptive systems",2-s2.0-85026753417
"Kazman R., Stoddard R., Danks D., Cai Y.","Causal modeling, discovery, & inference for software engineering",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026788910&doi=10.1109%2fICSE-C.2017.138&partnerID=40&md5=00a636b04f3f2aca20dc0c33552b4578","Empirical studies in software engineering frequently rely on correlation data in an effort to demonstrate that a process or tool affects an important or meaningful outcome, with the ultimate goal of improving software engineering practice. But all students of statistics know that 'correlation does not imply causation,' and so causal conclusions (using traditional methods) from observational studies are inevitably highly constrained. These studies thus have limited impact on real world practice. In this paper, we use methods beyond mere correlation, and apply techniques of causal discovery to software engineering data as a means of unambiguously determining cause and effect. We apply causal discovery techniques to a set of observational data on open source projects, use the results to determine some consequences of architectural flaws, and show how causal inference may be applied to software engineering data in the future. © 2017 IEEE.","Causal inference; Correlation studies; Empirical software engineering","C (programming language); Open source software; Open systems; Causal inferences; Correlation studies; Empirical Software Engineering; Observational study; Open source projects; Real-world practice; Software engineering data; Software engineering practices; Software engineering",2-s2.0-85026788910
"Ma Y., Liu X., Hu Z., Yang D., Huang G., Liu Y., Xie T.","Aladdin: Automating release of android deep links to in-app content",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026738381&doi=10.1109%2fICSE-C.2017.107&partnerID=40&md5=1afa41831e79c19f59226609ea10bea2","Unlike the Web where each web page has a global URL to reach, a specific 'content page' inside a mobile app cannot be opened unless the user explores the app with several operations from the landing page. Recently, deep links have been advocated by major companies to enable targeting and opening a specific page of an app externally with an accessible uniform resource identifier (URI). In this paper, we present an empirical study of deep links over 20,000 Android apps, and find that deep links do not get wide adoption among current Android apps, and non-trivial manual efforts are required for app developers to support deep links. To address such an issue, we propose the Aladdin approach and supporting tool to release deep links to access arbitrary locations of existing apps. We evaluate Aladdin with popular apps and demonstrate its effectiveness and performance. © 2017 IEEE.","Android apps; Deep link; Program analysis","C (programming language); Software engineering; Websites; Android apps; Deep link; Empirical studies; Landing pages; Non-trivial; Program analysis; Supporting tool; Uniform resource identifiers; Android (operating system)",2-s2.0-85026738381
"Labunets K., Janes A., Felderer M., Massacci F.","Teaching predictive modeling to junior software engineers - Seminar format and its evaluation",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026746934&doi=10.1109%2fICSE-C.2017.62&partnerID=40&md5=f03dcd4bd182c5e480e34e539e09685c","Due to the increased importance of machine learning in software and security engineering, effective trainings are needed that allow software engineers to learn the required basic knowledge to understand and successfully apply prediction models fast. In this paper, we present a two-days seminar to teach machine learning-based prediction in software engineering and the evaluation ofits learning effects based on Bloom's taxonomy. As a teaching scenario for the practical part, we used a paper reporting a research study on the application ofmachine learning techniques to predict vulnerabilities in the code. The results of the evaluation showed that the seminar is an appropriate format for teaching predictive modeling to software engineers. The participants were very enthusiastic and self-motivated to learn about the topic and the empirical investigation based on Bloom's taxonomy showed positive learning effects on the knowledge, comprehension, application, analysis, and evaluation level. © 2017 IEEE.","Bloom's taxonomy; Empirical Software Engineering; Machine Learning; Predictive models","Artificial intelligence; Blooms (metal); Engineers; Forecasting; Learning systems; Software engineering; Taxonomies; Bloom's taxonomy; Empirical investigation; Empirical Software Engineering; Learning techniques; Prediction model; Predictive modeling; Predictive models; Security engineering; C (programming language)",2-s2.0-85026746934
"Balestri D., Capucci D., Demitri N., Bacchi A., Pelagatti P.","Coordination driven capture of nicotine inside a mesoporous MOF",2017,"Materials",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021651117&doi=10.3390%2fma10070727&partnerID=40&md5=178aff8468723779163db6f68feffe98","Metal organic frameworks (MOFs) are a wide class of crystalline porous polymers studied in many fields, ranging from catalysis to gas storage. In the past few years, MOFs have been studied for the encapsulation of organic or organometallic molecules and for the development of potential drug carriers. Here, we report on the study of two structurally-related mesoporous Cu-MOFs, namely PCN-6 and PCN-60 (PCN stands for Porous Coordination Network), for nicotine trapping. Nicotine is a well-known alkaloid liquid molecule at room temperature, whose crystalline structure is still unknown. In this work, the loading process was monitored by electron ionization mass spectrometry by using a direct insertion probe (DIP-EI/MS), infrared (IR), and ultraviolet/visible (UV/VIS) analysis. Both nuclear magnetic resonance (NMR) spectroscopy and thermogravimetric (TGA) analysis showed evidence that nicotine trapping reaches remarkable uptakes up to 40 wt %. In the case of PCN-6@nicotine, X-ray structural resolution revealed that the guest uptake is triggered by coordination of the pyridine ring of nicotine to the copper nuclei of the paddle-wheel units composing the framework of PCN-6. © 2017 by the authors.","Crystalline sponge; Host-guest; Inclusion; MOF; Nicotine","Crystalline materials; Inclusions; Ionization of gases; Java programming language; Mass spectrometry; Molecules; Nuclear magnetic resonance; Nuclear magnetic resonance spectroscopy; Organic polymers; Organometallics; Thermogravimetric analysis; Coordination-driven; Crystalline structure; Electron ionization mass spectrometry; Host-guests; Metalorganic frameworks (MOFs); Nuclear magnetic resonance(NMR); Organo-metallic molecules; Porous coordination networks; Nicotine",2-s2.0-85021651117
"Sadkhan S.B., Salman H.M.","Proposed identification algorithm of evil nodes in WSN",2017,"International Conference on Current Research in Computer Science and Information Technology, ICCIT 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026786266&doi=10.1109%2fCRCSIT.2017.7965552&partnerID=40&md5=dcfee351d3ff7797dee88b7dc57f4225","There are two main stages in the proposed system: Firstly includes detection and determining the number of evil paths depending on encoding an input messages by the source node by using the system of linear equations and sent these coded messages to the sink mode along the disjointed-multi-paths of the network. The sink node will construct number of equations from the received coded messages. It can detect number of evil paths depending on the number of inconsistent equations. It can determine which paths are exact evil paths depending on the indices of these inconsistent equations. In the second stage, both the source node and the sink node will deal only with the nodes of the evil path. They will built the source codes for the nodes of the evil path. Depending on these source codes, the sink node can detect number of the evil nodes by using a Boolean operations. Also it can locate the evil nodes according to the source code of the source node and the source code of the sink node. © 2017 IEEE.","Attacks; Information Security; WSN; WSN security","Computer programming languages; Security of data; Attacks; Boolean operations; Coded messages; Identification algorithms; Source codes; Source nodes; System of linear equations; WSN security; Codes (symbols)",2-s2.0-85026786266
"Vost S., Wagner S.","Keeping continuous deliveries safe",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026752449&doi=10.1109%2fICSE-C.2017.135&partnerID=40&md5=eb2aabc117eaa3ea8559ded4d6360cb5","Allowing swift release cycles, Continuous Delivery has become popular in application software development and is starting to be applied in safety-critical domains such as the automotive industry. These domains require thorough analysis regarding safety constraints, which can be achieved by the execution of safety tests resulting from a safety analysis on the product. With continuous delivery in place, such tests need to be executed with every build to ensure the latest software still fulfills all safety requirements. Even more though, the safety analysis has to be updated with every change to ensure the safety test suite is still up-to-date. We thus propose that a safety analysis should be treated no differently from other deliverables such as source-code and dependencies, propose guidelines to adopt this and formulate implications for the development process. © 2017 IEEE.","Embedded Software; Software Quality; Software Safety","Accident prevention; Application programs; Automotive industry; Computer software selection and evaluation; Embedded software; Safety engineering; Safety testing; Software design; Software engineering; Software testing; Development process; Release cycles; Safety analysis; Safety constraint; Safety requirements; Safety-critical domain; Software Quality; Software safety; C (programming language)",2-s2.0-85026752449
"Tosun A., Turkgulu O., Razon D., Aydemir H.Y., Gureller A.","Predicting defects using test execution logs in an industrial setting",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026787321&doi=10.1109%2fICSE-C.2017.148&partnerID=40&md5=b306e21b0c3b2e22b3b09db654921c3a","Researchers often focus on the development process and the final product (source code) to investigate and predict software defects. Unfortunately, these models may not be applicable to software projects in which there is no access to the data sources regarding development process. For example, in cases when a company conducts tests on behalf of its business contractors, it is only possible to evaluate in-process quality of the company based on its testing process. We present an industrial case at Ericsson Turkey that illustrates such a business constraint. We define a set of in-process testing metrics that are extracted from acceptance test execution logs of a large scale software application developed at Ericsson Turkey. We measure the acceptance testing process of 15 weeks using these metrics, and predict the number of defects reported in weekly acceptance tests. We report our measurement, model construction and assessment steps in this paper. © 2017 IEEE.","Acceptance testing; Industrial case study; Software defect prediction; Test execution logs","Application programs; C (programming language); Defects; Forecasting; Software engineering; Software testing; Testing; Acceptance testing; Business constraints; Development process; Industrial case study; Industrial settings; Large-scale software applications; Software defect prediction; Test execution; Acceptance tests",2-s2.0-85026787321
"Artac M., Borovssak T., Di Nitto E., Guerriero M., Tamburri D.A.","DevOps: Introducing infrastructure-as-code",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026740945&doi=10.1109%2fICSE-C.2017.162&partnerID=40&md5=01d7b87c6d32f489eec541f30c3d2a64","DevOps entails a series of software engineering tactics aimed at shortening the actionable operation of software design changes. One of these tactics is to harness infrastructure-as-code, that is, writing a blueprint that contains deployment specifications ready for orchestration in the cloud. This abstract briefly discusses all necessary elements and abstractions in writing and maintaining that blueprint, revolving around a key standard for its expression, namely, the OASIS 'Topology and Orchestration Specification for Cloud Applications' (TOSCA) industrial standard adopted by as many as 60+ big industrial players worldwide. © 2017 IEEE.","DevOps; Infrastructure-as-Code; TOSCA","Codes (symbols); Software design; Software engineering; Specifications; Cloud applications; DevOps; Industrial standards; Infrastructure-as-Code; TOSCA; C (programming language)",2-s2.0-85026740945
"Svajlenko J., Roy C.K.","Fast and flexible large-scale clone detection with cloneworks",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026731354&doi=10.1109%2fICSE-C.2017.3&partnerID=40&md5=5557c31f67c5dcb4b9afd1f80c6f631a","Clone detection in very-large inter-project repositories has numerous applications in software research and development. However, existing tools do not provide the flexibility researchers need to explore this emerging domain. We introduce CloneWorks, a fast and flexible clone detector for large-scale clone detection experiments. CloneWorks gives the user full control over the representation of the source code before clone detection, including easy plug-in of custom source transformation, normalization and filtering logic. The user can then perform targeted clone detection for any type or kind of clone of interest. CloneWorks uses our fast and scalable partitioned partial indexes approach, which can handle any input size on an average workstation using input partitioning. CloneWorks can detect Type-3 clones in an input as large as 250 million lines of code in just four hours on an average workstation, with good recall and precision as measured by our BigCloneBench. © 2017 IEEE.","Clone detection; Code clone; Fast; Flexible; Scalable","Application programs; C (programming language); Codes (symbols); Software engineering; Clone detection; Code clone; Fast; Flexible; Scalable; Cloning",2-s2.0-85026731354
"Vesin B., Jolak R., Chaudron M.R.V.","OctoUML: An environment for exploratory and collaborative software design",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016285615&doi=10.1109%2fICSE-C.2017.19&partnerID=40&md5=1bdcb9c80166a23d29136666c5b9d54d","Software architects seek efficient support for planningand designing models at multiple levels of abstraction andfrom different perspectives. For this it is desirable that softwaredesign tools support both informal and formal representation ofdesign, and also support their combination and the transitionbetween them. Furthermore, software design tools should beable to provide features for collaborative work on the design.OctoUML supports the creation of software models at variouslevels of formality, collaborative software design, and multi-modalinteraction methods. By combining these features, OctoUML isa prototype of a new generation software design environmentthat aims to better supports software architects in their actualsoftware design and modelling processes. © 2017 IEEE.","Collaborative design; Modelling notations; Multi-modal interaction; Software design; UML; User experience","C (programming language); Groupware; Software architecture; Software engineering; Software prototyping; Collaborative design; Collaborative software design; Collaborative Work; Formal representations; Modelling process; Multi-Modal Interactions; Software architects; User experience; Software design",2-s2.0-85016285615
"Wang H., Guo Y.","Understanding third-party libraries in mobile app analysis",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026755013&doi=10.1109%2fICSE-C.2017.161&partnerID=40&md5=d441e95d0c763f7c5370fabb60d76c9e","Third-party libraries are widely used in mobile apps. Recent studies showed that third-party libraries account for more than 60% of the code in Android apps on average. As a result, program analysis on Android apps typically requires detecting or removing third-party libraries first, because they usually introduce significant noises and affect the analysis results. In this technical briefing, we will introduce the latest research advances related to third-party libraries used in mobile apps. The briefing will be focused on: (1) the importance of third-party libraries, including the current status, types and distribution, based on the analysis results on over 1 million Android apps, (2) how to detect third-party libraries from Android apps, including an overview of existing approaches and their limitations, (3) the implications of third-party libraries in software engineering tasks such as mobile app analysis, as well as case studies from the domain of program analysis and mobile security, (4) future challenges and research directions related to third-party libraries. © 2017 IEEE.","Mobile apps; Mobile security; Program analysis; Third-party libraries","Android (operating system); Application programs; C (programming language); Libraries; Software engineering; Android apps; Case-studies; Current status; Future challenges; Mobile apps; Program analysis; Research advances; Third parties; Mobile security",2-s2.0-85026755013
"Theisen C., Dunaiski M., Williams L., Visser W.","Writing good software engineering research papers: Revisited",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026753991&doi=10.1109%2fICSE-C.2017.51&partnerID=40&md5=eaf417f67581dc9c6410a9a6f8f13ce7","With the goal of helping software engineering researchers understand how to improve their papers, Mary Shaw presented 'Writing Good Software Engineering Research Papers' in 2003. Shaw analyzed the abstracts of the papers submitted to the 2002 International Conference of Software Engineering (ICSE) to determine trends in research question type, contribution type, and validation approach. We revisit Shaw's work to see how the software engineering research community has evolved since 2002. The goal of this paper is to aid software engineering researchers in understanding trends in research question design, research question type, and validation approach by analyzing the abstracts of the papers submitted to ICSE 2016. We implemented Shaw's recommendation for replicating her study through the use of multiple coders and the calculation of inter-rater reliability and demonstrate that her approach can be repeated. Our results indicate that reviewers have increased expectations that papers have solid evaluations of the research contribution. Additionally, the 2016 results include at least 17% mining software repository (MSR) papers, a category of papers not seen in 2002. The advent of MSR papers has increased the use of generalization/characterization research questions, the production of empirical report contribution, and validation by evaluation. © 2017 IEEE.","Abstracts; Guidelines; Research; Writing","Abstracting; C (programming language); Research; Software engineering; Technical writing; Guidelines; Inter-rater reliabilities; Mining software repository (MSR); Research questions; Validation approach; Engineering research",2-s2.0-85026753991
"Pereira J.A.","Runtime collaborative-based configuration of software product lines",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026740596&doi=10.1109%2fICSE-C.2017.154&partnerID=40&md5=1792f24db5a9081f660b79ab70e3d79e","Software Product Line (SPL) configuration practices have been employed by industries as a mass customization process. However, the inherent variability of large SPLs leads to configuration spaces of exponential sizes. Thus, scalability and performance concerns start to be an issue when facing runtime environments, since it is usually infeasible to explore the entire configuration space exhaustively. In this context, the aim of my research is therefore to propose an efficient collaborative-based runtime approach that relies on recommender techniques to provide accurate and scalable configurations to users. To demonstrate the efficiency of the proposed approach, I conduct series of experiments on real-world SPLs. In addition, I plan empirically verify through a user case study the usability of the proposed approach. My expected contribution is to support the adoption of SPL configuration practices in industrial scenarios. © 2017 IEEE.","Collaborative-based recommendations; Configuration; Recommender systems; Software product lines","Computer software; Recommender systems; Software design; Software engineering; Wave functions; Collaborative-based recommendations; Configuration; Industrial scenarios; Inherent variability; Runtime environments; Scalability and performance; Software Product Line; Software product lines; C (programming language)",2-s2.0-85026740596
"Wong K., Patzelt M., Poulette B., Hathaway R.","Scenario-based learning in a MOOC specialization capstone on software product management",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026772148&doi=10.1109%2fICSE-C.2017.70&partnerID=40&md5=15e6c73d586bebaa6e94253bfed067bf","A Massive Open Online Course (MOOC) is a popular way for universities to deliver quality course content to a global audience. Furthermore, a MOOC specialization offers a series of related such courses with a capstone component. Typical software engineering capstone projects in campus courses involve teamwork and creating software. Within such a context, students experience the software development process and human dynamics. However, MOOC capstones need to work for individual learners, and scale to handle thousands of potential learners. Consequently, this paper outlines our approach in using scenario-based learning to simulate an environment of interacting with others for a learner playing the role of a software product manager. © 2017 IEEE.",,"Curricula; Education; Software design; Software engineering; Deliver quality; Engineering capstones; Human dynamics; Massive open online course; Scenario based learning; Software development process; Software product management; Software products; C (programming language)",2-s2.0-85026772148
"Emami-Taba M.","A game-theoretic decision-making framework for engineering self-protecting software systems",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026768564&doi=10.1109%2fICSE-C.2017.43&partnerID=40&md5=5e42a89a33348a5029eb9532974b2258","Targeted and destructive nature of strategies used by attackers to break down the system require mitigation approaches with dynamic awareness. Making a right decision, when facing today's sophisticated and dynamic attacks, is one of the most challenging aspects of engineering self-protecting software systems. Inspired by game theory, in this research work, we model the interactions between the attacker and the software system as a two-player game. Using game-theoretic techniques, the self-protecting software systems is able to: (i) fuse the strategies of attackers into the decision-making model, and (ii) refine the strategies in dynamic attack scenarios by utilizing what has learned from the system's and adversary's interactions. This research introduces a novel decision-making framework with three phases: (i) modeling quality goals aiming at incorporating them into the decision model, (ii) designing game-theoretic techniques in order to build the decision model, and (iii) realizing the decisionmaking engine in the adaptation manager. Modeling quality goals provides the adaptation manager with the knowledgebase required in making a systematic adaptation decision. The framework aims at exhibiting a plug-and-play capability to adapt game-theoretic techniques that suite security goals and requirements of the software. © 2017 IEEE.","Decision Making; Game Theory; Self-Protecting Software; Software Quality Goals","C (programming language); Computer software; Computer software selection and evaluation; Decision making; Decision theory; Engineering research; Managers; Software engineering; Adaptation decisions; Attack scenarios; Decision making models; Decision modeling; Decision-making frameworks; Self protecting; Software Quality; Software systems; Game theory",2-s2.0-85026768564
"Posner J., Fohry C.","Fault tolerance for cooperative lifeline-based global load balancing in Java with APGAS and Hazelcast",2017,"Proceedings - 2017 IEEE 31st International Parallel and Distributed Processing Symposium Workshops, IPDPSW 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028084033&doi=10.1109%2fIPDPSW.2017.31&partnerID=40&md5=2baeec8cade43de0477d9448ec543b3e","Fault tolerance is a major issue for parallel applications. Approaches on application-level are gaining increasing attention because they may be more efficient than system-level ones. In this paper, we present a generic reusable framework for fault-tolerant parallelization with the task pool pattern. Users of this framework can focus on coding sequential tasks for their problem, while respecting some framework contracts. The framework is written in Java and deploys the APGAS library as well as Hazelcast's distributed and fault-tolerant IMap. Our fault-tolerance scheme uses two system-wide maps, in which it stores, e.g., backups of local task pools. Framework users may configure the number of backup copies to control how many simultaneous failures are tolerated. The algorithm is correct in the sense that the computed result is the same as in non-failure case, or the program aborts with an error message. In experiments with up to 128 workers, we compared the framework's performance with that of a non-fault-tolerant variant during failure-free operation. For the UTS and BC benchmarks, the overhead was at most 35%. Measured values were similar as for a related, but less flexible fault-tolerant X10 framework, without a clear winner. Raising the number of backup copies to six only marginally improved the overhead. © 2017 IEEE.","APGAS; fault tolerance; Hazelcast; Java; load balancing; resiliency; task pool","Computer software reusability; Java programming language; Lakes; Network function virtualization; Resource allocation; APGAS; Hazelcast; Java; resiliency; task pool; Fault tolerance",2-s2.0-85028084033
"Wohlrab R.","Continuous management of design- and run-time artifacts for self-adaptive systems",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026734203&doi=10.1109%2fICSE-C.2017.31&partnerID=40&md5=74a8105cfe8333cd39287c5e3d3f4419","With the rise of smart and autonomous systems, self-adaptation plays a significant role in the capabilities of software-intensive systems. When developing and operating self-adaptive systems, a growing amount of information is required. This information forms the basis to systems' evolution and adaptation at run time, but is also used at design time to evolve and maintain the systems. To support development organizations in the future, efficient ways to manage information throughout the systems' lifecycle are needed. However, there is currently a lack of methods to continuously manage artifacts for self-adaptive systems. In our research, we aim to close this gap by developing methods and techniques to manage both design-time and run-time artifacts. We conduct empirical studies to identify practitioners' needs and challenges. Then we develop innovative solutions and technologies and evaluate them in practical scenarios. © 2017 IEEE.","Collaboration; Information management; Self-adaptive systems; Traceability","Adaptive systems; C (programming language); Continuous time systems; Life cycle; Software engineering; Amount of information; Autonomous systems; Collaboration; Innovative solutions; Manage information; Self-adaptive system; Software intensive systems; Traceability; Information management",2-s2.0-85026734203
"Kampmann A.","Local analysis for global inputs",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026743044&doi=10.1109%2fICSE-C.2017.32&partnerID=40&md5=10c46351e7ea143356dfa55738dc1eb9","Fuzz testing and symbolic test generation both face their own challenges. While symbolic testing has scalability issues, fuzzing cannot uncover faults which require carefully engineered inputs. In this paper I propose a combination of both approaches, compensating weaknesses of each approach with the strength of the other approach. I present my plans for evaluation, which include applications of the hybrid tool to programs which neither of the approaches can handle on its own. © 2017 IEEE.","Fuzzing; Hybrid; Symbolic execution; System testing; Test generation; Unit testing","Application programs; Software engineering; Fuzzing; Hybrid; Symbolic execution; System testing; Test generations; Unit testing; C (programming language)",2-s2.0-85026743044
"Vegas S.","Analyzing software engineering experiments: Everything you always wanted to know but were afraid to ask",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026733501&doi=10.1109%2fICSE-C.2017.160&partnerID=40&md5=27e2e6f69a23d9560730bcbae2487bde","Experimentation is a key issue in science and engineering. But it is one of software engineering's stumbling blocks. Quite a lot of experiments are run nowadays, but it is a risky business. Software engineering has some special features, leading to some experimentation issues being conceived of differently than in other disciplines. The aim of this technical briefing is to help participants to avoid common pitfalls when analyzing the results of software engineering experiments. The technical briefing is not intended as a data analysis course, because there is already plenty of literature on this subject. It reviews several key issues that we have identified in published software engineering experiments, and addresses them based on the knowledge acquired after 18 years running experiments. © 2017 IEEE.","Analysis of experiments; Controlled experiments; Software Engineering experimentation","C (programming language); Technical presentations; Controlled experiment; Key Issues; Risky business; Science and engineering; Software engineering experiments; Stumbling blocks; Software engineering",2-s2.0-85026733501
"Boehm B.W.","Software cost estimation meets software diversity",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026757600&doi=10.1109%2fICSE-C.2017.159&partnerID=40&md5=b6161afc4e893b7e41ef884c9b8b4e01","The previous goal of having a one-size-fits-all software cost (and schedule) estimation model is no longer achievable. Sources of wide variation in the nature of software development and evolution processes, products, properties, and personnel (PPPPs) require a variety of estimation models and methods best fitting their situations. This Technical Briefing will provide a short history of pattern-breaking changes in software estimation methods, a summary of the sources of variation in software PPPPs and their estimation implications, a summary of the types of estimation methods being widely used or emerging, a summary of the best estimation-types for the various PPPP-types, and a process for guiding an organization's choices of estimation methods as their PPPP-types evolve. © 2017 IEEE.","Cost estimation; Expert consensus; Function points; Schedule estimation; Software cost; Software diversity; Software effort; Software instructions; Story points","Cost estimating; Costs; Software design; Software engineering; Cost estimations; Expert consensus; Function point; Software cost; Software diversity; Software effort; Software instruction; Story points; C (programming language)",2-s2.0-85026757600
"Raza M., Faria J.P., Salazar R.","Helping software engineering students analyzing their performance data: Tool support in an educational environment",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026761449&doi=10.1109%2fICSE-C.2017.61&partnerID=40&md5=576d2a25ca09c5ad2810c317d0f76b82","Process PAIR is a novel tool for automating the performance analysis of software developers. Based on a performance model calibrated from the performance data of many developers, it automatically identifies and ranks potential performance problems and root causes of individual developers. We present the results of a controlled experiment involving 61 software engineering master students, half of whom used ProcessPAIR in a performance analysis assignment. The results show significant benefits in terms of students' satisfaction (average score of 4.78 out of 5 for ProcessPAIR users, against 3.81 for other users), quality of the analysis outcomes (average grades achieved of 88.1 out of 100 for ProcessPAIR users, against 82.5 for other users), and time required to do the analysis (average of 252 min for ProcessPAIR users, against 262 min for other users, but with much room for improvement). © 2017 IEEE.","Controlled experiment; Performance analysis; Personal Software Process; Software engineering education","C (programming language); Education; Education computing; Software engineering; Students; Controlled experiment; Educational environment; Performance analysis; Performance problems; Personal Software Process; Software developer; Software engineering students; Students' satisfaction; Quality control",2-s2.0-85026761449
"Mathew G., Agrawal A., Menzies T.","Trends in topics at SE conferences (1993-2013)",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026747250&doi=10.1109%2fICSE-C.2017.52&partnerID=40&md5=2e31a068e4e333b79e46a48391641431","Using topic modeling, we analyse the titles and abstracts of nearly 10,000 papers from 20 years published in 11 top-ranked Software Engineering(SE) conferences between 1993 to 2013. Seven topics are identified as the dominant themes in modern software engineering. We show that these topics are not static, rather, some of them are becoming decidedly less prominent over time (modeling) while others are become very prominent indeed (defect analysis). By clustering conferences according to the topics they publish, we identify four large groups of SE conferences, e.g. ASE, FSE and ICSE publish mostly the same work (exceptions: there are more program analysis results in FSE than in ASE or ICSE). Using these results, we offer numerous recommendations including how to plan an individual's research program, when to make or merge conferences, and how to encourage a broader range of topics at SE conferences. An extended version of this paper, that analyzes more conferences and papers, is available on https://goo.gl/mVdyfj. © 2017 IEEE.","Bibliometrics; Software Engineering; Text Mining; Topic Modeling","C (programming language); Data mining; Bibliometrics; Defect analysis; Extended versions; Large groups; Program analysis; Research programs; Text mining; Topic Modeling; Software engineering",2-s2.0-85026747250
"Chen C., Alfayez R., Srisopha K., Boehm B., Shi L.","Why is it important to measure maintainability and what are the best ways to do it?",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026754234&doi=10.1109%2fICSE-C.2017.75&partnerID=40&md5=8deff7fa9514ebad054f6d2e3735ebc4","Being highly maintainable is the key to reducing approximately 75% of most systems' life cycle costs. Software maintainability is defined as the ease with which a software system or a component can be modified, to correct faults, improve performance or other attributes, or adapt to a changed environment. There exist metrics that can help developers measure and analyze the maintainability level of a project objectively. Most of these metrics involve automated analysis of the code. In this extended abstract paper, we addressed the importance of understanding software maintainability, explored some of the best ways to measure maintainability and briefly described a comparison study we conducted between automated maintainability metrics and human-assessed maintainability metrics through a controlled experiment by performing change-request modifications on open source software (OSS) projects. © 2017 IEEE.",,"Computer software; Life cycle; Maintainability; Open source software; Open systems; Software engineering; Automated analysis; Comparison study; Controlled experiment; Extended abstracts; Improve performance; Open source software projects; Software maintainability; Software systems; C (programming language)",2-s2.0-85026754234
"Castellano E.","Quality attributes and preferences on the synthesis of reactive systems",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026773765&doi=10.1109%2fICSE-C.2017.48&partnerID=40&md5=dc4febde5c7abadaa17a74d2861f12fe","Given a model of the environment's behaviour, a set of system goals, and a set of controllable actions, the controller synthesis problem is to automatically generate a controller that only restricts controllable actions. Qualitative controller synthesis techniques yield controllers that guarantee achieving a given goal in the presence of an adversarial environment. However, synthesis produces one out of many possible solutions and no support for expressing preference over them is provided. Quantitative synthesis techniques are a natural way of optimising control with respect to preferences, however, they require quantitative modelling, which in many cases is not available, possible, or desired, and incur in high computational complexity. In this work, we aim to develop a qualitative preference framework for control problems. © 2017 IEEE.","Behavioural Models; Controller Synthesis; Preferences; Reactive Systems","C (programming language); Software engineering; Adversarial environments; Behavioural model; Control problems; Controller synthesis; Preferences; Quality attributes; Reactive system; Synthesis techniques; Controllers",2-s2.0-85026773765
"Song H., Chauvel F., Solberg A., Foyn B., Yates T.","How to support customisation on SaaS: A grounded theory from customisation consultants",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026736703&doi=10.1109%2fICSE-C.2017.136&partnerID=40&md5=937b1415138b792afdf5143236c9adb5","This paper reports the initial result of a qualitative research on how to support customisation of SaaS (Software as a Service). The research follows the grounded theory method, and investigates the expectation of consultants who are specialized in customising enterprise software systems. The resulting theory contributes to the understanding of how customisation on SaaS differs from the traditional one, and provides a high-level guidance for SaaS vendors to prepare effective support for customisation. © 2017 IEEE.","Grounded Theory; SaaS; Software Customisation","Enterprise software; Software as a service (SaaS); Software engineering; Customisation; Enterprise software systems; Grounded theory; Grounded theory methods; Qualitative research; SaaS; SaaS (software as a service); C (programming language)",2-s2.0-85026736703
"Goncalves R.Q., Von Wangenheim C.G.","DotProject+: Open-source software for project management education",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026745803&doi=10.1109%2fICSE-C.2017.128&partnerID=40&md5=e64079c1be16d9414a81f9c98c927145","Teaching the usage of Project Management (PM) tools is an important part of Software Engineering education. In this context, instructors often adopt some professional PM tool, such as MS-Project, GanttProject or dotProject. However, as such tools lack instructional features, some studies propose the adoption of educational PM tools. Yet, even these tools may be insufficient, due to their limited content coverage, and/or not support the learning of prominent professional PM tools. Attempting to improve this situation, this paper presents the enhancement of a professional open-source PM tool - dotProject - for educational purposes. The enhancements include the completion of the support for project initiating and planning, and the reorganization of the tool's interface to assist its adoption in the classroom. Results from applying the enhanced tool in a series of case studies in PM courses, indicate that dotProject+ contributes to the students' learning and facilitates the teaching of the usage of a PM tool in alignment with the PMBOK. © 2017 IEEE.","DotProject+; Learning; PM tool; PMBOK; Project management; Teaching","C (programming language); Education; Open systems; Professional aspects; Project management; Software engineering; Teaching; Case-studies; DotProject; Learning; MS-project; Open sources; PMBOK; Project management education; Open source software",2-s2.0-85026745803
"Omoronyia I.","Privacy engineering in dynamic settings",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026746034&doi=10.1109%2fICSE-C.2017.89&partnerID=40&md5=d0778a145785f2100ee87240559384f3","Modern distributed software platforms are linking smart objects such as smartphones, cars and health devices to the internet. A frequent challenge in the design of such platforms is determining the appropriate information disclosure protocol to use when one object interacts with another. For example, how can a software architect verify that when the platform constrains the sender to obtain consent from the subject before disclosure or notifying the subject after disclosure, then the privacy needs of the subject are addressed? To this end, this research presents an analysis framework for privacy engineering. We demonstrate how the framework's outputs can help software architects achieve privacy-by-design of software platforms for smart objects. © 2017 IEEE.",,"Software architecture; Software engineering; Analysis frameworks; Design of softwares; Distributed software; Dynamic settings; Information disclosure; Privacy engineerings; Smart objects; Software architects; C (programming language)",2-s2.0-85026746034
"Sarkar V., Grossman M., Budimlic Z., Imam S.","Preparing an online Java parallel computing course",2017,"Proceedings - 2017 IEEE 31st International Parallel and Distributed Processing Symposium Workshops, IPDPSW 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028059268&doi=10.1109%2fIPDPSW.2017.162&partnerID=40&md5=45d38c006a7f758f32aaa3f77fa94b93","While multi-core platforms are now ubiquitous in all areas of information technology, from enterprise software engineering to mobile app development, parallel computing education is still lagging behind the demand for skilled parallel programmers. At many universities today, parallel and concurrent computing is still not part of the core curriculum because of resistance to major curriculum changes. Many other universities lack the necessary educators or infrastructure to teach a comprehensive parallel computing course. Furthermore, even addressing these issues would do nothing towards supporting software professionals who have already entered the work force and have no plans to return to school. To address this broad need for a standalone, publically available, comprehensive, and easily accessible course on parallel computing, we have developed an online offering packaged as a Coursera Specialization on Parallel, Concurrent, and Distributing Computing in Java. In this paper, we describe the preparations for this online course and the unique challenges we encountered in terms of both curriculum development and technical infrastructure. We describe how lessons learned from an on-campus parallelism course at Rice University helped to shape the Coursera specialization, and summarize our experience with implementing this specialization on the Coursera platform at scale. © 2017 IEEE.","component; formatting; style; styling","Application programs; E-learning; Education; Engineering education; Enterprise software; Java programming language; Software engineering; Teaching; Ubiquitous computing; component; Curriculum development; Distributing computing; formatting; Multi-core platforms; style; styling; Technical infrastructure; Curricula",2-s2.0-85028059268
"Hung W.-L., Garg V.K.","Automatic-Signal Monitors with Multi-object Synchronization",2017,"Proceedings - 2017 IEEE 31st International Parallel and Distributed Processing Symposium, IPDPS 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027729362&doi=10.1109%2fIPDPS.2017.57&partnerID=40&md5=bd496029e2b730233f8b9d2e039f416f","Current monitor based systems have some disadvantages for multi-object operations. They require the programmers to (1) manually determine the order of locking operations, (2) manually determine the points of execution where threads should signal other threads, (3) use global locks or perform busy waiting for operations that depend upon a condition that spans multiple objects. Transactional memory systems eliminate the need for explicit locks, but do not support conditional synchronization. They also require the ability to rollback transactions. In this paper, we propose new monitor based methods that provide automatic signaling for global conditions that span multiple objects. Our system provides automatic notification for global conditions. Assuming that the global condition is a Boolean expression of local predicates, our method allows efficient monitoring of the conditions without any need for global locks. Furthermore, our system solves the monitor composition problem without requiring global locks. We have implemented our constructs on top of Java and have evaluated their overhead. Our results show that on most of the test cases, not only our code is simpler but also faster than Java's reentrant-lock as well as the Deuce transactional memory system. © 2017 IEEE.","automatic signal; concurrency; implicit signal; monitor; parallel; synchro-nization","Java programming language; Locks (fasteners); Storage allocation (computer); Automatic notification; Automatic signals; Boolean expressions; Composition problem; concurrency; Efficient monitoring; parallel; Transactional memory; Monitoring",2-s2.0-85027729362
"Lee G., Agiakatsikas D., Wu T., Cetin E., Diessel O.","TLegUp: A TMR code generation tool for SRAM-based FPGA applications using HLS",2017,"Proceedings - IEEE 25th Annual International Symposium on Field-Programmable Custom Computing Machines, FCCM 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027687054&doi=10.1109%2fFCCM.2017.57&partnerID=40&md5=8abc3f5b913f491f51d3fcb443e88e5a","We present TLegUp, an extension of LegUp, that automatically generates Triple Modular Redundant designs for FPGAs from C programs. TLegUp is expected to improve the productivity of application designers for space, to allow designers to experiment with alternative application partitioning, voter insertion and fault-tolerant aware scheduling and binding algorithms, and to support the automatic insertion of the infrastructure needed to run a fault-tolerant system. In this paper, we examine TLegUp's capacity to make use of both combinational and sequential voters by triplicating a design before scheduling and binding occur. In contrast, traditional RTL-based tools are constrained to use only combinational voters so as to preserve the scheduling and binding of the design, critical path lengths are consequently increased. We compare the use of sequential and combinational voters for a range of benchmarks implemented on a Xilinx Virtex-6 FPGA in terms of: (i) maximum operating frequency, (ii) latency, (iii) execution time, and (iv) soft-error sensitivity. Compared to the use of combinational voters, the use of sequential voters reduces the application execution time on the CHStone benchmark suite by 4% on average. © 2017 IEEE.","FPGA; HLS; TMR","Benchmarking; Bins; Computers; Fault tolerance; Field programmable gate arrays (FPGA); Integrated circuit design; Radiation hardening; Scheduling; Scheduling algorithms; Application execution; Application partitioning; Code generation tools; Critical path lengths; Fault tolerant systems; Maximum operating frequency; Scheduling and bindings; Triple modular redundant; C (programming language)",2-s2.0-85027687054
"Schroeder J., Berger C., Knauss A., Preenja H., Ali M., Staron M., Herpel T.","Comparison of model size predictors in practice",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026756134&doi=10.1109%2fICSE-C.2017.66&partnerID=40&md5=f10be4c83632773b5331d216bb1693c6","The amount of software in modern vehicles is constantly growing. However, the risk for functional and quality deficiencies increases simultaneously with size. This results in industry for example in inevitable and unexpected refactorings of software models, which is slowing down development processes in turn. In this industrial case study, we evaluate model growth predictors applied to foresee critical model size developments. We present five approaches and systematically compare them regarding prediction accuracy. © 2017 IEEE.",,"Software engineering; Comparison of models; Development process; Growth predictors; Industrial case study; Model size; Prediction accuracy; Refactorings; Software model; C (programming language)",2-s2.0-85026756134
"Linares-Vasquez M., Bernal-Cardenas C., Bavota G., Oliveto R., Di Penta M., Poshyvanyk D.","GEMMA: Multi-objective optimization of energy consumption of GUIs in android apps",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026730591&doi=10.1109%2fICSE-C.2017.10&partnerID=40&md5=84d0fe543c3cd2e6737aa9a3b805103e","This tool demonstration describes GEMMA, a tool aimed at optimizing the colors used by Android apps, with the goal of reducing the energy consumption on (AM)OLED displays while keeping the user interface visually attractive for end-users. GEMMA has been developed as a distributed architecture to ensure scalability. It is composed of a Web-based client and processing nodes that are capable of analyzing multiple requests (apps) concurrently. The underlying approach makes use of power models, color theory, and multi-objective genetic algorithms. The empirical evaluation of GEMMA indicated its ability to reduce energy consumption while producing color combinations pleasant enough for the users. Also, a qualitative analysis conducted with app developers highlighted the potential applicability of the tool in an industrial context.VIDEO: https://www.youtube.com/watch?v=k-5ReMVwK0c. © 2017 IEEE.",,"C (programming language); Color; Energy utilization; Genetic algorithms; HTTP; Multiobjective optimization; Software engineering; User interfaces; Color combination; Distributed architecture; Empirical evaluations; Multi-objective genetic algorithm; Processing nodes; Qualitative analysis; Reduce energy consumption; Tool demonstration; Android (operating system)",2-s2.0-85026730591
"Falcao R.","Elicitation of delightful context-aware features: Challenges and outlook extended abstract",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026788784&doi=10.1109%2fICSE-C.2017.23&partnerID=40&md5=724745903a7c2c6e7a753c7d24490944","Current requirements elicitation techniques do not deal with an essential part of context awareness: comprehension of the relationships among the numerous contextual elements of a certain domain and how they can positively influence the user task. As a result, solution providers continuously miss the opportunity to delight users by identifying contextual behaviors that will lead to better recommendations or adaptations. This paper discusses this problem and proposes a data-based solution. The expected scientific contributions of the ongoing research are delineated as well. © 2017 IEEE.","Context awareness; Context modeling; Requirements engineering; Software engineering","Requirements engineering; Software engineering; Context modeling; Context- awareness; Context-aware features; Contextual behavior; Contextual elements; Extended abstracts; Requirements elicitation techniques; Scientific contributions; C (programming language)",2-s2.0-85026788784
"Nakagawa H., Matsui S., Tsuchiya T.","A visualization of specification coverage based on document similarity",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026754663&doi=10.1109%2fICSE-C.2017.117&partnerID=40&md5=971a5b19448098c8b5d8444672dfadca","Code coverage is a metric used to represent how much code is tested when particular test cases are executed. As is code coverage, specification coverage is expected to help us to comprehend how much specification to be implemented is tested. In this study, we propose a visualization process for specification coverage. This process finds traceability links between specifications and test cases using a similarity metric and constructs two views for visualization. We develop a prototype tool for automatically executing the process and evaluate the process in a preliminary experiment on a web application development in industry. This extended abstract explains the overview of our study and the preliminary results. © 2017 IEEE.","Specification coverage; Testing; Traceability; Visualization","Codes (symbols); Flow visualization; Software engineering; Software prototyping; Software testing; Specifications; Testing; Visualization; Document similarity; Extended abstracts; Prototype tools; Similarity metrics; Traceability; Traceability links; Visualization process; Web application development; C (programming language)",2-s2.0-85026754663
"Khatami Z., Kaiser H., Ramanujam J.","Redesigning OP2 compiler to use HPX runtime asynchronous techniques",2017,"Proceedings - 2017 IEEE 31st International Parallel and Distributed Processing Symposium Workshops, IPDPSW 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028063737&doi=10.1109%2fIPDPSW.2017.14&partnerID=40&md5=6c9c25e0dd8d6b4df88eb58a75590264","Maximizing parallelism level in applications can be achieved by minimizing overheads due to load imbalances and waiting time due to memory latencies. Compiler optimization is one of the most effective solutions to tackle this problem. The compiler is able to detect the data dependencies in an application and is able to analyze the specific sections of code for parallelization potential. However, all of these techniques provided with a compiler are usually applied at compile time, so they rely on static analysis, which is insufficient for achieving maximum parallelism and producing desired application scalability. One solution to address this challenge is the use of runtime methods. This strategy can be implemented by delaying certain amount of code analysis to be done at runtime. In this research, we improve the parallel application performance generated by the OP2 compiler by leveraging HPX, a C++ runtime system, to provide runtime optimizations. These optimizations include asynchronous tasking, loop interleaving, dynamic chunk sizing, and data prefetching. The results of the research were evaluated using an Airfoil application which showed a 40-50% improvement in parallel performance. © 2017 IEEE.","Asynchronous Task Execution; Controlling Chunk Sizes; HPX; Interleaving Loops; OP2; Prefetching Data","Program compilers; Static analysis; Application scalability; Asynchronous task executions; Compiler optimizations; Controlling Chunk Sizes; Interleaving Loops; Parallelization potential; Prefetching; Runtime optimization; C++ (programming language)",2-s2.0-85028063737
"Li L., Li D., Bissyande T.F., Klein J., Le Traon Y., Lo D., Cavallaro L.","Understanding android app piggybacking",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026776815&doi=10.1109%2fICSE-C.2017.109&partnerID=40&md5=1c3b7af581e712afa2b278428236ca75","The Android packaging model offers adequate opportunities for attackers to inject malicious code into popular benign apps, attempting to develop new malicious apps that can then be easily spread to a large user base. Despite the fact that the literature has already presented a number of tools to detect piggybacked apps, there is still lacking a comprehensive investigation on the piggybacking processes. To fill this gap, in this work, we collect a large set of benign/piggybacked app pairs that can be taken as benchmark apps for further investigation. We manually look into these benchmark pairs for understanding the characteristics of piggybacking apps and eventually we report 20 interesting findings. We expect these findings to initiate new research directions such as practical and scalable piggybacked app detection, explainable malware detection, and malicious code location. © 2017 IEEE.",,"C (programming language); Malware; Software engineering; Large users; Malicious codes; Malware detection; Packaging models; Android (operating system)",2-s2.0-85026776815
"Martinez J., Ziadi T., Bissyande T.F., Klein J., Le Traon Y.","Bottom-up technologies for reuse: Automated extractive adoption of software product lines",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026748915&doi=10.1109%2fICSE-C.2017.15&partnerID=40&md5=226e5515121172e97c2dc2f9d8d6ec15","Adopting Software Product Line (SPL) engineering principles demands a high up-front investment. Bottom-Up Technologies for Reuse (BUT4Reuse) is a generic and extensible tool aimed to leverage existing similar software products in order to help in extractive SPL adoption. The envisioned users are 1) SPL adopters and 2) Integrators of techniques and algorithms to provide automation in SPL adoption activities. We present the methodology it implies for both types of users and we present the validation studies that were already conducted. BUT4Reuse tool and source code are publicly available under the EPL license. Website http://but4reuse.github.io Video: https://www.youtube.com/watch?v=pa62Yc9LWyk. © 2017 IEEE.","Extractive software product line adoption; Reverse engineering; Software product line engineering; Variability management","Computer software; Computer software reusability; Reverse engineering; Software design; Software engineering; Engineering principles; Software Product Line; Software product line engineerings; Software product lines; Software products; Source codes; Validation study; Variability management; C (programming language)",2-s2.0-85026748915
"Qiu R., Khurshid S., Pasareanu C.S., Yang G.","A synergistic approach for distributed symbolic execution using test ranges",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026779632&doi=10.1109%2fICSE-C.2017.116&partnerID=40&md5=7042ac21724686f4e947259d69b0066f","Symbolic execution is a systematic program analysis technique that has received a lot of attention in the research community. However, scaling symbolic execution continues to pose a major challenge. This paper introduces Synergise, a novel two-fold integration approach. One, it integrates distributed analysis and constraint re-use to enhance symbolic execution using feasible ranges, which allow sharing of constraint solving results among different workers without communicating or sharing potentially large constraint databases (as required traditionally). Two, it integrates complementary techniques for test input generation, e.g., search-based generation and symbolic execution, for creating higher quality tests using unexplored ranges, which allows symbolic execution to re-use tests created by another technique for effective distribution of exploration of previously unexplored paths. © 2017 IEEE.",,"Model checking; Software engineering; Complementary techniques; Constraint Databases; Distributed analysis; Effective distribution; Integration approach; Research communities; Symbolic execution; Systematic program; C (programming language)",2-s2.0-85026779632
"Hu E.-W., Su B., Wang J.","Software performance prediction at source level",2017,"Proceedings - 2017 15th IEEE/ACIS International Conference on Software Engineering Research, Management and Applications, SERA 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026636298&doi=10.1109%2fSERA.2017.7965736&partnerID=40&md5=8718049cba72c443d19a5fcaddb4c357","Performance prediction is critical in embedded system design for reducing the turnaround time of software. Using simulation to measure the performance of the whole source code is often too slow, particularly after the modification of the source code due to changes in problem specification. In this paper we present a comprehensive method that combines analytical modeling and statistical approach to predicting the performance of application software at source code level. We take samples from EEMBC and SMV benchmarks and gather the static attributes from the source code of those samples as our learning set. To determine the effectiveness of our new approach, we select several functions from PHY Benchmark as our testing set. We then apply multiple linear regression technique enhanced with the inclusion of new approaches by using the popular statistical tool SPSS23 to predict the performance of these functions. Comparing our predicted results with the actual measured values, the outcome is promising as the average relative error is within 20%. © 2017 IEEE.","Analytic model; Multiple linear regression; Performance prediction; Source code level","Analytical models; Codes (symbols); Computer programming languages; Embedded software; Engineering research; Forecasting; Linear regression; Software engineering; Statistical mechanics; Analytic modeling; Average relative error; Comprehensive method; Multiple linear regressions; Performance prediction; Problem specification; Source codes; Statistical approach; Application programs",2-s2.0-85026636298
"Guzman E., Ibrahim M., Glinz M.","Mining twitter messages for software evolution",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026776112&doi=10.1109%2fICSE-C.2017.65&partnerID=40&md5=ef26524b8614849d477b90c1ca4a0afa","Twitter is a widely used social network. Previous research showed that users engage in Twitter to communicate about software applications via short messages, referred to as tweets, and that some of these tweets are relevant for software evolution. However, a manual analysis is impractical due to the large number of tweets - in the range of thousands per day for popular apps. In this work we present ALERTme, an approach to automatically classify, group and rank tweets about software applications. We apply machine learning techniques for automatically classifying tweets requesting improvements, topic modeling for grouping semantically related tweets and a weighted function for ranking tweets according to their relevance for software evolution. We ran our approach on 68,108 tweets from three different software applications and compared the results against practitioners' assessments. Our results are promising and could help incorporate short, informal user feedback with social components into the software evolution process. © 2017 IEEE.","Software evolution; Text mining; User feedback","Application programs; Data mining; Learning systems; Social networking (online); Software engineering; Machine learning techniques; Social components; Software applications; Software Evolution; Software evolution process; Text mining; User feedback; Weighted function; C (programming language)",2-s2.0-85026776112
"Xu Z., Lin J., Matsuoka S.","Benchmarking SW26010 many-core processor",2017,"Proceedings - 2017 IEEE 31st International Parallel and Distributed Processing Symposium Workshops, IPDPSW 2017",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028068403&doi=10.1109%2fIPDPSW.2017.9&partnerID=40&md5=bd6a49d83fcb167d984bc1ed159ab554","Equipped with the Chinese home-grown SW26010 many-core processor, TaihuLight claims the top place in the TOP500 list released in June 2016. Although some large-scale applications have been successfully running on the supercomputer, few studies have been conducted to analyze the performance impact caused by the extreme memory-bound architecture design. To facilitate native in-depth optimizations and performance modeling, understanding the architecture and performance characteristics of SW26010 is essential. Therefore, we developed a suite of micro-benchmarks written in C/assembly and characterized the key architectural components: (1) the pipelines of computing processing elements; (2) the softwarecontrolled memory hierarchy; and (3) the lightweight onchip communication at register level. Our benchmark results indicate that the comprehensive optimizations from highlevel algorithm design to low-level instruction scheduling are required to achieve good performance on SW26010. © 2017 IEEE.","micro-benchmark; performance benchmarking; register-level communication; SW26010; TaihuLight","C (programming language); Distributed computer systems; Integrated circuit design; Memory architecture; Parallel processing systems; Pipeline processing systems; Supercomputers; Architectural components; Architecture and performance; Comprehensive optimizations; Large-scale applications; Micro-benchmark; Performance benchmarking; SW26010; TaihuLight; Benchmarking",2-s2.0-85028068403
"Loyola P., Matsuo Y.","Learning graph representations for defect prediction",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026781427&doi=10.1109%2fICSE-C.2017.68&partnerID=40&md5=5cf4f2e227d3a6f76fe196552721c144","We propose to study the impact of the representation of the data in defect prediction models. For this study, we focus on the use of developer activity data, from which we structure dependency graphs. Then, instead of manually generating features, such as network metrics, we propose a model inspired in recent advances in Representation Learning which are able to automatically learn representations from graph data. These new representations are compared against manually crafted features for defect prediction in real world software projects. © 2017 IEEE.","Defect Prediction; Representation learning","Defects; Forecasting; Software engineering; Defect prediction; Defect prediction models; Dependency graphs; Developer activities; Learning graphs; Network metrics; Representation learning; Software project; C (programming language)",2-s2.0-85026781427
"Gu T., Ma X., Xu C., Jiang Y., Cao C., Lu J.","Synthesizing object transformation for dynamic software updating",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026782164&doi=10.1109%2fICSE-C.2017.96&partnerID=40&md5=b3db6765b9b454b7c9ccd89641ad21c0","Dynamic software updating (DSU) can upgrade arunning program on-the-fly by directly replacing the in-memorycode and reusing existing runtime state (e.g., heap objects) forthe updated execution. Additionally, it is usually necessary totransform the runtime state into a proper new state to avoidinconsistencies that arise during runtime states reuse amongdifferent versions of a program. However, such transformationsmostly require human efforts, which is time-consuming anderror-prone. This paper presents AOTES, an approach to automatingobject transformations for dynamic updating of Javaprograms. AOTES tries to generate the new state by re-executinga method invocation history and leverages symbolic execution tosynthesize the history from the current object state without anyrecording. We evaluated AOTES on software updates taken fromApache Tomcat, Apache FTP Server and Apache SSHD Server. Experimental results show that AOTES successfully handled 47 of57 object transformations of 18 updated classes, while two state-of-the-artapproaches only handled 11 and 6 of 57, respectively. © 2017 IEEE.","Dynamic software updating; Execution synthesis; Inverse method generation; Symbolic execution","Computer software reusability; Inverse problems; Model checking; Software engineering; Dynamic software updating; Dynamic updating; Inverse methods; Method invocation; Object transformation; Run-time state; Software updates; Symbolic execution; C (programming language)",2-s2.0-85026782164
"Gao C., Man Y., Xu H., Zhu J., Zhou Y., Lyu M.R.","IntelliAd: Assisting mobile app developers in measuring ad costs automatically",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026755384&doi=10.1109%2fICSE-C.2017.123&partnerID=40&md5=748f1391e39a71bb53b8408035c0c298","In-app mobile advertising serves as a primary source of revenue for most free apps. Such apps are embedded with third-party SDKs for ads displaying and are monetized by user impressions. However, ad placement can sometimes spoil user experience, for example, by too much memory consumption and battery drainage, thus leading to app uninstalling and unfavorable user feedback. Therefore, ensuring user perceptions of mobile ads can be greatly beneficial to app developers. Furthermore, various ad networks and formats make ads selection a great challenge. To achieve this, we design a tool named IntelliAd to automatically measure the ads-related consumption on mobile phones. Based on the measured costs, developers can optimize the ad-embedding schemes for their apps. © 2017 IEEE.","Ad Costs; Automatic Measurement; Mobile Advertising","Costs; Marketing; Software engineering; Automatic measurements; Battery drainage; Memory consumption; Mobile advertising; Primary sources; User experience; User feedback; User perceptions; C (programming language)",2-s2.0-85026755384
"Tang C., Bagheri H., Paisarnsrisomsuk S., Sullivan K.","Towards designing effective data persistence through tradeoff space analysis",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026764257&doi=10.1109%2fICSE-C.2017.106&partnerID=40&md5=0bb56fce3cacd9b5be8c4b5eb25fd75a","Partial system specifications give rise to design spaces: sets of designs that satisfy specified constraints but that can vary in other dimensions, including non-functional properties such as performance. A tradespace is a design space where each design is paired with its relevant corresponding properties. Exploring tradespaces to find high-value designs is hard and time-consuming. The software engineering field provides inadequate support for tradespace exploration. In the context of object relational mapping (ORM), modern model-view-controller frameworks such as Django translate application-specific object models into relational database schemas with guarantees that they satisfy specified functional (data storage) requirements, however, these translators generally do not consider the range of possible schemas or the related performance tradeoffs. We present a novel approach using automated tradespace exploration to find schemas with optimal time and space tradeoffs. The engineer specifies an object model that defines objects and relationships. Our tool set then (1) synthesizes a design space of schemas for the object model, (2) profiles the time and space performance of each schema to generate the corresponding tradespace, and (3) analyzes the tradespace to identify designs on the optimal frontier, thus exposing essential tradeoffs. We achieve scalability of analysis through the use of the Spark MapReduce framework. In a set of experiments, our approach consistently found designs that were dramatically better than those produced by several widely used ORM tools. © 2017 IEEE.","Design space; Dynamic analysis; Experimental software engineering; Relational logic; Synthesis; Tradespace","Digital storage; Dynamic analysis; Software engineering; Specifications; Synthesis (chemical); Design spaces; Experimental software engineering; Non functional properties; Object-relational mapping; Relational logic; Time and space performance; Trade space explorations; Tradespace; C (programming language)",2-s2.0-85026764257
"Mols C.-E., Wnuk K.","Charting the market disruptive nature of open source: Experiences from sony mobile",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026759540&doi=10.1109%2fICSE-C.2017.110&partnerID=40&md5=bad559c6c079479a9fe6beb142352faa","Open Source Software (OSS) has substantial impact on how software-intensive firms develop products and deliver value to the customers. These companies need both strategic and operational support on how to adapt OSS as a part of their products and how to adjust processes and organizations to increase the benefits from OSS participation. This work presents the key insights from the journey that Sony Mobile has made from a company developing proprietary software to a respected member of OSS communities. We framed the experiences into an Open Source Maturity Model that includes two scenarios: engineering-driven and business-driven open source. We outline the most important decisions, roles, processes and implications. © 2017 IEEE.","Open Source Software; Software business; Software Ecosystems","C (programming language); Computer software; Open systems; Software engineering; Maturity model; Open sources; Proprietary software; Software business; Software ecosystems; Open source software",2-s2.0-85026759540
"Subramanian S., Berzish M., Tripp O., Ganesh V.","A solver for a theory of strings and bit-vectors",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026784835&doi=10.1109%2fICSE-C.2017.73&partnerID=40&md5=34b6670081b789b565e562b69c539866","We present the Z3strBV solver for a many-sorted first-order quantifier-free theory Tw, bv of string equations, string length represented as bit-vectors, and bit-vector arithmetic aimed at formal verification, automated testing, and security analysis of C/C++ applications. Our key motivation for building such a solver is the observation that existing string solvers are not efficient at modeling the combined theory over strings and bit-vectors. We demonstrate experimentally that Z3strBV is significantly more efficient than a reduction of string/bit-vector constraints to strings/natural numbers followed by a solver for strings/natural numbers or modeling strings as bit-vectors. We also propose two optimizations. First, we explore the concept of library-aware SMT solving, which fixes summaries in the SMT solver for string library functions such as strlen in C/C++. Z3strBV is able to consume these functions directly instead of re-analyzing the functions from scratch each time. Second, we experiment with a binary search heuristic that accelerates convergence on a consistent assignment of string lengths. We also show that Z3strBV is able to detect nontrivial overflows in real-world system-level code, as confirmed against seven security vulnerabilities from the CVE and Mozilla databases. © 2017 IEEE.","Automated reasoning; Program analysis; SMT solvers; String solvers; Vulnerability detection","Heuristic algorithms; Nonlinear equations; Software engineering; Vectors; Automated reasoning; Program analysis; Smt solvers; String solvers; Vulnerability detection; C (programming language)",2-s2.0-85026784835
"Pham L.H., Thi L.L.T., Sun J.","Assertion generation through active learning",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026728300&doi=10.1109%2fICSE-C.2017.87&partnerID=40&md5=fb420756358e9681d652a1c8c582bf1e","Program assertions are useful for many program analysis tasks. They are however often missing in practice. In this work, we develop a novel approach for generating likely assertions automatically based on active learning. Our target is complex Java programs which cannot be symbolically executed (yet). Our key idea is to generate candidate assertions based on test cases and then apply active learning techniques to iteratively improve them. The experiments show that active learning really helps to improve the generated assertions. © 2017 IEEE.","Active learning; Assertion generation; Testing","Artificial intelligence; Computer software; Iterative methods; Software engineering; Testing; Active Learning; Assertion generations; Java program; Program analysis; Test case; C (programming language)",2-s2.0-85026728300
"Bohme M., Soremekun E.O., Chattopadhyay S., Ugherughe E.J., Zeller A.","How developers debug software - The DBGBENCH dataset",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026736040&doi=10.1109%2fICSE-C.2017.94&partnerID=40&md5=46d782bb5a93daad1e244de0ca160b48","How do professional software engineers debug computer programs? In an experiment with 27 real bugs that existed in several widely used programs, we invited 12 professional software engineers, who together spent one month on localizing, explaining, and fixing these bugs. This did not only allow us to study the various tools and strategies used to debug the same set of errors. We could also determine exactly which statements a developer would localize as faults, how a developer would diagnose and explain an error, and how a developer would fix an error - all of which software engineering researchers seek to automate. Until now, it has been difficult to evaluate the effectiveness and utility of automated debugging techniques without a user study. We publish the collected data, called DBGBENCH, to facilitate the effective evaluation of automated fault localization, diagnosis, and repair techniques w.r.t. The judgement of human experts. © 2017 IEEE.","Bug Diagnosis; Debugging in Practice; Fault Localization; Software Repair; Tool Evaluation; User as Tool Benchmark","C (programming language); Errors; Fault detection; Program diagnostics; Repair; Software engineering; Automated debugging; Fault localization; Human expert; Professional software engineers; Repair techniques; Software repair; Tool evaluations; User study; Program debugging",2-s2.0-85026736040
"Vegas S., Riofrio P., Juristo N.","Does subject type influence software engineering experiment results?",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026741513&doi=10.1109%2fICSE-C.2017.113&partnerID=40&md5=96c4774d06a7a187aff0c9b465a36f75","Context: A key issue when dealing with the generalization threat of software engineering experiments is to use different subject types. Objective: In this paper, we aim to investigate which subject types are used in experiments and their impact on results. Method: We have performed a systematic mapping study by manually searching experiments published from January 2014 to June 2016 in six leading software engineering conferences and journals. Results: Out of the 833 papers published in the period covered, we have identified 93 papers reporting experiments with subjects. Of these, 27 papers report experiments that have two subject types (professionals and students). We have studied the impact of subject type on the results of experiments reported in 11 of these papers. Conclusion: We have observed contradictory results. Only in some cases subject type influences experimental results. This suggests that further research is needed in order to find an explanation. © 2017 IEEE.","Experimentation; Experiments with professionals; Experiments with subjects","C (programming language); Experimentation; Key Issues; Software engineering experiments; Systematic mapping studies; Software engineering",2-s2.0-85026741513
"Coppola R.","Fragility and evolution of android test suites",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026774126&doi=10.1109%2fICSE-C.2017.22&partnerID=40&md5=690503d4644dbfcc37b0a91a8b05b13b","In this paper a PhD research started in November 2015 is described. Its principal aims are an investigation of existing techniques and issues of GUI testing for Android applications, and a definition and exploration of the fragility problem for GUI test suites. The final outcomes of the work, whose end is forecasted for early 2019, will mainly be: (i) a study of the adoption of testing among open-source mobile applications, (ii) a characterization of the fragility issues and its causes, (iii) a set of metrics to evaluate the presence of fragility of existing projects: (iv) a set of best practices for developers to avoid testing fragilities for their scripted test suites. © 2017 IEEE.","GUI testing; Mobile applications; Software evolution; Testing","Android (operating system); Application programs; C (programming language); Graphical user interfaces; Mobile computing; Mobile telecommunication systems; Open source software; Software engineering; Testing; Android applications; Best practices; GUI testing; Mobile applications; Open sources; Software Evolution; Software testing",2-s2.0-85026774126
"Urica T., Simonova A., Kascak S.","Control design and simulation of continuous systems",2017,"Proceedings of the 2017 18th International Scientific Conference on Electric Power Engineering, EPE 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026673458&doi=10.1109%2fEPE.2017.7967263&partnerID=40&md5=28b39ad163115095002cac6afa17cca9","This paper deals with system analysis and control design. There are many ways to design a proper controller for a specific system. Usually, a good knowledge of a system dynamics is required to do so. The paper is mainly focused on the analytical method called pole placement. This method was implemented to the graphical user interface Dynamic systems created in the development software LabVIEW. © 2017 IEEE.","control design; LabVIEW; PID control; Pole placement; transfer function","Graphical user interfaces; Poles; Poles and zeros; Three term control systems; Transfer functions; User interfaces; Analysis and controls; Analytical method; Continuous system; Control design; LabViEW; Pole placement; Software LabVIEW; System Dynamics; Computer programming languages",2-s2.0-85026673458
"Xin Q.","Towards addressing the patch overfitting problem",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026740980&doi=10.1109%2fICSE-C.2017.42&partnerID=40&md5=1383e3ba64fa38edeb29f612323e5b4e","Current automatic program repair techniques often produce overfitting patches. Such a patch passes the test suite but does not actually repair the bug. In this paper, we propose two techniques to address the patch overfitting problem. First, we propose an automatic repair technique that performs syntactic code search to leverage bug-related code from a code database to produce patches that are likely to be correct. Due to the weak and incomplete program specification encoded in the test suite, a patch is still possible to be overfitting. We next propose a patch testing technique which generates test inputs uncovering the semantic differences between a patch and its original faulty program, tests if the patch is overfitting, and if so, generates test cases. Such overfitting-indicative test cases could be added to the test suite to make it stronger. © 2017 IEEE.","Automatic program repair; Patch overfitting; Patch testing","Codes (symbols); Repair; Semantics; Software engineering; Software testing; Automatic programs; Code database; Over fitting problem; Overfitting; Patch testing; Program specification; Repair techniques; Semantic difference; C (programming language)",2-s2.0-85026740980
"Emami-Taba M.","Decision-making in self-protecting software systems: A game-theoretic approach",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026746577&doi=10.1109%2fICSE-C.2017.155&partnerID=40&md5=255bc64600dd7463513c8768fab57604","Dynamic strategies used by attackers to break down the software system calls for dynamic countermeasure selection techniques. A significant challenge in engineering self-proctoring software system is selecting a proper countermeasure while the software systems undergoes a well-planned attack. To address this challenge, in this research work, we model the interactions between the attacker and the software system as a two-player game. Modeling such interaction using game theory enables the decision-making engine to model the strategies of the attackers while considers the effect of possible defense strategies in a dynamic attack scenario. In this research work, we aim at engineering a novel decision-making framework that utilizes game theoretic techniques to select the proper mitigation against an attack. The introduced framework consists of three high-level phases including: modeling quality goal, designing game-theoretic techniques, and realizing the decision-making engine. The first phase models the security goals of the system and maps goal-oriented model to the designed game-theoretic technique. Such goal model makes the decision-making engine capable of tracking the satisfaction of modeled goals before and after applying a mitigation strategy. The framework provides the steps to map the goal-oriented model to any game-theoretic techniques that is suitable to model the countermeasure selection. © 2017 IEEE.","Decision Making; Game Theory; Self-Protecting Software; Software Quality Goals","C (programming language); Computer software; Computer software selection and evaluation; Decision theory; Engineering research; Engines; Game theory; Software engineering; Attack scenarios; Decision-making frameworks; Dynamic strategies; Goal oriented modeling; Mitigation strategy; Selection techniques; Self protecting; Software Quality; Decision making",2-s2.0-85026746577
"Cito J., Oliveira F., Leitner P., Nagpurkar P., Gall H.C.","Context-based analytics - Establishing explicit links between runtime traces and source code",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering: Software Engineering in Practice Track, ICSE-SEIP 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026838215&doi=10.1109%2fICSE-SEIP.2017.1&partnerID=40&md5=2ed050ae63bb13cc87002001bfae69ec","Diagnosing problems in large-scale, distributed applications runningin cloud environments requires investigating different sources ofinformation to reason about application state at any given time. Typical sources of information available to developers and operatorsinclude log statements and other runtime information collectedby monitors, such as application and system metrics. Just as importantly, developers rely on information related to changes to the source code andconfiguration files (program code) when troubleshooting. This information is generally scattered, and it is up to the troubleshooterto inspect multiple implicitly-connected fragments thereof. Currently, different tools need to be used in conjunction, e.g., logaggregation tools, source-code management tools, and runtime-metricdashboards, each requiring different data sources and workflows. Notsurprisingly, diagnosing problems is a difficult proposition. In this paper, we propose Context-Based Analytics, an approach that makes the links between runtime informationand program-code fragments explicit by constructing a graph based on anapplication-context model. Implicit connections between informationfragments are explicitly represented as edges in the graph. We designeda framework for expressing application-context models and implemented a prototype. Further, we instantiated our prototype framework with an application-contextmodel for two real cloud applications, one from IBM and another from a major telecommunications provider. We applied context-based analytics to diagnose twoissues taken from the issue tracker of the IBM application and foundthat our approach reduced the effort of diagnosing these issues. In particular, context-based analytics decreased the number of required analysis steps by 48% and the number ofneeded inspected traces by 40% on average as compared to a standard diagnosis approach. © 2017 IEEE.","DevOps; Runtime Information; Software Analytics","Codes (symbols); Computer programming languages; Graphic methods; Application contexts; Cloud applications; Cloud environments; DevOps; Distributed applications; Run-time information; Sources of informations; Telecommunications providers; Software engineering",2-s2.0-85026838215
"Graziotin D., Fagerholm F., Wang X., Abrahamsson P.","Unhappy developers: Bad for themselves, bad for process, and bad for software product",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025817929&doi=10.1109%2fICSE-C.2017.104&partnerID=40&md5=1af8beb596d73bd2eb231764ec547703","Recent research in software engineering supports the 'happy-productive' thesis, and the desire of flourishing happiness among programmers is often expressed by industry practitioners. Recent literature has suggested that a cost-effective way to foster happiness and productivity among workers could be to limit unhappiness of developers due to its negative impact. However, possible negative effects of unhappiness are still largely unknown in the software development context. In this paper, we present the first results from a study exploring the consequences of the unhappy developers. Using qualitative data analysis of the survey responses given by 181 participants, we identified 49 potential consequences of unhappiness while developing software. These results have several implications. While raising the awareness of the role of moods, emotions and feelings in software development, we foresee that our classification scheme will spawn new happiness studies linking causes and effects, and it can act as a guideline for developers and managers to foster happiness at work. © 2017 IEEE.","Affect; Behavioral software engineering; Developer experience; Emotion; Human aspects; Mood","Cost effectiveness; Software design; Software engineering; Surveys; Affect; Developer experience; Emotion; Human aspects; Mood; C (programming language)",2-s2.0-85025817929
"Neto V.V.G.","A model-based approach towards the building of trustworthy software-intensive systems-of-systems",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026743160&doi=10.1109%2fICSE-C.2017.28&partnerID=40&md5=37ba6511ed9bc51969883fd7c99efb2e","Software-Intensive Systems-of-Systems (SoS) are an arrangement of interoperable systems called constituents joined together to accomplish a set of missions. They often support critical domains, such as emergency and crisis management and healthcare systems. In this sense, SoS must be trustworthy, that is, they must not fail, since they exhibit a substantial potential to cause damage and threats to human lives. In this direction, it is paramount to perform validation and verification (V&V) activities. These activities can assure that the final SoS performs its operation conforming to its specification and in a correct form, with no fails. However, SoS exhibit further complexity to the conduction of V&V, especially due to their dynamic properties (emergent behaviors and dynamic architectures), and due to the fact that constituents are not necessarily known at design-time. Thus, novel approaches are required to make SoS trustworthy. In this direction, this paper presents the research status of an ongoing PhD project that contributes to the software engineering and trustworthiness of this type of software. © 2017 IEEE.","Model-based; Systems-of-systems; Trustworthy; Validation; Verification","Interoperability; Software engineering; System of systems; Systems engineering; Verification; Interoperable systems; Model-based OPC; Software intensive systems; Systems of systems; Trustworthy; Trustworthy softwares; Validation; Validation and verification; C (programming language)",2-s2.0-85026743160
"Gazman A., Bahadori M., Zhu Z., Bergman K.","Programmable optical power distribution in silicon photonic platform",2017,"6th IEEE Photonics Society Optical Interconnects Conference, OI 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026752131&doi=10.1109%2fOIC.2017.7965511&partnerID=40&md5=f27b589e497130eaf5cb16ce539611f8","We demonstrate a reconfigurable, software-controlled, C-band optical power distribution system leveraging a 1×7 cascaded microring-based silicon photonic device. The thermo-optic effect and the spectral response of each ring is characterized and utilized in FPGA-based control plane algorithm to achieve precise power distribution profiles. © 2017 IEEE.",,"C (programming language); Optical interconnects; Photonics; Fpga based controls; Optical power distribution; Power distributions; Reconfigurable; Silicon photonic devices; Silicon photonics; Spectral response; Thermooptic effects; Photonic devices",2-s2.0-85026752131
"Dittrich Y., Vaidyanathan L., Gonsalves T.A., Jhunjhunwala A.","Developing E-banking services for rural India: Making use of socio-technical prototypes",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026770639&doi=10.1109%2fICSE-C.2017.55&partnerID=40&md5=f34ac814107c44f50a987d08be5d684b","Information and Communication Technology (ICT) is one of the key enablers for including underserved communities in economic and societal development across the world. Our research analyzes several banking service projects developing technical solutions for rural India. This poster presents an experience report based on systematic debriefing of involved project leaders and initiators, triangulated with additional documentation. The concept of Socio-Technical Prototype is developed and used to show how to mitigate the challenges of ICT based banking service provision for socially constrained communities. The concept of Socio-Technical Prototype extends the notion of prototypes, as it implies a full functioning implementation of the service including all relevant stakeholders. In order to not only prototype end-user functionality but also the interaction of the solution with the specific social, technical and physical environment. The implications for software engineering in the development of such large-scale prototypes and pilots are outlined. © 2017 IEEE.","ICT for Development; India; Iterative Development; Participatory Design; TeNeT","C (programming language); Economic and social effects; Rural areas; Software engineering; ICT for Development; India; Iterative development; Participatory design; TeNeT; Software prototyping",2-s2.0-85026770639
"Conoscenti M., Vetro A., De Martin J.C.","Peer to peer for privacy and decentralization in the internet of things",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026740886&doi=10.1109%2fICSE-C.2017.60&partnerID=40&md5=a07096424e945b52be9d1dddd852d940","In the Internet of Things (IoT) era new connected devices will spread highly sensitive personal data. Sending this type of data to centralized companies represents a serious risk for people's privacy, since economical or political interests could lead to an illegitimate use of personal information (as shown by Snowden's revelations). With the purpose of overcoming such status-quo, our research goal is to develop software systems according to the notion of decentralized private-by-design IoT. The basic idea is that data produced by personal IoT devices are safely stored in a distributed system whose design guarantees privacy, leaving to the people-the real data owners-the decision of which of them to share and with whom. To achieve this goal, a possible solution is to leverage the use of Peer-to-Peer storage networks in combination with the blockchain. However, such architecture, despite promising, embeds still limitations, especially in terms of scalability. In this paper we discuss our research motivation, we describe our research idea applied in a possible scenario and we present the scalability problem. © 2017 IEEE.","Blockchain; Internet of things; Peer to peer; Privacy","C (programming language); Data privacy; Digital storage; Peer to peer networks; Scalability; Software engineering; Block-chain; Distributed systems; Internet of thing (IOT); Peer to peer; Peer to peer storage networks; Personal information; Research motivations; Scalability problems; Internet of things",2-s2.0-85026740886
"Scoccia G.L., Malavolta I., Autili M., Di Salle A., Inverardi P.","User-centric android flexible permissions",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026774708&doi=10.1109%2fICSE-C.2017.84&partnerID=40&md5=69c2448ebf2e05de7a452b9640a64ec6","Privacy in mobile apps is a fundamental aspect to be considered, particularly with regard to meeting end user expectations. Due to the rigidities of the Android permission model, desirable trade-offs are not allowed. End users are confined into a secondary role, having the only option of choosing between either privacy or functionalities. This work proposes a user-centric approach to the flexible management of Android permissions that empowers end users to specify the desired level of permissions on a per-feature basis. © 2017 IEEE.","Android Permissions; Mobile Apps; Privacy","C (programming language); Data privacy; Economic and social effects; Software engineering; Android Permissions; End users; Flexible management; Mobile apps; Trade off; User-centric; Android (operating system)",2-s2.0-85026774708
"Ghaisas S., Sainani A., Anish P.R., Suriyanarayanan R., Rajaram P.","Ethos, pathos, and logos to prevent sexual harassment at workplaces: A regulatory solution based on operant conditioning",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026729984&doi=10.1109%2fICSE-C.2017.131&partnerID=40&md5=793eab60f60342db57838ec375ba8a1b","Sexual harassment at workplace has been a criticalchallenge for women, especially in the service sector due to oddworking hours. Companies and Government on their part havetaken up measures to protect women employees but theproblem seems persistent. To address this, we have designed aregulatory solution based on operant conditioning. Operantconditioning argues that people's behaviors are primarilycontrolled by consequences. It is therefore possible to appeal totheir ethics (Ethos), emotions (Pathos) and logic (Logos) andshape their behavior for preventing harassment at workplace. © 2017 IEEE.","Ethos; Logos; Operant conditioning; Pathos; Regulations; Sexual harassment","Laws and legislation; Software engineering; Ethos; Logos; Operant conditioning; Pathos; Regulations; Sexual harassment; C (programming language)",2-s2.0-85026729984
"Goyal A.","Effective bug triage for non-reproducible bugs",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026754973&doi=10.1109%2fICSE-C.2017.41&partnerID=40&md5=477731d43b8bf8da9dc5af7608bd4cfb","The objective of this research work is to develop a proficient recommender system for effective bug triaging. To build this we initiated with introducing a novel time based model, Visheshagya, for bug report assignment. Subsequently, we propose a novel AHP based bug assignment approach, W8Prioritizer, based on bug parameter prioritization. We further extend our work for triaging Non-reproducible (NR) bugs, the bugs for which the developer faces difficulty in reproducing. However, certain fraction of these bugs gets fixed later. We propose a novel prediction model, NRFixer to predict the fixability of bug reports marked as NR. In the future, we plan to work on bug report assignment for fixable NR bugs using Visheshagya and W8Prioritizer. Overall our initial results are encouraging and shows the possibility of making a robust recommender system for effective bug report assignment for both reproducible (R) and NR bugs. © 2017 IEEE.","Bug Triaging; Mining Software Repositories; Non-Reproducible Bugs; Recommender Systems","C (programming language); Engineering research; Recommender systems; Software engineering; Bug reports; Bug Triaging; Mining software repositories; Non-Reproducible Bugs; Prediction model; Prioritization; Time based; Program debugging",2-s2.0-85026754973
"Ciccozzi F., Di Ruscio D., Malavolta I., Pelliccione P., Tumova J.","Engineering the software of robotic systems",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026768493&doi=10.1109%2fICSE-C.2017.167&partnerID=40&md5=0c6222e8bf9df976f12d587a18852ad0","The production of software for robotic systems is often case-specific, without fully following established engineering approaches. Systematic approaches, methods, models, and tools are pivotal for the creation of robotic systems for real-world applications and turn-key solutions. Well-defined (software) engineering approaches are considered the 'make or break' factor in the development of complex robotic systems. The shift towards well-defined engineering approaches will stimulate component supply-chains and significantly reshape the robotics marketplace. The goal of this technical briefing is to provide an overview on the state of the art and practice concerning solutions and open challenges in the engineering of software required to develop and manage robotic systems. Model-Driven Engineering (MDE) is discussed as a promising technology to raise the level of abstraction, promote reuse, facilitate integration, boost automation and promote early analysis in such a complex domain. © 2017 IEEE.","Model-Driven Engineering; Robotics; Software Engineering","Robotics; Software engineering; Supply chains; Complex domains; Component supply chain; Level of abstraction; Model-driven Engineering; Real-world; Robotic systems; State of the art; Turn-key; C (programming language)",2-s2.0-85026768493
"James T., Galster M., Blincoe K., Miller G.","What is the perception of female and male software professionals on performance, team dynamics and job satisfaction? Insights from the trenches",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering: Software Engineering in Practice Track, ICSE-SEIP 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026799522&doi=10.1109%2fICSE-SEIP.2017.31&partnerID=40&md5=3b9f6a919e0f7a4e25cd8e868c7a5d07","Research has shown that gender diversity correlates positively with innovation and productivity in many professional engineering and technology domains. Yet, software development teams are dominated by males. In this paper, we aim at understanding whether female software professionals, compared to male, have different perceptions on a) team performance and dynamics, b) their own personal performance, c) their immediate supervisors, and d) accomplishment, recognition, and opportunities. Understanding perceptions of different genders can help software professionals, their supervisors and those responsible for staff create and foster environments in which both females and males are comfortable and perform best. To achieve this aim, we conducted a survey targeted at individual software professionals in technical roles. We collected and analyzed data from 55 female and 69 male respondents. Our results show basic differences in demographics (e.g., males tend to be older, have more senior roles, and have longer tenure with their employer). While we did find some differences around perceptions of spirit of team work, productivity, sense of satisfaction and fairness of reviews from supervisors, in general, females and males do not seem to differ significantly in their perceptions. Based on the results from our survey and insights from the current literature, we discuss commonalities and differences between females and males, and explore potential implications for performance reviews, recognition, and career progression. © 2017 IEEE.","descriptive survey; diversity; female and male software professionals; perceptions; software development teams","C (programming language); Job satisfaction; Productivity; Sensory perception; Software engineering; Supervisory personnel; Surveys; Career progression; diversity; female and male software professionals; Gender diversity; Performance reviews; Personal performance; Professional engineerings; Software development teams; Software design",2-s2.0-85026799522
"Rouf Y., Shtern M., Fokaefs M., Litoiu M.","A hierarchical architecture for distributed security control of large scale systems",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026782553&doi=10.1109%2fICSE-C.2017.64&partnerID=40&md5=3408f73e6569123ec0870cdfac234e03","In the era of Big Data, software systems can be affected by its growing complexity, both with respect to functional and non-functional requirements. As more and more people use software applications over the web, the ability to recognize if some of this traffic is malicious or legitimate is a challenge. The traffic load of security controllers, as well as the complexity of security rules to detect attacks can grow to levels where current solutions may not suffice. In this work, we propose a hierarchical distributed architecture for security control in order to partition responsibility and workload among many security controllers. In addition, our architecture proposes a more simplified way of defining security rules to allow security to be enforced on an operational level, rather than a development level. © 2017 IEEE.","Cloud computing; Ddos; Security control","Application programs; Big data; Cloud computing; Controllers; Hierarchical systems; Large scale systems; Software engineering; Ddos; Distributed architecture; Distributed security; Hierarchical architectures; Non-functional requirements; Operational level; Security controls; Software applications; C (programming language)",2-s2.0-85026782553
"Lima C.","Product line architecture recovery: An approach proposal (extended abstract)",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026732672&doi=10.1109%2fICSE-C.2017.38&partnerID=40&md5=daac6c1d11f6e8d5846239de604d245e","The Product Line Architecture (PLA) is an important asset for the success of Software Product Line (SPL) projects. Due to the complexity of managing the architectural variability, maintain the PLA up-to-date and synchronized with the project source code is a hard problem. The systematic use of Software Architecture Recovery (SAR) techniques enables the PLA recovery and keeps the PLA aligned with the development. In this context, we present our initial proposal that consists of an approach to recover PLAs based on the use of (bottom-up) SAR techniques. We performed some studies (such as surveys, literature reviews, and exploratory studies) to investigate the relationship between SAR and PLA to identify gaps and define the research area state-of-the-art. The combination of SAR and PLA is an important strategy to address some issues of PLA design. We identified that few studies address architectural variability, PLA variability traceability, and empirical evaluation such as experiments, surveys, mixed-methods, and so on. © 2017 IEEE.","Product Line Architecture; Software architecture; Software Product Line","Computer software; Recovery; Software architecture; Software engineering; Surveys; Architectural variability; Empirical evaluations; Exploratory studies; Extended abstracts; Product line architecture; Software architecture recovery; Software Product Line; Software product lines; C (programming language)",2-s2.0-85026732672
"Yan W., Yuanyuan X., Zhe Y., Zhili G.","Ammonia injection controller in SCR-DeNOx system for marine diesel engines based on ARMAX and MPC",2017,"Proceedings - 2017 32nd Youth Academic Annual Conference of Chinese Association of Automation, YAC 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026891615&doi=10.1109%2fYAC.2017.7967552&partnerID=40&md5=ecc5f1eb393fc5b7a2a7fcedfc12519b","To comply with more stringent nitrogen oxides (NOx) emission standard Tier III, which was issued by the International Maritime Organization (IMO), shipping industry has been exploring effective measures for NOx emission reduction. Selective catalyst reduction (SCR) is widely used for its simultaneously achieving high NOx conversion efficiency and low ammonia slip. In this paper, a SCR denitrification (SCR-DeNOx) system for a certain marine diesel engine (MAN6S50MC-C) is used as the research object. A mechanism model is established for the SCR-DeNOx system and then a model of the ammonia injection control sub-system is identified. Based on the identified model, an ammonia injection controller is proposed in this paper, where model predictive control (MPC) strategy is used with the aim of increasing the robustness and reducing secondary pollution of the system. Simulation results show that the denitrification rate of the proposed MPC is increased by 5.66% while the ammonia slip is decreased by 25.6204ppm, compared with the traditional PID controller. It is a certain theoretical guiding significance for energy conservation and pollution reduction in the actual SCR-DeNOx system. © 2017 IEEE.","Marine diesel engine; Model identification; Model predictive control (MPC); Selective catalyst reduction (SCR)","Ammonia; C (programming language); Catalysts; Controllers; Denitrification; Emission control; Engines; Marine engines; Model predictive control; Nitrogen oxides; Pollution; Pollution control; Predictive control systems; Three term control systems; Denitrification rate; Guiding significances; International maritime organizations; Marine Diesel Engines; Model identification; SCR denitrifications; Secondary pollution; Selective catalyst reduction; Diesel engines",2-s2.0-85026891615
"Cornejo O.","Flexible in-the-field monitoring",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026740806&doi=10.1109%2fICSE-C.2017.37&partnerID=40&md5=b4b1e352a2751935092adc2010e07a3e","Fully assessing the robustness of a software application in-house is infeasible, especially considering the huge variety of hardly predictable stimuli, environments, and configurations that applications must handle in the field. For this reason, modern testing and analysis techniques can often process data extracted from the field, such as crash reports and profile data, or can even be executed directly in the field, for instance to diagnose and correct problems. In all these cases, collection, processing, and distribution of field data must be done seamlessly and unobstrusively while users interact with their applications. To limit the intrusiveness of in-the-field monitoring a common approach is to reduce the amount of collected data (e.g., to rare events and to crash dumps), which, however, may severely affect the effectiveness of the techniques that exploit field data. The objective of this Ph.D. thesis is to define solutions for collecting field data in a cost effective way without affecting the quality of the user experience. This result can enable a new range of testing and analysis solutions that extensively exploit field data. © 2017 IEEE.","Dynamic analysis; Monitoring; User experience","Application programs; Cost effectiveness; Dynamic analysis; Monitoring; Software engineering; User interfaces; Analysis solution; Analysis techniques; Cost effective; Field monitoring; Process data; Profile data; Software applications; User experience; C (programming language)",2-s2.0-85026740806
"Hoschele M., Zeller A.","Mining input grammars with AUTOGRAM",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026741442&doi=10.1109%2fICSE-C.2017.14&partnerID=40&md5=c82d7324733cd051625a5e2b83df555e","Knowledge about how a program processes its inputs can help to understand the structure of the input as well as the structure of the program. In a JSON value like [1, true, 'Alice'], for instance the integer value 1, the boolean value true and the string value 'Alice' would be handled by different functions or stored in different variables. Our AUTOGRAM tool uses dynamic tainting to trace the data flow of each input character for a set of sample inputs and identifies syntactical entities by grouping input fragments that are handled by the same functions. The resulting context-free grammar reflects the structure of valid inputs and can be used for reverse engineering of formats and can serve as direct input for test generators. A video demonstrating AUTOGRAM is available at https://youtu.be/Iqym60iWBBk. © 2017 IEEE.","Context-free grammars; Dynamic tainting; Fuzzing; Input formats","Context free grammars; Reverse engineering; Software engineering; Boolean values; Data flow; Dynamic tainting; Fuzzing; Input format; Integer values; Tool use; C (programming language)",2-s2.0-85026741442
"Soremekun E.O.","Debugging with probabilistic event structures",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026760060&doi=10.1109%2fICSE-C.2017.34&partnerID=40&md5=4d44568b2d825749fba0ace23e2db8d0","Debugging is a search process to find, understand and fix the root cause of software defects. Can debugging benefit from probabilistic information? We hypothesize that debugging activities can benefit from probabilistic information that capturethe statistical dependence of program features and the minorvariations of program behavior. This probabilistic informationhelps to guide the search for the root cause of the bug andprovides detailed diagnostic information (such as failure-inducinginputs and method calls leading to the fault). To realize ourhypothesis, we propose to improve debugging activities by guiding bug diagnosis using both probabilistic reasoning and program analysis. The main idea is to mine probabilistic information from program executions, then apply these information to construct probabilistic event structures (e.g. probabilistic call graphs) that guides debugging activities such as fault localization and comprehension. The resulting probabilistic model will guide bug diagnosis towards the most likely paths to the root cause of bugs and provide contextual diagnostic information. © 2017 IEEE.","Bug Diagnosis; Debugging; Dependencies; Fault Localization; Probabilities; Slices; Statistical Debugging","C (programming language); Computer debugging; Probability; Program diagnostics; Software engineering; Dependencies; Fault localization; Probabilistic information; Probabilistic modeling; Probabilistic reasoning; Slices; Statistical debugging; Statistical dependence; Program debugging",2-s2.0-85026760060
"Kokaly S.","Managing assurance cases in model based software systems",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026787244&doi=10.1109%2fICSE-C.2017.44&partnerID=40&md5=3087875920e355ee08451b8c9be86a6b","Software has emerged as a significant part of many domains, including financial service platforms, social networks and vehicle control. Standards organizations have responded to this by creating regulations to address issues such as safety and privacy. In this context, compliance of software with standards has emerged as a key issue. For software development organizations, compliance is a complex and costly goal to achieve and is often accomplished by producing so-called assurance cases, which demonstrate that the system indeed satisfies the property imposed by a standard (e.g., safety, privacy, security). As systems and standards undergo evolution for a variety of reasons, maintaining assurance cases multiplies the effort. In this work, we propose to exploit the connection between the field of model management and the problem of compliance management and propose methods that use model management techniques to address compliance scenarios such as assurance case evolution and reuse. For validation, we ground our approaches on the automotive domain and the ISO 26262 standard for functional safety of road vehicles. © 2017 IEEE.","Assurance cases; Co-evolution; Impact assessment; Model management; Regulatory compliance; Reuse","C (programming language); Control system synthesis; Safety engineering; Social sciences computing; Software design; Software engineering; Standards; Assurance case; Co-evolution; Impact assessments; Model management; Reuse; Regulatory compliance",2-s2.0-85026787244
"Zhong H., Meng N.","An empirical study on using hints from past fixes",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026755401&doi=10.1109%2fICSE-C.2017.88&partnerID=40&md5=e56812c9b9192ba1782ebbd39b3064e8","With the usage of version control systems, many bugfixes have accumulated over the years. Researchers have proposedvarious approaches that reuse past fixes to fix new bugs. However, some fundamental questions, such as how new bug fixes can beconstructed from old fixes, have not been investigated. When anapproach reuses past fixes to fix a new bug, the new bug fixshould overlap with past fixes in terms of code structures and/orcode names. Based on this intuition, we systematically design sixoverlap metrics, and conduct an empirical study on 5,735 bugfixes to investigate the usefulness of past fixes. For each bug fix, we create delta dependency graphs, and identify how bug fixesoverlap with each other by detecting isomorphic subgraphs. Ourresults show Besides that above two major findings, we haveadditional ten findings, which can deepen the understanding onautomatic program repair. © 2017 IEEE.","Automatic program repair; Empirical study; Reusing bug fixes","Costs; Repair; Software engineering; Automatic programs; Bug fixes; Code structure; Dependency graphs; Empirical studies; Isomorphic subgraphs; Version control system; C (programming language)",2-s2.0-85026755401
"Marquez G., Astudillo H.","Selection of software components from business objectives scenarios through architectural tactics",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026727210&doi=10.1109%2fICSE-C.2017.35&partnerID=40&md5=6403c2022867ce1adf86dee54b0cf1c1","The architecture of a software system is result of architectural design decisions, where architects select among alternatives (architectural tactics) and software components when a stakeholders business objective is demanded. However, thereis not evidence of framework that conducts the appropriateselection of software components using architectural tactics. In this paper we present a PhD research proposal that describes a framework to obtain software components from business goal scenarios using architectural tactics supported by semantic recommendation systems. The expected results of this research is a technique and tool to acquire assemblies of software components that are more accurate in a certain context at the moment to propose solutions to the software architect in order to improve design decisions. © 2017 IEEE.","Architectural tactics; Semantic Recommender Systems; Software architecture; Software component","Recommender systems; Semantics; Software architecture; Software engineering; Architectural design decisions; Architectural tactics; Business objectives; Research proposals; Selection of software; Semantic recommendations; Software architects; Software component; C (programming language)",2-s2.0-85026727210
"Maruyama K., Hayashi S.","A tool supporting postponable refactoring",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026772237&doi=10.1109%2fICSE-C.2017.108&partnerID=40&md5=cc8a302b11c72cf278ae588868feeb5e","Failures of precondition checking when attempting to apply automated refactorings often discourage programmers from attempting to use these refactorings in the future. To alleviate this situation, the postponement of the failed refactoring instead its cancellation is beneficial. This poster paper proposes a new concept of postponable refactoring and a prototype tool that implements postponable Extract Method as an Eclipse plug-in. We believe that this refactoring tool inspires a new field of reconciliation automated and manual refactoring. © 2017 IEEE.","Code change management; Precondition checking; Software evolution; Software refactoring","Software engineering; Code changes; Precondition checking; Prototype tools; Refactoring tools; Refactorings; Software Evolution; Software refactoring; Tool supporting; C (programming language)",2-s2.0-85026772237
"Do L.N.Q., Ali K., Livshits B., Bodden E., Smith J., Murphy-Hill E.","Cheetah: Just-in-time taint analysis for android apps",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026785213&doi=10.1109%2fICSE-C.2017.20&partnerID=40&md5=25b3e76752ab1b6bdec9d6813136ed72","Current static-analysis tools are often long-running, which causes them to be sidelined into nightly build checks. As a result, developers rarely use such tools to detect bugs when writing code, because they disrupt their workflow. In this paper, we present Cheetah, a static taint analysis tool for Android apps that interleaves bug fixing and code development in the Eclipse integrated development environment. Cheetah is based on the novel concept of Just-in-Time static analysis that discovers and reports the most relevant results to the developer fast, and computes the more complex results incrementally later. Unlike traditional batch-style static-analysis tools, Cheetah causes minimal disruption to the developer's workflow. This video demo showcases the main features of Cheetah: https://www.youtube.com/watch?v=i-KQD-GTBdA. © 2017 IEEE.","Cheetah; Just-in-Time; Layered analysis; Static analysis","Android (operating system); C (programming language); Just in time production; Program debugging; Software engineering; Analysis tools; Cheetah; Code development; Eclipse Integrated Development Environment; Just in time; Layered analysis; Novel concept; Writing codes; Static analysis",2-s2.0-85026785213
"Di Nucci D., Palomba F., Prota A., Panichella A., Zaidman A., De Lucia A.","PETrA: A software-based tool for estimating the energy profile of android applications",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026749765&doi=10.1109%2fICSE-C.2017.18&partnerID=40&md5=c0f887a9a4d8aca493e9bfdf228097f8","Energy efficiency is a vital characteristic of any mobile application, and indeed is becoming an important factor for user satisfaction. For this reason, in recent years several approaches and tools for measuring the energy consumption of mobile devices have been proposed. Hardware-based solutions are highly precise, but at the same time they require costly hardware toolkits. Model-based techniques require a possibly difficult calibration of the parameters needed to correctly create a model on a specific hardware device. Finally, software-based solutions are easier to use, but they are possibly less precise than hardware-based solution. In this demo, we present PETrA, a novel software-based tool for measuring the energy consumption of Android apps. With respect to other tools, PETrA is compatible with all the smartphones with Android 5.0 or higher, not requiring any device specific energy profile. We also provide evidence that our tool is able to perform similarly to hardware-based solutions. © 2017 IEEE.","Energy Consumption; Estimation; Mobile Apps","Application programs; C (programming language); Energy efficiency; Energy utilization; Estimation; Hardware; Mobile devices; Software engineering; Android applications; Mobile applications; Mobile apps; Model based techniques; Software-based solutions; Specific energy; Specific hardware; User satisfaction; Android (operating system)",2-s2.0-85026749765
"Wu F., Jing X.-Y., Dong X., Cao J., Xu M., Zhang H., Ying S., Xu B.","Cross-project and within-project semi-supervised software defect prediction problems study using a unified solution",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026725782&doi=10.1109%2fICSE-C.2017.72&partnerID=40&md5=910f9c69cff4d397aa4a22c6584be1a5","When there exists not enough historical defect data for building accurate prediction model, semi-supervised defect prediction (SSDP) and cross-project defect prediction (CPDP) are two feasible solutions. Existing CPDP methods assume that the available source data is well labeled. However, due to expensive human efforts for labeling a large amount of defect data, usually, we can only make use of the suitable unlabeled source data to help build the prediction model. We call CPDP in this scenario as cross-project semi-supervised defect prediction (CSDP). As to within-project semi-supervised defect prediction (WSDP), although some WSDP methods have been developed in recent years, there still exists much room for improvement. In this paper, we aim to provide an effective solution for both CSDP and WSDP problems. We introduce the semi-supervised dictionary learning technique, an effective machine learning technique, into defect prediction and propose a semi-supervised structured dictionary learning (SSDL) approach for CSDP and WSDP. SSDL can make full use of the useful information in limited labeled defect data and a large amount of unlabeled data. Experiments on two public datasets indicate that SSDL can obtain better prediction performance than related SSDP methods in the CSDP scenario. © 2017 IEEE.","Cross-project semi-supervised defect prediction; Semi-supervised structured dictionary learning; Within-project semi-supervised defect prediction","C (programming language); Defects; Learning algorithms; Learning systems; Software engineering; Accurate prediction; Defect prediction; Dictionary learning; Effective solution; Machine learning techniques; Prediction performance; Software defect prediction; Structured dictionary learning; Forecasting",2-s2.0-85026725782
"Jabbarvand R.","Advancing energy testing of mobile applications",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026749344&doi=10.1109%2fICSE-C.2017.45&partnerID=40&md5=cee57d519ea73cda2227efffdbf087e4","The rising popularity of mobile apps deployed on battery-constrained devices has motivated the need for effective energy-aware testing techniques. However, currently there is a lack of test generation tools for exercising the energy properties of apps. Automated test generation is not useful without tools that help developers to measure the quality of the tests. Additionally, the collection of tests generated for energy testing could be quite large, as it may involve a test suite that covers all the energy hotspots under different use cases. Thereby, there is a need for techniques to manage the size of test suite, while maintaining its effectiveness in revealing energy defects. Our research plan to advance energy testing for mobile applications include various techniques for energy-aware test generation, energy-aware test-suite adequacy assessment, and energy-aware test-suite minimization. © 2017 IEEE.","Android; Energy Consumption; Green Software Engineering; Mutation Testing; Software Testing; Test suite Minimization","C (programming language); Energy utilization; Mobile computing; Mobile telecommunication systems; Power management; Software engineering; Testing; Android; Automated test generations; Constrained devices; Mobile applications; Mutation testing; Test generations; Test suite minimization; Testing technique; Software testing",2-s2.0-85026749344
"Xie M., Wang Q., Cui Q., Yang G., Li M.","CQM: Coverage-constrained quality maximization in crowdsourcing test",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026749646&doi=10.1109%2fICSE-C.2017.112&partnerID=40&md5=ab4e65a44e3d1a83d8069bb13aaf73c1","Mobile app testing is challenging since each test needs to be executed in a variety of operating contexts including heterogeneous devices, various wireless networks, and different locations. Crowdsourcing enables a mobile app testing to be distributed as a crowdsourced task to leverage the crowd in a community. However, a high test quality and expected test context coverage are difficult to achieve in crowdsourcing test. Upon distributing a test task, mobile app providers can neither know who will participate and submit a high-qualified test report nor predict whether all expected test contexts can be covered during the test. To address this problem, we put forward a novel research problem called Coverage-constrained Quality Maximization (CQM) for crowdsourcing test. Given a mobile app test task, our objective is to discover and recommend a set of potential workers from available crowd workers such that they can accomplish the task achieving expected test context coverage and the possible highest test quality. We prove that the CQM problem is NP-Complete and then introduce two efficient greedy algorithms. Based on a real dataset of the largest Chinese crowdsourcing test platform, our evaluation shows that the proposed algorithms are effective and efficient, and can be potentially used as online services in practice. © 2017 IEEE.",,"C (programming language); Crowdsourcing; Software engineering; Testing; Greedy algorithms; Heterogeneous devices; NP Complete; On-line service; Research problems; Test platforms; Test quality; Test reports; Statistical tests",2-s2.0-85026749646
"Yan M., Zhang X., Liu C., Zou J., Xu L., Xia X.","Learning to aggregate: An automated aggregation method for software quality model",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026779565&doi=10.1109%2fICSE-C.2017.139&partnerID=40&md5=aa73254c09b0a22e5d8025cebb01adf0","Quality models are regarded as a well-acceptedapproach for assessing high-level abstract quality characteristics(e.g., maintainability) by aggregation from low-level metrics. However, most of the existing quality models adopt the weightedlinear aggregation method which suffers from a lack of consensusin how to decide the correct weights. To address this issue, wepresent an automated aggregation method which adopts a kind ofprobabilistic weight instead of the subjective weight in previousaggregation methods. In particular, we utilize a topic modelingtechnique to estimate the probabilistic weight by learning froma software benchmark. In this manner, our approach can enableautomated quality assessment by using the learned knowledgewithout manual effort. In addition, we conduct an application onthe maintainability assessment of the systems in our benchmark. The result shows that our approach can reveal the maintainabilitywell through a correlation analysis with the changed lines of code. © 2017 IEEE.",,"Benchmarking; Computer software selection and evaluation; Maintainability; Software engineering; Aggregation methods; Correlation analysis; Lines of code; Quality assessment; Quality characteristic; Quality models; Software quality modeling; Subjective weights; C (programming language)",2-s2.0-85026779565
"Wang L., Sun X., Wang J., Duan Y., Li B.","Construct bug knowledge graph for bug resolution",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026772768&doi=10.1109%2fICSE-C.2017.102&partnerID=40&md5=9766c46d4f61cab7e5ab321896219606","This paper proposed to utilize bug knowledge graph for bug resolution. Bug knowledge graph provide more comprehensive and relevant bug information (i.e., bug reports, commits, relevant developers, etc.). Moreover, our approach can automatically update bug knowledge graph based on the the lifelong learning topic model. Preliminary results show that bug knowledge graph can provide more accurate and comprehensive information related to a bug issue. © 2017 IEEE.",,"Graphic methods; Program debugging; Software engineering; Bug reports; Comprehensive information; Knowledge graphs; Life long learning; Topic Modeling; C (programming language)",2-s2.0-85026772768
"Gren L., Al-Sabbagh K.","Group developmental psychology and software development performance",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026755387&doi=10.1109%2fICSE-C.2017.85&partnerID=40&md5=6124b0e6a20feb38e8e45084215552ff","Due to the fact that software development is a product of team effort it is important to investigate the influence of group developmental psychology on software development performance. In this case study we wanted to test how performance (i.e. velocity and planning effectiveness) are related to the group's maturity level. We gave the Group Development Questionnaire (the GDQ) to 19 software developers to assess their group maturity (i.e. their progress in their group development) and ran correlation analysis against the development velocity and planning effectiveness (i.e. earned points over planned points). The results show that group maturity is correlated to planning effectiveness but not velocity, meaning that group development is connected to the team's ability to plan well, but not their ability to implement tasks fast. © 2017 IEEE.",,"C (programming language); Software engineering; Correlation analysis; Development performance; Developmental psychology; Group development; Maturity levels; Planning effectiveness; Software developer; Software design",2-s2.0-85026755387
"Furia C.A.","What good is Bayesian data analysis for software engineering?",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026787577&doi=10.1109%2fICSE-C.2017.92&partnerID=40&md5=619052fde4fa07027c5f5aab5336f3d1","This abstract outlines the problems with classical statistical hypothesis testing, and recommends using alternative techniques based on Bayesian statistics, which are largely immune to the shortcomings of statistical hypothesis testing, and support a robust induction process. © 2017 IEEE.",,"Software engineering; Statistical tests; Testing; Bayesian data analysis; Bayesian statistics; Induction process; Statistical hypothesis testing; C (programming language)",2-s2.0-85026787577
"Knauss A., Schroder J., Berger C., Eriksson H.","Software-related challenges of testing automated vehicles",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026765808&doi=10.1109%2fICSE-C.2017.67&partnerID=40&md5=114ef226aecf03cf16022bdd6310ab84","Automated vehicles are not supposed to fail at any time or in any situations during driving. Thus, vehicle manufactures and proving ground operators are challenged to complement existing test procedures with means to systematically evaluate automated driving. In this paper, we explore software related challenges from testing the safety of automated vehicles. We report on findings from conducting focus groups and interviews including 26 participants (e.g., vehicle manufacturers, suppliers, and researchers) from five countries. © 2017 IEEE.",,"Automation; Automobile manufacture; Safety testing; Software engineering; Software testing; Vehicles; Automated driving; Automated vehicles; Focus groups; Ground operator; Test procedures; Vehicle manufacturers; C (programming language)",2-s2.0-85026765808
"Lu Y., Zhou T., Li W., Wu H.","The critical local buckling load and ultimate strength of cold-formed thin-walled C-sections under axial compression",2017,"Harbin Gongye Daxue Xuebao/Journal of Harbin Institute of Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029495410&doi=10.11918%2fj.issn.0367-6234.201607058&partnerID=40&md5=5dc8ff5980f642a7a06262fcb83cd701","To study the plate-assembly effects on the local buckling loads and ultimate strength of cold-formed thin-walled C-sections, the cross-sectional deformation of each plate of the C-section with respect to local buckling was analyzed and an analytical web local buckling model was proposed considering the plate-assembly effects. Based on the energy method and equilibrium conditions, an analytical formula for thin-walled compressed C-sections was derived. The derived formula was verified by the finite strip method and the Chinese code GB 50018-2002, respectively. The ultimate strengths of 21 cold-formed C-section columns under compression were calculated by adopting the analytical formulae in the direct strength method and compared with the test results and the results calculated by the Chinese code GB 50018-2002, respectively. The results show that the derived formula is reasonable and reliable for the local buckling loads, whereas the Chinese code brings out systematic errors, namely conservative results for the depth of web to width of flange ratio less than 4.5 and unsafe results for the depth of web to width of flange ratio more than 4.5. As for the ultimate strength, the results from the proposed method agrees well with the test results, which indicate that the proposed method is reasonable and reliable. In contrast, the Chinese code are conservative with respect to the tests results and the difference between the Chinese code and the test result increases as the depth of web to width of flange ratio increasing. © 2017, Editorial Board of Journal of Harbin Institute of Technology. All right reserved.","C-sections; Cold-formed steel; Local buckling load; Plate-assembly effects; Ultimate strength","Buckling; Codes (symbols); Compressive strength; Flanges; Systematic errors; Thin walled structures; C sections; Cold-formed steel; Local buckling loads; Plate assemblies; Ultimate strength; C (programming language)",2-s2.0-85029495410
"Macho C.","Preventing and repairing build breakage - Extended abstract",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026772332&doi=10.1109%2fICSE-C.2017.29&partnerID=40&md5=a00553580c4be9611e8ed23f282f4aa3","Build systems play a crucial role in modern software engineering. Recent studies have shown that many builds fail, mostly due to neglected maintenance. This blocks teams from continuing the development and costs time and resources to fix. The target of the thesis is to reduce build breakage by investigating changes that lead to failing builds, identifying bad and best practices for build configuration, and providing an approach to automatically repair broken builds. As a first step, we conduct empirical studies to determine changes and change patterns that lead to build breakage and reveal the reasons for build breakage. Based on these findings, we develop an approach to automatically refactor build configurations that are likely to fail and an approach to repair broken builds. We plan to evaluate our approaches first, quantitatively by measuring the performance of our approaches in open source projects and second, qualitatively by asking developers to use our approaches and give feedback on their applicability and usefulness. © 2017 IEEE.","Build Systems; Maintenance; Software Quality","Computer software selection and evaluation; Maintenance; Open source software; Repair; Software engineering; Best practices; Build systems; Change patterns; Empirical studies; Extended abstracts; Open source projects; Software Quality; C (programming language)",2-s2.0-85026772332
"Bacchelli A., Beller M.","Double-blind review in software engineering venues: The community's perspective",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026771406&doi=10.1109%2fICSE-C.2017.49&partnerID=40&md5=9649f9aa76e4c64f10c01fa087ee9b8d","The peer review process is central to the scientific method, the advancement and spread of research, as well as crucial for individual careers. However, the single-blind review mode currently used in most Software Engineering (SE) venues is susceptible to apparent and hidden biases, since reviewers know the identity of authors. We perform a study on the benefits and costs that are associated with introducing double-blind review in SE venues. We surveyed the SE community's opinion and interviewed experts on double-blind reviewing. Our results indicate that the costs, mostly logistic challenges and side effects, outnumber its benefits and mostly regard difficulty for authors in blinding papers, for reviewers in understanding the increment with respect to previous work from the same authors, and for organizers to manage a complex transition. While the surveyed community largely consents on the costs of DBR, only less than one-third disagree with a switch to DBR for SE journals, all SE conferences, and, in particular, ICSE, the analysis of a survey with authors of submitted papers at ICSE 2016 run by the program chairs of that edition corroborates our result. © 2017 IEEE.","Academic community; Double-blind review; Scientific publishing","C (programming language); Cost benefit analysis; Costs; Reviews; Surveys; Academic community; Benefits and costs; Complex transitions; Peer-review process; Scientific method; Side effect; Software engineering",2-s2.0-85026771406
"Afridi H.G.","Empirical investigation of correlation between rewards and crowdsource-based software developers",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026751761&doi=10.1109%2fICSE-C.2017.149&partnerID=40&md5=6b1d5f03c929c3ce1d386fb90be422ed","Numerous reward system practices are adopted in software development companies in order to motivate their developers to perform at best level and align the management and developer's interest. However, due to lack of a central mechanism for team formation on crowdsourcing-based software development platform, it is difficult for managers to adopt effective reward system strategies in order to align the developer's interest. In order to address this issue, we exploit an approach, to empirically investigate the existing reward system practices, adopted on the crowdsourcing-based software development platforms, to motivate their developers and their perception. Subsequently, we implement a crawler to mine the characteristics of completed tasks and related reward information from the TopCoder platform of Tech Platform Inc (TPI). The promising results suggest the applicability of the proposed approach in order, 1) to investigate the reward system practices across the crowdsourcing-based platforms and, 2) to help the managers in formulating and implementing an effective reward system to incentivize their developers. © 2017 IEEE.","Correlation; Crowdsourcing; Developers; Regression; Reward System; TopCoder","C (programming language); Correlation methods; Crowdsourcing; Human resource management; Managers; Software engineering; Developers; Development platform; Empirical investigation; Regression; Reward systems; Software developer; Team formation; TopCoder; Software design",2-s2.0-85026751761
"Fernandes B., Pinto G., Castor F.","Assisting non-specialist developers to build energy-efficient software",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026744263&doi=10.1109%2fICSE-C.2017.133&partnerID=40&md5=ed22f0067bcdc0169aa2d8125d0e5c98","In this paper we introduce CECOTOOL, a tool that analyzes the energy behavior of alternative collection implementations and provides potentially useful recommendations about good implementation options. We applied it to two real-world software systems from the DaCapo suite [1], Xalan and Tomcat. With no prior knowledge of the application domains, we were able to reduce the energy consumption up to 4.37%. © 2017 IEEE.",,"Energy efficiency; Energy utilization; Software engineering; Energy efficient; Prior knowledge; Real-world; Software systems; C (programming language)",2-s2.0-85026744263
"Di Penta M., Tamburri D.A.","Combining quantitative and qualitative studies in empirical software engineering research",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026749209&doi=10.1109%2fICSE-C.2017.163&partnerID=40&md5=c168eb72508f6c3c55cceda2ada057a8","This technical briefing provides an overview of how quantitative empirical research methods can be combined with qualitative ones generating the family of empirical software engineering approaches known as mixed-methods. The ultimate aim of such mixed-methods is supporting cause-effect claims combining multiple data types, sources and analyses that provide software practitioners and academicians solid rationale and practical value to research results. This briefing offers lessons we learned in instrumenting and executing mixed-methods approaches for the benefit of the goal above. © 2017 IEEE.","Empirical Software Engineering; Grounded Theory; Qualitative Methods; Quantitative Methods","C (programming language); Technical presentations; Empirical research method; Empirical Software Engineering; Grounded theory; Multiple data types; Qualitative method; Qualitative study; Quantitative method; Software practitioners; Software engineering",2-s2.0-85026749209
"Towey D., Foster D., Gilardi F., Martin P., White A., Jiang Y., Pan Y., Qu Y.","Students as partners in a multi-media note-taking app development: Best practices",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026762403&doi=10.1109%2fICSE-C.2017.58&partnerID=40&md5=58469446597146a2e0d567c691d397cd","This paper summarises some of the best practices learned from an extended software engineering project completed through a collaboration of multidisciplinary faculty and several teams of computer science students. The collaboration delivered an advanced multimedia note-taking application, as an open educational resource (OER), capable of supporting both students and research into note-making practices. The project lasted beyond a single academic year, thus enabling multiple student cohort participation, and took place in an English medium of instruction, Sino-foreign university in China. The experiences and reflections surrounding the project were examined, with a number of resulting ideas for best practices. © 2017 IEEE.","Learning and Teaching Research; Note-making; Open Education Resource (OER); Student Projects; Student-Teacher Collaboration; Technology in the Classroom","C (programming language); Education; Engineering education; Multimedia systems; Software engineering; Teaching; Learning and teachings; Note-making; Open Education Resources; Student project; Student teachers; Technology in the classroom; Students",2-s2.0-85026762403
"Havrikov N.","Efficient fuzz testing leveraging input, code, and execution",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026742743&doi=10.1109%2fICSE-C.2017.26&partnerID=40&md5=2f2b23ca142d7b2c6fdb61983a40ad15","Any kind of smart testing technique must be very efficient to be competitive with random fuzz testing. State-of the-art test generators are largely inferior to random testing in real world applications. This work proposes to gather and evaluate lightweight analyses that can enable the creation of an efficient and sufficiently effective analysis-assisted fuzz tester. The analyses shall leverage information sources apart from the program under test itself, such as e.g. descriptions of the targeted input format in the form of extended context-free grammars, or hardware counters. As the main contributions, an efficient framework for building fuzzers around given analyses will be created, and with its help analyses will be identified and categorized according to their performance. © 2017 IEEE.","Efficient fuzz testing; Fuzz testing; Fuzzing; Grammar-based testing; Software engineering; Test input generation","C (programming language); Context free grammars; Fuzzy inference; Software engineering; Testing; Effective analysis; Fuzz Testing; Fuzzing; Grammar-based testing; Hardware counters; Information sources; Test inputs; Testing technique; Software testing",2-s2.0-85026742743
"Williams G., Mahmoud A.","Mining twitter data for a more responsive software engineering process",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026760389&doi=10.1109%2fICSE-C.2017.53&partnerID=40&md5=6e05c2b3909f032953a6db7f6072804d","Twitter has created an unprecedented opportunityfor software developers to monitor the opinions of large populationsof end-users of their software. However, automaticallyclassifying useful tweets is not a trivial task. Challenges stem fromthe scale of the data available, its unique format, diverse nature, and high percentage of spam. To overcome these challenges, thisextended abstract introduces a three-fold procedure that is aimedat leveraging Twitter as a main source of technical feedbackthat software developers can benefit from. The main objective isto enable a more responsive, interactive, and adaptive softwareengineering process. Our analysis is conducted using a dataset oftweets collected from the Twitter feeds of three software systems. Our results provide an initial proof of the technical value ofsoftware-relevant tweets and uncover several challenges to bepursued in our future work. © 2017 IEEE.","Classification twitter; Data mining; Maintenance","Data mining; Maintenance; Social networking (online); Software engineering; End users; Software developer; Software engineering process; Software systems; Three folds; C (programming language)",2-s2.0-85026760389
"Di Ruscio D., Franzago M., Malavolta I., Muccini H.","Envisioning the future of collaborative model-driven software engineering",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026767433&doi=10.1109%2fICSE-C.2017.143&partnerID=40&md5=bf98c663f2415035b3eb23967cba5d48","The adoption of Model-driven Software Engineering (MDSE) to develop complex software systems in application domains like automotive and aerospace is being supported by the maturation of model-driven platforms and tools. However, empirical studies show that a wider adoption of MDSE technologies is still an issue. One limiting factor is related to the limited support for collaborative MDSE. This paper reflects on research directions, challenges, and opportunities of collaborative MDSE. © 2017 IEEE.","Collaborative MDSE; Collaborative Software Engineering; Model-Driven Engineering","Application programs; C (programming language); Groupware; Collaborative MDSE; Collaborative model; Collaborative softwares; Complex software systems; Empirical studies; Model driven software engineering; Model-driven; Model-driven Engineering; Software engineering",2-s2.0-85026767433
"Porru S., Pinna A., Marchesi M., Tonelli R.","Blockchain-oriented software engineering: Challenges and new directions",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026739193&doi=10.1109%2fICSE-C.2017.142&partnerID=40&md5=1cb3e2ba77f13d048a0f2ae1645e9443","In this work, we acknowledge the need for software engineers to devise specialized tools and techniques for blockchain-oriented software development. Ensuring effective testing activities, enhancing collaboration in large teams, and facilitating the development of smart contracts all appear as key factors in the future of blockchain-oriented software development. © 2017 IEEE.","Blockchain; Cryptocurrencies; Smart contracts; Software engineering","C (programming language); Electronic money; Software design; Software testing; Block-chain; Effective testing; Specialized tools; Software engineering",2-s2.0-85026739193
"Gazzola L.","Field testing of software applications",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026786868&doi=10.1109%2fICSE-C.2017.30&partnerID=40&md5=0d384da99cafdd39757a5055d73c551e","When interacting with their software systems, users may have to deal with problems like crashes, failures, and program instability. Faulty software running in the field is not only the consequence of ineffective in-house verification and validation techniques, but it is also due to the complexity and diversity of the interactions between an application and its environment. Many of these interactions can be hardly predicted at testing time, and even when they could be predicted, often there are so many cases to be tested that they cannot be all feasibly addressed before the software is released. This Ph.D. thesis investigates the idea of addressing the faults that cannot be effectively addressed in house directly in the field, exploiting the field itself as testbed for running the test cases. An enormous number of diverse environments would then be available for testing, giving the possibility to run many test cases in many different situations, timely revealing the many failures that would be hard to detect otherwise. © 2017 IEEE.","Field failures; Field testing; Isolation","Application programs; C (programming language); Safety engineering; Software engineering; Verification; Field failure; Field testing; Isolation; Running-in; Software applications; Software systems; Testing time; Verification-and-validation; Software testing",2-s2.0-85026786868
"Mallozzi P.","Combining machine-learning with invariants assurance techniques for autonomous systems",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026772370&doi=10.1109%2fICSE-C.2017.40&partnerID=40&md5=8bb1c6c97a13831cd4f8b37fac8c9246","Autonomous Systems are systems situated in some environment and are able of taking decision autonomously. The environment is not precisely known at design-time and it might be full of unforeseeable events that the autonomous system has to deal with at run-time. This brings two main problems to be addressed. One is that the uncertainty of the environment makes it difficult to model all the behaviours that the autonomous system might have at the design-time. A second problem is that, especially for safety-critical systems, maintaining the safety requirements is fundamental despite the system's adaptations. We address such problems by shifting some of the assurance tasks at run-time. We propose a method for delegating part of the decision making to agent-based algorithms using machine learning techniques. We then monitor at run-time that the decisions do not violate the autonomous system's safety-critical requirements and by doing so we also send feedback to the decision-making process so that it can learn. We plan to implement this approach using reinforcement learning for decision making and predictive monitoring for checking at run-time the preservation and/or violation of invariant properties of the system. We also plan to validate it using ROS as software middleware and miniaturized vehicles and real vehicles as hardware. © 2017 IEEE.","Autonomous systems; Invariants enforcement; Machine-learning","Artificial intelligence; C (programming language); Decision making; Decision support systems; Learning systems; Middleware; Reinforcement learning; Software engineering; Autonomous systems; Decision making process; Invariant properties; Invariants enforcement; Machine learning techniques; Predictive monitoring; Safety critical systems; Safety requirements; Safety engineering",2-s2.0-85026772370
"Li L., Bissyande T.F., Bartel A., Klein J., Le Traon Y.","The multi-generation repackaging hypothesis",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026779066&doi=10.1109%2fICSE-C.2017.140&partnerID=40&md5=31ce0ee3011b89c9c7b318e6fa91c6de","App repackaging is a common threat in the Android ecosystem. To face this threat, the literature now includes a large body of work proposing approaches for identifying repackaged apps. Unfortunately, although most research involves pairwise similarity comparison to distinguish repackaged apps from their 'original' counterparts, no work has considered the threat to validity of not being able to discover the true original apps. We provide in this paper preliminary insights of an investigation into the Multi-Generation Repackaging Hypothesis: is the original in a repackaging process the outcome of a previous repackaging process? Leveraging the Androzoo dataset of over 5 million Android apps, we validate this hypothesis in the wild, calling upon the community to take this threat into account in new solutions for repackaged app detection. © 2017 IEEE.",,"C (programming language); Engineering research; Software engineering; Android apps; Multi generations; New solutions; Android (operating system)",2-s2.0-85026779066
"Dubey A., Abhinav K., Virdi G.","A framework to preserve confidentiality in crowdsourced software development",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026743463&doi=10.1109%2fICSE-C.2017.145&partnerID=40&md5=5444a8bad60082c6a681c9e8b69e9826","We propose a framework to preserve confidential information in a crowdsourced software development. The software industry is moving towards gig economy where majority of workforce is freelancers. The freelancers may have varying level of trust. Hence, protection of confidential information is becoming an increasingly important subject. In this paper, we discuss various challenges in protecting sensitive information in software development projects and propose a confidentiality preserving software development process. We perform a preliminary evaluation of the process. We use an information theoretic approach to protect confidential information. Results demonstrate the feasibility of the framework and uncovers several aspects that requires further research studies. © 2017 IEEE.","Crowdsourcing; Information sanitization; Software development","C (programming language); Crowdsourcing; Information theory; Software engineering; Confidential information; Information-theoretic approach; Research studies; Sanitization; Sensitive informations; Software development process; Software development projects; Software industry; Software design",2-s2.0-85026743463
"Gousios G., Spinellis D.","Mining software engineering data from GitHub",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026766727&doi=10.1109%2fICSE-C.2017.164&partnerID=40&md5=a7e3ae6ba9f697e869a42845b77e2707","GitHub is the largest collaborative source code hosting site built on top of the Git version control system. The availability of a comprehensive API has made GitHub a target for many software engineering and online collaboration research efforts. In our work, we have discovered that a) obtaining data from GitHub is not trivial, b) the data may not be suitable for all types of research, and c) improper use can lead to biased results. In this tutorial, we analyze how data from GitHub can be used for large-scale, quantitative research, while avoiding common pitfalls. We use the GHTorrent dataset, a queryable offline mirror of the GitHub API data, to draw examples from and present pitfall avoidance strategies. © 2017 IEEE.","Empirical software engineering; GHTorrent; Git; GitHub","Engineering research; Software engineering; Empirical Software Engineering; GHTorrent; GitHub; Mining software engineering datum; On-line collaborations; Quantitative research; Source codes; Version control system; C (programming language)",2-s2.0-85026766727
"Nunes M., Lalh H., Sharma A., Wong A., Miucin S., Fedorova A., Beschastnikh I.","Studying multi-threaded behavior with TSViz",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026768280&doi=10.1109%2fICSE-C.2017.9&partnerID=40&md5=6674bcecf4cb48e3e7e3bd105b09338c","Modern high-performing systems make extensive use of multiple CPU cores. These multi-threaded systems are complex to design, build, and understand. Debugging performance of these multi-threaded systems is especially challenging. This requires the developer to understand the relative execution of dozens of threads and their inter-dependencies, including data-sharing and synchronization behaviors. We describe TSViz, a visualization tool to help developers study and understand the activity of complex multi-threaded systems. TSviz depicts the partial order of concurrent events in a time-space diagram, and simultaneously scales this diagram according to the physical clock timestamps that tag each event. A developer can then interact with the visualization in several ways, for example by searching for events of interest, studying the distribution of critical sections across threads and zooming the diagram in and out. We overview TSviz design and describe our experience with using it to study a high-performance multi-threaded key-value store based on MongoDB. A video demo of TSViz is online: https://youtu.be/LpuiOZ3PJCk. © 2017 IEEE.","Concurrency; Log analysis; Multi-threaded systems; Performance debugging; Tracing; Visualization","C (programming language); Flow visualization; Software engineering; Visualization; Concurrency; Log analysis; Multi-threaded system; Performance debugging; Tracing; Program debugging",2-s2.0-85026768280
"Escobar-Avila J., Parra E., Haiduc S.","Text retrieval-based tagging of software engineering video tutorials",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026742842&doi=10.1109%2fICSE-C.2017.121&partnerID=40&md5=77e6dbc80e2e3b06ec24ee7637b567fb","Video tutorials are an emerging form of documentation in software engineering and can efficiently provide developers with useful information needed for their daily tasks. However, to get the information they need, developers have to find the right tutorial for their task at hand. Currently, there is little information available to quickly judge whether a tutorial is relevant to a topic or helpful to the task at hand, which can lead to missing the best tutorials and wasting time watching irrelevant ones. We present the first efforts towards new tagging approaches using text retrieval that describe the contents of software engineering video tutorials, making it easier and faster to understand their purpose and contents. We also present the results of a preliminary evaluation of thirteen such approaches, revealing the potential of some and limitations of others. © 2017 IEEE.","Software engineering; Tagging; Text retrieval; Video tutorials","C (programming language); Information retrieval; Daily tasks; Tagging; Text retrieval; Video tutorials; Software engineering",2-s2.0-85026742842
"De Oliveira P.A.","Predictive analysis of cloud systems",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026749281&doi=10.1109%2fICSE-C.2017.39&partnerID=40&md5=d2d389a992fa6ea678c7528c4014ee29","Predictive analysis methods offer the possibility ofestimating the impact of design decisions, which may help inthe accomplishment of operational optimal results, before thedeployment of the system, and therefore minimizing the requiredeffort and cost. However, current predictive methods cannot beused on cloud environments, because of their complexity anddynamic nature. The main goal of this thesis is to investigatemethods for predictive analysis of cloud systems. Given modelsof cloud systems and their environments, we will specify differentadaptation mechanisms, and techniques for the estimation ofdifferent QoS metrics that help in the analysis of cloud systems. Specifically, we will use model transformation techniques tospecify the behavior of systems and their dynamic adaptation, as well as the performance metrics and tools for their analysis. Our tools will be based on simulation, and we will explore theuse of statistical model checking tools, and in particular thosedeveloped for graph-transformation systems. © 2017 IEEE.","Cloud Systems; Graph-Transformation Systems; Predictive Analysis","Graph theory; Model checking; Predictive analytics; Software engineering; Cloud environments; Cloud systems; Design decisions; Dynamic adaptations; Graph transformation system; Performance metrics; Predictive methods; Statistical model checking; C (programming language)",2-s2.0-85026749281
"Engelke A., Weidendorfer J.","Using LLVM for optimized lightweight binary re-writing at runtime",2017,"Proceedings - 2017 IEEE 31st International Parallel and Distributed Processing Symposium Workshops, IPDPSW 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028068365&doi=10.1109%2fIPDPSW.2017.103&partnerID=40&md5=662780b5168d68862515663179d4b45e","Providing new parallel programming models/abstractions as a set of library functions has the huge advantage that it allows for an relatively easy incremental porting path for legacy HPC applications, in contrast to the huge effort needed when novel concepts are only provided in new programming languages or language extensions. However, performance issues are to be expected with fine granular usage of library functions. In previous work, we argued that binary rewriting can bridge the gap by tightly coupling application and library functions at runtime. We showed that runtime specialization at the binary level, starting from a compiled, generic stencil code can help in approaching performance of manually written, statically compiled version. In this paper, we analyze the benefits of post-processing the re-written binary code using standard compiler optimizations as provided by LLVM. To this end, we present our approach for efficiently converting x86-64 binary code to LLVM-IR. Using the mentioned generic code for arbitrary 2d stencils, we present performance numbers with and without LLVM postprocessing. We find that we can now achieve the performance of variants specialized by hand. © 2017 IEEE.","Binary Transformation; Dynamic Code Generation; Dynamic Optimization; High Performance Computing","Binary codes; Codes (symbols); Parallel programming; Program compilers; Binary transformation; Compiler optimizations; Dynamic code generation; Dynamic optimization; High performance computing; Language extensions; Parallel programming model; Runtime specialization; Bins",2-s2.0-85028068365
"Phan H., Nguyen H.A., Nguyen T.N., Rajan H.","Statistical learning for inference between implementations and documentation",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering: New Ideas and Emerging Results Track, ICSE-NIER 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026771938&doi=10.1109%2fICSE-NIER.2017.9&partnerID=40&md5=1d54e433749a5f41cef352f1e081b3f1","API documentation is useful for developers to better understand how tocorrectly use the libraries. However, not all libraries provide gooddocumentation on API usages. To provide better documentation, existingtechniques have been proposed including program analysis-based anddata mining-based approaches. In this work, instead of mining, we aimto generate behavioral exception documentation for any given code. Wetreat the problem of automatically generating documentation from anovel perspective: Statistical machine translation (SMT). We considerthe documentation and source code for an API method as the twoabstraction levels of the same intention. We use SMT to translatedocumentation from source code and vice versa. Our preliminary resultsshow that the direction of statistical learning for inference betweenimplementations and documentation is very promising. © 2017 IEEE.","API documentation generation; statistical machine translation","Application programming interfaces (API); Codes (symbols); Computational linguistics; Computer aided language translation; Computer programming; Libraries; Linguistics; Software engineering; Speech transmission; API documentation generation; Program analysis; Source codes; Statistical learning; Statistical machine translation; Program documentation",2-s2.0-85026771938
"Kayraklioglu E., Chang W., El-Ghazawi T.","Comparative performance and optimization of chapel in modern manycore architectures",2017,"Proceedings - 2017 IEEE 31st International Parallel and Distributed Processing Symposium Workshops, IPDPSW 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028034245&doi=10.1109%2fIPDPSW.2017.126&partnerID=40&md5=31a89f56638845d6e8d5cc8df20ab901","Chapel is an emerging scalable, productive parallel programming language. In this work, we analyze Chapel's performance using The Parallel Research Kernels on two different manycore architectures including a state-of-the-art Intel Knights Landing processor. We discuss implementation techniques in Chapel and their relation to the OpenMP implementations of the PRK. We also suggest and prototype several optimizations in different layers of the software stack including the Chapel compiler. In our experiments we observed that base performance of Chapel ranges from 41%-184% that of OpenMP. The optimization techniques we discussed shows performance improvements ranging from 1.4x to 2x in Chapel. © 2017 IEEE.","Chapel; Knights Landing; OpenMP; Parallel Research Kernels","Parallel programming; Chapel; Comparative performance; Different layers; Implementation techniques; Many-core architecture; OpenMP; Optimization techniques; Parallel Research Kernels; Application programming interfaces (API)",2-s2.0-85028034245
"Juchli M., Krombeen L., Rao S., Yu C.S., Sawant A.A., Bacchelli A.","Mining Motivated Trends of Usage of Haskell Libraries",2017,"Proceedings - 2017 IEEE/ACM 1st International Workshop on API Usage and Evolution, WAPI 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026730457&doi=10.1109%2fWAPI.2017.6&partnerID=40&md5=c514489fb9f5b3e7d874ef0db743aaf6","We propose an initial approach to minethe usage trends of libraries in Haskell, a popular functional programming language. We integrate it with a novel, initial method to automatically determine the reasons of clients for switching to different versions. Based onthese, we conduct a preliminary investigation of trends of usage in Haskelllibraries. Results suggest that trends are similar to those in the Javaecosystem and in line with Rogers' theory on the diffusion of innovation. Our results also provide indication on Haskell libraries being allby and large stable. © 2017 IEEE.","api usage; mining software repositories; version popularity","Application programming interfaces (API); Libraries; api usage; Diffusion of innovations; Haskell; Mining software repositories; version popularity; Functional programming",2-s2.0-85026730457
"Yan Y., Liu J., Cameron K.W., Umar M.","HOMP: Automated Distribution of Parallel Loops and Data in Highly Parallel Accelerator-Based Systems",2017,"Proceedings - 2017 IEEE 31st International Parallel and Distributed Processing Symposium, IPDPS 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027687689&doi=10.1109%2fIPDPS.2017.99&partnerID=40&md5=9905296d37c57c095f8bc2a5dcbe9683","Heterogeneous computing systems, e.g., those with accelerators than the host CPUs, offer the accelerated performance for a variety of workloads. However, most parallel programming models require platform dependent, time-consuming hand-tuning efforts for collectively using all the resources in a system to achieve efficient results. In this work, we explore the use of OpenMP parallel language extensions to empower users with the ability to design applications that automatically and simultaneously leverage CPUs and accelerators to further optimize use of available resources. We believe such automation will be key to ensuring codes adapt to increases in the number and diversity of accelerator resources for future computing systems. The proposed system combines language extensions to OpenMP, load-balancing algorithms and heuristics, and a runtime system for loop distribution across heterogeneous processing elements. We demonstrate the effectiveness of our automated approach to program on systems with multiple CPUs, GPUs, and MICs. © 2017 IEEE.","accelerator architecture; alignment; data and computation distribution; load balance; OpenMP; parallel loops; performance model; runtime system","Alignment; Application programming interfaces (API); Automation; Distributed computer systems; Parallel programming; Program processors; Accelerator architectures; Computation distribution; Load balance; OpenMP; Parallel loops; Performance Model; Runtime systems; Acceleration",2-s2.0-85027687689
"Qiao Y., Hashimoto K., Eriguchi A., Wang H., Wang D., Tsuruoka Y., Taura K.","Cache friendly parallelization of neural encoder-decoder models without padding on multi-core architecture",2017,"Proceedings - 2017 IEEE 31st International Parallel and Distributed Processing Symposium Workshops, IPDPSW 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028071125&doi=10.1109%2fIPDPSW.2017.165&partnerID=40&md5=2e82ff99cedd1f9cba9aeee2271a0c89","Scaling up Artificial Intelligence (AI) algorithms for massive datasets to improve their performance is becoming crucial. In Machine Translation (MT), one of most important research fields of AI, models based on Recurrent Neural Net- works (RNN) show state-of-the-art performance in recent years, and many researchers keep working on improving RNN-based models to achieve better accuracy in translation tasks. Most implementations of Neural Machine Translation (NMT) models employ a padding strategy when processing a mini-batch to make all sentences in a mini-batch have the same length. This enables an efficient utilization of caches and GPU/SIMD parallelism but leads to a waste of computation time. In this paper, we implement and parallelize batch learning for a Sequence-to- Sequence (Seq2Seq) model, which is the most basic model of NMT, without using a padding strategy. More specifically, our approach forms vectors which represent the input words as well as the neural network's states at different time steps into matrices when it processes one sentence, and as a result, the approach makes a better use of cache and optimizes the process that adjusts weights and biases during the back-propagation phase. Our experimental evaluation shows that our implementation achieves better scalability on multi-core CPUs. We also discuss our approach's potential to be used in other implementations of RNN-based models. © 2017 IEEE.","Cache Optimization; Neural Machine Translation; Parallel Programming","Backpropagation; Computational linguistics; Computer aided language translation; Parallel programming; Program processors; Program translators; Signal encoding; Cache optimization; Different time steps; Experimental evaluation; Machine translations; Massive data sets; Multicore architectures; Parallelizations; State-of-the-art performance; Computer architecture",2-s2.0-85028071125
"Zhang H., Hollingsworth J.K.","Data Centric Performance Measurement Techniques for Chapel Programs",2017,"Proceedings - 2017 IEEE 31st International Parallel and Distributed Processing Symposium, IPDPS 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027709639&doi=10.1109%2fIPDPS.2017.37&partnerID=40&md5=879f26aaef9db1f6ca290b3a7b1010f3","Chapel is an emerging PGAS (Partitioned Global Address Space) language whose design goal is to make parallel programming more productive and generally accessible. To date, the implementation effort has focused primarily on correctness over performance. We present a performance measurement technique for Chapel and the idea is also applicable to other PGAS models. The unique feature of our tool is that it associates the performance statistics not to the code regions (functions), but to the variables (including the heap allocated, static, and local variables) in the source code. Unlike code-centric methods, this data-centric analysis capability exposes new optimization opportunities that are useful in resolving data locality problems. This paper introduces our idea and implementations of the approach with three benchmarks. We also include a case study optimizing benchmarks based on the information from our tool. The optimized versions improved the performance by a factor of 1.4x for LULESH, 2.3x for MiniMD, and 2.1x for CLOMP with simple modifications to the source code. © 2017 IEEE.","Benchmark Optimization; Chapel Performance Analysis; Data-Centric Profiling; PGAS Model","Codes (symbols); Parallel programming; Analysis capabilities; Data centric; Partitioned Global Address Space; Performance analysis; Performance measurements; Performance statistics; PGAS model; Simple modifications; Benchmarking",2-s2.0-85027709639
"Clauss P., Altintas E., Kuhn M.","Automatic Collapsing of Non-Rectangular Loops",2017,"Proceedings - 2017 IEEE 31st International Parallel and Distributed Processing Symposium, IPDPS 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027689901&doi=10.1109%2fIPDPS.2017.34&partnerID=40&md5=a56bb2c520188fc1af68023732200b23","Loop collapsing is a well-known loop transformation which combines some loops that are perfectly nested into one single loop. It allows to take advantage of the whole amount of parallelism exhibited by the collapsed loops, and provides a perfect load balancing of iterations among the parallel threads. However, in the current implementations of this loop optimization, as the ones of the OpenMP language, automatic loop collapsing is limited to loops with constant loop bounds that define rectangular iteration spaces, although load imbalance is a particularly crucial issue with non-rectangular loops. The OpenMP language addresses load balance mostly through dynamic runtime scheduling of the parallel threads. Nevertheless, this runtime schedule introduces some unavoidable executiontime overhead, while preventing to exploit the entire parallelism of all the parallel loops. In this paper, we propose a technique to automatically collapse any perfectly nested loops defining non-rectangular iteration spaces, whose bounds are linear functions of the loop iterators. Such spaces may be triangular, tetrahedral, trapezoidal, rhomboidal or parallelepiped. Our solution is based on original mathematical results addressing the inversion of a multi-variate polynomial that defines a ranking of the integer points contained in a convex polyhedron. We show on a set of non-rectangular loop nests that our technique allows to generate parallel OpenMP codes that outperform the original parallel loop nests, parallelized either by using options 'static' or 'dynamic' of the OpenMPschedule clause. © 2017 IEEE.","load balanc-ing; loop collapsing; loop parallelization; OpenMP","Application programming interfaces (API); Distributed computer systems; Geometry; Polynomials; Convex polyhedrons; loop collapsing; Loop optimizations; Loop parallelization; Loop transformation; OpenMP; Perfectly nested loops; Run-time scheduling; Iterative methods",2-s2.0-85027689901
"Allen N., Pearce H., Roop P., Von Hanxleden R.","A model driven approach for cardiac pacemaker design using a PRET processor",2017,"Proceedings - 2017 IEEE 20th International Symposium on Real-Time Distributed Computing, ISORC 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026771415&doi=10.1109%2fISORC.2017.5&partnerID=40&md5=0ce2fdcc5d368ccd5e96b49e3c13200d","Implantable medical devices such as cardiac pacemakers have been recalled frequently with safety related issues. This paper proposes a model driven approach for pacemaker design by combining the strengths of two well-known philosophies for safety critical systems. First, we adopt the SCCharts synchronous language for pacemaker specification. Second, we adopt a PRET architecture for the underlying processor which has been modified to include reactive semantics. PRET processors offer an ideal platform for providing timing guarantees. We use automatic code generation combined with static timing analysis during the design phase. Also, we use an existing emulation model of the human heart using a 33-node conduction network for closed loop validation of the designed pacemaker. © 2017 IEEE.","heart; pacemaker; pret; processor design; reactive; sccharts","Automatic programming; Biomedical equipment; Closed loop control systems; Distributed computer systems; Heart; Integrated circuit design; Philosophical aspects; Safety engineering; Semantics; Systems analysis; Automatic code generations; Closed-loop validation; Implantable medical devices; pret; Processor design; reactive; Safety critical systems; sccharts; Pacemakers",2-s2.0-85026771415
"Hohenstein U., Koka P.","Reusable components for adding multi-tenancy to legacy applications",2017,"Proceedings - 2017 15th IEEE/ACIS International Conference on Software Engineering Research, Management and Applications, SERA 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026665063&doi=10.1109%2fSERA.2017.7965727&partnerID=40&md5=abc12a8ccd609d4251db6a4cadbbe1d5","Applications offered as Software-as-a-Service should pursue a multi-tenant architecture in order to be profitable. Multi-tenancy helps to reduce the number of application instances by sharing resources amongst several tenants, thus saving operational costs, particularly in public cloud environments. While research mostly discusses how to design green-field software in a multi-tenant manner, this paper focuses on moving existing brown-field software into the Cloud thereby adding multi-tenancy. A low-effort approach is presented to leave the legacy application's source code unchanged. Only a couple of additional components have to be added taking care of multi-tenancy. Applying the aspect-oriented language AspectJ, we evaluate in a case study that such an approach is feasible: Tenant management, tenant-specific authentication, data isolation among multiple tenants for various database servers and strategies, and tenant-specific customization by modifying existing behavior can be achieved. These multi-tenancy features are provided in a reusable and modular framework that helps to apply them to other applications with a few lines of codes. © 2017 IEEE.","Aspect-orientation; AspectJ; Case study; Cloud migration; Industrial application; Multi-tenancy; SaaS","Computer software reusability; Engineering research; Green computing; Industrial applications; Object oriented programming; Software as a service (SaaS); Software engineering; Aspect orientation; Aspect-J; Cloud migrations; Multi tenancies; SaaS; Application programs",2-s2.0-85026665063
"García A.C., Lancho R.S., Aleaga A.M.L., Rodríguez A.C., Leyva L.L.L.","Intelligent adaptation of Axisymmetric Solid Parts in machining process planning by case based reasoning",2017,"International Journal of Intelligent Engineering and Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019234163&doi=10.22266%2fijies2017.0630.27&partnerID=40&md5=cfb62d0f51b685dc9c8f722878ddd730","The goal of this paper is the adaptation of plans of manufacturing processes of Axisymmetric Solid Parts under the approach of Case Based Reasoning (CBR). To this end, a data model for feature-based representation has been developed, which contains the geometric, dimensional and technological information required for the preparation of the one-piece process plan. As a result, an algorithm to generate new parts process plans from a similar plan retrieved from the case base is presented, which is based on the specific information of the Primitive Form Features (PFF) and considers the possible interaction between neighboring PFFs. The computer support of the developed algorithm was implemented in AutoLISP as programming language of the CAD system used and the interface was created in OpenDCL.","CAD/CAPP system; CBR; Cutting schemes; Form features; Geometric information",,2-s2.0-85019234163
"Mohdfazalulhaque S., Srikanth V., Reddy E.S.","Detection of logical clone in code using data dependency and expression list",2017,"Journal of Theoretical and Applied Information Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021718089&partnerID=40&md5=61f9e0c8aec1d639dd7bf9cc5e6ed702","Code plagiarism is a main issue in various institutes and software industries. We don’t have a perfect approach in detecting the code copied. In various countries like INDIA, USA and UK majority of industries and institutes have gained their own tool for detection of code plagiarism. The developed tools will identify the code program similarities based on statements written in programming language. Our proposed work is to develop an approach which detects the dependencies based on data. We consider data program for tracking similarities on code. The list of expression and data dependencies are detected based on code copied. We prepared a dependency matrix which checks the dependencies of data in the program and compares with the list using efficient method. © 2005 – ongoing JATIT & LLS.","Code cloning; Dependency data; Detection; List related to expression; Method of matrix",,2-s2.0-85021718089
[No author name available],"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026754636&partnerID=40&md5=283b35efba0f4d76db3a3fb143963da9","The proceedings contain 167 papers. The topics discussed include: DroidBot: DroidBot: a lightweight UI-guided test input generator for android; fast and flexible large-scale clone detection with CloneWorks; studying multi-threaded behavior with TSViz; cheetah: just-in-time taint analysis for Android apps; statistical migration of API usages; surf: summarizer of user reviews feedback; CSSDev: refactoring duplication in cascading style sheets; bottom-up technologies for reuse: automated extractive adoption of software product lines; JSDeodorant: class-awareness for JavaScript programs; decision-making in self-protecting software systems: a game-theoretic approach; empirical investigation of correlation between rewards and crowdsource-based software developers; improving test execution time with improved cache locality; live programming the behavioral layer of robot; runtime collaborative-based configuration of software product lines; obsidian: a safer blockchain programming language; a formally verified sequentializer for lustre-like concurrent synchronous data-flow programs; a framework to preserve confidentiality in crowdsourced software development; a hierarchical architecture for distributed security control of large scale systems; and a machine learning approach for determining the validity of traceability links.",,,2-s2.0-85026754636
"Memon A., Gao Z., Nguyen B., Dhanda S., Nickell E., Siemborski R., Micco J.","Taming google-scale continuous testing",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering: Software Engineering in Practice Track, ICSE-SEIP 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026802755&doi=10.1109%2fICSE-SEIP.2017.16&partnerID=40&md5=2ab31637d5a6cf11622c7062c7ff7992","Growth in Google's code size and feature churn rate has seen increased reliance on continuous integration (CI) and testing to maintain quality. Even with enormous resources dedicated to testing, we are unable to regression test each code change individually, resulting in increased lag time between code check-ins and test result feedback to developers. We report results of a project that aims to reduce this time by: (1) controlling test workload without compromising quality, and (2) distilling test results data to inform developers, while they write code, of the impact of their latest changes on quality. We model, empirically understand, and leverage the correlations that exist between our code, test cases, developers, programming languages, and code-change and test-execution frequencies, to improve our CI and development processes. Our findings show: Very few of our tests ever fail, but those that do are generally 'closer' to the code they test, certain frequently modified code and certain users/tools cause more breakages, and code recently modified by multiple developers (more than 3) breaks more often. © 2017 IEEE.","continuous integration; selection; software testing","Codes (symbols); Integration testing; Software engineering; Churn rates; Code changes; Continuous integrations; Continuous testing; Development process; Regression tests; selection; Test execution; Software testing",2-s2.0-85026802755
"Alnawasreh K., Pelliccione P., Hao Z., Range M., Bertolino A.","Online robustness testing of distributed embedded systems: An industrial approach",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering: Software Engineering in Practice Track, ICSE-SEIP 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026844028&doi=10.1109%2fICSE-SEIP.2017.17&partnerID=40&md5=11d661160b9f8930bc03cf2e96bd7b3a","Having robust systems that behave properly even in presence of faults is becoming increasingly important. This is the case of the system we investigate in this paper, which is an embedded distributed system consisting of components that communicate with each other via messages exchange in the RBS (Radio Based Station) at Ericsson AB in Gothenburg, Sweden. Specifically, this paper describes a novel fault injection approach for testing the robustness of distributed embedded systems with very limited computation power. The new approach is inspired by Netflix's ChaosMonkey, a fault injection approach that has been developed for testing distributed systems hosted in the cloud. However, ChaosMonkey cannot be used in the context of RBS since the latter consists of small-embedded components with specific requirements of performance, programming language, and communication paradigm. This paper reports about the approach called Postmonkey we developed, illustrates the results of applying it to RBS, and discusses the potential of utilizing fault injection to test complex, embedded, and distributed systems. The approach and tool are now adopted by Ericsson. © 2017 IEEE.","distributed embedded systems; fault injection; online testing","Embedded systems; Online systems; Software engineering; Software testing; Communication paradigm; Computation power; Distributed embedded system; Distributed systems; Embedded components; Fault injection; On-line testing; Robustness testing; Distributed computer systems",2-s2.0-85026844028
"Hnaif A.A., El-Obaid A., Al-Ramahi N.","Traffic light management system based on Hamiltonian Routing Technique",2017,"Journal of Theoretical and Applied Information Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021760940&partnerID=40&md5=319db25becf1fbcd2ff78106a959bcf5","Traffic congestions are recognized as a major problem in the modern urban cities. The Hashemite Kingdom of Jordan is considered as one of the top countries worldwide that is suffering from the traffic jam problem due to its old infrastructure. The current traffic light signals system in Jordan is still controlled by the fixed timers. Therefore, this research develops an intelligent Traffic Light Management System Based on the Hamiltonian Routing Technique (TLBH) and on the Decision Support System (DSS) in order to execute a proper action. Hence, this research develops a system can that be used to minimize the waiting time on the traffic signals for vehicles, which can in return lead to the reduction of the traffic congestion incurred by the vehicles. This research is comprehensive to many scenarios, where three of these scenarios are listed in this research and are implemented by the system by using the MATLAB programming language; based on specific rules. According to these sufficient testing scenarios, the simulation result shows significant improvements in the TLBH technique in comparison with the current traffic system. The proposed technique has the minimum total and waiting time in all scenarios compared to the current traffic system. © 2005 – ongoing JATIT & LLS.","Hamiltonian routing technique; Routing protocols; Traffic light management system",,2-s2.0-85021760940
"Rodchenko A., Kotselidis C., Nisbet A., Pop A., Lujan M.","Type Information Elimination from Objects on Architectures with Tagged Pointers Support",2017,"IEEE Transactions on Computers",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022182477&doi=10.1109%2fTC.2017.2709739&partnerID=40&md5=83a4a2e328f84616ef19b5be56a7dc7d","Implementations of object-oriented programming languages associate type information with each object to perform various runtime tasks such as dynamic dispatch, type introspection, and reflection. A common means of storing such relation is by inserting a pointer to the associated type information into every object. Such an approach, however, introduces memory and performance overheads when compared with non-object-oriented languages. CCBY","Hardware; high-level language architectures; Java; Layout; Memory management; Metadata; Object oriented modeling; Runtime environments; simulation","Computer hardware; Computer programming languages; Computer software; High level languages; Java programming language; Memory architecture; Metadata; Modeling languages; Java; Layout; Memory management; Object oriented model; Runtime environments; simulation; Object oriented programming",2-s2.0-85022182477
"Leatongkam A., Nanthaamornphong A., Rouson D.W.","WIP: Generating Sequence Diagrams for Modern Fortran",2017,"Proceedings - 2017 IEEE/ACM 12th International Workshop on Software Engineering for Science, SE4Science 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026775675&doi=10.1109%2fSE4Science.2017.13&partnerID=40&md5=1162177ee7decd7c055a79a39d55e5c1","Fortran finds widespread use in scientific and engineering communities that embraced computing early, including weather and climate science and mechanical, nuclear, and aerospace engineering. Over its lifetime, Fortran has evolved to support multiple programming paradigms, including Object-Oriented Programming (OOP). Despite the recently burgeoning ecosystem of tools and libraries supporting modern Fortran, there remains limited support for generating common Object-Oriented Design (OOD) diagrams from Fortran source code. ForUML partially fills this need by reverse engineering Unified Modeling Language (UML) class diagrams from object-oriented (OO) Fortran programs. Class diagrams provide useful information about class structures and inter-relationships, but class diagrams do not convey the temporal information required to understand runtime class behavior and interactions. UML sequence diagrams provide such important algorithmic details. This paper proposes to extend ForUML to extract UML sequence diagrams from Fortran code and to offer this capability via a widely used open-source platform. The paper argues that the proposed capability can raise the level of abstraction at which the computational science community discusses modern Fortran. © 2017 IEEE.","computational science; modern Fortran; Object-oriented design; object-oriented programming; reverse engineering","Codes (symbols); Computer simulation languages; Engineering education; FORTRAN (programming language); Graphic methods; Modeling languages; Open source software; Open systems; Reverse engineering; Software engineering; Unified Modeling Language; Computational science; Engineering community; Object oriented design; Objectoriented programming (OOP); Open source platforms; Programming paradigms; UML sequence diagrams; Unified modeling language class diagrams; Object oriented programming",2-s2.0-85026775675
"Petke J., Harman M., Langdon W.B., Weimer W.","Specialising Software for Different Downstream Applications Using Genetic Improvement and Code Transplantation",2017,"IEEE Transactions on Software Engineering",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023741332&doi=10.1109%2fTSE.2017.2702606&partnerID=40&md5=7ed07a5d5f0ff0fdb634096a41e0e9ab","Genetic improvement uses computational search to improve existing software while retaining its partial functionality. Genetic improvement has previously been concerned with improving a system with respect to all possible usage scenarios. In this paper, we show how genetic improvement can also be used to achieve specialisation to a specific set of usage scenarios. We use genetic improvement to evolve faster versions of a C++ program, a Boolean satisfiability solver called MiniSAT, specialising it for three applications. Our specialised solvers achieve between 4% and 36% execution time improvement, which is commensurate with efficiency gains achievable using human expert optimisation for the general solver. We also use genetic improvement to evolve faster versions of an image processing tool called ImageMagick, utilising code from GraphicsMagick, another image processing tool which was forked from it. We specialise the format conversion functionality to black &amp; white images and colour images only. Our specialised versions achieve up to 3% execution time improvement. OAPA","C++ languages; code specialisation; code transplants; genetic improvement; Genetic programming; GI; GraphicsMagick; Image processing; ImageMagick; Optimization; SAT; Software; Software engineering","Application programs; Codes (symbols); Computer programming; Computer software; Genetic algorithms; Genetic programming; Geographic information systems; Image processing; Optimization; Software engineering; C++ language; Genetic improvements; GraphicsMagick; ImageMagick; Specialisation; C++ (programming language)",2-s2.0-85023741332
"Chiw C., Kindlmann G., Reppy J.","DATm: Diderot's automated testing model",2017,"Proceedings - 2017 IEEE/ACM 12th International Workshop on Automation of Software Testing, AST 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026737522&doi=10.1109%2fAST.2017.5&partnerID=40&md5=9d31f2774002ead981583029ccc63e8e","Diderot is a parallel domain-specific language forthe analysis and visualization of multidimensional scientific images, such as those produced by CT and MRI scanners. Diderot is designed to support algorithms that are based on differential tensor calculus and produces a higher-order mathematical model which allows direct manipulation of tensor fields. One of the main challenges of the Diderot implementation is bridging this semantic gap by effectively translating high-level mathematical notation of tensor calculus into efficient low-level code in the target language. A key question for a high-level language, such as Diderot, is how do we know that the implementation is correct. We have previously presented and defended a core set of rewriting rules, but the full translation from source to executable requires much more work. In this paper, we present DATm, Diderot's automated testing model to check the correctness of the core operations in the programming language. DATm can automatically create test programs, and predict what the outcome should be. We measure the accuracy of the computations written in the Diderot language, based on how accurately the output of the program represents the mathematical equivalent of the computations. This paper describes a model for testing a high-level language based on correctness. It introduces the pipeline for DATm, a tool that can automatically create and test tens of thousands of Diderot test programs and that has found numerous bugs. We make a case for the necessity of extensive testing by describing bugs that are deep in the compiler, and only could be found with a unique application of operations. Lastly, we demonstrate that the model can be used to create other types of tests by visual verification. © 2017 IEEE.","Diderot; domain specific testing; DSL; tensor calc; visual verificaiton","Automation; Calculations; Computer programming languages; Computerized tomography; Differentiation (calculus); DSL; High level languages; Magnetic resonance imaging; Problem oriented languages; Program debugging; Semantics; Tensors; Translation (languages); Diderot; Direct manipulation; Domain specific languages; Domain-specific testing; Mathematical notations; Scientific images; visual verificaiton; Visual verification; Software testing",2-s2.0-85026737522
"Jannesari A., Ul Huda Z., Atre R., Li Z., Wolf F.","Parallelizing audio analysis applications - A case study",2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering: Software Engineering and Education Track, ICSE-SEET 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026748835&doi=10.1109%2fICSE-SEET.2017.9&partnerID=40&md5=583e52af47dd52b4d2b81ba75c8d438a","As multicore computers become widespread, the need for software programmers to decide on the most effective parallelization techniques becomes very prominent. In this case study, we examined a competition in which four teams of graduate students parallelized two sequential audio analysis applications. The students were introduced with PThreads, OpenMP and TBB parallel programming models. Use of different profiling and debugging tools was also taught during this course. Two of the teams parallelized libVorbis audio encoder and the other two parallelized the LAME encoding engine. The strategies used by the four teams to parallelize these applications included the use of taught programming models, focusing on both fine-grained and coarse-grained parallelism. These strategies are discussed in detail along with the tools utilized for the development and profiling. An analysis of the results obtained is also performed to discuss speedups and audio quality of the encoded output. A list of the lessons to be remembered while parallelizing an application has been provided as well. These lessons include best pedagogical methods, importance of understanding the program before choosing a programming model, concentrating on coarse-grained parallelism first, looking for dependency relaxation, parallelism beyond the predefined language constructs, the need of practice or prior experience in parallel programming and the need for assisting tools in parallelization. © 2017 IEEE.","Parallelizing existing sequential applications; Project based Parallelization; Teaching parallel programming","Application programming interfaces (API); Computer software; Education; Education computing; Engineering education; Parallel programming; Quality control; Signal encoding; Software engineering; Students; Teaching; Graduate students; Language constructs; Parallel programming model; Parallelization techniques; Parallelizations; Pedagogical method; Programming models; Sequential applications; Program debugging",2-s2.0-85026748835
"Osman H., Chis A., Corrodi C., Ghafari M., Nierstrasz O.","Exception Evolution in Long-Lived Java Systems",2017,"IEEE International Working Conference on Mining Software Repositories",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026514772&doi=10.1109%2fMSR.2017.21&partnerID=40&md5=ea8cea59215ef2ed328b0a431514dd9d","Exception handling allows developers to deal with abnormal situations that disrupt the execution flow of a program. There are mainly three types of exceptions: standard exceptions provided by the programming language itself, custom exceptions defined by the project developers, and third-party exceptions defined in external libraries. We conjecture that there are multiple factors that affect the use of these exception types. We perform an empirical study on long-lived Java projects to investigate these factors. In particular, we analyze how developers rely on the different types of exceptions in throw statements and exception handlers. We confirm that the domain, the type, and the development phase of a project affect the exception handling patterns. We observe that applications have significantly more error handling code than libraries and they increasingly rely on custom exceptions. Also, projects that belong to different domains have different preferences of exception types. For instance, content management systems rely more on custom exceptions than standard exceptions whereas the opposite is true in parsing frameworks. © 2017 IEEE.","Empirical study; Exception handling; Software evolution","Libraries; Content management system; Empirical studies; Error handling codes; Exception handlers; Exception handling; Exception handling patterns; Project developers; Software Evolution; Java programming language",2-s2.0-85026514772
"Brandauer S., Wrigstad T.","Spencer: Interactive heap analysis for the masses",2017,"IEEE International Working Conference on Mining Software Repositories",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026525638&doi=10.1109%2fMSR.2017.35&partnerID=40&md5=dd5e900886510b22eecde2ffcd526fa5","Programming language-design and run-Time-implementation require detailed knowledge about the programs that users want to implement. Acquiring this knowledge is hard, and there is little tool support to effectively estimate whether a proposed tradeoff actually makes sense in the context of real world applications. Ideally, knowledge about behaviour of 'typical' programs is 1) easily obtainable, 2) easily reproducible, and 3) easily sharable. We present Spencer, an open source web service and APIframework for dynamic analysis of a continuously growing set of traces of standard program corpora. Users do not obtain traces on their own, but can instead send queries to the web service that will be executed on a set of program traces. Queries are built in terms of a set of query combinators that present a high level interface for working with trace data. Since the framework is high level, and there is a hosted collection of recorded traces, queries are easy to implement. Since the data sets are shared by the research community, results are reproducible. Since the actual queries run on one (or many) servers that provide analysis as a service, obtaining results is possible on commodity hardware. Data in Spencer is meant to be obtained once, and analysed often, making the overhead of data collection mostly irrelevant. This allows Spencer to collect more data than traditional tracing tools can afford within their performance budget. Results in Spencer are cached, making complicated analyses that build on cached primitive queries speedy. © 2017 IEEE.","Dynamic Analysis; Heap Analysis; Tracing","Budget control; Dynamic analysis; Open source software; Web services; Websites; Commodity hardware; Data collection; Heap Analysis; High level interface; Performance budget; Programming language design; Research communities; Tracing; Data acquisition",2-s2.0-85026525638
"Oliveira W., Oliveira R., Castor F.","A study on the energy consumption of android app development approaches",2017,"IEEE International Working Conference on Mining Software Repositories",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026543643&doi=10.1109%2fMSR.2017.66&partnerID=40&md5=9449d636be2563cf723d09dc17689e9a","Mobile devices have become ubiquitous in the recent years, but the complaints about energy consumption are almost universal. On Android, the developer can choose among several different approaches to develop an app. In this paper, we investigate the impact of some of the most popular development approaches on the energy consumption of Android apps. Our study uses a testbed of 33 different benchmarks and 3 applications on 5 different devices to compare the energy efficiency and performance of the most commonly used approaches to develop apps on Android: Java, JavaScript, and C/C++ (through the NDK tools). In our experiments, Javascript was more energy-efficient in 75% of all benchmarks, while their Java counterparts consume up to 36.27x more energy (median of 1.97x). On the other hand, both Java and C++ outperformed JavaScript in most of the benchmarks. Based on these results, four Java applications were re-engineered to use a combination of Java and either JavaScript or C/C++ functions. For one of the apps, the hybrid solution using Java and C++ spent 10x less time and almost 100x less energy than a pure Java solution. The results were not uniform, however. For another app, when we restructured its implementation so as to minimize cross-language method invocations, the hybrid solution using Java and C++ took 8% longer to execute and consumed 11% more energy than a hybrid solution using Java and JavaScript. Since most Android apps are written solely in Java, the results of this study indicate that leveraging a combination of approaches may lead to non-negligible improvements in energy-efficiency and performance. © 2017 IEEE.","Android; Benchmark Testing; Energy Consumption; Hybrid Apps; Performance; Smartphones","Benchmarking; C++ (programming language); Energy efficiency; Energy utilization; High level languages; Smartphones; Android; Benchmark testing; Development approach; Efficiency and performance; Energy efficient; Java applications; Method invocation; Performance; Android (operating system)",2-s2.0-85026543643
"Ali F., Kwak D., Khan P., Ei-Sappagh S.H.A., Islam S.M.R., Park D., Kwak K.-S.","Merged Ontology and SVM-Based Information Extraction and Recommendation System for Social Robots",2017,"IEEE Access",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021968653&doi=10.1109%2fACCESS.2017.2718038&partnerID=40&md5=1e19516d53c7ed6381af61c527c82a97","The recent technology of human voice capture and interpretation has spawned the social robot to convey information and to provide recommendations. This technology helps people obtain information about a particular topic after giving an oral query to a humanoid robot. However, most of the search engines are keyword-matching mechanism-based, and the existing full-text query search engines are inadequate at retrieving relevant information from various oral queries. With only predefined words and sentence-based recommendations, a social robot may not suggest the correct items, if items retrieved along with the information are not predefined. In addition, the available conventional ontology-based systems cannot extract precise data from webpages to show the correct results. In this regard, we propose a merged ontology and support vector machine (SVM)-based information extraction and recommendation system. In the proposed system, when a humanoid robot receives an oral query from a disabled user, the oral query changes into a full-text query, the system mines the full-text query to extract the disabled user's needs, and then converts the query into the correct format for a search engine. The proposed system downloads a collection of information about items (city features, diabetes drugs, and hotel features). The SVM identifies the relevant information on the item and removes anything irrelevant. Merged ontology-based sentiment analysis is then employed to find the polarity of the item for recommendation. The system suggests items with a positive polarity term to the disabled user. The intelligent model and merged ontology were designed by employing Java and Protégé Web Ontology Language 2 software, respectively. Experimentation results show that the proposed system is highly productive when analyzing retrieved information, and provides accurate recommendations. © 2017 IEEE.","full-text-query mining; information extraction; Ontology; recommendation system; social robotics","Anthropomorphic robots; Artificial intelligence; Computer software; Data mining; Feature extraction; Information analysis; Information retrieval; Internet; Java programming language; Ontology; Recommender systems; Robotics; Robots; Support vector machines; Intelligent modeling; Key word matching; Ontology-based systems; Positive polarity; Sentiment analysis; Social robotics; Text query; Web ontology language; Search engines",2-s2.0-85021968653
"Jallouli O., Assad S.E., Chetto M., Lozi R.","Design and analysis of two stream ciphers based on chaotic coupling and multiplexing techniques",2017,"Multimedia Tools and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021698823&doi=10.1007%2fs11042-017-4953-x&partnerID=40&md5=ec02feedc3d237e50dc6fdcbcf536aee","In this paper, we design and implement two new stream ciphers based on Pseudo Chaotic Number Generators (PCNGs) which integrate discrete chaotic maps, namely, Piecewise Linear Chaotic Map (PWLCM), Skewtent and Logistic map. They are weakly coupled by a predefined matrix A for the first PCNG and they are coupled by a binary diffusion matrix D for the second one. Each PCNG includes a chaotic multiplexing technique that allows the enhancement of the robustness of the system. The structure is implemented with finite precision N = 32 bits in C language. Security performance of the proposed stream ciphers is analysed and several cryptanalytic and statistical tests are applied. Experimental results highlight robustness as well as efficiency in terms of computation time of these two stream ciphers. © 2017 Springer Science+Business Media, LLC","Chaos-based cryptography; Coupling and multiplexing techniques; Discrete chaotic maps; Pseudo-chaotic number generator; Stream cipher","C (programming language); Chaotic systems; Cryptography; Lyapunov methods; Number theory; Piecewise linear techniques; Chaos-based cryptography; Discrete chaotic maps; Multiplexing techniques; Number generator; Stream Ciphers; Matrix algebra",2-s2.0-85021698823
"Shatnawi A., Mili H., El Boussaidi G., Boubaker A., Gueheneuc Y.-G., Moha N., Privat J., Abdellatif M.","Analyzing program dependencies in Java EE applications",2017,"IEEE International Working Conference on Mining Software Repositories",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026508847&doi=10.1109%2fMSR.2017.6&partnerID=40&md5=ae242402357577e0e5decbf4b62ebf96","Program dependency artifacts such as call graphs help support a number of software engineering tasks such as software mining, program understanding, debugging, feature location, software maintenance and evolution. Java Enterprise Edition (JEE) applications represent a significant part of the recent legacy applications, and we are interested in modernizing them. This modernization involves, among other things, analyzing dependencies between their various components/tiers. JEE applications tend to be multilanguage, rely on JEE container services, and make extensive use of late binding techniques-All of which makes finding such dependencies difficult. In this paper, we describe some of these difficulties and how we addressed them to build a dependency call graph. We developed our tool called DeJEE (Dependencies in JEE) as an Eclipse plug-in. We applied DeJEE on two open-source JEE applications: Java PetStore and JSP Blog. The results show that DeJEE is able to identify different types of JEE dependencies. © 2017 IEEE.","Code Analysis; Container Services; Java EE application; Modernization; Program Dependency; Server Pages","Application programs; Computer software; Containers; Java programming language; Modernization; Open source software; Software engineering; XML; Code analysis; Feature location; Java EE; Legacy applications; Program Dependency; Program understanding; Software maintenance and evolution; Software minings; Program debugging",2-s2.0-85026508847
"Rausch T., Hummer W., Leitner P., Schulte S.","An Empirical Analysis of Build Failures in the Continuous Integration Workflows of Java-Based Open-Source Software",2017,"IEEE International Working Conference on Mining Software Repositories",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026529844&doi=10.1109%2fMSR.2017.54&partnerID=40&md5=d0decd936e13eafc3efc87436c600f47","Continuous Integration (CI) has become a common practice in both industrial and open-source software development. While CI has evidently improved aspects of the software development process, errors during CI builds pose a threat to development efficiency. As an increasing amount of time goes into fixing such errors, failing builds can significantly impair the development process and become very costly. We perform an indepth analysis of build failures in CI environments. Our approach links repository commits to data of corresponding CI builds. Using data from 14 open-source Java projects, we first identify 14 common error categories. Besides test failures, which are by far the most common error category (up to >80% per project), we also identify noisy build data, e.g., induced by transient Git interaction errors, or general infrastructure flakiness. Second, we analyze which factors impact the build results, taking into account general process and specific CI metrics. Our results indicate that process metrics have a significant impact on the build outcome in 8 of the 14 projects on average, but the strongest influencing factor across all projects is overall stability in the recent build history. For 10 projects, more than 50% (up to 80%) of all failed builds follow a previous build failure. Moreover, the fail ratio of the last k=10 builds has a significant impact on build results for all projects in our dataset. © 2017 IEEE.","build errors; continuous integration; correlation analysis; mining software repositories","Computer software; Errors; Integration; Java programming language; Open systems; Software design; Software engineering; Continuous integrations; Correlation analysis; Development process; Empirical analysis; In-depth analysis; Mining software repositories; Overall stabilities; Software development process; Open source software",2-s2.0-85026529844
"Hanna L., Kucheryavy P., Liu C., Zhang X., Lockard J.V.","Long-Lived Photoinduced Charge Separation in a Trinuclear Iron-μ3-oxo-based Metal-Organic Framework",2017,"Journal of Physical Chemistry C",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022175049&doi=10.1021%2facs.jpcc.7b03936&partnerID=40&md5=a15653adb6af4f069f120b79f9a3ae19","The presence of long-lived charge-separated excited states in metal-organic frameworks (MOFs) can enhance their photocatalytic activity by decreasing the probability that photogenerated electrons and holes recombine before accessing adsorbed reactants. Detecting these charge-separated states via optical transient absorption, however, can be challenging when they lack definitive optical signatures. We investigate the long-lived excited state of a MOF with such vague optical properties, MIL-100(Fe), composed of Fe3-μ3-oxo clusters and trimesic acid linkers, using Fe K-edge X-ray transient absorption (XTA) spectroscopy to unambiguously determine its ligand-to-metal charge-transfer character. Spectra measured at time delays up to 3.6 μs confirm the long-lived nature of the charge-separated excited state. Several trinuclear iron μ3-oxo carboxylate complexes, which model the trinuclear cores of the MOF structure, are measured for comparison using both steady-state X-ray absorption spectroscopy and XTA to further support this assignment and corresponding decay time. The MOF is prepared as a colloidal nanoparticle suspension for these measurements, so both its fabrication and particle size analysis are presented as well. © 2017 American Chemical Society.",,"Carboxylation; Crystalline materials; Iron compounds; Java programming language; Optical properties; Particle size; Particle size analysis; Separation; Suspensions (fluids); X ray absorption spectroscopy; Charge-separated state; Colloidal nanoparticles; Ligand-to-metal charge transfers; Metal organic framework; Metalorganic frameworks (MOFs); Photocatalytic activities; Photogenerated electrons; Photoinduced charge separation; Excited states",2-s2.0-85022175049
"Tajeddin S., Azad N.L.","Ecological Cruise Control of a Plug-in Hybrid Electric Vehicle: A comparison of different GMRES-based Nonlinear Model Predictive Controls",2017,"Proceedings of the American Control Conference",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027050918&doi=10.23919%2fACC.2017.7963505&partnerID=40&md5=576cc1c0219785d95ba50174c7875559","Recently, there has been a growing interest in integrating NMPC in automotive applications in order to make driving more intelligent and ecological. One major challenge in the way of developing Nonlinear Model Predictive Controllers for automotive systems is to reach sub-millisecond computation times for real-time applications. C/GMRES and Newton/GMRES are fast optimization methods demonstrating promising results. This paper develops an Ecological Cruise Control for a Plug-in Hybrid Electric Vehicle, and then presents a comparison between the two aforementioned optimizers in terms of accuracy and speed. Simulation results tested on a high-fidelity model of Toyota Prius in Autonomie identify C/GMRES method slightly faster than Newton/GMRES method with approximately the same accuracy in the solution. © 2017 American Automatic Control Council (AACC).","Automatic Code Generator; C/GMRES; Ecological Cruise Control; Newton/GMRES; Nonlinear Model Predictive Control","C (programming language); Distillation columns; Ecology; Electric machine control; Hybrid vehicles; Model predictive control; Nonlinear systems; Plug-in hybrid vehicles; Predictive control systems; Real time systems; Automatic code generators; Automotive applications; Automotive Systems; Fast optimizations; High fidelity models; Nonlinear model predictive control; Plug in hybrid electric vehicles; Real-time application; Cruise control",2-s2.0-85027050918
"Leahy K.J., Aksaray D., Belta C.","Informative path planning under temporal logic constraints with performance guarantees",2017,"Proceedings of the American Control Conference",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027032442&doi=10.23919%2fACC.2017.7963223&partnerID=40&md5=fd52504f4f2f5f1b2f33248e3c08de71","In this work we consider an agent trying to maximize a submodular reward function while moving in a graph environment. Such reward functions can be used to capture a variety of crucial sensing objectives in robotics including, but not limited to, mutual information and entropy. Furthermore, the agent must satisfy a mission specified by temporal logic constraints, which can encode many rich and complex missions such as 'visit regions A or B, then visit C, infinitely often. Never visit D before visiting C.' We present an algorithm to maximize a submodular reward function under these constraints and provide an approximation for the performance of the proposed algorithm. The results are validated via simulation. © 2017 American Automatic Control Council (AACC).",,"Approximation algorithms; C (programming language); Motion planning; Temporal logic; Complex mission; Logic constraints; Mutual informations; Performance guarantees; Reward function; Submodular; Computer circuits",2-s2.0-85027032442
"Pascarella L., Bacchelli A.","Classifying Code Comments in Java Open-Source Software Systems",2017,"IEEE International Working Conference on Mining Software Repositories",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026557759&doi=10.1109%2fMSR.2017.63&partnerID=40&md5=8a9441edf6d25de142f901c1a708a179","Code comments are a key software component containing information about the underlying implementation. Several studies have shown that code comments enhance the readability of the code. Nevertheless, not all the comments have the same goal and target audience. In this paper, we investigate how six diverse Java OSS projects use code comments, with the aim of understanding their purpose. Through our analysis, we produce a taxonomy of source code comments, subsequently, we investigate how often each category occur by manually classifying more than 2,000 code comments from the aforementioned projects. In addition, we conduct an initial evaluation on how to automatically classify code comments at line level into our taxonomy using machine learning, initial results are promising and suggest that an accurate classification is within reach. © 2017 IEEE.","comment taxonomy; software quality; source code comments","Codes (symbols); Computer software; Computer software selection and evaluation; Java programming language; Learning systems; Open source software; Software engineering; Taxonomies; Open source software systems; Software component; Software Quality; Source code comments; Target audience; Open systems",2-s2.0-85026557759
"Ishio T., Sakaguchi Y., Ito K., Inoue K.","Source File Set Search for Clone-And-Own Reuse Analysis",2017,"IEEE International Working Conference on Mining Software Repositories",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026535951&doi=10.1109%2fMSR.2017.19&partnerID=40&md5=f53139130656df9cbb57a2845d71adfd","Clone-And-own approach is a natural way of source code reuse for software developers. To assess how known bugs and security vulnerabilities of a cloned component affect an application, developers and security analysts need to identify an original version of the component and understand how the cloned component is different from the original one. Although developers may record the original version information in a version control system and/or directory names, such information is often either unavailable or incomplete. In this research, we propose a code search method that takes as input a set of source files and extracts all the components including similar files from a software ecosystem (i.e., a collection of existing versions of software packages). Our method employs an efficient file similarity computation using b-bit minwise hashing technique. We use an aggregated file similarity for ranking components. To evaluate the effectiveness of this tool, we analyzed 75 cloned components in Firefox and Android source code. The tool took about two hours to report the original components from 10 million files in Debian GNU/Linux packages. Recall of the top-five components in the extracted lists is 0.907, while recall of a baseline using SHA-1 file hash is 0.773, according to the ground truth recorded in the source code repositories. © 2017 IEEE.","File clone detection; Origin analysis; Software reuse; Source code search","Cloning; Codes (symbols); Computer programming languages; Computer software reusability; Program debugging; Clone detection; Origin analysis; Security vulnerabilities; Similarity computation; Source code repositories; Source code searches; Version control system; Version information; Open source software",2-s2.0-85026535951
"Aivaloglou E., Hermans F., Moreno-Leon J., Robles G.","A dataset of scratch programs: Scraped, shaped and scored",2017,"IEEE International Working Conference on Mining Software Repositories",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026557031&doi=10.1109%2fMSR.2017.45&partnerID=40&md5=fd5d8c01c12e603e0030d4ce89ce27d3","Scratch is increasingly popular, both as an introductory programming language and as a research target in the computing education research field. In this paper, we present a dataset of 250K recent Scratch projects from 100K different authors scraped from the Scratch project repository. We processed the projects' source code and metadata to encode them into a database that facilitates querying and further analysis. We further evaluated the projects in terms of programming skills and mastery, and included the project scoring results. The dataset enables the analysis of the source code of Scratch projects, of their quality characteristics, and of the programming skills that their authors exhibit. The dataset can be used for empirical research in software engineering and computing education. © 2017 IEEE.","computing education; dataset; Scratch","Computer programming; Query processing; Software engineering; Computing education; dataset; Empirical research in software engineering; Introductory programming; Programming skills; Quality characteristic; Scratch; Source codes; Quality control",2-s2.0-85026557031
"Yang D., Martins P., Saini V., Lopes C.","Stack Overflow in Github: Any Snippets There?",2017,"IEEE International Working Conference on Mining Software Repositories",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026518178&doi=10.1109%2fMSR.2017.13&partnerID=40&md5=f34c59b0a87554a3396d764c204e96b3","When programmers look for how to achieve certain programming tasks, Stack Overflow is a popular destination in search engine results. Over the years, Stack Overflow has accumulated an impressive knowledge base of snippets of code that are amply documented. We are interested in studying how programmers use these snippets of code in their projects. Can we find Stack Overflow snippets in real projects? When snippets are used, is this copy literal or does it suffer adaptations? And are these adaptations specializations required by the idiosyncrasies of the target artifact, or are they motivated by specific requirements of the programmer? The large-scale study presented on this paper analyzes 909k non-fork Python projects hosted on Github, which contain 290M function definitions, and 1.9M Python snippets captured in Stack Overflow. Results are presented as quantitative analysis of block-level code cloning intra and inter Stack Overflow and GitHub, and as an analysis of programming behaviors through the qualitative analysis of our findings. © 2017 IEEE.","Code clone; Code reuse; Large-scale analysis","Behavioral research; Cloning; Codes (symbols); High level languages; Knowledge based systems; Search engines; Code clone; Code reuse; Function definitions; Large-scale analysis; Large-scale studies; Programming tasks; Qualitative analysis; Search engine results; Computer programming",2-s2.0-85026518178
"Aprajita, Luthra S., Mussbacher G.","Specifying Evolving Requirements Models with TimedURN",2017,"Proceedings - 2017 IEEE/ACM 9th International Workshop on Modelling in Software Engineering, MiSE 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026833071&doi=10.1109%2fMiSE.2017.10&partnerID=40&md5=c97247dde87ec82477f5429a042d39fd","The User Requirements Notation (URN) supports the elicitation, specification, and analysis of integrated goal and scenario models. The analysis of the goal and scenario models focuses on one snapshot in time and does not allow the model to change over time. While several models may be created that represent different stages of a system, managing several, slightly different model copies is a space-consuming, time-consuming, and error-prone task that makes it difficult to maintain consistency across the model copies. This paper introduces TimedURN, an extension of the URN standard, which enables the modeling and analysis of a comprehensive set of changes to a goal and scenario model over time. The changes to the model are captured in one base model, which eases system evolution. The metamodel for TimedURN is presented and it is argued that it can also be applied to other modeling languages. Furthermore, the usefulness of TimedURN is illustrated with an example from the sustainability domain and the comprehensiveness of the supported types of changes is assessed. © 2017 IEEE.","analysis; evaluation mechanism; evolution; goal modeling; Goal-oriented Requirement Language; GRL; scenario modeling; traversal mechanism; UCM; URN; Use Case Maps; User Requirements Notation","Object oriented programming; Software engineering; analysis; evolution; Goal modeling; Goal-oriented requirement language; Scenario Modeling; Use case maps; User requirements notation; Modeling languages",2-s2.0-85026833071
"Tiwari N.M., Upadhyaya G., Nguyen H.A., Rajan H.","Candoia: A platform for building and sharing mining software repositories tools as apps",2017,"IEEE International Working Conference on Mining Software Repositories",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026506925&doi=10.1109%2fMSR.2017.56&partnerID=40&md5=f2fc4d0384ca3f2993adff23e575bcfa","We propose Candoia, a novel platform and ecosystemfor building and sharing Mining Software Repositories(MSR) tools. Using Candoia, MSR tools are built as apps, and Candoia ecosystem, acting as an appstore, allows effective sharing. Candoia platform provides, data extraction tools for curating custom datasets for user projects, and data abstractions for enabling uniform access to MSR artifacts from disparate sources, which makes apps portable and adoptable across diverse software project settings of MSR researchers and practitioners. The structured design of a Candoia app and the languages selected for building various components of a Candoia app promotes easy customization. To evaluate Candoia we have built over two dozen MSR apps for analyzing bugs, software evolution, project management aspects, and source code and programming practices showing the applicability of the platform for buildinga variety of MSR apps. For testing portability of apps acrossdiverse project settings, we tested the apps using ten popularproject repositories, such as Apache Tomcat, JUnit, Node.js, etc, and found that apps required no changes to be portable. We performed a user study to test customizability and we found that five of eight Candoia users found it very easy to customize an existing app. Candoia is available for download. © 2017 IEEE.","Candioa ecosystem; Candoia; Candoia exchange; MSR; MSR apps; MSR data","Ecology; Ecosystems; Project management; Candoia; Mining software repositories; Mining software repository (MSR); MSR data; Programming practices; Software Evolution; Software project; Structured design; Program debugging",2-s2.0-85026506925
"Kikas R., Gousios G., Dumas M., Pfahl D.","Structure and evolution of package dependency networks",2017,"IEEE International Working Conference on Mining Software Repositories",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026515162&doi=10.1109%2fMSR.2017.55&partnerID=40&md5=7902af45d2726ec5612620ed01dda5cd","Software developers often include available open-source software packages into their projects to minimize redundant effort. However, adding a package to a project can also introduce risks, which can propagate through multiple levels of dependencies. Currently, not much is known about the structure of open-source package ecosystems of popular programming languages and the extent to which transitive bug propagation is possible. This paper analyzes the dependency network structure and evolution of the JavaScript, Ruby, and Rust ecosystems. The reported results reveal significant differences across language ecosystems. The results indicate that the number of transitive dependencies for JavaScript has grown 60% over the last year, suggesting that developers should look more carefully into their dependencies to understand what exactly is included. The study also reveals that vulnerability to a removal of the most popular package is increasing, yet most other packages have a decreasing impact on vulnerability. The findings of this study can inform the development of dependency management tools. © 2017 IEEE.","Dependency Management; Mining Software Repositories; Software Ecosystems; Software Evolution","Ecology; Ecosystems; High level languages; Information dissemination; Open systems; Software engineering; Dependency networks; Management tool; Mining software repositories; Multiple levels; Open source package; Software developer; Software ecosystems; Software Evolution; Open source software",2-s2.0-85026515162
"Wan Z., Lo D., Xia X., Cai L.","Bug Characteristics in Blockchain Systems: A Large-Scale Empirical Study",2017,"IEEE International Working Conference on Mining Software Repositories",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026537029&doi=10.1109%2fMSR.2017.59&partnerID=40&md5=7e20f1a12f3f9b5ae7612293b2d05763","Bugs severely hurt blockchain system dependability. A thorough understanding of blockchain bug characteristics is required to design effective tools for preventing, detecting and mitigating bugs. We perform an empirical study on bug characteristics in eight representative open source blockchain systems. First, we manually examine 1,108 bug reports to understand the nature of the reported bugs. Second, we leverage card sorting to label the bug reports, and obtain ten bug categories in blockchain systems. We further investigate the frequency distribution of bug categories across projects and programming languages. Finally, we study the relationship between bug categories and bug fixing time. The findings include: (1) semantic bugs are the dominant runtime bug category, (2) frequency distributions of bug types show similar trends across different projects and programming languages, (3) security bugs take the longest median time to be fixed, (4) 35.71% performance bugs are fixed in more than one year, performance bugs take the longest average time to be fixed. © 2017 IEEE.","blockchain; Bug characteristics; Empirical study","Open source software; Open systems; Semantics; Block-chain; Bug characteristics; Effective tool; Empirical studies; Frequency distributions; Performance bugs; Security bugs; System dependability; Program debugging",2-s2.0-85026537029
"Beller M., Gousios G., Zaidman A.","Oops, My Tests Broke the Build: An Explorative Analysis of Travis CI with GitHub",2017,"IEEE International Working Conference on Mining Software Repositories",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026546946&doi=10.1109%2fMSR.2017.62&partnerID=40&md5=05b5449ef761fd90b05c5f6d6c6e3dbe","Continuous Integration (CI) has become a best practice of modern software development. Yet, at present, we have a shortfall of insight into the testing practices that are common in CI-based software development. In particular, we seek quantifiable evidence on how central testing is to the CI process, how strongly the project language influences testing, whether different integration environments are valuable and if testing on the CI can serve as a surrogate to local testing in the IDE. In an analysis of 2,640,825 Java and Ruby builds on Travis CI, we find that testing is the single most important reason why builds fail. Moreover, the programming language has a strong influence on both the number of executed tests, their run time, and proneness to fail. The use of multiple integration environments leads to 10% more failures being caught at build time. However, testing on Travis CI does not seem an adequate surrogate for running tests locally in the IDE. To further research on Travis CI with GitHub, we introduce TravisTorrent. © 2017 IEEE.",,"Integration; Integrodifferential equations; Software design; Software testing; Best practices; Build time; Continuous integrations; Integration environments; Multiple integrations; Running tests; Runtimes; Integration testing",2-s2.0-85026546946
"Ortega F.R., Bolivar S., Bernal J., Galvan A., Tarre K., Rishe N., Barreto A.","Towards a 3D Virtual Programming Language to increase the number of women in computer science education",2017,"2017 IEEE Virtual Reality Workshop on K-12 Embodied Learning through Virtual and Augmented Reality, KELVAR 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026392848&doi=10.1109%2fKELVAR.2017.7961558&partnerID=40&md5=0431aab3873b27c1e63cfdc5a27c22af","We propose a 3D Virtual Programming Language to provide an interactive tool for beginners and intermediate students. We believe that the direction of our research will help increase the recruitment and retention of women in CS. We developed an initial prototype and surveyed students to determine the figures that work best. Our results show that it is hard for CS students to provide clear 3D representations for programming concepts in some instances yet we were able to derive some common figures. © 2017 IEEE.","H.5.1 [Multimedia Information Systems]: Augmented reality - Mixed Reality; K.3.2 [Computer and Information Science Education]: Computer Science Education","Augmented reality; Computer programming; Computer programming languages; Education; Education computing; Students; Virtual reality; 3d representations; Computer Science Education; Interactive tool; Mixed reality; Programming concepts; E-learning",2-s2.0-85026392848
"Dewey K., Conrad P., Craig M., Morozova E.","Evaluating test suite effectiveness and assessing student code via constraint logic programming",2017,"Annual Conference on Innovation and Technology in Computer Science Education, ITiCSE",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029531678&doi=10.1145%2f3059009.3059051&partnerID=40&md5=572e00034b55127ab9a40777965db1ca","A good suite of test inputs is an indispensable tool both for manual and automated assessment of student submissions to programming assignments. Yet, without a way to evaluate our test suites, it is difficult to know how well we are doing, much less improve our practice. We present a technique for evaluating a hand-generated test suite by comparing its ability to find defects against that of a test suite generated automatically using Constraint Logic Programming (CLP). We describe our technique and present a case study using student submissions for an assignment from a second-year programming course. Our results show that a CLP-generated test suite was able to identify significant defects that the instructor-generated suite missed, despite having similar code coverage. © 2017 ACM.",,"Computer circuits; Computer programming languages; Defects; Education computing; Engineering education; Engineering research; Logic programming; Students; Technology transfer; Automated assessment; Code coverage; Constraint Logic Programming; Indispensable tools; Programming assignments; Programming course; Test inputs; Automatic test pattern generation",2-s2.0-85029531678
"Valdecantos H.A., Tarrit K., Mirakhorli M., Coplien J.O.","An Empirical Study on Code Comprehension: Data Context Interaction Compared to Classical Object Oriented",2017,"IEEE International Conference on Program Comprehension",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025120299&doi=10.1109%2fICPC.2017.23&partnerID=40&md5=11e13193c386ffd4ef6ff3160509627c","Source code comprehension affects software development - especially its maintenance - where code reading is one of the most time-consuming activities. A programming language, together with the programming paradigm it supports, is a strong factor that profoundly impacts how programmers comprehend code. We conducted a human-subject controlled experiment to evaluate comprehension of code written using the Data Context Interaction (DCI) paradigm relative to code written with commonly used Object-Oriented (OO) programming. We used a new research-level language called Trygve which implements DCI concepts, and Java, a pervasive OO language in the industry. DCI revisits lost roots of the OO paradigm to address problems that are inherent to Java and most other contemporary OO languages. We observed correctness, time consumption, and locality of reference during reading comprehension tasks. We present a method which relies on the Eigenvector Centrality metric from Social Network Analysis to study the locality of reference in programmers by inspecting their sequencing of reading language element declarations and their permanence time in the code. Results indicate that DCI code in Trygve supports more comprehensible code regarding correctness and improves the locality of reference, reducing context switching during the software discovery process. Regarding reading time consumption, we found no statistically significant differences between both approaches. © 2017 IEEE.","Controlled experiment; Data Context Interaction; Human subjects; Object-Oriented; Program comprehension; Programming languages; Programming paradigms","Codes (symbols); Computer programming; Computer programming languages; Java programming language; Software design; Controlled experiment; Data contexts; Human subjects; Object oriented; Program comprehension; Programming paradigms; Object oriented programming",2-s2.0-85025120299
"Basso F.P., Werner C.M.L., Oliveira T.C.","Automated Approach for Asset Integration in Eclipse IDE",2017,"Proceedings - 2017 IEEE/ACM Joint 5th International Workshop on Software Engineering for Systems-of-Systems and 11th Workshop on Distributed Software Development, Software Ecosystems and Systems-of-Systems, JSOS 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026396147&doi=10.1109%2fJSOS.2017.16&partnerID=40&md5=34ae8a43822db0ea2bf213874c02a7c6","Model Driven Development (MDD) tasks are used in different software development processes. These tasks are traditionally started with transformation engines. Adapting MDD tasks to be managed in Eclipse Mylyn instead of traditional solutions can facilitate the access to and use of MDD techniques and tools for other contexts in software development, such as agile teams. In a previous work we have introduced a new Domain Specific Language (DSL) named RAS++ used on the top of proposals for MDE Artifacts and Settings. This work adds technical-level information that allows to transform RAS++ specifications to the Eclipse Mylyn. Through a proof-of-concept, we show that RAS++ plays the role of a pivotal representation language between Eclipse IDE and Model-Driven Engineering (MDE) Ecosystems, pointing out new research directions. © 2017 IEEE.","Eclipse Mylyn; Ecosystem; Integration; Model Driven Development; Toolchain","Computer programming languages; Ecology; Ecosystems; Integration; Integrodifferential equations; Java programming language; Software engineering; Domain specific languages; Eclipse Mylyn; Model driven development; Model-driven Engineering; Representation languages; Software development process; Toolchain; Transformation engine; Software design",2-s2.0-85026396147
"Kaila E., Lindén R., Lokkila E., Laakso M.-J.","About programming maturity in finnish high schools: A comparison between high school and university students' programming skills",2017,"Annual Conference on Innovation and Technology in Computer Science Education, ITiCSE",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029502473&doi=10.1145%2f3059009.3059021&partnerID=40&md5=e99e8d5ad07998e41c976b8eafd43163","In this study, we compare students' ability to learn and master a variety of computer programming concepts in two different student groups. The first group consists of 64 university level students with various backgrounds (adult control), and the second group consists of 40 Finnish junior high school students of age 15 (adolescent treatment group). Neither group had significant prior programming experience. Both groups were taught a similar semester-long introductory course on Python programming, using the same learning management system (LMS). We find that for almost all of the concepts, both groups perform equally well, but students in the adolescent treatment group perform significantly worse when learning the concepts of loop structures and repetition. The results are further compared to the lecture surveys that were collected from the junior high school course to further explain the causes of the findings. Based on the results and the teaching methods that are presented in this paper, we are able to show that adolescent junior high school students and adult university students have similar abilities to learn abstract computer science concepts using a fully functional programming environment. © 2017 ACM.","Adolescence; Computer science education; Junior high school; Maturity; Python; Study habits; Teaching methods","Computer programming; Education; Education computing; Engineering education; Engineering research; Functional programming; High level languages; Speed control; Teaching; Adolescence; Computer Science Education; Junior high schools; Maturity; Python; Study habits; Teaching methods; Students",2-s2.0-85029502473
"Padua G.B.D., Shang W.","Studying the Prevalence of Exception Handling Anti-Patterns",2017,"IEEE International Conference on Program Comprehension",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025120726&doi=10.1109%2fICPC.2017.1&partnerID=40&md5=e10d9f5d1f913581a225d0ace5c1cbd8","Modern programming languages, such as Java and C#, typically provide features that handle exceptions. These features separate error-handling code from regular source code and are proven to enhance the practice of software reliability, comprehension, and maintenance. Having acknowledged the advantages of exception handling features, the misuse of them can still cause catastrophic software failures, such as application crash. Prior studies suggested anti-patterns of exception handling, while little knowledge was shared about the prevalence of these anti-patterns. In this paper, we investigate the prevalence of exception-handling anti-patterns. We collected a thorough list of exception anti-patterns from 16 open-source Java and C# libraries and applications using an automated exception flow analysis tool. We found that although exception handling anti-patterns widely exist in all of our subjects, only a few anti-patterns (e.g. Unhandled Exceptions, Catch Generic, Unreachable Handler, Over-catch, and Destructive Wrapping) can be commonly identified. On the other hand, we find that the prevalence of anti-patterns illustrates differences between C# and Java. Our results call for further in-depth analyses on the exception handling practices across different languages. © 2017 IEEE.","empirical software engineering; exception flow analysis; exception handling comprehension; object-oriented programming; static analysis","Application programs; Computer programming; Object oriented programming; Open source software; Software engineering; Software reliability; Static analysis; Anti-patterns; Empirical Software Engineering; Error handling codes; Exception handling; Flow analysis; In-depth analysis; Open sources; Software failure; Java programming language",2-s2.0-85025120726
"Alexandru C.V., Panichella S., Gall H.C.","Replicating Parser Behavior Using Neural Machine Translation",2017,"IEEE International Conference on Program Comprehension",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025129989&doi=10.1109%2fICPC.2017.11&partnerID=40&md5=691f3f7e6afc6ec708503800dfd2aee8","More than other machine learning techniques, neural networks have been shown to excel at tasks where humans traditionally outperform computers: recognizing objects in images, distinguishing spoken words from background noise or playing 'Go'. These are hard problems, where hand-crafting solutions is rarely feasible due to their inherent complexity. Higher level program comprehension is not dissimilar in nature: while a compiler or program analysis tool can extract certain facts from (correctly written) code, it has no intrinsic 'understanding' of the data and for the majority of real-world problems, a human developer is needed - for example to find and fix a bug or to summarize the bahavior of a method. We perform a pilot study to determine the suitability of neural machine translation (NMT) for processing plain-text source code. We find that, on one hand, NMT is too fragile to accurately tokenize code, while on the other hand, it can precisely recognize different types of tokens and make accurate guesses regarding their relative position in the local syntax tree. Our results suggest that NMT may be exploited for annotating and enriching out-of-context code snippets to support automated tooling for code comprehension problems. We also identify several challenges in applying neural networks to learning from source code and determine key differences between the application of existing neural network models to source code instead of natural language. © 2017 IEEE.","code analysis; deep learning; neural machine translation; parsing; source code","Codes (symbols); Complex networks; Computational linguistics; Computer aided language translation; Computer programming; Computer programming languages; Deep learning; Education; Learning systems; Syntactics; Trees (mathematics); Code analysis; Inherent complexity; Machine learning techniques; Machine translations; Neural network model; parsing; Program comprehension; Source codes; Program compilers",2-s2.0-85025129989
"Malaquias R., Ribeiro M., Bonifacio R., Monteiro E., Medeiros F., Garcia A., Gheyi R.","The Discipline of Preprocessor-Based Annotations - Does #ifdef TAG n't #endif Matter",2017,"IEEE International Conference on Program Comprehension",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025173309&doi=10.1109%2fICPC.2017.41&partnerID=40&md5=a9777caa317869cded2555dbcf790122","The C preprocessor is a simple, effective, and language-independent tool. Developers use the preprocessor in practice to deal with portability and variability issues. Despite the widespread usage, the C preprocessor suffers from severe criticism, such as negative effects on code understandability and maintainability. In particular, these problems may get worse when using undisciplined annotations, i.e., when a preprocessor directive encompasses only parts of C syntactical units. Nevertheless, despite the criticism and guidelines found in systems like Linux to avoid undisciplined annotations, the results of a previous controlled experiment indicated that the discipline of annotations has no influence on program comprehension and maintenance. To better understand whether developers care about the discipline of preprocessor-based annotations and whether they can really influence on maintenance tasks, in this paper we conduct a mixed-method research involving two studies. In the first one, we identify undisciplined annotations in 110 open-source C/C++ systems of different domains, sizes, and popularity GitHub metrics. We then refactor the identified undisciplined annotations to make them disciplined. Right away, we submit pull requests with our code changes. Our results show that almost two thirds of our pull requests have been accepted and are now merged. In the second study, we conduct a controlled experiment. We have several differences with respect to the aforementioned one, such as blocking of cofounding effects and more replicas. We have evidences that maintaining undisciplined annotations is more time consuming and error prone, representing a different result when compared to the previous experiment. Overall, we conclude that undisciplined annotations should not be neglected. © 2017 IEEE.",,"Computer operating systems; Computer programming; C preprocessor; Controlled experiment; Different domains; Language independents; Maintenance tasks; Mixed method; Program comprehension and maintenances; Understandability; C (programming language)",2-s2.0-85025173309
"Kobeissi N., Bhargavan K., Blanchet B.","Automated Verification for Secure Messaging Protocols and Their Implementations: A Symbolic and Computational Approach",2017,"Proceedings - 2nd IEEE European Symposium on Security and Privacy, EuroS and P 2017",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024477053&doi=10.1109%2fEuroSP.2017.38&partnerID=40&md5=d20099a25d9b03ec2faecddc12812897","Many popular web applications incorporate end-to-end secure messaging protocols, which seek to ensure that messages sent between users are kept confidential and authenticated, even if the web application's servers are broken into or otherwise compelled into releasing all their data. Protocols that promise such strong security guarantees should be held up to rigorous analysis, since protocol flaws and implementations bugs can easily lead to real-world attacks. We propose a novel methodology that allows protocol designers, implementers, and security analysts to collaboratively verify a protocol using automated tools. The protocol is implemented in ProScript, a new domain-specific language that is designed for writing cryptographic protocol code that can both be executed within JavaScript programs and automatically translated to a readable model in the applied pi calculus. This model can then be analyzed symbolically using ProVerif to find attacks in a variety of threat models. The model can also be used as the basis of a computational proof using CryptoVerif, which reduces the security of the protocol to standard cryptographic assumptions. If ProVerif finds an attack, or if the CryptoVerif proof reveals a weakness, the protocol designer modifies the ProScript protocol code and regenerates the model to enable a new analysis. We demonstrate our methodology by implementing and analyzing a variant of the popular Signal Protocol with only minor differences. We use ProVerif and CryptoVerif to find new and previously-known weaknesses in the protocol and suggest practical countermeasures. Our ProScript protocol code is incorporated within the current release of Cryptocat, a desktop secure messenger application written in JavaScript. Our results indicate that, with disciplined programming and some verification expertise, the systematic analysis of complex cryptographic web applications is now becoming practical. © 2017 IEEE.","cryptographic protocols; formal verification; secure messaging","Calculations; Codes (symbols); Computer programming languages; Cryptography; High level languages; Problem oriented languages; Automated verification; Computational approach; Cryptographic assumptions; Cryptographic protocols; Domain specific languages; Messaging protocols; secure messaging; Systematic analysis; Formal verification",2-s2.0-85024477053
"Walker J., Mayo J., Shene C.-K., Carr S.","Visualization for secure coding in C",2017,"Annual Conference on Innovation and Technology in Computer Science Education, ITiCSE",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029481572&doi=10.1145%2f3059009.3072990&partnerID=40&md5=37a69c888bc5052a529482b01cc9a2f6","This paper describes a pedagogical system to visualize program execution.1 The visualization is designed to help students understand how to develop more secure and robust C programs. The system provides several perspectives on the execution including: the values of registers and the logical address space, a call graph, the file descriptor and inode tables, and the handling of sensitive data like passwords and keys. These visualizations are designed to help students understand fundamental concepts such as: buffer overflows, integer overflows, proper handling of sensitive data and application of the principle of least privilege in several contexts including file operations, secure SUID programming, and use and management of the process environment. © 2017 Copyright held by the owner/author(s).","Program execution; Security education; Visualization","C (programming language); Data handling; Education; Education computing; Engineering research; Flow visualization; Integer programming; Network security; Students; Visualization; Buffer overflows; Fundamental concepts; Integer overflow; Least privilege; Pedagogical systems; Process environment; Program execution; Security education; Engineering education",2-s2.0-85029481572
"Orlandini V., Provenzano A., Giglio S., Magi A.","SLMSuite: A suite of algorithms for segmenting genomic profiles",2017,"BMC Bioinformatics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021361778&doi=10.1186%2fs12859-017-1734-5&partnerID=40&md5=eeccc04fcb7d46491c5be8b8ed835dbe","Background: The identification of copy number variants (CNVs) is essential to study human genetic variation and to understand the genetic basis of mendelian disorders and cancers. At present, genome-wide detection of CNVs can be achieved using microarray or second generation sequencing (SGS) data. Although these technologies are very different, the genomic profiles that they generate are mathematically very similar and consist of noisy signals in which a decrease or increase of consecutive data represent deletions or duplication of DNA. In this framework, the most important step of the analysis consists of segmenting genomic profiles for the identification of the boundaries of genomic regions with increased or decreased signal. Results: Here we introduce SLMSuite, a collection of algorithms, based on shifting level models (SLM), to segment genomic profiles from array and SGS experiments. The SLM algorithms take as input the log-transformed genomic profiles from SGS or microarray experiments and output segmentation results. We apply our method to the analysis of synthetic genomic profiles and real whole genome sequencing data and we demonstrate that it outperforms the state of the art circular binary segmentation algorithm in terms of sensitivity, specificity and computational speed. Conclusion: The SLMSuite contains an R library with the segmentation methods and three wrappers that allow to use them in Python, Ruby and C++. SLMSuite is freely available at https://sourceforge.net/projects/slmsuite. © 2017 The Author(s).","Bioinformatics; Genomics; SLM; Software","Bioinformatics; C++ (programming language); Computer programming; Computer software; Image segmentation; Binary segmentation; Computational speed; Genetic variation; Genomics; Microarray experiments; Segmentation methods; Segmentation results; Whole genome sequencing; Genes; DNA; algorithm; chemistry; computer interface; copy number variation; DNA sequence; genetics; high throughput sequencing; human; human genome; Internet; Algorithms; DNA; DNA Copy Number Variations; Genome, Human; High-Throughput Nucleotide Sequencing; Humans; Internet; Sequence Analysis, DNA; User-Computer Interface",2-s2.0-85021361778
"Hatano T., Matsuo A.","Removing Code Clones from Industrial Systems Using Compiler Directives",2017,"IEEE International Conference on Program Comprehension",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025138389&doi=10.1109%2fICPC.2017.4&partnerID=40&md5=b600e0e4a8f26626ab045923b3140842","Refactoring of code clones is an effective method for improving software maintainability. Existing studies have proposed automated techniques and tools for refactoring. However, it is difficult to apply refactoring to our industrial systems in practice because of three main reasons. First, we have many industrial systems written in COBOL which requires a particular refactoring method compared with current techniques because Type-2 clones in COBOL are generated by renaming parts of identifiers. Second, nested clones must be refactored, in which an instance of a clone set is contained within an instance of another clone set. They also make it difficult to estimate the reduction size by refactoring. Third, refactoring requires testing which is time-consuming and laborious. To overcome these problems, we developed an approach for refactoring of Type-2 clones in COBOL programs. Our approach identifies actual refactorable clone sets and includes a string comparison technique to parameterize partial differences in identifier names. The clone sets are extracted as shared code fragments and transformed into the refactored code using compiler directives. It is easy to confirm that refactoring using compiler directives preserves program behavior, because they do not change program structure. We also provide a method that makes it possible to refactor nested clones by ordering their refactoring. This method enables to estimate how many lines can be reduced by refactoring. We applied the approach to four industrial systems to assess how many lines can be reduced. The results show that the lines could be reduced by 10 to 15% and one system was reduced by 27%. We also discuss the parameter number required for our refactoring approach. © 2017 IEEE.","COBOL; code clones; refactoring","Cloning; COBOL (programming language); Codes (symbols); Computer programming; Automated techniques; COBOL; Code clone; Compiler directives; Industrial systems; Refactoring methods; Refactorings; Software maintainability; Program compilers",2-s2.0-85025138389
"Azadmanesh M.R., Van De Vanter M.L., Hauswirth M.","Language-Independent Information Flow Tracking Engine for Program Comprehension Tools",2017,"IEEE International Conference on Program Comprehension",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025134546&doi=10.1109%2fICPC.2017.5&partnerID=40&md5=199a4edb61b3a3d8f1b92d2c96e76862","Program comprehension tools are often developed for a specific programming language. Developing such a tool from scratch requires significant effort. In this paper, we report on our experience developing a language-independent framework that enables the creation of program comprehension tools, specifically tools gathering insight from deep dynamic analysis, with little effort. Our framework is language independent, because it is built on top of Truffle, an open-source platform, developed in Oracle Labs, for implementing dynamic languages in the form of AST interpreters. Our framework supports the creation of a diverse variety of program comprehension techniques, such as query, program slicing, and back-in-time debugging, because it is centered around a powerful information-flow tracking engine. Tools developed with our framework get access to the information-flow through a program execution. While it is possible to develop similarly powerful tools without our framework, for example by tracking information-flow through bytecode instrumentation, our approach leads to information that is closer to source code constructs, thus more comprehensible by the user. To demonstrate the effectiveness of our framework, we applied it to two of Truffle-based languages namely Simple Language and TruffleRuby, and we distill our experience into guidelines for developers of other Truffle-based languages who want to develop program comprehension tools for their language. © 2017 IEEE.","AST interpreter; Dependency; Information flow; Language-independent; Program comprehension; Tool","Computer programming; Engines; Open source software; Program interpreters; Search engines; Tools; AST interpreter; Dependency; Information flows; Language independents; Program comprehension; Program debugging",2-s2.0-85025134546
"Benammar N., Ridouard F., Bauer H., Richard P.","Forward End-To-End delay Analysis for AFDX networks",2017,"IEEE Transactions on Industrial Informatics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021981665&doi=10.1109%2fTII.2017.2720799&partnerID=40&md5=c14e8354c3722c587c38589c1fe7521c","Packet switched networks and message multiplexing have been a major upgrade for industrial systems communications. In the avionics domain, this evolution was brought by the introduction of Avionics Full Duplex Switched Ethernet (AFDX). Guaranteed upper bounds of end-to-end delays for messages transmitted over an AFDX network are mandatory for certification reasons. IEEE","Aerospace electronics; AFDX; analysis; Context; Delays; end-to-end delay; Multiplexing; Ports (Computers); Switches; Upper bound; worst-case transmission time","Avionics; Delay control systems; Java programming language; Multiplexing; Switches; Time switches; Aerospace electronics; AFDX; analysis; Context; Delays; End to end delay; Ports (Computers); Transmission time; Upper Bound; Ethernet",2-s2.0-85021981665
"Rietze C., Titov E., Lindner S., Saalfrank P.","Thermal isomerization of azobenzenes: On the performance of Eyring transition state theory",2017,"Journal of Physics Condensed Matter",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026370117&doi=10.1088%2f1361-648X%2faa75bd&partnerID=40&md5=1f2fb91f4be0787ef8482bb6f71f706e","The thermal Z → E (back-)isomerization of azobenzenes is a prototypical reaction occurring in molecular switches. It has been studied for decades, yet its kinetics is not fully understood. In this paper, quantum chemical calculations are performed to model the kinetics of an experimental benchmark system, where a modified azobenzene (AzoBiPyB) is embedded in a metal-organic framework (MOF). The molecule can be switched thermally from cis to trans, under solvent-free conditions. We critically test the validity of Eyring transition state theory for this reaction. As previously found for other azobenzenes (albeit in solution), good agreement between theory and experiment emerges for activation energies and activation free energies, already at a comparatively simple level of theory, B3LYP/6-31G- including dispersion corrections. However, theoretical Arrhenius prefactors and activation entropies are in qualitiative disagreement with experiment. Several factors are discussed that may have an influence on activation entropies, among them dynamical and geometric constraints (imposed by the MOF). For a simpler model-Z → E isomerization in azobenzene-a systematic test of quantum chemical methods from both density functional theory and wavefunction theory is carried out in the context of Eyring theory. Also, the effect of anharmonicities on activation entropies is discussed for this model system. Our work highlights capabilities and shortcomings of Eyring transition state theory and quantum chemical methods, when applied for the Z → E (back-) isomerization of azobenzenes under solvent-free conditions. © 2017 IOP Publishing Ltd Printed in the UK.","azobenzene; DFT; electronic structure; Eyrings TST; kinetics; switches; thermal isomerization","Activation energy; Chemical activation; Crystalline materials; Density functional theory; Design for testability; Electric switches; Electronic structure; Entropy; Enzyme kinetics; Isomerization; Isomers; Java programming language; Kinetics; Quantum chemistry; Quantum theory; Switches; Experimental benchmarks; Eyrings TST; Metal organic framework; Quantum chemical calculations; Quantum-chemical methods; Solvent free conditions; Thermal isomerizations; Transition state theories; Azobenzene",2-s2.0-85026370117
"Sun H., Tang B., Wu P.","Development of Hybrid Ultrafiltration Membranes with Improved Water Separation Properties Using Modified Superhydrophilic Metal-Organic Framework Nanoparticles",2017,"ACS Applied Materials and Interfaces",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021676597&doi=10.1021%2facsami.7b05504&partnerID=40&md5=2aca2598650e8ee16a423f41c2bc5d02","Metal-organic frameworks (MOFs) are being intensively explored as filler materials for polymeric membranes primarily due to their high polymer affinity, large pore volumes, and alterable pore functionalities, but the development of MOF-based ultrafiltration (UF) membranes for water treatment lags behind. Herein, poly(sulfobetaine methacrylate) (PSBMA)-functionalized MOF UiO-66-PSBMA was developed, and incorporated into polysulfone (PSf) casting solution to fabricate novel hybrid UF membranes via phase-inversion method. The resultant UiO-66-PSBMA/PSf membrane exhibited significantly improved water flux (up to 602 L m-2 h-1), which was 2.5 times that of the pristine PSf membrane (240 L m-2 h-1) and 2 times that of UiO-66-NH2/PSf membrane (294 L m-2 h-1), whereas the rejection of UiO-66-PSBMA/PSf membrane was still maintained at a high level. Moreover, UiO-66-PSBMA/PSf membrane exhibited improved antifouling performance. The improvement of membrane performances could be attributed to the well-tailored properties of UiO-66-PSBMA. On one hand, the excellent dispersion and compatibility of UiO-66-PSBMA ensured the formation of a uniform structure with few defects. On the other hand, the superhydrophilicity of UiO-66-PSBMA could accelerate the exchange rate between solvent and nonsolvent, resulting in a more hydrophilic surface and a more porous structure. Besides, UiO-66-PSBMA nanoparticles in the thin layer provided additional flow paths for water permeation through their hydrophilic porous structure as well as the tiny interspace between PSf matrix. This study indicates the great application potential of UiO-66-PSBMA in fabricating hybrid UF membranes and provides a useful guideline to integrate other modified hydrophilic MOFs to design UF membranes for water treatment. © 2017 American Chemical Society.","hybrid membrane; metal-organic framework; postsynthetic modification; ultrafiltration; water purification; zwitterionic","Chemicals removal (water treatment); Crystalline materials; Filled polymers; Hydrophilicity; Java programming language; Metal nanoparticles; Nanoparticles; Polymers; Porosity; Ultrafiltration; Water treatment; Hybrid membrane; Metal organic framework; Postsynthetic modification; Water purification; zwitterionic; Membranes",2-s2.0-85021676597
"Yabushita M., Li P., Islamoglu T., Kobayashi H., Fukuoka A., Farha O.K., Katz A.","Selective Metal-Organic Framework Catalysis of Glucose to 5-Hydroxymethylfurfural Using Phosphate-Modified NU-1000",2017,"Industrial and Engineering Chemistry Research",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022224296&doi=10.1021%2facs.iecr.7b01164&partnerID=40&md5=d5ca47625a26a9e7a95dfcea56aa0537","This manuscript demonstrates the synthesis of selective Lewis-acid sites in a metal-organic framework (MOF) for glucose transformation to 5-hydroxymethylfurfural (HMF). These sites are synthesized via partial phosphate modification of zirconia-cluster nodes in MOF NU-1000, which titrates strong Lewis-acid sites that would lead to undesired side reactions. Our mechanistic study using isotope tracer analysis and kinetic isotope effect measurements reveals that an isomerization-dehydration mechanism mainly occurs on the MOF catalyst, where fructose is an intermediate. This mechanism suggests that dilute concentrations are favorable in order to suppress undesired intermolecular condensation of glucose/fructose/HMF and maximize HMF yield. We demonstrate both high yield and selectivity of HMF formation of 64% with the MOF catalyst, at an initial glucose concentration of 1 mM in water/2-propanol. In stark contrast, similar partial phosphate modification of a bulk zirconia yields a catalyst that exhibits poor HMF selectivity, while possessing nearly identical Brønsted acidity to the selective NU-1000-based catalyst. © 2017 American Chemical Society.",,"Catalysts; Crystalline materials; Glucose; Isotopes; Java programming language; Zirconia; 5 hydroxymethyl furfurals; Dilute concentrations; Glucose concentration; Intermolecular condensation; Kinetic isotope effects; Mechanistic studies; Metal organic framework; Zirconia clusters; Catalyst selectivity",2-s2.0-85022224296
"Sun Z., Tong G., Zhao B., Zhang Q., Zhou Q., Lyu X.","Research of Adaptive Color Classification Method for Solar Cells",2017,"Taiyangneng Xuebao/Acta Energiae Solaris Sinica",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032490668&partnerID=40&md5=18fcf6293da36530790fa57eb00dfa87","A new color classification method based on machine vision was proposed, which could adapt to different kinds of classification standards. With the help of LabVIEW software platform, the Euclidean distance algorithm was used to obtain the similar degree of solar cell with standard sample of cells by color image segmentation, image extraction, image filtering and de-noising etc. algorithms, then it could carry out the color sorting of solar cells. The experimental results show that this method is fast, the adaptive degree is high, and the accurate rate is more than 99. 7%. All of these are fully consistent with different manufacturers of solar cells in real-time online color classification requirements. © 2017, Editorial Board of Acta Energiae Solaris Sinica. All right reserved.","Adaptive method; Color classification; LabVIEW; Machine vision; Solar cell","Color; Color printing; Computer programming languages; Computer vision; Image segmentation; Adaptive methods; Classification standard; Color classification; Color image segmentation; Euclidean distance algorithm; Lab-view softwares; LabViEW; Standard samples; Solar cells",2-s2.0-85032490668
"Andriesse D., Slowinska A., Bos H.","Compiler-Agnostic Function Detection in Binaries",2017,"Proceedings - 2nd IEEE European Symposium on Security and Privacy, EuroS and P 2017",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026645253&doi=10.1109%2fEuroSP.2017.11&partnerID=40&md5=d74becfd20295282acb61b4fb3331c64","We propose Nucleus, a novel function detection algorithm for binaries. In contrast to prior work, Nucleus is compiler-agnostic, and does not require any learning phase or signature information. Instead of scanning for signatures, Nucleus detects functions at the Control Flow Graph-level, making it inherently suitable for difficult cases such as non-contiguous or multi-entry functions. We evaluate Nucleus on a diverse set of 476 C and C ++ binaries, compiled with GCC, clang and Visual Studio for x86 and x64, at optimization levels O0-O3. We achieve consistently good performance, with a mean F-score of 0.95. © 2017 IEEE.","Disassembly; function detection; reverse engineering; static analysis","Bins; Data flow analysis; Flow graphs; Network security; Program compilers; Reverse engineering; Static analysis; Control flow graphs; Detection algorithm; Disassembly; Learning phase; Novel functions; Optimization levels; Signature information; Visual studios; C++ (programming language)",2-s2.0-85026645253
"Lin B., Ponzanelli L., Mocci A., Bavota G., Lanza M.","On the Uniqueness of Code Redundancies",2017,"IEEE International Conference on Program Comprehension",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025148042&doi=10.1109%2fICPC.2017.36&partnerID=40&md5=34d6e9fa79f1b4f468d559bb111f652f","Code redundancy widely occurs in software projects. Researchers have investigated the existence, causes, and impacts of code redundancy, showing that it can be put to good use, for example in the context of code completion. When analyzing source code redundancy, previous studies considered software projects as sequences of tokens, neglecting the role of the syntactic structures enforced by programming languages. However, differences in the redundancy of such structures may jeopardize the performance of applications leveraging code redundancy. We present a study of the redundancy of several types of code constructs in a large-scale dataset of active Java projects mined from GitHub, unveiling that redundancy is not uniform and mainly resides in specific code constructs. We further investigate the implications of the locality of redundancy by analyzing the performance of language models when applied to code completion. Our study discloses the perils of exploiting code redundancy without taking into account its strong locality in specific code constructs. © 2017 IEEE.","code completion; code redundancy; empirical study","Codes (symbols); Computer programming; Syntactics; Code completions; Code constructs; Code redundancy; Empirical studies; Language model; Large-scale dataset; Software project; Syntactic structure; Redundancy",2-s2.0-85025148042
"Milojkovic N., Ghafari M., Nierstrasz O.","Exploiting Type Hints in Method Argument Names to Improve Lightweight Type Inference",2017,"IEEE International Conference on Program Comprehension",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025134739&doi=10.1109%2fICPC.2017.33&partnerID=40&md5=718ff6495077e78b4ec254a4f5fc3d80","The lack of static type information is one of the main obstacles to program comprehension in dynamically-typed languages. While static type inference algorithms try to remedy this problem, they usually suffer from the problem of false positives or false negatives. In order to partially compensate for the lack of static type information, a common practice in dynamically-typed languages is to name or annotate method arguments in such a way that they reveal their expected type, e.g., aString, anInt, or string: String. Recent studies confirmed that these type annotations are indeed frequently used by developers in dynamically-typed languages. We propose a lightweight heuristic that uses these hints from method argument names to augment the performance of a static type inference algorithm. The evaluation through a proof-of-concept prototype implemented in Pharo Smalltalk shows that the augmented algorithm outperforms the basic algorithm, and correctly infers types for 81% more method arguments. © 2017 IEEE.","dynamically-typed languages; heuristic; type hints; type-inference","Computer programming; Inference engines; Dynamically typed languages; heuristic; Program comprehension; Proof of concept; Type annotations; type hints; Type Inference Algorithm; Type inferences; Heuristic methods",2-s2.0-85025134739
"Jiang S., McMillan C.","Towards Automatic Generation of Short Summaries of Commits",2017,"IEEE International Conference on Program Comprehension",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025144337&doi=10.1109%2fICPC.2017.12&partnerID=40&md5=8d7746d6122f572c21057c399b260f99","Committing to a version control system means submitting a software change to the system. Each commit can have a message to describe the submission. Several approaches have been proposed to automatically generate the content of such messages. However, the quality of the automatically generated messages falls far short of what humans write. In studying the differences between auto-generated and human-written messages, we found that 82% of the human-written messages have only one sentence, while the automatically generated messages often have multiple lines. Furthermore, we found that the commit messages often begin with a verb followed by an direct object. This finding inspired us to use a 'verb+object' format in this paper to generate short commit summaries. We split the approach into two parts: verb generation and object generation. As our first try, we trained a classifier to classify a diff to a verb. We are seeking feedback from the community before we continue to work on generating direct objects for the commits. © 2017 IEEE.","code differencing; commit log; commit message; natural language processing; program comprehension; version control system","Computer programming; Control systems; Information management; code differencing; commit log; commit message; Program comprehension; Version control system; Natural language processing systems",2-s2.0-85025144337
"Milojkovic N., Ghafari M., Nierstrasz O.","It's Duck (Typing) Season!",2017,"IEEE International Conference on Program Comprehension",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025149643&doi=10.1109%2fICPC.2017.10&partnerID=40&md5=a15584aaa94cf3cfc7123c810bbc949f","Duck typing provides a way to reuse code and allow a developer to write more extensible code. At the same time, it scatters the implementation of a functionality over multiple classes and causes difficulties in program comprehension. The extent to which duck typing is used in real programs is not very well understood. We report on a preliminary study of the prevalence of duck typing in more than a thousand dynamically-typed open source software systems developed in Smalltalk. Although a small portion of the call sites in these systems is duck-typed, in half of the analysed systems at least 20% of methods are duck-typed. © 2017 IEEE.","cross-hierarchy polymorphism; duck typing; dynamically-typed languages","Computer programming; Computer software; Open source software; Software engineering; duck typing; Dynamically typed languages; Multiple class; Open source software systems; Program comprehension; Smalltalk; Open systems",2-s2.0-85025149643
"O'Hara K.J., Burke K., Ruggiero D., Anderson S.","Linking language & thinking with code: Computing within a writing-intensive introduction to the liberal arts",2017,"Annual Conference on Innovation and Technology in Computer Science Education, ITiCSE",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029523142&doi=10.1145%2f3059009.3059018&partnerID=40&md5=b5b01955e7d944853662a327b2dfb78e","This paper describes the design, implementation and preliminary evaluation of a computing component for a three-week writing-intensive introductory program at a liberal arts college. Specific curricular recommendations are presented that could have a direct, positive impact if adopted in similar courses. A two-pronged approach involving a faculty-led HTML workshop, along with student-led contextualized coding studios, was employed. Computing Unplugged activities were used, including a novel Page Rank Unplugged networking activity. An analysis of attitude surveys shows the program positively changed students attitudes about enjoyment solving CS problems, but potentially reinforced the misconception that CS is just learning programming languages. © 2017 ACM.","Attitudes; Computing in liberal arts; Computing unplugged","Arts computing; Education; Education computing; Engineering education; Engineering research; Students; Teaching; Attitude surveys; Attitudes; Computing unplugged; Liberal arts; Page ranks; Humanities computing",2-s2.0-85029523142
"Beniamini G., Gingichashvili S., Orbach A.K., Feitelson D.G.","Meaningful Identifier Names: The Case of Single-Letter Variables",2017,"IEEE International Conference on Program Comprehension",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025175118&doi=10.1109%2fICPC.2017.18&partnerID=40&md5=751093cfe4faa8e53a6e03e555432484","It is widely accepted that variable names in computer programs should be meaningful, and that this aids program comprehension. 'Meaningful' is commonly interpreted as favoring long descriptive names. However, there is at least some use of short and even single-letter names: using 'i' in loops is very common, and we show (by extracting variable names from 1000 popular github projects in 5 languages) that some other letters are also widely used. In addition, controlled experiments with different versions of the same functions (specifically, different variable names) failed to show significant differences in ability to modify the code. Finally, an online survey showed that certain letters are strongly associated with certain types and meanings. This implies that a single letter can in fact convey meaning. The conclusion from all this is that single letter variables can indeed be used beneficially in certain cases, leading to more concise code. © 2017 IEEE.","meaningful identifier names; Program comprehension; single-letter names","Controlled experiment; Descriptive names; meaningful identifier names; Online surveys; Program comprehension; single-letter names; Computer programming",2-s2.0-85025175118
[No author name available],"2017 IEEE Virtual Reality Workshop on K-12 Embodied Learning through Virtual and Augmented Reality, KELVAR 2017",2017,"2017 IEEE Virtual Reality Workshop on K-12 Embodied Learning through Virtual and Augmented Reality, KELVAR 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026388354&partnerID=40&md5=930322fb46705a7a34e176c60bf7240e","The proceedings contain 10 papers. The topics discussed include: designing and conducting research using immersive technologies in schools: seven observations; virtual reality mediated instruction and learning; virtual humans for temperature visualization in a tangible augmented reality educational game; embodied experiment of levitation in microgravity in a simulated virtual reality environment for science learning; iVR for the geosciences; embodied learning mechanics and their relationship to usability of handheld augmented reality; mixed-reality barriers: person-tracking in k-12 schools; considerations on the use of virtual and augmented reality technologies in music education; and towards a 3D virtual programming language to increase the number of women in computer science education.",,,2-s2.0-85026388354
"Ellis H.J.C., Hislop G.W., Burdge D.","Courseware: HFOSS project evaluation",2017,"Annual Conference on Innovation and Technology in Computer Science Education, ITiCSE",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029494843&doi=10.1145%2f3059009.3072975&partnerID=40&md5=667ed5b4da65e75b247e28c96c1b21b0","Many instructors are excited by the potential learning that occurs via student participation in Humanitarian Free and Open Source Software (HFOSS) projects. However, one of the main challenges for instructors desiring to support such participation is identifying an appropriate project. There are a vast number of HFOSS projects with varying sizes, complexities, domains and community cultures. This presentation describes a guided approach to evaluating an HFOSS project for someone trying to pick a project to which they will contribute. The activity is designed with particular attention to instructors who need to identify an HFOSS project that they will use in a class. The characteristics evaluated include the pattern of contributions, pattern of commits, programming languages used, and more. This activity uses OpenMRS as a sample project to evaluate. © 2017 Copyright held by the owner/author(s).","Computing education; HFOSS; Open source software","Computer software; Education; Education computing; Engineering education; Engineering research; Open systems; Project management; Software engineering; Computing education; Courseware; Free and open source softwares; HFOSS; Project evaluation; Student participation; Open source software",2-s2.0-85029494843
"Backes M., Rieck K., Skoruppa M., Stock B., Yamaguchi F.","Efficient and Flexible Discovery of PHP Application Vulnerabilities",2017,"Proceedings - 2nd IEEE European Symposium on Security and Privacy, EuroS and P 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026640086&doi=10.1109%2fEuroSP.2017.14&partnerID=40&md5=b6b57cf13fb1fb290d953ed2441927c7","The Web today is a growing universe of pages and applications teeming with interactive content. The security of such applications is of the utmost importance, as exploits can have a devastating impact on personal and economic levels. The number one programming language in Web applications is PHP, powering more than 80% of the top ten million websites. Yet it was not designed with security in mind and, today, bears a patchwork of fixes and inconsistently designed functions with often unexpected and hardly predictable behavior that typically yield a large attack surface. Consequently, it is prone to different types of vulnerabilities, such as SQL Injection or Cross-Site Scripting. In this paper, we present an interprocedural analysis technique for PHP applications based on code property graphs that scales well to large amounts of code and is highly adaptable in its nature. We implement our prototype using the latest features of PHP 7, leverage an efficient graph database to store code property graphs for PHP, and subsequently identify different types of Web application vulnerabilities by means of programmable graph traversals. We show the efficacy and the scalability of our approach by reporting on an analysis of 1,854 popular open-source projects, comprising almost 80 million lines of code. © 2017 IEEE.","information flow analysis; PHP; vulnerability scanner","Codes (symbols); Open source software; Cross site scripting; Graph traversals; Information flow analysis; Inter-procedural analysis; Interactive contents; Open source projects; Vulnerability scanner; Web application vulnerability; Open systems",2-s2.0-85026640086
"Weintrop D., Wilensky U.","Between a block and a typeface: Designing and evaluating hybrid programming environments",2017,"IDC 2017 - Proceedings of the 2017 ACM Conference on Interaction Design and Children",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026291067&doi=10.1145%2f3078072.3079715&partnerID=40&md5=8215f2d5e7460129e6b6618c3b122703","The last ten years have seen a proliferation of introductory programming environments designed for learners across the K-12 spectrum. These environments include visual blockbased tools, text-based languages designed for novices, and, increasingly, hybrid environments that blend features of block-based and text-based programming. This paper presents results from a quasi-experimental study investigating the affordances of a hybrid block/text programming environment relative to comparable blockbased and textual versions in an introductory high school computer science class. The analysis reveals the hybrid environment demonstrates characteristics of both ancestors while outperforming the block-based and text-based versions in certain dimensions. This paper contributes to our understanding of the design of introductory programming environments and the design challenge of creating and evaluating novel representations for learning. © 2017 Copyright is held by the owner/author(s).","Block-based programming; Design; K-12 education; Programming environments","Design; Education; Visual languages; Affordances; Block based; Design challenges; High school; Hybrid programming; Introductory programming; K-12 education; Programming environment; Computer programming",2-s2.0-85026291067
"Moors L., Sheehan R.","Aiding the transition from novice to traditional programming environments",2017,"IDC 2017 - Proceedings of the 2017 ACM Conference on Interaction Design and Children",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026308502&doi=10.1145%2f3078072.3084317&partnerID=40&md5=5100af3aa73c513a95b277cc72804c70","Novice programming environments are increasingly popular as introductory tools for teaching programming. Many of these tools differ significantly from traditional programming environments and are successful in motivating novices and making it simple to start programming. However, it has been reported that students still struggle when transitioning to general-purpose languages and have difficulties learning certain concepts. In this paper, we briefly describe some of the problems novices have when learning to program and identify drawbacks to existing novice programming environments. We then present two different works in progress with features designed to keep some of the advantages of current novice programming environments but in such a way that students are led to deeper concepts. Such features include immediate feedback, loop construction, and automated identifier updating. This report references the feasibility of these approaches. © 2017 Copyright is held by the owner/author(s).","Block-based programming; Novice programming; Programming environments","Block based; General purpose languages; Immediate feedbacks; Novice programming; Programming environment; Teaching programming; Education",2-s2.0-85026308502
"Yildiz E., Ekin E.","Automatic comment generation using only source code",2017,"2017 25th Signal Processing and Communications Applications Conference, SIU 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026294780&doi=10.1109%2fSIU.2017.7960702&partnerID=40&md5=806c1df12677b30e3c8f890b5fe546e7","In this study, automatic comment generation for Java methods is described. It is sufficient that the codes conform to the syntax rules of the Java programming language, and it is not expected to be runnable. In order to generate comments, source code is examined syntactically. At this stage, only the method signature and its return type is needed. By working on open source Java projects, different templates have been developed for different method types. Using the compiled information which is the result of the examining source code that is currently being developed, the most suitable template is chosen and texts are created. These texts explain the aim of the method. Created texts are added to source code as a comment. © 2017 IEEE.","documentation generation; program comprehension; source code summarization","Automatic programming; Codes (symbols); Computer programming; Computer programming languages; Open source software; Program documentation; Signal processing; Java methods; Open sources; Program comprehension; Source codes; Java programming language",2-s2.0-85026294780
"Yang S.","Knitting visualizer: Connecting craft and code",2017,"IDC 2017 - Proceedings of the 2017 ACM Conference on Interaction Design and Children",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026288788&doi=10.1145%2f3078072.3091985&partnerID=40&md5=8ba96fb99cc5cf1e9539388a5841435e","The Knitting Visualizer aims to highlight the relationship between craft and computation. This demo is targeted at amateur knitters who have a basic familiarity with programming and who would like to develop their own knitting patterns. The demo features two-way translation between Javascript code and a symbolic knitting chart with a preview of the physical product. Future work is planned to improve on this demo. © 2017 Copyright is held by the owner/author(s).","Knitting; Novice programming; Programming languages","Javascript; Knitting; Novice programming; Physical products; Two ways; Visualizers; Computer programming languages",2-s2.0-85026288788
"Atherton J., Blikstein P.","Sonification blocks: A block-based programming environment for embodied data Sonification",2017,"IDC 2017 - Proceedings of the 2017 ACM Conference on Interaction Design and Children",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026329629&doi=10.1145%2f3078072.3091992&partnerID=40&md5=32255d8397c47dd49138c6cd8410283c","High school students often struggle to find the motivation to learn to program. Music can be a powerful motivator for these students, but existing tools that combine music production with programming often fail to meaningfully engage students with core computer science concepts. Sonification Blocks was created to shift the focus back toward big ideas in programming. Sonification Blocks is a programming language for data sonification, the process of creating audio algorithms and controlling them with streams of data. Its implementation as a block-based language with clear, interactive data visualizers allows high-school-aged learners to develop computational literacy. Furthermore, the act of manipulating sound parameters with data streams that are controlled through body motion may help connect learners with powerful ideas in programming and data science. © 2017 Copyright is held by the owner/author(s).","Computer science education; Constructionism; Embodied cognition; Music; Sonification","Computer hardware description languages; Education; Education computing; Motivation; Students; Computer Science Education; Constructionism; Embodied cognition; Music; Sonifications; Computer programming",2-s2.0-85026329629
"Koracharkornradt C.","Tuk Tuk: A block-based programming game",2017,"IDC 2017 - Proceedings of the 2017 ACM Conference on Interaction Design and Children",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026302829&doi=10.1145%2f3078072.3091990&partnerID=40&md5=e448466e472f3aad9cd3f77f7993744f","Studying computer programming helps children develop computational thinking, a problem-solving methodology that can be transferred to solve everyday problems. Additionally, exposing children to an advanced computational concept of search algorithm allows them to see how different problem-solving techniques are designed to tackle more challenging tasks, and improve their ability to solve problems. We present a block-based programming game called Tuk Tuk for children in kindergarten level (junior version), and elementary and middle school level (standard version). With Tuk Tuk, learners create a computer program in a block-based language to control a car to complete a given task, earn money, reach the next level, and unlock new coding blocks. By completing each task, learners will learn important computational concepts and algorithms, a basis of computational thinking, such as conditionals, iterations, depth-first search (DFS) and breadth-first search (BFS). © 2017 Copyright is held by the owner/author(s).","Blo1ck-based programming; Game","Computer program listings; Computer programming; Breadth-first search; Computational thinkings; Depth-First-Search (DFS); Elementary and middle schools; Game; Problem solving technique; Search Algorithms; Standard versions; Problem solving",2-s2.0-85026302829
"Cavur M., Demir E.","Real-time localization methodology with RFID technology in closed area [Kapali Alanlarda RFID Teknolojisi ile Anlik Konumlandirma Metodolojisi]",2017,"2017 25th Signal Processing and Communications Applications Conference, SIU 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026327347&doi=10.1109%2fSIU.2017.7960736&partnerID=40&md5=db9115edbc5173a70b6d103e7b107105","In recent years, many companies want to keep track of personnel, sources and working machines due to various reasons. This is sometimes achieved for security purposes and sometimes for coordination and performance purposes. The purpose and requirements are the main factors that determine the shape of tracking. Such developed systems for this purpose have different technologies according to their requirements. The real-time tracking can be determined with high precision in open areas with the global positioning system (GPS). However, previous research and developments for indoor tracking have mostly focused on infrared, wireless LAN and ultrasonic. In this study, the infrastructure of the system was designed by using RFID technology. The use of open source Geographical Information Systems (GIS) as a substructure also provided spatial display and analysis possibilities for this study. The open source t database is also integrated into this system. The tracking algorithm is completely unique and original and is encoded in the Java programming language. In the algorithm, the accuracy of locating the proximity, direction and whether the RFID reader is on the right and left of the last point received is increased. The methodology used was tested in an underground salt mine and proved to study successfully. © 2017 IEEE.","Localization in closed Areas by using RFID; Real-Time Localization Closed Areas; RFID","Computer programming; Geographic information systems; Global positioning system; Java programming language; Open source software; Radio frequency identification (RFID); Salt mines; Signal processing; High-precision; Indoor tracking; Keep track of; Real time tracking; Real-time localization; Research and development; RFID Technology; Tracking algorithm; Open systems",2-s2.0-85026327347
"Myint C.Z., Gopal L., Aung Y.L.","Reconfigurable smart water quality monitoring system in IoT environment",2017,"Proceedings - 16th IEEE/ACIS International Conference on Computer and Information Science, ICIS 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030624157&doi=10.1109%2fICIS.2017.7960032&partnerID=40&md5=68a50d9996ae08ffcaafcda0a7ba0d1f","Since the effective and efficient system of water quality monitoring (WQM) are critical implementation for the issue of polluted water globally, with increasing in the development of Wireless Sensor Network (WSN) technology in the Internet of Things (IoT) environment, real time water quality monitoring is remotely monitored by means of real-time data acquisition, transmission and processing. This paper presents a reconfigurable smart sensor interface device for water quality monitoring system in an IoT environment. The smart WQM system consists of Field Programmable Gate Array (FPGA) design board, sensors, Zigbee based wireless communication module and personal computer (PC). The FPGA board is the core component of the proposed system and it is programmed in very high speed integrated circuit hardware description language (VHDL) and C programming language using Quartus II software and Qsys tool. The proposed WQM system collects the five parameters of water data such as water pH, water level, turbidity, carbon dioxide (CO2) on the surface of water and water temperature in parallel and in real time basis with high speed from multiple different sensor nodes. © 2017 IEEE.","Internet of Things (IoT); Smart; Water parameters; Wireless Sensor Network (WSN); Zigbee","C (programming language); Carbon; Carbon dioxide; Computer hardware description languages; Data acquisition; Field programmable gate arrays (FPGA); Monitoring; Personal computers; Sensor nodes; Water levels; Water pollution; Water quality; Wireless sensor networks; Wireless telecommunication systems; Zigbee; Internet of Things (IOT); Real time data acquisition; Smart; Very high speed integrated circuits; Water parameters; Water quality monitoring; Water quality monitoring systems; Wireless communications; Internet of things",2-s2.0-85030624157
"Salunkhe R.R., Kaneti Y.V., Yamauchi Y.","Metal-Organic Framework-Derived Nanoporous Metal Oxides toward Supercapacitor Applications: Progress and Prospects",2017,"ACS Nano",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021398704&doi=10.1021%2facsnano.7b02796&partnerID=40&md5=067830f0387454ea0e7e4504e2219140","Transition metal oxides (TMOs) have attracted significant attention for energy storage applications such as supercapacitors due to their good electrical conductivity, high electrochemical response (by providing Faradaic reactions), low manufacturing costs, and easy processability. Despite exhibiting these attractive characteristics, the practical applications of TMOs for supercapacitors are still relatively limited. This is largely due to their continuous Faradaic reactions, which can lead to major changes or destruction of their structure as well phase changes (in some cases) during cycling, leading to the degradation in their capacitive performance over time. Hence, there is an immediate need to develop new synthesis methods, which will readily provide stable porous architectures, controlled phase, as well as useful control over dimensions (1-D, 2-D, and 3-D) of the metal oxides for improving their performance in supercapacitor applications. Since its discovery in late 1990s, metal-organic frameworks (MOFs) have influenced many fields of material science. In recent years, they have gained significant attention as precursors or templates for the derivation of porous metal oxide nanostructures and nanocomposites for next-generation supercapacitor applications. Even though these materials have widespread applications and have been widely studied in terms of their structural features and synthesis, it is still not clear how these materials will play an important role in the development of the supercapacitor field. In this review, we will summarize the recent developments in the field of MOF-derived porous metal oxide nanostructures and nanocomposites for supercapacitor applications. Furthermore, the current challenges along with the future trends and prospects in the application of these materials for supercapacitors will also be discussed. © 2017 American Chemical Society.","energy storage; hollow nanomaterials; hybrid materials; metal-organic frameworks; MOF-derived oxides; nanocomposites; porous metal oxides; supercapacitors","Crystalline materials; Energy storage; Hybrid materials; Java programming language; Metallic compounds; Nanocomposites; Nanostructured materials; Nanostructures; Supercapacitor; Transition metal compounds; Electrical conductivity; Electrochemical response; Energy storage applications; Metal organic framework; Metalorganic frameworks (MOFs); Porous metal oxides; Supercapacitor application; Transition-metal oxides; Metals",2-s2.0-85021398704
"Kailong Z., Min W., Hang S., Ansheng Y., De La Fortelle A., Kejian M.","QoS-CITS: A simulator for service-oriented cooperative ITS of intelligent vehicles",2017,"Proceedings - 16th IEEE/ACIS International Conference on Computer and Information Science, ICIS 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030642380&doi=10.1109%2fICIS.2017.7960093&partnerID=40&md5=c21b4648693d420344aeea7a5b64e76e","With the emerging vehicular network and the possible diverse applications, Intelligent Transportation Systems (ITS) have been evolving to Cooperative ITS (C-ITS, CITS) with connected intelligent vehicles, and the topics in this domain also raise more and more research interesting recently. However, subjecting to the immaturity of V2X communication technology and the deployment of intelligent vehicles in large scale, such studies and the corresponding verification are all challenged within current situations. Focusing on several emerging features, such as cyber-physical fusion, vehicular networking, service-carrier etc, a new simulator QoS-CITS for such service-oriented C-ITS is designed. To enhance the adaptivity, an para-reconfigurable architecture is firstly adopted, within which all reservation-based models of traffic objects, state-driven behaviors, cooperation mechanisms, and policies proposed for service-oriented C-ITS are implemented. And then, a series of experiments are conducted via employing parameters within typical scenes, and all fundamental functions of QoS-CITS are verified. With this simulator, researchers can carry out various experiments, not only classic ones but service-oriented, via setting parameters according to their study and verification requirements, and then analyze the performance with statistics data automatically recorded. © 2017 IEEE.","Cooperative ITS; Intelligent Vehicle; Model; Service-oriented; Simulator; V2X","Behavioral research; C (programming language); Intelligent systems; Models; Quality of service; Reconfigurable architectures; Service oriented architecture (SOA); Simulators; Vehicle to vehicle communications; Vehicles; Communication technologies; Cooperation mechanism; Cooperative ITS; Diverse applications; Intelligent transportation systems; Service Oriented; Vehicular networkings; Vehicular networks; Intelligent vehicle highway systems",2-s2.0-85030642380
"Buru C.T., Li P., Mehdi B.L., Dohnalkova A., Platero-Prats A.E., Browning N.D., Chapman K.W., Hupp J.T., Farha O.K.","Adsorption of a Catalytically Accessible Polyoxometalate in a Mesoporous Channel-type Metal-Organic Framework",2017,"Chemistry of Materials",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021452199&doi=10.1021%2facs.chemmater.7b00750&partnerID=40&md5=14cbb0fa29f02598af29adb349d07e34","A Keggin-type polyoxometalate (H3PW12O40) was incorporated into a mesoporous Zr-based MOF (NU-1000) via an impregnation method in aqueous media, resulting in the hybrid material, PW12@NU-1000. The POM@MOF composite was characterized by a suite of physical methods, indicating the retention of crystallinity and high porosity of the parent MOF. The hybrid material was also stable to leaching in aqueous media at varying pH. Finally, the material was tested as a heterogeneous catalyst for the oxidation of 2-chloroethyl ethyl sulfide using hydrogen peroxide as the oxidant. PW12@NU-1000 was shown to have a higher catalytic activity than either of the individual constituents alone. © 2017 American Chemical Society.",,"Catalyst activity; Crystalline materials; Hybrid materials; Java programming language; 2-chloroethyl ethyl sulfides; Aqueous media; Crystallinities; Heterogeneous catalyst; Impregnation methods; Metal organic framework; Physical methods; Polyoxometalates; Oxides",2-s2.0-85021452199
"Mostafiz M.I., Mahmud S.M.F., Hussain M.M.-U., Ali M.E., Trajcevski G.","Class-based conditional MaxRS query in spatial data streams",2017,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025589327&doi=10.1145%2f3085504.3085517&partnerID=40&md5=03fa47989db0cf580f787e9c0b5a81a8","We address the problem of maintaining the correct answer-sets to the Conditional Maximizing Range-Sum (C-MaxRS) query in spatial data streams. Given a set of (possibly weighted) 2D point objects, the traditional MaxRS problem determines an optimal placement for an axes-parallel rectangle r so that the number-or, the weighted sum-of objects in its interior is maximized. In many practical settings, the objects from a particular set-e.g., restaurants-can be of distinct types-e.g., fast-food, Asian, etc. The C-MaxRS problem deals with maximizing the overall sum, given class-based existential constraints, i.e., a lower bound on the count of objects of interests from particular classes. We first propose an efficient algorithm to the static C-MaxRS query, and extend the solution to handle dynamic (data streams) settings. Our experiments over datasets of up to 100,000 objects show that the proposed solutions provide significant efficiency benefits. © 2017 Association for Computing Machinery.","C-MaxRS; Conditional MaxRS; Constrained query processing; Maximizing range sum query; Spatial data streams","Data communication systems; Management information systems; Query processing; Class-based; Conditional MaxRS; Efficiency benefits; Lower bounds; Optimal placements; Spatial data streams; Sum-query; Weighted Sum; C (programming language)",2-s2.0-85025589327
"Rui R., Tu Y.-C.","Fast equi-join algorithms on GPUs: Design and implementation",2017,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025658384&doi=10.1145%2f3085504.3085521&partnerID=40&md5=e0031caf9a243859ffc4852017ae7c6a","Processing relational joins on modern GPUs has attracted much attention in the past few years. With the rapid development on the hardware and software environment in the GPU world, the existing GPU join algorithms designed for earlier architecture cannot make the most out of latest GPU products. In this paper, we report new design and implementation of join algorithms with high performance under today's GPGPU environment. This is a key component of our scientific database engine named G-SDMS. In particular, we overhaul the popular radix hash join and redesign sort-merge join algorithms on GPUs by applying a series of novel techniques to utilize the hardware capacity of latest Nvidia GPU architecture and new features of the CUDA programming framework. Our algorithms take advantage of revised hardware arrangement, larger register file and shared memory, native atomic operation, dynamic parallelism, and CUDA Streams. Experiments show that our new hash join algorithm is 2.0 to 14.6 times as efficient as existing GPU implementation, while the new sort-merge join achieves a speedup of 4.0X to 4.9X. Compared to the best CPU sort-merge join and hash join known to date, our optimized code achieves up to 10.5X and 5.5X speedup. Moreover, we extend our design to scenarios where large data tables cannot fit in the GPU memory. © 2017 ACM.",,"Computer hardware description languages; Database systems; Graphics processing unit; Hardware; Hash functions; Management information systems; Memory architecture; Program processors; Atomic operation; CUDA Programming; Design and implementations; GPU implementation; Hardware and software; Novel techniques; Register files; Scientific database; Computer hardware",2-s2.0-85025658384
"Evans N., Olivier S.L., Barrett R., Stelle G.","Scheduling Chapel tasks with Qthreads on manycore: A tale of two schedulers",2017,"Proceedings of the 7th International Workshop on Runtime and Operating Systems for Supercomputers, ROSS 2017 - In conjunction with HPDC",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025588971&doi=10.1145%2f3095770.3095774&partnerID=40&md5=b8e40a94765a720e4d007c58cb4b548a","This paper describes improvements in task scheduling for the Chapel parallel programming language provided in its default on-node tasking runtime, the Qthreads library. We describe a new scheduler distrib which builds on the approaches of two previous Qthreads schedulers, Sherwood and Nemesis, and combines the best aspects of both-work stealing and load balancing from Sherwood and a lock free queue access from Nemesis- to make task queuing better suited for the use of Chapel in the manycore era. We demonstrate the efficacy of this new scheduler by showing improvements in various individual benchmarks of the Chapel test suite on the Intel Knights Landing architecture. © 2017 ACM.","Chapel; Qthreads; Task queues; Work stealing","Parallel programming; Queueing theory; Supercomputers; Chapel; Lock-free; Many-core; Qthreads; Task queues; Task queuing; Task-scheduling; Work stealing; Scheduling",2-s2.0-85025588971
"Cominsky L., Peruta C., Wandling S., McCarthy B., Li L.","Learning by Making for STEM success",2017,"IDC 2017 - Proceedings of the 2017 ACM Conference on Interaction Design and Children",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026324179&doi=10.1145%2f3078072.3081315&partnerID=40&md5=6c8b397a8b5565e834396801692765ed","Sonoma State University's Learning by Making program, funded by the US Department of Education's Investing in Innovation program, has created a one-year course that is now approved as a college preparatory Science Laboratory course (Area D) by the UC/CSU Doorways process. An innovative hardware platform has been developed that has been optimized for use by students in high needs rural communities with low Internet bandwidth. All programming is done in the Logo language that supports experimental design, use of a variety of environmental and physical sensors, and analysis of the resulting data. © 2017 Copyright is held by the owner/author(s).","Experiments; High-school curriculum; Logo; Making; NGSS; STEM","Education; Experiments; Hardware platform; High school curriculum; Innovation programs; Logo; Making; NGSS; Science laboratories; US Department of Education; STEM (science, technology, engineering and mathematics)",2-s2.0-85026324179
"Gourlet P., Le Goc M., Follmer S.","Revisiting turtles and termites: An open-ended interactive physical game with multiple robots",2017,"IDC 2017 - Proceedings of the 2017 ACM Conference on Interaction Design and Children",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026305370&doi=10.1145%2f3078072.3091979&partnerID=40&md5=b07bdb04482cd39eea7b4c422e81dfde","We present a first prototype of an open-ended interactive physical game aiming at developing children's understanding of dynamic systems in a playful and embodied way. We use a swarm user interface, Zooids, developed by Le Goc et al., made of independent self-propelled elements that move collectively and react to user input. Papert promoted an active way of developing a computational literacy, through programming a turtle with LOGO, from which Resnick proposed StarLogo, a ""multi-turtles"" language to simulate complex systems behaviors. Our interface is positioned in between these two perspectives: it allows to physically interact with multiple ""turtles"", each having its own dynamic. Each Zooid can be assigned an action that will affect the system behavior. Based on this principle, our first prototype invites children to resolve situations by changing individual actions in a dynamic system. © 2017 Copyright is held by the owner/author(s).","Computational thinking; Game; Open-ended play; System thinking; Tangibles","Dynamical systems; User interfaces; Computational thinkings; Game; Open-ended play; System thinkings; Tangibles; Dynamics",2-s2.0-85026305370
"Johri A., Yang S.","Scaffolded help for learning: How experts collaboratively support newcomer participation in online communities",2017,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025118701&doi=10.1145%2f3083671.3083694&partnerID=40&md5=20f6be6545e90cc400b46b9166d55e74","Online communities, often in the form of discussion forums, encapsulate the very notion of ""doing good with technology"" by serving as a conduit for help-seeking and problem-solving by users who volunteer their time and effort. One form of helping is assisting others with learning new content, an under-examined topic within the context of online communities, and in this paper we present a study investigating how online discussion forums go beyond informational support and guide newcomers. learning. We analyzed a forum dedicated to helping newcomers learn the programming language Javaâ. Using an empirical approach that combined analysis of forum data with interviews with expert we found that experts consciously and collaboratively scaffolded newcomers. learning by creating shared understanding, providing ongoing diagnosis, and fading their help over time. Multiple resources were leveraged for scaffolding and learners often received personalized instruction through collaborative contributions of multiple experts on the forum. © 2017 Copyright is held by the owner/author(s).","Expert-novice collaboration; Online communities; Scaffolding","Distributed computer systems; E-learning; Java programming language; Online systems; Scaffolds; Social networking (online); Empirical approach; Expert-novice collaboration; Informational support; On-line communities; Online discussion forums; Personalized instruction; Scaffolding; Shared understanding; Education",2-s2.0-85025118701
"Demey L.","The Porphyrian Tree and Multiple Inheritance: A Rejoinder to Tylman on Computer Science and Philosophy",2017,"Foundations of Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021294369&doi=10.1007%2fs10699-017-9531-1&partnerID=40&md5=27386aaf80646afa90720109f8b3a6ef","Tylman (Found Sci, 2017) has recently pointed out some striking conceptual and methodological analogies between philosophy and computer science. In this paper, I focus on one of Tylman’s most convincing cases, viz. the similarity between Plato’s theory of Ideas and the object-oriented programming (OOP) paradigm, and analyze it in some more detail. In particular, I argue that the (Neo)platonic doctrine of the Porphyrian tree corresponds to the fact that most object-oriented programming languages do not support multiple inheritance. This analysis further reinforces Tylman’s point regarding the conceptual continuity between classical metaphysical theorizing and contemporary computer science. © 2017 Springer Science+Business Media B.V.","Computer science; Diamond problem; Multiple inheritance; Neoplatonic metaphysics; Object-oriented programming; Porphyrian tree","Computer programming; Computer science; Forestry; Multiple inheritance; Neoplatonic metaphysics; Objectoriented programming (OOP); Porphyrian tree; S-theory; Object oriented programming",2-s2.0-85021294369
"Mitchell R., Olsson T.","Barriers for bridging interpersonal gaps: Three inspirational design patterns for increasing collocated social interaction",2017,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025125983&doi=10.1145%2f3083671.3083697&partnerID=40&md5=5ab1de71989b0bbebd336b7d74931b07","Positive face-to-face social encounters between strangers can strengthen the sense of community in modern urban environments. However, it is not always easy to initiate friendly encounters due to various inhibiting social norms. We present three inspirational design patterns for reducing inhibitions to interact with unfamiliar others. These abstractions are based on a broad design space review of concepts, encompassing examples across a range of scales, fields, media and forms. Each inspirational pattern is formulated as a response to a different challenge to initiating social interaction but all share an underlying similarity in offering varieties of barriers and filters that paradoxically also separate people. The patterns are ""Closer Through Not Seeing""; ""Closer Through Not Touching""; and ""Minimize Encounter Duration"". We believe these patterns can support designers, in understanding, articulating, and generating approaches to creating embodied interventions and systems that enable unacquainted people to interact. © 2017 Copyright is held by the owner/author(s).","Collocated interaction; Face-to-face interaction; Social interaction design, pattern languages, embodied interaction","Computer applications; Computer programming; Collocated interactions; Design Patterns; Design spaces; Face-to-face interaction; Pattern languages; Sense of community; Social interactions; Urban environments; Social sciences",2-s2.0-85025125983
"Hua F., Wang X., Li J., Ma M., Niu W.","Development and application of impact testing machine for spot-welded joints",2017,"Hanjie Xuebao/Transactions of the China Welding Institution",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029485963&partnerID=40&md5=1036c2cac51a6c32b7953fbd559505a4","In order to research and evaluate the impact properties of resistance spot-welded joints, a pendulum impact to test machine and fixtures was developed. And the control system, human-machine interface, data acquisition system and data processing algorithm were also developed based on the Labview software and high speed data acquisition card. All the above hardware equipment and software constitute an integrated system for the performance testing of spot-welded joints. With the testing machine, the impact properties of DP980 specimens welded with different currents were measured. Based on the measured data, the consistency of the impact forces, maximum swing angles and total absorbed energies measured and calculated with several different methods were compared and analyzed in detail. It is concluded that the measured impact force is reliable, the data processing algorithm is correct, and the testing results can be used for evaluating the impact properties of spot-welded joints. © 2017, Editorial Board of Transactions of the China Welding Institution, Magazine Agency Welding. All right reserved.","Absorbed energy; Dynamic strength; Impact testing machine; Resistance spot welding; Tension shear impact","Computer programming languages; Data acquisition; Data handling; Impact testing; Materials testing apparatus; Resistance welding; Software testing; Spot welding; Welds; Absorbed energy; Dynamic strength; Impact testing machines; Resistance spot welding; Tension shear; Welding",2-s2.0-85029485963
"Xu M., Tian W., Buyya R.","A survey on load balancing algorithms for virtual machines placement in cloud computing",2017,"Concurrency Computation ",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014473446&doi=10.1002%2fcpe.4123&partnerID=40&md5=665604c5cd3e14e49e741be71072042a","The emergence of cloud computing based on virtualization technologies brings huge opportunities to host virtual resource at low cost without the need of owning any infrastructure. Virtualization technologies enable users to acquire, configure, and be charged on pay-per-use basis. However, cloud data centers mostly comprise heterogeneous commodity servers hosting multiple virtual machines (VMs) with potential various specifications and fluctuating resource usages, which may cause imbalanced resource utilization within servers that may lead to performance degradation and service level agreements violations. So as to achieve efficient scheduling, these challenges should be addressed and solved by using load balancing strategies, which have been proved to be nondeterministic polynomial time (NP)-hard problem. From multiple perspectives, this work identifies the challenges and analyzes existing algorithms for allocating VMs to hosts in infrastructure clouds, especially focuses on load balancing. A detailed classification targeting load balancing algorithms for VM placement in cloud data centers is investigated, and the surveyed algorithms are classified according to the classification. The goal of this paper is to provide a comprehensive and comparative understanding of existing literature and aid researchers by providing an insight for potential future enhancements. Copyright © 2017 John Wiley & Sons, Ltd.","cloud computing; data centers; load balancing; placement algorithms; virtual machine","Java programming language; Network security; Polynomial approximation; Resource allocation; Surveys; Virtual machine; Virtual reality; Virtualization; Data centers; Detailed classification; Load balancing algorithms; Nondeterministic polynomial; Performance degradation; Placement algorithm; Service Level Agreements; Virtualization technologies; Cloud computing",2-s2.0-85014473446
"Sun L., Frederick C., Ding L., Rohmeyer R.","The application of second language acquisition to programming language study",2017,"ASEE Annual Conference and Exposition, Conference Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030536516&partnerID=40&md5=3a2c2d767c15544deeb887f357e50c33","This paper describes a design and implementation of a Second Language Acquisition in a Blended Learning (SLA-aBLe) project that aims to examine the efficacy of SLA approaches for teaching programming language. The project, which has been running for three semesters, modifies specific learning modules in a programming language class using a series of shorter videos with subtitles, online quizzes with tiered questions and comments, and a topic specified discussion board with Q&A sections. The SLA aspect of the SLA-aBLe study is emphasized through the use of strategies defined as best-practice SLA techniques, such as the inclusion of self-testing tired questions and visual-aided explanation in screencasts, more online programming writing assessment, more collaboration, and 'speak aloud' in labs. A series of surveys assessing students' perceptions, attitudes, and satisfaction of students in the SLA-aBLe, and control groups were analyzed. Their academic performance on exam scores was compared. A random group of students were selected and interviewed face-to-face each semester to understand the effectiveness of the SLA-aBLe design. Assessment results confirmed the effectiveness of SLA-aBLe design. © American Society for Engineering Education, 2017.",,"Ada (programming language); Computer programming languages; Engineering education; Students; Academic performance; Blended learning; Design and implementations; Discussion boards; On-line programming; Second language acquisition; Specific learning; Teaching programming; Education",2-s2.0-85030536516
"Frederick C., Sun L.","Work in progress: Using second language acquisition techniques to teach programming - Results from a two-year project",2017,"ASEE Annual Conference and Exposition, Conference Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030564567&partnerID=40&md5=d0003f26157086d4ff921dfd886348e7","This WIP paper presents two years of findings for an NSF funded project under the Research Initiation Grant in Engineering Education (RIGEE) program. The project (SLA-aBLe) is currently in the second year of implementation and assessment. Final results from the project will be presented and discussed at the annual ASEE conference. The project used second language acquisition (SLA) theory and techniques to facilitate learning in an introductory programming language class. The project was developed by a multi-disciplinary team and involved multiple instructors and sections of an introductory programming language class using MATLAB. Each semester, instructors trained in SLA techniques taught sections of both the SLA-aBLe and non-SLA-aBLe programming language course, and the performance of students in the different type of course sections was compared. Assessment of effectiveness was conducted in a scientifically rigorous and extensive manner, using multiple surveys, student grades and instructor assessment. Results from the first year of implementation indicated that students in the SLA-aBLe sections of the programming class exhibited higher end of course lab scores, exam scores and grades than students in non-SLA-aBLe sections of the same course. In addition, students in the SLA-aBLe sections reported higher levels of motivation and less frustration than students in the non-SLA-aBLe sections of the class. Perceptions of faculty competence did not differ by type of course section or across faculty teaching the class. This project is continuing into its final year of implementation during the 2016-2017 academic year. Researchers will continue to assess the course using student perceptions, and class outcomes to determine effectiveness of the program. The proposed paper will focus on presenting two years of data from the project, including discussion of the overall success of using SLA techniques in engineering education. © American Society for Engineering Education, 2017.",,"Ada (programming language); Computer programming languages; Education; Engineering education; MATLAB; Students; First year; Introductory programming; Multi-disciplinary teams; Programming class; Second language acquisition; Student grades; Student perceptions; Work in progress; Teaching",2-s2.0-85030564567
"Ham T.R., Amini R.","Learning two programming languages in one semester does not adversely affect undergraduate biomedical engineering student performance",2017,"ASEE Annual Conference and Exposition, Conference Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030526412&partnerID=40&md5=739090b58ada7f3b2a36b4c5b03387ac",[No abstract available],,"Biomedical engineering; Engineering education; Students; Student performance; Education",2-s2.0-85030526412
"Lawson W.G., Secules S., Bhattacharyya S., Elby A., Hawkins W., Dumitras T., Ramirez N.","Traditional versus hardware-driven introductory programming courses: A comparison of student identity, efficacy and success",2017,"ASEE Annual Conference and Exposition, Conference Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030545280&partnerID=40&md5=5cb9c188d2d399943514b04ac362c6f5","This paper compares an innovative approach to teaching an introductory C programming course to a traditional C programming course for electrical engineering students. Students who pass either course must subsequently take a traditional intermediate C programming course. The novel course utilizes hardware-based projects to motivate students to master language syntax and implement key programming concepts and best practices. In addition to comparing the attitudes and self-perceptions of the students in each of the introductory courses, we also look at success rates for each cohort in the intermediate programming class as well as their progress toward their degrees. The electrical engineering students who took either introductory class on average had identical GPAs. However, students who took the novel introductory C course did somewhat better than the other cohort in the intermediate traditional class. Furthermore, after students took the novel course, they were more likely to feel that they fit in as electrical engineers and less likely to believe that programming was ""not real engineering."" This increase spanned a number of subgroups within the course, including students from underserved populations. Additional results, a synopsis of the two introductory courses, and a description of a technology-driven intermediate programming course are presented and discussed in this paper. © American Society for Engineering Education, 2017.",,"Engineering education; Hardware; Students; Teaching; Electrical engineering students; Innovative approaches; Introductory course; Introductory programming course; Programming class; Programming concepts; Programming course; Real engineering; C (programming language)",2-s2.0-85030545280
"Qiu T., Feng M., Lu S., Li Z., Wu Y., Zoltowski C.B., Lu Y.-H.","Online programming system for code analysis and activity tracking",2017,"ASEE Annual Conference and Exposition, Conference Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030537013&partnerID=40&md5=872b7ef4fc7288b223e15bb4d4841af2","Many tools have been developed to assist programmers develop high-quality code. However, installing, updating, configuring, learning, and running these tools can be unnecessary burden on students. Moreover, instructors do not have detailed knowledge about students' learning experience before programming assignments are submitted. This paper presents an online system that can automatically analyze students' programs and provides insightful information about their code. This system records every syntax and run-time error so that an instructor can obtain real-time view of students' activities and progress. Hence, the instructor can identify common misconceptions before an assignment is due. This system is evaluated in an A-B test of a sophomore C programming class of 42 students. The results suggest that this system has positive effect on helping students learn. © American Society for Engineering Education, 2017.","Online education; Web-based technology","Codes (symbols); Distance education; Education; Engineering education; Students; Activity tracking; On-line education; On-line programming; Programming assignments; Run-time errors; Students' learning experiences; Students' projects; Web-based technologies; C (programming language)",2-s2.0-85030537013
"Barham R., Hsieh S.-J.T.","MAKER: Smart packaging machine simulator for teaching ladder logic programming",2017,"ASEE Annual Conference and Exposition, Conference Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030545166&partnerID=40&md5=58c580ed3bc4ef65a326852a8c7b9548","This paper describes the results of an instructional pilot in programmable logic controller (PLC) programming in the ladder-logic language. As an extra-credit opportunity, students were invited to participate in a programming activity in ladder-logic that consisted of the following: 1) a preinstructional assessment of prior knowledge, (2) an online slideshow presentation that introduces PLCs, including future training and employment opportunities, (3) an online post-instructional assessment of acquired knowledge, and (4) an opinion survey designed to measure student demand for a course that teaches industrial automation. These data were meant to be shared with school administration so that changes to the course catalog would be properly informed by documented student need. The instructional machine was created as a result of attending a Summer Research Experiences for Teachers program at Texas A&M University in 2016. © American Society for Engineering Education, 2017.",,"Computer circuits; Engineering education; Ladders; Logic programming; Students; Employment opportunities; Industrial automation; Ladder logic programming; Opinion surveys; Programmable logic controller programming; Programming activities; Research Experiences for Teachers; Student demands; Teaching",2-s2.0-85030545166
"Brophy S.P., Lowe T.A.","A learning trajectory for developing computational thinking and programming",2017,"ASEE Annual Conference and Exposition, Conference Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030531483&partnerID=40&md5=744af05462184aa6377a14b400560975","This research study identifies the relationship between students' prior experiences with programming and their development of computational thinking and programming during their first year engineering experience. Many first year programs teach students basic programming concepts using languages like MATLAB or LABView. These languages are used because many of the disciplinary schools expect students to use computational models to analyze systems of interest. Some undergraduate engineering students are entering college with strong computational backgrounds, while others have no experience at all. This study is the first in a series to better identify students' transition into developing and reasoning with analytical tools. The learning progression across two programming languages is critical to developing a student's ability to generalize across various computational tools. The goal of this study is to identify how students progress in their ability to engage in computational thinking and programming relative to other learning outcomes for the course. This initial investigation uses students' prior background in programming and their exam scores to evaluate their interdependence of prior knowledge on learning programming across their first semester in university. As anticipated, learning a new language is difficult compared to the other course objectives. However, students with some prior knowledge of programming demonstrate a balanced performance between computational thinking and the other course objectives. Students who have limited programming experience do demonstrate a higher variance in their performance in problems related to computational thinking compared to their other course objectives. One of the leading factors is the time spent practicing programming. This paper will be of interest to instructors with the objective of developing computational thinking and programming in classrooms with a large variance in students' backgrounds with programming. © American Society for Engineering Education, 2017.",,"Computational methods; Curricula; Education; Engineering education; MATLAB; Professional aspects; Teaching; Computational thinkings; First-year engineering experience; Learning programming; Learning progressions; Learning trajectories; Programming concepts; Programming experience; Undergraduate engineering students; Students",2-s2.0-85030531483
"Choi J., Shull T., Garzaran M.J., Torrellas J.","ShortCut: Architectural support for fast object access in scripting languages",2017,"Proceedings - International Symposium on Computer Architecture",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025679719&doi=10.1145%2f3079856.3080237&partnerID=40&md5=626dc4a6082be053550cc520c34d13d6","The same flexibility that makes dynamic scripting languages appealing to programmers is also the primary cause of their low performance. To access objects of potentially different types, the compiler creates a dispatcher with a series of if statements, each performing a comparison to a type and a jump to a handler. This induces major overhead in instructions executed and branches mispredicted. This paper proposes architectural support to signifcantly improve the effciency of accesses to objects. The idea is to modify the instruction that calls the dispatcher so that, under most conditions, it skips most of the branches and instructions needed to reach the correct handler, and sometimes even the execution of the handler itself. Our novel architecture, called ShortCut, performs two levels of optimization. Its Plain design transforms the call to the dispatcher into a call to the correct handler-bypassing the whole dispatcher execution. Its Aggressive design transforms the call to the dispatcher into a simple load or store-bypassing the execution of both dispatcher and handler. We implement the ShortCut software in the state-of-the-art Google V8 JIT compiler, and the ShortCut hardware in a simulator. We evaluate ShortCut with the Octane and SunSpider JavaScript application suites. Plain ShortCut reduces the average execution time of the applications by 30% running under the baseline compiler, and by 11% running under the maximum level of compiler optimization. Aggressive ShortCut performs only slightly better. © 2017 Association for Computing Machinery.","Inline Caching; JavaScript; Microarchitecture; Scripting Language","Computer software; High level languages; Java programming language; Program compilers; Architectural support; Average Execution Time; Compiler optimizations; Inline Caching; Javascript; Micro architectures; Novel architecture; Scripting languages; Computer architecture",2-s2.0-85025679719
"Kolli A., Gogte V., Saidi A., Diestelhorst S., Chen P.M., Narayanasamy S., Wenisch T.F.","Language-level persistency",2017,"Proceedings - International Symposium on Computer Architecture",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025622238&doi=10.1145%2f3079856.3080229&partnerID=40&md5=d89877d4bfe62a0021634cfeec8c72bb","The commercial release of byte-addressable persistent memories, such as Intel/Micron 3D XPoint memory, is imminent. Ongoing research has sought mechanisms to allow programmers to implement recoverable data structures in these new main memories. Ensuring recoverability requires programmer control of the order of persistent stores; recent work proposes persistency models as an extension to memory consistency to specify such ordering. Prior work has considered persistency models at the abstraction of the instruction set architecture. Instead, we argue for extending the language-level memory model to provide guarantees on the order of persistent writes. We explore a taxonomy of guarantees a language-level persistency model might provide, considering both atomicity and ordering constraints on groups of persistent stores. Then, we propose and evaluate Acquire-Release Persistency (ARP), a language-level persistency model for C++11. We describe how to compile code written for ARP to a state-of-the-art ISA-level persistency model. We then consider enhancements to the ISA-level persistency model that can distinguish memory consistency constraints required for proper synchronization but unnecessary for correct recovery. With these optimizations, we show that ARP increases performance by up to 33.2% (19.8% avg.) over coding directly to the baseline ISA-level persistency model for a suite of persistent-write-intensive workloads. © 2017 Association for Computing Machinery.","Language-level models; Memory persistency; Persistent memories","C++ (programming language); Internet protocols; Memory architecture; Instruction set architecture; Language levels; Memory consistency; Memory modeling; Ordering constraints; Persistent memory; State of the art; Write-intensive workloads; Computer architecture",2-s2.0-85025622238
"Li Z., Liu L., Deng Y., Yin S., Wang Y., Wei S.","Aggressive pipelining of irregular applications on reconfigurable hardware",2017,"Proceedings - International Symposium on Computer Architecture",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025579436&doi=10.1145%2f3079856.3080228&partnerID=40&md5=9c9e400d7e68652e35b82acc7ba4bcab","CPU-FPGA heterogeneous platforms offer a promising solution for high-performance and energy-effcient computing systems by providing specialized accelerators with post-silicon reconfgurability. To unleash the power of FPGA, however, the programmability gap has to be flled so that applications specifed in high-level programming languages can be effciently mapped and scheduled on FPGA. The above problem is even more challenging for irregular applications, in which the execution dependency can only be determined at run time. Thus over-serialized accelerators are generated from existing works that rely on compile time analysis to schedule the computation. In this work, we propose a comprehensive software-hardware co-design framework, which captures parallelism in irregular applications and aggressively schedules pipelined execution on reconfgurable platform. Based on an inherently parallel abstraction packaging parallelism for runtime schedule, our framework signifcantly differs from existing works that tend to schedule executions at compile time. An irregular application is formulated as a set of tasks with their dependencies specifed as rules describing the conditions under which a subset of tasks can be executed concurrently. Then datapaths on FPGA will be generated by transforming applications in the formulation into task pipelines orchestrated by evaluating rules at runtime, which could exploit fne-grained pipeline parallelism as handcrafted accelerators do. An evaluation shows that this framework is able to produce datapath with its quality close to handcrafted designs. Experiments show that generated accelerators are dramatically more effcient than those created by current high-level synthesis tools. Meanwhile, accelerators generated for a set of irregular applications attain 0.5x~1.9x performance compared to equivalent software implementations we selected on a server-grade 10-core processor, with the memory subsystem remaining as the bottleneck. © 2017 Association for Computing Machinery.","FPGA; Hardware Accelerator; Parallel Programming","Acceleration; Application programs; Computer architecture; Computer hardware; Data flow analysis; Field programmable gate arrays (FPGA); Hardware; Hardware-software codesign; High level languages; High level synthesis; Memory architecture; Parallel programming; Pipeline processing systems; Pipelines; Quality control; Computing system; Hardware accelerators; Heterogeneous platforms; High-level programming language; Irregular applications; Memory subsystems; Pipeline parallelisms; Software implementation; Reconfigurable hardware",2-s2.0-85025579436
"Luo C., Wang J., Zhao W., Wang L.","Multi-lab-driven learning method used for robotics ROS System development",2017,"ASEE Annual Conference and Exposition, Conference Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030528924&partnerID=40&md5=b7e977168887c86208a51b1e00ffd7ea","The Robot Operating System (ROS), a collection of tools, libraries, and conventions, is a powerful framework for programming robot software, and ROS-based mobile robot systems are becoming increasingly significant in human life. ROS has therefore been extensively taught in robotics program in electrical engineering programs. However, although it is a low-cost solution to allowing students to perform a variety of simulations and validating new algorithms before implementing them on an actual mobile robot, teaching ROS so that students can use it efficiently and effectively is a challenging task. Regular electrical engineering courses on ROS may focus on theories but neglect hands-on experiences. Traditional lab-driven pedagogy may provide hands-on opportunities on ROS itself but may still not bring students close enough to the actual applications of ROS to their major robot projects in their electrical engineering education. In this paper, a technological content knowledge (TCK) based method is utilized to create learning opportunities that allow students to construct their knowledge of the technology/tool (the T) in close relation to the content/robot programming (the C). The multi-lab-driven method (MLDM) was employed to construct the TCK of ROS of students in the context of designing an autonomous mobile robot system. A sequence of multiple labs were assigned to students to cover various topics in the ROS. A variety of labs that reflect the ROS experiments and assist students in better understanding robotics programming were elaborately managed. Based on students' performance on various lab assignments, lab reports, presentations, the final robot project, students' input to the official course evaluation administered by the university, and a comparison to the instructor's previous years of teaching experience, we propose that the MLDM is effective in helping students to learn ROS efficiently and meaningfully in the real world of engineering projects. Preliminary assessment of this multi-lab-driven learning method for providing robotics education supports its effectiveness. © American Society for Engineering Education, 2017.",,"C (programming language); Curricula; Engineering education; Laboratories; Learning systems; Mobile robots; Robot programming; Robotics; Robots; Students; Teaching; Technical presentations; Autonomous Mobile Robot; Electrical engineering course; Electrical engineering programs; Engineering project; Learning opportunity; Mobile robot systems; Preliminary assessment; Robot operating systems (ROS); Education",2-s2.0-85030528924
"Rahemi H., He S., Ducharme M.","Summer Engineering Experience (SEE) program - A program to prepare freshmen students for engineering studies",2017,"ASEE Annual Conference and Exposition, Conference Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030562784&partnerID=40&md5=22651019313d0a31a3523471addad694","This paper details the development process of the Summer Engineering Experience (SEE) program implemented at Vaughn College in order to prepare first-year students for engineering programs. Unlike the traditional pre-engineering programs held in other universities or colleges, which are devoted mainly to mathematics or physics courses, the objective of the Vaughn program is to enhance students' hands-on, computational, programming, communication, and problem solving skills. The five-week SEE program was offered in the summer 2016, Monday through Thursday, from 8:00 am to 4:00 pm. Lectures and hands-on classes throughout the program covered topics such as engineering computation using MATLAB and C++, robotics, bridge truss design & analysis, technical writing and presentation. The Friday session of the SEE program was designated for technical seminars and workshops designed to enhance students' learning outcomes related to critical thinking, problem solving, and life-long learning. Guest speakers from the industry were invited to deliver lectures and host workshops current with today's technology. Given the rapid pace of technological change, the Friday seminar series and workshops were designed to foster in Vaughn's engineering students a mind-set receptive to changes in technology in order to prepare them for their future professional careers. During the last two weeks of the program, students were arranged into two to three person groups to work with a SEE faculty mentor and develop a project with real-world engineering application. These projects were presented on the final day of the SEE program, and faculty evaluated the student performances according to specific learning outcomes. A rubric survey was also distributed to students in order to assess the program's effectiveness. The implementation and assessment process of Vaughn's SEE program based on both faculty and students' survey results will be discussed in the ASEE Annual Conference. © American Society for Engineering Education, 2017.","C++; Freshmen students; MATLAB; Robotics; Workshops","Application programs; Bridges; C++ (programming language); Cesium; Computer software; Education; Employment; Engineering education; MATLAB; Problem solving; Professional aspects; Robotics; Surveys; Teaching; Technical presentations; Development process; Engineering applications; Engineering computation; First year students; Problem solving skills; Professional careers; Student performance; Technological change; Students",2-s2.0-85030562784
"Bugg R.A., Collins W., Kramer S.W.","Evolution of short-term international service-learning class in Quito, Ecuador",2017,"ASEE Annual Conference and Exposition, Conference Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030556872&partnerID=40&md5=7318fc5192931645c5c6a0c3d7828305","Many study abroad classes typically provide opportunities for students to travel and learn about different cultures in developed countries. The overwhelming majority of American students study abroad in Western Europe and Australia. However, the cost, duration and timing of these classes, often prevent some students from being able to participate during their undergraduate education. In order to help alleviate these common barriers, two faculty members at Auburn University designed and implemented a 10-day Service-Learning class to Quito, Ecuador. An international Service-Learning class is defined as: ""A structured academic experience in another country in which students (a) participate in an organized service activity that addresses identified community needs; (b) learn from direct interaction and crosscultural dialogue with others; and (c) reflect on the experience in such a way as to gain a deeper appreciation of the host country and, an enhanced sense of their own responsibilities as citizens, locally and globally"" (Bringle et al 2011). The class was designed to appeal to students who would not have otherwise considered studying abroad. In order to minimize the cost and curriculum disruption, the program fee was limited to $2, 500 and the 10 days coincided with the students' academic spring break. Academic credit was not offered in the 2010 initial class, but since 2012 - 2017, the class has been offered as a construction elective within the Building Science curriculum. The students and faculty typically work with a community construction project, usually an after school care center for 200-350 underprivileged children, consisting of a 4-story, 30, 000-sf concrete framed building. Students are given the opportunity to work on an Ecuadorian construction site using rudimentary tools and methods in order to serve an underprivileged population. This paper describes the design, implementation and evolution of this International Service-Learning class and international experience offered in the construction management curriculum. © American Society for Engineering Education, 2017.","Construction; Service-learning; Study-abroad","C (programming language); Construction; Curricula; Engineering education; Project management; Students; Auburn universities; Community constructions; Construction management; International experiences; International service learning; Service learning; Study abroad; Undergraduate education; Education",2-s2.0-85030556872
"Forin T.R., Sukumaran B., Farrell S., Hartman H., Jahan K., Dusseau R.A., Bhavsar P., Hand J., Bruckerhoff T.F.S.","Rethinking Engineering Diversity, Transforming Engineering Diversity (REDTED)",2017,"ASEE Annual Conference and Exposition, Conference Proceedings",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030554182&partnerID=40&md5=f7a03ea82b1196ead3d06802a87b3a02","The research project described in this paper is titled ""Rethinking Engineering Diversity, Transforming Engineering Diversity (REDTED),"" which is part of the National Science Foundation, Revolutionizing Engineering Department (RED) grants. The project is in its first year and therefore what is described in this paper will be a brief overview of the project and some of the work done during the first year. The proposed research is to explore how the representation of women and Underrepresented Minority (URM) students and historically underserved groups will be increased in an engineering department by deploying a multi-pronged approach. Our definition of diverse student populations includes both visible differences such as gender and racial minorities, but also includes invisible differences such as poor, LGBTQ, disabled, veterans, and others. The approach includes curricular and extra-curricular reform, which is targeted at the Civil and Environmental Engineering (CEE) Department at Rowan and includes: a) Radically changing admission standards to promote excellence; b) Enhancing the perception and understanding of diversity and equality among students, faculty and administrators to create a more inclusive environment; c) Developing Advocate and Allies Mentoring Program for first year, and transfer students; d) Transforming existing engineering curriculum of second and third year from a narrow sub-discipline based approach to a more inclusive, system-based approach; e) Enriching students' aspirations by providing successful and diverse role models from industry and academia; and f) Developing a model for inclusion of diverse students. The study is unique in that the definition of diversity is expanded to include both visible and invisible aspects. It also takes a comprehensive approach in seeking to attract a more diverse population into engineering while also making sure that the diverse students who do choose to pursue engineering find an inclusive and welcoming climate. The first year of the study has included conducting surveys of students and faculty to get baseline data on the attitudes to inclusivity. It will also include faculty workshops to begin the process of modifying our curriculum. In addition, the peer mentoring program and its structure is also being discussed and student workshops will be conducted to develop peer mentoring skills. © American Society for Engineering Education, 2017.",,"C (programming language); Curricula; Engineering education; Professional aspects; Standards; Curricular reforms; Engineering curriculum; Engineering department; Mentoring programs; National Science Foundations; Student populations; Student workshops; Underrepresented minorities; Students",2-s2.0-85030554182
"Jensen P.H., West M., Kellar J.J., Kellogg S.D., Karlin J., Degen C.M.","Culture and attitude: A scholarship, mentoring and professional development program to increase the number of women graduating with engineering degrees",2017,"ASEE Annual Conference and Exposition, Conference Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030559171&partnerID=40&md5=add24d0e86bf52c3e9585a1c7477f502","Industry, media, and academia desire a more diverse engineering workforce. In response to those needs, faculty at South Dakota School of Mines and Technology (SD Mines) established the Culture and Attitude (C&A) program in fall 2010 with the support of a National Science Foundation S-STEM award. The program provides scholarships for academically bright and financially needy women, and also recognizes the need to change the fundamental paradigm (culture) for recruiting, and retaining students, particularly women, in engineering. To that end, the C&A program created a strong mentoring program, one that advocated a transformational approach to serving women in engineering. The program began as a collaboration between Metallurgical and Industrial Engineering programs and expanded to the Mechanical Engineering program in year 3. Students were required to meet with a mentor and their advisor at varied frequency throughout the semester based on their academic standing and class. They were also required to attend professional development activities, professional society meetings, and social activities with the entire C&A group once a month. The professional development and social activities included both technical (laboratory) and social (teamwork) confidence building exercises. Program analysis was performed using traditional metrics (retention, the percentage of female enrolled and graduated) along with focus groups, longitudinal tracking, and examining student typology through Hermann Brain Dominance Inventory (HBDI). Students in the program were compared to the population that graduated from other engineering programs on campus. The retention, enrollment, and graduation rates of women increased in the initial five year period. Particularly noteworthy were the typology data, and focus group reactions to the program. HBDI results show that women at SD Mines think differently than their male counterparts, and majors with a greater percentage of women graduates received more than just the typical analytical engineering typology. C&A participants who received the scholarship in all three majors were more diverse in their typological preference. In other words, the participants were more entrepreneurial, highly detailed, empathetic engineers, a goal of the Engineer of 2020. Results from the focus groups showed that the professional activities were valued, but social activities were valued more. These findings became clearer in the focus group sessions where students indicated that the social activities allowed time for scholars to make social connections across academic disciplines. While much has been learned through approaching gender and intellectual diversity, much work remains before sustainable progress is made. Plans are now being developed to strengthen the program by incorporating service learning components as well as curricular changes for a broader institutionalization of the C&A program on campus. © American Society for Engineering Education, 2017.",,"Education; Engineering education; Professional aspects; Students; Confidence building; Mechanical engineering program; National Science Foundations; Professional activities; Professional development; Professional development program; Transformational approach; Women in engineering; C (programming language)",2-s2.0-85030559171
"Krause S.J., Middleton J.A., Hjelmstad K.D., Judson E., Culbertson R.J., Ankeny C.J., Chen Y.-C., Ross L., Mayled L.H., Lopez E., Park Y.S., Smith B.B.","Scaling a faculty professional development program to multiple disciplines through disciplinary communities of practice evolving from evidence-based workshops",2017,"ASEE Annual Conference and Exposition, Conference Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030544719&partnerID=40&md5=2c96ff48c6a8168cf25e4235433ffccc","For more effective teaching and learning in undergraduate engineering education, there is a strong need for faculty professional development to instruction from instructor-centered, information-transmission teaching by lecture to more student-centered, conceptual-change learning by active learning through student engagement. The National Science Foundation IUSE (Improving Undergraduate STEM Education) program has funded a large-scale faculty development program at a large southwestern university called Just-in-Time-Teaching with Two Way Formative Feedback for Multiple Disciplinary (JTFD) Programs. The project scales to seven engineering disciplines with 84 faculty using a train-the-trainer model to engage faculty in year-long apprenticeships with a semester of eight biweekly workshops followed by a semester of six biweekly mentor-supported classroom innovation implementation. Prior project research has shown that evidence-based practices such as student engagement, contextualization of content, and two-way formative feedback can improve student attitudes, achievement and persistence. Research also shows that changing faculty teaching beliefs toward evidence-based strategies and practices can be difficult, but the transition can be eased when disciplinary communities of practice support faculty while they are changing their beliefs and practices. The personal interactions that occur within and between the disciplinary communities of practice are being characterized in JTFD with social network analysis (SNA) and will be correlated to shifts, across time, in the beliefs and practice of the faculty toward student-centered instruction. Prior project SNA research has shown faculty who are socially better connected to one another also teach with more student-centered classroom practices, as found from classroom observations. This was assessed by a tool called Reformed Teaching Observation Protocol (RTOP) which has 25 items related to evidence based practice and is used by trained observers to assess classroom practice. Faculty beliefs and classroom practice are being assessed in JTFD with surveys, open ended questions and classroom observations. Faculty motivation is being assessed with a new survey using expectancy-value theory. The impact of faculty changes in classroom practice results have been collected during the spring 2016 term from four pairs of disciplinary leader trainers who completed the eight workshops. One result showed that the effect of the eight workshops on faculty's student-centered classroom practice, as measured by RTOP, was an improvement between 34% and 65%. Another result showed that, for two faculty, compared to the same class for a prior semester, significant gains in the student grade ratio (the ratio of A's plus B's to C's plus D's plus E's plus W's). Thus, the cohort of eight faculty trained during the Spring 2016 semester shifted their practice significantly from teacher-centered instruction to student-centered learning as shown by the classroom observation RTOP results. Because of the limited number of participants other measures of change in faculty beliefs and motivation were positive, but did not show statistical significance. Future cohorts with larger numbers of participants can reveal correlations between faculty beliefs, motivation and classroom practice. © American Society for Engineering Education, 2017.",,"C (programming language); Education; Education computing; Engineering education; Motivation; Occupational therapy; Surveys; Teaching; Technical presentations; Evidence-based practices; Information transmission; National Science Foundations; Professional development; Professional development program; Student centered instruction; Student-centered learning; Undergraduate engineering educations; Students",2-s2.0-85030544719
"Yildiz F., Coogler K.L.","An interdisciplinary experimental engineering projects course development",2017,"ASEE Annual Conference and Exposition, Conference Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030556477&partnerID=40&md5=9d1946d4ca82e31d593e7102829ad42f","The Engineering Technology (ET) program is one of several unique programs at Sam Houston State University. The program offers six Bachelor of Science (BS) Major degrees and a variety of courses for a BS Minor. The BS degrees offered in the program are: (a) Engineering Technology-Electronics; (b) Engineering Technology-Safety Management; (c) Construction Management; (d) Design and Development; (e) Electronics and Computer Engineering Technology; and (f) Industrial Education. All the students enrolled in one of these degree programs must take the same major core courses as well as the degree-specific courses as part of curriculum requirements. The common degree specific courses include Circuits, Engineering Graphics, Leadership and Management, Industrial Safety, etc. With these degree-specific requirements, students learn common content for ET degrees. Each of the six degrees require students to declare a minor in order to reach 120/123 hours as part of the curriculum requirement for graduation. In most cases, students select a minor from ET degrees, but any minor is allowed for students to declare (e.g., General Business). The goal of this interdisciplinary course is to engage ET students in engineering-related interdisciplinary projects. The new proposed course (junior/senior standing) gives an opportunity to those students majoring and minoring in ETrelated degrees to share and advance their knowledge with other students by working on an interdisciplinary project. Projects are assigned either by the course instructor or proposed by the students. This course design centers on its uniqueness, when compared to a standard capstone design course. The nature of the projects, student feedback, challenges, and outcomes/results are obtained through by implementation of the course. A comparison of the Interdisciplinary Experimental Engineering Project Course to a capstone course is offered in this paper. © American Society for Engineering Education, 2017.",,"Accident prevention; C (programming language); Education; Engineering education; Project management; Risk management; Safety engineering; Students; Capstone design course; Computer engineering technology; Construction management; Design and Development; Engineering graphics; Experimental engineering; Interdisciplinary course; Interdisciplinary project; Curricula",2-s2.0-85030556477
"Freeman A.L., Bandyopadhyay P.K., Johnson M., Kagan M., Schmiedekamp A.M., Shull P.J., Cohan C.","Board # 24: Sustainable Bridges from Campus to campus: Preliminary results from cohort 1",2017,"ASEE Annual Conference and Exposition, Conference Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030532675&partnerID=40&md5=0476965818465534d6dfee928a1a6cfc","The impetus for the Sustainable Bridges from Campus to Campus study is to address the urgent need to expand the pool of Science, Technology, Engineering, and Math (STEM) graduates, especially African American, Native American, and Hispanic students. Long-term improvements in the pipeline of a diverse STEM workforce start with sustaining effective bridge programs that can produce more Engineering baccalaureates. To improve retention in Engineering, this study will conduct academic enrichment programs for racially underrepresented Engineering students at three points in their career at the Penn State-entering freshmen, rising sophomores, and rising juniors. The goals of the study are to (a) increase retention in Engineering among racially underrepresented students in the Penn State system, (b) develop long-term sustainability plans for these enrichment programs, and (c) compare retention rates in Engineering depending on whether students attended a summer academic enhancement program at their local campus or at a different campus and whether they transfer between campuses within the University system. The guiding framework for the summer bridge programs is the Minority Engineering Program (MEP) Model. The study started in January 2016. During summer 2016, we conducted 5 summer bridge programs with the first cohort of freshmen across 4 campuses in the Penn State system. The students in Cohort 1 are currently in the fall semester of their freshmen year. At this early point in the study, our paper can present an overview of the project as well as reporting preliminary data on Cohort 1 after their first semester (Fall 2016). Academic performance data after the first semester include grade point average, math course grades, academic social support, and whether they are retained at the University. © American Society for Engineering Education, 2017.",,"C (programming language); Education; Engineering education; Professional aspects; STEM (science, technology, engineering and mathematics); Students; Academic performance; Grade point average; Long-term sustainability; Minority engineering programs; Science , technology , engineering , and maths; Summer Bridge Program; Sustainable bridges; Underrepresented students; Bridges",2-s2.0-85030532675
"Quan G.M., Turpen C.A., Gupta A., Tanu E.D.","Designing a course for peer educators in undergraduate engineering design courses",2017,"ASEE Annual Conference and Exposition, Conference Proceedings",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030556232&partnerID=40&md5=17db0471d132d7869202b4f72c6cd0de","Learning Assistants (LAs) are undergraduate peer educators who participate in weekly pedagogy seminars and work alongside faculty instructors in active-learning based undergraduate courses. While LA programs were initially developed for science and math courses, many LA programs support LAs in a wide range of disciplines. This paper describes a pilot adaptation of the LA program for engineering design courses that we have developed at the University of Maryland, College Park Campus. All LAs assist in 14 separate sections of University of Maryland's engineering design course for first-year undergraduate students. Our seminar integrates topics from the discipline-general LA pedagogy seminar (cognitive science of learning, facilitation of classroom discourse, collaboration, metacognition) with topics especially relevant to engineering design (design reviews, design thinking, expert-novice practices in engineering design, engineering epistemology, teamwork and equity). While seminar goals aligned with the goals of LA programs nationally, our seminar design team also articulated several values which guided the design of our seminar: a) helping LAs reframe their role as supporting growth rather than evaluation, b) valuing a broad set of metrics of success from day one, c) celebrating that different students bring in different expertise, and disrupting overly simplistic expertise/novice dichotomies, d) acknowledging that we all have different starting points and valuing a plurality of goals, e) helping our students track their own progress through reflecting on concrete representations of their thinking, and f) supporting LAs in developing deep disciplinary knowledge of design thinking. This paper describes the embodiment of these goals by highlighting several key features of the seminar. We conduct quantitative and qualitative analysis of several data sources (surveys, instructor reflections, field notes, and coursework) to assess the extent to which the embodiment of our values helped us meet our goals. Finally, we describe challenges and identify areas where we were not meeting our goals and describe some of the aspects of the seminar that we plan to revise in the next iteration. © American Society for Engineering Education, 2017.",,"C (programming language); Education; Engineering education; Students; Teaching; Engineering design; Engineering design course; Learning assistant; Quantitative and qualitative analysis; Undergraduate Courses; Undergraduate engineering; Undergraduate students; University of Maryland; Curricula",2-s2.0-85030556232
"Ragusa G., Slaughter J.B., Juarez C.","The impact of community college students' propensity for innovation on persistence in STEM majors",2017,"ASEE Annual Conference and Exposition, Conference Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030564481&partnerID=40&md5=46e0baaddd7d03871d3cb078a726c59e","There is a critical need for more students with engineering and science majors to enter into, persist, and graduate from postsecondary institutions. Increasing the diversity in engineering and science is also a profound identified need. According to national statistics, the largest groups of underrepresented minority students in engineering and science attend United States public higher education institutions and in particular the community colleges. Recent research has indicated that students from these populations who are strong problem solvers, and who understand how to seek assistance and navigate college campuses, are most likely persist to degree completion. Accordingly, this research examined a sample of non-traditional college students enrolled in science and engineering programs in four urban community colleges to determine (a) the types and frequency of support practices they utilized, (b) how such practices influenced their achievement, persistence and transfer status to four-year colleges and universities, and (c) how in turn their propensity for innovation and creative problem solving affected such choices and persistence. The study analyzed the impact of pedagogical support practices-practices designed to foster successful transfer from community college to four-year colleges and universities, and how students' innovative capability affected such transfer capacity. The goals were: (a) to understand whether particular pedagogical support practices were effective in offering nontraditional students a program that enabled them to remain in engineering and science majors and to transfer to a four-year college or university, and (b) to determine if students' propensity for innovative problem solving influenced use of pedagogical practices and ultimately, transfer persistence. The research targeted four research questions: (1) What are the patterns of pedagogical practices that community colleges employ to enhance students' transfer success in engineering and science? (2) How do students' creative and innovative problem solving approaches influence the choices that they make in using pedagogical support practices? (3) What are the impacts of pedagogical practices and differences among pedagogical practices, on persistence toward students' transfer to colleges and universities? (4) How do students' creative and innovative problem solving approaches influence their persistence toward transfer to engineering and science programs at four-year universities? This research involves a two-stage study in which in stage one, the types of pedagogical support practices used in community colleges were analyzed and taxonomized. Results of this part of research led to the delineation and refining of three categories of pedagogical support: (1) College attending support, (2) Program planning and execution support, and (3) Classroom and program performance support. These categories led to development and refinement of a college level pedagogical practice taxonomy and inventory which was used in stage two of the research in which data was collected on 2476 community college students in STEM majors. The intent of stage two of the research is to determine the role of students' creativity and propensity of innovation had on their persistence and the impact that use of particular pedagogical practices had on their persistence, creativity and propensity for innovation in STEM. Two structural equation models (SEMs) have been developed for data analyses with one containing grade point average (as a proxy for achievement) as the outcome of interest and the second with engineering creativity and propensity for innovation as the outcome of interest. These two models indicate that use of pedagogical practices impact students' creativity and propensity for innovation and propensity for innovation impacts students' achievement (with GPA as a proxy.) Notably, background characteristics also have impacts on the two outcomes of interest. This research informs community college faculty and student affairs personnel on which support practices best support students in STEM majors to transfer to colleges and universities and how students' creativity and propensity for innovation affects such transfer persistence. © American Society for Engineering Education, 2017.",,"C (programming language); Education; Education computing; Engineering education; Innovation; Problem solving; Societies and institutions; STEM (science, technology, engineering and mathematics); Teaching; Colleges and universities; Creative problem-solving; Higher education institutions; Non-traditional students; Post-secondary institutions; Science and engineering; Structural equation models; Underrepresented minorities; Students",2-s2.0-85030564481
"Popescu O., Abraham S., El-Tawab S.","A mobile platform using software defined radios for wireless communication systems experimentation",2017,"ASEE Annual Conference and Exposition, Conference Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030541445&partnerID=40&md5=932e6401a1836d410848c7c43c627782","A distinctive feature of wireless communication systems is implied by the fact that there is no physical connection between the transmitter and its corresponding receiver, which enables user mobility. However, experimenting with wireless communication systems is mostly done in the lab, where transmitters and receivers are setup on benches, in stationary settings. This prevents students from experiencing fading and other propagation effects associated with mobile wireless channels. This paper describes a mobile platform for wireless communication experimentation that enables students to run experiments beyond the confines of a traditional lab, in realistic settings that cover indoor and outdoor scenarios with both fixed and mobile propagation characteristics. The platform presented consists of a Universal Software Radio Peripheral (USRP) from National Instruments to implement the transmitter, an affordable RTL-SDR USB dongle to implement the receiver, a laptop computer used to program the SDR boards, and equipment for visualizing radio signal characteristics such as a portable spectrum analyzer or oscilloscope. This choice results in a moderate overall cost for the radio hardware required by the platform, which can be easily programmed using open source software such as GNU Radio as well as software packages like Matlab or LabView. For experimentation in wireless scenarios with low mobility (both indoors and outdoors, corresponding to walking speeds) the transmitter and receiver may be placed on push carts, while for higher mobility they may be placed on university owned golf carts moving at faster speeds on the designated campus routes. Furthermore, mobile transmitters and receivers may also be placed in cars driving on the campus streets and through the university parking lots/garages to enable experiments simulating vehicleto-vehicle (V2V) and vehicle-to-infrastructure (V2I) communications. © American Society for Engineering Education, 2017.",,"Computer peripheral equipment; Computer programming languages; Engineering education; Fading (radio); Fixed platforms; Laptop computers; MATLAB; Mobile phones; Open source software; Open systems; Radio communication; Radio transmission; Signal receivers; Software engineering; Spectrum analyzers; Transmitters; Vehicle to vehicle communications; Vehicles; Wireless telecommunication systems; Mobile wireless channels; National Instruments; Software-defined radios; Transmitter and receiver; Universal software radio peripherals (USRP); Vehicle to infrastructure (V2I); Wireless communication system; Wireless communications; Software radio",2-s2.0-85030541445
"Hill I.","Engaging multidisciplinary engineers in an introduction to programming laboratory",2017,"ASEE Annual Conference and Exposition, Conference Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030548608&partnerID=40&md5=0ac6713a0088489c78532087d3c64e74","Engineering students outside of computer science are required to take an introductory course in computer programming in one of several languages (MATLAB, C++, VB.net), including a laboratory component. This provides a unique challenge in engaging a group of multidisciplinary students with different programming backgrounds, especially since the lab is required by some engineering majors but optional for others. The lab had essentially turned into a recitation session with additional lecturing and reviews of homework solutions. Over the last several semesters the college has reevaluated how the lab can be useful to all disciplines, and this paper outlines the curriculum redesign to problem-based learning in a collaborative classroom. Students now work in a space designed for active learning for two periods each week, grouped in teams of six. Their goal is to solve programming challenges that range from programming fundamentals to image processing and manipulating experimental data, which stimulates the interest of all engineering disciplines. Example labs include solving programming interview questions, using image kernels to sharpen digital images, and developing a simple Microsoft Paint application. These challenges correspond to the latest lecture material, forcing students to actively work through the current learning objectives and keep pace with the course. Each lab session has the support of a faculty member and teaching assistants to guide discussions and provide just-in-time teaching. Student feedback and grades have shown students are meeting the desired learning objectives while also enjoying the challenging nature of the problems. Students with no prior programming experience have especially benefited from the new lab format with strong improvements in critical thinking, creativity, and problem solving skills. © American Society for Engineering Education, 2017.",,,2-s2.0-85030548608
"Jamieson P.","VerilogTown - Improving students learning hardware description language design - Verilog - With a video game",2017,"ASEE Annual Conference and Exposition, Conference Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030541588&partnerID=40&md5=195052dae31de3d01d9fdfaa9e634e52","In this work, we present our game, verilogTown, as an aid to students learning Verilog. The reason for such a game comes from our experiences teaching digital system design where we observed a challenge for second year students learning to design with the Verilog hardware description language (HDL). In this work, we speculate why it is hard to learn an HDL, claiming that like learning all languages, the students do not play/use the language enough to develop an understanding of them (including Verilog). A student's typical process of learning Verilog includes class examples and assignments, labs, and a project, but like learning more traditional programming languages, until a learner spends significant time using a language to build something, these experiences only result in a basic understanding. verilogTown was created to provide students with a medium to play with Verilog in an engaging and safe environment. The hope is that instead of simply completing a working design for a class, students will be challenged by the game puzzles and will spend significantly more time with Verilog design. Our comparison on exam performance in 2014 and 2015 without and with verilogTown suggests that our game impacts student Verilog understanding. © American Society for Engineering Education, 2017.",,,2-s2.0-85030541588
"Shankar R.T., Sakraida T.J., McAfee F.X.","Smart and connected health apps: A cross-disciplinary effort",2017,"ASEE Annual Conference and Exposition, Conference Proceedings",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030568707&partnerID=40&md5=1ebd74ca5758589ee19db2d23accbfcf","Engineering undergraduates may not have full appreciation of the potential impact of technology on health care, currently one-sixth of the US GDP. Technology has a major role to play in reducing health care cost. We focus here on building smart phone apps for patients to use at home to manage their health care. This will reduce the number of patients' visits to hospitals, length of hospital stay, and the stress of a hospital visit. Eleven teams of engineering, nursing, and arts students were brought together to develop such smart phone apps for health care. Different teams focused on different aspects of the app eco system, viz., interfacing biosensors to the smart phone, augmented reality on smart phones to help the patient visualize various procedures/exercises, and cloud-based data and trend analyses to help communicate with medical professionals and/or seek additional information online. This initial experience has helped us build an integrated ecosystem that uses only one programming language (JavaScript) that also is very popular and easy-to-learn. Future course offerings will leverage this. We hypothesize that such a transdisciplinary collaboration will not only increase awareness of health care challenges and solutions among mainstream engineering students, but also pave the way to recruit and retain women and underrepresented minority students in engineering. Social science research has shown that framing engineering tasks in terms of real-world problems and narratives would help enhance engineering identity among women and underrepresented minority student groups. The current mainstream engineering students taking this course will also benefit as they will get exposed to challenges in the healthcare industry, learn to communicate and collaborate with non-engineering majors, and apply their knowledge to solve real-world problems. © American Society for Engineering Education, 2017.",,"Augmented reality; Health care; Home health care; Hospitals; Medical information systems; mHealth; Problem oriented languages; Professional aspects; Smartphones; Students; Telephone sets; Cross-disciplinary; Engineering undergraduates; Healthcare industry; Length of hospital stays; Medical professionals; Real-world problem; Social science research; Underrepresented minorities; Engineering education",2-s2.0-85030568707
"Burrows A.C., Borowczak M.","Teaching teachers to think like engineers using NetLogo",2017,"ASEE Annual Conference and Exposition, Conference Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030546694&partnerID=40&md5=3ab28b7c25dc8112cce0338feb91c8a7","This paper provides a view of 22 K12 teachers' expectations versus the actuality of immersion into an engineering education computer science (CS) project during a Math/Science Partnership (MSP) grant called RAMPED, which was a 16-day, yearlong MSP grant. The CS session using NetLogo was selected for focused examination. NetLogo is a multi-agent simulator that uses the educational Logo programming language and was designed for classroom modeling experience. The research question for the study was, ""How do K12 teachers view their skill set of using computer science in their classrooms before, during, and after professional development (PD)?"" RAMPED participants spent a total of three days immersed in using NetLogo as a vehicle for learning fundamental computer science principles and engineering applications for K12 classrooms. The authors used a social constructivism approach and examined K12 teacher NetLogo usage in and out of the classroom. The authors also collected the data via K12 teacher surveys and informal interviews. Findings show that the teachers self-reported high expectations of their skillset as well as easy assimilation of NetLogo (but not CS) into their classroom teaching. On a scale from 0 to 5, where 0 is not at all skillful and 5 is extremely skillful, survey pretest results show over 50% at a 3, 4, or 5. Posttest survey results show over 90% at a 3, 4, or 5. After the summer session, NetLogo was useful to 95% of K12 teachers. After an academic year NetLogo follow-up session over 75% of the K12 teachers were satisfied with instruction and support. Over 85% of teachers believed that the workshop ""stretched teacher thinking into their classrooms."" Teachers' qualitative comments are included for triangulation. Conclusions include that intense K12 teacher exposure to engineering CS topics (e.g. 24 hours total of a larger PD) is not enough to truly enact meaningful classroom changes (although the teachers did create new activities). Additional support for meaningful classroom change and K12 teacher confidence is necessary. In general, K12 teachers need (and asked for) support in the form of ready to use lessons and documents (e.g. additional activities) along with leader presence to support them in trying their self-created plans situated within the NGSS standards. The actuality of working with NetLogo (and changing functions and code) to present STEM concepts/topics was both invigorating (it was new for the K12 teachers) and frustrating (it was often hard for the K12 teachers to see connections to content) as teachers moved through expectations and actuality. Implications include planning for structured K12 teacher academic year support in implementing CS topics for sustainability in classrooms. © American Society for Engineering Education, 2017.","Computer science; Computer science education; Engineering education; K12 teachers; Pre-service teacher education; STEM","Computer science; Education; Education computing; Engineering education; Modeling languages; Multi agent systems; STEM (science, technology, engineering and mathematics); Surveys; Classroom teaching; Computer Science Education; Engineering applications; K-12 teachers; Pre-service teacher education; Professional development; Research questions; Social constructivism; Teaching",2-s2.0-85030546694
"Islam S., Shankar R.T., Minor I., Lapp S.I., Schoorman D.","Engagement in practice: Outreach program to introduce computer science to middle school students",2017,"ASEE Annual Conference and Exposition, Conference Proceedings",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030543723&partnerID=40&md5=9c8ca8ea9d27769f6b3c9c1d26bde47f","Research continues to show a consistent decline in the number of students entering the field of Computer Science (CS) (Ali and Shubra, 2010). Studies also indicate that an optimal time to promote interest in CS is during the middle school years (Tai, Liu, Maltese, and Fan, 2006). Yet, most CS courses are only offered as electives, which are not required for graduation (Urness and Manley, 2013). This makes fostering interest in CS at an early age even more challenging. However, some programs, such as the Alice Camps, have successfully encouraged interest in the subject for middle school students (Adams, 2007). Recently, we completed a community outreach program to provide CS classes to local Title I middle school students attending a summer camp. The authors taught hour-long CS classes to four groups of students. The purpose of the classes was to boost interest in CS by teaching students basic computer programming concepts. The students were also educated about careers that require this skill set and were introduced to a programming language called ""Processing"". We observed that students showed increased enthusiasm towards CS. In addition, we noticed that the group activity component of the classes encouraged sociability and idea synthesis among peers. This CS community outreach program motivated us to extend the effort to teach science concepts using the Processing language. This may potentially promote sociability, creativity, and empowerment in STEM among middle school students. Specifically, we plan to use the Processing programming language to facilitate learning of biological and chemical concepts, since such concepts can be difficult for students to visualize from a textbook. This paper provides details on other researchers' relevant work in this area, the use of the Processing programming language, and our plan for data collection and analysis. © American Society for Engineering Education, 2017.",,,2-s2.0-85030543723
"Meuer E.M., Kern E.A., Andrews M., Tenhoff A., Andrews K., Huschka P., Ryan E.M., Tozour L., Thomas A.P.","MAKER: Painting pitches",2017,"ASEE Annual Conference and Exposition, Conference Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030538515&partnerID=40&md5=ee29f6e6378fbbbf54313e988f75b46c","The following paper presents a system for creating real-time visuals based on multiple simultaneous vocal inputs. The goal of this work is to augment live musical performances by visually conveying the spirit and structure of the piece. Using the Processing programming language, sounds are analyzed and return pitch and amplitude as numerical values. Visuals representing pitch and amplitude for each of the musicians are created in real-time and are projected concurrently with the live musical performance. This process is demonstrated by work presented here with a professional 8-voice ensemble. As part of this project, a library of functions is being created and shared to allow others to implement similar productions. © American Society for Engineering Education, 2017.",,,2-s2.0-85030538515
"Miller C.","Teaching hardware to demystify foundational software concepts",2017,"ASEE Annual Conference and Exposition, Conference Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030549526&partnerID=40&md5=20956727ed2a7bc32c9e55051929c62b","Both top-down and bottom-up approaches have been proposed for software and programming education. Motivations can be cited for both approaches, but empirical data for either approach can be difficult to obtain. In this paper, we explore potential benefits of a bottom-up approach which begins at the architecture and machine language level. Abstractions of basic software concepts such as data storage and pointers can lead to misconceptions. Understanding how these abstractions are implemented in the underlying hardware can provide clarity of foundational software concepts. An introductory course on embedded systems and microcontrollers for electrical and computer engineers was modified in an attempt to strengthen student understanding of foundational software concepts. The material covered in the course primarily remained the same, but the course schedule was modified to move the system architecture and instruction set material to the beginning of the course, rather than the end. Data was collected for common exam questions for offerings both prior to and following the course modification. The data indicates that students who were exposed to the functionality of the underlying architecture prior to high-level programming languages had a better understanding of basic concepts such as storage allocation and referential pointers. This paper contributes to the fields of education in electrical and computer engineering and computer science by providing data on student outcomes for alternate approaches to content delivery. We hope that this information is useful in curriculum design and development for related fields. © American Society for Engineering Education, 2017.",,,2-s2.0-85030549526
"Danowitz A., Benson B., Edmonds J.","Teaching systems and robotics in a four-week summer short course",2017,"ASEE Annual Conference and Exposition, Conference Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030564405&partnerID=40&md5=1d892e80df5773716880a347f4c873f2","This paper describes a four-week summer short-course designed to introduce students with limited hands-on technical experience to the low-level details of embedded systems and robotic Students start the course using a Raspberry Pi 3 to learn the basics of Linux and programming, and end the course by competing in a capture-the-flag type competition with the webconfigurable GPS-guided autonomous robots they designed and tested in the course. Throughou the course, students are introduced to programming languages including Python and PHP, advanced programming concepts such as using sockets for inter-process communication, data interchange formats such as JSON, basic API development, system concepts such as I2C and UART serial interfaces, PWM motor control, and sensor fusion to improve robotic navigation and localization. This course was offered to students for the first time in the summer of 2016, and though formal feedback collection was limited, informal feedback indicated that students found the course to be challenging, engaging, and beneficial to their overall understanding of engineering. The paper walks the reader through the background of this course. It then discusses the weekly lesson plans, supplemental material provided to the students, and our general strategy for teaching the course's programming and system design concepts in such an accelerated time frame. Finally, the paper discusses the student and instructor reactions to the course, lessons learned, and suggestions for future offerings. The material developed for this course will be posted online so that other educators may use it in their teaching. © American Society for Engineering Education, 2017.",,,2-s2.0-85030564405
"Yu W., Farook O., Agrawal J.P., Ahmed A.","Teaching microcontrollers with emphasis on control applications in the undergraduate engineering technology program",2017,"ASEE Annual Conference and Exposition, Conference Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030533771&partnerID=40&md5=f636d5b4410e81457684c21c3fcde5eb","The paper expounds the practices utilized in teaching introductory undergraduate microcontroller's class. The microcontrollers have become ubiquitous in our daily life. They have been the engine behind automatically-controlled products and devices. As a result this course is taken by many of the non-electrical majoring students. In this paper, we present our pedagogies for teaching a microcontroller introductory course with emphasis on detection and control applications. The proposed course uses Arduino [1], which is an open-source electronics platform, based on easy-to-use hardware and software. The course cover the architectural details of ATmega328P. The course is unique in instructing students utilizing standard C (C11 (formerly C1X) is an informal name for ISO/IEC 9899:2011) [2], the current standard for the C programming language. This approach is a departure from the plethora of code written by non-standardized coding schemes, so prevalent on the Arduino net based community. Another unique feature of instructions of the course is coding methodology. The instruction for the course is done following strict adherence to Structured Coding methodology. Most of the technology students prefer visualization activities and hands-on experiences in their learning environment. The SparkFun Inventor's Kit [3] with Arduino Uno and other open source resources have become an effective tool for the entry-level microcontroller course. In this course, we teach necessary programming skills and knowledge of computer interfacing with input and output devices. Various types of transducers, sensors and actuators used in the course are described in the paper. Through class examples and lab experiments, students establish the concept of using microcontrollers to make open-loop and closed-loop control systems, and demonstrate knowledge learned by their course projects. The course adhere to the teaching philosophy of Outcome Based Education [4] (OBE), as such utilizes and employ various standard tools and techniques. The paper discuss the pedagogies implemented in the course. © American Society for Engineering Education, 2017.",,,2-s2.0-85030533771
"Salzman N., Ubic R.","Development and assessment of a combined REU/RET program in Materials Science",2017,"ASEE Annual Conference and Exposition, Conference Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030555943&partnerID=40&md5=207be3529920b080c3c3c92ca1ac346b","In this paper we present an evaluation and lessons learned from a joint Research Experience for Undergraduates (REU) and Research Experience for Teachers (RET) program focused on energy and sustainability topics within a Materials Science and Engineering program at a public university. This program brought eleven undergraduate science and engineering students with diverse educational and institutional backgrounds and four local middle and high school teachers on campus for an 8-week research experience working in established lab groups at the university. Using the Qualtrics online survey software, we conducted pre-experience and post-experience surveys of the participants to assess the effects of participating in this summer research program. At the beginning of the summer, all participants provided their definition of technical research and described what they hoped to get out of their research experience, and the undergraduate students described their future career and educational plans. At the conclusion of the summer, a post-experience survey presented participants' with their answers from the beginning of the summer and asked them to reflect on how their understanding of research and future plans involving research changed over the course of the summer experience. Many participants evolved a new understanding of research as a result of participating in the summer experience. In particular, they better recognized the collaborative nature of research and the challenges that can arise as part of the process of doing research. Participants acquired both technical and professional skills that they found useful, such as learning new programming languages, becoming proficient at using new pieces of equipment, reviewing technical literature, and improving presentation and communication skills. Undergraduates benefited from developing new relationships with their peers, while the teacher participants benefited from developing relationships with faculty and staff at the university. While most of the participants felt that they were better prepared for future studies or employment, they did not feel like the summer research experience had a significant impact on their future career or degree plans. Finally, while almost all of the participants described their summer research experience as positive, areas for improvement included better planning and access to mentors, as well as more structured activities for the teachers to adapt their research activities for the classroom. © American Society for Engineering Education, 2017.",,"Education; Engineering education; Students; Surveys; Teaching; Communication skills; High school teachers; Materials science and engineering; Research experience for teachers; Research experience for undergraduates; Science and engineering; Technical literature; Undergraduate students; Engineering research",2-s2.0-85030555943
"Leaf J., Preston A.S., Richter D.C., Gerlick R.E.","An undergraduate service learning research project using a humanoid robot to enhance treatment for children with autism spectrum disorder",2017,"ASEE Annual Conference and Exposition, Conference Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030555966&partnerID=40&md5=a257e84ec6db64b12b908d01c213ca09","This service learning undergraduate research project focuses on the use of humanoid robots to increase the effectiveness of therapy of children with autism spectrum disorder (ASD). Engineers often focus on industrial applications for robotics and automation. This project allows the engineering student to learn that the skills they are learning in industrial robotics can also be applied to societal problems in the community and provide ways to give back to the community. One in sixty-eight children are diagnosed with some level of autism, with the most common treatment being Applied Behavior Analysis (ABA). While ABA is an evidence-based approach, the learning process is time consuming, and it is not uncommon for an objective to take months, if not years, for a child to master. Two important consequences of this are the financial costs and the closing ""window of opportunity,"" as therapy is often most effective in the younger, formative years. As an aid in improving ASD therapy, robots have been developed over the past decade, with noted potential for their use as ""co-therapists."" However, two major barriers to wider adoption of robots in therapy are the intensive programming requirements of the robots and the limited ""off-the-shelf"" programs available to clinicians. This paper describes a pilot project with the aim of enabling therapists to use the advanced technology of robots by eliminating these barriers through (1) the adoption of an intuitive and adaptable programming platform (NAO humanoid robot) and (2) development of an initial template program for the area of early language-communication. © American Society for Engineering Education, 2017.",,,2-s2.0-85030555966
"Brown F., Narayan S., Wahby R.S., Engler D., Jhala R., Stefan D.","Finding and Preventing Bugs in JavaScript Bindings",2017,"Proceedings - IEEE Symposium on Security and Privacy",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024488598&doi=10.1109%2fSP.2017.68&partnerID=40&md5=b142847f508f0e41a253c2b197171905","JavaScript, like many high-level languages, relies on runtime systemswritten in low-level C and C++. For example, the Node.js runtime systemgives JavaScript code access to the underlying filesystem, networking, and I/O by implementing utility functions in C++. Since C++'s typesystem, memory model, and execution model differ significantly fromJavaScript's, JavaScript code must call these runtime functions viaintermediate binding layer code that translates type, state, and failure between the two languages. Unfortunately, binding code isboth hard to avoid and hard to get right. This paper describes several types of exploitable errors that bindingcode creates, and develops both a suite of easily-to-build static checkersto detect such errors and a backwards-compatible, low-overhead API toprevent them. We show that binding flaws are a serious security problem byusing our checkers to craft 81 proof-of-concept exploits forsecurity flaws in the binding layers of the Node.js and Chrome, runtimesystems that support hundreds of millions of users. As one practical measure of binding bug severity, we were awarded $6,000 in bounties for just two Chrome bug reports. © 2017 IEEE.",,"Bins; C++ (programming language); Codes (symbols); Computer programming languages; Java programming language; Binding layers; Execution model; Memory modeling; Practical measures; Proof of concept; Runtime functions; Security problems; Utility functions; High level languages",2-s2.0-85024488598
"Sivakorn S., Argyros G., Pei K., Keromytis A.D., Jana S.","HVLearn: Automated Black-Box Analysis of Hostname Verification in SSL/TLS Implementations",2017,"Proceedings - IEEE Symposium on Security and Privacy",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024473636&doi=10.1109%2fSP.2017.46&partnerID=40&md5=07bc1d7ea5b41ff7439cc3cc88bf222a","SSL/TLS is the most commonly deployed family of protocols for securing network communications. The security guarantees of SSL/TLS are critically dependent on the correct validation of the X.509 server certificates presented during the handshake stage of the SSL/TLS protocol. Hostname verification is a critical component of the certificate validation process that verifies the remote server's identity by checking if the hostname of the server matches any of the names present in the X.509 certificate. Hostname verification is a highly complex process due to the presence of numerous features and corner cases such as wildcards, IP addresses, international domain names, and so forth. Therefore, testing hostname verification implementations present a challenging task. In this paper, we present HVLearn, a novel black-box testing framework for analyzing SSL/TLS hostname verification implementations, which is based on automata learning algorithms. HVLearn utilizes a number of certificate templates, i.e., certificates with a common name (CN) set to a specific pattern, in order to test different rules from the corresponding specification. For each certificate template, HVLearn uses automata learning algorithms to infer a Deterministic Finite Automaton (DFA) that describes the set of all hostnames that match the CN of a given certificate. Once a model is inferred for a certificate template, HVLearn checks the model for bugs by finding discrepancies with the inferred models from other implementations or by checking against regular-expression-based rules derived from the specification. The key insight behind our approach is that the acceptable hostnames for a given certificate template form a regular language. Therefore, we can leverage automata learning techniques to efficiently infer DFA models that accept the corresponding regular language. We use HVLearn to analyze the hostname verification implementations in a number of popular SSL/TLS libraries and applications written in a diverse set of languages like C, Python, and Java. We demonstrate that HVLearn can achieve on average 11.21% higher code coverage than existing black/gray-box fuzzing techniques. By comparing the DFA models inferred by HVLearn, we found 8 unique violations of the RFC specifications in the tested hostname verification implementations. Several of these violations are critical and can render the affected implementations vulnerable to active man-in-the-middle attacks. © 2017 IEEE.",,"Automata theory; Black-box testing; C (programming language); Complex networks; Education; Finite automata; Formal languages; Java programming language; Network security; Specifications; Certificate validations; Critical component; Deterministic finite automata; International domain names; Learning techniques; Man in the middle attacks; Network communications; Regular expressions; Learning algorithms",2-s2.0-85024473636
"Khamphroo M., Kwankeo N., Kaemarungsi K., Fukawa K.","MicroPython-based educational mobile robot for computer coding learning",2017,"2017 8th International Conference on Information and Communication Technology for Embedded Systems, IC-ICTES 2017 - Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025665816&doi=10.1109%2fICTEmSys.2017.7958781&partnerID=40&md5=b9730e5f9b6c81962a77108fd3addf97","This article presents a prototype of educational mobile robotic platform based on MicroPython library system, which enables robot control with Python language programming. Moreover, this robotic platform supports a visual programming environment called Blockly to develop a program, which is very simple and similar to an intuitive jigsaw puzzle. Both Python and Blockly are simple coding tools for first-time learner who are interested in programming learning. The proposed mobile robot utilizes a modular design which is based on the simple block snapping without any wiring. The robot contains a brain module, which is the main processor of the system. Other modules are simple sensors and the body module, which acts as a hub between the brain and sensor modules. The robot is arranged such that it is easy-to-use and simple enough to set up in minutes. © 2017 IEEE.","Blockly; Educational Mobile Robot; MicroPython; Programming Learning","Computer programming; Educational robots; Embedded systems; High level languages; Integrated circuits; Machine design; Mobile robots; Robot programming; Robotics; Robots; Blockly; Library systems; MicroPython; Modular designs; Programming learning; PYTHON language; Robotic platforms; Visual programming environments; Education",2-s2.0-85025665816
"Lee H., Kim J.Y., Choi W., Moon M.H.","Effect of cationic monomer content on polyacrylamide copolymers by frit-inlet asymmetrical flow field-flow fractionation/multi-angle light scattering",2017,"Journal of Chromatography A",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019165967&doi=10.1016%2fj.chroma.2017.04.057&partnerID=40&md5=9bfb6e3a28fe8123c4dad455b48adad4","In this study, ultrahigh-molecular-weight (MW) (&gt;107 Da) cationic polyacrylamides (C-PAMs), which are water-soluble polymers used in waste water treatment, were characterized using frit-inlet asymmetrical flow field-flow fractionation coupled with multi-angle light scattering and differential refractive detection. C-PAMs copolymerized with acryloxyethyltrimethyl ammonium chloride (DAC) were prepared by varying the feed amount of cationic monomer, polymerization method (solution vs. emulsion), and degree of branching. The MW of the copolymers prepared using emulsion polymerization (107–109 Da) was generally larger than that of copolymers prepared using solution polymerization (4 × 107–108 Da). When the amount of cationic monomer was increased from 10 to 55 mol% in solution polymerization, hydrophobic contraction of the core induced formation of more compact C-PAMs. The copolymers prepared using emulsion polymerization formed highly aggregated or supercoil structures owing to increased intermolecular hydrophobic interaction when less cationic monomer was used. However, the MW decreased with increased cationic group content. In addition, C-PAMs larger than ∼108 Da prepared using the emulsion method were separated by steric/hyperlayer elution mode while those in the 107–108 Da range were analyzed in either normal or steric/hyperlayer mode depending on the decay patterns of field programming. Moreover, branched copolymers were found to be resolved with different elution modes under the same field decay pattern depending on the degree of branching: steric/hyperlayer for low-branching and normal for high-branching C-PAMs. © 2017 Elsevier B.V.","Cationic monomer content; Cationic polyacrylamide; Field-flow fractionation; Multi-angle light scattering","Cationic polymerization; Emulsification; Emulsion polymerization; Flow fields; Fractionation; Hydrophobicity; Light scattering; Liquid chromatography; Monomers; Polyacrylates; Waste treatment; Wastewater treatment; Water treatment; Cationic monomers; Cationic polyacrylamides; Field flow fractionation; Frit inlet asymmetrical flow field-flow fractionations; Intermolecular hydrophobic interactions; Multi-angle light scatterings; Polyacrylamide copolymers; Ultra-high molecular weight; C (programming language); acryloxyethyltrimethyl ammonium chloride; ammonium chloride; cationic polyacrylamide; polyacrylamide; unclassified drug; acrylic acid resin; cation; polyacrylamide; polymer; Article; conformation; controlled study; elution; emulsion polymerization; field flow fractionation; frit inlet asymmetrical flow field flow fractionation; geometry; hydrodynamics; hydrogen bond; hydrophobicity; light scattering; molecular interaction; molecular weight; multi angle light scattering; polymerization; priority journal; solution polymerization; chemistry; light; radiation scattering; water management; Acrylic Resins; Cations; Fractionation, Field Flow; Light; Molecular Weight; Polymers; Scattering, Radiation; Water Purification",2-s2.0-85019165967
"Wulf C., Hasselbring W., Ohlemacher J.","Parallel and generic pipe-and-filter architectures with teetime",2017,"Proceedings - 2017 IEEE International Conference on Software Architecture Workshops, ICSAW 2017: Side Track Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025650828&doi=10.1109%2fICSAW.2017.20&partnerID=40&md5=bb2038e1c80198ce16fe8d90266870b5","Pipe-and-Filter (P&F) is a well-known and often used architectural style. However, to the best of our knowledge, there is no P&F framework which can model and execute generic P&F architectures. For example, the frameworks Fastflow, StreamIt, and Spark do not support multiple input and output streams per filter and thus cannot model branches. Other frameworks focus on very specific use cases and neglect type-safety when interconnecting filters. Furthermore, an efficient parallel execution of P&F architectures is still an open challenge. Although some available frameworks can execute filters in parallel, there is much potential for optimization. Unfortunately, most frameworks have a fixed execution strategy which cannot be altered without major changes. In this paper, we present our P&F framework TeeTime. It is able to model and to execute arbitrary P&F architectures. Simultaneously, it is open for modifications in order to experiment with the P&F style. Moreover, it allows to execute filters in parallel by utilizing the capabilities of contemporary multi-core processor systems. Besides a description of its major features, we also present an application example in Java. © 2017 IEEE.","Framework; Parallelization; Pipe-and-filter; TeeTime","Bandpass filters; Java programming language; Software architecture; And filters; Application examples; Execution strategies; Framework; Multi-core processor; Parallel executions; Parallelizations; TeeTime; Parallel architectures",2-s2.0-85025650828
"Ngo V.C., Dehesa-Azuara M., Fredrikson M., Hoffmann J.","Verifying and Synthesizing Constant-Resource Implementations with Types",2017,"Proceedings - IEEE Symposium on Security and Privacy",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024472122&doi=10.1109%2fSP.2017.53&partnerID=40&md5=f2a4840639e3482b359b75b3f3a2a528","Side channel attacks have been used to extract critical data such as encryption keys and confidential user data in a variety of adversarial settings. In practice, this threat is addressed by adhering to a constant-time programming discipline, which imposes strict constraints on the way in which programs are written. This introduces an additional hurdle for programmers faced with the already difficult task of writing secure code, highlighting the need for solutions that give the same source-level guarantees while supporting more natural programming models. We propose a novel type system for verifying that programs correctly implement constant-resource behavior. Our type system extends recent work on automatic amortized resource analysis (AARA), a set of techniques that automatically derive provable upper bounds on the resource consumption of programs. We devise new techniques that build on the potential method to achieve compositionality, precision, and automation. A strict global requirement that a program always maintains constant resource usage is too restrictive for most practical applications. It is sufficient to require that the program's resource behavior remain constant with respect to an attacker who is only allowed to observe part of the program's state and behavior. To account for this, our type system incorporates information flow tracking into its resource analysis. This allows our system to certify programs that need to violate the constant-time requirement in certain cases, as long as doing so does not leak confidential information to attackers. We formalize this guarantee by defining a new notion of resource-aware noninterference, and prove that our system enforces it. Finally, we show how our type inference algorithm can be used to synthesize a constant-time implementation from one that cannot be verified as secure, effectively repairing insecure programs automatically. We also show how a second novel AARA system that computes lower bounds on resource usage can be used to derive quantitative bounds on the amount of information that a program leaks through its resource use. We implemented each of these systems in Resource Aware ML, and show that it can be applied to verify constant-time behavior in a number of applicationsincluding encryption and decryption routines, database queries, and other resource-aware functionality. © 2017 IEEE.","Information flow; Language-based security; Resource analysis; Static analysis; Timing channels","Application programs; Cryptography; Inference engines; Query languages; Side channel attack; Confidential information; Encryption and decryption; Information flow tracking; Information flows; Language-based security; Resource analysis; Timing channels; Type Inference Algorithm; Static analysis",2-s2.0-85024472122
"Ortega-Rodriguez L.A., Salazar-Almanza A., Tapia-Ruiz M.E., Velasco-Avella J., Santoyo-Mora M., Camarillo-Gomez K.A., Henandez L.A.M., Perez-Soto G.I.","Open architecture controller for a 22-DOF humanoid robot",2017,"18th Congreso Mexicano de Robotica, COMRob 2016",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025661728&doi=10.1109%2fCOMROB.2016.7955159&partnerID=40&md5=5460eaf0c5a490263d548b8fe142053c","In this paper, an open architecture controller for a humanoid robot of 22 degrees of freedom is presented, substituting the manufacturer controller. A humanoid robot represents a complex challenge to control it due to its own structure and the environment in which it has to interact. In order to interact with the environment, it must ensure the performance of the humanoid robot motion through developing small tasks. The proposed open architecture controller defines the position and velocity of each motor, as well as the execution time from a task in a single data stream, according with the perception of the environment given by an artificial vision system which will be omitted in this paper. The open architecture controller was developed with a Raspberry Pi 2 using the C++ programming language to send the data stream to the servomotors of the humanoid robot. The experimental results demonstrate an improvement in the execution of servomotors tasks, thus, the overall humanoid robot performance is improved; the proposed open architecture controller demonstrates several advantages over the manufacturer controller because it is possible to execute several processes simultaneously in less time. © 2017 IEEE.","C++ language; humanoid robot; Open architecture controller","Anthropomorphic robots; C++ (programming language); Computer architecture; Computer hardware description languages; Controllers; Data communication systems; High level languages; Manufacture; Robot programming; Robots; Servomechanisms; Servomotors; Artificial vision system; C++ language; Data stream; Humanoid robot; Open architecture controllers; Visual servoing",2-s2.0-85025661728
"Singh N.","Automatic parallelization using OpenMP API",2017,"International Conference on Signal Processing, Communication, Power and Embedded System, SCOPES 2016 - Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025158727&doi=10.1109%2fSCOPES.2016.7955837&partnerID=40&md5=50eb3c9c1f0b905007abecb7c5d6d9a5","Nowdays we can see change in technology from single core to multicore. Even though the Systems are Nowdays we can see change in technology from single core to multicore. Even though the Systems are provided with multicore processors only one of the core is utilized for the execution of C program. In computers, parallel processing is the processing of program instructions by dividing them among multiple processors or multiple cores with the objective of running a program in less time. Here in our paper we try to parallelize any complex C program automatically by inserting OpenMP pragmas before loops present in C program thereby reducing the time required for execution moreover leading to proper utilization of CPU. © 2016 IEEE.","OpenMP (open multiprocessing); Parallelization","Application programming interfaces (API); C (programming language); Embedded systems; Program processors; Signal processing; Automatic Parallelization; Multi core; Multi-core processor; Multiple processors; Open multiprocessings; Parallel processing; Parallelizations; Program instructions; Multicore programming",2-s2.0-85025158727
"Veerabhadraiah S., Rao M.P.","Application of adaptive filters in desired signal extraction",2017,"International Conference on Signal Processing, Communication, Power and Embedded System, SCOPES 2016 - Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025146919&doi=10.1109%2fSCOPES.2016.7955602&partnerID=40&md5=c39c1a6d822d06136e673d0f7623c390","An application of Adaptive Filters (AF) in Desired Signal Extraction (DSE) embedded in Unknown Dynamic System (UDS) is explored in the current research. Least Mean Square Algorithm (LmSA) is utilized in proposed DSE. The UDS is synthesized by adopting Pseudo Random Binary Sequence (PrBS) excitation. To start with the LMSA is educated to converge and adapt its coefficients to the prevailing PRBS signal. These coefficients are subsequently utilized in DSE already embedded in the random noise. Carried out simulation studies by software implementation using 'C' language with different filter orders, step sizes and arrived at an optimum solution in respect of different synthesized signals. Computational complexities associated with Weiner filter for simulation applications are also included in this paper. The results obtained during simulation for different filter orders are tabulated and also depicted pictorially. The LMSA implementation methodology is shown in a block diagram as well explained in terms of a flow chart. Finally the LMSA is implemented in realistic environment and the desired signal extracted is also depicted pictorially. © 2016 IEEE.","AF; AP; AR; ARMA; CCL; DSE; FC; LMSA; LP; MA; MSE; PRBS; SS; UDS; WV","Adaptive filters; Argon; Bandpass filters; Binary sequences; C (programming language); Computer simulation languages; Computer software; Dynamical systems; Embedded systems; Extraction; Signal filtering and prediction; ARMA; Implementation methodology; Least mean square algorithms; LMSA; PRBS; Pseudo-random binary sequences; Simulation applications; Software implementation; Signal processing",2-s2.0-85025146919
"Jang S.-L., Wang J.-J.","Low-phase noise Class-C VCO with dynamic body bias",2017,"Electronics Letters",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021267574&doi=10.1049%2fel.2016.4477&partnerID=40&md5=8a4bc6405dbf7884115cab77677fd4ee","A 2.5 GHz Class-C voltage-controlled oscillator (VCO) with dynamic back-gate-biased MOSFET is proposed. A dynamic gate biasing circuit is used to reduce power consumption by switching N-Type MOS from initial Class-AB to Class-C operation in steady state. Moreover, the VCO uses dynamic back-gate bias to reduce threshold voltage of switching MOSFET during the start-up oscillation. The Class-C differential VCO is implemented in TSMC 0.18 μm bipolarcomplementary- metal-oxide-semiconductor (BiCMOS) process. The measured phase noise is -124.8 dBc/Hz at 1 MHz offset frequency from 2.48 GHz carrier while consuming 2.64 mW power from a 0.8 V supply. Tuning range of VCO is 0.72 GHz, from 2.48 to 3.3 GHz, whereas the control voltage was tuned from 0 to 2 V. The VCO occupies a chip area of 446 × 840 μm2 and provides a figure of merit of -197.55 dBc/Hz.",,"Bias voltage; MOSFET devices; Oscillistors; Phase noise; Variable frequency oscillators; Biasing circuit; Control voltages; Differential VCO; Dynamic body bias; Figure of merits; Low phase noise; Metal oxide semiconductor; Offset frequencies; C (programming language)",2-s2.0-85021267574
"Liu J., Wei Y., Li P., Zhao Y., Zou R.","Selective H2S/CO2 Separation by Metal-Organic Frameworks Based on Chemical-Physical Adsorption",2017,"Journal of Physical Chemistry C",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021626815&doi=10.1021%2facs.jpcc.7b04465&partnerID=40&md5=1d49e4e57d976333700a05ca43441454","The removal of hydrogen sulfide (H2S) is essential in various industry applications such as purification of syngas for avoiding its corrosion and toxicity to catalysts. The design of adsorbents that can bear corrosion of H2S and overcome the competitive adsorption from carbon dioxide (CO2) is a challenge. To obtain insight into the stability and adsorption mechanism of metal-organic frameworks (MOFs) during the H2S separation process, 11 MOF-based materials were employed for H2S capture from CO2. Density functional theory, molecular dynamic studies, and dynamic separation experiments were used to investigate selective H2S/CO2 separation. Most of these MOFs showed one-off high capacity and selectivity to H2S. Complete reversible physical adsorption was proven on Mg-MOF-74, MIL-101(Cr), UiO-66, ZIF-8, and Ce-BTC. Incomplete reversible adsorption occurred on UiO-66(NH2). Disposable chemical reaction happened on HKUST-1, Cu-BDC(ted)0.5, Zn-MOF-74, MIL-100(Fe) gel, and MOF-5. Using breakthrough experiments, UiO-66, Mg-MOF-74, and MIL-101(Cr) were screened out to present promising performance on the H2S capture. The present study is useful to identify and design suitable MOF materials for high-performance H2S capture and separation. (Chemical Equation Presented). © 2017 American Chemical Society.",,"Adsorption; Carbon; Carbon dioxide; Chemical reactions; Corrosion; Crystalline materials; Density functional theory; Desulfurization; Dynamics; Java programming language; Molecular dynamics; Separation; Adsorption mechanism; Breakthrough experiment; Competitive adsorption; Industry applications; Metal organic framework; Metalorganic frameworks (MOFs); Physical adsorption; Reversible adsorption; Gas adsorption",2-s2.0-85021626815
"Singh J.P., Singh S.","Implementation of OFDM and other multicarrier modulations on SDR",2017,"International Conference on Signal Processing, Communication, Power and Embedded System, SCOPES 2016 - Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025131470&doi=10.1109%2fSCOPES.2016.7955784&partnerID=40&md5=0b00d1c7e8cecc22d03f54307c4f50b4","OFDM has developed into a popular scheme for wideband digital communication, used in different applications such as digital television and audio broadcasting, Internet access, wireless networks and 4G mobile communications etc. SDR has become a universal platform for implementing any type of waveform in software. During the transmission, some data is lost due to transmission impairments. The loss in the signal can be detected at the receiver side. We use Universal Software Radio Peripheral (NI USRP-2920) as SDR to transmit and receive the OFDM signal. MATLAB and LABVIEW software are used to design the OFDM to encode the digital data into multicarrier frequencies. Computer was used to generate and processing of the signal with the help of MATLAB and LABVIEW software. We implemented SLM and Clipping & Filtering technique to reduce PAPR in OFDM of the transmitted signal using SDR. © 2016 IEEE.",,"4G mobile communication systems; Application programs; Computer programming languages; Digital communication systems; Digital television; Embedded systems; MATLAB; Radio communication; Signal processing; Signal receivers; Television applications; Television broadcasting; Television networks; 4G mobile communication; Digital communications; Filtering technique; Lab-view softwares; Multi-carrier frequencies; Transmission impairment; Transmitted signal; Universal platform; Software radio",2-s2.0-85025131470
"Saha P., Khanra M.","Equivalent circuit model of supercapacitor for self-discharge analysis - A comparative study",2017,"International Conference on Signal Processing, Communication, Power and Embedded System, SCOPES 2016 - Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025149204&doi=10.1109%2fSCOPES.2016.7955667&partnerID=40&md5=2dae2d85d9eaa168726777ef2aa2c83f","Self-discharge of supercapacitor is an important phenomenon that needs to be considered carefully, especially for the applications like wireless sensor networks, memory backup systems, etc. Different types of models have been proposed by the various researchers to capture the supercapacitor dynamics. In this paper, two electrical equivalent circuit models, variable leakage resistance (VLR) model and charge redistribution based model, have been considered for comparative study. Both the models have been analyzed based on the charge and long term self-discharge responses obtained through experimentation and simulation. The device under test is the Maxwell BCAP0100 P270 T07 supercapacitor. First, it has been charged at 2A constant current to its rated voltage; then, has been left for self-discharge. The terminal voltage has been collected for total charging time as well as self-discharge for 8000 seconds. The data have been acquired using National Instruments (NI) hardware and LabVIEW software. Based on the case study used in this paper, it is observed that the charge redistribution based model is better able to capture the self-discharge phenomenon. However, the error in the VLR model may not be insignificant always. © 2016 IEEE.","Charge redistribution; Electrical equivalent circuit; Self discharge; Supercapacitor; Ultracapacitor","Circuit simulation; Circuit theory; Computer programming languages; Electric network parameters; Embedded systems; Signal processing; Supercapacitor; Timing circuits; Wireless sensor networks; Charge redistribution; Comparative studies; Electrical equivalent circuit; Equivalent circuit model; Lab-view softwares; National Instruments; Self-discharge analysis; Self-discharges; Equivalent circuits",2-s2.0-85025149204
"Kesuma D.A., Purwanto P., Putranto T.T., Rahmani T.P.D.","Factor weighting in DRASTIC modelling for assessing the groundwater vulnerability in Salatiga groundwater basin, Central Java Province, Indonesia",2017,"IOP Conference Series: Earth and Environmental Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023197693&doi=10.1088%2f1755-1315%2f70%2f1%2f012008&partnerID=40&md5=2e49ea34f632501acffe0de6b64b2fe6","The increase in human population as well as area development in Salatiga Groundwater Basin, Central Java Province, will increase the potency of groundwater contamination in that area. Groundwater quality, especially the shallow groundwater, is very vulnerable to the contamination from industrial waste, fertilizer/agricultural waste, and domestic waste. The first step in the conservation of groundwater quality is by conducting the mapping of the groundwater vulnerability zonation against the contamination. The result of this research was groundwater vulnerability map which showed the areas vulnerable to the groundwater contamination. In this study, groundwater vulnerability map was assessed based on the DRASTIC Method and was processed spatially using Geographic Information System. The DRASTIC method is used to assess the level of groundwater vulnerability based on weighting on seven parameters, which are: depth to the water table (D), recharge (R), aquifer material (A), soil media (S), topography (T), impact of vadose zone (I), and hydraulic conductivity (C). The higher the DRASTIC Index will result in the higher vulnerability level of groundwater contamination in that area. The DRASTIC Indexes in the researched area were 85 - 100 (low vulnerability level), 101 -120 (low to moderate vulnerability level), 121 - 140 (moderate vulnerability level), 141 - 150, (moderate to high vulnerability level), and 151 - 159 (high vulnerability level). The output of this study can be used by local authority as a tool for consideration to arrange the policy for sustainable area development, especially the development in an area affecting the quality of Salatiga Groundwater Basin. © Published under licence by IOP Publishing Ltd.",,"Aquifers; Contamination; Geographic information systems; Groundwater; Groundwater pollution; Groundwater resources; Java programming language; Water quality; Aquifer materials; Central Java Province; Groundwater basins; Groundwater contamination; Groundwater vulnerability; Human population; Local authorities; Shallow groundwater; Recharging (underground waters)",2-s2.0-85023197693
"Yalamanchili S., Kumari K.S.","Comparison of manual and automatic testing using genetic algorithm for information handling system",2017,"International Conference on Signal Processing, Communication, Power and Embedded System, SCOPES 2016 - Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025114499&doi=10.1109%2fSCOPES.2016.7955752&partnerID=40&md5=2b52f4c6c45a26bafef2cd22c5ee38a1","Testing is one of the vital activities which must be performed during the software development mainly intent to find the errors according to customer requirement. The purpose of Information Handling for improving software reliability is to provide better service to the administrator or useful for applications developed in an organization. Manual testing process an inter-office communication has been provided for all the developers, managers, tester to communicate. As developer develops the application where the tester can generate the test case required for an application and compare the actual value and expected value the required bug reports as been generated manually. Automation testing process uses a VBScript scripting language to specify the test procedure and to manipulate the objects and controls of the application under test. Where the test cases are been as scripts. In this process it involves the functional testing in genetic algorithm as genetic programming in required computer language to obtain a result summary whereas the report structure. © 2016 IEEE.","Automation testing; Genetic Algorithm; Manual testing; Software testing methods","Application programs; Automatic testing; Computer programming; Embedded systems; Functional programming; Genetic algorithms; Genetic programming; Program debugging; Signal processing; Software design; Software reliability; Application under tests; Automation testing; Customer requirements; Information handling; Information handling systems; Manual testing; Office communications; Scripting languages; Software testing",2-s2.0-85025114499
"Otto J., Vogel-Heuser B., Niggemann O.","Automatic Parameter Estimation for Reusable Software Components of Modular and Reconfigurable Cyber-Physical Production Systems in the Domain of Discrete Manufacturing",2017,"IEEE Transactions on Industrial Informatics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023741399&doi=10.1109%2fTII.2017.2718729&partnerID=40&md5=00b3ad649564b41280ff19148fee9490","The main feature of Cyber-Physical Production Systems is its adaptability. They adapt quickly to new requirements such as new products or product variants. Nowadays, a bottleneck is the automation system, for which high manual engineering efforts are needed: Today, on-site technicians write and rewrite automation software, configure real-time communication protocols and create system configurations consisting of machine timing, physical dimensions of products, sensitivity and motor control accelerations and velocities. Cyber-Physical Production Systems often solve this dilemma by relying on reusable software components which are composed in the overall automation software. However, this solution comes with a price, reusable software components need free parameters to adjust to the individual production configurations. IEEE","Automation; cyber-physical production systems; cyber-physical systems; discrete manufacturing; Object oriented modeling; Optimization; Production; Software; Timing; Unified modeling language","Automation; Computer software; Computer software reusability; Embedded systems; Manufacture; Modeling languages; Object oriented programming; Optimization; Production; Unified Modeling Language; Automation software; Discrete manufacturing; Object oriented model; Production system; Real-time communication; Reusable software components; System configurations; Timing; Cyber Physical System",2-s2.0-85023741399
"Dzik J.M., Puścian A., Mijakowska Z., Radwanska K., Łęski S.","PyMICE: APython library for analysis of IntelliCage data",2017,"Behavior Research Methods",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021155506&doi=10.3758%2fs13428-017-0907-5&partnerID=40&md5=9588a9e423922dc2dad799c10cf4bee0","IntelliCage is an automated system for recording the behavior of a group of mice housed together. It produces rich, detailed behavioral data calling for new methods and software for their analysis. Here we present PyMICE, a free and open-source library for analysis of IntelliCage data in the Python programming language. We describe the design and demonstrate the use of the library through a series of examples. PyMICE provides easy and intuitive access to IntelliCage data, and thus facilitates the possibility of using numerous other Python scientific libraries to form a complete data analysis workflow. © 2017 The Author(s)","Analysis; Behavior; IntelliCage; Library; Mice; Python","behavior; computer language; data analysis; human; human experiment; library; workflow",2-s2.0-85021155506
"Gabrani G., Solomon A., Dviwedi U.","Handwritten statement analysis using neural networks",2017,"International Conference on Signal Processing, Communication, Power and Embedded System, SCOPES 2016 - Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025170418&doi=10.1109%2fSCOPES.2016.7955742&partnerID=40&md5=6a33ea43f537b4b544c19ba8e1be7580","This paper aims to scan a handwritten statement sample in the form of an image then uses the neural network to identify the graphological and statement analysis marker s that can give an insight into the psyche of the person who wrote the sample. It is a tried and tested fact that at least 70% of the communication that we engage in is nonverbal in nature. It is from this fact that the sciences of Micro-expression reading, body language analysis etc originated. A similar pattern is observed in the the linguistics of the choice of words of a person and his handwriting. Graphology (Handwriting Analysis) and Statement Analysis can also be a tool to gain an insight in to the psyche of the person. For example if a person uses the word never as a substitute for no in a yes or no there is a high probability of a suspicion of deception in the context. Similar techniques are used by experts of Neuro Linguistic programming worldwide for a variety of applications. They are used to interrogate criminals and hasten the process of investigation. They can act as human lie detectors. From a written statement they can highlight the possible statement that need cross-verification as they can spot graphological and statement analysis markers in them. But such people are few in number and it takes years and years of training to be at that skill level. Hence a software (Matlab application) is then programmed to replicate this behaviour. © 2016 IEEE.","Artificial Intelligence; Handwriting; Neural Network; Sentiment Analysis; Sentiment Analysis","Application programs; Artificial intelligence; Behavioral research; Data mining; Embedded systems; Linguistics; Neural networks; Signal processing; Body language; Handwriting; Handwriting analysis; High probability; Matlab applications; Micro-expressions; Sentiment analysis; Similar pattern; MATLAB",2-s2.0-85025170418
"Vacheva G., Stanev R., Hinov N.","Physical model of an electric vehicle for research of dynamic operating modes",2017,"2017 15th International Conference on Electrical Machines, Drives and Power Systems, ELMA 2017 - Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025457830&doi=10.1109%2fELMA.2017.7955403&partnerID=40&md5=83c77802bd6ecdeea8b6cb720d007f7e","This paper presents mathematical and physical model of permanent magnet synchronous machine which enable simulation and experimental studies of various dynamic modes of operation of electric vehicle in laboratory environment. The mathematical model is realized in Matlab programming language. It provides useful information for investigation of the dynamic modes including control strategies related to recuperation modes. Several operation modes are experimentally studied and analyzed using the physical model. © 2017 IEEE.","dynamic modes; Electric vehicles; modeling; permanent magnets synchronous motors (PMSM)","Electric machinery; Electric vehicles; Magnets; MATLAB; Models; Permanent magnets; Synchronous motors; Vehicles; Control strategies; Dynamic modes; Laboratory environment; Operating modes; Operation mode; Permanent magnet synchronous machines; Permanent magnets synchronous motors; Physical model; Dynamics",2-s2.0-85025457830
"Thomas S.S., Saraswat A., Shashwat A., Bharti V.","Sensing heart beat and body temperature digitally using Arduino",2017,"International Conference on Signal Processing, Communication, Power and Embedded System, SCOPES 2016 - Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025175929&doi=10.1109%2fSCOPES.2016.7955737&partnerID=40&md5=a41846a6a52f48fae582c2e772110ce6","The project is named as 'DIGITALLY SENSE HEART RATE AND BODY TEMPERATURE USING ARDUINO'. With the development of technology, in this project we can digitally sensing body temperature and heart rate using arduino. Mainly arduino is used because it can sense the environment by receiving input from variety of sensors and can affect its surroundings by controlling lights, motors, and other actuators. The microcontroller on the board is programmed using the Arduino programming language. LM35 is used for the sense body temperature. Body temperature is a basic parameter for monitoring and diagnosing human health. Heart beat sensor was used for sensing heart rate. This device will allow one to measure their mean arterial pressure (MAP) in about one minute and the accurate body temperature will be displayed on the Android. The system can be used to measure physiological parameters, such as Heart rate (Systolic and Diastolic), Pulse rate. © 2016 IEEE.","Ardunio; Body temperature; Heart rate","Blood pressure; Embedded systems; Physiological models; Physiology; Signal processing; Ardunio; Basic parameters; Body temperature; Heart beat sensors; Heart rates; Human health; Mean arterial pressure; Physiological parameters; Heart",2-s2.0-85025175929
"Valsamakis Y., Savidis A.","Sharable personal automations for ambient assisted living",2017,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024888836&doi=10.1145%2f3056540.3056560&partnerID=40&md5=7749fb0dc08b2a8b5b827317c7b6c3f0","The population of elderly people and disabled has exponentially increased thanks to advances of medicine which allow people to live longer and healthier than the previous generations. In this context, Ambient Assisted Living (AAL) applications which promotes independent living is more necessary than ever. Also, the Internet of Things (IoT) proliferates as the dominant technological paradigm for the open deployment of networked smart objects in the environment, including physical things, smart devices and entire applications. In our work, a primary objective was the delivery of an AAL framework on the top of smart objects which uses the full range of IoT technologies. Very early, it became evident that the demand of personalized applications in the context of AAL is very intense. This is mainly due to the highly individualized and fluid nature of the required applications. Along these lines, we focus in providing an end-user programming environment to empower carers, possibly the elderly and family themselves, with the necessary tools to easily and quickly craft, test, modify and deploy smart object applications they would like to have in their everyday life. In this paper, we support personalized automations using smart objects for outdoor daily activities, outside the elderly's protected home environment. We initially outline possible useful mobility scenarios. Then, we elaborate on the visual tools we are developing, followed by a brief case study using them. © 2017 ACM.","Ambient Assisted Living; End-User Programming; Internet of Things; Mobility; Visual Programming Languages","Carrier mobility; Computer programming; Internet of things; Visual languages; Ambient assisted living; Ambient assisted living (AAL); End user programming; Independent living; Internet of thing (IOT); Mobility scenarios; Primary objective; Visual programming languages; Assisted living",2-s2.0-85024888836
"Lee G., Heo S., Kim B., Kim J., Kim H.","Integrated IoT programming with selective abstraction",2017,"Proceedings of the ACM SIGPLAN Conference on Languages, Compilers, and Tools for Embedded Systems (LCTES)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029511605&doi=10.1145%2f3078633.3081031&partnerID=40&md5=be5eca5c9baebd3b44a5062d0dd5a9b6","The explosion of networked devices has driven a new computing environment called the Internet of Things (IoT), enabling various services such as home automation and health monitoring. Despite the promising applicability of the IoT, developing an IoT service is challenging for programmers, because the programmers should integrate multiple programmable devices and heterogeneous third-party devices. Recent works have proposed integrated programming platforms, but they either require device-specific implementation for third-party devices without any device abstraction, or abstract all the devices to the standard interfaces requiring unnecessary abstraction of programmable devices. To integrate IoT devices with selective abstraction, this work revisits the object oriented programming (OOP) model, and proposes a new language extension and its compiler-runtime framework, called Esperanto. With three annotations that map each object to its corresponding IoT device, the Esperanto language allows programmers to integrate multiple programmable devices into one OOP program and to abstract similar third-party devices into their common ancestor classes. Given the annotations, the Esperanto compiler automatically partitions the integrated program into multiple sub-programs for each programmable IoT device, and inserts communication and synchronization code. Moreover, for the ancestor classes, the Esperanto runtime dynamically identifies connected third-party devices, and links their corresponding descendent objects. Compared to an existing approach on the integrated IoT programming, Esperanto requires 33.3% fewer lines of code to implement 5 IoT services, and reduces their response time by 44.8% on average.","Esperanto; Integrated programming model; Internet of things; IoT",,2-s2.0-85029511605
"Chang B.R., Lee Y.-D., Liao P.-H.","Development of Multiple Big Data Analytics Platforms with Rapid Response",2017,"Scientific Programming",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022180740&doi=10.1155%2f2017%2f6972461&partnerID=40&md5=8e96f53f6a6899ef626f69de497bf497","The crucial problem of the integration of multiple platforms is how to adapt for their own computing features so as to execute the assignments most efficiently and gain the best outcome. This paper introduced the new approaches to big data platform, RHhadoop and SparkR, and integrated them to form a high-performance big data analytics with multiple platforms as part of business intelligence (BI) to carry out rapid data retrieval and analytics with R programming. This paper aims to develop the optimization for job scheduling using MSHEFT algorithm and implement the optimized platform selection based on computing features for improving the system throughput significantly. In addition, users would simply give R commands rather than run Java or Scala program to perform the data retrieval and analytics in the proposed platforms. As a result, according to performance index calculated for various methods, although the optimized platform selection can reduce the execution time for the data retrieval and analytics significantly, furthermore scheduling optimization definitely increases the system efficiency a lot. © 2017 Bao Rong Chang et al.",,"Computer software; Java programming language; Scheduling; Scheduling algorithms; Search engines; Job scheduling; Multiple platforms; Performance indices; Platform selection; Rapid response; Scheduling optimization; System efficiency; System throughput; Big data",2-s2.0-85022180740
"Chambers M.B., Wang X., Ellezam L., Ersen O., Fontecave M., Sanchez C., Rozes L., Mellot-Draznieks C.","Maximizing the Photocatalytic Activity of Metal-Organic Frameworks with Aminated-Functionalized Linkers: Substoichiometric Effects in MIL-125-NH2",2017,"Journal of the American Chemical Society",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021135910&doi=10.1021%2fjacs.7b02186&partnerID=40&md5=03e1b5faaedf44793474a23046bea0ea","Despite the promise of utilizing metal-organic frameworks (MOFs) as highly tunable photocatalytic materials, systematic studies that interrogate the relationship between their catalytic performances and the amount of functionalized linkers are lacking. Aminated linkers are known to enhance the absorption of light and afford photocatalysis with MOFs under visible-light irradiation. However, the manner in which the photocatalytic performances are impacted by the amount of such linkers is poorly understood. Here, we assess the photocatalytic activity of MIL-125, a TiO2/1,4-benzenedicarboxylate (bdc) MOF for the oxidation of benzyl alcohol to benzaldehyde when increasing amounts of bdc-NH2 linkers (0%, 20%, 46%, 70%, and 100%) are incorporated in the framework. Analytical TEM allowed assessing the homogeneous localization of bdc-NH2 in these mixed-linker MOFs. Steady state reaction rates reveal two regimes of catalytic performances: a first linear regime up to ?50% bdc-NH2 into the hybrid framework whereby increased amounts of bdc-NH2 yielded increased photocatalytic rates, followed by a plateau up to 100% bdc-NH2. This unexpected ""saturation"" of the catalytic activity above ?50% bdc-NH2 content in the framework whatever the wavelength filters used demonstrates that amination of all linkers of the MOF is not required to obtain the maximum photocatalytic activity. This is rationalized on the basis of mixed-valence Ti3+/Ti4+ intermediate catalytic centers revealed by electron spin resonance (ESR) measurements and recent knowledge of lifetime excited states in MIL-125-type of solids. © 2017 American Chemical Society.",,"Amination; Crystalline materials; Electron spin resonance spectroscopy; Java programming language; Light; Magnetic moments; Photocatalysis; Reaction rates; Electron spin resonance measurements; Metal organic framework; Metalorganic frameworks (MOFs); Photocatalytic activities; Photocatalytic materials; Photocatalytic performance; Steady state reactions; Visible-light irradiation; Catalyst activity; benzaldehyde derivative; benzyl alcohol; dicarboxylic acid derivative; metal organic framework; titanium dioxide; amination; Article; electron spin resonance; light absorption; one pot synthesis; oxidation; photocatalysis; proton nuclear magnetic resonance; scanning electron microscopy; steady state; stoichiometry; transmission electron microscopy",2-s2.0-85021135910
"Yang J., Trickett C.A., Alahmadi S.B., Alshammari A.S., Yaghi O.M.","Calcium l -Lactate Frameworks as Naturally Degradable Carriers for Pesticides",2017,"Journal of the American Chemical Society",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021056850&doi=10.1021%2fjacs.7b04542&partnerID=40&md5=91ac143df1756bdd274c5b3990c48755","Two porous, chiral metal-organic frameworks (MOFs), Ca14(l-lactate)20(acetate)8(C2H5OH)(H2O) (MOF-1201) and Ca6(l-lactate)3(acetate)9(H2O) (MOF-1203), are constructed from Ca2+ ions and l-lactate [CH3CH(OH)COO-], where Ca2+ ions are bridged by the carboxylate and hydroxyl groups of lactate and the carboxylate group of acetate to give a three-dimensional arrangement of Ca(-COO, -OH) polyhedra supporting one-dimensional pores with apertures and internal diameters of 7.8 and 9.6 Å (MOF-1201) and 4.6 and 5.6 Å (MOF-1203), respectively. These MOFs represent the first examples of extended porous structures based on Ca2+ and lactate. They show permanent porosity of 430 and 160 m2 g-1, respectively, and can encapsulate an agriculturally important fumigant, cis-1,3-dichloropropene. MOF-1201 shows a 100 times lower release rate compared with liquid cis-1,3-dichloropropene under the same test conditions (25 °C, air flow rate of 1 cm3 min-1). The hydrolysis of MOF-1201 in water makes it the first example of a degradable porous solid carrier for such fumigants. © 2017 American Chemical Society.",,"Carboxylation; Crystalline materials; Fumigation; Java programming language; Pesticides; Polyols; Porosity; Air flow-rate; Carboxylate groups; Hydroxyl groups; Internal diameters; Porous solids; Porous structures; Release rate; Test condition; Calcium; 1,3 dichloropropene; acetic acid; calcium ion; calcium lactate; calcium oxide; carboxylic acid; fumigant; hydroxyl group; lactic acid; metal organic framework; pesticide; unclassified drug; water; Article; degradation; hydrolysis; porosity",2-s2.0-85021056850
"Schreyer W., Kikawa T., Losekamm M.J., Paul S., Picker R.","PENTrack—a simulation tool for ultracold neutrons, protons, and electrons in complex electromagnetic fields and geometries",2017,"Nuclear Instruments and Methods in Physics Research, Section A: Accelerators, Spectrometers, Detectors and Associated Equipment",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017524285&doi=10.1016%2fj.nima.2017.03.036&partnerID=40&md5=e78703c05b03e6d06ca2b4c21ba859dd","Modern precision experiments trapping low-energy particles require detailed simulations of particle trajectories and spin precession to determine systematic measurement limitations and apparatus deficiencies. We developed PENTrack, a tool that allows to simulate trajectories of ultracold neutrons and their decay products—protons and electrons—and the precession of their spins in complex geometries and electromagnetic fields. The interaction of ultracold neutrons with matter is implemented with the Fermi-potential formalism and diffuse scattering using Lambert and microroughness models. The results of several benchmark simulations agree with STARucn v1.2, uncovered several flaws in Geant4 v10.2.2, and agree with experimental data. Experiment geometry and electromagnetic fields can be imported from commercial computer-aided-design and finite-element software. All simulation parameters are defined in simple text files allowing quick changes. The simulation code is written in C++ and is freely available at github.com/wschreyer/PENTrack.git. © 2017 The Authors","Charged-particle tracking; Monte Carlo simulation; Neutron electric dipole moment; Neutron lifetime; Spin tracking; Ultracold neutrons","C++ (programming language); Charged particles; Computer aided design; Electric dipole moments; Electromagnetic fields; Finite element method; Geometry; Intelligent systems; Monte Carlo methods; Neutron reflection; Neutrons; Complex geometries; Finite element software; Low-energy particles; Neutron lifetime; Particle tracking; Particle trajectories; Simulation parameters; Ultra-cold neutrons; Computer software",2-s2.0-85017524285
"Xu M., Yuan S., Chen X.-Y., Chang Y.-J., Day G., Gu Z.-Y., Zhou H.-C.","Two-Dimensional Metal-Organic Framework Nanosheets as an Enzyme Inhibitor: Modulation of the α-Chymotrypsin Activity",2017,"Journal of the American Chemical Society",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021084017&doi=10.1021%2fjacs.7b03450&partnerID=40&md5=844dea7d3ed11e54f6bfd680406478dc","Two-dimensional metal-organic framework (MOF) nanosheets are utilized as effective enzyme inhibitors, providing an inspiring means to enhance the control of cellular processes as well as improve our understanding of the surface chemistry between MOFs and enzymes. In this paper, we demonstrated that the activity of α-chymotrypsin (ChT) can be effectively inhibited with 96.9% inhibition by 2-D Cu(bpy)2(OTf)2 nanosheets, while Zn2(bim)4 nanosheets show no significant inhibition effect toward ChT. Kinetic studies revealed that the material acts as a competitive inhibitor toward ChT. Furthermore, fluorescence and circular dichroism spectroscopy reveal that the 2-D MOF nanosheets do not change the secondary structure of the enzyme. The Cu(II) center of the 2-D nanosheets binds the 4-(2-hydroxyethyl)-1-piperazineethanesulfonic acid (HEPES) molecules in the buffer, leading to an electrostatic interaction between the nanosheets and the enzyme. In addition, the irreversible coordination interactions between Cu(II) center and His-57 played an important role during the inhibition process, as supported by ionic strength experiments and UV absorbance changes of Cu(II) d-d transitions. As a result, the substrate is prevented from reaching the active sites of the enzyme causing enzyme inhibition. The modulation of enzyme activity by 2-D MOF nanosheets opens up a new direction for the exploration of the MOF-bio interface in physiological and catalytic systems. © 2017 American Chemical Society.",,"Circular dichroism spectroscopy; Crystalline materials; Dichroism; Enzyme activity; Enzymes; Ionic strength; Java programming language; Modulation; Nanosheets; Surface chemistry; Alpha chymotrypsins; Coordination interactions; Enzyme inhibitors; Inhibition effect; Inhibition process; Secondary structures; Strength experiments; Two-dimensional metals; Enzyme inhibition; chymotrypsin A; cupric ion; enzyme inhibitor; metal organic framework; nanosheet; zinc ion; Article; circular dichroism; competitive inhibition; controlled study; enzyme activity; enzyme inhibition; enzyme kinetics; fluorescence spectroscopy; ionic strength; protein secondary structure; static electricity; X ray diffraction",2-s2.0-85021084017
"Ciliberti D., Kloosterman F.","Falcon: A highly flexible open-source software for closed-loop neuroscience",2017,"Journal of Neural Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031695524&doi=10.1088%2f1741-2552%2faa7526&partnerID=40&md5=313abd07700393f30fae7e9b909a27fa","Objective. Closed-loop experiments provide unique insights into brain dynamics and function. To facilitate a wide range of closed-loop experiments, we created an open-source software platform that enables high-performance real-time processing of streaming experimental data. Approach. We wrote Falcon, a C++ multi-threaded software in which the user can load and execute an arbitrary processing graph. Each node of a Falcon graph is mapped to a single thread and nodes communicate with each other through thread-safe buffers. The framework allows for easy implementation of new processing nodes and data types. Falcon was tested both on a 32-core and a 4-core workstation. Streaming data was read from either a commercial acquisition system (Neuralynx) or the open-source Open Ephys hardware, while closed-loop TTL pulses were generated with a USB module for digital output. We characterized the round-trip latency of our Falcon-based closed-loop system, as well as the specific latency contribution of the software architecture, by testing processing graphs with up to 32 parallel pipelines and eight serial stages. We finally deployed Falcon in a task of real-time detection of population bursts recorded live from the hippocampus of a freely moving rat. Main results. On Neuralynx hardware, round-trip latency was well below 1 ms and stable for at least 1 h, while on Open Ephys hardware latencies were below 15 ms. The latency contribution of the software was below 0.5 ms. Round-trip and software latencies were similar on both 32- and 4-core workstations. Falcon was used successfully to detect population bursts online with ∼40 ms average latency. Significance. Falcon is a novel open-source software for closed-loop neuroscience. It has sub-millisecond intrinsic latency and gives the experimenter direct control of CPU resources. We envisage Falcon to be a useful tool to the neuroscientific community for implementing a wide variety of closed-loop experiments, including those requiring use of complex data structures and real-time execution of computationally intensive algorithms, such as population neural decoding/encoding from large cell assemblies. © 2017 IOP Publishing Ltd.","closed-loop neuroscience; multi-threaded software; online burst detection; open-source software; real-time processing","C++ (programming language); Closed loop systems; Computer software; Data handling; Distributed parameter control systems; Hardware; Neurology; Neurophysiology; Open systems; Pipeline processing systems; Population statistics; Software engineering; Software testing; Burst detection; Closed loops; Closed-loop experiments; Complex data structures; Computationally intensive algorithms; Multithreaded softwares; Real-time detection; Realtime processing; Open source software",2-s2.0-85031695524
"Garcia P.","Distribution of language measures among individuals with and without non-fluent aphasia",2017,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025166119&doi=10.1145%2f3056540.3076214&partnerID=40&md5=d8cadeb0a212ff6e54b47a5a958684ee","Existing studies report varied findings on the features that influence a non-fluent aphasia diagnosis, due to the numerous measurements and aphasia classifications available. This study applies Mann-Whitney U test to evaluate the distribution of 32 language measures among 78 individuals with and without non-fluent aphasia in the AphasiaBank corpus. The results highlight the different distribution of verbs, auxiliaries, and present participles between the two populations. Future studies will combine the results of this study with the measures speech therapist deem most informative, to generate a tool for visually synthesizing the AphasiaBank data. © 2017 ACM..","Aphasia; Language; Mann-Whitney U; Test battery","Computer applications; Computer programming; Aphasia; Different distributions; Language; Language measure; Mann-Whitney; Mann-Whitney U test; Test batteries; Data visualization",2-s2.0-85025166119
"Dillhoff A., Pahwa H., Conly C., Athitsos V.","Providing meaningful alignments for periodic signs",2017,"ACM International Conference Proceeding Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024927525&doi=10.1145%2f3056540.3056544&partnerID=40&md5=0dba905990bc247287eac8b992c6f452","In sign languages, a periodic sign is one that contains repeated movements. Dynamic Time Warping (DTW) is often used in sign language recognition to generate a frame alignment between two input signs that provides a measure of their similarity. Alignments provided by DTW may not be meaningful when the input contains periodic signs, especially when the number of periods differs between inputs. Additionally, the number of periods may change between individual signers and signs. Little work has been done to address the problem of recognizing periodic signs in the context of DTW. This work evaluates two DTW-based approaches. The first uses a newly defined periodic warping path. The second uses manual annotations to truncate periodic input to contain no more than two periods. These two methods are compared against a standard implementation of DTW. Recognition accuracy and quality of alignment are analyzed. The results motivate a need for further research in periodic sign language recognition. © 2017 ACM.","DTW; Periodic sequences; Sign language recognition","Computer applications; Computer programming; Dynamic time warping; Frame alignments; Manual annotation; Periodic sequence; Recognition accuracy; Sign language; Sign Language recognition; Alignment",2-s2.0-85024927525
"Luo L., Zhang Y., Ma W., Zhuang Y.","System for Land Surface Model Applications Based on Cloud Computing",2017,"IEEE Access",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021821486&doi=10.1109%2fACCESS.2017.2718002&partnerID=40&md5=cd3e15be5b1d18a33e2fd91157681f8a","Cloud computing satisfies the requirement for large volumes of storage and computing resources to simulate land surface models (LSMs). Thus, the Science Cloud of the Chinese Academy of Sciences, which is based on a data cloud and high performance computing cloud, was adopted to support the simulation of LSMs. In this paper, we take advantage of the software and hardware resources of the Science Cloud to establish a prototype system for LSM applications. First, pre-processing and post-processing are crucial components of LSMs, so we specifically designed a freely available integrated software package called 'PPLSMS' (for the pre- and post-processing of LSMs) with different scripting languages and data sets, which can be built on the cloud computing platform. Second, we developed a dedicated Web portal for LSMs based on the cloud computing platform with the representational state transfer application programming interface, which allows the operation of functions, such as parameter and data selection, model configuration, as well as customization of the output, statistics and visualization via a Web browser. Finally, some basic steps were presented to operate the Web portal for LSM applications. The system integrated data sets and approaches may serve as a practical means to facilitate the simulation of LSMs. © 2013 IEEE.","Cloud computing; land surface model; post-processing; pre-processing; web portal","Application programming interfaces (API); Application programs; Cloud computing; Data visualization; Digital storage; Interface states; Portals; Surface measurement; Websites; Chinese Academy of Sciences; Cloud computing platforms; High performance computing (HPC); Land surface modeling; Post processing; Pre-processing; Representational state transfer; Software and hardwares; Distributed computer systems",2-s2.0-85021821486
[No author name available],"Proceedings of the ACM SIGPLAN Conference on Languages, Compilers, and Tools for Embedded Systems (LCTES)",2017,"Proceedings of the ACM SIGPLAN Conference on Languages, Compilers, and Tools for Embedded Systems (LCTES)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029532109&partnerID=40&md5=b5208f342262e0f321f44252a0df6f6c","The proceedings contain 11 papers. The topics discussed include: AOT vs. JIT: impact of profile data on code quality; adaptive optimization for OpenCL programs on embedded heterogeneous systems; auto-vectorization for image processing DSLs; dynamic translation of structured loads/stores and register mapping for architectures with SIMD extensions; optimal functional unit assignment and voltage selection for pipelined MPSoC with guaranteed probability on time performance; integrated IoT programming with selective abstraction; towards SMT-based LTL model checking of clock constraint specification language for real-time and embedded systems; integrating task scheduling and cache locking for multicore real-time embedded systems; towards memory-efficient processing-in-memory architecture for convolutional neural networks; unified nvTCAM and sTCAM architecture for improving packet matching performance; a lightweight progress maximization scheduler for non-volatile processor under unstable energy harvesting; and OSEK-V: application-specific RTOS instantiation in hardware.",,,2-s2.0-85029532109
"Zhou Z., Li W., Li Y., Gao Y.","Development of Ultrasonic Phased Array Immersion C-Scan Automatic Detection System",2017,"Jixie Gongcheng Xuebao/Journal of Mechanical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028046948&doi=10.3901%2fJME.2017.12.028&partnerID=40&md5=6cfabeb5a760650af1a1263be7d64663","The conventional ultrasonic water immersion C-Scan system has disadvantages such as small scanning step distance, low efficiency and inflexibility because the fixed focal depth transducer are adopted. To improve the detection efficiency and applicability of ultrasonic water immersion C-Scan system, the software and hardware of ultrasonic phased array water immersion C-Scan system is developed which based on the electronic linear scanning method and imaging algorithm combined with the three degree-freedom mechanical scanning device. A phased array transducer with 64 elements is used to detect the imperfections of aluminum alloy plate and additive manufactured titanium alloy and evaluate the performance of the detection system. The results show that the developed system has greatly improved the detection efficiency and the detection ability compared to the conventional ultrasonic water immersion C-Scan system. © 2017 Journal of Mechanical Engineering.","Detection system; Immersion C-Scan; Non-destructive testing(NDT); Ultrasonic phased array","Aluminum alloys; C (programming language); Efficiency; Nondestructive examination; Scanning; Titanium alloys; Transducers; Ultrasonic applications; Ultrasonic transducers; Automatic detection systems; Detection system; Immersion C-Scan; Mechanical scanning devices; Non destructive testing; Phased array transducers; Software and hardwares; Ultrasonic phased array; Ultrasonic testing",2-s2.0-85028046948
"Kim D., Kim D.W., Buyukcakir O., Kim M.-K., Polychronopoulou K., Coskun A.","Highly Hydrophobic ZIF-8/Carbon Nitride Foam with Hierarchical Porosity for Oil Capture and Chemical Fixation of CO2",2017,"Advanced Functional Materials",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021072960&doi=10.1002%2fadfm.201700706&partnerID=40&md5=49bb8869242d84d00966917a57870d96","The introduction of hierarchical porosity into metal-organic frameworks (MOFs) has been of considerable interest in gas separation and heterogeneous catalysis due to the efficient mass transfer kinetics through meso/macropores. Here, a facile, scalable approach is reported for the preparation of carbon nitride (CN) foams as structural templates with micrometer-sized pores and high nitrogen content of 25.6 wt% by the fast carbonization of low-cost melamine foam. The nitrogen functionalities of CN foam facilitate chemical anchoring and growth of ZIF-8 (zeolitic imidazolate frameworks) crystals, which leads to the development of hierarchical porosity. The growth of ZIF-8 crystals also renders CN foam, which is hydrophilic in nature, highly hydrophobic exhibiting 135° of water contact angle due to the enhanced surface roughness, thus creating a natural shield for the MOF crystals against water. The introduction of ZIF-8 crystals onto the CN foam enables selective absorption of oils up to 58 wt% from water/oil mixtures and also facilitates the highly efficient conversion of CO2 to chloropropene carbonate in a quantitative yield with excellent product selectivity. Importantly, this present approach could be extended to the vast number of MOF structures, including the ones suffering from water instability, for the preparation of highly functional materials for various applications. © 2017 WILEY-VCH Verlag GmbH & Co. KGaA, Weinheim","CO2 conversion; coatings; composite materials; heterogeneous catalysts; metal-organic frameworks","Carbon dioxide; Carbon nitride; Carbonization; Catalysis; Coatings; Composite coatings; Composite materials; Crystalline materials; Functional materials; Hydrophobicity; Java programming language; Nitrides; Nitrogen; Porosity; Surface roughness; Heterogeneous catalyst; Hierarchical porosity; High nitrogen content; Mass-transfer kinetics; Metal organic framework; Metalorganic frameworks (MOFs); Nitrogen functionalities; Zeolitic imidazolate frameworks; Foams",2-s2.0-85021072960
"Giordano D., Russell J.K.","The heat capacity of hydrous multicomponent natural melts and glasses",2017,"Chemical Geology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994518743&doi=10.1016%2fj.chemgeo.2016.08.036&partnerID=40&md5=2372ad5dd307dd2aa11fbf2514cf9587","The thermophysical properties of silicate melts and glasses are of fundamental importance for the characterization of the dynamics and energetics of silicate melts on Earth and terrestrial planets. The heat capacity of silicate melts is of particular importance because of its implications for the temperature dependencies of melt enthalpy and entropy and for the potential relationship to melt structure and transport properties. Currently, there are reliable models for predicting the heat capacity of simple and multicomponent silicate glasses (Cp glass) as a function of composition and temperature. Recent differential scanning calorimetry (DSC) measurements of heat capacity for multicomponent silicate liquid (Cp liquid), however, have shown that published models do not accurately reproduce heat capacity measurements on some silicate melts. Here, we have compiled a database of heat capacity values for hydrous and anhydrous multicomponent natural samples. The measurements are on pairs of glasses and melts over the compositional range (wt%) of: SiO2 (44–79), Al2O3 (5–35), TiO2 (0–3), FeOtot (0 − 11); Na2O + K2O (0–27); CaO + MgO (0–39), H2O (0–6.3) and minor oxides. The compiled data show strong correlations between silica content (XSiO2) and the configurational heat capacity (Cp config) defined as Cp liquid − Cpglass measured across the glass transition temperature (Tg). This correlation is used to establish an empirical model for predicting Cp liquid as a function of melt composition (i.e. SiO2 content) and values of Cp glass measured at the onset of the glass transition: Cp liquid=52.6–55.88XSiO2+Cp glass The model reproduces values of Cp liquid to within an average relative error of ~ 2.4%. Published models for the heat capacities of silicate melts (e.g., Stebbins, 1984; Richet and Bottinga, 1985; Lange and Navrotsky, 1992) applied to the same dataset have average relative errors in excess of 5.5%. © 2016 Elsevier B.V.","Configurational heat capacity; Glass transition; Heat capacity; Silicate glass; Silicate melt","Differential scanning calorimetry; Glass; Glass transition; Liquids; Silica; Silicates; Specific heat; Thermodynamic properties; Vaporization; Average relative error; Compositional range; Heat capacity measurements; Silicate glass; Silicate melts; Strong correlation; Temperature dependencies; Terrestrial planets; C (programming language); calorimetry; enthalpy; entropy; glass; heat capacity; physical property; silicate melt; temperature effect",2-s2.0-84994518743
"Su Y.-H., Chen A.-M., Wang H.-L., Xiang C.-H.","Quantum entanglement and critical exponents in one-dimensional spin-1 bond-alternating XXZ chains",2017,"Wuli Xuebao/Acta Physica Sinica",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026368291&doi=10.7498%2faps.66.120301&partnerID=40&md5=cf128c96884b1b096245cf39b1771570","The characterization of the quantum phase transition in a lowdimensional system has attracted a considerable amount of attention in quantum manybody systems. As one of the fundamental models in quantum magnetism, spin-1 models have richer phase diagrams and show more complex physical phenomena. In the spin-1 antiferromagnetic XXZ model, the Haldane phase and the Néel phase are the gapped topologic phases which cannot be characterized by the local order parameters. To characterize the nature in such phases, one has to calculate the non-local long range order parameters. Normally, the non-local order parameter in the topological phase is obtained from the extrapolation of finite-sized system in numerical study. However, it is difficult to extract the critical exponents with such an extrapolated non-local order parameter due to the numerical accuracy. In a recently developed tensor network representation, i.e., the infinite matrix product state (iMPS) algorithm, it was shown that the non-local order can be directly calculated from a very large lattice distance in an infinite-sized system rather than an extrapolated order parameter in a finite-sized system. Therefore, it is worthwhile using this convenient technique to study the non-local orders in the topological phases and characterize the quantum criticalities in the topological quantum phase transitions. In this paper, by utilizing the infinite matrix product state algorithm based on the tensor network representation and infinite time evolving block decimation method, the quantum entanglement, fidelity, and critical exponents of the topological phase transition are investigated in the one-dimensional infinite spin-1 bond-alternating XXZ Heisenberg model. It is found that there is always a local dimerization order existing in the whole parameter range when the bond-alternative strength parameter changes from 0 to 1. Also, due to the effect of the bond-alternating, there appears a quantum phase transition from the long-rang ordering topological Néel phase to the local ordering dimerization phase. The von Neumann entropy, fidelity per lattice site, and order parameters all give the same phase transition point at _c = 0:638. To identify the type of quantum phase transition, the central charge c≃0.5 is extracted from the ground state von Neumann entropy and the finite correlation length, which indicates that the phase transition belongs to the twodimensional Ising universality class. Furthermore, it is found that the Néel order and the susceptibility of Néel order have power-law relations to |δ-δc|. From the numerical fitting of the Néel order and its susceptibility, we obtain the characteristic critical exponents β' = 0.236 and γ' =0.838. It indicates that such critical exponents from our method characterize the nature of the quantum phase transition. Our critical exponents from the iMPS method can provide guidance for studying the properties of the phase transition in quantum spin systems. © 2017 Chinese Physical Society.","Critical exponent; Quantum entanglement; Quantum phase transition; Topological phase","Antiferromagnetism; C (programming language); Complex networks; Dimerization; Entropy; Extrapolation; Parameter estimation; Phase diagrams; Phase transitions; Quantum entanglement; Tensors; Topology; Critical exponent; Infinite matrix products; Long-range order parameters; Low-dimensional systems; Network representation; Quantum many-body systems; Quantum phase transitions; Topological phase; Quantum theory",2-s2.0-85026368291
"Viola E., Wigderson A.","Local Expanders",2017,"Computational Complexity",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021102948&doi=10.1007%2fs00037-017-0155-1&partnerID=40&md5=319d33d26f8491bf6bc47a6e83ec0625","A map (Formula presented.) has localityt if every output bit of f depends only on t input bits. Arora et al. (Colloquium on automata, languages and programming, ICALP, 2009) asked if there exist bounded-degree expander graphs on 2n nodes such that the neighbors of a node (Formula presented.) can be computed by maps of constant locality. We give an explicit construction of such graphs with locality one. We then give three applications of this construction: (1) lossless expanders with constant locality, (2) more efficient error reduction for randomized algorithms, and (3) more efficient hardness amplification of one-way permutations. We also give, for n of the form (Formula presented.), an explicit construction of bipartite Ramanujan graphs of degree 3 with 2n−1 nodes in each side such that the neighbors of a node (Formula presented.) can be computed either (1) in constant locality or (2) in constant time using standard operations on words of length (Formula presented.). Our results use in black-box fashion deep explicit constructions of Cayley expander graphs, by Kassabov (Invent Math 170(2):327–354, 2007) for the symmetric group (Formula presented.) and by Morgenstern (J Comb Theory Ser B 62(1):44–62, 1994) for the special linear group SL(Formula presented.). © 2017 Springer International Publishing AG","Cayley graph; Derandomization; Expander graph; Hardness amplification; Locality",,2-s2.0-85021102948
"Foster N.","The next 700 network programming languages",2017,"Proceedings of the Annual ACM Symposium on Theory of Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024377514&doi=10.1145%2f3055399.3081042&partnerID=40&md5=00e69136340b303581f963cf00058e1f","Specification and verification of computer networks has become a reality in recent years, with the emergence of domain-specific programming languages and automated reasoning tools. But the design of these frameworks has been largely ad hoc, driven more by the needs of applications and the capabilities of hardware than by any foundational principles. This talk will present NetKAT, a language for programming networks based on a well-studied mathematical foundation: regular languages and finite automata. The talk will describe the design of the language, discuss its semantic underpinnings, and present highlights from ongoing work extending the language with stateful and probabilistic features. © 2017 ACM.","Domain-specific languages; Formal verification; Kleene algebra with tests; NetKAT; Software-defined networking","Case based reasoning; Computation theory; Computer programming languages; Computer systems programming; Formal verification; Problem oriented languages; Semantics; Software defined networking; Software testing; Verification; Automated reasoning tools; Domain specific languages; Domain specific programming languages; Kleene algebra with tests; Mathematical foundations; NetKAT; Network programming language; Specification and verification; Computer programming",2-s2.0-85024377514
"Artmann S., Weismantel R., Zenklusen R.","A strongly polynomial algorithm for bimodular integer linear programming",2017,"Proceedings of the Annual ACM Symposium on Theory of Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024401307&doi=10.1145%2f3055399.3055473&partnerID=40&md5=44f7697d0d23e0ac29218b07915da5b1","We present a strongly polynomial algorithm to solve integer programs of the form max{cTx: Ax ≤ b, x ∈ ℤn}, for A ∈ ℤm×n with rank (A) = n, b ∈ ℤm, c ∈ ℤn, and where all determinants of (n×n)-submatrices of A are bounded by 2 in absolute value. In particular, this implies that integer programs max{cTx: Qx ≤ b, x ∈ ℤn ≥≥0}, where Q ∈ ℤm×n has the property that all subdeterminants are bounded by 2 in absolute value, can be solved in strongly polynomial time. We thus obtain an extension of the well-known result that integer programs with constraint matrices that are totally uni-modular are solvable in strongly polynomial time. © 2017 ACM.","Bounded subdeterminants; Combinatorial optimization; Integer programming; Total unimodularity","C (programming language); Combinatorial optimization; Computation theory; Matrix algebra; Optimization; Polynomial approximation; Polynomials; Absolute values; Bounded subdeterminants; Integer Linear Programming; Integer program; Strongly polynomial algorithm; Strongly polynomial time; Sub-matrices; Total unimodularity; Integer programming",2-s2.0-85024401307
"DRABENT W.","Logic + control: On program construction and verification",2017,"Theory and Practice of Logic Programming",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020521138&doi=10.1017%2fS1471068417000047&partnerID=40&md5=7b03b93d5f755442f956cdcc4fc532fc","This paper presents an example of formal reasoning about the semantics of a Prolog program of practical importance (the SAT solver of Howe and King). The program is treated as a definite clause logic program with added control. The logic program is constructed by means of stepwise refinement, hand in hand with its correctness and completeness proofs. The proofs are declarative – they do not refer to any operational semantics. Each step of the logic program construction follows a systematic approach to constructing programs which are provably correct and complete. We also prove that correctness and completeness of the logic program is preserved in the final Prolog program. Additionally, we prove termination, occur-check freedom and non-floundering. Our example shows how dealing with “logic” and with “control” can be separated. Most of the proofs can be done at the “logic” level, abstracting from any operational semantics. The example employs approximate specifications; they are crucial in simplifying reasoning about logic programs. It also shows that the paradigm of semantics-preserving program transformations may be not sufficient. We suggest considering transformations which preserve correctness and completeness with respect to an approximate specification. Copyright © Cambridge University Press 2017","declarative programming; floundering; logic programming; occur-check; program completeness; program correctness; program transformation; specification","Computer circuits; Computer programming; Computer programming languages; Logic programming; Semantics; Specifications; Declarative Programming; floundering; occur-check; program completeness; Program correctness; Program transformations; PROLOG (programming language)",2-s2.0-85020521138
"Holzer M., Jakobi S., Kutrib M.","The chop of languages",2017,"Theoretical Computer Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013414290&doi=10.1016%2fj.tcs.2017.02.002&partnerID=40&md5=0c5f260eb2328ebf2f82b3f08479149a","We investigate chop operations, which can be seen as generalized concatenation. For several language families of the Chomsky hierarchy we prove (non)closure properties under chop operations and incomparability to the family of languages that are the chop of two regular languages. We also prove non-closure of that language family under Boolean operations and closure under reversal. Further, the representation of a regular language as the chop of two regular expressions can be exponentially more succinct than its regular expression. By considering the chop of two linear context-free languages we already obtain language families that have non-semi-decidable problems such as emptiness or finiteness. © 2017 Elsevier B.V.","Chomsky hierarchy; Closure properties; Decidability; Descriptional complexity; Language operation","Computability and decidability; Computer programming languages; Pattern matching; Boolean operations; Chomsky Hierarchy; Closure property; Descriptional complexity; Language operation; Regular expressions; Context free languages",2-s2.0-85013414290
"Kamina T., Aotani T., Masuhara H.","Push-based reactive layer activation in context-oriented programming",2017,"Proceedings of the 9th International Workshop on Context-Oriented Programming, COPS 2017 - Collocated with the European Conference on Object-Oriented Programming",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030785716&doi=10.1145%2f3117802.3117805&partnerID=40&md5=0a9accced3475f119717e881d04021dc","There are context-dependent behaviors that are active only when a certain condition holds, and that require a certain transition process before activation. We propose a layer-activation mechanism of context-oriented programming languages for such context-dependent behaviors. Our mechanism supports the implicit layer activation (as opposed to the event-based layer activation) in a sense that a condition of activation is written as a conditional expression over reactive values (e.g., values obtained from sensors). In addition, it is push-based in a sense that it executes the transition process immediately a.er the condition becomes valid (as opposed to the mechanisms that defer the transition process until the first execution of a context-dependent behavior). In this paper, we present how this mechanism works in an extension of ServalCJ with push-based reactive values, and identify open issues raised by this proposal.","Implicit layer activation; Reactive values; Transition processes","Chemical activation; Activation mechanisms; Conditional expressions; Context dependent; Context oriented programming; In contexts; Reactive layers; Reactive values; Transition process; Object oriented programming",2-s2.0-85030785716
"Springer M., Krieger A., Manilov S., Masuhara H.","Dart2java: Running dart in Java-based environments",2017,"Proceedings of the 12th Workshop on Implementation, Compilation and Optimization of Object-Oriented Languages, Programs and Systems, ICOOOLPS 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026377139&doi=10.1145%2f3098572.3098575&partnerID=40&md5=8ce01f04053ac8da3077a98bd9714c23","We present the design and implementation of dart2java, an experimental Dart to Java compiler. It is implemented in Dart and currently supports many but not all Dart language constructs. dart2java is a playground to evaluate performance implications of running Dart code on the JVM and to investigate if it is possible to write Dart code in a largely Javadominated environment. This paper describes the architecture of dart2java, performance optimizations such as non-nullability of primitive types and generic specialization (and their implications), as well as ideas for language interoperability, i.e., calling Java code from Dart and vice versa. © 2017 ACM.","Compiler; Dart; Java; Source code generation","Codes (symbols); Object oriented programming; Program compilers; Compiler; Dart; Design and implementations; Java; Language constructs; Language interoperability; Performance optimizations; Source code generation; Java programming language",2-s2.0-85026377139
"Welch D., Durkee B., Kabbani M., Sitaraman M.","Demo: Formalization IDEs integrated with a verifying compiler",2017,"Proceedings of the 12th Workshop on Implementation, Compilation and Optimization of Object-Oriented Languages, Programs and Systems, ICOOOLPS 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026429106&doi=10.1145%2f3098572.3098580&partnerID=40&md5=630158270e9771bb6a1450748cd7394f","This demonstration will illustrate both a web-And desktop-based formalization IDE (F-IDE) that are backed by a verifying compiler for the RESOLVE specification and programming language. Each IDE we demo supports construction of mathematical developments, formal interface specifications of generic, object-based concepts, and alternative implementations annotated with internal assertions to enable verification. While the first portion of the demo will illustrate the language and verification in the context of the webbased environment, the second half will demonstrate features of a newer desktop-based IDE that provides additional modern IDE amenities beyond those offered by the web-based version. Each IDE we present integrates feedback for mathematical and programmatic type checking, proving, among others, and permit users to generate and run executable, property-preserving Java. © 2017 ACM.",,"Computer programming languages; Integrodifferential equations; Program compilers; Specifications; Interface specification; Object based; Property-preserving; Typechecking; Verifying compilers; Web based; Web-based environment; Object oriented programming",2-s2.0-85026429106
"Horváth G., Pataki N., Balassi M.","Code generation in serializers and comparators of apache flink",2017,"Proceedings of the 12th Workshop on Implementation, Compilation and Optimization of Object-Oriented Languages, Programs and Systems, ICOOOLPS 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026420154&doi=10.1145%2f3098572.3098579&partnerID=40&md5=11c02cb31ece306f3f1e47089cbf1adb","There is a shift in the Big Data world. Applications used to be I/O bound. InfiniBand, SSDs reduced the I/O overhead and more sophisticated algorithms were developed. CPU became a bottleneck for some applications. Using state of the art CPUs, reduced CPU usage can lead to reduced electricity costs even when an application is I/O bound. Apache Flink is an open source framework for processing streams of data and batch jobs. It is using serialization for wide variety of purposes. Not only for sending data over the network, saving it to the hard disk, or for fault tolerance, but also some of the operators can work on the serialized representation of the data instead of Java objects. This approach can improve the performance significantly. Flink has a custom serialization method that enables operators to work on the serialized formats. Currently, Apache Flink uses reflection to serialize Plain Old Java Objects (POJOs). Reflection in Java is notoriously slow. Moreover, the structure of the code is harder to optimize for the JIT compiler. As a Google Summer of Code project in 2016, we implemented code generation for serializers and comparators for POJOs to improve the performance of Apache Flink. Flink has a delicate type system which provides us with lots of information about the types that need to be serialized. Using this information it is possible to generate specialized code with great performance. We achieved more than 6X performance improvement in the serialization which was a 20% overall improvement. © 2017 ACM.","Big data; Code generation; Flink; Janino; Java","Batch data processing; Codes (symbols); Comparator circuits; Comparators (optical); Cost reduction; Data handling; Java programming language; Object oriented programming; Open source software; Program compilers; Program processors; Code Generation; Electricity costs; Flink; Janino; Java; JIT compiler; Open source frameworks; State of the art; Big data",2-s2.0-85026420154
"Shen F.","Android security via static program analysis",2017,"MobiSys 2017 PhD Forum - Proceedings of the 2017 Workshop on MobiSys 2017 Ph.D. Forum, co-located with MobiSys 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025683929&doi=10.1145%2f3086467.3086469&partnerID=40&md5=4a0866430e100a2edcfb73a9a847670f","Android is a popular platform designed for mobile devices. It consists of a customized Linux kernel, middleware, and a few core applications such as the Phone application. The middleware, commonly referred to as the Android framework, provides libraries and runtime services to applications. Applications in Android are written mainly in Java. Once compiled, Android transforms its applications into the Dalvik Executable (or DEX) format to minimize the memory footprint. Android uses a Java VM called Dalvik to execute DEX bytecode. Unlike other mobile OSes, Android has a unique permission mechanism. At development time, an application developer needs to explicitly request permissions by including them in an application configuration file. We refer to this configuration file simply as the manifest in the remainder of the paper. At installation time, each user needs to review the permissions that the application requests and explicitly grant them. © 2017 ACM.",,"Android (operating system); Computer operating systems; Java programming language; Middleware; Android securities; Application developers; Configuration files; Installation time; Phone applications; Popular platform; Run-time services; Static program analysis; Mobile security",2-s2.0-85025683929
"Bassino F., Bouvel M., Pierrot A., Pivoteau C., Rossin D.","An algorithm computing combinatorial specifications of permutation classes",2017,"Discrete Applied Mathematics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016054799&doi=10.1016%2fj.dam.2017.02.013&partnerID=40&md5=aafb3e2890b31acaa96cd0c313d46bec","This article presents a methodology that automatically derives a combinatorial specification for a permutation class  C, given its basis  B of excluded patterns and the set of simple permutations in  C, when these sets are both finite. This is achieved considering both pattern avoidance and pattern containment constraints in permutations. The obtained specification yields a system of equations satisfied by the generating function of  C, this system being always positive and algebraic. It also yields a uniform random sampler of permutations in  C. The method presented is fully algorithmic. © 2017 Elsevier B.V.","Combinatorial specification; Generating function; Pattern avoidance; Permutation class; Random sampler","Specifications; Algorithm computing; Generating functions; Pattern avoidance; Permutation class; Random sampler; System of equations; C (programming language)",2-s2.0-85016054799
"Curticapean R., Dell H., Marx D.","Homomorphisms are a good basis for counting small subgraphs",2017,"Proceedings of the Annual ACM Symposium on Theory of Computing",2,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025123238&doi=10.1145%2f3055399.3055502&partnerID=40&md5=8fb9e42591bd8692fd58f7c4aaa03f57","We introduce graph motif parameters, a class of graph parameters that depend only on the frequencies of constant-size induced subgraphs. Classical works by Lovász show that many interesting quantities have this form, including, for fixed graphs H, the number of H-copies (induced or not) in an input graph G, and the number of homomorphisms from H to G We use the framework of graph motif parameters to obtain faster algorithms for counting subgraph copies of fixed graphs H in host graphs G. More precisely, for graphs H on k edges, we show how to count subgraph copies of H in time kO(k) · n0.174k+o(k) by a surprisingly simple algorithm. This improves upon previously known running times, such as O(n0.91k+c) time for k-edge matchings or O(n0.46k+c) time for k-cycles. Furthermore, we prove a general complexity dichotomy for evaluating graph motif parameters: Given a class C of such parameters, we consider the problem of evaluating f ∈ C on input graphs G, parameterized by the number of induced subgraphs that f depends upon. For every recursively enumerable class C, we prove the above problem to be either FPT or #W[1]-hard, with an explicit dichotomy criterion. This allows us to recover known dichotomies for counting subgraphs, induced subgraphs, and homomorphisms in a uniform and simplified way, together with improved lower bounds. Finally, we extend graph motif parameters to colored subgraphs and prove a complexity trichotomy: For vertex-colored graphs H and G, where H is from a fixed class H, we want to count color-preserving H-copies in G We show that this problem is either polynomial-time solvable or FPT or #W[1]-hard, and that the FPT cases indeed need FPT time under reasonable assumptions. © 2017 ACM.","Counting subgraphs; Exponential time hypothesis; Fixed-parameter tractability; Homomorphisms","Algebra; C (programming language); Graphic methods; Complexity dichotomies; Exponential time hypothesis; Fixed-parameter tractability; Graph parameters; Homomorphisms; Induced subgraphs; SIMPLE algorithm; Subgraphs; Graph theory",2-s2.0-85025123238
"Ramson S., Lincke J., Hirschfeld R.","The declarative nature of implicit layer activation",2017,"Proceedings of the 9th International Workshop on Context-Oriented Programming, COPS 2017 - Collocated with the European Conference on Object-Oriented Programming",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030787434&doi=10.1145%2f3117802.3117804&partnerID=40&md5=8dedc4932fe3b8231e2b86a6da9e1f37","Context-oriented programming (cop) directly addresses context variability by providing dedicated language concepts: layers, units of modularity, store context-dependent behavior. During runtime, layers can be applied dynamically depending on the current context of the program. Various activation means for layers have been proposed. Most of them require developers to model context switches explicitly. In contrast, implicit layer activation (ila) allows developers to bind the activation status of a layer to a boolean predicate. The associated layer stays automatically active as long as the given predicate evaluates to true. Despite its declarative semantics, ila is usually implemented in an imperative fashion. In this paper, we present and compare two implementation variants for ila in ContextJS: an imperative and a reactive implementation. Furthermore, we discuss their trade-offs regarding code complexity as well as runtime overhead. © 2017 Copyright held by the owner/author(s).","Active expressions; Context-oriented programming; Implicit layer activation; Reactive programming","Chemical activation; Economic and social effects; Semantics; Active expressions; Boolean predicates; Code complexity; Context dependent; Context oriented programming; Declarative semantics; Reactive programming; Runtime overheads; Object oriented programming",2-s2.0-85030787434
"Henning J., Felgentreff T., Hirschfeld R.","VMWrapping Fake it till you make it",2017,"Proceedings of the 12th Workshop on Implementation, Compilation and Optimization of Object-Oriented Languages, Programs and Systems, ICOOOLPS 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026402763&doi=10.1145%2f3098572.3098576&partnerID=40&md5=bb9dc8a1d59b5a0f1ae6a12bf5277137","Building or extending Virtual Machines (VMs) to investigate new language features or optimization techniques is challenging in several ways. The overhead for developing a new research VM for an existing practical language is immense, and meaningful evaluation often requires implementing much more than just the parts that are interesting for the research question. In this paper, we propose a different approach for implementing VMs based on wrapping an existing, feature complete VM. Our technique aims for lower implementation overhead by reducing the number of features that have to be implemented to produce a working prototype and thus producing results quicker. While already proving useful for research, our approach also suggests a way to extend legacy virtual machines with new features and optimizations. © 2017 ACM.","Rpython; Virtual machines","Network security; Object oriented programming; Language features; Optimization techniques; Research questions; Rpython; Virtual machine",2-s2.0-85026402763
"Chari G., Garbervetsky D., Marr S.","A metaobject protocol for optimizing application-speci€c run-Time variability",2017,"Proceedings of the 12th Workshop on Implementation, Compilation and Optimization of Object-Oriented Languages, Programs and Systems, ICOOOLPS 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026377135&doi=10.1145%2f3098572.3098577&partnerID=40&md5=af3ba3971668bdee7d048439764123ba","Just-in-Time compilers and their aggressive speculative optimizations reduced the performance gap between dynamic and static languages drastically. To successfully speculate, compilers rely on the program variability observed at run time to be low, and use heuristics to determine when optimization is beneficial. However, some variability patterns are hard to capture with heuristics. Specifically, ephemeral, warmup, rare, and highly indirect variability are challenges for today's compiler heuristics. As a consequence, they can lead to reduced application performance. However, these types of variability are identi€able at the application level and could be mitigated with information provided by developers. As a solution, we propose a metaobject protocol for dynamic compilation systems to enable application developers to provide such information at run time. As a proof of concept, we demonstrate performance improvements for a few scenarios in a dynamic language built on top of the Truffle and Graal system. © 2017 ACM.",,"Object oriented programming; Optimization; Application developers; Application level; Application performance; Dynamic compilation; Just in time compilers; Metaobject protocol; Speculative optimization; Variability patterns; Program compilers",2-s2.0-85026377135
"Ahmed R., Rana B.M.J., Ahmmed S.F.","Effects of magnetic, radiation and chemical reaction on unsteady heat and mass transfer flow of an oscillating cylinder",2017,"AIP Conference Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021869204&doi=10.1063%2f1.4984649&partnerID=40&md5=24dbcb5f3442a7f6e1d4977a9e5c336a","The effects of magnetic, radiation and chemical reaction parameters on the unsteady heat and mass transfer boundary layer flow past an oscillating cylinder is considered. The dimensionless momentum, energy and concentration equations are solved numerically by using explicit finite difference method with the help of a computer programming language Compaq visual FORTRAN 6.6a. The obtained results of this study have been discussed for different values of well-known parameters with different time steps. The effect of these parameters on the velocity field, temperature field and concentration field, skin-friction, Nusselt number, streamlines and isotherms has been studied and results are presented by graphically represented by the tabular form quantitatively. The stability and convergence analysis of the solution parameters that have been used in the mathematical model have been tested. © 2017 Author(s).","Chemical reaction; explicit finite difference; magnetic; MHD; oscillating cylinder; radiation",,2-s2.0-85021869204
"Rana B.M.J., Ahmed R., Ahmmed S.F.","Thermal radiation and mass transfer effects on unsteady MHD free convection flow past a vertical oscillating plate",2017,"AIP Conference Proceedings",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021863527&doi=10.1063%2f1.4984643&partnerID=40&md5=f489541d662f922c096c22fd13bbbfef","Unsteady MHD free convection flow past a vertical porous plate in porous medium with radiation, diffusion thermo, thermal diffusion and heat source are analyzed. The governing non-linear, partial differential equations are transformed into dimensionless by using non-dimensional quantities. Then the resultant dimensionless equations are solved numerically by applying an efficient, accurate and conditionally stable finite difference scheme of explicit type with the help of a computer programming language Compaq Visual Fortran. The stability and convergence analysis has been carried out to establish the effect of velocity, temperature, concentration, skin friction, Nusselt number, Sherwood number, stream lines and isotherms line. Finally, the effects of various parameters are presented graphically and discussed qualitatively. © 2017 Author(s).","Free convection; Heat generation; Mass transfer; Oscillating plate; Porous medium; Thermal radiation",,2-s2.0-85021863527
[No author name available],"MAPL 2017 - Proceedings of the 1st ACM SIGPLAN International Workshop on Machine Learning and Programming Languages, co-located with PLDI 2017",2017,"MAPL 2017 - Proceedings of the 1st ACM SIGPLAN International Workshop on Machine Learning and Programming Languages, co-located with PLDI 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029722731&partnerID=40&md5=fef4ac144824398454da5e0bc80326d8","The proceedings contain 6 papers. The topics discussed include: a computational model for TensorFlow: an introduction; Dyna: toward a self-optimizing declarative language for machine learning applications; debugging probabilistic programs; combining the logical and the probabilistic in program analysis; learning a classifier for false positive error reports emitted by static code analysis tools; and verified perceptron convergence theorem.",,,2-s2.0-85029722731
[No author name available],"ARRAY 2017 - Proceedings of the 4th ACM SIGPLAN International Workshop on Libraries, Languages, and Compilers for Array Programming, co-located with PLDI 2017",2017,"ARRAY 2017 - Proceedings of the 4th ACM SIGPLAN International Workshop on Libraries, Languages, and Compilers for Array Programming, co-located with PLDI 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029694987&partnerID=40&md5=5390b0d869fc943db25e5be1d4e4a3d4","The proceedings contain 8 papers. The topics discussed include: Quad Ropes: immutable, declarative arrays with parallelizable operations; an ELI-to-C compiler: design, implementation, and performance; array programming in Whiley; flexible data views: design and implementation; portable vectorization and parallelization of C++ multi-dimensional array computations; efficient array slicing on the Intel Xeon Phi coprocessor; modular array-based GPU computing in a dynamically-typed language; and HPTT: a high-performance tensor transposition C++ library.",,,2-s2.0-85029694987
"Vieira T., Francis-Landau M., Filardo N.W., Khorasani F., Eisner J.","Dyna: Toward a self-optimizing declarative language for machine learning applications",2017,"MAPL 2017 - Proceedings of the 1st ACM SIGPLAN International Workshop on Machine Learning and Programming Languages, co-located with PLDI 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029694953&doi=10.1145%2f3088525.3088562&partnerID=40&md5=9b73e693d863d48fdd27f6a94317bef8","Declarative programming is a paradigm that allows programmers to specify what they want to compute, leaving how to compute it to a solver. Our declarative programming language, Dyna, is designed to compactly specify computations like those that are frequently encountered in machine learning. As a declarative language, Dyna's solver has a large space of (correct) strategies available to it. We describe a reinforcement learning framework for adaptively choosing among these strategies to maximize efficiency for a given workload. Adaptivity in execution is especially important for software that will run under a variety of workloads, where no fixed policy works well. We hope that reinforcement learning will identify good policies reasonably quickly - offloading the burden of writing efficient code from human programmers.","Declarative programming; Machine learning; Reinforcement learning","Artificial intelligence; Computer programming; Computer programming languages; Learning systems; Logic programming; Object oriented programming; Adaptivity; Declarative Languages; Declarative Programming; Declarative programming language; Human programmers; Large spaces; Machine learning applications; Self-optimizing; Reinforcement learning",2-s2.0-85029694953
"Chen H., Ching W.-M., Hendren L.","An ELI-to-C compiler: Design, implementation, and performance",2017,"ARRAY 2017 - Proceedings of the 4th ACM SIGPLAN International Workshop on Libraries, Languages, and Compilers for Array Programming, co-located with PLDI 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029683554&doi=10.1145%2f3091966.3091969&partnerID=40&md5=f4096ffb9c3d68434d7d9e83cdb26d4d","ELI is a succinct array-based interactive programming language derived from APL. In this paper we present the overall design and implementation of a bootstrapped ELI-to-C compiler which is implemented in ELI. We provide a brief introduction to the ELI language, a high-level view of the code generation strategy, and a description of our bootstrapping process. We also provide a preliminary performance evaluation. Firstly, we use three existing C benchmarks to demonstrate the performance of the ELI-generated C code as compared with interpreted ELI and native C. Secondly, we use two benchmarks originally from APL to compare the ELI-generated C to interpreted ELI and a naive hand-generated C version. These preliminary results are encouraging, showing speedups over the interpreter and in many cases performance close to C. The results also show that some future optimizations, such as copy elimination/avoidance, would be beneficial. © 2017 ACM.","Array programming language; Bootstrapping; Compiler; Performance","APL (programming language); Benchmarking; Computer programming languages; High level languages; Libraries; Program compilers; Bootstrapping; C codes; C compilers; Code Generation; Compiler; Overall design; Performance; C (programming language)",2-s2.0-85029683554
"Margara A., Salvaneschi G.","Consistency types for safe and efficient distributed programming",2017,"Proceedings of the 19th Workshop on Formal Techniques for Java-Like Programs, FTfJP 2017 - Co-located with ECOOP 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026386394&doi=10.1145%2f3103111.3104044&partnerID=40&md5=3c50fcd04cfb8411db6a96aade852201","Consistency is a long standing problem in distributed systems. Low consistency levels are considered a necessity for scalability. High consistency is required for critical tasks such as payment and identification. Modern (geo-)distributed systems rely on the data propagation mechanisms and consistency guarantees of the distributed data store they build upon, which makes the implementation of a system that mixes different levels of consistency complex and error prone. In this paper we present preliminary work on ConSysT, a programming language that supports heterogeneous consistency specifications at the type level. In ConSysT, developers assign consistency levels directly to the data and the type system ensures the correct behavior of the application even with computations that mix data at multiple consistency levels. Our vision is that the ConSysT runtime automatically determines the most efficient mechanism to achieve the desired level of consistency among those offered by the underlying data store. © 2017 ACM.",,"Computer software; Consistency level; Data propagation; Distributed data stores; Distributed programming; Distributed systems; Level of consistencies; Levels of consistency; Standing problems; Java programming language",2-s2.0-85026386394
"Biermann F., Sestoft P.","Quad ropes: Immutable, declarative arrays with parallelizable operations",2017,"ARRAY 2017 - Proceedings of the 4th ACM SIGPLAN International Workshop on Libraries, Languages, and Compilers for Array Programming, co-located with PLDI 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029683745&doi=10.1145%2f3091966.3091971&partnerID=40&md5=f387e3dadc3ecd5c787dae0ac5645474","We describe the quad rope data structure, a representation of immutable two-dimensional arrays that avoids many of the performance pitfalls of plain C-style two-dimensional arrays. Our motivation is that, for end-user development in high-level declarative programming languages, it is impractical to let users choose between different array-like data structures. Instead, one should use the same, somewhat performance-robust, representation for every programming task. Quad ropes roughly retain array efficiency, as long as programmers express their programs using high-level constructs. Moreover, they allow for fast concatenation and dynamic task-based parallelism and are well suited to represent sparse arrays. We describe their operational semantics and evaluate the performance of individual functions on quad ropes as well as declarative algorithms that use our quad rope implementation. © 2017 ACM.","Declarative arrays; End-user development; Spreadsheets","Computer programming; Computer programming languages; Data structures; Human computer interaction; Libraries; Program compilers; Rope; Semantics; Spreadsheets; Array efficiency; Declarative arrays; Declarative programming language; Dynamic tasks; End user development; Operational semantics; Programming tasks; Two-dimensional arrays; High level languages",2-s2.0-85029683745
"Springer M., Wauligmann P., Masuhara H.","Modular array-based GPU computing in a dynamically-typed language",2017,"ARRAY 2017 - Proceedings of the 4th ACM SIGPLAN International Workshop on Libraries, Languages, and Compilers for Array Programming, co-located with PLDI 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029717404&doi=10.1145%2f3091966.3091974&partnerID=40&md5=3d7f066fa8c4654ae47441ad076b2df2","Nowadays, GPU accelerators are widely used in areas with large data-parallel computations such as scientific computations or neural networks. Programmers can either write code in low-level CUDA/OpenCL code or use a GPU extension for a high-level programming language for better productivity. Most extensions focus on statically-typed languages, but many programmers prefer dynamically-typed languages due to their simplicity and flexibility. This paper shows how programmers can write high-level modular code in Ikra, a Ruby extension for array-based GPU computing. Programmers can compose GPU programs of multiple reusable parallel sections, which are subsequently fused into a small number of GPU kernels. We propose a seamless syntax for separating code regions that extensively use dynamic language features from those that are compiled for efficient execution. Moreover, we propose symbolic execution and a program analysis for kernel fusion to achieve performance that is close to hand-written CUDA code. © 2017 ACM.","CUDA; GPGPU; Kernel fusion; Ruby","Codes (symbols); Computer programming; Computer software reusability; Graphics processing unit; High level languages; Libraries; Program processors; Ruby; CUDA; Dynamic languages; Dynamically typed languages; GPGPU; High-level programming language; Kernel fusion; Scientific computation; Symbolic execution; Program compilers",2-s2.0-85029717404
"Pearce D.J.","Array programming in Whiley",2017,"ARRAY 2017 - Proceedings of the 4th ACM SIGPLAN International Workshop on Libraries, Languages, and Compilers for Array Programming, co-located with PLDI 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029709282&doi=10.1145%2f3091966.3091972&partnerID=40&md5=a70c9bcc360c3ba44f211374ffb9f84c","Arrays are a fundamental mechanism for developing and reasoning about programs. Using them, one can easily encode a range of important algorithms from various domains, such as for sorting, graph traversal, heap manipulation and more. However, the encoding of such problems in traditional languages is relatively opaque. That is, such programming languages do not allow those properties important for the given problem to be encoded within the language itself and, instead, rely up on programmer-supplied comments. This paper explores how array-based programming is enhanced by programming languages which support specifications and invariants over arrays. Examples of such systems include Dafny, Why3, Whiley, Spec# and more. For this paper, we choose Whiley as this language provides good support for array-based programming. Whiley is a programming language designed for verification and employs a verifying compiler to ensure that programs meet their specifications. A number of features make Whiley particularly suitable for array-based programming, such as type invariants and abstract properties. We explore this through a series of worked examples. © 2017 ACM.","Array programming; Loop invariants; Software verification","Computer programming; Encoding (symbols); Libraries; Problem oriented languages; Specifications; Verification; Array programming; Fundamental mechanisms; Graph traversals; Loop invariants; Reasoning about programs; Software verification; Type invariants; Verifying compilers; Program compilers",2-s2.0-85029709282
"Amrani M., Schobbens P.-Y.","Formal analysis of object-oriented mograms",2017,"Proceedings of the 19th Workshop on Formal Techniques for Java-Like Programs, FTfJP 2017 - Co-located with ECOOP 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026431371&doi=10.1145%2f3103111.3104042&partnerID=40&md5=8c8d07e61a3647201780dcc0b4b3f647","A mogram designates a software language implemented in either a programming or a modelling language. Object-Oriented mograms share many common language features, but also have specificities related to inheritance, collection values, opposite and contained references, or overloading. We propose a mathematical framework that captures the semantics of such mograms with a precise characterisation of the variation points. We implemented a prototype tool that enables formal analysis in a uniform way. © 2017 ACM.","Formal verification; OO languages; Semantics","Computer software; Formal verification; Modeling languages; Object oriented programming; Semantics; Common languages; Formal analysis; Mathematical frameworks; Object oriented; Prototype tools; Software languages; Variation points; Java programming language",2-s2.0-85026431371
"Abdelgawad M.A.","Towards a Java subtyping operad",2017,"Proceedings of the 19th Workshop on Formal Techniques for Java-Like Programs, FTfJP 2017 - Co-located with ECOOP 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026385711&doi=10.1145%2f3103111.3104043&partnerID=40&md5=5ea908fbaf02e8009cb91aca58d112cc","The subtyping relation in Java exhibits self-similarity. The self-similarity in Java subtyping is interesting and intricate due to the existence of wildcard types and, accordingly, the existence of three subtyping rules for generic types: covariant subtyping, contravariant subtyping and invariant subtyping. Supporting bounded type variables adds to the complexity of the subtyping relation in Java and other similar generic nominally-Typed OO languages such as C# and Scala. In this paper we explore defining an operad to model the construction of the subtyping relation in Java and similar languages. Operads, from category theory, are frequently used to model self-similar phenomena. The Java subtyping operad, we hope, will shed more light on understanding the type systems of generic nominally-Typed OO languages. © 2017 ACM.","Generics; Java; Nominal typing; Object-oriented programming (oop); Operads; Variance annotations","Computer software; Formal languages; Object oriented programming; Generics; Java; Nominal typing; Objectoriented programming (OOP); Operads; Variance annotations; Java programming language",2-s2.0-85026385711
"Abadi M., Isard M., Murray D.G.","A computational model for TensorFlow an introduction",2017,"MAPL 2017 - Proceedings of the 1st ACM SIGPLAN International Workshop on Machine Learning and Programming Languages, co-located with PLDI 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029726574&doi=10.1145%2f3088525.3088527&partnerID=40&md5=ede5bc0dbb84784b31c58e8bbc49caa9","TensorFlow is a powerful, programmable system for machine learning. This paper aims to provide the basics of a conceptual framework for understanding the behavior of TensorFlow models during training and inference: it describes an operational semantics, of the kind common in the literature on programming languages. More broadly, the paper suggests that a programming-language perspective is fruitful in designing and in explaining systems such as TensorFlow.","Machine learning; TensorFlow","Artificial intelligence; Computer programming languages; Object oriented programming; Semantics; Computational model; Conceptual frameworks; Operational semantics; Programmable systems; TensorFlow; Learning systems",2-s2.0-85029726574
"Cong J., Wei P., Yu C.H., Zhou P.","Bandwidth Optimization Through On-Chip Memory Restructuring for HLS",2017,"Proceedings - Design Automation Conference",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023635031&doi=10.1145%2f3061639.3062208&partnerID=40&md5=b60dbc5eb3a6ec4ba4d3d3b60e8bb179","High-level synthesis (HLS) is getting increasing attention from both academia and industry for high-quality and high-productivity designs. However, when inferring primitive-Type arrays in HLS designs into on-chip memory buffers, commercial HLS tools fail to effectively organize FPGAs' on-chip BRAM building blocks to realize high-bandwidth data communication; this often leads to sub-optimal quality of results. This paper addresses this issue via automated on-chip buffer restructuring. Specifically, we present three buffer restructuring approaches and develop an analytical model for each approach to capture its impact on performance and resource consumption. With the proposed model, we formulate the process of identifying the optimal design choice into an integer non-linear programming (INLP) problem and demonstrate that it can be solved efficiently with the help of a one-Time C-To-HDL (hardware description language) synthesis. The experimental results show that our automated source-To-source code transformation tool improves the performance of a broad class of HLS designs by averagely 4.8x. © 2017 ACM.",,"Automation; Bandwidth; C (programming language); Computer aided design; Computer hardware description languages; Cosine transforms; Integer programming; Nonlinear programming; Bandwidth optimization; Building blockes; High productivity; High-bandwidth data communications; On-chip buffers; Quality of results; Resource consumption; Source code transformation; High level synthesis",2-s2.0-85023635031
"Belyakova J.","Generic approach to certified static checking of module-like constructs",2017,"Proceedings of the 19th Workshop on Formal Techniques for Java-Like Programs, FTfJP 2017 - Co-located with ECOOP 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026371886&doi=10.1145%2f3103111.3104045&partnerID=40&md5=a34e3bff255bc7a80ec8d882c1d6d9fe","In this paper we consider the problem of certified static checking of module-like constructs of programming languages. We argue that there are algorithms and properties related to modules that can be defined and proven in abstract way. We advocate the design of a generic Coq library, which is aimed to provide three building blocks for each checking mechanism: propositional, computable, and correctness proofs. Implemented part of the library is justified by applying it to a certified static checker of an extension of STLC. CCS Concepts • Software and its engineering → Modules / packages; Semantics;. © 2017 ACM.","Certified software; Compilers; Coq; Generic programming; Interpreters; Modules","Computer software; Program compilers; Program interpreters; Semantics; Theorem proving; Building blockes; Certified software; Correctness proofs; Generic approach; Generic programming; Modules; Static checking; Java programming language",2-s2.0-85026371886
"Osvald L., Rompf T.","Flexible data views: Design and implementation",2017,"ARRAY 2017 - Proceedings of the 4th ACM SIGPLAN International Workshop on Libraries, Languages, and Compilers for Array Programming, co-located with PLDI 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029722492&doi=10.1145%2f3091966.3091970&partnerID=40&md5=0442e0a02b42b1310b84912ba31ffa16","In this paper, we present a library-based framework of data views over chunks of memory segments. Such views not only enable a uniform treatment of references and arrays, but they provide a more general abstraction in the sense that parts of arrays, references, or even views, can be combined into hierarchies to form new logical data structures. To provide efficient implementations in widely used industrial languages such as C++ and Scala, we employ static and dynamic multi-staging techniques, respectively. Through staging and code specialization, the overhead of traversal and tracking of such view hierarchies is mostly eliminated. Thus, our data views can be used as building blocks for creating data structures for which programmers need not pick a specific representation but can rely on code generation and specialization to provide the right implementation that meets asymptotic running time and space guarantees. We apply our approach in case studies in which twodimensional array views are used to efficiently encode real-world matrices, showing performance on par with specialized data structures such as sparse matrices from popular linear algebra libraries (Armadillo and Eigen), or hand-tuned dense representations. We also show the practicality of specializing data views at run-time on the JVM via Lightweight Modular Staging, a Scala framework for dynamic multi-stage programming, by designing a user-friendly API that hides the underlying compilation through lazy evaluation and a uniform access principle. © 2017 ACM.","Algorithms; Arrays; Memory model; Specialization","Algorithms; Application programming interfaces (API); Data structures; Libraries; Linear algebra; Matrix algebra; Program compilers; Space time codes; Arrays; Design and implementations; Efficient implementation; Linear algebra libraries; Memory modeling; Multi-stage programming; Specialization; Two-dimensional arrays; C++ (programming language)",2-s2.0-85029722492
"Park J., Rival X., Ryu S.","Revisiting recency abstraction for JavaScript: Towards an intuitive, compositional, and efficient heap abstraction",2017,"SOAP 2017 - Proceedings of the 6th ACM SIGPLAN International Workshop on State of the Art in Program Analysis, co-located with PLDI 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029685435&doi=10.1145%2f3088515.3088516&partnerID=40&md5=703de38ff7fd9d1f8e1cacc257e474e2","JavaScript is one of the most widely used programming languages. To understand the behaviors of JavaScript programs and to detect possible errors in them, researchers have developed several static analyzers based on the abstract interpretation framework. However, JavaScript provides various language features that are difficult to analyze statically and precisely such as dynamic addition and removal of object properties, first-class property names, and higher-order functions. To alleviate the problem, JavaScript static analyzers often use recency abstraction, which refines address abstraction by distinguishing recent objects from summaries of old objects. We observed that while recency abstraction enables more precise analysis results by allowing strong updates on recent objects, it is not monotone in the sense that it does not preserve the precision relationship between the underlying address abstraction techniques: for an address abstraction A and a more precise abstraction B, recency abstraction on B may not be more precise than recency abstraction on A. Such an unintuitive semantics of recency abstraction makes its composition with various analysis sensitivity techniques also unintuitive. In this paper, we propose a new singleton abstraction technique, which distinguishes singleton objects to allow strong updates on them without changing a given address abstraction. We formally define recency and singleton abstractions, and explain the unintuitive behaviors of recency abstraction. Our preliminary experiments show promising results for singleton abstraction. © 2017 ACM.","Address abstraction; Address partition; Recency abstraction","Computer programming languages; High level languages; Semantics; Sensitivity analysis; Abstract interpretations; Abstraction techniques; Address abstraction; Higher order functions; JavaScript programs; Language features; Precise abstractions; Recency abstraction; Abstracting",2-s2.0-85029685435
"Murphy C., Gray P., Stewart G.","Verified perceptron convergence theorem",2017,"MAPL 2017 - Proceedings of the 1st ACM SIGPLAN International Workshop on Machine Learning and Programming Languages, co-located with PLDI 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029679039&doi=10.1145%2f3088525.3088673&partnerID=40&md5=9e7edb59bfaa2fce89ac71658b4b151a","Frank Rosenblatt invented the perceptron algorithm in 1957 as part of an early attempt to build ""brain models"", artificial neural networks. In this paper, we apply tools from symbolic logic such as dependent type theory as implemented in Coq to build, and prove convergence of, one-layer perceptrons (specifically, we show that our Coq implementation converges to a binary classifier when trained on linearly separable datasets). Our perceptron and proof are extensible, which we demonstrate by adapting our convergence proof to the averaged perceptron, a common variant of the basic perceptron algorithm. We perform experiments to evaluate the performance of our Coq perceptron vs. an arbitrary-precision C++ implementation and against a hybrid implementation in which separators learned in C++ are certified in Coq. We find that by carefully optimizing the extraction of our Coq perceptron, we can meet - and occasionally exceed - the performance of the arbitrary-precision C++ implementation. Our hybrid Coq certifier demonstrates an architecture for building high-assurance machine-learning systems that reuse existing codebases.","Convergence; Interactive theorem proving; Linear classification; Perceptron","Artificial intelligence; Brain models; C++ (programming language); Classification (of information); High level languages; Learning systems; Neural networks; Object oriented programming; Averaged perceptron; Convergence; Convergence theorem; Dependent type theory; Hybrid implementation; Interactive theorem proving; Linear classification; Perceptron algorithms; Theorem proving",2-s2.0-85029679039
"Ancona D., Ferrando A., Franceschini L., Mascardi V.","Parametric trace expressions for runtime verification of Java-like programs",2017,"Proceedings of the 19th Workshop on Formal Techniques for Java-Like Programs, FTfJP 2017 - Co-located with ECOOP 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026373015&doi=10.1145%2f3103111.3104037&partnerID=40&md5=ab6614aab679aee55a4050b843744cd1","Parametric trace expressions are a formalism expressly designed for parametric runtime verification (RV) which has been introduced and successfully employed in the context of runtime monitoring of multiagent systems. Trace expressions are built on the general notion of event type, which allows them to be adopted in different contexts. In this paper we show how trace expressions can be used for conveniently specifying the expected behavior of a Java-like program to be monitored at runtime. Furthermore, we investigate the basic properties of the primitive operators on which trace expressions are coinductively defined in terms of a labeled transition system; this provides a basis for formal reasoning about equivalence of trace expressions and for adopting useful optimization techniques to speed up runtime verification. © 2017 ACM.","Labeled transition systems; Object-oriented languages; Runtime monitoring; Trace expressions","Computer software; Distributed computer systems; Multi agent systems; Object oriented programming; Verification; Formal reasoning; Java-like programs; Labeled transition systems; Optimization techniques; Primitive operator; Run-time verification; Runtime Monitoring; Trace expressions; Java programming language",2-s2.0-85026373015
"Mukherjee R., Purandare M., Polig R., Kroening D.","Formal Techniques for Effective Co-verification of Hardware/Software Co-designs",2017,"Proceedings - Design Automation Conference",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023600451&doi=10.1145%2f3061639.3062253&partnerID=40&md5=913eaf71d2efaf66dfc3c163a70f5452","Verification is indispensable for building reliable of hardware/software co-designs. However, the scope of formal methods in this domain is limited. This is attributed to the lack of unified property specification languages, the semantic gap between hardware and software components, and the lack of verifiers that support both C and Verilog/VHDL. To address these limitations, we present an approach that uses a bounded co-verification tool, HW-CBMC, for formally validating hardware/software co-designs written in Verilog and C. Properties are expressed in C enriched with special-purpose primitives that capture temporal correlation between hardware and software events. We present an industrial case-study, proving bounded safety properties as well as discovering critical co-design bugs on a large and complex text analytics FPGA accelerator from IBM. © 2017 ACM.","Firmware; HW/SW Co-verification; SAT/SMT Solver; Symbolic Execution; Text Accelerator Co-design; Verilog","Accident prevention; C (programming language); Computer aided design; Computer hardware description languages; Firmware; Formal methods; Formal verification; Hardware; Hardware-software codesign; Semantics; Specification languages; Co-designs; Co-verification; Hardware and software components; Industrial case study; Property specification language; SAT/SMT Solver; Symbolic execution; Temporal correlations; Verification",2-s2.0-85023600451
"Vrvilo N., Yu L., Sarkar V.","A marshalled data format for pointers in relocatable data blocks",2017,"International Symposium on Memory Management, ISMM",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029504284&doi=10.1145%2f3092255.3092276&partnerID=40&md5=b3329e6f464a1dff5c8c14e53ea8abbb","As future computing hardware progresses towards extreme-scale technology, new challenges arise for addressing heterogeneous compute and memory resources, for providing application resilience in the presence of more frequent failures, and for working within strict energy constraints. While C++ has gained popularity in recent years within the HPC community, some concepts of object-oriented program design may be at odds with the techniques we use to address the challenges of extreme-scale computing. In this work, we focus on the challenges related to using aggregate data structures that include pointer values within a programming model where the runtime may frequently relocate data, and traditional serialization techniques are not practical. We propose and evaluate a marshalled encoding for relocatable data blocks, and present a C++ library and other tools to simplify the work of the application programmer developing new applications or porting existing applications to such emerging programming models.","Data block relocation; Marshalling; Onesided communication; Open community runtime; Serialization","C++ (programming language); Computer software; Data blocks; Marshalling; One-sided communications; Runtimes; Serialization; Object oriented programming",2-s2.0-85029504284
"Bakouny Y.E., Crolard T., Mezher D.","A Coq-based synthesis of Scala programs which are correct-by-construction",2017,"Proceedings of the 19th Workshop on Formal Techniques for Java-Like Programs, FTfJP 2017 - Co-located with ECOOP 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026349234&doi=10.1145%2f3103111.3104041&partnerID=40&md5=2807cef1007f268bcfd0408d378f377c","The present paper introduces Scala-of-Coq, a new compiler that allows a Coq-based synthesis of Scala programs which are ""correctby- construction"". A typical workflow features a user implementing a Coq functional program, proving this program's correctness with regards to its specification and making use of Scala-of-Coq to synthesize a Scala program that can seamlessly be integrated into an existing industrial Scala or Java application. © 2017 ACM.","Compilation; Coq; Formal methods; Functional programming; Scala","Application programs; Computer software; Formal methods; Functional programming; Program compilers; Theorem proving; Compilation; Correct-by-construction; Functional programs; Java applications; Scala; Java programming language",2-s2.0-85026349234
"Plagne L., Bojnourdi K.","Portable vectorization and parallelization of C++ multi-dimensional array computations",2017,"ARRAY 2017 - Proceedings of the 4th ACM SIGPLAN International Workshop on Libraries, Languages, and Compilers for Array Programming, co-located with PLDI 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029690967&doi=10.1145%2f3091966.3091973&partnerID=40&md5=4c1cb5515f1dfb63e11b293f8225d4d5","This paper presents LEGOLAS++ arrays, a multi-dimensional array library. Parameterized type of LEGOLAS++ arrays enable data layout adaptation for specific Single Instruction Multiple Data (SIMD) core architectures. The mapping of complex array-based kernels to regular collections of data is efficiently vectorized. In addition, LEGOLAS++ arrays can combine multi-threaded parallelism with SIMD acceleration. For example, a direct tridiagonal solver applied to a collection of equally sized problems exhibits a speedup of more than ×22 on an 8-core SIMD processor. © 2017 ACM.","C++; Data layout transformation; Multi-dimensional array; Parallel programming; SIMD; Template metaprogramming; Vectorization","Cesium; Computer architecture; Libraries; Metadata; Parallel programming; Program compilers; Data layout transformations; Multidimensional arrays; SIMD; Template metaprogramming; Vectorization; C++ (programming language)",2-s2.0-85029690967
"Barnasconi M., Adhikari S.","INVITED: ESL Design in SystemC AMS: Introducing a top-down design methodology for mixed-signal systems: Invited",2017,"Proceedings - Design Automation Conference",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023604403&doi=10.1145%2f3061639.3072951&partnerID=40&md5=e08c3b06ffe6f159e4695dc962ef0b12","For the design and verification of a heterogeneous system architecture containing analog, digital, and software functionality, the use of modern languages and advanced Electronic System-Level (ESL) top-down design methodologies becomes fundamental. This paper will present the industrial application of the SystemC analog/mixed-signal (AMS) extensions in combination with SystemC and other C++ libraries, to enable mixed-signal system-level design of a Magneto Resistive Sensor product. It will demonstrate an efficient top-down design and early verification approach by creating an accurate mixed-signal virtual prototype for concept development and architecture exploration, bringing high modelling fidelity and high simulation speed. © 2017 ACM.","Analog/Mixed-Signal; Electronic System Level; IEEE Std 1666-2011; IEEE Std 1666.1-2016; Magneto Resistive Sensor; SystemC; SystemC AMS","C++ (programming language); Computer aided design; Design; Electric signal systems; Product design; Signal systems; System theory; Systems analysis; Verification; Analog/Mixed-Signal; Electronic system level; IEEE Std 1666-2011; IEEE Std 1666.1-2016; Magneto resistive sensors; SystemC; SystemC-AMS; Logic design",2-s2.0-85023604403
"Liu Z., Criswell J.","Flexible and efficient memory object metadata",2017,"International Symposium on Memory Management, ISMM",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029484117&doi=10.1145%2f3092255.3092268&partnerID=40&md5=583197693b84a3e6d862ddf8858e42e6","Compiler-based tools can protect software from attack and find bugs within programs. To support programs written in type-unsafe languages such as C, such tools need to add code into a program that must, at run-Time, take a pointer into a memory object and locate metadata for that memory object. Current methods of locating metadata are either flexible (supporting metadata of varying sizes) at the expense of speed and scalability or are fast (e.g., by using shadow tables) at the cost of flexibility (metadata is small and must always be the same size). This paper presents a new method of attaching metadata to memory objects, named Padding Area MetaData (PAMD), that is both flexible and efficient. Metadata can be any size, and different memory objects can have different sized metadata. While flexible, the algorithm for finding the metadata given a pointer into the memory object takes constant time. Our method extends Baggy Bounds with Accurate Checking (BBAC) which attaches constantsized metadata to memory objects for performing precise dynamic bounds checks. Our design supports variable-sized metadata, and our implementation supports larger programs. We evaluated the performance and scalability of PAMD using dynamic bounds checking as an exemplar of our method. Our results show that our method adds at most 33% overhead to an identical dynamic bounds checking tool that trades precision for performance by using a simple shadow table. Our results also show that our method, while having the same flexibility as splay trees, performs significantly faster and scales better as a program allocates more memory.","Dynamic analysis; Memory metadata; Memory safety; Security hardening; Shadow table","Dynamic analysis; Embedded systems; Metadata; Program compilers; Program debugging; Scalability; Constant time; Design support; Implementation support; Memory safety; Performance and scalabilities; Security hardening; Shadow table; Support programs; C (programming language)",2-s2.0-85029484117
"Giannini P., Servetto M., Zucca E.","Tracing sharing in an imperative pure calculus (extended abstract)",2017,"Proceedings of the 19th Workshop on Formal Techniques for Java-Like Programs, FTfJP 2017 - Co-located with ECOOP 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026409839&doi=10.1145%2f3103111.3104038&partnerID=40&md5=330ce67b002f35163d08f87184e2d777","We introduce a type and effect system, for an imperative object calculus, which infers sharing possibly introduced by the evaluation of an expression. Sharing is directly represented at the syntactic level as a relation among free variables, thanks to the fact that the calculus is pure. That is, imperative features are modeled by just rewriting source code terms. We consider both standard variables and affine variables, which can occur at most once in their scope. The latter are used as temporary references, to ""move"" a capsule (an isolated portion of store) to another location in the store. The sharing effects inferred by the type system are very expressive, and generalize notions introduced in literature by type modifiers. © 2017 ACM.","Calculi; Sharing; Type and effect systems","Biomineralization; Calculations; Computer software; Calculi; Extended abstracts; Free variable; Imperative features; Object calculi; Sharing; Type and effect systems; Type systems; Java programming language",2-s2.0-85026409839
"Bjørnseth B.A., Meyer J.C., Natvig L.","Efficient array slicing on the Intel Xeon Phi coprocessor",2017,"ARRAY 2017 - Proceedings of the 4th ACM SIGPLAN International Workshop on Libraries, Languages, and Compilers for Array Programming, co-located with PLDI 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029713511&doi=10.1145%2f3091966.3091975&partnerID=40&md5=87886af2a7b5b9a1dc602e7db901c230","Array slicing is an operation which selects a subset of elements from a source array and copies them into a destination array. In this article we present an algorithm for generating code for a subset of Fortran slicing expressions, targeting the first generation Intel Xeon Phi coprocessor. The resulting code outperforms the code produced by Intel's Fortran compiler by 2:40× on average for a set of slicing expressions, and by 2:23× and 1:13× on average for two slicing expressions relevant for border exchange code. © 2017 ACM.","Code generation; Compiler; Fortran; Slicing; Xeon phi","Codes (symbols); Coprocessor; FORTRAN (programming language); Libraries; Code Generation; Compiler; Fortran compilers; Slicing; Source arrays; Xeon phi; Program compilers",2-s2.0-85029713511
"Vorobyov K., Signoles J., Kosmatov N.","Shadow state encoding for efficient monitoring of block-level properties",2017,"International Symposium on Memory Management, ISMM",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029543646&doi=10.1145%2f3092255.3092269&partnerID=40&md5=606d576a83d610088ccd452ccf94e520","Memory shadowing associates addresses from an application's memory to values stored in a disjoint memory space called shadow memory. At runtime shadow values store metadata about application memory locations they are mapped to. Shadow state encodings -The structure of shadow values and their interpretation - vary across different tools. Encodings used by the state-of-The-Art monitoring tools have been proven useful for tracking memory at a byte-level, but cannot address properties related to memory block boundaries. Tracking block boundaries is however crucial for spatial memory safety analysis, where a spatial violation such as outof- bounds access, may dereference an allocated location belonging to an adjacent block or a different struct member. This paper describes two novel shadow state encodings which capture block-boundary-related properties. These encodings have been implemented in E-ACSL -A runtime verification tool for C programs. Initial experiments involving checking validity of pointer and array accesses in computationally intensive runs of programs selected from SPEC CPU benchmarks demonstrate runtime and memory overheads comparable to state-of-The-Art memory debuggers.","Frama-c; Memory safety; Runtime monitoring; Shadow memory","C (programming language); Encoding (symbols); Signal encoding; State assignment; Efficient monitoring; Memory overheads; Memory safety; Monitoring tools; Run-time verification; Runtime Monitoring; Shadow memory; State of the art; Program debugging",2-s2.0-85029543646
"Rapoport M., Lhoták O.","Mutable wadler fest DOT",2017,"Proceedings of the 19th Workshop on Formal Techniques for Java-Like Programs, FTfJP 2017 - Co-located with ECOOP 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026382121&doi=10.1145%2f3103111.3104036&partnerID=40&md5=6da424cd2b75ed7f6ae62a1ecee1375c","The Dependent Object Types (DOT) calculus aims to model the essence of Scala, with a focus on abstract type members, pathdependent types, and subtyping. Other Scala features could be defined by translation to DOT. Mutation is a fundamental feature of Scala currently missing in DOT. Mutation in DOT is needed not only to model effectful computation and mutation in Scala programs, but even to precisely specify how Scala initializes immutable variables and fields (vals). We present an extension to DOT that adds typed mutable reference cells. We have proven the extension sound with a mechanized proof in Coq. We present the key features of our extended calculus and its soundness proof, and discuss the challenges that we encountered in our search for a sound design and the alternative solutions that we considered. © 2017 ACM.",,"Calculations; Computer software; Theorem proving; Abstract types; Alternative solutions; Fundamental features; Key feature; Mechanized proofs; Sound designs; Soundness proofs; Subtypings; Java programming language",2-s2.0-85026382121
"Rhodes D., Flanagan C., Freund S.N.","Correctness of partial escape analysis for multithreading optimization",2017,"Proceedings of the 19th Workshop on Formal Techniques for Java-Like Programs, FTfJP 2017 - Co-located with ECOOP 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026424812&doi=10.1145%2f3103111.3104039&partnerID=40&md5=54de4cd0ba32b679ecfd25cbc661bb5b","Compilers open use escape analysis to elide locking operations on thread-local data. Similarly, dynamic race detectors may use escape analysis to elide race checks on thread-local data. In this paper, we study the correctness of these two related optimizations when using a partial escape analysis, which identifies objects that are currently thread-local but that may later become thread-shared. We show that lock elision based on partial escape analysis is unsound for the Java memory model. We also show that race check elision based on a partial escape analysis weakens the precision of dynamic race detectors. Finally, we prove that race check elision based on a partial escape analysis is sound with respect to this weakened, but still useful, notion of precision. © 2017 ACM.","Escape analysis; Lock elision; Race detection","Computer software; Locks (fasteners); Escape analysis; Java Memory model; Local data; Lock elisions; Multi-threading; Race detection; Java programming language",2-s2.0-85026424812
"Asǎvoae I.M., Nguyen H.N., Roggenbach M., Shaikh S.A.","Software model checking: A promising approach to verify mobile app security-A position paper",2017,"Proceedings of the 19th Workshop on Formal Techniques for Java-Like Programs, FTfJP 2017 - Co-located with ECOOP 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026354873&doi=10.1145%2f3103111.3104040&partnerID=40&md5=3d298bdfabbbdcf233b3510cb7d3787f","In this position paper we advocate software model checking as a technique suitable for security analysis of mobile apps. Our recommendation is based on promising results that we achieved on analysing app collusion in the context of the Android operating system. Broadly speaking, app collusion appears when, in performing a threat, several apps are working together, i.e., they exchange information which they could not obtain on their own. In this context, we developed the K-Android tool, which provides an encoding of the Android/Smali code semantics within the K framework. KAndroid allows for software model checking of Android APK ?les. though our experience so far is limited to collusion, we believe the approach to be applicable to further security properties as well as other mobile operating systems. © 2017 ACM.","Android; Collusion; Mobile security; Software model checking","Android (operating system); Application programs; Computer software; Java programming language; Model checking; Semantics; Android; Code semantics; Collusion; Mobile operating systems; Position papers; Security analysis; Security properties; Software model checking; Mobile security",2-s2.0-85026354873
"Alderson T., Alderson T.","3-Dimensional Optical Orthogonal Codes with Ideal Autocorrelation-Bounds and Optimal Constructions",2017,"IEEE Transactions on Information Theory",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021792156&doi=10.1109%2fTIT.2017.2717538&partnerID=40&md5=9987570b7976ebc0ce6b211d2b173f22","Several new constructions of 3-dimensional optical orthogonal codes are presented here. In each case, the codes have ideal off-peak autocorrelation &#x03BB;a &#x0003D; 0, and in all but one case a cross correlation of &#x03BB;c &#x0003D; 1. All codes produced are optimal with respect to the applicable Johnson bound either presented or developed here. Thus, on one hand the codes are as large as possible, and on the other, the bound(s) are shown to be tight. All codes are constructed by using a particular automorphism (a Singer cycle) of PG(k,q), the finite projective geometry of dimension k over the field of order q, or by using an affine analogue in AG(k,q). IEEE","3-D code; 3-D OOC; Binary codes; Correlation; finite projective geometries; Geometry; Johnson bound; Manganese; Optical Orthogonal Codes; Optical pulses; optimal codes; PG(k,q); Singer cycle; Three-dimensional displays; Wavelength division multiplexing","Autocorrelation; Binary codes; Codes (symbols); Correlation methods; Geometry; Laser pulses; Manganese; Optical correlation; Optimal systems; Wavelength division multiplexing; 3-D code; 3-D OOC; Finite projective geometry; Johnson bound; Optical orthogonal codes; Optimal codes; PG(k,q); Singer cycle; Three-dimensional display; C (programming language)",2-s2.0-85021792156
"Reif M., Eichberg M., Hermann B., Mezini M.","Hermes: Assessment and creation of effective test corpora",2017,"SOAP 2017 - Proceedings of the 6th ACM SIGPLAN International Workshop on State of the Art in Program Analysis, co-located with PLDI 2017",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029714442&doi=10.1145%2f3088515.3088523&partnerID=40&md5=026d336e27f6b7f777608e2cfa3a8bdd","An integral part of developing a new analysis is to validate the correctness of its implementation and to demonstrate its usefulness when applied to real-world code. As a foundation for addressing both challenges developers typically use custom or well-established collections of Java projects. The hope is that the collected projects are representative for the analysis' target domain and therefore ensure a sound evaluation. But, without proper means to understand how and to which degree the features relevant to an analysis are found in the projects, the evaluation necessarily remains inconclusive. Additionally, it is likely that the collection contains many projects which are - w.r.t. the developed analysis - basically identical and therefore do not help the overall evaluation/testing of the analysis, but still cost evaluation time. To overcome these limitations we propose Hermes, a framework that enables the systematic assessment of given corpora and the creation of new corpora of Java projects. To show the usefulness of Hermes, we used it to comprehend the nature of the projects belonging to the Qualitas Corpus (QC) and then used it to compute a minimal subset of all QC projects useful for generic data- and control-flow analyses. This subset enables effective and efficient integration test suites. © 2017 ACM.","Benchmark suites; Java; Program analysis; Test corpora","Computer software; Java programming language; Benchmark suites; Control flow analysis; Cost evaluations; Java; Minimal subset; Program analysis; Systematic assessment; Test corpus; Software testing",2-s2.0-85029714442
"Springer P., Su T., Bientinesi P.","HPTT: A high-performance tensor transposition C++ library",2017,"ARRAY 2017 - Proceedings of the 4th ACM SIGPLAN International Workshop on Libraries, Languages, and Compilers for Array Programming, co-located with PLDI 2017",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028504127&doi=10.1145%2f3091966.3091968&partnerID=40&md5=cf22dc4e544b345ee46f86b4df8b4964","Recently we presented TTC, a domain-specific compiler for tensor transpositions. Despite the fact that the performance of the generated code is nearly optimal, due to its offline nature, TTC cannot be utilized in all the application codes in which the tensor sizes and the necessary tensor permutations are determined at runtime. To overcome this limitation, we introduce the open-source C++ library High-Performance Tensor Transposition (HPTT). Similar to TTC, HPTT incorporates optimizations such as blocking, multithreading, and explicit vectorization; furthermore it decomposes any transposition into multiple loops around a so called microkernel. This modular design-inspired by BLIS-makes HPTT easy to port to different architectures, by only replacing the handvectorized micro-kernel (e.g., a 4 × 4 transpose). HPTT also offers an optional autotuning framework-guided by performance heuristics-that explores a vast search space of implementations at runtime (similar to FFTW). Across a wide range of different tensor transpositions and architectures (e.g., Intel Ivy Bridge, ARMv7, IBM Power7), HPTT attains a bandwidth comparable to that of SAXPY, and yields remarkable speedups over Eigen's tensor transposition implementation. Most importantly, the integration of HPTT into the Cyclops Tensor Framework (CTF) improves the overall performance of tensor contractions by up to 3.1×. © 2017 ACM.","Autotuning; High-performance computing; Multidimensional transposition; Tensors; Vectorization","C++ (programming language); Libraries; Multitasking; Open source software; Optimal systems; Optimization; Program compilers; Application codes; Autotuning; High performance computing; Modular designs; Multidimensional transposition; Tensor contraction; Tensor frameworks; Vectorization; Tensors",2-s2.0-85028504127
"Wei X., Yu C.H., Zhang P., Chen Y., Wang Y., Hu H., Liang Y., Cong J.","Automated Systolic Array Architecture Synthesis for High Throughput CNN Inference on FPGAs",2017,"Proceedings - Design Automation Conference",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023613465&doi=10.1145%2f3061639.3062207&partnerID=40&md5=1d974c3b3188182c20965e69cad8dbe5","Convolutional neural networks (CNNs) have been widely applied in many deep learning applications. In recent years, the FPGA implementation for CNNs has attracted much attention because of its high performance and energy efficiency. However, existing implementations have difficulty to fully leverage the computation power of the latest FPGAs. In this paper we implement CNN on an FPGA using a systolic array architecture, which can achieve high clock frequency under high resource utilization. We provide an analytical model for performance and resource utilization and develop an automatic design space exploration framework, as well as source-to-source code transformation from a C program to a CNN implementation using systolic array. The experimental results show that our framework is able to generate the accelerator for real-life CNN models, achieving up to 461 GFlops for floating point data type and 1.2 Tops for 8-16 bit fixed point. © 2017 ACM.",,"Automation; C (programming language); Computer aided design; Cosine transforms; Deep learning; Deep neural networks; Energy efficiency; Field programmable gate arrays (FPGA); Network architecture; Neural networks; Automatic design space explorations; Computation power; Convolutional neural network; Floating-point data; FPGA implementations; Resource utilizations; Source code transformation; Systolic array architecture; Systolic arrays",2-s2.0-85023613465
"Nandi C., Grossman D., Sampson A., Mytkowicz T., McKinley K.S.","Debugging probabilistic programs",2017,"MAPL 2017 - Proceedings of the 1st ACM SIGPLAN International Workshop on Machine Learning and Programming Languages, co-located with PLDI 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029701425&doi=10.1145%2f3088525.3088564&partnerID=40&md5=11fc6dd1af1aee45b18b797b6a67e3d5","Many applications compute with estimated and uncertain data. While advances in probabilistic programming help developers build such applications, debugging them remains extremely challenging. New types of errors in probabilistic programs include 1) ignoring dependencies and correlation between random variables and in training data, 2) poorly chosen inference hyper-parameters, and 3) incorrect statistical models. A partial solution to prevent these errors in some languages forbids developers from explicitly invoking inference. While this prevents some dependence errors, it limits composition and control over inference, and does not guarantee absence of other types of errors. This paper presents the FLEXI programming model which supports constructs for invoking inference in the language and reusing the results in other statistical computations. We define a novel formalism for inference with a Decorated Bayesian Network and present a tool, DePP, that analyzes this representation to identify the above errors. We evaluate DePP on a range of prototypical examples to show how it helps developers to detect errors. © 2017 ACM.","Debugging; Probabilistic programming; Program analysis; Statistical inference","Artificial intelligence; Bayesian networks; Computer debugging; Errors; Learning systems; Object oriented programming; Random errors; Hyper-parameter; Probabilistic programming; Probabilistic programs; Program analysis; Programming models; Statistical computations; Statistical inference; Uncertain datas; Program debugging",2-s2.0-85029701425
"Dietrich J., Sui L., Rasheed S., Tahir A.","On the construction of soundness oracles",2017,"SOAP 2017 - Proceedings of the 6th ACM SIGPLAN International Workshop on State of the Art in Program Analysis, co-located with PLDI 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029683540&doi=10.1145%2f3088515.3088520&partnerID=40&md5=89be43fc239508a861124f8e2699abee","One of the inherent advantages of static analysis is that it can create and reason about models of an entire program. However, mainstream languages such as Java use numerous dynamic language features designed to boost programmer productivity, but these features are notoriously difficult to capture by static analysis, leading to unsoundness in practice. While existing research has focused on providing sound handling for selected language features (mostly reflection), based on anecdotal evidence and case studies, there is little empirical work to investigate the extent to which particular features cause unsoundness of static analysis in practice. In this paper, we (1) discuss language features that may cause unsoundness and (2) discuss a methodology that can be used to check the (un)soundness of a particular static analysis, call-graph construction, based on soundness oracles. These oracles can also be used for hybrid analyses. © 2017 ACM.","Dynamic analysis; Soundness; Static analysis","Computer programming; Dynamic analysis; Anecdotal evidences; Call graph construction; Case-studies; Dynamic languages; Hybrid analysis; Language features; Programmer productivity; Soundness; Static analysis",2-s2.0-85029683540
"Andreasen E.S., Møller A., Nielsen B.B.","Systematic approaches for increasing soundness and precision of static analyzers",2017,"SOAP 2017 - Proceedings of the 6th ACM SIGPLAN International Workshop on State of the Art in Program Analysis, co-located with PLDI 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029707584&doi=10.1145%2f3088515.3088521&partnerID=40&md5=1a2175cfa0f83de24c2da3f5fbad843e","Building static analyzers for modern programming languages is difficult. Often soundness is a requirement, perhaps with some well-defined exceptions, and precision must be adequate for producing useful results on realistic input programs. Formally proving such properties of a complex static analysis implementation is rarely an option in practice, which raises the challenge of how to identify causes and importance of soundness and precision problems. Through a series of examples, we present our experience with semi-automated methods based on delta debugging and dynamic analysis for increasing soundness and precision of a static analyzer for JavaScript. The individual methods are well known, but to our knowledge rarely used systematically and in combination. © 2017 ACM.","JavaScript; Soundness; Static analysis; Testing","High level languages; Testing; Automated methods; Delta debugging; Input programs; Javascript; Soundness; Static analyzers; Static analysis",2-s2.0-85029707584
"McBurney W.P., Jiang S., Kessentini M., Kraft A.N., Armaly A., Mkaouer W., McMillan C.","Towards Prioritizing Documentation Effort",2017,"IEEE Transactions on Software Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021845866&doi=10.1109%2fTSE.2017.2716950&partnerID=40&md5=cca68064f2e619b9fa94d28b029dffb5","Programmers need documentation to comprehend software, but they often lack the time to write it. Thus, programmers must prioritize their documentation effort to ensure that sections of code important to program comprehension are thoroughly explained. In this paper, we explore the possibility of automatically prioritizing documentation effort. We performed two user studies to evaluate the effectiveness of static source code attributes and textual analysis of source code towards prioritizing documentation effort. The first study used open-source API Libraries while the second study was conducted using closed-source industrial software from ABB. Our findings suggest that static source code attributes are poor predictors of documentation effort priority, whereas textual analysis of source code consistently performed well as a predictor of documentation effort priority. IEEE","code documentation; Documentation; Gold; Java; Libraries; Neural networks; program comprehension; Programming; Software; software maintenance","Codes (symbols); Computer programming; Computer programming languages; Computer software; Computer software maintenance; Gold; Java programming language; Libraries; Mathematical programming; Neural networks; Open source software; System program documentation; Closed source; Industrial software; Java; Open sources; Program comprehension; Source codes; Static sources; Textual analysis; Program documentation",2-s2.0-85021845866
"Mushtaq Z., Rasool G., Shehzad B.","Multilingual Source Code Analysis: A Systematic Literature Review",2017,"IEEE Access",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021789175&doi=10.1109%2fACCESS.2017.2710421&partnerID=40&md5=ed257128a50e4ef8c84eb41972b8cf23","Contemporary software applications are developed using cross-language artifacts which are interdependent with each other. The source code analysis of these applications requires the extraction and examination of artifacts which are build using multiple programming languages along with their dependencies. A large number of studies presented on multilingual source code analysis and its applications in the last one and half decade. The objective of this systematic review (SLR) is to summarize state of the art and prominent areas for future research. This systematic literature review is based on different techniques, tools and methodologies to analyze multilingual source code applications. We finalized 56 multi-discipline published papers relevant to multilingual source code analysis and its applications out of 3820 papers, filtered through multi-stage search criterion. Based on our findings, we highlight research gaps and challenges in the field of multilingual applications. The research findings are presented in the form of research problems, research contributions, challenges and future prospects. We identified 46 research issues and requirements for analyzing multilingual applications and grouped them in 13 different software engineering domains. We examined the research contributions and mapped them with individual research problems. We presented the research contributions in the form of tools techniques and approaches that are presented in the form of research models, platforms, frameworks, prototype models and case studies. Every research has its limitations or prospects for future research. We highlighted the limitations and future perspectives and grouped them in various software engineering domains. Most of the research trends and potential research areas are identified in static source code analysis, program comprehension, refactoring, reverse engineering, detection, and traceability of cross-language links, code coverage, security analysis, cross-language parsing and abstraction of source code models. OAPA","Analytical models; Bibliographies; Data mining; Manuals; Reverse engineering; Reverse Engineering; Software; Software architecture; Software design; Software engineering; Software maintenance; Systematics","Analytical models; Bibliographies; Codes (symbols); Computer programming languages; Computer software; Computer software maintenance; Data mining; Linguistics; Problem oriented languages; Reverse engineering; Software architecture; Software design; Software engineering; Manuals; Potential researches; Program comprehension; Software applications; Software engineering domain; Source code analysis; Systematic literature review; Systematics; Application programs",2-s2.0-85021789175
"Agirreazkuenaga I., Larrondo A.","Much more than airtime: radio strategies to foster an inclusive Latino identity in the Basque country",2017,"Journal of Ethnic and Migration Studies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021174419&doi=10.1080%2f1369183X.2017.1339595&partnerID=40&md5=b29f6ed44a5f6cc3e0d230f39482a02b","New opportunities for launching media projects targeting minority migrant audiences have emerged in the wake of international migration [Georgiou, Myria. 2001. “Mapping Diasporic Minorities and their Media in Europe. Studying the Media.” A working paper for the EMTEL project “Diasporic Minorities and Their Media: A Mapping.” http://www.lse.ac.uk/media@lse/research/EMTEL/minorities/papers/]. However, most start-up enterprises in this category fail to develop effective strategies for establishing a dialogue between the minority audiences they serve and the native-born local populations. This paper, which examines the role radio plays in the integration of newcomers to the Basque Country, analyses the successful programming and outreach initiatives of Candela Radio in Bilbao, Spain, as well as the barriers to multiculturalism that must be overcome in complex societies like the Basque Country, in which deeply rooted traditions and values [Shafir, Gershon. 1995. Immigrants and Nationalists: Ethnic Conflict and Accommodation in Catalonia, the Basque Country, Latvia and Estonia. New York: State University of New York Press] are inextricably bound to language. The results of this qualitative study indicate that publically funded Radio Candela has not only managed to construct an audience that bridges the traditional gap between local migrant and native communities but is also actively fostering the development of a hybrid Latino-Basque identity. © 2017 Informa UK Limited, trading as Taylor & Francis Group","identity; Intercultural communication; Latino-Basque; radio",,2-s2.0-85021174419
"Yan Y., Dantu K., Ko S.Y., Ziarek L.","Poster: RTDroid: A real-time solution with Android",2017,"MobiSys 2017 - Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026263593&doi=10.1145%2f3081333.3089312&partnerID=40&md5=37b74fe8652d5e0ee81699566db129c3","Since the introduction of the smartphone, mobile computing has become pervasive in our society. Meanwhile, Mobile devices have evolved far beyond the stereotypical personal devices and been employed in various traditional real-time embedded domains. Of the currently available mobile systems, Android has seen the most widespread deployment outside of the consumer electronics market. Its open source nature has prompted its ubiquitous adoption in sensing, medical, robotics, and autopilot applications. However, it is not surprising that Android does not provide any real-time guarantee since it is designed as a mobile system and optimised for mobility, user experience, and energy efficiency. Although there has been much interest [1, 2, 3] in adopting Android in real-time contexts, surprisingly little work has been done to examine the suitability of Android for real-time systems. Existing work only provides solutions to traditional problems, including real-time garbage collection at the virtual machine layer, real-time OS scheduling and resource management. While it is critical to address these issues, it is by no means sufficient. After all, Android is a vast system that is more than a Java virtual machine and a kernel. Our work [4, 6, 7] examines the internals of Android, the Android programming model, libraries and core systems services. We discuss the implications and challenges of adapting Android constructs and core system services for real-time and present a solution for each, name RTDroid, as a whole system. It is unique in that it redesigns Android's internal components, replaces Android's Dalvik/ART with a real-time Java virtual machine, FijiVM, and leverages off-the-shelf real-time OSes. RTDroid also provides an event-driven programming model [5] for the development of real-time applications. To retain a familiar style of Android application, we make a number of changes to the Android abstractions and how they interact with the underlying system as well as each other. We aim to leave legacy Android code unaffected and expose real-time features to components which have timeliness requirements. More specifically, Our programming model consist of four parts: 1) real-time constructs for real-time expressiveness, 2) a real-time extension to Android's application manifest for the real-time configuration, 3) real-time communication channels that enable construct interactions with real-time semantics, 4) pause-less memory management with scoped memory. To validate the predictability of RTDroid's implementation, we firstly report a number of micro benchmark results with RTDroid basic constructs. Then, we demonstrate three real-world applications implemented in RTDroid and provide statistic results. Our results illustrate that, at least in these use-cases, the modified platform delivers significantly better time predictability than stock Android and reduces the code complexity as compared to the traditional real-time programming paradigm, RTSJ. © 2017 Copyright held by the owner/author(s).",,"Android (operating system); Computer programming; Energy efficiency; Java programming language; Machine components; mHealth; Network security; Occupational risks; Open source software; Scheduling; Semantics; Virtual machine; Consumer electronics markets; Event-driven programming model; Java virtual machines; Real time programming; Real-time application; Real-time communication; Real-time garbage collection; Time predictabilities; Real time systems",2-s2.0-85026263593
"Thoeum M., Tama A.E., Priyadi A., Purnomo M.H., Pujiantara M.","Design system detecting and monitoring current harmonics using online S transformation based on LabVIEW",2017,"2017 International Conference on Sustainable and Renewable Energy Engineering, ICSREE 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025154371&doi=10.1109%2fICSREE.2017.7951520&partnerID=40&md5=4485bcbf29f0be959db677086bb2aa2e","Nowadays, the civil, business, and industrial electrical power loads in Indonesia are growth rapidly. The main growth is in non-linear load as source of current harmonic which causes serious problem in power quality and safety of electric power system. To solve the problem, power quality monitoring system which is integrated with more effective measurement, control, communication, and supervision ability are needed. To realize those, in this research paper, an online real-time current harmonic detecting and monitoring system using S transform based on LabVIEW software is designed and created. S-transform is chosen to give the support for operation in dynamic condition. Resulting prototype is a harmonic analyzer that works in single or three-phase line through the addition of two identical CT with CT-235. When this prototype is operated in linear or non-linear load, it can monitor the current harmonic in real time mode with continuous data update every 1 second and around 1% measurement error. The testing result also pointed out that prototype still gets to work when the load is changed dynamically. It is different with another harmonic analyzer based on Fourier transform (with analysis update every 10 cycles at frequency 50 Hz) which stops operating when dynamic frequency happened less than 10 cycles (0.2 second). © 2017 IEEE.","dynamic harmonic analyzer; harmonic online analyzer; monitoring current harmonics; stockwell analysis","Computer programming languages; Electric power systems; Frequency meters; Harmonic analysis; Load testing; Mathematical transformations; Monitoring; Quality control; Current harmonics; Electrical power loads; Harmonic analyzers; Lab-view softwares; Online analyzers; Power quality monitoring system; Quality and safeties; stockwell analysis; Power quality",2-s2.0-85025154371
"Bosch J., Olsson H.","Towards Evidence-Based Organizations: Learnings From Embedded Systems, Online Games And Internet of Things",2017,"IEEE Software",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023637413&doi=10.1109%2fMS.2017.265095929&partnerID=40&md5=22199aeae010e7545acaf5f3b83ccd33","One of the prevailing trends in software-intensive companies is the adoption of data driven development practices. Across domains, companies increasingly collect and use data to support development and decision-making activities. In this paper, we study how companies in three domains transition towards data driven development practices where continuous collection and analysis of data inform R&amp;D and management. Currently, the game development and IoT companies are more advanced in terms of data collection and analysis, but these practices are rapidly gaining momentum also in the embedded systems domain. Based on our research, we develop a model in which we detail a set of levels that software-intensive companies typically move through as they transition from &#x2018;ad-hoc&#x2019; collection of data towards an &#x2018;evidence-based&#x2019; organization in which data informs all processes in the organization. IEEE","Companies; D Software/Software Engineering; D.2 Software Engineering; D.2.18 Software Engineering Process; Data collection; Decision making; Embedded systems; Games; Internet of Things; K Computing Milieux; K.6 Management of Computing and Information Systems; K.6.3 Software Management; K.6.3.a Software development; K.6.3.c Software process","C (programming language); Computer games; Data acquisition; Decision making; E-learning; Embedded systems; Industry; Information management; Internet of things; Online systems; Software engineering; Data collection; Games; Management of computing and information systems; Software engineering process; Software management; Software process; Software/software engineering; Software design",2-s2.0-85023637413
"Cai J.L., Tzeng C.-B.","Design of an embedded monitoring system used for the operation conditioning of wind turbine: Wind energy",2017,"2017 International Conference on Sustainable and Renewable Energy Engineering, ICSREE 2017",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025167870&doi=10.1109%2fICSREE.2017.7951521&partnerID=40&md5=562dbe7477ceaf42882297c4dc7d9f96","In this paper, a low-cost and real-time remote monitoring system is proposed to continuously monitor the output performance and operation status of the distributed wind power plant. This system is based on the LoRa network to monitor those parameters related to the output performance and operation status of the wind turbine. The man-machine interface is designed with LabVIEW software to monitor the measured data of output voltage, output current, output power, wind speed, the rotational speed of the wind turbine, vibration analysis of bearing operation, bearing operating noise analysis and operating temperature distribution of the wind turbine. The monitoring node for wind power generator use the LoRa long-distance transmission protocol to transfer data to realize the regional wind power generator data transmission and monitoring. The functionality and the behavior of this proposed system are validated by a series of tests. Test results have proven that this proposed system is capable of completely monitoring the output performance and operation status of each wind turbine. © 2017 IEEE.","monitoring system; operation status; output performance; wind power plant; wind turbine","Computer programming languages; Reactive power; Vibration analysis; Wind power; Wind turbines; Lab-view softwares; Long distance transmission; Man machine interface; Moni-toring nodes; Monitoring system; Operation status; Output performance; Real-time remote monitoring; Monitoring",2-s2.0-85025167870
