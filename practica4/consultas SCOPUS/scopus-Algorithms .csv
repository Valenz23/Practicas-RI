Authors,Title,Year,Source title,Cited by,Link,Abstract,Author Keywords,Index Keywords,EID
"Kurtz B., Mejia F., Kleissl J.","A virtual sky imager testbed for solar energy forecasting",2018,"Solar Energy",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031806827&doi=10.1016%2fj.solener.2017.10.036&partnerID=40&md5=d9695dcbf04d73fc1e248263cb4b53c5","Whole sky imagers are commonly used for forecasting irradiance available for solar energy production, but validation of the forecast models used is difficult due to sparse reference data. We document the use of Large Eddy Simulations (LES) and a 3D Radiative Transfer Model to produce virtual clouds, sky images, and radiation measurements, which permit comprehensive validation of the sky imager forecast. We then use this virtual testbed to investigate the primary sources of sky imager forecast error on a cumulus cloud scene. The largest source of nowcast (0-min-ahead forecast) errors is the converging-ray geometry implied by use of a camera, while longer-term forecasts suffer from overly-simplistic assumptions about cloud evolution. We expect to use these findings to focus future algorithm development, and the virtual testbed to evaluate our progress. © 2017 Elsevier Ltd","Forecast; Large Eddy Simulations; Whole sky imager","Forecasting; Radiative transfer; Solar energy; Testbeds; Algorithm development; Energy forecasting; Energy productions; Forecast errors; Primary sources; Radiation measurements; Radiative transfer model; Virtual test beds; Large eddy simulation; algorithm; cloud; forecasting method; irradiance; large eddy simulation; model validation; nowcasting; optical instrument; radiative transfer; solar power",2-s2.0-85031806827
"Zhao T., Song G., He X.","Inferring diffusion networks with life stage heterogeneity",2018,"Science China Information Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032840274&doi=10.1007%2fs11432-016-9122-x&partnerID=40&md5=afcf1d9cbb7f4f8149eaaa425e80859e","A network inference problem focuses on discovering the structure of a diffusion network from observed cascades. This problem is significantly more challenging in several settings in which this type of an inference is desirable or necessary because of heterogeneity in the diffusion process. The heterogeneity of the diffusion process in different life stages results in the inaccuracy of a common assumption of constant influence strength. In this study, a Life Stage Heuristic (LSH) method is proposed to model life stage heterogeneity by decoupling the popularity level of an item under propagation from a true strength of social ties to improve inference accuracy. The proposed LSH is incorporated into almost all existing state-of-the-art network inference algorithms to improve estimation accuracy with only minimal changes in the implementation and maintaining the same running time. Additionally, NetRate, NetInf, and ConNIe are used as three examples to demonstrate the power of the proposed method. Furthermore, clustering of cascades prior to the LSH is proposed to eliminate noise, and the optimized method is termed as Clustered Life Stage Heuristic (CLSH). Extensive experiments on synthetic and real world datasets indicate that both LSH and CLSH methods significantly improve the accuracy of network inference. © 2017, Science China Press and Springer-Verlag GmbH Germany, part of Springer Nature.","clustering cascade; information diffusion; life stage heterogeneity; network inference; social influence","Inference engines; Diffusion networks; Diffusion process; Information diffusion; Life stages; Network inference; Real-world datasets; Social influence; State of the art; Heuristic methods",2-s2.0-85032840274
"Zhu Q., Liu Y., Lu J., Cao J.","Observability of Boolean control networks",2018,"Science China Information Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032664900&doi=10.1007%2fs11432-017-9135-4&partnerID=40&md5=7979e790e50fd759d41e6fec101677d4","We show some new results on the observability of Boolean control networks (BCNs). First, to study the observability, we combine two BCNs with the same transition matrix into a new BCN. Then, we propose the concept of a reachable set that results in a given set of initial states, and we derive four additional necessary and sufficient conditions for the observability of BCNs. In addition, we present an algorithm and construct an observability graph to determine the observability of BCNs. Finally, we illustrate the obtained results using three numerical examples. © 2017, Science China Press and Springer-Verlag GmbH Germany, part of Springer Nature.","Boolean control network; observability; semi-tensor product","Tensors; Boolean control networks; Initial state; New results; Reachable set; Semi-tensor product; Transition matrices; Observability",2-s2.0-85032664900
"Ramírez-Gallego S., Fernández A., García S., Chen M., Herrera F.","Big Data: Tutorial and guidelines on information and process fusion for analytics algorithms with MapReduce",2018,"Information Fusion",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031496391&doi=10.1016%2fj.inffus.2017.10.001&partnerID=40&md5=6a693a569a782eb3fac76e4ac7be22f1","We live in a world were data are generated from a myriad of sources, and it is really cheap to collect and storage such data. However, the real benefit is not related to the data itself, but with the algorithms that are capable of processing such data in a tolerable elapse time, and to extract valuable knowledge from it. Therefore, the use of Big Data Analytics tools provide very significant advantages to both industry and academia. The MapReduce programming framework can be stressed as the main paradigm related with such tools. It is mainly identified by carrying out a distributed execution for the sake of providing a high degree of scalability, together with a fault-tolerant scheme. In every MapReduce algorithm, first local models are learned with a subset of the original data within the so-called Map tasks. Then, the Reduce task is devoted to fuse the partial outputs generated by each Map. The ways of designing such fusion of information/models may have a strong impact in the quality of the final system. In this work, we will enumerate and analyze two alternative methodologies that may be found both in the specialized literature and in standard Machine Learning libraries for Big Data. Our main objective is to provide an introduction of the characteristics of these methodologies, as well as giving some guidelines for the design of novel algorithms in this field of research. Finally, a short experimental study will allow us to contrast the scalability issues for each type of process fusion in MapReduce for Big Data Analytics. © 2017 Elsevier B.V.","Big Data Analytics; Information fusion; Machine learning; MapReduce; Spark","Artificial intelligence; Data handling; Digital storage; Electric sparks; Information fusion; Learning systems; Scalability; Data analytics; Degree of scalability; Fault tolerant schemes; Map-reduce; Map-reduce programming; Novel algorithm; Scalability issue; Standard machines; Big data",2-s2.0-85031496391
"Kumar T.J., Purusotham S.","The degree constrained k-cardinality minimum spanning tree problem: A lexi-search algorithm",2018,"Decision Science Letters",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032507885&doi=10.5267%2fj.dsl.2017.7.002&partnerID=40&md5=2b4bf23f3641637484a0d74594975e02","This paper deals with the degree constrained k-cardinality minimum spanning tree (k-MSTPD) problem defined on a connected, edge weighted and undirected graph. The aim of this problem is to determine the least weighted spanning tree with exactly k vertices such that except the root vertex, no other vertex in the resultant spanning tree exceeds the specified degree limit. The k-MSTPD problem has many practical applications for the design of electric, communication, and transportation networks. The problem is then formulated as a zero-one programming. In this paper, an exact algorithm known as Lexi-search algorithm (LSA) is developed to tackle the k-MSTPD problem. Furthermore, the developed LSA is programmed in Matlab and tested on some benchmark instances as well as on random instances and the respective results are reported. The obtained experimental results showed that the developed LSA takes significantly less time to find the optimal solutions. © 2018 Growing Science Ltd. All rights reserved.","Degree constraint; K-cardinality minimum spanning; Lexi-search algorithm; Tree",,2-s2.0-85032507885
"Dabrowski J.J., de Villiers J.P., Beyers C.","Naïve Bayes switching linear dynamical system: A model for dynamic system modelling, classification, and information fusion",2018,"Information Fusion",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032181819&doi=10.1016%2fj.inffus.2017.10.002&partnerID=40&md5=bec9b8d5bc7ccab1fdd8c9e3369f17c5","The Naïve Bayes Switching Linear Dynamical System (NB-SLDS) is proposed as a novel variant of the switching linear dynamical system (SLDS). The variant models multi-variable systems that undergo regime changes in their dynamics. The model may be applied to identify regime changes or classify systems according to their dynamics. The NB-SLDS provides the means to fuse multiple sequential data sources into a single model. A key feature of the model is that it is able to handle missing and unsynchronised data. Filtering and smoothing algorithms for inference and an expectation maximisation algorithm for parameter learning in the NB-SLDS are presented. The model is demonstrated and compared to the SLDS and hidden Markov model (HMM) in a human action recognition problem. © 2017","Classification; Dynamic Bayesian network; Missing data; Regime model; Time series","Bayesian networks; Classification (of information); Hidden Markov models; Inference engines; Linear control systems; Markov processes; Sodium; Time series; Dynamic Bayesian networks; Expectation-maximisation; Human-action recognition; Missing data; Parameter learning; Smoothing algorithms; Switching linear dynamical systems; System modelling; Dynamical systems",2-s2.0-85032181819
"Xie Y., Zhang J., Xia Y., Fulham M., Zhang Y.","Fusing texture, shape and deep model-learned information at decision level for automated classification of lung nodules on chest CT",2018,"Information Fusion",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032367648&doi=10.1016%2fj.inffus.2017.10.005&partnerID=40&md5=ba1b9dbb6b5dff54e9335ae8e4f0c90e","The separation of malignant from benign lung nodules on chest computed tomography (CT) is important for the early detection of lung cancer, since early detection and management offer the best chance for cure. Although deep learning methods have recently produced a marked improvement in image classification there are still challenges as these methods contain myriad parameters and require large-scale training sets that are not usually available for most routine medical imaging studies. In this paper, we propose an algorithm for lung nodule classification that fuses the texture, shape and deep model-learned information (Fuse-TSD) at the decision level. This algorithm employs a gray level co-occurrence matrix (GLCM)-based texture descriptor, a Fourier shape descriptor to characterize the heterogeneity of nodules and a deep convolutional neural network (DCNN) to automatically learn the feature representation of nodules on a slice-by-slice basis. It trains an AdaBoosted back propagation neural network (BPNN) using each feature type and fuses the decisions made by three classifiers to differentiate nodules. We evaluated this algorithm against three approaches on the LIDC-IDRI dataset. When the nodules with a composite malignancy rate 3 were discarded, regarded as benign or regarded as malignant, our Fuse-TSD algorithm achieved an AUC of 96.65%, 94.45% and 81.24%, respectively, which was substantially higher than the AUC obtained by other approaches. © 2017 Elsevier B.V.","AdaBoost, information fusion; Back propagation neural network (BPNN); Chest CT; Deep convolutional neural network (DCNN); Lung nodule classification","Adaptive boosting; Backpropagation; Biological organs; Classification (of information); Computerized tomography; Convolution; Image enhancement; Learning systems; Medical imaging; Neural networks; Torsional stress; Automated classification; Back-propagation neural networks; Chest CT; Convolutional neural network; Feature representation; Gray level co occurrence matrix(GLCM); Large-scale training sets; Lung nodule; Deep neural networks",2-s2.0-85032367648
"Pour A.N., Ghobadi S.N.","Optimal selling price, replenishment lot size and number of shipments for two-echelon supply chain model with deteriorating items",2018,"Decision Science Letters",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032475559&doi=10.5267%2fj.dsl.2017.7.001&partnerID=40&md5=3eabaa17891668ec9546c9528fb29fc5","This paper deals with a pricing and production-distribution model for a deteriorating item in a two-echelon supply chain. The profit function for the manufacturer and retailer in the integrated supply chain is derived. The manufacturer's production batch size is regulated to an integer multiple of the discrete delivery lot quantity to the retailer. The objective is to maximize the total profit per unit time by finding the optimal selling price, production lot size, total cycle time, number of deliveries, and delivery lot size, simultaneously. Based on the notion of optimal interval, we outline an effective algorithm for finding the optimal solution. Finally, the authors present a numerical example to illustrate the theoretical results of the model. Sensitivity analysis for the optimal solution with respect to major parameters is also carried out. The results show that, when the deterioration rate increases, both the optimal production lot size and cycle time decrease. It is interesting to note that an increase in the deterioration rate also tends to reduce the delivery lot size without affecting the number of deliveries per production batch. Also, the optimal interval for N does not change when deterioration rate changes. Reductions in the inventory cycle times for both parties demonstrate the negative effects of deterioration on the supply chain. © 2018 Growing Science Ltd. All rights reserved.","Deteriorating item; Lot-sizing; Multiple shipments; Pricing",,2-s2.0-85032475559
"Baldwin P.R., Tan Y.Z., Eng E.T., Rice W.J., Noble A.J., Negro C.J., Cianfrocco M.A., Potter C.S., Carragher B.","Big data in cryoEM: automated collection, processing and accessibility of EM data",2018,"Current Opinion in Microbiology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032485775&doi=10.1016%2fj.mib.2017.10.005&partnerID=40&md5=ec1da9ab4fb2d3faa57e17eeb8986a29","The scope and complexity of cryogenic electron microscopy (cryoEM) data has greatly increased, and will continue to do so, due to recent and ongoing technical breakthroughs that have led to much improved resolutions for macromolecular structures solved using this method. This big data explosion includes single particle data as well as tomographic tilt series, both generally acquired as direct detector movies of ∼10–100 frames per image or per tilt-series. We provide a brief survey of the developments leading to the current status, and describe existing cryoEM pipelines, with an emphasis on the scope of data acquisition, methods for automation, and use of cloud storage and computing. © 2017 Elsevier Ltd",,"algorithm; automation; classification; cloud computing; computer graphics; cryoelectron microscopy; data analysis software; information processing; metadata; Review",2-s2.0-85032485775
"Tsirigos K.D., Govindarajan S., Bassot C., Västermark Å., Lamb J., Shu N., Elofsson A.","Topology of membrane proteins — predictions, limitations and variations",2018,"Current Opinion in Structural Biology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032212566&doi=10.1016%2fj.sbi.2017.10.003&partnerID=40&md5=a51dadcffd346e1a9c2c75d7f9566464","Transmembrane proteins perform a variety of important biological functions necessary for the survival and growth of the cells. Membrane proteins are built up by transmembrane segments that span the lipid bilayer. The segments can either be in the form of hydrophobic alpha-helices or beta-sheets which create a barrel. A fundamental aspect of the structure of transmembrane proteins is the membrane topology, that is, the number of transmembrane segments, their position in the protein sequence and their orientation in the membrane. Along these lines, many predictive algorithms for the prediction of the topology of alpha-helical and beta-barrel transmembrane proteins exist. The newest algorithms obtain an accuracy close to 80% both for alpha-helical and beta-barrel transmembrane proteins. However, lately it has been shown that the simplified picture presented when describing a protein family by its topology is limited. To demonstrate this, we highlight examples where the topology is either not conserved in a protein superfamily or where the structure cannot be described solely by the topology of a protein. The prediction of these non-standard features from sequence alone was not successful until the recent revolutionary progress in 3D-structure prediction of proteins. © 2017 Elsevier Ltd",,"alpha hemolysin; membrane protein; TolC protein; voltage dependent anion channel; alpha helix; artificial neural network; bacterial membrane; beta sheet; conformational transition; hidden Markov model; mitochondrial membrane; nonhuman; oligomerization; prediction; priority journal; protein domain; protein structure; Review; sequence alignment",2-s2.0-85032212566
"Liu W., Yang X., Tao D., Cheng J., Tang Y.","Multiview dimension reduction via Hessian multiset canonical correlations",2018,"Information Fusion",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028972232&doi=10.1016%2fj.inffus.2017.09.001&partnerID=40&md5=d0937224860436347425758b6f8fb2f9","Canonical correlation analysis (CCA) is a main technique of linear subspace approach for two-view dimension reduction by finding basis vectors with maximum correlation between the pair of variables. The shortcoming of the traditional CCA lies that it only handles data represented by two-view features and cannot reveal the nonlinear correlation relationship. In recent years, many variant algorithms have been developed to extend the capability of CCA such as discriminative CCA, sparse CCA, kernel CCA, locality preserving CCA and multiset canonical correlation analysis (MCCA). One representative work is Laplacian multiset canonical correlations (LapMCC) that employs graph Laplacian to exploit the nonlinear correlation information for multiview high-dimensional data. However, it possibly leads to poor extrapolating power because Laplacian regularization biases the solution towards a constant function. In this paper, we present Hessian multiset canonical correlations (HesMCC) for multiview dimension reduction. Hessian can properly exploit the intrinsic local geometry of the data manifold in contrast to Laplacian. HesMCC takes the advantage of Hessian and provides superior extrapolating capability and finally leverage the performance. Extensive experiments on several popular datasets for handwritten digits classification, face classification and object classification validate the effectiveness of the proposed HesMCC algorithm by comparing it with baseline algorithms including TCCA, KMUDA, MCCA and LapMCC. © 2017 Elsevier B.V.","Canonical correlation analysis; Dimension reduction; Hessian; Multiview","Character recognition; Classification (of information); Clustering algorithms; Correlation methods; Data mining; Extrapolation; Laplace transforms; Canonical correlation analysis; Canonical correlations; Dimension reduction; Hessian; Laplacian regularizations; Multi-views; Multiset canonical correlation analysis; Non-linear correlations; Data reduction",2-s2.0-85028972232
"Yuan W., Guan D., Ma T., Khattak A.M.","Classification with class noises through probabilistic sampling",2018,"Information Fusion",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027514343&doi=10.1016%2fj.inffus.2017.08.007&partnerID=40&md5=bdd36462059609109d466e63b487beda","Accurately labeling training data plays a critical role in various supervised learning tasks. Now a wide range of algorithms have been developed to identify and remove mislabeled data as labeling in practical applications might be erroneous due to various reasons. In essence, these algorithms adopt the strategy of one-zero sampling (OSAM), wherein a sample will be selected and retained only if it is recognized as clean. There are two types of errors in OSAM: identifying a clean sample as mislabeled and discarding it, or identifying a mislabeled sample as clean and retaining it. These errors could lead to poor classification performance. To improve classification accuracy, this paper proposes a novel probabilistic sampling (PSAM) scheme. In PSAM, a cleaner sample has more chance to be selected. The degree of cleanliness is measured by the confidence on the label. To accurately estimate the confidence value, a probabilistic multiple voting idea is proposed which is able to assign a high confidence value to a clean sample and a low confidence value to a mislabeled sample. Finally, we demonstrate that PSAM could effectively improve the classification accuracy over existing OSAM methods. © 2017","Mislabeled training data; Multiple voting; One-zero sampling; Probabilistic sampling","Information fusion; Software engineering; Classification accuracy; Classification performance; Confidence values; High confidence; Mislabeled data; Multiple voting; Probabilistic sampling; Training data; Cleaning",2-s2.0-85027514343
"Cao J., Li W., Ma C., Tao Z.","Optimizing multi-sensor deployment via ensemble pruning for wearable activity recognition",2018,"Information Fusion",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028000152&doi=10.1016%2fj.inffus.2017.08.002&partnerID=40&md5=459d86d95f54a6927d6ee515e94865ca","With the rapid development of sensor types and processers, most wearable activity recognition systems tend to making use of multiple homogeneous or heterogeneous sensors to obtain plethora information. However, in a realistic environment, it is difficult to configure an appropriate multi-sensor deployment to gain a tradeoff among computational complexity, accuracy and subject personality. In this paper, a multi-sensor fusion with ensemble pruning system (MSF-EP) is designed to connect with multi-sensor based wearable activity recognition system. As a result, the multi-sensor configuration problem is transformed to multiple ensemble classifier pruning problem. With respect to ensemble pruning for MSF-EP system, two popular order-based ensemble pruning approaches are utilized firstly: reduce-error pruning (RE) and complementarily pruning (Comp). Then, in light of the proposed MSF-EP system, two new ensemble pruning criteria are proposed: mRMR pruning and discriminative pruning (Disc). The mRMR pruning measure is based on mutual information and is a composite criterion of classifier redundancy and relevance with regard to the selected classifier set. Taking into account the discriminations of misclassified instances and correctly classified instances in classifier subset selected respectively, another ensemble pruning measure Disc, which combining RE pruning and Comp pruning, is presented in the form of mutual information also. Finally, the proposed pruning learner with lower error is selected as final ensemble classifier. Through the algorithm, the number and type of multi-sensor are appropriately decided to optimize the multi-sensor fusion without regrading the accuracy performance. The system conducts experimental studies on two real-world activity recognition data sets and the results show the superiority of system over other ensemble algorithms. © 2017 Elsevier B.V.","Body sensor networks; Ensemble pruning; Human activity recognition; Multi-sensor data fusion",,2-s2.0-85028000152
"Du S., Song G., Hong H., Liu D.","Learning dynamic dependency network structure with time lag",2018,"Science China Information Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028950675&doi=10.1007%2fs11432-016-9070-4&partnerID=40&md5=e5e14bf91ef5b21c65acf612720e99a4","Characterizing and understanding the structure and the evolution of networks is an important problem for many different fields. While in the real-world networks, especially the spatial networks, the influence from one node to another tends to vary over both space and time due to the different space distances and propagation speeds between nodes. Thus the time lag plays an essential role in interpreting the temporal causal dependency among nodes and also brings a big challenge in network structure learning. However most of the previous researches aiming to learn the dynamic network structure only treat the time lag as a predefined constant, which may miss important information or include noisy information if the time lag is set too small or too large. In this paper, we propose a dynamic Bayesian model with adaptive lags (DBAL) which simultaneously integrates two usually separate tasks, i.e., learning the dynamic dependency network structure and estimating time lags, within one unified framework. Specifically, we propose a novel weight kernel approach for time series segmenting and sampling via leveraging samples from adjacent segments to avoid the sample scarcity. Besides, an effective Bayesian scheme cooperated with reversible jump Markov chain Monte Carlo (RJMCMC) and expectation propagation (EP) algorithm is proposed for parameter inference. Extensive empirical evaluations are conducted on both synthetic and two real-world datasets, and the results demonstrate that our proposed model is superior to the traditional methods in learning the network structure and the temporal dependency. © 2017, Science China Press and Springer-Verlag GmbH Germany.","dependency network; dynamic network; time lag","Bayesian networks; Markov processes; Dependency networks; Dynamic network; Empirical evaluations; Expectation Propagation; Parameter inference; Real-world networks; Reversible jump Markov chain Monte Carlo; Time lag; Inference engines",2-s2.0-85028950675
"Vieira W.G.R., Nitzsche F., De Marqui C.","The Use of Damping Based Semi-Active Control Algorithms in the Mechanical Smart-Spring System",2018,"Journal of Vibration and Acoustics, Transactions of the ASME",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032017475&doi=10.1115%2f1.4038034&partnerID=40&md5=2df6eafddcdfbe924ac57aefa3d9a759","In recent decades, semi-Active control strategies have been investigated for vibration reduction. In general, these techniques provide enhanced control performance when compared to traditional passive techniques and lower energy consumption if compared to active control techniques. In semi-Active concepts, vibration attenuation is achieved by modulating inertial, stiffness, or damping properties of a dynamic system. The smart spring is a mechanical device originally employed for the effective modulation of its stiffness through the use of semi-Active control strategies. This device has been successfully tested to damp aeroelastic oscillations of fixed and rotary wings. In this paper, the modeling of the smart spring mechanism is presented and two semi-Active control algorithms are employed to promote vibration reduction through enhanced damping effects. The first control technique is the smart-spring resetting (SSR), which resembles resetting control techniques developed for vibration reduction of civil structures as well as the piezoelectric synchronized switch damping on short (SSDS) technique. The second control algorithm is referred to as the smart-spring inversion (SSI), which presents some similarities with the synchronized switch damping (SSD) on inductor technique previously presented in the literature of electromechanically coupled systems. The effects of the SSR and SSI control algorithms on the free and forced responses of the smart-spring are investigated in time and frequency domains. An energy flow analysis is also presented in order to explain the enhanced damping behavior when the SSI control algorithm is employed.",,"Energy utilization; Stiffness; Structural analysis; Aeroelastic oscillations; Control performance; Energy flow analysis; Semi-active control algorithms; Synchronized switch damping; Time and frequency domains; Vibration attenuation; Vibration reductions; Damping",2-s2.0-85032017475
"Zou Z.-Z., Yu X.-T., Zhang Z.-C.","Quantum connectivity optimization algorithms for entanglement source deployment in a quantum multi-hop network",2018,"Frontiers of Physics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030462689&doi=10.1007%2fs11467-017-0721-7&partnerID=40&md5=3d84326524a04d65d01d656a1c92aad6","At first, the entanglement source deployment problem is studied in a quantum multi-hop network, which has a significant influence on quantum connectivity. Two optimization algorithms are introduced with limited entanglement sources in this paper. A deployment algorithm based on node position (DNP) improves connectivity by guaranteeing that all overlapping areas of the distribution ranges of the entanglement sources contain nodes. In addition, a deployment algorithm based on an improved genetic algorithm (DIGA) is implemented by dividing the region into grids. From the simulation results, DNP and DIGA improve quantum connectivity by 213.73% and 248.83% compared to random deployment, respectively, and the latter performs better in terms of connectivity. However, DNP is more flexible and adaptive to change, as it stops running when all nodes are covered. © 2018, Higher Education Press and Springer-Verlag GmbH Germany.","deployment algorithm; entanglement source deployment; quantum connectivity",,2-s2.0-85030462689
"Sayevand K., Pichaghchi K.","Efficient algorithms for analyzing the singularly perturbed boundary value problems of fractional order",2018,"Communications in Nonlinear Science and Numerical Simulation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029806427&doi=10.1016%2fj.cnsns.2017.09.012&partnerID=40&md5=2793c588c3e7839b677e71166a69f05c","In this paper, we were concerned with the description of the singularly perturbed boundary value problems in the scope of fractional calculus. We should mention that, one of the main methods used to solve these problems in classical calculus is the so-called matched asymptotic expansion method. However we shall note that, this was not achievable via the existing classical definitions of fractional derivative, because they do not obey the chain rule which one of the key elements of the matched asymptotic expansion method. In order to accommodate this method to fractional derivative, we employ a relatively new derivative so-called the local fractional derivative. Using the properties of local fractional derivative, we extend the matched asymptotic expansion method to the scope of fractional calculus and introduce a reliable new algorithm to develop approximate solutions of the singularly perturbed boundary value problems of fractional order. In the new method, the original problem is partitioned into inner and outer solution equations. The reduced equation is solved with suitable boundary conditions which provide the terminal boundary conditions for the boundary layer correction. The inner solution problem is next solved as a solvable boundary value problem. The width of the boundary layer is approximated using appropriate resemblance function. Some theoretical results are established and proved. Some illustrating examples are solved and the results are compared with those of matched asymptotic expansion method and homotopy analysis method to demonstrate the accuracy and efficiency of the method. It can be observed that, the proposed method approximates the exact solution very well not only in the boundary layer, but also away from the layer. © 2017 Elsevier B.V.","Boundary layer; Boundary value problem; Local fractional derivative; Matched asymptotic expansion method; Singular perturbation","Asymptotic analysis; Boundary conditions; Boundary layers; Boundary value problems; Calculations; Problem solving; Boundary layer corrections; Fractional derivatives; Homotopy analysis methods; Local fractional derivatives; Matched asymptotic expansion method; Singular perturbations; Singularly perturbed boundary value problems; Terminal boundary conditions; Perturbation techniques",2-s2.0-85029806427
"Branco H.M.G.C., Oleskovicz M., Coury D.V., Delbem A.C.B.","Multiobjective optimization for power quality monitoring allocation considering voltage sags in distribution systems",2018,"International Journal of Electrical Power and Energy Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032812667&doi=10.1016%2fj.ijepes.2017.10.011&partnerID=40&md5=44b0998f18003ba71745c7015f3a5a70","In this research, a multiobjective optimization approach is proposed to help allocate Power Quality (PQ) monitors in Distribution Systems (DS), focusing on: minimizing the cost of monitoring; minimizing topological ambiguity; maximizing the load monitoring; maximizing the amount of monitored extensions; minimizing the amount of Voltage Sags (VS) that are not monitored and maximizing the monitoring redundancy of the VS. A Multiobjective Evolutionary Algorithm with Tables (MEAT) was used to solve the problem. Results from the IEEE test systems showed that the MEAT provided the Pareto Fronts with diversified and well-distributed solutions, which made them relevant for planning monitoring systems for PQ in DS. The proposed model enables power companies to evaluate investments needed for continuous monitoring of PQ, ensuring greater flexibility in the monitoring plan and a better analysis of the cost/benefit ratio considering the six objectives presented. © 2017 Elsevier Ltd","Allocating monitors; Distribution systems; Multiobjective evolutionary algorithm with tables; Multiobjective optimization; Power quality","Cost benefit analysis; Electric load management; Electric utilities; Evolutionary algorithms; Investments; Multiobjective optimization; Optimization; Power quality; Continuous monitoring; Cost/benefit ratio; Distributed solutions; Distribution systems; IEEE test systems; Multi objective evolutionary algorithms; Power quality monitoring; Topological ambiguity; Monitoring",2-s2.0-85032812667
"Lujano-Rojas J.M., Zubi G., Dufo-López R., Bernal-Agustín J.L., Catalão J.P.S.","Novel probabilistic optimization model for lead-acid and vanadium redox flow batteries under real-time pricing programs",2018,"International Journal of Electrical Power and Energy Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032699626&doi=10.1016%2fj.ijepes.2017.10.037&partnerID=40&md5=83c943a40da8d4eade3697c05b7fb232","The integration of storage systems into smart grids is being widely analysed in order to increase the flexibility of the power system and its ability to accommodate a higher share of wind and solar power. The success of this process requires a comprehensive techno-economic study of the storage technology in contrast with electricity market behaviour. The focus of this work is on lead-acid and vanadium redox flow batteries. This paper presents a novel probabilistic optimization model for managing energy storage systems. The model is able to incorporate the forecasting error of electricity prices, offering with this a near-optimal control option. Using real data from the Spanish electricity market from the year 2016, the probability distribution of forecasting error is determined. The model determines electricity price uncertainty by means of Monte Carlo Simulation and includes it in the energy arbitrage problem, which is eventually solved by using an integer-coded genetic algorithm. In this way, the probability distribution of the revenue is determined with consideration of the complex behaviours of lead-acid and vanadium redox flow batteries as well as their associated operating devices such as power converters. © 2017 Elsevier Ltd","Genetic algorithm; Lead-acid battery; Real-time pricing; Smart grid; Vanadium redox flow battery","Commerce; Costs; Digital storage; Economics; Electric batteries; Electric energy storage; Electric industry; Electric power transmission networks; Forecasting; Genetic algorithms; Intelligent systems; Lead acid batteries; Monte Carlo methods; Optimization; Power markets; Probability distributions; Smart power grids; Solar energy; Energy storage systems; Integer coded genetic algorithms; Probabilistic optimization; Real time pricing; Smart grid; Spanish electricity markets; Techno-economic studies; Vanadium redox flow batteries; Flow batteries",2-s2.0-85032699626
"Chi Z., Liu H., Zang S.","Multi-objective optimization of the impingement-film cooling structure of a gas turbine endwall using conjugate heat transfer simulations",2018,"Journal of Thermal Science and Engineering Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028716810&doi=10.1115%2f1.4037131&partnerID=40&md5=898d61e8f1cf341d91fac17da8253f34","This paper discusses the approach of cooling design optimization of a high-pressure turbine (HPT) endwall with applied 3D conjugate heat transfer (CHT) computational fluid dynamics (CFD). This study involved the optimization of the spacing of impingement jet array and the exit width of shaped holes, which are different for each cooling cavity. The optimization objectives were to reduce the wall-temperature level and to increase the aerodynamic performance. The optimization methodology consisted of an in-house parametric design and CFD mesh generation tool, a CHT CFD solver, a database of CFD results, a metamodel, and an algorithm for multi-objective optimization. The CFD tool was validated against experimental data of an endwall at CHT conditions. The metamodel, which could efficiently estimate the optimization objectives of new individuals without CFD runs, was developed and coupled with nondominated sorting genetic algorithm II (NSGA II) to accelerate the optimization process. Through the optimization search, the Pareto front of the problem was found in each iteration. The accuracy of metamodel with more iterations was improved by enriching database. But optimal designs found by the last iteration are almost identical with those of the first iteration. Through analyzing extra CFD results, it was demonstrated that the design variables in the Pareto front successfully reached the optimal values. The optimal pitches of impingement arrays could be decided accommodating the local thermal load while avoiding jet lift-off of film coolant. It was also suggested that cylindrical film holes near throat should be beneficial to both aerodynamic and cooling performances. © 2018 by ASME.",,"Aerodynamics; Computational fluid dynamics; Cooling; Fighter aircraft; Gas turbines; Genetic algorithms; Heat transfer; Heating; Iterative methods; Mesh generation; Optimal systems; Optimization; Aero-dynamic performance; Conjugate heat transfer; Cooling performance; High pressure turbine; Impingement film cooling; Non dominated sorting genetic algorithm ii (NSGA II); Optimization methodology; Parametric design; Multiobjective optimization",2-s2.0-85028716810
"Ji Y., Lai L., Zhong S., Zhang L.","Bifurcation and chaos of a new discrete fractional-order logistic map",2018,"Communications in Nonlinear Science and Numerical Simulation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032034408&doi=10.1016%2fj.cnsns.2017.10.009&partnerID=40&md5=0ca8e42648823c06b3123ba5f5630358","The fractional-order discrete maps with chaotic behaviors based on the theory of “fractional difference” are proposed in recent years. In this paper, instead of using fractional difference, a new fractionalized logistic map is proposed based on the numerical algorithm of fractional differentiation definition. The bifurcation diagrams of this map with various differential orders are given by numerical simulation. The simulation results show that the fractional-order logistic map derived in this manner holds rich dynamical behaviors because of its memory effect. In addition, new types of behaviors of bifurcation and chaos are found, which are different from those of the integer-order and the previous fractional-order logistic maps. © 2017 Elsevier B.V.","Bifurcation; Chaos; Discrete fractional map; Logistic map","Chaos theory; Computer simulation; Numerical analysis; Bifurcation and chaos; Bifurcation diagram; Chaotic behaviors; Dynamical behaviors; Fractional differentiation; Fractional order; Logistic maps; Numerical algorithms; Bifurcation (mathematics)",2-s2.0-85032034408
"Antunes P.R.S., Mohammadi S.A., Voss H.","A nonlinear eigenvalue optimization problem: Optimal potential functions",2018,"Nonlinear Analysis: Real World Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031014227&doi=10.1016%2fj.nonrwa.2017.09.003&partnerID=40&md5=6def4c7415bd5152b1b1327a823a3024","In this paper we study the following optimal shape design problem: Given an open connected set Ω⊂RN and a positive number A∈(0,|Ω|), find a measurable subset D⊂Ω with |D|=A such that the minimal eigenvalue of −div(ζ(λ,x)∇u)+αχDu=λu in Ω, u=0 on ∂Ω, is as small as possible. This sort of nonlinear eigenvalue problems arises in the study of some quantum dots taking into account an electron effective mass. We establish the existence of a solution and we determine some qualitative aspects of the optimal configurations. For instance, we can get a nearly optimal set which is an approximation of the minimizer in ultra-high contrast regime. A numerical algorithm is proposed to obtain an approximate description of the optimizer. © 2017 Elsevier Ltd","Nonlinear eigenvalue problem; Quantum dots; Shape optimization; Ultra-high contrast regime","Nanocrystals; Optimization; Semiconductor quantum dots; Shape optimization; Switching systems; Approximate descriptions; Electron effective mass; Existence of a solutions; Nonlinear eigenvalue; Nonlinear eigenvalue problem; Numerical algorithms; Optimal shape design; Ultra-high; Eigenvalues and eigenfunctions",2-s2.0-85031014227
"Langdon A.J., Sharpe M.J., Schoenbaum G., Niv Y.","Model-based predictions for dopamine",2018,"Current Opinion in Neurobiology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032391927&doi=10.1016%2fj.conb.2017.10.006&partnerID=40&md5=9c7588434bfa4bf00efccac2603ae35d","Phasic dopamine responses are thought to encode a prediction-error signal consistent with model-free reinforcement learning theories. However, a number of recent findings highlight the influence of model-based computations on dopamine responses, and suggest that dopamine prediction errors reflect more dimensions of an expected outcome than scalar reward value. Here, we review a selection of these recent results and discuss the implications and complications of model-based predictions for computational theories of dopamine and learning. © 2017",,"dopamine; algorithm; analytical error; complete serial compound stimulus; computational theory; dopaminergic nerve cell; dopaminergic prediction; human; learning; model; nonhuman; prediction; prediction error; priority journal; Review; stimulus; temporal difference reinforcement learning; theory",2-s2.0-85032391927
"Wang X., Che M., Wei Y.","Partial orthogonal rank-one decomposition of complex symmetric tensors based on the Takagi factorization",2018,"Journal of Computational and Applied Mathematics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032723913&doi=10.1016%2fj.cam.2017.09.050&partnerID=40&md5=63682f86db239d2f28b27ff3e5cf5463","This paper is devoted to the computation of rank-one decomposition of complex symmetric tensors. Based on the Takagi factorization of complex symmetric matrices, we derive algorithm for computing the partial orthogonal rank-one decomposition of complex symmetric tensors with an order being a power of two, denoted by CSTPOROD. We consider the properties of this decomposition. We design a strategy (tensor embedding) to computing the partial orthogonal rank-one decomposition of complex symmetric tensors, whose order is not the power of two. Similar to the case of complex symmetric tensors, we consider how to compute the partial orthogonal rank-one decomposition of general complex tensors. We illustrate our algorithms via numerical examples. © 2017 Elsevier B.V.","Complex symmetric tensor; Complex tensor; Partial orthogonality; Rank-one decomposition; Takagi factorization; Tensor embedding","Factorization; Complex symmetric; Complex tensors; Orthogonality; Power-of-two; Takagi factorization; Tensors",2-s2.0-85032723913
"Lyu M., Liu T., Wang Z., Yan S., Jia X., Wang Y.","Orbit Response Recognition during Touchdowns by Instantaneous Frequency in Active Magnetic Bearings",2018,"Journal of Vibration and Acoustics, Transactions of the ASME",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030761161&doi=10.1115%2f1.4037850&partnerID=40&md5=e1b18ce005f9b1dad967d4bf8d1ee34e","During touchdowns of active magnetic bearings (AMB), the violent collision between rotors and touchdown bearings (TDB) can cause damages to both parts. Orbit response recognition provides a way for the AMB controller to automatically switch the control algorithm to actively suppress the rotor-TDB vibration and promptly relevitate the rotor during touchdowns. A novel method based on Hilbert transform (HT) is proposed to recognize the orbit responses (pendulum vibration, combined rub and bouncing, and full rub) in touchdowns. In this method, the rotor suspension status is monitored by the AMB controller in real-time. When touchdown is detected, the rotor displacement signal during the sampling period is intercepted, and the instantaneous frequency (IF) is calculated by HT. Then, the local variance of IF during the sampling period is calculated, and it is compared with the threshold value. Combined rub and bouncing can be identified for it has the largest local variance. Finally, the mean value of IF during the sampling period is calculated and is compared with the other threshold value. Pendulum vibration can be identified for it has a lower and fixed mean value, while full rub has a larger value. The principle of the recognition method is demonstrated by the simulated results of a thermodynamic model. The results reveal that the method is feasible in recognizing the orbit responses and can be implemented in the AMB controller to help switch the control algorithms automatically in case of touchdowns. © 2018 by ASME.","active magnetic bearing; Hilbert transform; instantaneous frequency; Orbit response recognition; touchdown bearing","Magnetic bearings; Magnetic disk storage; Magnetism; Mathematical transformations; Pendulums; Active Magnetic Bearing; Active magnetic bearings; Hilbert transform; Instantaneous frequency; Recognition methods; Rotor displacement; Simulated results; Thermodynamic model; Controllers",2-s2.0-85030761161
"Neville B.A., Forster S.C., Lawley T.D.","Commensal Koch's postulates: establishing causation in human microbiota research",2018,"Current Opinion in Microbiology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032723713&doi=10.1016%2fj.mib.2017.10.001&partnerID=40&md5=2ac632426b1f1ee3f95e34a6ae2a01b8","Advances in high-throughput sequencing technologies and the development of sophisticated bioinformatics analysis methods, algorithms, and pipelines to handle the large amounts of data generated have driven the field of human microbiome research forward. This specialist knowledge has been crucial to thoroughly mine the human gut microbiota, particularly in the absence of methods for the routine cultivation of most enteric microorganisms. In recent years, however, significant efforts have been made to address the ‘great plate count anomaly’ and to overcome the barriers to cultivation of the fastidious and mostly strictly anaerobic bacteria that reside in the human gut. As a result, many new species have been discovered, characterised, genome sequenced, and deposited in culture collections. These continually expanding resources enable experimental investigation of the human gut microbiota, validation of hypotheses made with sequence-based analyses, and phenotypic characterisation of its constituent microbes. Herein we propose a variant of Koch's postulates, aimed at providing a framework to establish causation in microbiome studies, with a particular focus on demonstrating the health-promoting role of the commensal gut microbiota. © 2017 The Authors",,"commensal; human; intestine flora; new species; nonhuman; validation process",2-s2.0-85032723713
"Ezz-Eldien S.S., Doha E.H., Bhrawy A.H., El-Kalaawy A.A., Machado J.A.T.","A new operational approach for solving fractional variational problems depending on indefinite integrals",2018,"Communications in Nonlinear Science and Numerical Simulation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030701382&doi=10.1016%2fj.cnsns.2017.08.026&partnerID=40&md5=261ae19003490415da364c95bd0afa41","In this paper, we propose a new accurate and robust numerical technique to approximate the solutions of fractional variational problems (FVPs) depending on indefinite integrals with a type of fixed Riemann–Liouville fractional integral. The proposed technique is based on the shifted Chebyshev polynomials as basis functions for the fractional integral operational matrix (FIOM). Together with the Lagrange multiplier method, these problems are then reduced to a system of algebraic equations, which greatly simplifies the solution process. Numerical examples are carried out to confirm the accuracy, efficiency and applicability of the proposed algorithm © 2017 Elsevier B.V.","Caputo derivatives; Chebyshev polynomials; Fractional variational problems; Lagrange multipliers method; Operational matrix; Riemann–Liouville integrals","Algebra; Lagrange multipliers; Matrix algebra; Polynomials; Variational techniques; Caputo derivatives; Chebyshev polynomials; Lagrange multipliers method; Liouville; Operational matrices; Variational problems; Problem solving",2-s2.0-85030701382
"Varga L.K., Kovac J.","Decomposing the permeability spectra of nanocrystalline finemet core",2018,"AIP Advances",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031943597&doi=10.1063%2f1.4991941&partnerID=40&md5=303ed32209180ea1062e3a9508b36172","In this paper we present a theoretical and experimental investigation on the magnetization contributions to permeability spectra of normal annealed Finemet core with round type hysteresis curve. Real and imaginary parts of the permeability were determined as a function of exciting magnetic field (HAC) between 40 Hz -110 MHz using an Agilent 4294A type Precision Impedance Analyzer. The amplitude of the exciting field was below and around the coercive field of the sample. The spectra were decomposed using the Levenberg-Marquardt algorithm running under Origin 9 software in four contributions: i) eddy current; ii) Debye relaxation of magnetization rotation, iii) Debye relaxation of damped domain wall motion and iv) resonant type DW motion. For small exciting amplitudes the first two components dominate. The last two contributions connected to the DW appear for relative large HAC only, around the coercive force. All the contributions will be discussed in detail accentuating the role of eddy current that is not negligible even for the smallest applied exciting field. © 2017 Author(s).",,,2-s2.0-85031943597
"Liu S., Yang B.","Optimal Vibration Reduction of Flexible Rotor Systems by the Virtual Bearing Method",2018,"Journal of Vibration and Acoustics, Transactions of the ASME",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031020947&doi=10.1115%2f1.4037956&partnerID=40&md5=af872ff07c280f4f9d335a3e308fad37","This paper presents a new approach to optimal bearing placement that minimizes the vibration amplitude of a flexible rotor system with a minimum number of bearings. The thrust of the effort is the introduction of a virtual bearing method (VBM), by which a minimum number of bearings can be automatically determined in a rotor design without trial and error. This unique method is useful in dealing with the issue of undetermined number of bearings. In the development, the VBM and a distributed transfer function method (DTFM) for closed-form analytical solutions are integrated to formulate an optimization problem of mixed continuous-and-integer type, in which bearing locations and bearing index numbers (BINs) (specially defined integer variables representing the sizes and properties of all available bearings) are selected as design variables. Solution of the optimization problem by a real-coded genetic algorithm yields an optimal design that satisfies all the rotor design requirements with a minimum number of bearings. Filling a technical gap in the literature, the proposed optimal bearing placement approach is applicable to either redesign of an existing rotor system for improvement of system performance or preliminary design of a new rotor system with the number of bearings to be installed being unforeknown. © 2018 by ASME.",,,2-s2.0-85031020947
"Dourado D.M., Ferreira R.J.L., de Lacerda Rocha M., Duarte U.R.","Energy consumption and bandwidth allocation in passive optical networks",2018,"Optical Switching and Networking",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032588904&doi=10.1016%2fj.osn.2017.10.004&partnerID=40&md5=fc7a98507693e39464a35c4dc2524a58","A compromise between the energy consumption, at the central office (CO), and the maximum bandwidth capacity, offered to end users of passive optical networks (PON), is demonstrated. Four classes of PON are considered: two are based on consolidated technologies (GPON and XG-PON), and the others are the emerging TWDM-PON and OFDM-PON. By means of the proposed algorithm, we evaluate the distribution of users in a Manhattan topology model regarding power consumption and quality of service (QoS) in two scenarios: 1) fixed split ratio and; 2) flexible power division. According to the results in the first scenario, it is possible to provide bit rates up to 178.1 Mb/s per user, for GPON, and 713.6 Mb/s per user, for XG-PON, without affecting the QoS even in a high activity network. The second scenario explores “where” and “when” network operators should migrate to higher capacity technologies (when providing bit rates up to 1 Gb/s per user) by means of deployment of TWDM-PON and/or OFDM-PON, while keeping a QoS above 20%. © 2017 Elsevier B.V.","Bandwidth allocation; Energy consumption; Passive optical network; Quality of service","Bandwidth; Energy utilization; Frequency allocation; Orthogonal frequency division multiplexing; Passive networks; Quality of service; Topology; Voltage dividers; Bandwidth capacity; Central offices; High activity; Manhattans; Network operator; Power division; Split ratio; Topology model; Passive optical networks",2-s2.0-85032588904
"Yen C.-F., Sivasankar S.","Improving estimation of kinetic parameters in dynamic force spectroscopy using cluster analysis",2018,"Journal of Chemical Physics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029885213&doi=10.1063%2f1.5001325&partnerID=40&md5=2b75c03c2b1c53e7a94ad4c6a4a41065","Dynamic Force Spectroscopy (DFS) is a widely used technique to characterize the dissociation kinetics and interaction energy landscape of receptor-ligand complexes with single-molecule resolution. In an Atomic Force Microscope (AFM)-based DFS experiment, receptor-ligand complexes, sandwiched between an AFM tip and substrate, are ruptured at different stress rates by varying the speed at which the AFM-tip and substrate are pulled away from each other. The rupture events are grouped according to their pulling speeds, and the mean force and loading rate of each group are calculated. These data are subsequently fit to established models, and energy landscape parameters such as the intrinsic off-rate (koff) and the width of the potential energy barrier (xβ) are extracted. However, due to large uncertainties in determining mean forces and loading rates of the groups, errors in the estimated koff and xβ can be substantial. Here, we demonstrate that the accuracy of fitted parameters in a DFS experiment can be dramatically improved by sorting rupture events into groups using cluster analysis instead of sorting them according to their pulling speeds. We test different clustering algorithms including Gaussian mixture, logistic regression, and K-means clustering, under conditions that closely mimic DFS experiments. Using Monte Carlo simulations, we benchmark the performance of these clustering algorithms over a wide range of koff and xβ, under different levels of thermal noise, and as a function of both the number of unbinding events and the number of pulling speeds. Our results demonstrate that cluster analysis, particularly K-means clustering, is very effective in improving the accuracy of parameter estimation, particularly when the number of unbinding events are limited and not well separated into distinct groups. Cluster analysis is easy to implement, and our performance benchmarks serve as a guide in choosing an appropriate method for DFS data analysis. © 2018 Author(s).",,"Atomic force microscopy; Benchmarking; Cluster analysis; Clustering algorithms; Complexation; Intelligent systems; Ligands; Monte Carlo methods; Nanoprobes; Potential energy; Sorting; Thermal noise; Uncertainty analysis; Accuracy of parameters; Dissociation kinetics; Dynamic force spectroscopy; Interaction energies; K-means clustering; Logistic regressions; Receptor-ligand complex; Single-molecule resolution; Parameter estimation",2-s2.0-85029885213
"Ahmadi E., Jasemi M., Monplaisir L., Nabavi M.A., Mahmoodi A., Amini Jam P.","New efficient hybrid candlestick technical analysis model for stock market timing on the basis of the Support Vector Machine and Heuristic Algorithms of Imperialist Competition and Genetic",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032185013&doi=10.1016%2fj.eswa.2017.10.023&partnerID=40&md5=a26bb21364fec92f2f991c613efe674c","In this paper, two hybrid models are used for timing of the stock markets on the basis of the technical analysis of Japanese Candlestick by Support Vector Machine (SVM) and Heuristic Algorithms of Imperialist Competition and Genetic. In the first model, SVM and Imperialist Competition Algorithm (ICA) are developed for stock market timing in which ICA is used to optimize the SVM parameters. In the second model, SVM is used with Genetic Algorithm (GA) where GA is used for feature selection in addition to SVM parameters optimization. Here the two approaches, Raw-based and Signal-based are devised on the basis of the literature to generate the input data of the model. For a comparison, the Hit Rate is considered as the percentage of correct predictions for periods of 1–6 day. The results show that SVM-ICA performance is better than SVM-GA and most importantly the feed-forward static neural network of the literature as the standard one. © 2017 Elsevier Ltd","Candlestick technical analysis; Finance; Genetic Algorithm; Imperialist Competition Algorithm; Stock market forecasting; Support Vector Machine","Commerce; Electronic trading; Finance; Financial markets; Genetic algorithms; Heuristic algorithms; Optimization; Parameter estimation; Timing circuits; Feed forward; Hybrid model; Japanese candlesticks; Parameters optimization; Static neural networks; Stock market forecasting; Stock market timings; Technical analysis; Support vector machines",2-s2.0-85032185013
"Fernandez-Viagas V., Valente J.M.S., Framinan J.M.","Iterated-greedy-based algorithms with beam search initialization for the permutation flowshop to minimise total tardiness",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032366192&doi=10.1016%2fj.eswa.2017.10.050&partnerID=40&md5=185ba1c5998d2f6e942e1ca40b16c09d","The permutation flow shop scheduling problem is one of the most studied operations research related problems. Literally, hundreds of exact and approximate algorithms have been proposed to optimise several objective functions. In this paper we address the total tardiness criterion, which is aimed towards the satisfaction of customers in a make-to-order scenario. Although several approximate algorithms have been proposed for this problem in the literature, recent contributions for related problems suggest that there is room for improving the current available algorithms. Thus, our contribution is twofold: First, we propose a fast beam-search-based constructive heuristic that estimates the quality of partial sequences without a complete evaluation of their objective function. Second, using this constructive heuristic as initial solution, eight variations of an iterated-greedy-based algorithm are proposed. A comprehensive computational evaluation is performed to establish the efficiency of our proposals against the existing heuristics and metaheuristics for the problem. © 2017 Elsevier Ltd","Beam search; Flowshop; Heuristics; Iterated greedy algorithm; Iterated local search; PFSP; Scheduling; Tardiness","Customer satisfaction; Function evaluation; Operations research; Scheduling; Beam search; Flow-shops; Heuristics; Iterated greedy algorithm; Iterated local search; PFSP; Tardiness; Quality control",2-s2.0-85032366192
"Abu-Aisheh Z., Raveaux R., Ramel J.-Y., Martineau P.","A parallel graph edit distance algorithm",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032512961&doi=10.1016%2fj.eswa.2017.10.043&partnerID=40&md5=e0955d97039a6d8c020baa630dfa70fc","Graph edit distance (GED) has emerged as a powerful and flexible graph matching paradigm that can be used to address different tasks in pattern recognition, machine learning, and data mining. GED is an error-tolerant graph matching problem which consists in minimizing the cost of the sequence that transforms a graph into another by means of edit operations. Edit operations are deletion, insertion and substitution of vertices and edges. Each vertex/edge operation has its associated cost defined in the vertex/edge cost function. Unfortunately, Unfortunately, the GED problem is NP-hard. The question of elaborating fast and precise algorithms is of first interest. In this paper, a parallel algorithm for exact GED computation is proposed. Our proposal is based on a branch-and-bound algorithm coupled with a load balancing strategy. Parallel threads run a branch-and-bound algorithm to explore the solution space and to discard misleading partial solutions. In the mean time, the load balancing scheme ensures that no thread remains idle. Experiments on 4 publicly available datasets empirically demonstrated that under time constraints our proposal can drastically improve a sequential approach and a naive parallel approach. Our proposal was compared to 6 other methods and provided more precise solutions while requiring a low memory usage. © 2017 Elsevier Ltd","Graph edit distance; Graph matching; Load balancing; Parallel computing; Pattern recognition","Branch and bound method; Cost functions; Costs; Data mining; Learning systems; Parallel processing systems; Pattern recognition; Resource allocation; Branch-and-bound algorithms; Error-tolerant graph matching; Graph edit distance; Graph matchings; Load balancing strategy; Load-balancing schemes; Precise solutions; Sequential approach; Pattern matching",2-s2.0-85032512961
"Ahmadinia M., Safari Z.","Numerical solution of singularly perturbed boundary value problems by improved least squares method",2018,"Journal of Computational and Applied Mathematics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032298586&doi=10.1016%2fj.cam.2017.09.023&partnerID=40&md5=26fb5ecec60bac1b6099646e7fa59536","This paper introduces a numerical method based on least squares method for solving singularly perturbed differential equations with two-point boundary conditions. Moreover, an intelligent algorithm is proposed to improve the method. This algorithm is essential as it finds the unknown location of the layer (boundary layer and interior layer). As part of evaluation, the convergence analysis of the method is presented. Numerical examples demonstrate the superconvergence of the intelligent algorithm and confirm the accuracy of the theory. © 2017 Elsevier B.V.","B-splines; Boundary value problems; Least squares method; Singular perturbed differential equations","Boundary conditions; Boundary layers; Boundary value problems; Differential equations; Numerical methods; Perturbation techniques; B splines; Convergence analysis; Intelligent Algorithms; Least squares methods; Numerical solution; Singularly perturbed; Singularly perturbed boundary value problems; Two point boundary conditions; Least squares approximations",2-s2.0-85032298586
"Bylina B.","The block WZ factorization",2018,"Journal of Computational and Applied Mathematics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032279337&doi=10.1016%2fj.cam.2017.10.004&partnerID=40&md5=f1167d8932021c077bb29f9c5625e266","In the paper the author presents a novel kind of the WZ factorization algorithm, namely a block WZ factorization algorithm. The aim of this new algorithm is to utilize the computational power of contemporary computers with hierarchical memory. In the paper, some properties of the matrix Z are given and analyzed. Next, a version of the block WZ factorization is presented. The author shows that such a block WZ factorization exists for strictly diagonally dominant matrices. The computational cost of this block algorithm is presented. The time and the accuracy of proposed block WZ factorization algorithm for random dense square diagonally dominant matrices are reported. The block algorithm turned out to be faster even up to 300 times than the original WZ factorization. © 2017 Elsevier B.V.","Block algorithm; Memory hierarchy; Quadrant interlocking factorization; Solution of linear systems; WZ factorization","Factorization; Linear systems; Block algorithm; Memory hierarchy; Quadrant interlocking factorizations; Solution of linear systems; WZ factorization; Matrix algebra",2-s2.0-85032279337
"Grassi S., Casiraghi E., Alamprese C.","Handheld NIR device: A non-targeted approach to assess authenticity of fish fillets and patties",2018,"Food Chemistry",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030702957&doi=10.1016%2fj.foodchem.2017.09.145&partnerID=40&md5=8fcbac8adf45b5fefc644268c215c602","This study evaluates the reliability of a handheld NIR device in distinguishing fillets and patties of Atlantic cod (n = 80) from those of haddock (n = 90), in comparison with a FT-NIR benchtop spectrometer. The authentication issue was faced by Linear Discriminant Analysis (LDA) and Soft Independent Modelling of Class Analogy (SIMCA), pre-treating spectral data with different algorithms, and validating models both internally and externally. The best LDA models gave 100% correct classification in prediction. Sensitivity >65% and specificity >74% in prediction were calculated for the best SIMCA models. No significant differences (P >.05) were found between the two instruments by McNemar test. Thus, the work demonstrated that a handheld NIR device can be a simple, cost-effective, and reliable alternative to benchtop spectrometers in fish fillet and patty authentication. These important findings can help in improving commercial fraud fight, extending the possibility to authenticate fish species also in processed products. © 2017 Elsevier Ltd","Atlantic cod; Fish authentication; Haddock; Near infrared spectroscopy; Portable device","Authentication; Cost effectiveness; Discriminant analysis; Fish; Near infrared spectroscopy; Spectrometers; Water analysis; Atlantic cod; Bench-top spectrometers; Cost effective; Haddock; Linear discriminant analysis; Portable device; Processed products; Spectral data; Infrared devices",2-s2.0-85030702957
"Shi C., Qian J., Han S., Fan B., Yang X., Wu X.","Developing a machine vision system for simultaneous prediction of freshness indicators based on tilapia (Oreochromis niloticus) pupil and gill color during storage at 4 °C",2018,"Food Chemistry",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030177781&doi=10.1016%2fj.foodchem.2017.09.047&partnerID=40&md5=f543e8bfc09241ec5f00e97cda53da58","The study assessed the feasibility of developing a machine vision system based on pupil and gill color changes in tilapia for simultaneous prediction of total volatile basic nitrogen (TVB-N), thiobarbituric acid (TBA) and total viable counts (TVC) during storage at 4 °C. The pupils and gills were chosen and color space conversion among RGB, HSI and L∗a∗b∗ color spaces was performed automatically by an image processing algorithm. Multiple regression models were established by correlating pupil and gill color parameters with TVB-N, TVC and TBA (R2 = 0.989–0.999). However, assessment of freshness based on gill color is destructive and time-consuming because gill cover must be removed before images are captured. Finally, visualization maps of spoilage based on pupil color were achieved using image algorithms. The results show that assessment of tilapia pupil color parameters using machine vision can be used as a low-cost, on-line method for predicting freshness during 4 °C storage. © 2017 Elsevier Ltd","Chilled storage; Color parameters; Freshness indicators; Machine vision; Pupil and gill; Tilapia","Color; Food storage; Forecasting; Image processing; Machinery; Regression analysis; Chilled storage; Color parameter; Freshness indicators; Pupil and gill; Tilapia; Computer vision; gill; machine; nonhuman; Oreochromis niloticus; prediction; storage; vision",2-s2.0-85030177781
"Niu J., Xu M., Lin Y., Xue Q.","Numerical solution of nonlinear singular boundary value problems",2018,"Journal of Computational and Applied Mathematics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031489852&doi=10.1016%2fj.cam.2017.09.040&partnerID=40&md5=779e110869e9b54a7e52d4da568ed1c8","In this paper, an efficient method based on the simplified reproducing kernel method (SRKM) and least squares method (LSM) is proposed for solving nonlinear singular boundary value problems. The algorithm consists of two steps. First, we apply SRKM to solve a linear equation which contains a set of parameters, second the LSM is used to find the optimal parameters. Error estimation and convergence order for the presented method are also discussed. Our numerical experiments validate our theoretical findings and demonstrate the performance of the algorithm in terms of simplicity, accuracy, and efficiency. © 2017 Elsevier B.V.","Convergence order; Error analysis; Least squares method; Nonlinear singular boundary value problem; Simplified reproducing kernel method","Boundary value problems; Error analysis; Convergence order; Least squares methods; Numerical experiments; Numerical solution; Optimal parameter; Reproducing kernel methods; Singular boundary value problems; Least squares approximations",2-s2.0-85031489852
"He F., Mao T., Hu T., Shu L.","A new type of change-detection scheme based on the window-limited weighted likelihood ratios",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032656379&doi=10.1016%2fj.eswa.2017.10.051&partnerID=40&md5=b7dcffc6d0058d1b3ce6911872ea5632","Process monitoring has been widely recognized as an important and critical tool in system monitoring for detection of abnormal behavior and quality improvement. In manufacturing processes or industrial systems, several sources of out-of-control variation, such as tool wear, gradual equipment deterioration, vibration, inconsistent material etc., often result in dynamic changes in the process parameter, or result in special residual signals of the systems. Detecting such weak or decaying signals is a challenging task. Although the window-limited generalized likelihood ratio (wl-GLR) scheme is widely used in changepoint detection and has some advantages, it may perform poorly when it is used to detect weak or decaying signals. This paper proposes a new change-detection scheme, the window-limited weighted likelihood ratio (wl-WLR) scheme, to improve the wl-GLR scheme. To do this, a new statistical distance measure called the GLR divergence is first defined and then its properties are analyzed. The wl-WLR scheme is designed to monitor the weighted average of the GLR divergences in a moving window, and the wl-GLR scheme can be viewed as a special case of the wl-WLR scheme. Two types of weight functionals are introduced and investigated for the wl-WLR scheme. Numerical algorithms to select the optimal weight parameters are provided based on a calibration sample. Extensive simulation study favors the proposed wl-WLR scheme for detecting weak or decaying signals, and its performance is robust even if the weight parameters are not accurately estimated. This paper has online supplementary materials. © 2017 Elsevier Ltd","Generalized likelihood ratio; Signal detection; Statistical distance; Statistical process control; Stochastic order; Weighted likelihood ratio","Parameter estimation; Process control; Process monitoring; Statistical process control; Stochastic systems; Change point detection; Extensive simulations; Generalized likelihood ratio; Likelihood ratios; Manufacturing process; Online supplementary material; Statistical distance; Stochastic order; Signal detection",2-s2.0-85032656379
"Yu Z., Zhang W.","Forts of quadratic polynomials under iteration",2018,"Journal of Computational and Applied Mathematics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031033072&doi=10.1016%2fj.cam.2017.09.008&partnerID=40&md5=ef1f143cb66520d3364ef17e7fb134c2","Since some dynamical behaviors of a one-dimensional mapping are influenced by the number of forts, attention is paid to the change of the number under iteration. For simple computation we work on quadratic polynomials. We use the theory of polynomial complete discrimination system to give a symbolic algorithm for the number of forts of iterated polynomials and apply the algorithm to quadratic functions, which proves an alternative result that the number either persists to be 1 or tends to infinity under iteration. We further compute the number for iterates of order 2,3,…,7 in the above infinity case and obtain critical values of the parameter at which the number changes. Those changes with finitely many data display a conjectured Fibonacci rule. © 2017 Elsevier B.V.","Complete discrimination system; Fibonacci sequence; Forts; Iteration; Quadratic polynomial","Computation theory; Polynomials; Complete discrimination system; Fibonacci sequences; Forts; Iteration; Quadratic polynomial; Iterative methods",2-s2.0-85031033072
"Grasegger G., Lastra A., Sendra J.R., Winkler F.","Rational general solutions of systems of first-order algebraic partial differential equations",2018,"Journal of Computational and Applied Mathematics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032277176&doi=10.1016%2fj.cam.2017.10.010&partnerID=40&md5=565e3d953b095f4877d607dcbfdf9580","We study the rational solutions of systems of first-order algebraic partial differential equations and relate them to those of an associated autonomous system. We also describe how rational general solutions of these systems are related, and provide an algorithm in some particular case concerning the dimension of the associated algebraic variety. Our results can be considered as a generalization of the approach by L. X. C. Ngô and F. Winkler on algebraic ordinary differential equations of order one, adapted to systems of first-order algebraic partial differential equations. © 2017 Elsevier B.V.","Algebraic partial differential equation; Exact computation; Rational general solution","Algebra; Partial differential equations; Algebraic varieties; Autonomous systems; Exact computations; First order; Rational general solution; Rational solution; Winkler; Ordinary differential equations",2-s2.0-85032277176
"Gu X.-M., Huang T.-Z., Yin G., Carpentieri B., Wen C., Du L.","Restarted Hessenberg method for solving shifted nonsymmetric linear systems",2018,"Journal of Computational and Applied Mathematics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032297612&doi=10.1016%2fj.cam.2017.09.047&partnerID=40&md5=10770f357d54eab1b040339232d28b60","It is known that the restarted full orthogonalization method (FOM) outperforms the restarted generalized minimum residual (GMRES) method in several circumstances for solving shifted linear systems when the shifts are handled simultaneously. Many variants of them have been proposed to enhance their performance. We show that another restarted method, the restarted Hessenberg method (Heyouni, 1996) based on Hessenberg procedure, can effectively be employed, which can provide accelerating convergence rate with respect to the number of restarts. Theoretical analysis shows that the new residual of shifted restarted Hessenberg method is still collinear with each other. In these cases where the proposed algorithm needs less enough elapsed CPU time to converge than the earlier established restarted shifted FOM, the weighted restarted shifted FOM, and some other popular shifted iterative solvers based on the short-term vector recurrence, as shown via extensive numerical experiments involving the recently popular application of handling time fractional differential equations. © 2017 Elsevier B.V.","Collinear; Fractional differential equations; Hessenberg process; Pivoting strategy; Restarted Hessenberg method; Shifted linear system","Differential equations; Linear systems; Collinear; Fractional differential equations; Pivoting strategy; Restarted Hessenberg method; Shifted linear systems; Iterative methods",2-s2.0-85032297612
"Marcuzzi F.","Linear estimation of physical parameters with subsampled and delayed data",2018,"Journal of Computational and Applied Mathematics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031712871&doi=10.1016%2fj.cam.2017.09.036&partnerID=40&md5=f8fb21a4de235abfc61adfd9243c75bb","An improved algorithm for the estimation of physical parameters with sub-sampled and delayed data is here presented. It shows a much better accuracy than the state-of-the-art when the sampling time of data acquisition Ts is much higher than the discretization step Tsc that should be used to get a highly accurate discrete model, i.e. Ts≫Tsc, which is a common situation in multi-body and finite-element modelling applications. Moreover, the method proposed is capable of compensating delays between different acquisition channels. For the numerical experiments we focus on a mainstream class of models in applied mechanics, i.e. linear elasto-dynamics. © 2017 Elsevier B.V.","Continuous-time models; Elasto-dynamics; Parameter estimation; State-space models; System identification","Continuous time systems; Data acquisition; Error analysis; Finite element method; Identification (control systems); State space methods; Acquisition channels; Continuous time models; Elasto-dynamics; Finite element modelling; Linear estimation; Numerical experiments; Physical parameters; State - space models; Parameter estimation",2-s2.0-85031712871
"Smedarchina Z., Siebrand W., Fernández-Ramos A.","Entanglement and co-tunneling of two equivalent protons in hydrogen bond pairs",2018,"Journal of Chemical Physics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029513992&doi=10.1063%2f1.5000681&partnerID=40&md5=ebc437aed6e6916ba2fff47e012527cb","A theoretical study is reported of a system of two identical symmetric hydrogen bonds, weakly coupled such that the two mobile protons can move either separately (stepwise) or together (concerted). It is modeled by two equivalent quartic potentials interacting through dipolar and quadrupolar coupling terms. The tunneling Hamiltonian has two imaginary modes (reaction coordinates) and a potential with a single maximum that may turn into a saddle-point of second order and two sets of (inequivalent) minima. Diagonalization is achieved via a modified Jacobi-Davidson algorithm. From this Hamiltonian the mechanism of proton transfer is derived. To find out whether the two protons move stepwise or concerted, a new tool is introduced, based on the distribution of the probability flux in the dividing plane of the transfer mode. While stepwise transfer dominates for very weak coupling, it is found that concerted transfer (co-tunneling) always occurs, even when the coupling vanishes since the symmetry of the Hamiltonian imposes permanent entanglement on the motions of the two protons. We quantify this entanglement and show that, for a wide range of parameters of interest, the lowest pair of states of the Hamiltonian represents a perfect example of highly entangled quantum states in continuous variables. The method is applied to the molecule porphycene for which the observed tunneling splitting is calculated in satisfactory agreement with experiment, and the mechanism of double-proton tunneling is found to be predominantly concerted. We show that, under normal conditions, when they are in the ground state, the two porphycene protons are highly entangled, which may have interesting applications. The treatment also identifies the conditions under which such a system can be handled by conventional one-instanton techniques. © 2018 Author(s).",,"Ground state; Hamiltonians; Hydrogen bonds; Probability distributions; Quantum theory; Continuous variables; Jacobi-Davidson algorithm; Probability flux; Quadrupolar coupling; Reaction coordinates; Theoretical study; Tunneling Hamiltonian; Tunneling splittings; Quantum entanglement",2-s2.0-85029513992
"Tempelaar R., Reichman D.R.","Generalization of fewest-switches surface hopping for coherences",2018,"Journal of Chemical Physics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031690344&doi=10.1063%2f1.5000843&partnerID=40&md5=56d0947200d022707647491745c19574","Fewest-switches surface hopping (FSSH) is perhaps the most widely used mixed quantum-classical approach for the modeling of non-adiabatic processes, but its original formulation is restricted to (adiabatic) population terms of the quantum density matrix, leaving its implementations with an inconsistency in the treatment of populations and coherences. In this article, we propose a generalization of FSSH that treats both coherence and population terms on equal footing and which formally reduces to the conventional FSSH algorithm for the case of populations. This approach, coherent fewest-switches surface hopping (C-FSSH), employs a decoupling of population relaxation and pure dephasing and involves two replicas of the classical trajectories interacting with two active surfaces. Through extensive benchmark calculations of a spin-boson model involving a Debye spectral density, we demonstrate the potential of C-FSSH to deliver highly accurate results for a large region of parameter space. Its uniform description of populations and coherences is found to resolve incorrect behavior observed for conventional FSSH in various cases, in particular at low temperature, while the parameter space regions where it breaks down are shown to be quite limited. Its computational expenses are virtually identical to conventional FSSH. © 2018 Author(s).",,"Spectral density; Benchmark calculations; Classical trajectories; Computational expense; Low temperatures; Non-adiabatic process; Population relaxation; Quantum-classical; Spin boson models; Temperature",2-s2.0-85031690344
"Xu S., de Lamare R.C., Vincent Poor H.","Distributed low-rank adaptive estimation algorithms based on alternating optimization",2018,"Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030476051&doi=10.1016%2fj.sigpro.2017.09.023&partnerID=40&md5=5b2049f63e5b1640e0bb156b41fb71ad","This paper presents a novel distributed low-rank scheme and adaptive algorithms for distributed estimation over wireless networks. The proposed distributed scheme is based on a transformation that performs dimensionality reduction at each agent of the network followed by transmission of a reduced set of parameters to other agents and reduced-dimension parameter estimation. Distributed low-rank joint iterative estimation algorithms based on alternating optimization strategies are developed, which can achieve significantly reduced communication overhead and improved performance when compared with existing techniques. A computational complexity analysis of the proposed and existing low-rank algorithms is presented along with an analysis of the convergence of the proposed techniques. Simulations illustrate the performance of the proposed strategies in applications of wireless sensor networks and smart grids. © 2017","Dimensionality reduction; Distributed estimation techniques; Low-rank algorithms; Smart grids; Wireless sensor networks","Adaptive algorithms; Electric power transmission networks; Iterative methods; Optimization; Smart power grids; Adaptive estimation algorithms; Alternating optimizations; Communication overheads; Computational complexity analysis; Dimensionality reduction; Distributed estimation; Rank algorithms; Smart grid; Wireless sensor networks",2-s2.0-85030476051
"Nakisa B., Rastgoo M.N., Tjondronegoro D., Chandran V.","Evolutionary computation algorithms for feature selection of EEG-based emotion recognition using mobile sensors",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031494000&doi=10.1016%2fj.eswa.2017.09.062&partnerID=40&md5=fe84140c13a8891a193cc7c4b2442830","There is currently no standard or widely accepted subset of features to effectively classify different emotions based on electroencephalogram (EEG) signals. While combining all possible EEG features may improve the classification performance, it can lead to high dimensionality and worse performance due to redundancy and inefficiency. To solve the high-dimensionality problem, this paper proposes a new framework to automatically search for the optimal subset of EEG features using evolutionary computation (EC) algorithms. The proposed framework has been extensively evaluated using two public datasets (MAHNOB, DEAP) and a new dataset acquired with a mobile EEG sensor. The results confirm that EC algorithms can effectively support feature selection to identify the best EEG features and the best channels to maximize performance over a four-quadrant emotion classification problem. These findings are significant for informing future development of EEG-based emotion classification because low-cost mobile EEG sensors with fewer electrodes are becoming popular for many new applications. © 2017","EEG signals; Emotion classification; Evolutionary computation algorithms; Feature selection","Calculations; Electroencephalography; Evolutionary algorithms; Feature extraction; Classification performance; EEG signals; Electroencephalogram signals; Emotion classification; Emotion recognition; High dimensionality; New applications; Optimal subsets; Classification (of information)",2-s2.0-85031494000
"Martín-Vaquero J., Queiruga-Dios A., Martín del Rey A., Encinas A.H., Hernández Guillén J.D., Rodríguez Sánchez G.","Variable step length algorithms with high-order extrapolated non-standard finite difference schemes for a SEIR model",2018,"Journal of Computational and Applied Mathematics",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018811767&doi=10.1016%2fj.cam.2017.03.031&partnerID=40&md5=e9919733d2f70e3fa9eb88acf4abfe2f","In the present manuscript, higher-order methods are derived to solve a SEIR model for malware propagation. They are obtained using extrapolation techniques combined with nonstandard finite difference (NSFD) schemes used in Jansen and Twizell (2002). Thus, the new algorithms are more efficient computationally, and are dynamically consistent with the continuous model. Later, different procedures are considered to control the error in the discrete schemes. Numerical experiments are provided to illustrate the theory, and for the comparison of the different strategies in the adaptation of the variable step length. © 2017 Elsevier B.V.","Extrapolation techniques; Malware propagation; Nonstandard finite difference schemes; SEIR model; Variable step-length algorithms","Computer crime; Dielectric waveguides; Extrapolation; Malware; Molecular physics; Extrapolation techniques; Malware propagation; Nonstandard finite difference schemes; Seir models; Variable step; Finite difference method",2-s2.0-85018811767
"Gustavson R., Ovchinnikov A., Pogudin G.","New order bounds in differential elimination algorithms",2018,"Journal of Symbolic Computation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025832201&doi=10.1016%2fj.jsc.2017.07.006&partnerID=40&md5=cb4dd1b8dbc98b2df9b9e1e21c87c214","We present a new upper bound for the orders of derivatives in the Rosenfeld–Gröbner algorithm under weighted rankings. This algorithm computes a regular decomposition of a radical differential ideal in the ring of differential polynomials over a differential field of characteristic zero with an arbitrary number of commuting derivations. This decomposition can then be used to test for membership in the given radical differential ideal. In particular, this algorithm allows us to determine whether a system of polynomial PDEs is consistent. In the case of one derivation, such a bound was given by Golubitsky et al. (2008). The only known bound in the case of several derivations was given by the authors of the present paper in 2016. The bound was achieved by associating to the algorithm antichain sequences whose lengths can be bounded using the results of León Sánchez and Ovchinnikov (2016). In the present paper, the above result by the current authors is generalized and significantly improved. © 2017 Elsevier Ltd","Computational complexity; Differential elimination algorithms; Polynomial differential equations",,2-s2.0-85025832201
"Salcedo-Sanz S., Aybar-Ruíz A., Camacho-Gómez C., Pereira E.","Efficient fractal-based mutation in evolutionary algorithms from iterated function systems",2018,"Communications in Nonlinear Science and Numerical Simulation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029166917&doi=10.1016%2fj.cnsns.2017.08.010&partnerID=40&md5=97e50b1d5a444be14e301f2ce144a9e4","In this paper we present a new mutation procedure for Evolutionary Programming (EP) approaches, based on Iterated Function Systems (IFSs). The new mutation procedure proposed consists of considering a set of IFS which are able to generate fractal structures in a two-dimensional phase space, and use them to modify a current individual of the EP algorithm, instead of using random numbers from different probability density functions. We test this new proposal in a set of benchmark functions for continuous optimization problems. In this case, we compare the proposed mutation against classical Evolutionary Programming approaches, with mutations based on Gaussian, Cauchy and chaotic maps. We also include a discussion on the IFS-based mutation in a real application of Tuned Mass Dumper (TMD) location and optimization for vibration cancellation in buildings. In both practical cases, the proposed EP with the IFS-based mutation obtained extremely competitive results compared to alternative classical mutation operators. © 2017 Elsevier B.V.","Evolutionary programming; Fractals; Iterated function systems; Mutation procedures design","Chaotic systems; Computer programming; Fractals; Optimization; Phase space methods; Probability density function; Random number generation; Benchmark functions; Continuous optimization problems; Evolutionary programming approach; Fractal structures; Iterated function system; Mutation operators; Real applications; Vibration cancellation; Evolutionary algorithms",2-s2.0-85029166917
"Villa F., Vallada E., Fanjul-Peyro L.","Heuristic algorithms for the unrelated parallel machine scheduling problem with one scarce additional resource",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031014412&doi=10.1016%2fj.eswa.2017.09.054&partnerID=40&md5=cea4c0cacfb4aded16c2b38b89844d06","In this paper, we study the unrelated parallel machine scheduling problem with one scarce additional resource to minimise the maximum completion time of the jobs or makespan. Several heuristics are proposed following two strategies: the first one is based on the consideration of the resource constraint during the whole solution construction process. The second one starts from several assignment rules without considering the resource constraint, and repairs the non feasible assignments in order to obtain a feasible solution. Several computation experiments are carried out over an extensive benchmark. A comparative evaluation against previously proposed mathematical models and matheuristics (combination of mathematical models and heuristics) is carried out. From the results, we can conclude that our methods outperform the existing ones, and the second strategy performs better, especially for large instances. © 2017 Elsevier Ltd","Additional resources; Heuristics; Makespan; Parallel machine problem; Scheduling","Machinery; Scheduling; Additional resources; Comparative evaluations; Construction process; Heuristics; Makespan; Parallel machine problems; Resource Constraint; Unrelated parallel machines; Heuristic algorithms",2-s2.0-85031014412
"Bach E., Sandlund B.","Baby-step giant-step algorithms for the symmetric group",2018,"Journal of Symbolic Computation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026239292&doi=10.1016%2fj.jsc.2017.07.003&partnerID=40&md5=e40a041d2d96e3db7e309bd46a778331","We study discrete logarithms in the setting of group actions. Suppose that G is a group that acts on a set S. When r,s∈S, a solution g∈G to rg=s can be thought of as a kind of logarithm. In this paper, we study the case where G=Sn and develop analogs to Shanks' baby-step / giant-step procedure for ordinary discrete logarithms. Specifically, we compute two sets A,B⊆Sn such that every permutation of Sn can be written as a product ab of elements a∈A and b∈B. Our deterministic procedure is optimal up to constant factors, in the sense that A and B can be computed in optimal asymptotic complexity, and |A| and |B| are a small constant from n! in size. We also analyze randomized “collision” algorithms for the same problem. © 2017 Elsevier Ltd","Collision algorithm; Computational group theory; Discrete logarithm; Group actions; Symmetric group",,2-s2.0-85026239292
"Martins de Sá E., Morabito R., de Camargo R.S.","Efficient Benders decomposition algorithms for the robust multiple allocation incomplete hub location problem with service time requirements",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031013790&doi=10.1016%2fj.eswa.2017.10.005&partnerID=40&md5=141dfbaa5f836d116b929e6caf66a0ac","Many transportation systems for routing flows between several origin-destination pairs of demand nodes have been widely designed as hub-and-spoke networks. To improve the provided service level of these networks, service time requirements are here considered during modeling, giving rise to a multiple allocation incomplete hub location problem with service time requirements. The problem consists of designing a hub and spoke network by locating hubs, establishing inter-hub arcs, and routing origin-destination demand flows at minimal cost while meeting some service time requirements. As travel times are usually uncertain for most real cases, the problem is approached via a binary linear programming robust optimization model, which is solved by two specialized Benders decomposition algorithms. The devised Benders decomposition framework outperforms a general purpose optimization solver on solving benchmark instances of the hub location literature. The achieved results also show how the probability of violating the travel time requirements decreases with the prescribed protection level, at the expense of the higher costs of the optimal solution for the robust optimization model. © 2017 Elsevier Ltd","Benders decomposition; Hub location problem with service requirements; Robust optimization; Travel time uncertainty","Assembly; Benchmarking; Linear programming; Location; Network routing; Stochastic programming; Traffic control; Travel time; Benders decomposition; Benders decomposition algorithm; Binary linear programming; Origin-destination pairs; Robust optimization; Robust optimization models; Service requirements; Travel time uncertainty; Optimization",2-s2.0-85031013790
"Sampaio P.S., Soares A., Castanho A., Almeida A.S., Oliveira J., Brites C.","Optimization of rice amylose determination by NIR-spectroscopy using PLS chemometrics algorithms",2018,"Food Chemistry",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029493181&doi=10.1016%2fj.foodchem.2017.09.058&partnerID=40&md5=872978329f2291fcdd8cd315aaab7902","Determining amylose content in rice with near infrared (NIR) spectroscopy, associated with a suitable multivariate regression method, is both feasible and relevant for the rice business to enable Process Analytical Technology applications for this critical factor, but it has not been fully exploited. Due to it being time-consuming and prone to experimental errors, it is urgent to develop a low-cost, nondestructive and ‘on-line’ method able to provide high accuracy and reproducibility. Different rice varieties and specific chemometrics tools, such as partial least squares (PLS), interval-PLS, synergy interval-PLS and moving windows-PLS, were applied to develop an optimal regression model for rice amylose determination. The model performance was evaluated by the root mean square error of prediction (RMSEP) and the correlation coefficient (R). The high performance of the siPLS method (R = 0.94; RMSEP = 1.938; 8941–8194 cm−1; 5592–5045 cm−1; and 4683–4335 cm−1) shows the feasibility of NIR technology for determination of the amylose with high accuracy. © 2017 Elsevier Ltd","iPLS; Multivariate models; mwPLS; PLS; Process Analytical Technologies; siPLS","Cyclodextrins; Drug products plants; Least squares approximations; Mean square error; Near infrared spectroscopy; Regression analysis; iPLS; Multivariate models; mwPLS; Process analytical technology; siPLS; Infrared devices; amylose; algorithm; Article; chemometric analysis; correlation coefficient; enzyme assay; multivariate analysis; near infrared spectroscopy; nonhuman; partial least squares regression; principal component analysis; process technology; rice",2-s2.0-85029493181
"Zhang L., Srisukkham W., Neoh S.C., Lim C.P., Pandit D.","Classifier ensemble reduction using a modified firefly algorithm: An empirical evaluation",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032179251&doi=10.1016%2fj.eswa.2017.10.001&partnerID=40&md5=081199cc91e44509329d65f6ce8b6cd1","In this research, we propose a variant of the firefly algorithm (FA) for classifier ensemble reduction. It incorporates both accelerated attractiveness and evading strategies to overcome the premature convergence problem of the original FA model. The attractiveness strategy takes not only the neighboring but also global best solutions into account, in order to guide the firefly swarm to reach the optimal regions with fast convergence while the evading action employs both neighboring and global worst solutions to drive the search out of gloomy regions. The proposed algorithm is subsequently used to conduct discriminant base classifier selection for generating optimized ensemble classifiers without compromising classification accuracy. Evaluated with standard, shifted, and composite test functions, as well as the Black-Box Optimization Benchmarking test suite and several high dimensional UCI data sets, the empirical results indicate that, based on statistical tests, the proposed FA model outperforms other state-of-the-art FA variants and classical metaheuristic search methods in solving diverse complex unimodal and multimodal optimization and ensemble reduction problems. Moreover, the resulting ensemble classifiers show superior performance in comparison with those of the original, full-sized ensemble models. © 2017 Elsevier Ltd","Classification; Ensemble reduction; Firefly algorithm","Bioluminescence; Classification (of information); Digital storage; Black-box optimization; Classification accuracy; Empirical evaluations; Firefly algorithms; Meta-heuristic search; Modified firefly algorithms; Multi-modal optimization; Pre-mature convergences; Optimization",2-s2.0-85032179251
"Lloyd-Jones L.R., Nguyen H.D., McLachlan G.J.","A globally convergent algorithm for lasso-penalized mixture of linear regression models",2018,"Computational Statistics and Data Analysis",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032227768&doi=10.1016%2fj.csda.2017.09.003&partnerID=40&md5=bd863e9f5f11cbdba52aab670cf11a7b","Variable selection is an old and pervasive problem in regression analysis. One solution is to impose a lasso penalty to shrink parameter estimates toward zero and perform continuous model selection. The lasso-penalized mixture of linear regressions model (L-MLR) is a class of regularization methods for the model selection problem in the fixed number of variables setting. A new algorithm is proposed for the maximum penalized-likelihood estimation of the L-MLR model. This algorithm is constructed via the minorization–maximization algorithm paradigm. Such a construction allows for coordinate-wise updates of the parameter components, and produces globally convergent sequences of estimates that generate monotonic sequences of penalized log-likelihood values. These three features are missing in the previously presented approximate expectation–maximization algorithms. The previous difficulty in producing a globally convergent algorithm for the maximum penalized-likelihood estimation of the L-MLR model is due to the intractability of finding exact updates for the mixture model mixing proportions in the maximization-step. This issue is resolved by showing that it can be converted into a simple numerical root finding problem that is proven to have a unique solution. The method is tested in simulation and with an application to Major League Baseball salary data from the 1990s and the present day, where the concept of whether player salaries are associated with batting performance is investigated. © 2017 Elsevier B.V.","Lasso; Major League Baseball; Mixture of linear regressions model; MM algorithm","Compensation (personnel); Linear regression; Maximum likelihood estimation; Mixtures; Optimization; Regression analysis; Sports; Wages; Globally convergent algorithms; Lasso; Linear regression models; Major League Baseball; Maximization algorithm; Maximum penalized likelihood; Model selection problem; Regularization methods; Parameter estimation",2-s2.0-85032227768
"Zheng Q.-Q., Ma C.-F.","A class of accelerated parameterized inexact Uzawa algorithms for complex symmetric linear systems",2018,"Applied Mathematics and Computation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032488834&doi=10.1016%2fj.amc.2017.10.007&partnerID=40&md5=897ccc0bcd243f97e864621e95679410","We establish a class of accelerated parameterized inexact Uzawa (APIU) algorithms for solving the complex symmetric linear systems. Our main contribution is accelerating the convergence of the PIU algorithm by making use of the extrapolation technique which is based on the eigenvalues of the iterative matrix. These accelerated parameterized inexact Uzawa algorithms involve two iteration parameters whose special choices can recover the parameterized inexact Uzawa algorithm and some other methods. First, the accelerated model for the PIU algorithm is established and the accelerated PIU algorithm is presented. Then we study the convergence of the corrected PIU algorithm. Moreover, we present the optimal iteration parameter and the corresponding optimal convergence factor for the PIU method. We also consider acceleration of the PIU iteraton by Krylov subspace methods. Numerical experiments are presented to illustrate the theoretical results and examine the numerical effectiveness of the new method. © 2017 Elsevier Inc.","Complex symmetric linear system; Convergence analysis; Extrapolation technique; Numerical experiment; Preconditioner; The parameterized inexact Uzawa method","Convergence of numerical methods; Eigenvalues and eigenfunctions; Extrapolation; Iterative methods; Linear systems; Numerical methods; Parameter estimation; Parameterization; Complex symmetric linear systems; Convergence analysis; Extrapolation techniques; Numerical experiments; Parameterized; Preconditioners; Uranium compounds",2-s2.0-85032488834
"Allamigeon X., Gaubert S., Skomra M.","Solving generic nonarchimedean semidefinite programs using stochastic game algorithms",2018,"Journal of Symbolic Computation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025802023&doi=10.1016%2fj.jsc.2017.07.002&partnerID=40&md5=43086a5192cf6d5e755a497ea66a58b5","A general issue in computational optimization is to develop combinatorial algorithms for semidefinite programming. We address this issue when the base field is nonarchimedean. We provide a solution for a class of semidefinite feasibility problems given by generic matrices. Our approach is based on tropical geometry. It relies on tropical spectrahedra, which are defined as the images by the valuation of nonarchimedean spectrahedra. We establish a correspondence between generic tropical spectrahedra and zero-sum stochastic games with perfect information. The latter have been well studied in algorithmic game theory. This allows us to solve nonarchimedean semidefinite feasibility problems using algorithms for stochastic games. These algorithms are of a combinatorial nature and work for large instances. © 2017 Elsevier Ltd","Nonarchimedean fields; Semidefinite programming; Stochastic mean payoff games; Tropical geometry",,2-s2.0-85025802023
"Yu Y., Zhao H.","Robust incremental normalized least mean square algorithm with variable step sizes over distributed networks",2018,"Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030175179&doi=10.1016%2fj.sigpro.2017.09.016&partnerID=40&md5=cf31d30fa816ca9d060432f8f6faf3f0","An improved incremental normalized least mean square (INLMS) algorithm is developed by minimizing the Huber cost function, which is robust against impulsive noises, over distributed networks. To significantly suppress impulsive noises, a recursive scheme based on the incremental cooperation strategy is designed for updating the cutoff parameter in the Huber function. Since the proposed algorithm can be interpreted as a variable step size INLMS algorithm, it has faster convergence rate and lower steady-state error than some existing incremental distributed algorithms in both impulsive and non-impulsive noise environments. In addition, to track a sudden change of the unknown system, a modified method of resetting the cutoff parameter is developed. © 2017 Elsevier B.V.","Adaptive networks; Distributed processing; Impulsive noises; Incremental distributed algorithm; Variable step size","Cost functions; Adaptive networks; Co-operation strategy; Distributed networks; Distributed processing; Impulsive noise environment; Normalized least mean square; Normalized least mean square algorithms; Variable step size; Impulse noise",2-s2.0-85030175179
"Sun T., Barrio R., Cheng L., Jiang H.","Precompact convergence of the nonconvex Primal–Dual Hybrid Gradient algorithm",2018,"Journal of Computational and Applied Mathematics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028877375&doi=10.1016%2fj.cam.2017.07.037&partnerID=40&md5=65d91a54e76f09431af0df1b4300feb6","The Primal–Dual Hybrid Gradient (PDHG) algorithm is a powerful algorithm used quite frequently in recent years for solving saddle-point optimization problems. The classical application considers convex functions, and it is well studied in literature. In this paper, we consider the convergence of an alternative formulation of the PDHG algorithm in the nonconvex case under the precompact assumption. The proofs are based on the Kurdyka–Ł ojasiewic functions, that cover a wide range of problems. A simple numerical experiment illustrates the convergence properties. © 2017 Elsevier B.V.","Convergence analysis; Kurdyka–Ł ojasiewic functions; Nonconvex optimization; Primal–Dual Hybrid Gradient algorithms","Functions; Convergence analysis; Convergence properties; Convex functions; Gradient algorithm; Nonconvex optimization; Numerical experiments; Optimization problems; Saddle point; Optimization",2-s2.0-85028877375
"Cordero A., Jordán C., Sanabria-Codesal E., Torregrosa J.R.","Highly efficient iterative algorithms for solving nonlinear systems with arbitrary order of convergence p+3, p≥5",2018,"Journal of Computational and Applied Mathematics",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016035481&doi=10.1016%2fj.cam.2017.02.032&partnerID=40&md5=a2a588737953195a320679b395f72f57","It is known that the concept of optimality is not defined for multidimensional iterative methods for solving nonlinear systems of equations. However, usually optimal fourth-order schemes (extended to the case of several variables) are employed as starting steps in order to design higher order methods for this kind of problems. In this paper, we use a non-optimal (in scalar case) iterative procedure that is specially efficient for solving nonlinear systems, as the initial steps of an eighth-order scheme that improves the computational efficiency indices of the existing methods, as far as the authors know. Moreover, the method can be modified by adding similar steps, increasing the order of convergence three times per step added. This kind of procedures can be used for solving big-sized problems, such as those obtained by applying finite differences for approximating the solution of diffusion problem, heat conduction equations, etc. Numerical comparisons are made with the same existing methods, on standard nonlinear systems and Fisher's equation by transforming it in a nonlinear system by using finite differences. From these numerical examples, we confirm the theoretical results and show the performance of the proposed schemes. © 2017 Elsevier B.V.","Convergence; Efficiency index; Fisher's equation; Iterative method; Nonlinear systems","Computational efficiency; Convergence of numerical methods; Efficiency; Finite difference method; Heat conduction; Nonlinear equations; Nonlinear systems; Numerical methods; Problem solving; Convergence; Efficiency index; Fisher's equation; Heat conduction equations; Higher-order methods; Non-linear systems of equations; Numerical comparison; Order of convergence; Iterative methods",2-s2.0-85016035481
"Saini R., Pratim Roy P., Prosad Dogra D.","A segmental HMM based trajectory classification using genetic algorithm",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031757419&doi=10.1016%2fj.eswa.2017.10.021&partnerID=40&md5=5231d22a3e1d7a76903fb29710e914ba","Trajectory classification techniques face various challenges due to varying length and lack of the presence of clear boundaries among the trajectory classes. To overcome such challenges, a trajectory shrinking framework using Adaptive Multi-Kernel based Shrinkage (AMKS) can be used. However, such a strategy often results in over-shrinking of trajectories leading to poor classification. To improve classification performance, we introduce two additional kernels that are based on convex hull and Ramer–Douglas–Peucker (RDP) algorithm. Next, we propose a supervised trajectory classification approach using a combination of global and Segmental Hidden Markov Model (HMM) based classifiers. In the first stage, HMM is used globally for classification of trajectory to provide state-wise distribution of trajectory segments. In the second stage, state-wise trajectory segments are classified and combined with global recognition performance to improve the classification results. Combination of Global HMM and Segmental HMM is performed using a genetic algorithm (GA) based framework in the final stage. We have conducted experiments over two publicly available datasets, popularly known as T15 and MIT. We have achieved 94.80% and 96.75% of accuracies on T15 and MIT datasets, respectively. We also analyzed the robustness of the proposed framework by adding Gaussian noise. To show the effectiveness of the system, we have performed recognition of on-line signature using proposed Segmental HMM based combination model. In SVC2004 signature dataset, it outperforms traditional HMM-based systems. © 2017 Elsevier Ltd","Genetic algorithm; HMM; Segmental HMM; Signature recognition; Supervised learning; SVC2004; Trajectory classification","Gaussian noise (electronic); Genetic algorithms; Markov processes; Shrinkage; Supervised learning; Trajectories; Trellis codes; Classification performance; Classification results; Segmental hidden markov models; Segmental HMM; Signature recognition; SVC2004; Trajectory classification; Trajectory segments; Hidden Markov models",2-s2.0-85031757419
"Wodecki J., Michalak A., Zimroz R.","Optimal filter design with progressive genetic algorithm for local damage detection in rolling bearings",2018,"Mechanical Systems and Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032878036&doi=10.1016%2fj.ymssp.2017.09.008&partnerID=40&md5=474e2b1d129a81c5557b9fe3fc4b2385","Harsh industrial conditions present in underground mining cause a lot of difficulties for local damage detection in heavy-duty machinery. For vibration signals one of the most intuitive approaches of obtaining signal with expected properties, such as clearly visible informative features, is prefiltration with appropriately prepared filter. Design of such filter is very broad field of research on its own. In this paper authors propose a novel approach to dedicated optimal filter design using progressive genetic algorithm. Presented method is fully data-driven and requires no prior knowledge of the signal. It has been tested against a set of real and simulated data. Effectiveness of operation has been proven for both healthy and damaged case. Termination criterion for evolution process was developed, and diagnostic decision making feature has been proposed for final result determinance. © 2017 Elsevier Ltd","Digital filter; Genetic algorithm; Local damage; Vibration","Bandpass filters; Bearings (machine parts); Decision making; Digital filters; Filtration; Genetic algorithms; Machinery; Roller bearings; Diagnostic decision makings; Evolution process; Industrial conditions; Local damage; Optimal filter design; Termination criteria; Underground mining; Vibration; Damage detection",2-s2.0-85032878036
"Ditzler G., Carla Bouaynaya N., Shterenberg R.","AKRON: An algorithm for approximating sparse kernel reconstruction",2018,"Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032034379&doi=10.1016%2fj.sigpro.2017.10.020&partnerID=40&md5=2c00201633fdcf72c7363df7897b58ae","Exact reconstruction of a sparse signal for an under-determined linear system using the ℓ0-measure is, in general, an NP-hard problem. The most popular approach is to relax the ℓ0-optimization problem to an ℓ1-approximation. However, the strength of this convex approximation relies upon rigid properties on the system, which are not verifiable in practice. Greedy algorithms have been proposed in the past to speed up the optimization of the ℓ1 problem, but their computational efficiency comes at the expense of a larger error. In an effort to control error and complexity, this paper goes beyond the ℓ1-approximation by growing neighborhoods of the ℓ1-solution that moves towards the optimal solution. The size of the neighborhood is tunable depending on the computational resources. The proposed algorithm, termed Approximate Kernel RecONstruction (AKRON), yields significantly smaller errors than current greedy methods with a controllable computational cost. By construction, the error of AKRON is smaller than or to equal the ℓ1-solution. AKRON enjoys all the error bounds of ℓ1 under the restricted isometry property condition. We benchmarked AKRON on simulated data from several under-determined systems, and the results show that AKRON can significantly improve the reconstruction error with slightly more computational cost than solving the ℓ1 problem directly. © 2017 Elsevier B.V.","Compressive sensing; Linear systems; Optimization","Computational complexity; Error analysis; Errors; Linear systems; Matrix algebra; Optimization; Compressive sensing; Computational costs; Computational resources; Convex approximation; Exact reconstruction; Greedy algorithms; Reconstruction error; Restricted isometry properties; Computational efficiency",2-s2.0-85032034379
"Cai Y., Rajapakse A.D., Haleem N.M., Raju N.","A threshold free synchrophasor measurement based multi-terminal fault location algorithm",2018,"International Journal of Electrical Power and Energy Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030760782&doi=10.1016%2fj.ijepes.2017.09.035&partnerID=40&md5=324d24930dd0e1ed7f465168ea6dd8eb","A new impedance based fault location algorithm is proposed for a generic multi-terminal transmission network consisting of a main line and tapped branches with no direct measurements available at the intermediate tapping nodes. The core of the algorithm is a threshold free faulted branch search algorithm that systematically compares the multiple estimates of voltages for the tapping nodes, computed using synchrophasor measurements at the terminals. Once the faulted branch is identified, multi-terminal fault location problem is reduced into a two-terminal fault location problem to determine the exact location of fault within the branch. The proposed algorithm is simple and does not involve resource intensive mathematical operations such as matrix inversion. The proposed algorithm was implemented as a module in an in-house developed real-time synchrophasor application software program, and its performance was evaluated using a test setup consisting of a real-time simulator, an actual synchrophasor network, and a phasor data concentrator. The tests showed that the proposed algorithm is capable of correctly determining the faulted branch, except for few faults that are very close to tapping nodes. When the algorithm is used with practical synchrophasor measurements, the fault location error was within a typical tower span for most cases. © 2017 Elsevier Ltd",,"Application programs; Computer software; Software testing; Direct measurement; Fault location algorithms; Mathematical operations; Multi-terminal fault location; Phasor data concentrators; Real time simulators; Synchrophasor measurements; Two-terminal fault locations; Location",2-s2.0-85030760782
"Ramaswami S., Siqueira M.","A fast algorithm for computing irreducible triangulations of closed surfaces in Ed",2018,"Computational Geometry: Theory and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019854239&doi=10.1016%2fj.comgeo.2017.05.007&partnerID=40&md5=d39320fc232019ba2ae86ccfd8bbfcc7","We give a fast algorithm for computing an irreducible triangulation T′ of an oriented, connected, boundaryless, and compact surface S in Ed from any given triangulation T of S. If the genus g of S is positive, then our algorithm takes O(g2+gn) time to obtain T′, where n is the number of triangles of T. Otherwise, T′ is obtained in linear time in n. While the latter upper bound is optimal, the former upper bound improves upon the currently best known upper bound by a lg⁡n/g factor. In both cases, the memory space required by our algorithm is in Θ(n). © 2017 Elsevier B.V.","Edge contractions; Irreducible triangulations; Link condition","Triangulation; Closed surfaces; Edge contractions; Fast algorithms; Linear time; Link condition; Memory space; Number of triangles; Upper Bound; Surveying",2-s2.0-85019854239
"Kang S., Kim M., Chae J.","A closed loop based facility layout design using a cuckoo search algorithm",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032863859&doi=10.1016%2fj.eswa.2017.10.038&partnerID=40&md5=476ad838753e09f84763a7838636d952","Facility layout problems (FLPs) are design problems that involve determining the most favorable arrangement of facilities in a given space. The closed loop layout problem (CLLP) is an FLP that employs a closed loop guided configuration. This type of layout is commonly discussed when designing a flexible manufacturing system (FMS). The CLLP is concerned with determining the efficient arrangement of manufacturing cells on a central loop based material handling system. Because the material flow between cells must pass through the loop path, distance is not measured in the conventional manner (i.e. the rectilinear or Euclidean distance). The problem is more complicated than a generic FLP because there are additional constraints that restrict cell shape and orientation as well as the positions of the pick-up and drop-off points. In this study, we propose a random-key and cuckoo search (CS) based approach to solve the CLLP. CS is a rather recently developed algorithm, and it has not yet been applied to FLPs in the literature. To evaluate the present algorithm, computational experiments are conducted using benchmark problems from a previous study. The obtained results show the remarkable performance of the proposed approach. © 2017 Elsevier Ltd","Closed loop layout; Cuckoo search; Facility layout design; Flexible manufacturing system","Manufacture; Materials handling; Optimization; Plant layout; Bench-mark problems; Closed loops; Computational experiment; Cuckoo search algorithms; Cuckoo searches; Facility layout design; Facility layout problems; Material handling systems; Flexible manufacturing systems",2-s2.0-85032863859
"Zhou M., Singh A.K., Pedrini G., Osten W., Min J., Yao B.","Tunable output-frequency filter algorithm for imaging through scattering media under LED illumination",2018,"Optics Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032858434&doi=10.1016%2fj.optcom.2017.10.018&partnerID=40&md5=1b15a3571a6417e06bd40db0d8b424d2","We present a tunable output-frequency filter (TOF) algorithm to reconstruct the object from noisy experimental data under low-power partially coherent illumination, such as LED, when imaging through scattering media. In the iterative algorithm, we employ Gaussian functions with different filter windows at different stages of iteration process to reduce corruption from experimental noise to search for a global minimum in the reconstruction. In comparison with the conventional iterative phase retrieval algorithm, we demonstrate that the proposed TOF algorithm achieves consistent and reliable reconstruction in the presence of experimental noise. Moreover, the spatial resolution and distinctive features are retained in the reconstruction since the filter is applied only to the region outside the object. The feasibility of the proposed method is proved by experimental results. © 2017 Elsevier B.V.","Experimental noise; LED illumination; Speckle imaging; Tunable output-frequency filter algorithm","Bandpass filters; Coherent scattering; Light emitting diodes; Experimental noise; Gaussian functions; Iterative algorithm; Iterative phase retrieval algorithm; LED illumination; Output frequency; Partially coherent illumination; Speckle imaging; Iterative methods",2-s2.0-85032858434
"Kumar A., Kumar V.","Performance analysis of optimal hybrid novel interval type-2 fractional order fuzzy logic controllers for fractional order systems",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032282207&doi=10.1016%2fj.eswa.2017.10.033&partnerID=40&md5=7e9836231114fdccee85fe321d81cbf7","The main objective of this paper is to propose the family of hybrid novel interval type-2 fractional order fuzzy PID (IT2FO-FPID) controllers, which incorporates fractional order integro-differentiator, taking into its consideration the advantages of the interval type-2 fuzzy controllers (IT2FLCs) and fractional order PID (FOPID) controllers. The incorporation of IT2FLCs with FOPID controllers has been investigated in terms of time response measure for unit set-point response and unit load disturbance. The resulting different hybrid IT2FO-FPID controller structures are examined on different fractional order processes followed by robustness analysis. It is observed that incorporation of fractional order integro-differential operators made the proposed control structures less sensitive to the parameters change. For this reason, fractional order integro-differential operators are adopted as design variables along with input/output scaling factors for designing of effective novel controllers. In order to do reasonable comparison, the tuning of the family of hybrid IT2FO-FPID controllers' parameters is done with newly Artificial Bee Colony-Genetic Algorithm (ABC-GA) optimization technique to develop optimal closed loop performance by considering the objective function as weighted sum of control loop error index and control output. The simulation analyses are executed for two different non-integer order plus time delay fractional order process plants (NIOPTD-I and NIOPTD-II). These processes represent a sensible estimation of most process plants and are employed to examine the comparative qualities of the presented hybrid IT2FO-FPID controllers. Further, the performance comparison and the significance of the different proposed hybrid controllers are investigated under unit set-point response, load disturbance rejection, and small control signal or actuators requirement. In order to test the efficacy of proposed controllers, the robustness analysis such as parameter variations is also investigated. Finally, the simulation investigations explicitly suggest that proposed different hybrid IT2FO-FPID control structures can be recommended in terms of better step response, better load disturbance rejection, small control signal response, and parameters variation. © 2017 Elsevier Ltd","ABC-GA algorithms; Fractional order controller; Hybrid Interval type-2 fractional order fuzzy PID controllers; Interval type-2 fuzzy PID controller; Robustness analysis; Time domain optimal tuning","Delay control systems; Differential equations; Disturbance rejection; Electric control equipment; Fuzzy inference; Fuzzy logic; Genetic algorithms; Mathematical operators; Optimization; Proportional control systems; Robust control; Robustness (control systems); Three term control systems; Time domain analysis; Tuning; Fractional-order controllers; Fuzzy PID controller; GA algorithm; Interval type-2 fuzzy; Optimal tuning; Robustness analysis; Controllers",2-s2.0-85032282207
"Liu D., Li W., Vong S.-W.","The tensor splitting with application to solve multi-linear systems",2018,"Journal of Computational and Applied Mathematics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028921784&doi=10.1016%2fj.cam.2017.08.009&partnerID=40&md5=9324d79945a031f2e226aa6711878e2c","In this paper, firstly, we introduce the variant tensor splittings, and present some equivalent conditions for a strong M-tensor based on the tensor splitting. Secondly, the existence and uniqueness conditions of the solution for multi-linear systems are given. Thirdly, we propose some tensor splitting algorithms for solving multi-linear systems with coefficient tensor being a strong M-tensor. As an application, a tensor splitting algorithm for solving the multi-linear model of higher order Markov chains is proposed. Numerical examples are given to demonstrate the efficiency of the proposed algorithms. © 2017 Elsevier B.V.","Inverse of a tensor; Multi-linear systems; Strong M-tensor; Tensor splitting; Tensor splitting algorithms","Linear systems; Markov processes; Equivalent condition; Existence and uniqueness; Higher-order Markov chains; Linear modeling; Multi-linear systems; Splitting algorithms; Splittings; Tensors",2-s2.0-85028921784
"Vigneron V., Kodewitz A., da Costa M.N., Tome A.M., Langlang E.","Non-negative sub-tensor ensemble factorization (NsTEF) algorithm. A new incremental tensor factorization for large data sets.",2018,"Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030835061&doi=10.1016%2fj.sigpro.2017.09.012&partnerID=40&md5=1feb10cdcd95ef635fa74748da325249","In this work we present a novel algorithm for nonnegative tensor factorization (NTF). Standard NTF algorithms are very restricted in the size of tensors that can be decomposed. Our algorithm overcomes this size restriction by interpreting the tensor as a set of sub-tensors and by proceeding the decomposition of sub-tensor by sub-tensor. This approach requires only one sub-tensor at once to be available in memory. © 2017 Elsevier B.V.","CANDECOMP/PARAFAC Decomposition; Incremental algorithm; Learning method; Matrix factorization; Non-negative tensor decomposition; NTF","Factorization; Candecomp/parafac decompositions; Incremental algorithm; Learning methods; Matrix factorizations; Non-negative tensor decompositions; Tensors",2-s2.0-85030835061
"Gutiérrez-Batista K., Campaña J.R., Vila M.-A., Martin-Bautista M.J.","Building a contextual dimension for OLAP using textual data from social networks",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031712961&doi=10.1016%2fj.eswa.2017.10.012&partnerID=40&md5=c119062447c6d962a86c978716a6f4d0","Due to the continuous growth of social networks the textual information available has increased exponentially. Data warehouses (DW) and online analytical processing (OLAP) are some of the established technologies to process and analyze structured data. However, one of their main limitations is the lack of automatic processing and analysis of unstructured data (specifically, textual data), and its integration with structured data. This paper proposes the creation, integration and implementation of a new dimension called Contextual Dimension from texts obtained from social networks into a multidimensional model. Such a dimension is automatically created after applying hierarchical clustering algorithms and is fully independent from the language of the texts. This dimension allows the inclusion of multidimensional analysis of texts using contexts and topics integrated with conventional dimensions into business decisions. The experiments were carried out by means of a freeware OLAP system (Wonder 3.0) using real data from social networks. © 2017 Elsevier Ltd","Context detection; Data warehousing; Multidimensional model; OLAP; Text clustering","Data warehouses; Social networking (online); Context detection; Contextual dimensions; Hierarchical clustering algorithms; Multi-dimensional analysis; Multi-dimensional model; OLAP; On-line analytical processing; Text Clustering; Clustering algorithms",2-s2.0-85031712961
"Kumar R., Tewari P.C., Khanduja D.","Parameters optimization of fabric finishing system of a textile industry using teaching–learning-based optimization algorithm",2018,"International Journal of Industrial Engineering Computations",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025128288&doi=10.5267%2fj.ijiec.2017.6.002&partnerID=40&md5=8594d6f1dcc94de77d8917ed8b6081b8","In the present work, a recently developed advanced optimization algorithm named as teaching–learning-based optimization (TLBO) is used for the parameters optimization of fabric finishing system of a textile industry. Fabric Finishing System has four main subsystems, arranged in hybrid configuration. For performance modeling and analysis of availability, a performance evaluating model of fabric finishing system has been developed with the help of mathematical formulation based on Markov-Birth-Death process using Probabilistic Approach. Then, the overall performance of the concerned system has first analyzed and then, optimized by using teaching–learning-based optimization (TLBO). The results of optimization using the proposed algorithm are validated by comparing with those obtained by using the genetic algorithm (GA) on the same system. Improvement in the results is obtained by the proposed algorithm. The results of effect of variation of the algorithm parameters on fitness values of the objective function are reported. © 2018 Growing Science Ltd. All rights reserved. and 2017 by the authors; licensee Growing Science, Canada.","Genetic algorithm; Markov process; Performance modeling; Probabilistic approach; TLBO",,2-s2.0-85025128288
"Nigmatullin R.R., Gubaidullin I.A.","NAFASS: Fluctuation spectroscopy and the Prony spectrum for description of multi-frequency signals in complex systems",2018,"Communications in Nonlinear Science and Numerical Simulation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027980619&doi=10.1016%2fj.cnsns.2017.08.009&partnerID=40&md5=50992f507bc6ce6927971f07a1e285e5","In this paper, we essentially modernize the NAFASS (Non-orthogonal Amplitude Frequency Analysis of the Smoothed Signals) approach suggested earlier. Actually, we solved two important problems: (a) new and effective algorithm was proposed and (b) we proved that the segment of the Prony spectrum could be used as the fitting function for description of the desired frequency spectrum. These two basic elements open an alternative way for creation of the fluctuation spectroscopy when the segment of the Fourier series can fit any random signal with trend but the dispersion spectrum of the Fourier series ω0·k(ω0≡2π/T)⇒Ωk(k=0,1,2,…,K−1) is replaced by the specific dispersion law Ωk calculated with the help of original algorithm described below. It implies that any finite signal will have a compact amplitude-frequency response (AFR), where the number of the modes is much less in comparison with the number of data points (K &lt;&lt; N). The NAFASS approach can be applicable for quantitative description of a wide set of random signals/fluctuations and allows one to compare them with each other based on one general platform. As the first example, we considered economic data and compare 30-years world prices for meat (beef, chicken, lamb and pork) entering as the basic components to every-day food consumption. These data were taken from the official site http://www.indexmundi.com/commodities/. We fitted these random functions with the high accuracy and calculated the desired “amplitude-frequency” response for these random price fluctuations. The calculated distribution of the amplitudes (Ack, Ask) and frequency spectrum Ωk (k = 0, 1,…, K−1) allows one to compress initial data (K (number of modes) &lt;&lt; N (number of data points), N/K ≅ 20–40) and receive an additional information for their comparison with each other. As the second example, we considered the transcendental/irrational numbers description in the frame of the proposed NAFASS approach, as well. This possibility was demonstrated on the quantitative description of the transcendental number π = 3.1415926535897932…, containing initially 6⋅104 digits. The results obtained for the second type of data can be useful for cryptography purposes. We do believe that the NAFASS approach can be widely used for creation of the new metrological standards based on comparison of different test fluctuations with the fluctuations registered from the pattern equipment. Apart from this obvious application, the NAFASS approach can be applicable for description of different nonlinear random signals containing the hidden beatings in radioelectronics and acoustics. © 2017 Elsevier B.V.","Economic data; Fourier transform; Meat prices; Prony decomposition; Short-time Fourier transform; Signal processing; Wavelet transform","Costs; Food supply; Fourier transforms; Frequency response; Meats; Signal processing; Spectroscopy; Wavelet decomposition; Wavelet transforms; Amplitude frequency response; Economic data; Effective algorithms; Fluctuation spectroscopy; Multi-frequency signals; Original algorithms; Quantitative description; Short time Fourier transforms; Fourier series",2-s2.0-85027980619
"Kugler M., Hostettler A., Soler L., Remond Y., George D.","A new algorithm for volume mesh refinement on merging geometries: Application to liver and vascularisation",2018,"Journal of Computational and Applied Mathematics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030460075&doi=10.1016%2fj.cam.2017.09.012&partnerID=40&md5=ea2bb563a8f53b6768dfae825cf10449","We introduce a new algorithm to merge several overlapping independent volumic meshes. Considering the different treated meshes, the biggest one is defined as the “main-mesh”, while the other ones are defined as the “sub-meshes”, and will be treated iteratively in order to provide a new unique mesh entity with a specific node distribution integrating the initial meshes geometry and precision. The “sub-meshes” are geometrically localised within the “main-mesh” into which the associated elements are refined. The proposed algorithm stops when the refined size of the “main-mesh” elements is close to the original “sub-mesh” elements size. The present algorithm preserves the mesh quality, initial geometry and precision of the different meshes, and optimises the number of elements produced, in order to keep a further Finite Element Model (FEM) calculation time as low as possible. The algorithm efficiency is validated on simple geometries and real life cases for medical applications and compared with refinement using the Brute Force Approach (BFA). Results indicate that only 3 iterative refinement steps are necessary to produce a new mesh presenting good integrated geometrical precision compared with BFA while optimising the calculation time by reducing the number of elements by 90%. © 2017 Elsevier B.V.","Finite element mesh; Liver; Local refinement; Merging geometry; Optimisation; Vascularisation","Finite element method; Geometry; Liver; Medical applications; Merging; Mesh generation; Optimization; Algorithm efficiency; Brute-force approach; Finite element meshes; Geometrical precision; Iterative refinement; Local refinement; Optimisations; Vascularisation; Iterative methods",2-s2.0-85030460075
"Liu T., Tan X., Sun B., Wu Y., Tsang D.H.K.","Energy management of cooperative microgrids: A distributed optimization approach",2018,"International Journal of Electrical Power and Energy Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032871581&doi=10.1016%2fj.ijepes.2017.10.021&partnerID=40&md5=f93e539287e0370659fe45606202ac96","The cooperation of multiple networked microgrids (MGs) can alleviate the mismatch problem between distributed generation and demand and reduce the overall cost of the power system. Energy management with direct energy exchange among MGs is a promising approach for improving energy efficiency. However, existing methods on microgrid cooperation usually overlook the underlying distribution network with operating constraints (e.g., voltage tolerance and power flow constraints). Hence the results may not be applicable to actual systems. This paper studies the energy management problem of multiple MGs that are interconnected by both the direct current (DC) energy exchange network and the alternating current (AC) traditional distribution networks. In our problem, each MG is equipped with renewable energy generators as well as distributed storage devices. In order to handle the non-convex power flow constraints, we exploit the recent results of the exact optimal power flow (OPF) relaxation method which can equivalently transform the original non-convex problem into a second-order cone programming problem and efficiently determine the optimal solution successfully. The objective of our problem is to minimize the overall energy cost in a distribution network consisting of multiple MGs, with the practical operating constraints (e.g., power balance and the battery's operational constraints) explicitly incorporated. Considering the privacy and scalability, we propose a distributed algorithm with convergence assurance based on the alternating direction method of multipliers (ADMM). We also implement our method based on the model predictive control (MPC) approach in order to handle the forecasting errors of the renewable energy generation. Simulations are made for different MG exchange topologies on three radial distribution network testbeds. Numerical results demonstrate that certain topologies are more favorable than others, and the cooperation strategy for the energy exchange is significantly affected by the MGs’ locations in the distribution network. © 2017 Elsevier Ltd","Cooperative microgrids; Direct energy exchange network; Distributed algorithms; Distributed energy resources; Distribution networks","Electric impedance measurement; Electric load flow; Electric power distribution; Energy efficiency; Energy management; Energy resources; Model predictive control; Multivariable control systems; Optimization; Parallel algorithms; Predictive control systems; Renewable energy resources; Topology; Virtual storage; Alternating direction method of multipliers; Distributed Energy Resources; Energy exchanges; Micro grid; Radial distribution networks; Renewable energy generation; Renewable energy generators; Second-order cone programming; Power management",2-s2.0-85032871581
"Bohler C., Klein R., Lingas A., Liu C.-H.","Forest-like abstract Voronoi diagrams in linear time",2018,"Computational Geometry: Theory and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023625891&doi=10.1016%2fj.comgeo.2017.06.013&partnerID=40&md5=93e2ea83a3ca71c7b55db1c56684b433","Voronoi diagrams are a general framework covering many types of concrete diagrams for different types of sites or distance measures. Generalizing a famous result by Aggarwal et al. [1] we prove the following. Suppose it is known that inside a closed domain D the Voronoi diagram V(S) is a tree, and for each subset S′⊂S, a forest with one face per site. If the order of Voronoi regions of V(S) along the boundary of D is given, then V(S) inside D can be constructed in linear time. © 2017 Elsevier B.V.","Abstract Voronoi diagrams; Forest structures; General distance; Linear-time algorithms; Voronoi diagrams","Clustering algorithms; Computational geometry; Forestry; Distance measure; Forest structure; General distance; Linear time; Linear-time algorithms; Voronoi diagrams; Voronoi regions; Graphic methods",2-s2.0-85023625891
"Ying B., Sayed A.H.","Performance limits of stochastic sub-gradient learning, part II: Multi-agent case",2018,"Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032027597&doi=10.1016%2fj.sigpro.2017.10.007&partnerID=40&md5=a00017a8935782281806031d5e75563b","The analysis in Part I [1] revealed interesting properties for subgradient learning algorithms in the context of stochastic optimization. These algorithms are used when the risk functions are non-smooth or involve non-differentiable components. They have been long recognized as being slow converging methods. However, it was revealed in Part I [1] that the rate of convergence becomes linear for stochastic optimization problems, with the error iterate converging at an exponential rate αi to within an O(μ)−neighborhood of the optimizer, for some α ∈ (0, 1) and small step-size μ. The conclusion was established under weaker assumptions than the prior literature and, moreover, several important problems were shown to satisfy these weaker assumptions automatically. These results revealed that sub-gradient learning methods have more favorable behavior than originally thought. The results of Part I [1] were exclusive to single-agent adaptation. The purpose of current Part II is to examine the implications of these discoveries when a collection of networked agents employs subgradient learning as their cooperative mechanism. The analysis will show that, despite the coupled dynamics that arises in a networked scenario, the agents are still able to attain linear convergence in the stochastic case; they are also able to reach agreement within O(μ) of the optimizer. © 2017","Affine-Lipschitz; Diffusion strategy; LASSO; Linear rate; Networked agents; Sub-gradient algorithm; SVM","Learning algorithms; Multi agent systems; Regression analysis; Stochastic systems; Diffusion strategies; LASSO; Linear rate; Lipschitz; Networked agents; Sub-gradient algorithm; Optimization",2-s2.0-85032027597
"Fabio Ceschini G., Gatta N., Venturini M., Hubauer T., Murarasu A.","A Comprehensive Approach for Detection, Classification, and Integrated Diagnostics of Gas Turbine Sensors",2018,"Journal of Engineering for Gas Turbines and Power",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032633681&doi=10.1115%2f1.4037964&partnerID=40&md5=dd8ebf9a968758170ff79d7a83c2c021","Anomaly detection in sensor time series is a crucial aspect for raw data cleaning in gas turbine (GT) industry. In addition to efficiency, a successful methodology for industrial applications should be also characterized by ease of implementation and operation. To this purpose, a comprehensive and straightforward approach for detection, classification, and integrated diagnostics of gas turbine sensors (named DCIDS) is proposed in this paper. The tool consists of two main algorithms, i.e., the anomaly detection algorithm (ADA) and the anomaly classification algorithm (ACA). The ADA identifies anomalies according to three different levels of filtering based on gross physics threshold application, intersensor statistical analysis (sensor voting), and single-sensor statistical analysis. Anomalies in the time series are identified by the ADA, together with their characteristics, which are analyzed by the ACA to perform their classification. Fault classes discriminate among anomalies according to their time correlation, magnitude, and number of sensors in which an anomaly is contemporarily identified. Results of anomaly identification and classification can subsequently be used for sensor diagnostic purposes. The performance of the tool is assessed in this paper by analyzing two temperature time series with redundant sensors taken on a Siemens GT in operation. The results show that the DCIDS is able to identify and classify different types of anomalies. In particular, in the first dataset, two severely incoherent sensors are identified and their anomalies are correctly classified. In the second dataset, the DCIDS tool proves to be capable of identifying and classifying clustered spikes of different magnitudes. © 2018 by ASME.",,"Classification (of information); Fault tolerant computer systems; Statistical methods; Time series; Anomaly detection; Anomaly identification; Anomaly-detection algorithms; Classification algorithm; Data cleaning; Integrated diagnostics; Redundant sensors; Time correlations; Gas turbines",2-s2.0-85032633681
"Li H., Ma Y., Fu Y.","An improved RIP-based performance guarantee for sparse signal recovery via simultaneous orthogonal matching pursuit",2018,"Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030225181&doi=10.1016%2fj.sigpro.2017.09.027&partnerID=40&md5=a73a3d5a0c05907845e8aa061a1f83a0","Recently, based on restricted isometry property (RIP), some sufficient conditions for exact support recovery with simultaneous orthogonal matching pursuit (SOMP) algorithm have been proposed when measurement matrices are different. In this paper, in the noiseless case, one sufficient condition for exact support recovery with SOMP is presented to improve the existing results. By using a counter example, in the noiseless case, an open problem presented in (Xu et. al, 2015) is solved. © 2017 Elsevier B.V.","Compressed sensing; Greedy algorithm; Multiple measurement vectors; Simultaneous orthogonal matching pursuit","Compressed sensing; Matrix algebra; Recovery; Counter examples; Greedy algorithms; Multiple measurement vectors; Orthogonal matching pursuit; Performance guarantees; Restricted isometry properties (RIP); Sparse signal recoveries; Support recoveries; Signal reconstruction",2-s2.0-85030225181
"Gao Y., Ai Q.","Distributed cooperative optimal control architecture for AC microgrid with renewable generation and storage",2018,"International Journal of Electrical Power and Energy Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032866574&doi=10.1016%2fj.ijepes.2017.10.007&partnerID=40&md5=a3d9686b0469d75fb85a49f845042361","AC microgrid is a promising approach to integrate various distributed generators and energy storage into the power system, and provide renewable and reliable energy to the customers. However, highly intermittent distributed energy sources and varying load demands pose increasing challenges for optimal energy management in an AC microgrid. In this paper, a distributed cooperative optimal control method based on the discrete consistency algorithm is proposed to realize the large-scale penetration of renewable energy in an AC microgrid. The proposed approach is implemented through a multi-agent distributed hierarchical control architecture, which only requires a local communication network to exchange the information. The optimal control is achieved through a three-level control architecture. The third control level aims at multi-objective optimal scheduling, considering the factors such as fuel consumption, pollution in the form of emissions and operational maintenance. The second control level is based on the discrete consistency algorithm that optimizes the frequency and voltage references of droop control and also shares the active and reactive power accurately according to the particular demand. The first control level is responsible for reference tracking of the associated components. Compared with the conventional centralized and decentralized controls, the proposed control method offers increased robustness and flexibility in the AC microgrid control, and only requires limited communication between neighboring agents to realize a global optimization. Finally, the effectiveness of the proposed strategy is verified in a typical AC microgrid model by using the PSCAD/EMTDC software. © 2017 Elsevier Ltd","Collaborative optimization; Consistency algorithm; Multi-agent system; Tie-line power","Global optimization; Multi agent systems; Network architecture; Optimization; Pollution control; Active and Reactive Power; Collaborative optimization; Consistency algorithms; Distributed energy sources; Hierarchical control architecture; Optimal control architecture; Optimal control methods; Tie line; Decentralized control",2-s2.0-85032866574
"Nurmohammadi T., Abbasian K., Yadipour R.","Ultra-fast all-optical plasmonic switching in near infra-red spectrum using a Kerr nonlinear ring resonator",2018,"Optics Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031799098&doi=10.1016%2fj.optcom.2017.09.082&partnerID=40&md5=6e43a8f809c5abb2ba2016075047962d","In this paper, an all-optical plasmonic switch based on metal–insulator–metal (MIM) nanoplasmonic waveguide with a Kerr nonlinear ring resonator is introduced and studied. Two-dimensional simulations utilizing the finite-difference time-domain algorithm are used to demonstrate an apparent optical bistability and significant switching mechanisms (in enabled-low condition: T(ON/OFF) =21.9 and in enabled-high condition: T(ON/OFF) =24.9) of the signal light arisen by altering the pump-light intensity. The proposed all-optical switching demonstrates femtosecond-scale feedback time (90 fs) and then ultra-fast switching can be achieved. The offered all-optical switch may recognize potential significant applications in integrated optical circuits. © 2017 Elsevier B.V.","FDTD algorithm; Optical bistablity; Telecom wavelength","Finite difference time domain method; High intensity light; Optical resonators; Optical switches; Plasmons; Resonators; Switching; Time domain analysis; FDTD algorithm; Finite-difference time-domain algorithms; Integrated optical circuit; Nanoplasmonic waveguides; Nonlinear ring resonators; Optical bistablity; Telecom wavelengths; Two-dimensional simulations; Nonlinear optics",2-s2.0-85031799098
"Coelho D.F.G., Dimitrov V.S., Rakai L.","Efficient computation of tridiagonal matrices largest eigenvalue",2018,"Journal of Computational and Applied Mathematics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029687278&doi=10.1016%2fj.cam.2017.08.008&partnerID=40&md5=5cfacb8eb8071ba4d3379da86edfe216","This paper proposes a method for a fast estimation of the largest eigenvalue of an asymmetric tridiagonal matrix. The proposed method is based on the Power method and the computation of the square of the original matrix. The matrix square is computed through a proposed fast algorithm designed specifically for tridiagonal matrices. Implementations for compressed column (CCS) and compressed row storage (CRS) formats are provided, discussed and compared to a standard scientific library. We investigate the roundoff numerical errors, showing that the proposed method provides errors no greater than the usual Power method. We provide numerical results with simulations in C/C++ implementation in order to demonstrate the effectiveness of the proposed method. © 2017 Elsevier B.V.","Eigenvalue; Fast algorithm; Power method; Tridiagonal matrix","Eigenvalues and eigenfunctions; Numerical methods; Compressed column; Efficient computation; Eigen-value; Fast algorithms; Largest eigenvalues; Numerical results; Power method; Tridiagonal matrices; Matrix algebra",2-s2.0-85029687278
"Abrardo A., Barni M., Kallas K., Tondi B.","A message passing approach for decision fusion in adversarial multi-sensor networks",2018,"Information Fusion",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021413999&doi=10.1016%2fj.inffus.2017.06.006&partnerID=40&md5=a5fe59ab0a7fb5bad58aba13ed1bd094","We consider a simple, yet widely studied, set-up in which a Fusion Center (FC) is asked to make a binary decision about a sequence of system states by relying on the possibly corrupted decisions provided by byzantine nodes, i.e. nodes which deliberately alter the result of the local decision to induce an error at the fusion center. When independent states are considered, the optimum fusion rule over a batch of observations has already been derived, however its complexity prevents its use in conjunction with large observation windows. In this paper, we propose a near-optimal algorithm based on message passing that greatly reduces the computational burden of the optimum fusion rule. In addition, the proposed algorithm retains very good performance also in the case of dependent system states. By first focusing on the case of small observation windows, we use numerical simulations to show that the proposed scheme introduces a negligible increase of the decision error probability compared to the optimum fusion rule. We then analyse the performance of the new scheme when the FC makes its decision by relying on long observation windows. We do so by considering both the case of independent and Markovian system states and show that the obtained performance are superior to those obtained with prior suboptimal schemes. As an additional result, we confirm the previous finding that, in some cases, it is preferable for the byzantine nodes to minimise the mutual information between the sequence system states and the reports submitted to the FC, rather than always flipping the local decision. © 2017 Elsevier B.V.","Adversarial signal processing; Decision fusion in adversarial setting; Decision fusion in the presence of Byzantines; Factor graph; Message passing algorithm","Complex networks; Sensor networks; Signal processing; Computational burden; Decision fusion; Factor graphs; Message passing algorithm; Multi-sensor networks; Mutual informations; Near-optimal algorithms; Sub-optimal schemes; Message passing",2-s2.0-85021413999
"Pohl D., Bouchachia A., Hellwagner H.","Batch-based active learning: Application to social media data for crisis management",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032873671&doi=10.1016%2fj.eswa.2017.10.026&partnerID=40&md5=7eb701caaa5bf017150891e270ba83ad","Classification of evolving data streams is a challenging task, which is suitably tackled with online learning approaches. Data is processed instantly requiring the learning machinery to (self-)adapt by adjusting its model. However for high velocity streams, it is usually difficult to obtain labeled samples to train the classification model. Hence, we propose a novel online batch-based active learning algorithm (OBAL) to perform the labeling. OBAL is developed for crisis management applications where data streams are generated by the social media community. OBAL is applied to discriminate relevant from irrelevant social media items. An emergency management user will be interactively queried to label chosen items. OBAL exploits the boundary items for which it is highly uncertain about their class and makes use of two classifiers: k-Nearest Neighbors (kNN) and Support Vector Machine (SVM). OBAL is equipped with a labeling budget and a set of uncertainty strategies to identify the items for labeling. An extensive analysis is carried out to show OBAL's performance, the sensitivity of its parameters, and the contribution of the individual uncertainty strategies. Two types of datasets are used: synthetic and social media datasets related to crises. The empirical results illustrate that OBAL has a very good discrimination power. © 2017 Elsevier Ltd","Active learning; Classification; Crisis management; Online learning; Social media","Artificial intelligence; Budget control; Classification (of information); Learning algorithms; Machinery; Nearest neighbor search; Risk management; Social networking (online); Support vector machines; Uncertainty analysis; Active Learning; Active-learning algorithm; Classification models; Crisis management; Individual uncertainties; K nearest neighbor (KNN); Online learning; Social media; E-learning",2-s2.0-85032873671
"Sendra S., Parra L., Lloret J., Tomás J.","Smart system for children's chronic illness monitoring",2018,"Information Fusion",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020911988&doi=10.1016%2fj.inffus.2017.06.002&partnerID=40&md5=f4167afb7989e8ec1143ca1613990301","Sick children need a continuous monitoring, but this involves high costs for the government and for the parents. The use of information and communication technologies (ICT) jointly with artificial intelligence and smart devices can reduce these costs, help the children and assist their parents. This paper presents a smart architecture for children's chronic illness monitoring that will let the caregivers (parents, teachers and doctors) to remotely monitor the health of the children based on the sensors embedded in the smartphones and smart wearable devices. The proposed architecture includes a smart algorithm developed to intelligently detect if a parameter has exceeded a threshold, thus it may imply an emergency or not. To check the correct operation of this system, we have developed a small wearable device that is able to measure the heart rate and the body temperature. We have designed a secure mechanism to stablish a Bluetooth connection with the smartphone. In addition, the system is able to perform the data fusion in both the information packetizing process, which contributes to improve the protocol performance, and in the measured values combination, where it is used a stochastic approach. As a result, our system can fusion data from different sensors in real-time and detect automatically strange situations for sending a warning to the caregivers. Finally, the consumed bandwidth and battery autonomy of the developed device have been measured. © 2017 Elsevier B.V.","Child monitoring; Chronic diseases; eHealth; Smart algorithm; Wearable devices","Data fusion; Diseases; Smartphones; Stochastic systems; Teaching; Wearable sensors; Wearable technology; Bluetooth connections; Chronic disease; Continuous monitoring; Ehealth; Information and Communication Technologies; Proposed architectures; Smart algorithms; Wearable devices; Education",2-s2.0-85020911988
"Attar M., Homaee O., Falaghi H., Siano P.","A novel strategy for optimal placement of locally controlled voltage regulators in traditional distribution systems",2018,"International Journal of Electrical Power and Energy Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030472698&doi=10.1016%2fj.ijepes.2017.09.028&partnerID=40&md5=69132112a14bdbb8a4748dd1e15f11eb","In this paper, an approach for placement of voltage regulators (VRs) in traditional distribution systems by considering a local controller model is presented. The main aims of this paper are controlling the voltage level in its permitted range and decreasing the costs imposed to the distribution system companies, such as costs that stem from power losses, VRs’ investment and maintenance. Genetic algorithm (GA) has been used as a tool to determine the number, location and rated power of VRs. Since in traditional distribution systems, tap position determination of VRs is achieved by local controllers, local controller model is established to determine tap operations. A 70-bus distribution system is considered to prove the value of the presented approach. Effectiveness of the proposed approach and ineffectiveness and infeasibility of conventional approaches are presented in numerical studies. The presented approach allowed to eliminate voltage violation in all load conditions and a reduction of power losses of about 6% for the maximum load level. © 2017 Elsevier Ltd","Distribution systems planning; Genetic algorithm; Local controller; Set point; Tap position; Voltage regulator","Controllers; Genetic algorithms; Conventional approach; Distribution systems; Local controllers; Optimal placements; Position determination; Setpoints; Voltage regulators (VRs); Voltage violation; Voltage regulators",2-s2.0-85030472698
"Silfies M., Kalantarov D., Search C.P.","Robust highly stable multi-resonator refractive index sensor",2018,"Optics Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032866485&doi=10.1016%2fj.optcom.2017.10.015&partnerID=40&md5=2ba9b948627e8215a54f87c34ec57f20","Here we show that a serial array of three evanescently coupled microring resonators can achieve detection limits for refractive index changes in the surrounding environment that are more than 40% better than a single resonator. The improved performance of the three rings occurs when only the central resonator is exposed to the refractive index change and is due to the narrower linewidth that results from the off-resonant coupling to the adjacent resonators. Unlike a single resonator sensor that is usually operated close to critical coupling to maximize the sensitivity, the three resonator configuration is able to achieve superior detection limits over a wide range of inter-resonator couplings. We use this to show that random variations of the couplings resulting from manufacturing variations has a minimal impact on the performance of the three ring system. © 2017","Genetic algorithm; Index measurements; Integrated optics devices; M icro-optical devices","Couplings; Genetic algorithms; Refractometers; Resonators; Semiconductor quantum wells; Index measurements; Integrated optics devices; Manufacturing Variation; Microring resonator; Refractive index changes; Refractive index sensor; Resonator configuration; Surrounding environment; Refractive index",2-s2.0-85032866485
"Sa'ad H.H.Y., Isa N.A.M., Ahmed M.M., Sa'd A.H.Y.","A robust structure identification method for evolving fuzzy system",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032880392&doi=10.1016%2fj.eswa.2017.10.011&partnerID=40&md5=31aa82433c15bef1bcf07d2956b268f0","This paper proposes a robust structure identification method (RSIM) based on incremental partitioning learning. RSIM starts with an open region (initial domain) that covers all input samples. The initial region starts with one fuzzy rule without fuzzy terms and then evolves through incremental partitioning learning, which creates many subregions for system error minimization. The three major contributions of the proposed RSIM are as follows: It locates sufficient splitting points provided through a robust partitioning technique, determines the optimum trade-off between accuracy and complexity through a novel partition-selection technique, minimizes global error through global least square optimization. These contributions offer many remarkable advantages. First, RSIM provides a solution for the curse of dimensionality. Second, RSIM can also be applied to low-dimensional problems. Third, RSIM seeks to produce few rules with low number of conditions to improve system readability. Fourth, RSIM minimizes the number of fired rules. Therefore, RSIM can achieve low-level complexity systems. Three low-dimension and six high-dimension and real-life benchmarks are used to evaluate the performance of RSIM with state-of-the art methods. Although RSIM has high interpretability, the results prove that RSIM exhibits greater accuracy than other existing methods. © 2017 Elsevier Ltd","Error-reducing method; Evolving method; Fuzzy system; Greedy algorithm; Incremental learning","Benchmarking; Economic and social effects; Errors; Fuzzy inference; Fuzzy systems; Structure (composition); Curse of dimensionality; Evolving method; Greedy algorithms; Incremental learning; Incremental partitioning; Partitioning techniques; State-of-the-art methods; Structure identification; Knowledge engineering",2-s2.0-85032880392
"Naldi S.","Solving rank-constrained semidefinite programs in exact arithmetic",2018,"Journal of Symbolic Computation",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025444492&doi=10.1016%2fj.jsc.2017.07.009&partnerID=40&md5=a6db4c27301c06c07fa10944182767e0","We consider the problem of minimizing a linear function over an affine section of the cone of positive semidefinite matrices, with the additional constraint that the feasible matrix has prescribed rank. When the rank constraint is active, this is a non-convex optimization problem, otherwise it is a semidefinite program. Both find numerous applications especially in systems control theory and combinatorial optimization, but even in more general contexts such as polynomial optimization or real algebra. While numerical algorithms exist for solving this problem, such as interior-point or Newton-like algorithms, in this paper we propose an approach based on symbolic computation. We design an exact algorithm for solving rank-constrained semidefinite programs, whose complexity is essentially quadratic on natural degree bounds associated to the given optimization problem: for subfamilies of the problem where the size of the feasible matrix, or the dimension of the affine section, is fixed, the algorithm is polynomial time. The algorithm works under assumptions on the input data: we prove that these assumptions are generically satisfied. We implement it in Maple and discuss practical experiments. © 2017 Elsevier Ltd","Computer algebra; Determinantal varieties; Exact algorithms; Linear matrix inequalities; Polynomial optimization; Rank constraints; Semidefinite programming; Spectrahedra; Sums of squares",,2-s2.0-85025444492
"Li C., Wang L., Sun S., Xia C.","Identification of influential spreaders based on classified neighbors in real-world complex networks",2018,"Applied Mathematics and Computation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032285463&doi=10.1016%2fj.amc.2017.10.001&partnerID=40&md5=b428b4cd41b101daeafb2d76fde9b35a","Identifying the influential spreaders in complex network is a very important topic, which is conducive to deeply understanding the role of nodes in the information diffusion and epidemic spreading among a population. To this end, in this paper, we propose a novel classified neighbors algorithm to quantify the nodal spreading capability and further to differentiate the influence of various nodes. Here, we believe that the contribution of different neighbors to their focal node is different, and then classify the neighbors of the focal node according to the removal order of the neighbor in the process of k-shell decomposition. By assigning different weights for each class of neighbors and summing up the neighbors’ contributions, the spreading capacity of the focal node can be accurately characterized. Through extensive simulation experiments over 9 real-world networks, the weight distribution of different types of neighbors has been optimized, and the results strongly indicate that the current algorithm has the higher ranking accuracy and differentiation extent when compared to other algorithms, such as degree centrality, k-shell decomposition method and mixed degree decomposition approach. Current results can help to greatly reduce the cost of sales promotion, considerably suppress the rumor dissemination and effectively control the outbreak of epidemics within many real-world systems. © 2017 Elsevier Inc.","Classified neighbors; Complex networks; Identification algorithms; Influential spreaders","Sales; Spreaders; Classified neighbors; Decomposition approach; Decomposition methods; Extensive simulations; Identification algorithms; Information diffusion; Real-world networks; Weight distributions; Complex networks",2-s2.0-85032285463
"Claverol M., García A., Garijo D., Seara C., Tejel J.","On Hamiltonian alternating cycles and paths",2018,"Computational Geometry: Theory and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019635718&doi=10.1016%2fj.comgeo.2017.05.009&partnerID=40&md5=750dc1c85aefbfabef0dee1b06598c39","We undertake a study on computing Hamiltonian alternating cycles and paths on bicolored point sets. This has been an intensively studied problem, not always with a solution, when the paths and cycles are also required to be plane. In this paper, we relax the constraint on the cycles and paths from being plane to being 1-plane, and deal with the same type of questions as those for the plane case, obtaining a remarkable variety of results. For point sets in general position, our main result is that it is always possible to obtain a 1-plane Hamiltonian alternating cycle. When the point set is in convex position, we prove that every Hamiltonian alternating cycle with minimum number of crossings is 1-plane, and provide O(n) and O(n2) time algorithms for computing, respectively, Hamiltonian alternating cycles and paths with minimum number of crossings. © 2017 Elsevier B.V.","1-plane graphs; Bicolored point sets; Hamiltonian alternating cycles and paths; Minimum number of crossings","Geometry; 1-plane graphs; Alternating cycle; Point set; Time algorithms; Hamiltonians",2-s2.0-85019635718
"Vilar J., Aneiros G., Raña P.","Prediction intervals for electricity demand and price using functional data",2018,"International Journal of Electrical Power and Energy Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032699257&doi=10.1016%2fj.ijepes.2017.10.010&partnerID=40&md5=9e787cd7e6fcc2d7c7668697b93df518","This paper provides two procedures to obtain prediction intervals for electricity demand and price based on functional data. The proposed procedures are related to one day ahead pointwise forecast. In particular, the first method uses a nonparametric autoregressive model and the second one uses a partial linear semi-parametric model, in which exogenous scalar covariates are incorporated in a linear way. In both cases, the proposed procedures for the construction of the prediction intervals use residual-based bootstrap algorithms, which allows also to obtain estimates of the prediction density. Applications to the Spanish Electricity Market, in year 2012, are reported. This work extends and complements the results of Aneiros et al. (2016), focused on pointwise forecasts of next-day electricity demand and price daily curves. © 2017 Elsevier Ltd","Electricity markets; Functional data; Functional time series forecasting; Load and price; Prediction intervals","Commerce; Costs; Electric power utilization; Forecasting; Auto regressive models; Bootstrap algorithms; Electricity demands; Functional datas; Functional time series; Prediction interval; Semi-parametric modeling; Spanish electricity markets; Power markets",2-s2.0-85032699257
"Hurtado F., Korman M., van Kreveld M., Löffler M., Sacristán V., Shioura A., Silveira R.I., Speckmann B., Tokuyama T.","Colored spanning graphs for set visualization",2018,"Computational Geometry: Theory and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026774013&doi=10.1016%2fj.comgeo.2017.06.006&partnerID=40&md5=2f74ded3bc7c2894439af456c626d143","We study an algorithmic problem that is motivated by ink minimization for sparse set visualizations. Our input is a set of points in the plane which are either blue, red, or purple. Blue points belong exclusively to the blue set, red points belong exclusively to the red set, and purple points belong to both sets. A red-blue-purple spanning graph (RBP spanning graph) is a set of edges connecting the points such that the subgraph induced by the red and purple points is connected, and the subgraph induced by the blue and purple points is connected. We study the geometric properties of minimum RBP spanning graphs and the algorithmic problems associated with computing them. Specifically, we show that the general problem can be solved in polynomial time using matroid techniques. In addition, we discuss more efficient algorithms for the case in which points are located on a line or a circle, and also describe a fast ([Formula presented]ρ+1)-approximation algorithm, where ρ is the Steiner ratio. © 2017 Elsevier B.V.","Approximation; Colored point set; Matroid intersection; Minimum spanning tree; Set visualization","Approximation algorithms; Combinatorial mathematics; Polynomial approximation; Visualization; Algorithmic problems; Approximation; Geometric properties; Matroid intersection; Minimum spanning trees; Point set; Polynomial-time; Steiner ratio; Trees (mathematics)",2-s2.0-85026774013
"Grande E., Imbimbo M., Tomei V.","Structural Optimization of Grid Shells: Design Parameters and Combined Strategies",2018,"Journal of Architectural Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032433218&doi=10.1061%2f%28ASCE%29AE.1943-5568.0000286&partnerID=40&md5=8c97fe004b314ba5aa4921b4a8367c51","The optimization of structures is a tricky process that involves strategies and mathematical algorithms in which the design parameters - introduced in terms of variables, constraint conditions, optimization functions, penalty conditions, and so forth - play very important roles. Their selection and introduction in the optimization process could influence the characteristics and the level of optimization of the derived solutions. This paper describes the roles of design parameters used in different optimization strategies. Moreover, an efficient optimization approach, which combines form-finding (FF), sizing-optimization (SO), and topologic-optimization (TO) strategies in a multilevel process for which design variables and constraint conditions are opportunely selected, is proposed. Numerical analyses referring to some canopy case studies derived from the current literature are also presented in the paper. The comparisons among optimization approaches, featuring FF, SO, and TO optimization strategies performed singularly or in combination throughout a simple sequence of phases, emphasize the effectiveness of the proposed approach for obtaining light structural solutions for grid shells. © 2017 American Society of Civil Engineers.",,"Design; Functions; Constraint conditions; Mathematical algorithms; Multi-level process; Optimization approach; Optimization function; Optimization strategy; Structural solutions; Topologic optimizations; Structural optimization",2-s2.0-85032433218
"Pan D., Wei Y., Fang H., Yang W.","A reliability estimation approach via Wiener degradation model with measurement errors",2018,"Applied Mathematics and Computation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030684156&doi=10.1016%2fj.amc.2017.09.020&partnerID=40&md5=0f57556747f8acfd0dfbd5850d167da6","This paper proposes a reliability estimation approach based on EM algorithm and Wiener processes by considering measurement errors. Firstly, the time-transformed Wiener processes are used to model the degradation process of the product, which simultaneously consider the temporal variability, unit-to-unit heterogeneity and measurement errors. In addition, we obtain the closed-form expressions of some reliability quantities such as reliability function and probability density function of the life. Moreover, the expectation maximization algorithm is adopted to estimate the model parameters effectively. Finally, a numerical example and a practical case study for LED lamps are provided to illustrate the effectiveness and superiority of the presented approach. © 2017 Elsevier Inc.","Expectation maximization; Measurement errors; Reliability; Wiener process","Errors; Image segmentation; Maximum principle; Measurement errors; Random processes; Reliability; Closed-form expression; Degradation process; Expectation - maximizations; Expectation-maximization algorithms; Reliability estimation; Reliability functions; Temporal variability; Wiener process; Probability density function",2-s2.0-85030684156
"Napoli A., Abd-Elhameed W.M.","Numerical Solution of Eighth-order Boundary Value Problems by Using Legendre Polynomials",2018,"International Journal of Computational Methods",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016461153&doi=10.1142%2fS0219876217500839&partnerID=40&md5=a1659bf2cca9933069abb52cde31a7d0","The main aim of this paper is to present and analyze a numerical algorithm for the solution of eighth-order boundary value problems. The proposed solutions are spectral and they depend on a new operational matrix of derivatives of certain shifted Legendre polynomial basis, along with the application of the collocation method. The nonzero elements of the operational matrix are expressed in terms of the well-known harmonic numbers. Numerical examples provide favorable comparisons with other existing methods and ascertain the efficiency and applicability of the proposed algorithm. © 2018 World Scientific Publishing Company.","Boundary value problem; harmonic numbers; Legendre polynomials; spectral methods","Boundary value problems; Computational mechanics; Matrix algebra; Numerical methods; Harmonic number; Legendre polynomials; Numerical algorithms; Numerical solution; Operational matrices; Operational matrix of derivatives; Shifted Legendre polynomials; Spectral methods; Polynomials",2-s2.0-85016461153
"Evans W., Felsner S., Kaufmann M., Kobourov S.G., Mondal D., Nishat R.I., Verbeek K.","Table cartogram",2018,"Computational Geometry: Theory and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021883604&doi=10.1016%2fj.comgeo.2017.06.010&partnerID=40&md5=b56e8868665f0ced4eaff0ff5d9639bc","A table cartogram of a two dimensional m×n table A of non-negative weights in a rectangle R, whose area equals the sum of the weights, is a partition of R into convex quadrilateral faces corresponding to the cells of A such that each face has the same adjacency as its corresponding cell and has area equal to the cell's weight. Such a partition acts as a natural way to visualize table data arising in various fields of research. In this paper, we give a O(mn)-time algorithm to find a table cartogram in a rectangle. We then generalize our algorithm to obtain table cartograms inside arbitrary convex quadrangles, circles, and finally, on the surface of cylinders and spheres. © 2017 Elsevier B.V.","Cartogram; Data visualization; Grid map; Tree map","Data visualization; Cartogram; Convex quadrangles; Convex quadrilaterals; Grid map; Non negatives; Time algorithms; Tree-maps; Trees (mathematics)",2-s2.0-85021883604
"Hashemi S., Aghamohammadi M.R., Sangrody H.","Restoring desired voltage security margin based on demand response using load-to-source impedance ratio index and PSO",2018,"International Journal of Electrical Power and Energy Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030656713&doi=10.1016%2fj.ijepes.2017.09.044&partnerID=40&md5=a0451369572e91d75d731f64c7e8916b","Demand Response (DR) is an active role of end-users in responding to signals coming from the market or to emergency signals coming from system operators, asking for a load reduction to help facing criticalities and reduce blackout risks. Load reduction is one of the typical DR participation methods for large and small consumers which is generally considered as a final defence strategy against system instability when voltage collapse is anticipated and may potentially result in blackout. In this paper, an algorithm concerning load reduction based DR is proposed. Indeed, a two-state algorithm based on finding optimal load reduction pattern and estimating threshold voltage of initiating DR is presented to prevent power system from voltage collapse. In this regard, load-to-source impedance ratio (ZL/XTh) is adopted as an index for evaluating voltage security margin (VSM) and is utilized in an optimization algorithm aimed at obtaining minimum load to be cut down. The proposed approach has been implemented in IEEE 39-bus network demonstrating its effectiveness and applicability. © 2017 Elsevier Ltd","(ZL/XTh) index; Demand response; Optimal load reduction pattern; PSO; Voltage security margin","Outages; Particle swarm optimization (PSO); System stability; Threshold voltage; (ZL/XTh) index; Demand response; Load reduction; Optimization algorithms; Participation methods; Source impedance ratios; Voltage collapse; Voltage security margin; Optimization",2-s2.0-85030656713
"Wan Y., Chen X., Zhang J.","Global and intrinsic geometric structure embedding for unsupervised feature selection",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031130146&doi=10.1016%2fj.eswa.2017.10.008&partnerID=40&md5=4458e821fcc5909e5fab372d608f2ed9","Dimensionality reduction becomes a significant problem due to the proliferation of high dimensional data. Sparse preserving projection (SPP) obtains the intrinsic geometric structure of the data, which contains natural discriminating information, and avoids the selection of parameters as well. However, SPP neglects the global structures since it computes the sparse representation of each data individually. Low rank representation (LRR), another commonly used dimensionality reduction method, finds the lowest rank representation of all data jointly, and is capable of capturing the global structures of data. Therefore in this paper, we propose a method, global and intrinsic geometric structure embedding for unsupervised feature selection (GGEFS), by constructing a low-rank-sparse graph. Our GGEFS method contains the loss of information, the preservation of structural information and the sparse regularization of projection matrix, on which we impose l2,1/2-matrix norm to select sparser and discriminative features. An effective iterative algorithm based on Lagrange Multiplier method is described to solve GGEFS. Extensive experimental results demonstrate that the proposed algorithm outperform several state-of-the-art unsupervised feature selection methods. © 2017 Elsevier Ltd","l2,1/2-Matrix norm; Low rank representation; Sparse preserve projection; Unsupervised feature selection","Clustering algorithms; Geometry; Iterative methods; Lagrange multipliers; Dimensionality reduction; Dimensionality reduction method; Discriminative features; l2,1/2-Matrix norm; Lagrange multiplier method; Low-rank representations; Sparse preserve projection; Unsupervised feature selection; Feature extraction",2-s2.0-85031130146
"Li X., Meng X., Yang X., Wang Y., Yin Y., Peng X., He W., Dong G., Chen H.","Multiple-image encryption via lifting wavelet transform and XOR operation based on compressive ghost imaging scheme",2018,"Optics and Lasers in Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032667246&doi=10.1016%2fj.optlaseng.2017.10.023&partnerID=40&md5=bb97256375f204f227a457a1b9992332","A multiple-image encryption method via lifting wavelet transform (LWT) and XOR operation is proposed, which is based on a row scanning compressive ghost imaging scheme. In the encryption process, the scrambling operation is implemented for the sparse images transformed by LWT, then the XOR operation is performed on the scrambled images, and the resulting XOR images are compressed in the row scanning compressive ghost imaging, through which the ciphertext images can be detected by bucket detector arrays. During decryption, the participant who possesses his/her correct key-group, can successfully reconstruct the corresponding plaintext image by measurement key regeneration, compression algorithm reconstruction, XOR operation, sparse images recovery, and inverse LWT (iLWT). Theoretical analysis and numerical simulations validate the feasibility of the proposed method. © 2017 Elsevier Ltd","Compressive ghost imaging; Lifting wavelet transform; XOR operation","Cryptography; Image processing; Imaging techniques; Inverse problems; Numerical methods; Wavelet transforms; Compression algorithms; Detector arrays; Ghost imaging; Lifting wavelet transforms; Multiple-image encryptions; Scrambled images; Scrambling operations; XOR operation; Image compression",2-s2.0-85032667246
"Ma R., Li X., Dong X., Xia Y.","Wavelength scanning distance interferometry using inflection point retrieval for phase unwrapping",2018,"Optics Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032705787&doi=10.1016%2fj.optcom.2017.10.030&partnerID=40&md5=b2938ec5dff2fd1ebf48f59c5d82465c","A real-time wavelength scanning distance interferometry is proposed. The interference signal generated by the light wavelength modulation is transformed into preliminary conversion signal with the two summarized waveform transformation laws. Inflection points of the interference signal are retrieved with two complementary methods which are discontinuity point judgment (DPJ) and the adjacent null points distance judgment (ANPDJ). Based on the preliminary conversion signal and the retrieved inflection points, the orthogonal signal is constructed. Displacement is calculated after demodulating the phase shift with the orthogonal demodulation algorithm. When millimeters distance is measured, the fluctuation of the measured result is around micrometers in about one hour. The measurement complexity and cost are all decreased, while, ideal measurement results can still be obtained. The approach can be used in a multitude of applications. © 2017 Elsevier B.V.","Distance measurement; Inflection point retrieval; Orthogonal demodulation; Phase unwrapping; Wavelength scanning","Demodulation; Distance measurement; Optical variables measurement; Scanning; Signal interference; Complementary methods; Demodulation algorithms; Discontinuity points; Inflection points; Interference signal; Orthogonal signals; Phase unwrapping; Wavelength scanning; Interferometry",2-s2.0-85032705787
"Ghanekar A., Sun M., Zhang Z., Zheng Y.","Optimal design of wavelength selective thermal emitter for thermophotovoltaic applications",2018,"Journal of Thermal Science and Engineering Applications",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021682222&doi=10.1115%2f1.4036790&partnerID=40&md5=14c1863cbef7e15d9d780ea4b4a09122","We theoretically and numerically demonstrate optimal design of wavelength selective thermal emitter using one-dimensional (1D) and two-dimensional (2D) metal-dielectric gratings for thermophotovoltaic (TPV) applications. Proposed design consists of tungsten (W) and silicon dioxide (SiO2) gratings which can withstand high temperatures. Radiative properties of 1D grating were calculated using a numerical method, while effective medium approximation was used for 2D gratings. Optimal designs were obtained such that output power is maximum for GaSb photovoltaic (PV) cell at emitter temperature of 1500K and radiated energy for longer wavelengths is limited to a low value. A constrained optimization was performed using genetic algorithm (GA) to arrive at optimal design. © 2018 by ASME.",,"Constrained optimization; Genetic algorithms; Low-k dielectric; Numerical methods; Silica; Silicon oxides; Effective Medium Approximation; Emitter temperature; Metal dielectrics; Radiated energies; Radiative properties; Thermophotovoltaic applications; Two Dimensional (2 D); Wavelength-selective; Optimal systems",2-s2.0-85021682222
"Jridi M., Alfalou A.","Real-time and encryption efficiency improvements of simultaneous fusion, compression and encryption method based on chaotic generators",2018,"Optics and Lasers in Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032438932&doi=10.1016%2fj.optlaseng.2017.10.007&partnerID=40&md5=020203cfc26142e11c3aa877afc603a7","In this paper, enhancement of an existing optical simultaneous fusion, compression and encryption (SFCE) scheme in terms of real-time requirements, bandwidth occupation and encryption robustness is proposed. We have used and approximate form of the DCT to decrease the computational resources. Then, a novel chaos-based encryption algorithm is introduced in order to achieve the confusion and diffusion effects. In the confusion phase, Henon map is used for row and column permutations, where the initial condition is related to the original image. Furthermore, the Skew Tent map is employed to generate another random matrix in order to carry out pixel scrambling. Finally, an adaptation of a classical diffusion process scheme is employed to strengthen security of the cryptosystem against statistical, differential, and chosen plaintext attacks. Analyses of key space, histogram, adjacent pixel correlation, sensitivity, and encryption speed of the encryption scheme are provided, and favorably compared to those of the existing crypto-compression system. The proposed method has been found to be digital/optical implementation-friendly which facilitates the integration of the crypto-compression system on a very broad range of scenarios. © 2017 Elsevier Ltd",,"Bandwidth compression; Pixels; Chosen-plaintext attack; Column permutations; Compression system; Computational resources; Efficiency improvement; Encryption algorithms; Initial conditions; Real time requirement; Cryptography",2-s2.0-85032438932
"Ambur R., Rinderknecht S.","Unbalance detection in rotor systems with active bearings using self-sensing piezoelectric actuators",2018,"Mechanical Systems and Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032868590&doi=10.1016%2fj.ymssp.2017.09.006&partnerID=40&md5=9f36c76025c291aea5c1201ca07ee473","Machines which are developed today are highly automated due to increased use of mechatronic systems. To ensure their reliable operation, fault detection and isolation (FDI) is an important feature along with a better control. This research work aims to achieve and integrate both these functions with minimum number of components in a mechatronic system. This article investigates a rotating machine with active bearings equipped with piezoelectric actuators. There is an inherent coupling between their electrical and mechanical properties because of which they can also be used as sensors. Mechanical deflection can be reconstructed from these self-sensing actuators from measured voltage and current signals. These virtual sensor signals are utilised to detect unbalance in a rotor system. Parameters of unbalance such as its magnitude and phase are detected by parametric estimation method in frequency domain. Unbalance location has been identified using hypothesis of localization of faults. Robustness of the estimates against outliers in measurements is improved using weighted least squares method. Unbalances are detected in a real test bench apart from simulation using its model. Experiments are performed in stationary as well as in transient case. As a further step unbalances are estimated during simultaneous actuation of actuators in closed loop with an adaptive algorithm for vibration minimisation. This strategy could be used in systems which aim for both fault detection and control action. © 2017 Elsevier Ltd","Active bearings; Fault diagnosis; Piezoelectric actuators; Rotor systems; Self-sensing; Unbalance detection","Actuators; Adaptive algorithms; Couplings; Failure analysis; Fault detection; Frequency domain analysis; Frequency estimation; Least squares approximations; Mechanical actuators; Piezoelectricity; Active bearing; Detection and controls; Electrical and mechanical properties; Fault detection and isolation; Rotor systems; Self-sensing; Self-sensing actuators; Weighted least squares; Piezoelectric actuators",2-s2.0-85032868590
"Oster K., Jacquemin J., Hardacre C., Ribeiro A.P.C., Elsinawi A.","Further development of the predictive models for physical properties of pure ionic liquids: Thermal conductivity and heat capacity",2018,"Journal of Chemical Thermodynamics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032295247&doi=10.1016%2fj.jct.2017.10.010&partnerID=40&md5=9688e029816fb69964c3799835a22e8c","Efficient, fast and accurate heat transfer units design is currently a ‘hot topic’ due to the demand for more approachable and high-performance-ability materials. This is usually performed by the prediction of physical properties coupled with sufficient structure searching (for example with genetic algorithm). Ionic liquids have been found to be prospective replacement materials in this case; however, the predictive capabilities of existing models still remain poor which affects their practical application significantly. It has also been observed that for some quaternary-phosphonium based carboxylate ILs, the models fail, particularly, for thermal conductivity and heat capacity predictions. The impact of electronic structure on the heat capacity was confirmed by DFT calculations, and this was also included in further refinement. The aim of this work is to assess the predictive capabilities of existing models for thermal conductivity and heat capacity, with further improvements based on more accurate investigated structure characterization (DFT) and reparameterization (group contribution methodology). The ILs chosen for the initial study are trihexyl(tetradecyl)phosphonium-based carboxylate derivatives. © 2017 Elsevier Ltd","Density functional theory; Heat capacity; Ionic liquids; Physical properties prediction; Thermal conductivity","Carboxylation; Characterization; Density functional theory; Density of liquids; Design for testability; Electronic structure; Forecasting; Genetic algorithms; Heat transfer; Ionic liquids; Liquids; Physical properties; Specific heat; Capacity prediction; Group contributions; Heat transfer units; Predictive capabilities; Properties prediction; Reparameterization; Replacement materials; Structure characterization; Thermal conductivity",2-s2.0-85032295247
"Wu Y., Shang P., Li Y.","Multiscale sample entropy and cross-sample entropy based on symbolic representation and similarity of stock markets",2018,"Communications in Nonlinear Science and Numerical Simulation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026551439&doi=10.1016%2fj.cnsns.2017.07.021&partnerID=40&md5=5321e413469511ab5c89931d21e65dce","A modified multiscale sample entropy measure based on symbolic representation and similarity (MSEBSS) is proposed in this paper to research the complexity of stock markets. The modified algorithm reduces the probability of inducing undefined entropies and is confirmed to be robust to strong noise. Considering the validity and accuracy, MSEBSS is more reliable than Multiscale entropy (MSE) for time series mingled with much noise like financial time series. We apply MSEBSS to financial markets and results show American stock markets have the lowest complexity compared with European and Asian markets. There are exceptions to the regularity that stock markets show a decreasing complexity over the time scale, indicating a periodicity at certain scales. Based on MSEBSS, we introduce the modified multiscale cross-sample entropy measure based on symbolic representation and similarity (MCSEBSS) to consider the degree of the asynchrony between distinct time series. Stock markets from the same area have higher synchrony than those from different areas. And for stock markets having relative high synchrony, the entropy values will decrease with the increasing scale factor. While for stock markets having high asynchrony, the entropy values will not decrease with the increasing scale factor sometimes they tend to increase. So both MSEBSS and MCSEBSS are able to distinguish stock markets of different areas, and they are more helpful if used together for studying other features of financial time series. © 2017 Elsevier B.V.","Modified multiscale entropy; Similarity; Stock markets; Symbolic representation","Commerce; Entropy; Financial data processing; Financial markets; Time series; Asian markets; Entropy value; Financial time series; Modified algorithms; Multi-scale entropies; Sample entropy; Similarity; Symbolic representation; Finance",2-s2.0-85026551439
"Baraldi P., Bonfanti G., Zio E.","Differential evolution-based multi-objective optimization for the definition of a health indicator for fault diagnostics and prognostics",2018,"Mechanical Systems and Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032879457&doi=10.1016%2fj.ymssp.2017.09.013&partnerID=40&md5=86868048b8056430a5a1f162e069750a","The identification of the current degradation state of an industrial component and the prediction of its future evolution is a fundamental step for the development of condition-based and predictive maintenance approaches. The objective of the present work is to propose a general method for extracting a health indicator to measure the amount of component degradation from a set of signals measured during operation. The proposed method is based on the combined use of feature extraction techniques, such as Empirical Mode Decomposition and Auto-Associative Kernel Regression, and a multi-objective Binary Differential Evolution (BDE) algorithm for selecting the subset of features optimal for the definition of the health indicator. The objectives of the optimization are desired characteristics of the health indicator, such as monotonicity, trendability and prognosability. A case study is considered, concerning the prediction of the remaining useful life of turbofan engines. The obtained results confirm that the method is capable of extracting health indicators suitable for accurate prognostics. © 2017 Elsevier Ltd","Associative kernel regression; Binary differential evolution; Fault diagnostics; Health indicator; Prognostics; Turbofan engine","Bins; Engines; Evolutionary algorithms; Multiobjective optimization; Optimization; Systems engineering; Turbofan engines; Differential Evolution; Fault diagnostics; Health indicators; Kernel regression; Prognostics; Health",2-s2.0-85032879457
"García Nieto P.J., García-Gonzalo E., Álvarez Antón J.C., González Suárez V.M., Mayo Bayón R., Mateos Martín F.","A comparison of several machine learning techniques for the centerline segregation prediction in continuous cast steel slabs and evaluation of its performance",2018,"Journal of Computational and Applied Mathematics",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015450075&doi=10.1016%2fj.cam.2017.02.031&partnerID=40&md5=efad53aa2f6ce1ab9aae8fb29ddb291f","Centerline segregation in steel cast products is an internal defect that can be very harmful when slabs are rolled in heavy plate mills. Consequently, anticipate its presence is a matter of importance to prevent future risks. The aim of this study was to obtain a predictive model able to perform an early detection of central segregation severity in continuous cast steel slabs. This study presents a novel hybrid algorithm, based on support vector machines (SVMs) in combination with the particle swarm optimization (PSO) technique, for predicting the centerline segregation from operation input parameters determined experimentally in continuous cast steel slabs. This optimization technique involves kernel parameter setting in the SVM training procedure, which significantly influences the regression accuracy. Additionally, a multilayer perceptron network (MLP) and a multivariate adaptive regression splines (MARS) approach, this last method also in combination with the particle swarm optimization (PSO) technique, were fitted to the experimental data with comparison purposes. To this end, the most important physical–chemical parameters of this industrial process are monitored and analyzed. The results of the present study are two-fold. In the first place, the significance of each physical–chemical variables on the segregation is presented through the model. Secondly, some models for predicting segregation are obtained with success. Indeed, regression with optimal hyperparameters was performed and coefficients of determination equal to 0.98 for continuity factor estimation and 0.97 for average width were obtained when this hybrid PSO–SVM-based model with RBF kernel function was applied to the experimental dataset, respectively. Furthermore, the results obtained with the MLP and PSO–MARS-based models are clearly worse than those obtained with the PSO–RBF–SVM-based model. The agreement between experimental data and the model confirmed the good performance of the latter. Finally, conclusions of this innovative research work are exposed. © 2017 Elsevier B.V.","Artificial neural networks (ANNs); Centerline segregation prediction; Continuous cast steel slabs; Multivariate adaptive regression splines (MARS); Particle swarm optimization (PSO); Support vector machines (SVMs)","Chemical analysis; Deep neural networks; Forecasting; Learning algorithms; Learning systems; Neural networks; Particle swarm optimization (PSO); Radial basis function networks; Regression analysis; Segregation (metallography); Slab mills; Splines; Steel metallurgy; Support vector machines; Cast steel; Centerline segregation; Machine learning techniques; Multilayer perceptron network (MLP); Multivariate adaptive regression splines; Particle swarm optimization technique; Physical-chemical parameters; Support vector machine (SVMs); Steel castings",2-s2.0-85015450075
"Colucci R., Leguizamon Cucunuba J.S., Lloyd S.","A recurrence-weighted prediction algorithm for musical analysis",2018,"Communications in Nonlinear Science and Numerical Simulation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028455472&doi=10.1016%2fj.cnsns.2017.08.017&partnerID=40&md5=2aeda14dca08ea5c3930d1c07ba4beba","Forecasting the future behaviour of a system using past data is an important topic. In this article we apply nonlinear time series analysis in the context of music, and present new algorithms for extending a sample of music, while maintaining characteristics similar to the original piece. By using ideas from ergodic theory, we adapt the classical prediction method of Lorenz analogues so as to take into account recurrence times, and demonstrate with examples, how the new algorithm can produce predictions with a high degree of similarity to the original sample. © 2017 Elsevier B.V.","Ergodic theory; Musical analysis; Nonlinear time series analysis","Forecasting; Harmonic analysis; Classical predictions; Degree of similarity; Ergodic theory; Musical analysis; Nonlinear time-series analysis; Original sample; Recurrence time; Weighted predictions; Time series analysis",2-s2.0-85028455472
"Wang W., Zhao H.","Boxed-constraint least mean square algorithm and its performance analysis",2018,"Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031931665&doi=10.1016%2fj.sigpro.2017.10.006&partnerID=40&md5=2b77267ee9bab8762745bc7db5c8246f","In this paper, a novel adaptive filter algorithm, called boxed-constraint least mean square (BXCLMS) algorithm, is proposed for identifying the boxed-constrained system where the parameter to estimate is limited in a range from lower bound to upper bound. The proposed algorithm is derived by using the Karush-Kuhn-Tucker (KKT) conditions and fixed-point iteration algorithm. In addition, the stochastic behavior analysis of proposed algorithm is performed in terms of mean and mean square performance. Finally, simulations are carried out to demonstrate the performance of BXCLMS algorithm and verify the correctness of the analytical results. © 2017 Elsevier B.V.","Boxed-constraint; Fixed-point iteration; Karush-Kuhn-Tucker condition; Least mean square",,2-s2.0-85031931665
"Sousa H.S., Prieto-Castrillo F., Matos J.C., Branco J.M., Lourenço P.B.","Combination of expert decision and learned based Bayesian Networks for multi-scale mechanical analysis of timber elements",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031303286&doi=10.1016%2fj.eswa.2017.09.060&partnerID=40&md5=fc0ef2746d882424f755efd3a8a1be30","The use of Bayesian Networks allows to organize and correlate information gathered from different sources and its optimization may incorporate restrictions adjusting the network based on expert knowledge and network operativeness, in such a way that it may satisfactorily represent a given domain. The main goal of this paper is to study if an optimized learned Bayesian Network may be used as a prior structure for an expert based network of an engineering structural material analysis. The methodology is applied to a database of results from an experimental campaign that focused on the mechanical characterization of timber elements recovered from an early 20th century building. To that study case it is evidenced that through a suitable combination of model averaging and supervision steps it is possible to achieve robust and reliable models to underpin the causal structure of a typical multi-scale timber analysis. © 2017 Elsevier Ltd","Bayesian Networks; Expert systems; Learning algorithms; Multi-scale analysis; Ranking; Timber","Expert systems; Learning algorithms; Timber; Experimental campaign; Expert knowledge; Mechanical analysis; Mechanical characterizations; Model averaging; Multi scale analysis; Ranking; Reliable models; Bayesian networks",2-s2.0-85031303286
"Hu L., Gao W., Zhao K., Zhang P., Wang F.","Feature selection considering two types of feature relevancy and feature interdependency",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032290189&doi=10.1016%2fj.eswa.2017.10.016&partnerID=40&md5=130152106c5e16c0a042e1886690e105","Feature selection based on information theory, which is used to select a group of the most informative features, has extensive application fields such as machine learning, data mining and natural language processing. However, numerous previous methods suffer from two common defects. (1) Feature relevancy is defined without distinguishing candidate feature relevancy and selected feature relevancy. (2) Some interdependent features may be misinterpreted as redundant features. In this study, we propose a feature selection method named Dynamic Relevance and Joint Mutual Information Maximization (DRJMIM) to address these two defects. DRJMIM includes four stages. First, the relevancy is divided into two categories: candidate feature relevancy and selected feature relevancy. Second, according to candidate feature relevancy that is joint mutual information, some redundant features are selected. Third, the redundant features are combined with a dynamic weight to reduce the selection possibility of true redundant features while increasing the false ones. Finally, the most informative and interdependent features are selected and true redundant features are eliminated simultaneously. Furthermore, our method is compared with five competitive feature selection methods on 12 publicly available data sets. The classification results show that DRJMIM performs better than other five methods. Its statistical significance is verified by a paired two-tailed t-test. Meanwhile, DRJMIM obtains few number of selected features when it achieves the highest classification accuracy. © 2017 Elsevier Ltd","Feature interdependency; Feature relevancy; Feature selection; Information theory","Classification (of information); Data mining; Defects; Information theory; Learning algorithms; Learning systems; Natural language processing systems; Application fields; Classification accuracy; Classification results; Feature interdependency; Feature relevancy; Feature selection methods; Joint mutual informations; Statistical significance; Feature extraction",2-s2.0-85032290189
"Tommasel A., Godoy D.","A Social-aware online short-text feature selection technique for social media",2018,"Information Fusion",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019594702&doi=10.1016%2fj.inffus.2017.05.003&partnerID=40&md5=7314a51a50b4631b275c9e90879de89a","Large-scale text categorisation in social environments, characterised by the high dimensionality of feature spaces, is one of the most relevant problems in machine learning and data mining nowadays. Short-texts, which are posted at unprecedented rates, accentuate both the importance of learning tasks and the challenges posed by such large feature space. A collection of social media short-texts does not only provide textual information but also topological information given by the relationships between posts and their authors. The linked nature of social data causes new complementary data dimensions to be added to the feature space, which, at the same time, becomes sparser. Additionally, in the context of social media, posts usually arrive simultaneously in streams, which hinders the deployment of efficient traditional feature selection techniques that assume a feature space fully known in advance. Hence, efficient and scalable online feature selection becomes an important requirement in numerous large-scale social applications. This work presents an online feature selection technique for high-dimensional data based on the integration of two information sources, social and content-based, for the real-time classification of short-text streams coming from social media. It focuses on discovering implicit relations amongst new posts, already known ones and their corresponding authors to identify groups of socially related posts. Then, each discovered group is represented by a set of non-redundant and relevant textual features. Finally, such features are used to train different learning models for classifying newly arriving posts. Extensive experiments conducted on real-world short-texts demonstrate that the proposed approach helps to improve classification results when compared to state-of-the-art and traditional online feature selection techniques. © 2017 Elsevier B.V.","Classification; Micro-blogging communities; Online feature selection","Classification (of information); Clustering algorithms; Data mining; Learning systems; Social networking (online); Text processing; Classification results; High dimensional data; Micro blogging; Online feature selection; Selection techniques; Social applications; Textual information; Topological information; Feature extraction",2-s2.0-85019594702
"Chilipi R., Al Sayari N., Al Hosani K., Fasil M., Beig A.R.","Third order sinusoidal integrator (TOSSI)-based control algorithm for shunt active power filter under distorted and unbalanced voltage conditions",2018,"International Journal of Electrical Power and Energy Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030694439&doi=10.1016%2fj.ijepes.2017.09.026&partnerID=40&md5=3a820ef2dfe7f906c104c7f02b492da9","The performance of a shunt active power filter (SAPF) essentially depends on the accuracy of synchronization and harmonic components extraction. The conventional algorithms such as synchronous reference frame theory and instantaneous reactive power theory work well under sinusoidal and balanced grid voltage conditions. This research is mainly aimed at enhancing the performance of the SAPF when the grid voltages are unbalanced and distorted. The synchronizing signals of the voltage at the point of common coupling (PCC) and system frequency are extracted from the distorted voltages using third order sinusoidal signal integrator (TOSSI) based frequency adaptive pre-filters. In this study, the TOSSI-based filter is used to extract current harmonic components from the load current which increases the selectivity and the dynamic performance of extraction process. The performance of the proposed control approach for a SAPF under distorted and unbalanced voltage conditions is demonstrated through computer simulations and validated by experimental results. © 2017 Elsevier Ltd","Harmonic currents filtering; Point of common coupling; Power quality; Shunt active power filter; Third order sinusoidal signal integrator","Bandpass filters; Electric fault currents; Extraction; Harmonic analysis; Power quality; Harmonic currents; Instantaneous reactive power theory; Point of common coupling; Shunt active power filter (SAPF); Shunt active power filters; Sinusoidal signal integrators; Synchronous reference frame theories; Unbalanced voltage condition; Active filters",2-s2.0-85030694439
"Tariq M.R., Ohno S.","An iterative LMI algorithm for quantization noise reduction in ΔΣ modulators",2018,"Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032022629&doi=10.1016%2fj.sigpro.2017.10.018&partnerID=40&md5=9ae7db0330920a35664df6bfc48af77c","In this paper, we design noise shaping filters for quantization noise reduction in ΔΣ modulators. The design problem for the noise shaping infinite impulse response (IIR) filter in the feedback of the ΔΣ modulator is in non-convex form, which is hard to solve in general. We propose an iterative linear matrix inequality (LMI) algorithm to find a near optimal noise shaping IIR filter by solving the non-convex design problem. The least-squares and the hybrid design are two methods, either of which can serve as a starting point for our iterative LMI algorithm to obtain a near optimal solution. We also compare and analyze the performances of some other noise shaping techniques with our proposed algorithm. A design example for a bandpass ΔΣ modulator based radio frequency transmitter is provided which takes into account the non-ideal behavior of the output analog filter. © 2017 Elsevier B.V.","Noise shaping filter; Non-convex optimization; Quantization; ΔΣ modulator","Convex optimization; IIR filters; Impulse response; Iterative methods; Least squares approximations; Linear matrix inequalities; Noise abatement; Optimization; Radio transmission; Bandpass delta-sigma modulator; Infinite impulse response; Iterative linear matrix inequality; Noise shaping filters; Nonconvex optimization; Quantization; Quantization noise reductions; Radio frequency transmitters; Modulators",2-s2.0-85032022629
"Chen S., Yuan Y., Zhang S., Zhao H.","An efficient NLCS algorithm for maneuvering forward-looking linear array SAR with constant acceleration",2018,"Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031820030&doi=10.1016%2fj.sigpro.2017.10.015&partnerID=40&md5=3f9dea414798e347c537c55c81856174","Forward-looking linear-array synthetic aperture radar (FLLA-SAR), which can overcome the deficiency of the traditional SAR on forward-looking imaging, continues to gain in significance due to the various applications, such as unmanned aerial vehicle (UAV) reconnaissance. To compensate the space-variant characteristic of along-track frequency modulation (FM) rate caused by the high speed maneuvering UAV, an efficient nonlinear chirp scaling (NLCS) algorithm is proposed in this paper. Based on the analysis of novel geometric configuration and the introduction of NLCS operation, the linear-array UAV SAR can reconstruct the 2-D image of the scout area. Finally, the validation of the proposed algorithm is done by exploiting the simulated data based on 3 × 3 array point targets and an airplane scattering model. © 2017 Elsevier B.V.","Acceleration; Forward-looking; Forward-looking linear-array synthetic aperture radar (FLLA-SAR); Nonlinear chirp scaling (NLCS)","Acceleration; Frequency modulation; Maneuverability; Radar; Radar imaging; Unmanned aerial vehicles (UAV); Constant acceleration; Forward looking; Geometric configurations; Linear-array synthetic-aperture radars; Nonlinear chirp scaling; Point targets; Scattering model; Space variants; Synthetic aperture radar",2-s2.0-85031820030
"Ashayerinasab H.A., Nehi H.M., Allahdadi M.","Solving the interval linear programming problem: A new algorithm for a general case",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031032487&doi=10.1016%2fj.eswa.2017.10.020&partnerID=40&md5=9402a5289a989317260e7763ce234127","Based on the binding constraint indices of the optimal solution to the linear programming (LP) model, a feasible system of linear equations can be formed. Because an interval linear programming (ILP) model is the union of numerous LP models, an interval linear equations system (ILES) can be formed, which is the union of these conventional systems. Hence, a new algorithm is introduced in which an arbitrary characteristic model of the ILP model is chosen and solved. The set of indices of its binding constraints is then obtained. This set is used to form and solve an ILES using the enclosure method. If all the components of the interval solutions to this system are strictly non-negative, the optimal solution set (OSS) of the ILP model is determined as the subscription of the zone created by reversing the signs of the binding constraints of the worst model and the binding constraints of the best model. The solutions to several problems obtained by the new algorithm and a Monte Carlo simulation are compared. The proposed algorithm is applicable to large-scale problems. To this end, an ILP model with 270 constraints and 270 variables is solved. © 2017","Interval linear equations system; Interval linear programming; Monte Carlo simulation; Optimal solution set","Bins; Intelligent systems; Linear equations; Monte Carlo methods; Optimal systems; Characteristic model; Conventional systems; Interval linear equations; Interval linear programming; Large-scale problem; Linear programming models; Optimal solution sets; System of linear equations; Linear programming",2-s2.0-85031032487
"Affi M., Derbel H., Jarboui B.","Variable neighborhood search algorithm for the green vehicle routing problem",2018,"International Journal of Industrial Engineering Computations",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025115180&doi=10.5267%2fj.ijiec.2017.6.004&partnerID=40&md5=9993bdf293e77549f7e7434339161a7c","This article discusses the ecological vehicle routing problem with a stop at a refueling station titled Green-Vehicle Routing Problem. In this problem, the refueling stations and the limit of fuel tank capacity are considered for the construction of a tour. We propose a variable neighborhood search to solve the problem. We tested and compared the performance of our algorithm intensively on datasets existing in the literature. © 2018 Growing Science Ltd. All rights reserved. and 2018 by the authors; licensee Growing Science, Canada.","Green vehicle routing problem; Heuristics; Refueling stations; Variable neighborhood search",,2-s2.0-85025115180
"Li R., Li H.A.","A Robust Three-Phase Isenthalpic Flash Algorithm Based on Free-Water Assumption",2018,"Journal of Energy Resources Technology, Transactions of the ASME",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030551343&doi=10.1115%2f1.4037901&partnerID=40&md5=c3d97c0ac9f5780144caccddd2f7541c","Isenthalpic flash is a type of flash calculation conducted at a given pressure and enthalpy for a feed mixture. Multiphase isenthalpic flash calculations are often required in compositional simulations of steam-based enhanced oil recovery methods. Based on a freewater assumption that the aqueous phase is pure water, a robust and efficient algorithm is developed to perform isenthalpic three-phase flashes. Assuming that the feed is stable, we first determine the temperature by solving the energy conservation equation. Then, the stability test on the feed mixture is conducted at the calculated temperature and the given pressure. If the mixture is found unstable, two-phase and three-phase vapor-liquid- aqueous isenthalpic flash can be simultaneously initiated without resorting to stability tests. The outer loop is used to update the temperature by solving the energy conservation equation. The inner loop determines the phase fractions and compositions through a three-phase free-water isothermal flash. A two-phase isothermal flash will be initiated if an open feasible region in the phase fractions appears in any iteration during the threephase flash or any of the ultimately calculated phase fractions from the three-phase flash do not belong to [0,1]. A number of example calculations for water/hydrocarbon mixtures are carried out, demonstrating that the proposed algorithm is accurate, efficient, and robust. © 2018 by ASME.",,"Energy conservation; Enhanced recovery; Isotherms; Mixtures; Oil well flooding; Aqueous phase; Compositional simulations; Energy conservation equations; Enhanced oil recovery; Feasible regions; Phase fractions; Stability tests; Water/hydrocarbon mixtures; Iterative methods",2-s2.0-85030551343
"Xia Y., Douglas S.C., Mandic D.P.","Performance analysis of the deficient length augmented CLMS algorithm for second order noncircular complex signals",2018,"Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032873155&doi=10.1016%2fj.sigpro.2017.10.021&partnerID=40&md5=f83e62970abf9db37fb6d3fb796ae8ec","The augmented complex LMS (ACLMS) algorithm deals with second order noncircular (improper) input signals, based on widely linear modelling and the use of full second order statistical information. In current analyses of ACLMS, it is implicitly or explicitly assumed that the length of the adaptive filter is equal to that of the unknown system's impulse response (optimal model order). In many applications, however, the length of the adaptive filter is smaller than required, the so called deficient length case, which renders the analysis for a ‘sufficient length’ ACLMS inadequate. To this end, we examine the statistical behaviour of the ACLMS algorithm in undermodelling situations. Exact expressions are developed to completely characterise both the transient and steady-state mean and mean square performances of the deficient length ACLMS for general second order noncircular Gaussian input signals. This is achieved using the recently introduced approximate uncorrelating transform (AUT), in order to jointly diagonalise the covariance and pseudo-covariance matrices with a single singular value decomposition (SVD), which both simplifies the analysis and enables a link between the degree of input noncircularity and the steady state mean square error (MSE) performance of the deficient length ACLMS. Simulations in system identification settings support the analysis. © 2017","Approximate uncorrelating transform (AUT); Augmented complex LMS (ACLMS); Deficient length adaptive filter; Mean square analysis; Second order noncircularity (improperness); Widely linear model","Adaptive filters; Covariance matrix; Impulse response; Mathematical transformations; Mean square error; Singular value decomposition; Approximate uncorrelating transforms; Augmented complex LMS; Mean square; Non-circularity; Widely linear modeling; Adaptive filtering",2-s2.0-85032873155
"Kleyntssens T., Esser C., Nicolay S.","An algorithm for computing non-concave multifractal spectra using the Sν spaces",2018,"Communications in Nonlinear Science and Numerical Simulation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029097927&doi=10.1016%2fj.cnsns.2017.08.029&partnerID=40&md5=1f5317a331be47223f91223514e9998e","We present an implementation of a multifractal formalism based on the Sν spaces and show that it effectively gives the right Hölder spectrum in numerous cases. In particular, it allows to recover non-concave spectra, where other multifractal formalisms only lead to the concave hull of the spectra. © 2017 Elsevier B.V.","Multifractal formalism; Non-concave spectrum; Sν spaces; Wavelet","Computer simulation; Numerical analysis; Multifractal formalism; Multifractal spectrum; Non-concave spectrum; Wavelet; Fractals",2-s2.0-85029097927
"Zhou P., Wang T., Lou X., Zhao X., Zhang F., Guo S.","Efficient flush-reload cache attack on scalar multiplication based signature algorithm",2018,"Science China Information Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028314221&doi=10.1007%2fs11432-017-9108-3&partnerID=40&md5=448596b13a930eed5eef14cd7caf39a7",[No abstract available],,,2-s2.0-85028314221
"Bagherinejad J., Shoeib M.","Dynamic capacitated maximal covering location problem by considering dynamic capacity",2018,"International Journal of Industrial Engineering Computations",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025154623&doi=10.5267%2fj.ijiec.2017.5.004&partnerID=40&md5=2e982429120d28a6e0b192d0e58a1e8f","Capacitated maximal covering location problems (MCLP) have considered capacity constraint of facilities but these models have been studied in only one direction. In this paper, capacitated MCLP and dynamic MCLP are integrated with each other and dynamic capacity constraint is considered for facilities. Since MCLP is NP-hard and commercial software packages are unable to solve such problems in a rational time, Genetic algorithm (GA) and bee algorithm are proposed to solve this problem. In order to achieve better performance, these algorithms are tuned by Taguchi method. Sample problems are generated randomly. Results show that GA provides better solutions than bee algorithm in a shorter amount of time. © 2018 Growing Science Ltd. All rights reserved. and 2017 by the authors; licensee Growing Science, Canada.","Bee algorithm; Capacitated MCLP; Dynamic capacity; Genetic algorithm; Multi-period MCLP",,2-s2.0-85025154623
"Yu X., Cui G., Zhang T., Kong L.","Constrained transmit beampattern design for colocated MIMO radar",2018,"Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031998920&doi=10.1016%2fj.sigpro.2017.10.010&partnerID=40&md5=9de83c0beffd9921a50a39403699b465","This paper considers the constrained waveform design for Multiple-Input Multiple-Output (MIMO) radar to synthesize a desired beampattern. Specifically, resorting to SemiDefinite Programming (SDP) related technique, we first minimize Integration Sidelobe Level (ISL) to optimize the waveform covariance matrix enforcing a uniform elemental power restriction as well as a 3dB bandwidth constraint. Then, based on Least Square (LS) approach, we present the existing Cyclic Algorithm (CA) and a new Sequential Iterative Algorithm (SIA) to devise the waveform under a constant modulus constraint, and a similarity constraint to allow the designed waveform sharing the similarity feature with a given reference waveform. In particular, the proposed SIA directly optimizes the objective function and its each iteration turns the multidimensional optimization problem into multiple one-dimensional optimization problems with closed-form solutions. Finally, we assess the effectiveness of the proposed technique through numerical simulations in comparison with CA. © 2017 Elsevier B.V.","Beampattern; Constrained waveform design; Sequential iterative algorithm; Similarity constraint","Covariance matrix; MIMO radar; MIMO systems; Optimization; Radar; Radar signal processing; Waveform analysis; Beam pattern; Constant modulus constraints; Iterative algorithm; Multidimensional optimization; Multiple input multiple output (MIMO) radars; Semi-definite programming; Similarity constraint; Waveform designs; Iterative methods",2-s2.0-85031998920
"Candela V., Falcó A., Romero P.D.","A general framework for a class of non-linear approximations with applications to image restoration",2018,"Journal of Computational and Applied Mathematics",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016505856&doi=10.1016%2fj.cam.2017.03.008&partnerID=40&md5=2b78e5e0ea392ddc9df4a758d7eaf7eb","In this paper, we establish sufficient conditions for the existence of optimal non-linear approximations to a linear subspace generated by a given weakly-closed (non-convex) cone of a Hilbert space. Most non-linear problems have difficulties to implement good projection-based algorithms due to the fact that the subsets, where we would like to project the functions, do not have the necessary geometric properties to use the classical existence results (such as convexity, for instance). The theoretical results given here overcome some of these difficulties. To see this we apply them to a fractional model for image deconvolution. In particular, we reformulate and prove the convergence of a computational algorithm proposed in a previous paper by some of the authors. Finally, some examples are given. © 2017 Elsevier B.V.","Fractional deconvolution; Image restoration; Non-linear approximation; Weakly-closed non-convex cone","Cones; Image reconstruction; Restoration; Computational algorithm; Convex cone; Existence results; Fractional model; Geometric properties; Image de convolutions; Nonlinear approximation; Nonlinear problems; Piecewise linear techniques",2-s2.0-85016505856
"Kang S., Song J.","Feature selection for continuous aggregate response and its application to auto insurance data",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031709477&doi=10.1016%2fj.eswa.2017.10.007&partnerID=40&md5=1ac3ea5df055bd62f42b2766a05014e8","This paper presents new feature selection algorithms for aggregate data analysis. Data aggregation is commonly used when it is not appropriate to model the relationship between a response and explanatory variables at an individual-level. We investigate substantial challenges in analysis for aggregate data. Then, we propose a groupwise feature selection method that addresses (i) the change in dataset depending on the selection of predictor variables, (ii) the presence of potential missing responses, and (iii) the suitability of model selection criteria when comparing models using different datasets. In application to real auto insurance data, we find a set of important predictors to classify the policyholders into some homogeneous risk groups. Our results clearly demonstrate the potential of the proposed feature selection method for aggregate data analysis in terms of flexibility and computational complexity. We expect that the proposed algorithms would be further applied into a wide range of decision-making tasks using aggregate data as they are applicable to any type of data. © 2017 Elsevier Ltd","Aggregate data; Auto insurance; Feature selection; Risk assessment; Tariff classification","Aggregates; Data handling; Decision making; Information analysis; Risk assessment; Aggregate datum; Explanatory variables; Feature selection algorithm; Feature selection methods; Individual levels; ITS applications; Model selection criteria; Predictor variables; Feature extraction",2-s2.0-85031709477
"Miyajima S.","Fast verified computation for the matrix principal pth root",2018,"Journal of Computational and Applied Mathematics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029708100&doi=10.1016%2fj.cam.2017.08.018&partnerID=40&md5=2ac4983c03ff96d16f85214450de960d","A fast iterative algorithm for numerically computing an interval matrix containing the principal pth root of an n×n matrix A is proposed. This algorithm is based on a numerical spectral decomposition of A, and is applicable when a computed eigenvector matrix of A is not ill-conditioned. Particular emphasis is put on the computational efficiency of the algorithm which has only O(n3+pn) operations per iteration. The algorithm moreover verifies the uniqueness of the contained pth root. Numerical results show the efficiency of the algorithm. © 2017 Elsevier B.V.","Matrix pth root; Principal pth root; Verified computation","Efficiency; Iterative methods; Matrix algebra; Eigenvector matrices; Ill-conditioned; Interval matrix; Iterative algorithm; Numerical results; Pth roots; Spectral decomposition; Verified computations; Computational efficiency",2-s2.0-85029708100
"Huang S., Wan Z., Zhang J.","An extended nonmonotone line search technique for large-scale unconstrained optimization",2018,"Journal of Computational and Applied Mathematics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030764355&doi=10.1016%2fj.cam.2017.09.026&partnerID=40&md5=d1733360e42f4899e0f1563d93d29994","In this paper, an extended nonmonotone line search is proposed to improve the efficiency of the existing line searches. This line search is first proved to be an extension of the classical line search rules. On the one hand, under mild assumptions, global convergence and R-linear convergence are established for the new line search rule. On the other hand, by numerical experiments, it is shown that the line search can integrate the advantages of the existing methods in searching for a suitable step-size. Combined with the spectral step-size, a class of spectral gradient algorithms are developed and employed to solve a large number of benchmark test problems from CUTEst. Numerical results show that the new line search is promising in solving large-scale optimization problems, and outperforms the other similar ones as it is combined with a spectral gradient method. © 2017 Elsevier B.V.","Algorithm; Global convergence; Large-scale optimization; Nonmonotone line search",,2-s2.0-85030764355
"Zuo C., Tao T., Feng S., Huang L., Asundi A., Chen Q.","Micro Fourier Transform Profilometry (μFTP): 3D shape measurement at 10,000 frames per second",2018,"Optics and Lasers in Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032446350&doi=10.1016%2fj.optlaseng.2017.10.013&partnerID=40&md5=5ec101fa4257b0ee0d5dc3b240f863ce","Fringe projection profilometry is a well-established technique for optical 3D shape measurement. However, in many applications, it is desirable to make 3D measurements at very high speed, especially with fast moving or shape changing objects. In this work, we demonstrate a new 3D dynamic imaging technique, Micro Fourier Transform Profilometry (μFTP), which can realize an acquisition rate up to 10,000 3D frame per second (fps). The high measurement speed is achieved by the number of patterns reduction as well as high-speed fringe projection hardware. In order to capture 3D information in such a short period of time, we focus on the improvement of the phase recovery, phase unwrapping, and error compensation algorithms, allowing to reconstruct an accurate, unambiguous, and distortion-free 3D point cloud with every two projected patterns. We also develop a high-frame-rate fringe projection hardware by pairing a high-speed camera and a DLP projector, enabling binary pattern switching and precisely synchronized image capture at a frame rate up to 20,000 fps. Based on this system, we demonstrate high-quality textured 3D imaging of 4 transient scenes: vibrating cantilevers, rotating fan blades, flying bullet, and bursting balloon, which were previously difficult or even unable to be captured with conventional approaches. © 2017 Elsevier Ltd","3D shape measurement; Fringe projection profilometry; Micro Fourier Transform Profilometry (μFTP); Phase unwrapping","Contour measurement; Error compensation; Fourier transforms; Hardware; High speed cameras; Imaging techniques; Projection systems; 3-d shape measurement; Compensation algorithm; Conventional approach; Fourier transform profilometry; Frames per seconds; Fringe projection profilometry; Phase unwrapping; Well-established techniques; Profilometry",2-s2.0-85032446350
"Skvortsov A., Ristic B., Kamenev A.","Predicting population extinction from early observations of the Lotka–Volterra system",2018,"Applied Mathematics and Computation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031506587&doi=10.1016%2fj.amc.2017.09.029&partnerID=40&md5=22944383e4550ca7f865a2bac6bfab49","Population extinction is one of the central themes in population biology. We propose a statistical algorithm for long-term prediction of an extinction event in the paradigmatic predator–prey model. The algorithm is based on noisy and sporadic observations of the Lotka–Volterra (LV) system at the early stages of its evolution, when the system is still very far from extinction. There are two stages in the algorithm: first, the unknown parameters (reaction rates) of the LV system are estimated using the Approximate Bayesian Computation method; then an analytical expression for the time-scale of extinction (which involves the estimated parameters) is applied to compute the probability density function of extinction time. The proposed algorithm is validated by numerical simulations for the case of a stochastic LV system specified by the birth–death rate equations. The algorithm can be seen as an initial step in the quest for long-term prediction of rare “catastrophic” events in complex stochastic dynamic systems (epidemics, host-parasite dynamics, enzyme kinetics, dynamic trading, etc.). © 2017","Bayesian estimation; Lotka–Volterra system; Population biology","Bayesian networks; Biology; Control systems; Ecology; Enzyme kinetics; Forecasting; Probability density function; Reaction rates; Stochastic systems; Analytical expressions; Approximate Bayesian; Bayesian estimations; Estimated parameter; Long-term prediction; Statistical algorithm; Stochastic dynamic systems; Volterra systems; Population dynamics",2-s2.0-85031506587
"Yan Z., Zhu T., Peng X., Li X.","Reliability analysis for multi-level stress testing with Weibull regression model under the general progressively Type-II censored data",2018,"Journal of Computational and Applied Mathematics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028853019&doi=10.1016%2fj.cam.2017.05.048&partnerID=40&md5=b890aa8093b8c1b337635a13ba1cede1","In this article, we discuss the problem of point and interval estimates of the Weibull(Extreme value) regression model in a multi-level stress test under the general progressive Type-II censoring. The maximum likelihood and Bayes methods are used for estimating the unknown parameters as well as some lifetime parameters (reliability, hazard rate function and the mean time to failure (MTTF)) at four fixed stress levels. We derive the maximum-likelihood estimates (MLEs) of regression parameters through the Conjugate Gradient (CG) method and their asymptotic variance–covariance matrix. Furthermore, we also obtain the MLEs’ changing tendency of the lifetime parameters along with logarithmic stress level. We propose to apply the Metropolis–Hasting (MH) algorithm to carry out a Bayesian estimation procedure. The Bayesian estimates are obtained under squared error loss (SEL) function, which can be easily extended to other loss function situations. Meanwhile, we obtain the Bayes estimates’ changing tendency of the lifetime parameters along with logarithmic stress level. Finally, one real data set has been analyzed for illustrative purposes. © 2017 Elsevier B.V.","Conjugate Gradient(CG) method; Extreme value distribution; MH algorithm; Parameter estimation; The general progressive Type-II censoring","Bayesian networks; Conjugate gradient method; Covariance matrix; Maximum likelihood; Maximum likelihood estimation; Regression analysis; Reliability analysis; Asymptotic variance; Bayesian estimations; Extreme value distributions; Maximum likelihood estimate; Mean time to failure; Progressive type II censoring; Regression parameters; Weibull regression models; Parameter estimation",2-s2.0-85028853019
"Kang S., Yan H., Dong L., Li C.","Finite-time adaptive sliding mode force control for electro-hydraulic load simulator based on improved GMS friction model",2018,"Mechanical Systems and Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032865415&doi=10.1016%2fj.ymssp.2017.09.009&partnerID=40&md5=99a7513f0b94bbf5b717459c3a929328","This paper addresses the force tracking problem of electro-hydraulic load simulator under the influence of nonlinear friction and uncertain disturbance. A nonlinear system model combined with the improved generalized Maxwell-slip (GMS) friction model is firstly derived to describe the characteristics of load simulator system more accurately. Then, by using particle swarm optimization (PSO) algorithm ​combined with the system hysteresis characteristic analysis, the GMS friction parameters are identified. To compensate for nonlinear friction and uncertain disturbance, a finite-time adaptive sliding mode control method is proposed based on the accurate system model. This controller has the ability to ensure that the system state moves along the nonlinear sliding surface to steady state in a short time as well as good dynamic properties under the influence of parametric uncertainties and disturbance, which further improves the force loading accuracy and rapidity. At the end of this work, simulation and experimental results are employed to demonstrate the effectiveness of the proposed sliding mode control strategy. © 2017 Elsevier Ltd","Electro-hydraulic load simulator; Finite-time adaptive sliding mode control; Force tracking; Improved GMS friction model","Friction; Loads (forces); Particle swarm optimization (PSO); Simulators; Sliding mode control; Tribology; Adaptive sliding mode control; Electro-hydraulics; Force tracking; Friction modeling; Hysteresis characteristics; Nonlinear sliding surface; Nonlinear system modeling; Particle swarm optimization algorithm; Adaptive control systems",2-s2.0-85032865415
"Taha W., Beig A.R., Boiko I.","Quasi optimum PI controller tuning rules for a grid-connected three phase AC to DC PWM rectifier",2018,"International Journal of Electrical Power and Energy Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030468380&doi=10.1016%2fj.ijepes.2017.09.027&partnerID=40&md5=afd0d27d986acc407f4b552ab94dda98","Controller tuning is deemed to be critical when dealing with the voltage oriented control (VOC) as it ultimately defines the system performance. This paper contributes to the tuning issue associated with VOC in three key points. Firstly, an algebraic solution (i.e. PI-parameters) based on the first-order-plus-time-delay (FOPTD) approximations of the plant dynamics is developed, along with approximating relationships and methodology. Secondly, a non-linear multi-criteria optimization algorithm, with PI-controller parameters being the decision variables, is developed in order to achieve the optimum disturbance rejection. The cost function employs a weighted-sum criterion to account for two sources of disturbances: grid voltage sag/dip and load current disturbances, which affect the regulated dc voltage. Simulation results suggest a quasi-optimum system performance, in terms of minimum integral time absolute of the error (ITAE) performance index of the dc-bus voltage, using the FOPTD tuning parameters. Hence, the developed FOPTD approximations demonstrate an accurate linear approximation. Thirdly and consequently, analytic tuning rules for the PI-controllers are proposed. The proposed rules provide quasi-optimum PI-parameters by direct substitution of system parameters in the tuning formulae, rather than solving complex algebraic equations as in the FOPTD tuning approach. The obtained results are verified experimentally. © 2017 Elsevier Ltd","AC-DC power converters; Optimal control; Optimization; PI control; Pulsewidth modulation converters; Space vector pulsewidth modulation","Algebra; Cost functions; Delay control systems; Disturbance rejection; Modulation; Multiobjective optimization; Optimization; Pulse width modulation; Rectifying circuits; Vector spaces; First order plus time delay; Multi-criteria optimization algorithm; Optimal controls; Optimum system performance; PI control; PI controller parameters; Pulsewidth modulation converters; Space vector pulse width modulation; Controllers",2-s2.0-85030468380
"Kouhestani B., Rappaport D., Salomaa K.","Routing in a polygonal terrain with the shortest beacon watchtower",2018,"Computational Geometry: Theory and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019608774&doi=10.1016%2fj.comgeo.2017.05.005&partnerID=40&md5=6b15ffc12a1605d82f7a7b94fedabe9e","In a paper by Biro et al. [3], a novel twist on guarding in art galleries, motivated by geographical greedy routing in sensor networks, is introduced. A beacon is a fixed point that when activated induces a force of attraction that can move points within the environment. The effect of a beacon is similar to standard visibility with some additional properties. The effects of a beacon are asymmetric leading to separate algorithms to compute the “beacon kernel” and “inverse beacon kernel”. In Biro [2] O(n2) time algorithms are given to compute the beacon kernel and the inverse beacon kernel in simple polygons. In this paper we revisit the problem of computing the shortest watchtower to guard a 2D terrain, using the properties of beacons, and we present an O(nlog⁡n) time algorithm that computes the shortest beacon watchtower. In doing this we introduce O(nlog⁡n) time algorithms to compute the beacon kernel and the inverse beacon kernel in a monotone polygon. We also prove that Ω(nlog⁡n) time is a lower bound for computing the beacon kernel of a monotone polygon. © 2017 Elsevier B.V.","Beacon attraction; Beacon kernel; Beacon watchtower; Greedy routing; Inverse beacon kernel","Geometry; Sensor networks; Towers; Beacon attraction; Beacon kernel; Beacon watchtower; Greedy routing; Inverse beacon kernel; Inverse problems",2-s2.0-85019608774
"Huang M.-D., Liu L.","Generating sets for the multiplicative groups of algebras over finite fields and expander graphs",2018,"Journal of Symbolic Computation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024500354&doi=10.1016%2fj.jsc.2017.07.008&partnerID=40&md5=9de581d806d8f7089b90fbf2042aa617","We consider computational problems concerning algebras over finite fields. In particular, we propose an algorithm for finding a small generating set for the multiplicative group of Fq[x]/F, where q=pn is a prime power and F∈Fq[x] is a polynomial not necessarily irreducible. Based on this result, a new set of expander graphs can be explicitly constructed. In addition, we present algorithms for basis construction and decomposition of a given element with respect to the basis. © 2017 Elsevier Ltd","Algebra; Cayley graph; Character sum; Expander graph; Generating set",,2-s2.0-85024500354
"Pedroche F., García E., Romance M., Criado R.","Sharp estimates for the personalized Multiplex PageRank",2018,"Journal of Computational and Applied Mathematics",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015709495&doi=10.1016%2fj.cam.2017.02.013&partnerID=40&md5=4f81ac6f0ffc621154991affe1c87e1a","PageRank can be understood as the stationary distribution of a Markov chain that occurs in a two-layer network with the same set of nodes in both layers: the physical layer and the teleportation layer. In this paper we present some bounds for the extension of this two-layer approach to Multiplex networks, establishing sharp estimates for this Multiplex PageRank and locating the possible values of the personalized PageRank for each node of a network. Several examples are shown to compare the values obtained for both algorithms, the classic and the two-layer PageRank. © 2017 Elsevier B.V.","Centrality measures; Multiplex networks; PageRank","Markov processes; Multiplexing; Centrality measures; Multiplex networks; PageRank; Personalized PageRank; Sharp estimates; Stationary distribution; Two-layer approach; Two-layer network; Network layers",2-s2.0-85015709495
"Hernández-Verón M.A., Martínez E.","Improving the accessibility of Steffensen's method by decomposition of operators",2018,"Journal of Computational and Applied Mathematics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030542268&doi=10.1016%2fj.cam.2017.09.025&partnerID=40&md5=69c0f5ecfb6ff9d368c9575c51e72ec7","Solving equations of the form H(x)=0 is usually done by applying iterative methods. The main interest of this paper is to improve the domain of starting points for Steffensen's method. In general, the accessibility of iterative methods that use divided differences in their algorithms is reduced, since there are difficulties in the choice of starting points to guarantee the convergence of the methods. In particular, by using a decomposition of the operator H and applying a special type of iterative methods, which combine two iterative schemes in the algorithms, we can improve the accessibility of Steffensen's method. Moreover, we analyze the local convergence of the new iterative method proposed in two cases: when H is differentiable and H is non-differentiable. The dynamical properties show that the method also improves the region of accessibility of Steffensen's method for non-differentiable operators. So, we present an alternative for the non-applicability of Newton's method to non-differentiable operators that improves the accessibility of Steffensen's method. The theoretical results are illustrated with numerical experiments. © 2017 Elsevier B.V.","Dynamics; Iterative method; Local convergence; Non-differentiable operator; Steffensen's method","Dynamics; Newton-Raphson method; Transportation; Divided difference; Dynamical properties; Iterative schemes; Local Convergence; Newton's methods; Non-differentiable; Numerical experiments; Steffensen's method; Iterative methods",2-s2.0-85030542268
"Dhimish M., Holmes V., Mehrdadi B., Dales M.","Comparing Mamdani Sugeno fuzzy logic and RBF ANN network for PV fault detection",2018,"Renewable Energy",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032285798&doi=10.1016%2fj.renene.2017.10.066&partnerID=40&md5=a283a20c17e0e174401e92d2d6725908","This work proposes a new fault detection algorithm for photovoltaic (PV) systems based on artificial neural networks (ANN) and fuzzy logic system interface. There are few instances of machine learning techniques deployed in fault detection algorithms in PV systems, therefore, the main focus of this paper is to create a system capable to detect possible faults in PV systems using radial basis function (RBF) ANN network and both Mamdani, Sugeno fuzzy logic systems interface. The obtained results indicate that the fault detection algorithm can detect and locate accurately different types of faults such as, faulty PV module, two faulty PV modules and partial shading conditions affecting the PV system. In order to achieve high rate of detection accuracy, four various ANN networks have been tested. The maximum detection accuracy is equal to 92.1%. Furthermore, both examined fuzzy logic systems show approximately the same output during the experiments. However, there are slightly difference in developing each type of the fuzzy systems such as the output membership functions and the rules applied for detecting the type of the fault occurring in the PV plant. © 2017 Elsevier Ltd","ANN networks; Fault detection; Fuzzy logic systems; Photovoltaic faults; Photovoltaic system",,2-s2.0-85032285798
"Yang J., Liu K.","Detecting buried wave-penetrable scatterers in a two-layered medium",2018,"Journal of Computational and Applied Mathematics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029706602&doi=10.1016%2fj.cam.2017.08.021&partnerID=40&md5=4be8ce31a68100ff1c51f3e03ea202a4","In a two-layered medium, we prove that a buried inhomogeneous scatterer is uniquely determined from the wave field data measured in the upper half-space with respect to many incident point sources. Moreover, we extend the multilevel sampling method in Liu and Zou (2013) to numerically reconstruct the buried scatterer applying only few incident fields and partial scattered data. The extended recovery scheme only involves matrix–vector operations and does not need to solve any large-scale ill-posed linear systems or any optimization process. It is feasible to deal with the scatterers of different features and easy to implement, highly tolerant to noise and computationally quite cheap. We can regard it as an effective yet simple computational method to provide a reliable initial guess for the implementation in existing more accurate and refined optimization-type reconstruction algorithms. © 2017 Elsevier B.V.","Buried scatterer; Inverse scattering; Multilevel sampling method; Two-layered medium; Uniqueness","Geometry; Linear systems; Buried scatterer; Inverse scattering; Multilevel samplings; Two-Layered Medium; Uniqueness; Inverse problems",2-s2.0-85029706602
"Zareie A., Sheikhahmadi A.","A hierarchical approach for influential node ranking in complex social networks",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031792425&doi=10.1016%2fj.eswa.2017.10.018&partnerID=40&md5=3cdf1f59c290a6dca4befdce635feb94","Due to the rapid extension of social networks in recent years, a new potential has emerged for global spreading of messages and effective broadcasting of news. Identification of influential nodes within a network is now seen as a key factor for bringing this potential into action. k-shell is a measure for detection of node influence, and has already been used in some successful algorithms in this field. However, k-shell does not provide enough information about the topological positions of the nodes, and the present paper seeks to present a special hierarchical measure for dealing with this issue. Along with introduction of the above measure, it is shown that it can be used for detecting and ranking node influence. The experiments done on real-world and artificial networks demonstrate that the proposed approach can rank the influence of nodes more accurately than other approaches. © 2017 Elsevier Ltd","Complex network; Influential nodes; k-Shell centrality; Node ranking; Spreading capability","Information systems; Mathematical models; Artificial networks; Complex social networks; Hierarchical approach; Influential nodes; K-shells; Key factors; Node ranking; Spreading capability; Complex networks",2-s2.0-85031792425
"Misu T.","Situated reference resolution using visual saliency and crowdsourcing-based priors for a spoken dialog system within vehicles",2018,"Computer Speech and Language",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032019500&doi=10.1016%2fj.csl.2017.09.001&partnerID=40&md5=c466f0313760af07c0313fb16d5fac21","In this paper, we address issues in situated language understanding in a moving car. More specifically, we propose a reference resolution method to identify user queries about specific target objects in their surroundings. We investigate methods of predicting which target object is likely to be queried given a visual scene and what kind of linguistic cues users naturally provide to describe a given target object in a situated environment. We propose methods to incorporate the visual saliency of the visual scene as a prior. Crowdsourced statistics of how people describe an object are also used as a prior. We have collected situated utterances from drivers using our research system, which was embedded in a real vehicle. We demonstrate that the proposed algorithms improve target identification rate by 15.1% absolute over the baseline method that does not use visual saliency-based prior and depends on public database with a limited number of category information. © 2018 Elsevier Ltd","Crowdsourcing; In-car interaction; Multimodal interaction; Situated dialog; Visual saliency","Crowdsourcing; Speech recognition; Baseline methods; Language understanding; Multi-Modal Interactions; Reference resolution; Situated dialog; Spoken dialog systems; Target identification; Visual saliency; Visualization",2-s2.0-85032019500
"Yahya Bey N.","Extraction of buried multidimensional signals and images in mixed sources of noise",2018,"Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030450871&doi=10.1016%2fj.sigpro.2017.09.022&partnerID=40&md5=26b62fc88dc095cdef41e324f03e54fc","In this paper, multi-dimensional extension and additional properties of already proposed extraction methods of buried one-dimensional signals in noise are developed. It is shown that heavy denoising uses no a-priori information, works without averaging or smoothing in the time or frequency domain with computation times much lower than those needed by ensemble averaging operations. Extraction is achieved independently of the nature of noise and locations of its spectral extent. Heavy denoising performances, comparative results with wavelets and other denoising algorithms, are illustrated via buried two-dimensional signals and images in noise. Proposed restoration of buried images in mixed sources of noise is able to preserve image information carried by fine structure, edges and texture. This ability opens novel perspectives for image restoration. © 2017 Elsevier B.V.","Buried images; Buried signals; Colored noise; Denoising; Image denoising; Image restoration; Multi-dimensional Fourier analysis; Shot noise; Wavelet denoising; White noise","Extraction; Fourier analysis; Frequency domain analysis; Image denoising; Image reconstruction; Restoration; White noise; Buried images; Colored noise; De-noising; Multi dimensional; Wavelet denoising; Shot noise",2-s2.0-85030450871
"Xia Y., Liu C., Da B., Xie F.","A novel heterogeneous ensemble credit scoring model based on bstacking approach",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031790752&doi=10.1016%2fj.eswa.2017.10.022&partnerID=40&md5=79a1ce6b6866c403f9bb75e675389bf6","In recent years, credit scoring has become an efficient tool that allows financial institutions to differentiate their potential default borrowers. Accordingly, researchers have developed a myriad of approaches, including statistical and artificial intelligence techniques, to fulfill the task of credit scoring. Recent studies have shown that ensemble methods, which combine multiple algorithms that process different hypotheses to form a new hypothesis, generally outperform the other credit scoring approaches. In this paper, we propose a novel heterogeneous ensemble credit model that integrates the bagging algorithm with the stacking method. The proposed model differs from the extant ensemble credit models in three aspects, namely, pool generation, selection of base learners, and trainable fuser. Four popular evaluation metrics, including accuracy, area under the curve (AUC), AUC-H measure, and Brier score, are employed to measure the performance of alternative models. To confirm the efficiency of the proposed bstacking approach, a wide range of models, including individual classifiers, homogeneous ensemble model, and heterogeneous ensemble model, are introduced as benchmarks. We also provided a discussion on the accurate yet complex credit scoring model (e.g., bstacking) from a regulatory perspective. © 2017 Elsevier Ltd","Bagging; Credit scoring; Heterogeneous ensemble; Stacking","Information systems; Area under the curves; Artificial intelligence techniques; Bagging; Credit scoring; Financial institution; Heterogeneous ensembles; Individual classifiers; Stacking; Mathematical models",2-s2.0-85031790752
"Guo Y., Wang A., Wang W.","Multi-source phase retrieval from multi-channel phaseless STFT measurements",2018,"Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030462500&doi=10.1016%2fj.sigpro.2017.09.026&partnerID=40&md5=b0864b710a6d62a0fecf579d99696e93","In a recent study, it was shown that, given only the magnitude of the short-time Fourier transform (STFT) of a signal, it is possible to recover the phase information of its STFT under certain conditions. However, this is only investigated for the single-source scenario. In this paper, we extend this work and formulate a multi-source phase retrieval problem where multi-channel phaseless STFT measurements are given as input. We then present a robust multi-source phase retrieval (RMSPR) algorithm based on a gradient descent (GD) algorithm by minimizing a non-convex loss function and independent component analysis (ICA). An improved least squares (LS) loss function is presented to find the initialization of the GD algorithm. Experimental evaluation has been conducted to show that under appropriate conditions the proposed algorithm can explicitly recover the phase of the sources, the mixing matrix, and the sources simultaneously, from noisy measurements. © 2017 Elsevier B.V.","Independent component analysis (ICA); Multi-source phase retrieval; Non-convex optimization; Short-time Fourier transform (STFT)","Convex optimization; Optimization; Experimental evaluation; Independent component analysis(ICA); Noisy measurements; Non-convex loss function; Nonconvex optimization; Phase information; Phase retrieval; Short time Fourier transforms; Independent component analysis",2-s2.0-85030462500
"Yadav D., Chowdary C.R.","OOIMASP: Origin based association rule mining with order independent mostly associated sequential patterns",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031746647&doi=10.1016%2fj.eswa.2017.10.015&partnerID=40&md5=8ed2953c4ec9732643f69181ed942a77","Efficient mining of association rules on a transaction dataset is an interesting and a challenging problem. The state-of-the-art MASP algorithm is dependent on the order of items in the transaction. We propose OOIMASP algorithm, which has two novel properties- 1) order independence and 2) it takes into consideration the origin of items to calculate unbiased support and unbiased confidence values. Order dependence is one of the drawbacks of MASP. OOIMASP addresses this issue by rearranging the items in transactions using a greedy frequency based approach. We compare the performance of our system with MASP on five synthetic data sets and three public data sets. The results show that our proposed approach outperforms the MASP in both the comparison metrics, i.e., the number of association rules generated and the length of the longest association rule. Both these metrics are important to evaluate the performance of an algorithm. On an average, OOIMASP algorithm generates 632% longer rules and 457% more association rules than MASP algorithm. The disadvantage of the proposed algorithm is, it requires more computational resources in terms of time, approximately 5 times more than MASP. We claim that the extra information extracted using our method compensates for the increase in time complexity as compared to MASP. The proposed method produces multiple trees which can be very useful in the visual analysis of data. © 2017 Elsevier Ltd","Association rule mining; Mostly associated sequential patterns; Unbiased confidence; Unbiased support","Association rules; Information analysis; Comparison metrics; Computational resources; Frequency-based approaches; Mining of association rules; Order independents; Sequential patterns; Synthetic datasets; Unbiased confidence; Trees (mathematics)",2-s2.0-85031746647
"Au S.-K., Brownjohn J.M.W., Mottershead J.E.","Quantifying and managing uncertainty in operational modal analysis",2018,"Mechanical Systems and Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032875774&doi=10.1016%2fj.ymssp.2017.09.017&partnerID=40&md5=758ad9af2c093ce55143aa5ed25b53c4","Operational modal analysis aims at identifying the modal properties (natural frequency, damping, etc.) of a structure using only the (output) vibration response measured under ambient conditions. Highly economical and feasible, it is becoming a common practice in full-scale vibration testing. In the absence of (input) loading information, however, the modal properties have significantly higher uncertainty than their counterparts identified from free or forced vibration (known input) tests. Mastering the relationship between identification uncertainty and test configuration is of great interest to both scientists and engineers, e.g., for achievable precision limits and test planning/budgeting. Addressing this challenge beyond the current state-of-the-art that are mostly concerned with identification algorithms, this work obtains closed form analytical expressions for the identification uncertainty (variance) of modal parameters that fundamentally explains the effect of test configuration. Collectively referred as ‘uncertainty laws’, these expressions are asymptotically correct for well-separated modes, small damping and long data; and are applicable under non-asymptotic situations. They provide a scientific basis for planning and standardization of ambient vibration tests, where factors such as channel noise, sensor number and location can be quantitatively accounted for. The work is reported comprehensively with verification through synthetic and experimental data (laboratory and field), scientific implications and practical guidelines for planning ambient vibration tests. © 2017 Elsevier Ltd","Ambient vibration test; Asymptotics; BAYOMA; Operational modal analysis; Signal-to-noise ratio; Uncertainty law","Damping; Modal analysis; Professional aspects; Signal to noise ratio; Testing; Uncertainty analysis; Ambient vibration test; Asymptotics; BAYOMA; Operational modal analysis; Uncertainty law; Vibration analysis",2-s2.0-85032875774
"Fabila-Monroy R., García A., Hurtado F., Jaume R., Pérez-Lantero P., Saumell M., Silveira R.I., Tejel J., Urrutia J.","Colored ray configurations",2018,"Computational Geometry: Theory and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019352579&doi=10.1016%2fj.comgeo.2017.05.008&partnerID=40&md5=e92efac25624ca66985541dcdc79f1e9","We study the cyclic color sequences induced at infinity by colored rays with apices being a given balanced finite bichromatic point set. We first study the case in which the rays are required to be pairwise disjoint. We derive a lower bound on the number of color sequences that can be realized from any such fixed point set and examine color sequences that can be realized regardless of the point set, exhibiting negative examples as well. We also provide a tight upper bound on the number of configurations that can be realized from a point set, and point sets for which there are asymptotically less configurations than that number. In addition, we provide algorithms to decide whether a color sequence is realizable from a given point set in a line or in general position. We address afterwards the variant of the problem where the rays are allowed to intersect. We prove that for some configurations and point sets, the number of ray crossings must be Θ(n2) and study then configurations that can be realized by rays that pairwise cross. We show that there are point sets for which the number of configurations that can be realized by pairwise-crossing rays is asymptotically smaller than the number of configurations realizable by pairwise-disjoint rays. We provide also point sets from which any configuration can be realized by pairwise-crossing rays and show that there is no configuration that can be realized by pairwise-crossing rays from every point set. © 2017 Elsevier B.V.","Circular sequences; Colored rays; Enumerative problems; Ray configurations; Red and blue points in the plane","Color; Blue points; Circular sequences; Colored rays; Enumerative problems; Ray configurations; Geometry",2-s2.0-85019352579
"Andrzejczak G.","Spline reproducing kernels on R and error bounds for piecewise smooth LBV problems",2018,"Applied Mathematics and Computation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030182847&doi=10.1016%2fj.amc.2017.09.021&partnerID=40&md5=d7c6db858a3fcc3a41affac5f3422b20","Reproducing kernel method for approximating solutions of linear boundary value problems is valid in Hilbert spaces composed of continuous functions, but its convergence is not satisfactory without additional smoothness assumptions. We prove 2nd order uniform convergence for regular problems with coefficient piecewise of Sobolev class H2. If the coefficients are globally of class H2, more refined phantom boundary NSC-RKHS method is derived, and the order of convergence rises to 3 or 4, according to whether the problem is piecewise of class H3 or H4. The algorithms can be successfully applied to various non-local linear boundary conditions, e.g. of simple integral form. The paper contains also a new explicit formula for general spline reproducing kernels in Hm[a, b], if the inner product 〈f,g〉m,ξ=∑i&lt;mf(i)(ξ)g(i)(ξ)+∫f(m)g(m) depends on any fixed reference point ξ ∈ [a, b]. The piecewise NSC–RKHS methods are then applied to two example regular LBV problems in H3 and H5. Exactness of the resulting numerical solutions, the degree of convergence, and their dependency of the reference point ξ ∈ [a, b] are presented in attached figures. © 2017 Elsevier Inc.","Integral boundary conditions; interpolating splines; Linear boundary value problems; Normal spline collocation method; Numerical solutions; Ordinary differential equations; Reproducing kernels; Sobolev spaces","Boundary conditions; Boundary value problems; Differential equations; Error analysis; Numerical methods; Ordinary differential equations; Plates (structural components); Sobolev spaces; Integral boundary conditions; Linear boundary value problem; Numerical solution; Reproducing kernel; Spline collocation methods; Interpolation",2-s2.0-85030182847
"Sahoo B., Samantaray S.R.","An enhanced fault detection and location estimation method for TCSC compensated line connecting wind farm",2018,"International Journal of Electrical Power and Energy Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032442052&doi=10.1016%2fj.ijepes.2017.10.022&partnerID=40&md5=16b1f11f5a500b8558095c2f6c7f9185","The paper presents a new approach to enhance the fault detection, and location determination based on travelling waves using Fast Discrete S-transform (FDST) for TCSC compensated lines connecting to wind farm. The FDST is applied to the modal components of measured currents at each terminal to detect the arrival time of the first travelling wave (transient) produced by the fault. The proposed method includes detecting the terminal with fastest arrival time of wave to identify the faulted section and estimate the fault location by using proper distance index. The simulation results have demonstrated good performance of the proposed scheme under different fault locations, fault resistances, fault inception angles, fault types, faulted sections, variations in TCSC parameters and changing wind speeds. The performance validation on the real-time digital simulator (RTDS) platform enhances the applicability of the proposed protection scheme for the TCSC based compensated line integrated with wind farm. The performance comparison with the conventional travelling wave fault location algorithms using Continuous Wavelet Transform (CWT) shows potential ability of the proposed method. © 2017 Elsevier Ltd","Doubly-fed induction generator (DFIG) windfarm; Fast discrete S-transform; Fault location; Phasor measurement unit (PMU); Real-time digital simulator (RTDS); TCSC compensated line; Travelling wave; Wide area protection (WAP)","Asynchronous generators; Electric equipment protection; Electric fault currents; Electric fault location; Electric utilities; Location; Mathematical transformations; Phasor measurement units; Units of measurement; Wave transmission; Wavelet transforms; Wind power; Real time digital simulator; S transforms; TCSC compensated line; Travelling waves; Wide area protection; Wind farm; Fault detection",2-s2.0-85032442052
"Wang W., Fan S.","Attacking OpenSSL ECDSA with a small amount of side-channel information",2018,"Science China Information Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028777862&doi=10.1007%2fs11432-016-9030-0&partnerID=40&md5=0f0ec6da2b750395f06fda8b7e555fa3","In this work, we mount a lattice attack on the ECDSA signatures implemented by the latest version of OpenSSL which uses the windowed non-adjacent form method to implement the scalar multiplication. We first develop a new way of extracting information from the side-channel results of the ECDSA signatures. Just given a small fraction of the information about a side-channel result denoted as double-and-add chain, we take advantage of the length of the chain together with positions of two non-zero digits to recover information about the ephemeral key. Combining the information of both the most significant digits and the least significant bits, we are able to gain more information about the ephemeral key. The problem of recovering ECDSA secret key is then translated to the hidden number problem which can be solved by lattice reduction algorithms. Our attack is mounted to the secp256k1 curve, and the result shows that 85 signatures would be enough to recover the secret key, which is better than the result that previous attack gained only utilizing the information extracted from the least significant bits, using about 200 signatures to recover the secret key. © 2017, Science China Press and Springer-Verlag GmbH Germany.","ECDSA; Flush+Reload attack; hidden number problem; lattice attack; OpenSSL; windowed non-adjacent form","Chains; Recovery; Side channel attack; ECDSA; Flush+Reload attack; hidden number problem; lattice attack; Non-adjacent form; Open SSL; Cryptography",2-s2.0-85028777862
"Hussain A., Aslam M., Arif S.M.","A standards-based approach for Auto-drawing single line diagram of multivendor smart distribution systems",2018,"International Journal of Electrical Power and Energy Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032875913&doi=10.1016%2fj.ijepes.2017.10.003&partnerID=40&md5=7825c23fd510a47091e1d65a1056f122","This paper presents a technique for the auto-drawing of single line diagram (SLD) of multivendor distribution systems. SLDs are used in electric power system visualization, which is very important for the control and monitoring of distribution systems for fault location, identification, separation, and service restoration. The task of auto-drawing an SLD for distribution systems has been made complicated due to the introduction of distributed generations and multivendor distribution systems. This paper proposes an algorithm for auto-drawing SLD, based on a ternary tree and collision avoidance algorithm. In addition, a standards-based approach is suggested for incorporating different distribution system planned and run by different vendors. Initially, client converts the distribution system diagram to a standard model, which is then sent to the server. The server draws the SLD by using the auto-SLD drawing algorithm and sends it back to the client, which can be verified by the client. © 2017 Elsevier Ltd","Electrical power systems; Graphical representation; Graphical visualization; Information visualization; Single line diagrams; Visualization techniques","Electric power distribution; Electric power systems; Information systems; Visualization; Electrical power system; Graphical representations; Graphical visualization; Information visualization; Single-line diagram; Visualization technique; Electric power system control",2-s2.0-85032875913
"Kim S., Palazzolo A.B.","Bifurcation Analysis of a Rotor Supported by Five-Pad Tilting Pad Journal Bearings Using Numerical Continuation",2018,"Journal of Tribology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030482428&doi=10.1115%2f1.4037699&partnerID=40&md5=00e30f23cce31b568288527ee0d0c2e0","This paper presents analytical bifurcations analysis of a ""Jeffcott"" type rigid rotor supported by five-pad tilting pad journal bearings (TPJBs). Numerical techniques such as nonautonomous shooting/arc-length continuation, Floquet theory, and Lyapunov exponents are employed along with direct numerical integration (NI) to analyze nonlinear characteristics of the TPJB-rotor system. A rocker pivot type five-pad TPJB is modeled with finite elements to evaluate the fluid pressure distribution on the pads, and the integrated fluid reaction force and moment are utilized to determine coexistent periodic solutions and bifurcations scenarios. The numerical shooting/continuation algorithms demand significant computational workload when applied to a rotor supported by a finite element bearing model. This bearing model may be significantly more accurate than the simplified infinitely short-/long-bearing approximations. Consequently, the use of efficient computation techniques such as deflation and parallel computing methods is applied to reduce the execution time. Loci of bifurcations of the TPJB-rigid rotor are determined with extensive numerical simulations with respect to both rotor spin speed and unbalance force magnitude. The results show that heavily loaded bearings and/or high unbalance force may induce consecutive transference of response in forms of synchronous to subsynchronous, quasi-periodic responses, and chaotic motions. It is revealed that the coexistent responses and their solution manifolds are obtainable and stretch out with selections of pad preload, pivot offset, and lubricant viscosity so that the periodic doubling bifurcations, saddle node bifurcations, and corresponding local stability are reliably determined by searching parameter sets. In case the system undergoes an aperiodic state, the rate of divergence/convergence of the attractor is examined quantitatively by using the maximum Lyapunov exponent (MLE). © Copyright 2017 by ASME.",,"Bifurcation (mathematics); Computation theory; Differential equations; Finite element method; Journal bearings; Lyapunov functions; Lyapunov methods; Computational workload; Maximum Lyapunov exponent; Nonlinear characteristics; Numerical continuation; Numerical integrations; Quasi-periodic response; Saddle node bifurcation; Tilting pad journal bearing; Rigid rotors",2-s2.0-85030482428
"Deng W., Xu J., Zhao S.","On developing stable finite element methods for pseudo-time simulation of biomolecular electrostatics",2018,"Journal of Computational and Applied Mathematics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030328760&doi=10.1016%2fj.cam.2017.09.004&partnerID=40&md5=cdf0ee509a140203fb5e376184209d45","The Poisson–Boltzmann Equation (PBE) is a widely used implicit solvent model for the electrostatic analysis of solvated biomolecules. To address the exponential nonlinearity of the PBE, a pseudo-time approach has been developed in the literature, which completely suppresses the nonlinear instability through an analytic integration in a time splitting framework. This work aims to develop novel Finite Element Methods (FEMs) in this pseudo-time framework for solving the PBE. Two treatments to the singular charge sources are investigated, one directly applies the definition of the delta function in the variational formulation and the other avoids numerical approximation of the delta function by using a regularization formulation. To apply the proposed FEMs for both PBE and regularized PBE in real protein systems, a new tetrahedral mesh generator based on the minimal molecular surface definition is developed. With a body-fitted mesh, the proposed pseudo-time FEM solvers are more accurate than the existing pseudo-time finite difference solvers. Moreover, based on the implicit Euler time integration, the proposed FEMs are unconditionally stable for solvated proteins with source singularities and non-smooth potentials, so that they could be more efficient than the existing pseudo-time discontinuous Galerkin method based on the explicit Euler time stepping. Due to the unconditional stability, the proposed pseudo-time algorithms are free of blow-up or overflow issues, without resorting to any thresholding technique. Numerical experiments of several benchmark examples and free energy calculations of protein systems are conducted to validate the stability, accuracy, and robustness of the proposed PBE solvers. © 2017 Elsevier B.V.","Electrostatic free energy; Finite element method; Molecular surface; Poisson–Boltzmann equation; Pseudo-time approach; Regularized Poisson–Boltzmann equation","Boltzmann equation; Control nonlinearities; Delta functions; Electrostatics; Free energy; Galerkin methods; Mesh generation; Poisson equation; Proteins; Biomolecular electrostatics; Electrostatic free energy; Exponential nonlinearity; Free-energy calculations; Molecular surfaces; Numerical approximations; Pseudo-time approaches; Time-discontinuous Galerkin methods; Finite element method",2-s2.0-85030328760
"Lin J., Su Y., Cheng Y., Lu C., Zhu L., Huang H., Liu Y.","A robust complex-domain state estimator using synchrophasor measurements",2018,"International Journal of Electrical Power and Energy Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032291818&doi=10.1016%2fj.ijepes.2017.10.020&partnerID=40&md5=97fe4dc5c990f3ca3306dcba45b8eb6c","Phasor measurement units (PMUs) have been widely deployed in modern power grids, which provides a great opportunity for high-precision and real-time power system state estimation. If power networks are completely observable by PMUs, linear state estimation can be achieved with massive synchronous data. In this paper, the analysis of phasor error is presented and a complex number weighted least squares (CWLS) algorithm for state estimation is proposed, which shows high computational efficiency and stronger robustness to phasor errors. Meanwhile, self-adaptive weight and bad data identification techniques are developed to enhance the CWLS's performance. Test results on various IEEE test systems and the realistic power grid validate the effectiveness and superiority of the proposed CWLS algorithm, outperforming the conventional weighted least squares (WLS) state estimation method as well as other existing industrial-grade approaches. © 2017 Elsevier Ltd","Complex domain; Phasor measurement units (PMUs); State estimation","Complex networks; Computational efficiency; Electric power transmission networks; Estimation; Least squares approximations; Phase measurement; State estimation; Units of measurement; Bad data identifications; Complex domains; Linear state estimation; Phasor measurement unit (PMUs); Real-time power system; State estimation methods; Synchrophasor measurements; Weighted least squares; Phasor measurement units",2-s2.0-85032291818
"Kuptsov P.V., Kuznetsov S.P.","Numerical test for hyperbolicity in chaotic systems with multiple time delays",2018,"Communications in Nonlinear Science and Numerical Simulation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027869758&doi=10.1016%2fj.cnsns.2017.08.016&partnerID=40&md5=bf8f9636f33465ee3777bb566ae1c748","We develop an extension of the fast method of angles for hyperbolicity verification in chaotic systems with an arbitrary number of time-delay feedback loops. The adopted method is based on the theory of covariant Lyapunov vectors and provides an efficient algorithm applicable for systems with high-dimensional phase space. Three particular examples of time-delay systems are analyzed and in all cases the expected hyperbolicity is confirmed. © 2017 Elsevier B.V.","Delay differential equations; Fast method of angles; Hyperbolic chaos; Hyperbolicity test","Chaos theory; Chaotic systems; Delay control systems; Differential equations; Phase space methods; Vector spaces; Covariant lyapunov vectors; Delay differential equations; Fast methods; High dimensional phase space; Hyperbolic chaos; Hyperbolicity; Multiple time delay; Time delay feedbacks; Time delay",2-s2.0-85027869758
"Wan C., Zhu Y., Yu J., Shen Y.","SMOPAT: Mining semantic mobility patterns from trajectories of private vehicles",2018,"Information Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032815148&doi=10.1016%2fj.ins.2017.10.043&partnerID=40&md5=b08e5c0e7d7ac3252518a37221d0e0c1","With the increasing use of private vehicles with positioning services, GPS trajectory data of vehicles has become one of the major sources of big data about urban life. Existing studies on mobility pattern mining from trajectories share a common limitation, i.e., they fail to capture the semantics of trajectories. Automatic derivation of semantic information for every trajectory is a challenging task. In this paper, we propose an approach, called SMOPAT (Semantic MObility PATterns), for mining spatial-temporal semantic mobility patterns from trajectories of private vehicles. We design a probabilistic generative model with latent variables to characterize the semantic mobility of vehicles. Based on the model, SMOPAT labels each location in a trajectory with a visit purpose by using a polynomial-time dynamic programming algorithm. It then employs an efficient algorithm to find the most frequent semantic mobility patterns. We evaluate our approach on a large data set of real trajectories of private vehicles spanning a time duration of over ten months with 114 million records in Shanghai, China. The experimental results show that our approach produces meaningful patterns and outperforms the two competing methods in terms of diversity, coherence, and coverage. © 2017 Elsevier Inc.","Private vehicles; Semantic mobility pattern; Trajectory","Dynamic programming; Polynomial approximation; Semantics; Trajectories; Vehicles; Automatic derivation; Gps trajectories; Mobility pattern; Polynomial-time dynamic programming; Private vehicles; Real trajectories; Semantic information; Spatial temporals; Big data",2-s2.0-85032815148
"Min W., Zhang Y., Li J., Xu S.","Recognition of pedestrian activity based on dropped-object detection",2018,"Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032034296&doi=10.1016%2fj.sigpro.2017.09.024&partnerID=40&md5=ee1cb47036dc8c162e7b940dac304b87","Aiming at recognizing dropped objects and matching their owners, this paper presents a method for analyzing pedestrian activity based on dropped-object detection in video surveillance. The recognition results may be applied to further analyzing human activity and intentions such as determining whether the dropped-objects are intentional hazardous or unconsciously lost articles according to the appearance of dropped-objects. The method consists of dropped-object detection and recognition. The dropped-object detection algorithm uses foreground detection based on bi-directional background modeling, MeanShift tracking, and pixel-based regional information at the drop-off point. It analyzes the relationship between the dropped objects and pedestrians at the pixel level in complex environments with noises and occlusions. Afterwards, an algorithm based on moment invariant and Principal Component Analysis (PCA) is proposed to further recognize the dropped-objects viewed from different directions and locations from video cameras. In addition, in order to solve the limitation of the centralized video processing model for large-scale video streams in real time, the proposed method is designed and accomplished in a distributed model. The experimental results showed that the proposed method can effectively and efficiently recognize the pedestrian activity through the dropped objects in real-time video data. © 2017 Elsevier B.V.","Distributed model; Dropped-object detection; Dropped-object recognition; Human activity analysis; Relevancy analysis; Video surveillance","Object recognition; Pixels; Principal component analysis; Security systems; Video cameras; Video signal processing; Complex environments; Distributed modeling; Foreground detection; Human activity analysis; Mean-shift tracking; Regional information; Relevancy analysis; Video surveillance; Object detection",2-s2.0-85032034296
"Silva Pereira S., López-Valcarce R., Pagès-Zamora A.","Parameter estimation in wireless sensor networks with faulty transducers: A distributed EM approach",2018,"Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032874692&doi=10.1016%2fj.sigpro.2017.10.012&partnerID=40&md5=73da63c9b4b9d921acc48876807a1e1b","We address the problem of distributed estimation of a vector-valued parameter performed by a wireless sensor network in the presence of noisy observations which may be unreliable due to faulty transducers. The proposed distributed estimator is based on the Expectation-Maximization (EM) algorithm and combines consensus and diffusion techniques: a term for information diffusion is gradually turned off, while a term for updated information averaging is turned on so that all nodes in the network approach the same value of the estimate. The proposed method requires only local exchanges of information among network nodes and, in contrast with previous approaches, it does not assume knowledge of the a priori probability of transducer failures or the noise variance. A convergence analysis is provided, showing that the convergent points of the centralized EM iteration are locally asymptotically convergent points of the proposed distributed scheme. Numerical examples show that the distributed algorithm asymptotically attains the performance of the centralized EM method. © 2017 Elsevier B.V.","Consensus averaging; Diffusion strategies; Distributed estimation; Expectation-maximization; Maximum-likelihood; Soft detection; Wireless sensor networks.","Image segmentation; Iterative methods; Maximum likelihood; Maximum likelihood estimation; Maximum principle; Numerical methods; Parameter estimation; Sensor nodes; Transducers; Wireless sensor networks; Consensus averaging; Diffusion strategies; Distributed estimation; Expectation - maximizations; Soft detection; Distributed parameter networks",2-s2.0-85032874692
"Yao X.-R., Lan R.-M., Liu X.-F., Zhu G., Zheng F., Yu W.-K., Zhai G.-J.","High throughput dual-wavelength temperature distribution imaging via compressive imaging",2018,"Optics Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032665854&doi=10.1016%2fj.optcom.2017.10.028&partnerID=40&md5=a2577765f46cbdddf249e253724a94e7","Thermal imaging is an essential tool in a wide variety of research areas. In this work we demonstrate high-throughput double-wavelength temperature distribution imaging using a modified single-pixel camera without the requirement of a beam splitter (BS). A digital micro-mirror device (DMD) is utilized to display binary masks and split the incident radiation, which eliminates the necessity of a BS. Because the spatial resolution is dictated by the DMD, this thermal imaging system has the advantage of perfect spatial registration between the two images, which limits the need for the pixel registration and fine adjustments. Two bucket detectors, which measures the total light intensity reflected from the DMD, are employed in this system and yield an improvement in the detection efficiency of the narrow-band radiation. A compressive imaging algorithm is utilized to achieve under-sampling recovery. A proof-of-principle experiment was presented to demonstrate the feasibility of this structure. © 2017 Elsevier B.V.","Computational imaging; Single-pixel camera; Thermal imaging","Cameras; Display devices; Image resolution; Infrared imaging; Pixels; Temperature distribution; Compressive imaging; Computational imaging; Detection efficiency; Digital micro-mirror device; Narrow-band radiation; Proof-of-principle experiments; Single-pixel cameras; Spatial registrations; Throughput",2-s2.0-85032665854
"Zhai D., Chen S., Xue S., Yin Z.","Pixel-based absolute surface metrology by three flat test with shifted and rotated maps",2018,"Optics and Lasers in Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032745345&doi=10.1016%2fj.optlaseng.2017.10.021&partnerID=40&md5=23f0456f2c6006db5f3020c1302d4852","In traditional three flat test, it only provides the absolute profile along one surface diameter. In this paper, an absolute testing algorithm based on shift-rotation with three flat test has been proposed to reconstruct two-dimensional surface exactly. Pitch and yaw error during shift procedure is analyzed and compensated in our method. Compared with multi-rotation method proposed before, it only needs a 90° rotation and a shift, which is easy to carry out especially in condition of large size surface. It allows pixel level spatial resolution to be achieved without interpolation or assumption to the test surface. In addition, numerical simulations and optical tests are implemented and show the high accuracy recovery capability of the proposed method. © 2017 Elsevier Ltd","Absolute testing; Shift-rotation; Three flat test","Numerical methods; Pixels; Absolute testing; High-accuracy; Recovery capabilities; Rotation methods; Spatial resolution; Surface metrology; Test surfaces; Two-dimensional surface; Rotation",2-s2.0-85032745345
"Chen Y.-S., Yang H.-X., Guo W.-Z., Liu G.-G.","Promotion of cooperation based on swarm intelligence in spatial public goods games",2018,"Applied Mathematics and Computation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032682401&doi=10.1016%2fj.amc.2017.10.022&partnerID=40&md5=9b6100c41357810f2ff4989e52d9f317","In this paper, we introduce the swarm intelligence methods into the evolutionary dynamics, and have studied the impact of swarm intelligent algorithm on the evolution of cooperation among selfish individuals in the continuous version of spatial public goods games (PGG). We update an individual's strategy according to the memory which records the most successful individual strategy in the past (referred to as its personal best strategy) as well as the knowledge of the best current strategy found by its nearest neighbors (referred to as the neighborhood best strategy). Through extensive simulations, we find that the introduction of swarm intelligence into PGG can promote cooperation strongly. Other pertinent quantities such as the time evolution of cooperator density, the spatial distribution of strategies and the updated velocities are also investigated. © 2017 Elsevier Inc.","Cooperation; Public goods games; Square lattice; Swarm intelligence","Artificial intelligence; Cooperation; Evolution of cooperation; Evolutionary dynamics; Extensive simulations; Nearest neighbors; Public goods games; Square lattices; Swarm intelligent; Swarm intelligence",2-s2.0-85032682401
"Li Y., Liu S., Zhong M., Ding S.X.","State estimation for stochastic discrete-time systems with multiplicative noises and unknown inputs over fading channels",2018,"Applied Mathematics and Computation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030723679&doi=10.1016%2fj.amc.2017.09.008&partnerID=40&md5=d57da0cb5879c2260377b8529cd99366","This paper deals with robust state estimation problem for a class of stochastic discrete-time systems with multiplicative noises and unknown inputs over fading channels. An unbiased unknown input insensitive filter is designed such that the variance of the estimation error is minimized in the sense of the so-called P-estimation. The filter gain matrix is derived through solving a recursive Riccati equation and a generalized Lyapunov equation. A necessary and sufficient condition that guarantees the existence of the filter is given, which establishes a fundamental limit on the mean square capacity of each fading channel. Unknown input estimation and finite horizon stability of the proposed filter are also discussed. To illustrate the effectiveness of the proposed approach, the proposed algorithm is applied to a faulty remote controlled uninterruptible power system, where both the state and the fault are estimated. © 2017 Elsevier Inc.","Fading channel; Multiplicative noise; Robust estimation; Unbiased minimum-variance filter; Unknown input","Digital control systems; Discrete time control systems; Lyapunov functions; Phase noise; Remote control; Riccati equations; State estimation; Stochastic systems; Discrete - time systems; Filter gain matrix; Minimum variance; Multiplicative noise; Robust estimation; Robust state estimation; Unknown input estimation; Unknown inputs; Fading channels",2-s2.0-85030723679
"Mirani A.A., Samuel R.","Discrete vibration stability analysis with hydromechanical specific energy",2018,"Journal of Energy Resources Technology, Transactions of the ASME",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030773162&doi=10.1115%2f1.4037899&partnerID=40&md5=7fc9e361e072b87a2934a32878ee53c2","Drill-bit vibrations and bit wear have been identified as the two major causes for premature polycrystalline diamond-compact (PDC) bit failure and difficulty in accurately predicting PDC bit performance. The objective of this paper is to present a new approach to drilling optimization by developing an algorithm that defines and generates a constrained stable rotary speed (RPM)-weight-on-bit (WOB) working domain for a given system as opposed to the traditional RPM-WOB charts. The algorithm integrates the dynamicstability model for bit vibrations with the bit-performance model for degraded bits. This study addresses the issues of dynamic-bit stability under torsional and lateral vibrations coupled with bit wear. The approach presented in this paper involves performing two separate analyses: vibration stability and bit-wear performance analysis. The optimum operating conditions are estimated at each depth of the drilling interval, taking into consideration the effect of bit wear and bit vibrations. Because the bit wears continuously while penetrating the rocks, discretization of depth is necessary for effective simulation. Discretization is done by dividing the drilling interval into subintervals of the desired length. Vibration-stability analysis and bit-wear performance analysis are preformed separately at every subinterval and then integrated over the discrete interval. For every subinterval, a WOB-RPM domain is determined within which the given system is dynamically stable (for vibrations), and the bit wear does not exceed the maximum allowable wear (MAW) for the section of the drilling interval selected. A unique concept to relate the fractional change in hydromechanical specific energy (HMSE) to the fractional change in bit wear has also been put forward that further constraints the WOB-RPM stable working domain. The new coupled vibration-stability chart, including the maximum rate of penetration (ROP), narrows down the conventional chart and provides different regions of operational stability. It has also been found that as the compressive strength of the rock increases, the bit-gauge friction factor also increases, which results in a compressed or reduced allowable working domain, both from the vibration-stability analysis and bit-performance analysis. Simple guidelines have been provided using the new stability domain chart to estimate the operating range for real-time optimization. © Copyright 2018 by ASME.",,"Bits; Compressive strength; Constrained optimization; Diamond drilling; Diamond drills; Optimization; Stability; Vibrations (mechanical); Discrete intervals; Drilling optimization; Operational stability; Optimum operating conditions; Performance analysis; Polycrystalline diamond compact bits; Rate of penetration; Real-time optimization; Vibration analysis",2-s2.0-85030773162
"Aichholzer O., Barba L., Hackl T., Pilz A., Vogtenhuber B.","Linear transformation distance for bichromatic matchings",2018,"Computational Geometry: Theory and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019743182&doi=10.1016%2fj.comgeo.2017.05.003&partnerID=40&md5=951ef103c527309d452e1d4fb72b3675","Let P=B∪R be a set of 2n points in general position in the plane, where B is a set of n blue points and R a set of n red points. A BR-matching is a plane geometric perfect matching on P such that each edge has one red endpoint and one blue endpoint. Two BR-matchings are compatible if their union is also plane. The transformation graph of BR-matchings contains one node for each BR-matching and an edge joining two such nodes if and only if the corresponding two BR-matchings are compatible. At SoCG 2013 it has been shown by Aloupis, Barba, Langerman, and Souvaine that this transformation graph is always connected, but its diameter remained an open question. In this paper we provide an alternative proof for the connectivity of the transformation graph and prove an upper bound of 2n for its diameter, which is asymptotically tight. Moreover, we present an O(n2log⁡n) time algorithm for constructing a transformation of length O(n) between two given BR-matchings. © 2017 Elsevier B.V.","Bichromatic point set; Compatible matchings; Perfect matchings; Reconfiguration problem; Transformation graph","Linear transformations; Bichromatic points; Matchings; Perfect matchings; Reconfiguration problems; Transformation graphs; Mathematical transformations",2-s2.0-85019743182
"Chen W., Zhang J., Gao M., Shen G.","Performance improvement of 64-QAM coherent optical communication system by optimizing symbol decision boundary based on support vector machine",2018,"Optics Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031096457&doi=10.1016%2fj.optcom.2017.09.088&partnerID=40&md5=f3aba4a4192611bf09089a229e27d807","High-order modulation signals are suited for high-capacity communication systems because of their high spectral efficiency, but they are more vulnerable to various impairments. For the signals that experience degradation, when symbol points overlap on the constellation diagram, the original linear decision boundary cannot be used to distinguish the classification of symbol. Therefore, it is advantageous to create an optimum symbol decision boundary for the degraded signals. In this work, we experimentally demonstrated the 64-quadrature-amplitude modulation (64-QAM) coherent optical communication system using support-vector machine (SVM) decision boundary algorithm to create the optimum symbol decision boundary for improving the system performance. We investigated the influence of various impairments on the 64-QAM coherent optical communication systems, such as the impairments caused by modulator nonlinearity, phase skew between in-phase (I) arm and quadrature-phase (Q) arm of the modulator, fiber Kerr nonlinearity and amplified spontaneous emission (ASE) noise. We measured the bit-error-ratio (BER) performance of 75-Gb/s 64-QAM signals in the back-to-back and 50-km transmission. By using SVM to optimize symbol decision boundary, the impairments caused by I/Q phase skew of the modulator, fiber Kerr nonlinearity and ASE noise are greatly mitigated. © 2017 Elsevier B.V.","64-QAM; Coherent optical communications; Decision boundary; Support vector machine","Light modulators; Modulation; Optical fiber communication; Optical Kerr effect; Optical signal processing; Support vector machines; 64-QAM; Amplified spontaneous emission noise; Coherent optical communication systems; Coherent optical communications; Decision boundary; High spectral efficiency; High-capacity communications; Linear decision boundary; Optical communication",2-s2.0-85031096457
"Biniaz A., Maheshwari A., Smid M.","Strong matching of points with geometric shapes",2018,"Computational Geometry: Theory and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023633002&doi=10.1016%2fj.comgeo.2017.06.009&partnerID=40&md5=c58aeb280833cfb988d344f382ed7f01","Let P be a set of n points in general position in the plane. Given a convex geometric shape S, a geometric graph GS(P) on P is defined to have an edge between two points if and only if there exists a homothet of S having the two points on its boundary and whose interior is empty of points of P. A matching in GS(P) is said to be strong, if the homothets of S representing the edges of the matching are pairwise disjoint, i.e., they do not share any point in the plane. We consider the problem of computing a strong matching in GS(P), where S is a diametral disk, an equilateral triangle, or a square. We present an algorithm that computes a strong matching in GS(P); if S is a diametral-disk, then it computes a strong matching of size at least ⌈[Formula presented]⌉, and if S is an equilateral-triangle, then it computes a strong matching of size at least ⌈[Formula presented]⌉. If S can be a downward or an upward equilateral-triangle, we compute a strong matching of size at least ⌈[Formula presented]⌉ in GS(P). When S is an axis-aligned square, we compute a strong matching of size at least ⌈[Formula presented]⌉ in GS(P), that improves the previous lower bound of ⌈[Formula presented]⌉. © 2017 Elsevier B.V.","Geometric graphs; Maximum matching; Strong matching","Applications; Computational geometry; Equilateral triangles; Geometric graphs; Geometric shape; Homothets; Lower bounds; Maximum matchings; Points in general position; Strong matching; Geometry",2-s2.0-85023633002
"Kong X., Chen C., Wen B.","Composite synchronization of three eccentric rotors driven by induction motors in a vibrating system",2018,"Mechanical Systems and Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032870628&doi=10.1016%2fj.ymssp.2017.09.025&partnerID=40&md5=8a691219597153dc79cffa1525e49177","This paper addresses the problem of composite synchronization of three eccentric rotors (ERs) driven by induction motors in a vibrating system. The composite synchronous motion of three ERs is composed of the controlled synchronous motion of two ERs and the self-synchronous motion of the third ER. Combining an adaptive sliding mode control (ASMC) algorithm with a modified master-slave control structure, the controllers are designed to implement controlled synchronous motion of two ERs with zero phase difference. Based on Lyapunov stability theorem and Barbalat's lemma, the stability of the designed controllers is verified. On basis of controlled synchronization of two ERs, self-synchronization of the third ER is introduced to implement composite synchronous motion of three ERs. The feasibility of the proposed composite synchronization method is analyzed by numerical method. The effects of motor and structure parameters on composite synchronous motion are discussed. Experiments on a vibrating test bench driven by three ERs are operated to validate the effectiveness of the proposed composite synchronization method, including a comparison with self-synchronization method. © 2017 Elsevier Ltd","Composite synchronization; Controlled synchronization; Self-synchronization; Stability; Vibrating system","Controllers; Convergence of numerical methods; Electric exciters; Induction motors; Numerical methods; Sliding mode control; Adaptive sliding mode control; Controlled synchronization; Lyapunov stability theorem; Master slave control; Self synchronization; Synchronization method; Vibrating systems; Vibrating test bench; Synchronization",2-s2.0-85032870628
"Martin-Bragado I., Borges R., Balbuena J.P., Jaraiz M.","Kinetic Monte Carlo simulation for semiconductor processing: A review",2018,"Progress in Materials Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030835004&doi=10.1016%2fj.pmatsci.2017.09.003&partnerID=40&md5=6cc42b0cfedfb70830ad30013aede0e7","The Kinetic Monte Carlo (KMC) algorithm is a particularly apt technique to simulate the complex processing of semiconductor devices. In this review, some of the main processes used for semiconductor industries to manufacture transistor from semiconductor materials, namely implantation, annealing and epitaxial growth are reviewed. The evolution of defects created during such processing for the particular, and well known case, of silicon, is commented. Kinetic Monte Carlo modeling is introduced and contrasted briefly with a continuum approach. Particular models of different phenomena, using both object and lattice KMC, are shown: point defect migration, cluster formation, dopant activation and deactivation, damage accumulation, amorphization, recrystallization, solid phase and selective epitaxial regrowth, etc. In this work we describe the models, its implementation into KMC, and we show several comparisons with significant experimental data validating the KMC approach and showing its capabilities. How extra capabilities can be included by extending the models to current problems in the semiconductor industry is also commented, in particular the use of SiGe alloys and the introduction of stress dependencies. © 2017 Elsevier Ltd","Kinetic Monte Carlo; Process simulation; Semiconductor processing; Silicon","Defects; Intelligent systems; Kinetics; Point defects; Semiconducting silicon; Semiconductor device manufacture; Semiconductor devices; Semiconductor growth; Semiconductor materials; Silicon; Damage accumulation; Dopant activation and deactivation; Kinetic Monte Carlo; Kinetic Monte Carlo model; Kinetic monte carlo simulation; Process simulations; Semiconductor industry; Semiconductor processing; Monte Carlo methods",2-s2.0-85030835004
"Zhao Z., Zhang H., Zheng H., Liu S.","New reversing freeform lens design method for LED uniform illumination with extended source and near field",2018,"Optics Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031771685&doi=10.1016%2fj.optcom.2017.09.101&partnerID=40&md5=e0b58da65f6c82e0787798c710319303","In light-emitting diode (LED) array illumination (e.g. LED backlighting), obtainment of high uniformity in the harsh condition of the large distance height ratio (DHR), extended source and near field is a key as well as challenging issue. In this study, we present a new reversing freeform lens design algorithm based on the illuminance distribution function (IDF) instead of the traditional light intensity distribution, which allows uniform LED illumination in the above mentioned harsh conditions. IDF of freeform lens can be obtained by the proposed mathematical method, considering the effects of large DHR, extended source and near field target at the same time. In order to prove the claims, a slim direct-lit LED backlighting with DHR equal to 4 is designed. In comparison with the traditional lenses, illuminance uniformity of LED backlighting with the new lens increases significantly from 0.45 to 0.84, and CV(RMSE) decreases dramatically from 0.24 to 0.03 in the harsh condition. Meanwhile, luminance uniformity of LED backlighting with the new lens is obtained as high as 0.92 at the condition of extended source and near field. This new method provides a practical and effective way to solve the problem of large DHR, extended source and near field for LED array illumination. © 2017 Elsevier B.V.","Illumination design; Lenses; Light-emitting diodes; Nonimaging optics","Distribution functions; Lenses; Light; Lighting; Optical instrument lenses; Freeform lens designs; Illuminance distribution; Illumination design; Light intensity distribution; Lightemitting diode(LED) array; Luminance uniformity; Non-imaging optics; Uniform illumination; Light emitting diodes",2-s2.0-85031771685
"Guo Y., Li B.-Z.","Novel method for parameter estimation of Newton's rings based on CFRFT and ER-WCA",2018,"Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031744484&doi=10.1016%2fj.sigpro.2017.10.005&partnerID=40&md5=8507674974608492258331a11b34e577","Newton's rings is one of the important optical signals, it can be used to measure the curvature radius of optical lens. Owing to the photoelectronic digitized realization and newly established mathematical model of Newton's rings, the measuring of curvature radius can be changed to parameter estimation of Newton's rings. Therefore, some modern signal processing tools have been successfully applied to parameter estimation of Newton's rings, such as Fourier transform (FT), chirp-Fourier transform (CFT) and fractional Fourier transform (FRFT). Nowadays, it has been one of the latest developments in optical signal processing field. In this paper, a novel method for parameter estimation of Newton's rings is proposed based on concise fractional Fourier transform (CFRFT) and evaporation rate based water cycle algorithm (ER-WCA). A pretreatment technology is further proposed to solve uneven illumination of actual Newton's rings. The experimental results show that the efficiency of proposed method is much higher than that of FRFT-based method. It can also be seen from the experimental results that the proposed pretreatment technology can increase the accuracy. © 2017 Elsevier B.V.","Concise fractional Fourier transform; Discrete optical signal processing; Fourier optics and signal processing; Fractional Fourier transforms","Discrete Fourier transforms; Estimation; Fourier optics; Fourier transforms; Lenses; Mines; Optical signal processing; Signal processing; Chirp Fourier transform; Discrete optical signal processing; Fourier optics and signal processing; Fractional Fourier transforms; Latest development; Modern signal processing; Pretreatment technology; Uneven illuminations; Parameter estimation",2-s2.0-85031744484
"Tian W., Mao Z., Zhang B., Li Y.","Shape optimization of a Savonius wind rotor with different convex and concave sides",2018,"Renewable Energy",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032390730&doi=10.1016%2fj.renene.2017.10.067&partnerID=40&md5=04450752e18eea6a1e04ec3afba84abc","This paper introduces an optimization procedure of a modified Savonius rotor with different convex and concave sides to maximize the power efficiency. A series of transient computational fluid dynamics (CFD) simulations are performed to find the peak coefficients of power (Cp) of each blade geometry. Then, a global response surface model is created according to the Kriging Method, which defines the relationship between optimization objective Cp and the design parameters. A Particle Swarm Optimization (PSO) algorithm is applied to finding the optimal design based on the response surface model. The optimal Cp is 0.2580 and is 4.41% higher than the traditional design. Comprehensive comparisons of torque, power and flow structures between the optimal and the traditional designs are performed to illustrate the mechanism of how the blade shapes improve the rotor performance. It is find found that the optimal blade shape has stronger tip vortices and recovery flows, which contributes to an increase in the performance of the rotor. © 2017 Elsevier Ltd","Blade; CFD; Kriging; Optimization; Particle Swarm Optimization; Savonius","Computational fluid dynamics; Computational geometry; Interpolation; Optimization; Particle swarm optimization (PSO); Structural optimization; Surface properties; Blade; Comprehensive comparisons; Computational fluid dynamics simulations; Kriging; Optimization procedures; Response surface modeling; Savonius; Savonius wind rotor; Shape optimization; computational fluid dynamics; energy efficiency; kriging; optimization; performance assessment; response surface methodology; shape; torque; wind turbine",2-s2.0-85032390730
"Lu S., Hu H., Yu X., Long J., Jing B., Zong Y., Wan M.","Passive acoustic mapping of cavitation using eigenspace-based robust Capon beamformer in ultrasound therapy",2018,"Ultrasonics Sonochemistry",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032798271&doi=10.1016%2fj.ultsonch.2017.10.017&partnerID=40&md5=2ff471ac7ef6ac873bd25243b291a2a8","Pulse-echo imaging technique can only play a role when high intensity focused ultrasound (HIFU) is turned off due to the interference between the primary HIFU signal and the transmission pulse. Passive acoustic mapping (PAM) has been proposed as a tool for true real-time monitoring of HIFU therapy. However, the most-used PAM algorithm based on time exposure acoustic (TEA) limits the quality of cavitation image. Recently, robust Capon beamformer (RCB) has been used in PAM to provide improved resolution and reduced artifacts over TEA-based PAM, but the presented results have not been satisfactory. In the present study, we applied an eigenspace-based RCB (EISRCB) method to further improve the PAM image quality. The optimal weighting vector of the proposed method was found by projecting the RCB weighting vector onto the desired vector subspace constructed from the eigenstructure of the covariance matrix. The performance of the proposed PAM was validated by both simulations and in vitro histotripsy experiments. The results suggested that the proposed PAM significantly outperformed the conventionally used TEA and RCB-based PAM. The comparison results between pulse-echo images of the residual bubbles and cavitation images showed the potential of our proposed PAM in accurate localization of cavitation activity during HIFU therapy. © 2017 Elsevier B.V.","Cavitation; Eigenspace-based robust Capon beamformer; Passive acoustic mapping; Real-time monitoring","Acoustic fields; Beamforming; Cavitation; Covariance matrix; Imaging techniques; Mapping; Ultrasonic applications; Cavitation activity; Comparison result; High intensity focused ultrasound; Optimal weighting vector; Passive acoustics; Real time monitoring; Robust Capon beamformer; Ultrasound therapy; Image enhancement",2-s2.0-85032798271
"Liu T.","A wavelet multiscale method for the inverse problem of a nonlinear convection–diffusion equation",2018,"Journal of Computational and Applied Mathematics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029318253&doi=10.1016%2fj.cam.2017.08.016&partnerID=40&md5=8c018197021d5701b6cb7ba370e5ac27","This paper is concerned with the problem of identifying the diffusion parameters in a nonlinear convection–diffusion equation, which arises as the saturation equation in the fractional flow formulation of the two-phase porous media flow equations. The forward problem is discretized using finite-difference methods and the inverse problem is formulated as a minimization problem with regularization terms. In order to overcome disturbance of local minimum, a wavelet multiscale method is applied to solve this parameter identification inverse problem. This method works by decomposing the inverse problem into multiple scales with wavelet transform so that the original inverse problem is reformulated to a set of sub-inverse problems relying on scale variables, and successively solving these sub-inverse problems according to the size of scale from the smallest to the largest. The stable and fast regularized Gauss–Newton method is applied to each scale. Numerical simulations show that the proposed algorithm is widely convergent, computationally efficient, and has the anti-noise and de-noising abilities. © 2017 Elsevier B.V.","Inversion; Nonlinear convection–diffusion equation; Permeability; Porous media flow; Tikhonov regularization; Wavelet multiscale method","Differential equations; Diffusion; Finite difference method; Mechanical permeability; Newton-Raphson method; Nonlinear equations; Partial differential equations; Porous materials; Two phase flow; Wavelet transforms; Diffusion equations; Inversion; Porous-media flow; Tikhonov regularization; Wavelet multi-scale; Inverse problems",2-s2.0-85029318253
"Chung E.T., Leung W.T., Vasilyeva M., Wang Y.","Multiscale model reduction for transport and flow problems in perforated domains",2018,"Journal of Computational and Applied Mathematics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030325819&doi=10.1016%2fj.cam.2017.08.017&partnerID=40&md5=c8bf941068d199c8185ab2d69042834d","Convection-dominated transport phenomenon is important for many applications. In these applications, the transport velocity is often a solution of heterogeneous flow problems, which results to a coupled flow and transport phenomena. In this paper, we consider a coupled flow (Stokes problem) and transport (unsteady convection–diffusion problem) in perforated domains. Perforated domains (see Fig. 1) represent void space outside hard inclusions as in porous media, filters, and so on. We construct a coarse-scale solver based on Generalized Multiscale Finite Element Method (GMsFEM) for a coupled flow and transport. The main idea of the GMsFEM is to develop a systematic approach for computing multiscale basis functions. We use a mixed formulation and appropriate multiscale basis functions for both flow and transport to guarantee a mass conservation. For the transport problem, we use Petrov–Galerkin mixed formulation, which provides a stability. As a first approach, we use the multiscale flow solution in constructing the basis functions for the transport equation. In the second approach, we construct multiscale basis functions for coupled flow and transport without solving global flow problem. The novelty of this approach is to construct a coupled multiscale basis function. Numerical results are presented for computations using offline basis. We also present an algorithm for adaptively adding online multiscale basis functions, which are computed using the residual information. Numerical examples using online GMsFEM show the speed up of convergence. © 2017 Elsevier B.V.","Flow and transport; Multiscale model reduction; Perforated domains","Finite element method; Functions; Porous materials; Surface morphology; Transport properties; Convection-dominated; Flow and transport; Multiscale finite element method; Multiscale model reductions; Perforated domain; Transport equation; Transport phenomena; Transport problems; Problem solving",2-s2.0-85030325819
"Wang Y., Hashemi-Sakhtsari A., Trinkle M., Ng B.W.-H.","Sparsity-aware DOA estimation of quasi-stationary signals using nested arrays",2018,"Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030853268&doi=10.1016%2fj.sigpro.2017.09.029&partnerID=40&md5=8344f9c8e29cdf9d08f6f07780d0f2ce","Direction of arrival (DOA) estimation of quasi-stationary signals (QSS) impinging on a nested array in the context of sparse representation is addressed in this paper. By exploiting the quasi-stationarity and extended virtual array structure provided inherently in the nested array, a new narrowband signal model can be obtained, achieving more degrees of freedom (DOFs) than the existing solutions. A sparsity-based recovery algorithm is proposed to fully utilise these DOFs. The suggested method is based on the sparse reconstruction for multiple measurement vector (MMV) which results from the signal subspace of the new signal model. Specifically, the notable advantages of the developed approach can be attributed to the following aspects. First, through a linear transformation, the redundant components in the signal subspace can be eliminated effectively and a covariance matrix with a reduced dimension is constructed, which saves the computational load in sparse signal reconstruction. Second, to further enhance the sparsity and fit the sampled and the actual signal subspace better, we formulate a sparse reconstruction problem that includes a reweighted ℓ1-norm minimisation subject to a weighted error-constrained Frobenius norm. Meanwhile, an explicit upper bound for error-suppression is provided for robust signal recovery. Additionally, the proposed sparsity-aware DOA estimation technique is extended to the wideband signal scenario by performing a group sparse recovery across multiple frequency bins. Last, upper bounds of the resolvable signals are derived for multiple array geometries. Extensive simulation results demonstrate the validity and efficiency of the proposed method in terms of DOA estimation accuracy and resolution over the existing techniques. © 2017 Elsevier B.V.","Direction of arrival (DOA); Nested array; Quasi-stationary signals (QSS); Sparse reconstruction","Covariance matrix; Degrees of freedom (mechanics); Frequency estimation; Linear transformations; Mathematical transformations; Recovery; Signal reconstruction; Vectors; Degrees of freedom (DoFs); Direction of arrivalestimation(DOA); Multiple measurement vector (MMV); Nested arrays; Quasi-stationary signals; Robust signal recoveries; Sparse reconstruction; Sparse signal reconstruction; Direction of arrival",2-s2.0-85030853268
"Karakaya G., Köksalan M., Ahipaşaoğlu S.D.","Interactive algorithms for a broad underlying family of preference functions",2018,"European Journal of Operational Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026306471&doi=10.1016%2fj.ejor.2017.07.028&partnerID=40&md5=00b59eb8c33739aa5fc8c5cf6050a979","In multi-criteria decision making approaches it is typical to consider an underlying preference function that is assumed to represent the decision maker's preferences. In this paper we introduce a broad family of preference functions that can represent a wide variety of preference structures. We develop the necessary theory and interactive algorithms for both the general family of the preference functions and for its special cases. The algorithms guarantee to find the most preferred solution (point) of the decision maker under the assumed conditions. The convergence of the algorithms are achieved by progressively reducing the solution space based on the preference information obtained from the decision maker and the properties of the assumed underlying preference functions. We first demonstrate the algorithms on a simple bi-criteria problem with a given set of available points. We also test the performances of the algorithms on three-criteria knapsack problems and show that they work well. © 2017 Elsevier B.V.","Interactive algorithm; Multiple objective programming; Search space reduction","Combinatorial optimization; Decision making; Decision maker's preferences; Interactive algorithms; Multi criteria decision making; Multiple objective programming; Preference functions; Preference information; Preference structures; Search space reduction; Excavators",2-s2.0-85026306471
"Saviniec L., Santos M.O., Costa A.M.","Parallel local search algorithms for high school timetabling problems",2018,"European Journal of Operational Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026499118&doi=10.1016%2fj.ejor.2017.07.029&partnerID=40&md5=89f9a46bcf60677ba73fbcfcb23c8b95","High school timetabling consists in assigning meetings between classes and teachers, with the goal of minimizing the violation of specific soft requirements. This family of problems has been frequently considered in the literature, but few strategies employing parallelism have been proposed. In this exploratory study, we consider two different parallel frameworks and present a thorough computational study in order to understand algorithmic decisions that are closely related to performance. Our best algorithm outperforms state-of-the-art algorithms for variants of the problem considered, indicating both the efficiency and the flexibility of the method. © 2017 Elsevier B.V.","Iterated local search; Parallel metaheuristics; Simulated annealing; Tabu search; Timetabling","Scheduling; Simulated annealing; Tabu search; Teaching; Computational studies; Exploratory studies; High school timetabling problems; Iterated local search; Local search algorithm; Parallel metaheuristics; State-of-the-art algorithms; Timetabling; Local search (optimization)",2-s2.0-85026499118
"Yang Z., Xiao M.-Q., Ge Y.-W., Feng D.-L., Zhang L., Song H.-F., Tang X.-L.","A double-loop hybrid algorithm for the traveling salesman problem with arbitrary neighbourhoods",2018,"European Journal of Operational Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025119484&doi=10.1016%2fj.ejor.2017.07.024&partnerID=40&md5=dd207e8c83b353779997750b357600ba","This paper addresses the traveling salesman problem with arbitrary neighbourhoods, which is an NP-hard problem in combinatorial optimization and is important in operations research and theoretical computer science. Existing methods based on neighbourhood predigestion and discretization are impractical in cases in which the neighbourhoods are arbitrary. In this paper, the neighbourhoods of the traveling salesman problem are generalized to arbitrarily connected regions in planar Euclidean space. A novel approach to solving this problem is proposed, including a boundary-based encoding scheme and a double-loop hybrid algorithm based on particle swarm optimization and genetic algorithm. In the hybrid algorithm, linear descending inertia weight particle swarm optimization is adopted to search continuous visiting positions in the outer loop, and the genetic algorithm is used to optimize the discrete visiting sequence in the inner loop. The boundary-based encoding scheme can reduce the search space significantly without degrading the solution quality, and the hybrid algorithm can find a high-quality solution in a reasonable time. The computational results on both small and large instances demonstrate that the proposed approach can guarantee a high-quality solution in a reasonable time, compared with three other state-of-the-art algorithms: iterative algorithm, branch-and-bound algorithm, and upper and lower bound algorithm. Moreover, the proposed approach works efficiently in a real-world application that cannot be solved by existing algorithms. © 2017 Elsevier B.V.","Arbitrary neighbourhoods; Boundary-based encoding scheme; Close-enough; Hybrid algorithm; Traveling salesman problem","Branch and bound method; Combinatorial optimization; Computational complexity; Encoding (symbols); Genetic algorithms; Iterative methods; Operations research; Optimization; Particle swarm optimization (PSO); Problem solving; Arbitrary neighbourhoods; Branch-and-bound algorithms; Close-enough; Encoding schemes; Hybrid algorithms; State-of-the-art algorithms; Theoretical computer science; Upper and lower bounds; Traveling salesman problem",2-s2.0-85025119484
"Geuens S., Coussement K., De Bock K.W.","A framework for configuring collaborative filtering-based recommendations derived from purchase data",2018,"European Journal of Operational Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024500511&doi=10.1016%2fj.ejor.2017.07.005&partnerID=40&md5=b41a6eda9a6382d544d58400af7c1ad6","This study proposes a decision support framework to help e-commerce companies select the best collaborative filtering algorithms (CF) for generating recommendations on the basis of online binary purchase data. To create this framework, an experimental design applies several CF configurations, which are characterized by different data-reduction techniques, CF methods, and similarity measures, to binary purchase data sets with distinct input data characteristics, i.e., sparsity level, purchase distribution, and item–user ratio. The evaluations in terms of accuracy, diversity, computation time, and trade-offs among these metrics reveal that the best-performing algorithm in terms of accuracy remains consistent regardless of the input-data characteristics. However, for diversity and computation time, the best-performing model varies with the input characteristics. This framework allows e-commerce companies to decide on the optimal CF configuration as a function of their specific binary purchase data sets. They also gain insight into the impact of changes in the input data set on the preferred algorithm configuration. © 2017 Elsevier B.V.","Binary purchase data; Collaborative filtering; E-commerce; OR in marketing; Recommendation systems","Bins; Commerce; Decision support systems; Electronic commerce; Input output programs; Recommender systems; Sales; Algorithm configurations; Binary purchase data; Collaborative filtering algorithms; Computation time; Decision support framework; Impact of changes; Reduction techniques; Similarity measure; Collaborative filtering",2-s2.0-85024500511
"Van der Heide G., Van Foreest N.D., Roodbergen K.J.","Optimizing stock levels for rental systems with a support warehouse and partial backordering",2018,"European Journal of Operational Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026256378&doi=10.1016%2fj.ejor.2017.07.040&partnerID=40&md5=ba6f3ef5ad136b08ad1207c23dc702ca","Various rental systems, such as public libraries and tool rental companies, have a support warehouse for storing rental products at low cost and carrying out expedited shipments in response to stock-outs at local warehouses. In case of stock-outs, rental systems commonly employ partial backordering, i.e., a limited number of demands is backordered while additional demand is lost. We include partial backordering in our models and demonstrate its relevance. We fully characterize costs and optimal base stock policies in cases with one support and one local warehouse and provide upper bounds for base stock levels in the general system. By enumerating base stock policies and evaluating exact costs numerically, we determine optimal base stock policies for small systems with up to six local warehouses. For larger systems we develop a greedy algorithm based on approximate cost evaluations. The resulting base stock policies have costs within 0.2% from optimality on average in experiments. Among other things, experiments indicate that existing methods with no backordering may lead to poor solutions with partial backordering and that partial backordering is an effective means to reduce lost demand even with limited partial backorder levels. © 2017 Elsevier B.V.","Inventory; Lateral transshipments; Partial backordering; Rental system; Support warehouse","Costs; Libraries; Base stock policy; Greedy algorithms; Inventory; Lateral trans shipments; Partial backorder; Partial backordering; Rental companies; Rental system; Warehouses",2-s2.0-85026256378
"Fetta A., Harper P., Knight V., Williams J.","Predicting adolescent social networks to stop smoking in secondary schools",2018,"European Journal of Operational Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028852021&doi=10.1016%2fj.ejor.2017.07.039&partnerID=40&md5=a1e30c39009141de6331748b1326cefc","Social networks are increasingly being investigated in the context of individual behaviours. Research suggests that friendship connections have the ability to influence individual actions, change personal opinions and subsequently impact upon personal wellbeing. This paper explores the effect of individual friendship selection decisions, and the impact they may have on the overall evolution of a social network. Using data from a large smoking cessation programme in secondary schools, an agent based simulation aiming to predict the evolution of the adolescent social networks is created. The simulation uses existing friendship selection algorithms from link prediction literature, along with a new approach to link prediction, termed PageRank-Max. This new algorithm is based upon the optimisation of an individuals eigen-centrality, and is found to be more successful than existing methods at predicting the future state of an adolescent social network. This research highlights the importance of eigen-centrality in adolescent friendship decisions, and the use of agent-based simulation to conduct behavioural investigations. Furthermore, it provides a proof-of-concept for targeted interventions driven by social network analysis, demonstrating the utility of using emerging sources of social network data for public heath interventions such as with tobacco use which is a major global health challenge. © 2017 The Author(s)","Agent based simulation; Behavioural OR; Link prediction; OR in health services; Social networks","Behavioral research; Optimization; Social networking (online); Agent based simulation; Behavioural OR; Individual behaviour; Link prediction; OR in health services; Selection algorithm; Selection decisions; Smoking cessations; Forecasting",2-s2.0-85028852021
"Lu J., Gupte A., Huang Y.","A mean-risk mixed integer nonlinear program for transportation network protection",2018,"European Journal of Operational Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025065929&doi=10.1016%2fj.ejor.2017.07.025&partnerID=40&md5=6744f4f85b1d7ed23e2b81ec9db392d3","This paper focuses on transportation network protection to hedge against extreme events such as earthquakes. Traditional two-stage stochastic programming has been widely adopted to obtain solutions under a risk-neutral preference through the use of expectations in the recourse function. In reality, decision makers hold different risk preferences. We develop a mean-risk two-stage stochastic programming model that allows for greater flexibility in handling risk preferences when allocating limited resources. In particular, the first stage minimizes the retrofitting cost by making strategic retrofit decisions whereas the second stage minimizes the travel cost. The conditional value-at-risk (CVaR) is included as the risk measure for the total system cost. The two-stage model is equivalent to a nonconvex mixed integer nonlinear program (MINLP). To solve this model using the Generalized Benders Decomposition (GBD) method, we derive a convex reformulation of the second-stage problem to overcome algorithmic challenges embedded in the non-convexity, nonlinearity, and non-separability of first- and second-stage variables. The model is used for developing retrofit strategies for networked highway bridges, which is one of the research areas that can significantly benefit from mean-risk models. We first justify the model using a hypothetical nine-node network. Then we evaluate our decomposition algorithm by applying the model to the Sioux Falls network, which is a large-scale benchmark network in the transportation research community. The effects of the chosen risk measure and critical parameters on optimal solutions are empirically explored. © 2017 Elsevier B.V.","CVaR; Generalized Benders Decomposition; Retrofitting; Stochastic mixed integer nonlinear optimization; Transportation","Costs; Integer programming; Nonlinear programming; Retrofitting; Risk assessment; Stochastic programming; Stochastic systems; Transportation; Conditional Value-at-Risk; CVaR; Decomposition algorithm; Generalized benders decompositions; Mixed integer nonlinear program; Mixed-integer nonlinear optimization; Transportation research; Two-stage stochastic programming; Stochastic models",2-s2.0-85025065929
"Deceuninck M., Fiems D., De Vuyst S.","Outpatient scheduling with unpunctual patients and no-shows",2018,"European Journal of Operational Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025067588&doi=10.1016%2fj.ejor.2017.07.006&partnerID=40&md5=01da0146141c9aeb5547682f5ac05c4b","We assess appointment scheduling strategies for outpatient services. To this end, we consider a fixed-length consultation session in which K patients have to be scheduled at predefined appointment times, but who may not be punctual. Their effective arrival time deviates from their appointment time by a stochastic unpunctuality time. We assume general, possibly distinct distributions for the patients’ consultation times as well as for their unpunctuality. The heterogeneity of the consultation times is motivated by patient classification: the schedule can be adapted to the patients’ characteristics. Our evaluation approach is based on a modified Lindley recursion in a discrete-time framework and obtains accurate predictions for the moments of the patient waiting times as well as the doctor's idle times and overtime. This evaluation method is then included in a local search algorithm to provide general insights into appointment scheduling under unpunctual patients. Our results suggest that the proposed method obtains substantial cost reductions when patient classification is correctly exploited. Finally, it is shown that our analysis can also be used to determine optimal sequencing rules for patients who arrive out of turn. © 2017 Elsevier B.V.","Appointment scheduling; OR in health services; Stochastic programming; Unpunctuality","Cost reduction; Stochastic programming; Stochastic systems; Accurate prediction; Appointment scheduling; Evaluation approach; Local search algorithm; OR in health services; Outpatient scheduling; Sequencing rules; Unpunctuality; Scheduling",2-s2.0-85025067588
"Wuttke D.A., Heese H.S.","Two-dimensional cutting stock problem with sequence dependent setup times",2018,"European Journal of Operational Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025611756&doi=10.1016%2fj.ejor.2017.07.036&partnerID=40&md5=fe5110fe929be2ed29c67aabe8639bb3","Motivated by a firm in the technical textile industry, we study a two-dimensional cutting stock problem with sequence dependent setup times and permissible tolerances. We provide a sequential heuristic with feedback loop based on the approach of Gilmore and Gomory and formulate the sequencing problem as a mixed integer program. We derive a lower bound algorithm and demonstrate the near-optimal performance of our heuristic. Finally, we use real data to test our heuristic and illustrate its applicability to a problem of realistic size. © 2017 Elsevier B.V.","Application; Cutting stock problem; Heuristics; Sequence dependent setup times","Applications; Heuristic programming; Optimization; Textile industry; Cutting stock problem; Heuristics; Mixed-integer programs; Near-optimal performance; Sequence-dependent setup time; Sequencing problems; Technical textiles; Two-dimensional cutting stocks; Integer programming",2-s2.0-85025611756
"Atefi R., Salari M., C. Coelho L., Renaud J.","The open vehicle routing problem with decoupling points",2018,"European Journal of Operational Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026384654&doi=10.1016%2fj.ejor.2017.07.033&partnerID=40&md5=7b15710c0dff196c64c2cb02320a3d80","In this paper we introduce the open vehicle routing problem with decoupling points (OVRP-DP). This practical problem is faced by companies dealing with carriers to ship their goods over large territories. In this case it may be profitable to use more than one carrier to perform a specific expedition: the first one leaves the depot and performs part of the deliveries, drops off all remaining load, and the second carrier continues from that point onwards. This drop off location is called the decoupling point of the route. This problem generalizes the classical OVRP in which each route must be performed by only one carrier. We model this problem using a realistic multi-drop less-than-truckload cost function composed of a non-linear transportation cost, a detour cost and a drop cost. We have developed a tailored Iterated Local Search (ILS) algorithm which handles the special features of the problem. The efficiency of the ILS was demonstrated by obtaining all best known solutions on a set of classical OVRP instances and improving it for one instance. Then, using real orders and transportation costs obtained from industrial partners, we clearly show the benefit of using decoupling points to optimize transportation costs. The performance of the ILS is analyzed and shown to be very robust and superior to what can be obtained with a commercial solver. © 2017 Elsevier B.V.","Common carriers; Decoupling points; Iterated local search; Open vehicle routing","Costs; Drops; Local search (optimization); Transportation; Vehicles; Commercial solvers; Common carriers; Decoupling point; Industrial partners; Iterated local search; Less-than-truckload; Open vehicle routing problems; Transportation cost; Vehicle routing",2-s2.0-85026384654
"Meissner J., Senicheva O.V.","Approximate dynamic programming for lateral transshipment problems in multi-location inventory systems",2018,"European Journal of Operational Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030709621&doi=10.1016%2fj.ejor.2017.06.049&partnerID=40&md5=e7b83b5d0b4961b23a9f7841d0d98609","Companies commonly allocate their inventories across multiple locations based on their historical sales rates. However, random fluctuations in customer purchases, such as those caused by weather conditions and other external factors, might cause significant deviations from expected demand, leading to excess stock in some locations and stockouts in others. To fix this mismatch, companies often turn to lateral transshipments, e.g., the movement of stock between locations of the same echelon. In this paper, we examine multi-location inventory systems under periodic review with multiple opportunities for proactive transshipments within one order cycle. If stockouts occur, demand is lost with no opportunity to backorder. The objective of our model is to find an optimal policy that indicates the sources and the destinations of transshipments as well as the number of units, to maximise the profit of the network. We create a dynamic program that can, in principal, be solved to optimality using Bellman's equation. However, the size of the state and decision spaces makes it impossible to find the optimal policy for real-world sized problem instances. Thereby, we use forward approximate dynamic programming to find a near-optimal transshipment policy. Finally, we conduct an extensive numerical study to gauge the performance of our transshipment policy. For small size instances, we compare our policy to the optimal one. For larger scale instances, we consider other practically oriented heuristics. Our numerical experiments show that our proposed algorithm performs very well compared to state-of-the-art methods in the literature. © 2017","Concave piecewise-linear approximation; Dynamic programming; Lost sales; Multi-location inventory; Proactive transshipments","Inventory control; Location; Numerical methods; Optimization; Piecewise linear techniques; Sales; Approximate dynamic programming; Lateral trans shipments; Lost sale; Multi-location inventory; Multi-location inventory systems; Piecewise linear approximations; Proactive transshipments; State-of-the-art methods; Dynamic programming",2-s2.0-85030709621
"Razavi Termeh S.V., Kornejady A., Pourghasemi H.R., Keesstra S.","Flood susceptibility mapping using novel ensembles of adaptive neuro fuzzy inference system and metaheuristic algorithms",2018,"Science of the Total Environment",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030701181&doi=10.1016%2fj.scitotenv.2017.09.262&partnerID=40&md5=f88704eff7dbfa534e98a6e011e300aa","Flood is one of the most destructive natural disasters which cause great financial and life losses per year. Therefore, producing susceptibility maps for flood management are necessary in order to reduce its harmful effects. The aim of the present study is to map flood hazard over the Jahrom Township in Fars Province using a combination of adaptive neuro-fuzzy inference systems (ANFIS) with different metaheuristics algorithms such as ant colony optimization (ACO), genetic algorithm (GA), and particle swarm optimization (PSO) and comparing their accuracy. A total number of 53 flood locations areas were identified, 35 locations of which were randomly selected in order to model flood susceptibility and the remaining 16 locations were used to validate the models. Learning vector quantization (LVQ), as one of the supervised neural network methods, was employed in order to estimate factors' importance. Nine flood conditioning factors namely: slope degree, plan curvature, altitude, topographic wetness index (TWI), stream power index (SPI), distance from river, land use/land cover, rainfall, and lithology were selected and the corresponding maps were prepared in ArcGIS. The frequency ratio (FR) model was used to assign weights to each class within particular controlling factor, then the weights was transferred into MATLAB software for further analyses and to combine with metaheuristic models. The ANFIS-PSO was found to be the most practical model in term of producing the highly focused flood susceptibility map with lesser spatial distribution related to highly susceptible classes. The chi-square result attests the same, where the ANFIS-PSO had the highest spatial differentiation within flood susceptibility classes over the study area. The area under the curve (AUC) obtained from ROC curve indicated the accuracy of 91.4%, 91.8%, 92.6% and 94.5% for the respective models of FR, ANFIS-ACO, ANFIS-GA, and ANFIS-PSO ensembles. So, the ensemble of ANFIS-PSO was introduced as the premier model in the study area. Furthermore, LVQ results revealed that slope degree, rainfall, and altitude were the most effective factors. As regards the premier model, a total area of 44.74% was recognized as highly susceptible to flooding. The results of this study can be used as a platform for better land use planning in order to manage the highly susceptible zones to flooding and reduce the anticipated losses. © 2017 Elsevier B.V.","ANFIS; Ant colony; Flood susceptibility mapping; Genetic algorithm; Particle swarm optimization","Ant colony optimization; Artificial intelligence; Disasters; Flood control; Floods; Fuzzy neural networks; Fuzzy systems; Genetic algorithms; Inference engines; Intelligent agents; Land use; Lithology; Location; Mapping; MATLAB; Optimization; Particle swarm optimization (PSO); Rain; Adaptive neuro-fuzzy inference system; ANFIS; Ant colonies; Ant Colony Optimization (ACO); Learning Vector Quantization; Meta-heuristics algorithms; Supervised neural networks; Susceptibility mapping; Fuzzy inference",2-s2.0-85030701181
"Chen L., Xu Q.","Iterative algorithms for the input and state recovery from the approximate inverse of strictly proper multivariable systems",2018,"Mechanical Systems and Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029677557&doi=10.1016%2fj.ymssp.2017.08.026&partnerID=40&md5=b55a8762c9eeef5a6052a935999309af","This paper proposes new iterative algorithms for the unknown input and state recovery from the system outputs using an approximate inverse of the strictly proper linear time-invariant (LTI) multivariable system. One of the unique advantages from previous system inverse algorithms is that the output differentiation is not required. The approximate system inverse is stable due to the systematic optimal design of a dummy feedthrough D matrix in the state-space model via the feedback stabilization. The optimal design procedure avoids trial and error to identify such a D matrix which saves tremendous amount of efforts. From the derived and proved convergence criteria, such an optimal D matrix also guarantees the convergence of algorithms. Illustrative examples show significant improvement of the reference input signal tracking by the algorithms and optimal D design over non-iterative counterparts on controllable or stabilizable LTI systems, respectively. Case studies of two Boeing-767 aircraft aerodynamic models further demonstrate the capability of the proposed methods. © 2017 Elsevier Ltd","Approximate inverse; Dummy D matrix; Iterative algorithm; Stability; Strictly proper","Aerodynamics; Convergence of numerical methods; Fighter aircraft; Inverse problems; Linear control systems; Linear systems; Matrix algebra; Multivariable systems; Optimal systems; State space methods; Approximate inverse; Convergence criterion; D matrixes; Feedback stabilization; Iterative algorithm; Linear time invariant; Reference input signals; Strictly proper; Iterative methods",2-s2.0-85029677557
"Mayer M., Arrizabalaga O., Lieb F., Ciba M., Ritter S., Thielemann C.","Electrophysiological investigation of human embryonic stem cell derived neurospheres using a novel spike detection algorithm",2018,"Biosensors and Bioelectronics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030106453&doi=10.1016%2fj.bios.2017.09.034&partnerID=40&md5=a5640ddba83c1dd59c53df7c076adcaa","Microelectrode array (MEA) technology in combination with three-dimensional (3D) neuronal cell models derived from human embryonic stem cells (hESC) provide an excellent tool for neurotoxicity screening. Yet, there are significant challenges in terms of data processing and analysis, since neuronal signals have very small amplitudes and the 3D structure enhances the level of background noise. Thus, neuronal signal analysis requires the application of highly sophisticated algorithms. In this study, we present a new approach optimized for the detection of spikes recorded from 3D neurospheres (NS) with a very low signal-to-noise ratio. This was achieved by extending simple threshold-based spike detection utilizing a highly sensitive algorithm named SWTTEO. This analysis procedure was applied to data obtained from hESC-derived NS grown on MEA chips. Specifically, we examined changes in the activity pattern occurring within the first ten days of electrical activity. We further analyzed the response of NS to the GABA receptor antagonist bicuculline. With this new algorithm method we obtained more reliable results compared to the simple threshold-based spike detection. © 2017 The Authors","3D culture; Human embryonic stem cell-derived neurons; Microelectrode array; Neurosphere; Spike detection algorithm; SWTTEO","Cell growth; Data handling; Electrodes; Electrophysiology; Microelectrodes; Signal detection; Signal to noise ratio; Stem cells; 3-d cultures; Human embryonic stem cells; Microelectrode array; Neurosphere; Spike detection; SWTTEO; Neurons; bicuculline; algorithm; Article; controlled study; electric activity; electrophysiology; human; human cell; human embryonic stem cell; microelectrode; microelectrode array; nerve cell network; neural stem cell; signal noise ratio; spike; stationary wavelet transform based teager energy operator",2-s2.0-85030106453
"Yan H., Song X., Tian K., Chen Y., Xiong Y., Min S.","Quantitative determination of additive Chlorantraniliprole in Abamectin preparation: Investigation of bootstrapping soft shrinkage approach by mid-infrared spectroscopy",2018,"Spectrochimica Acta - Part A: Molecular and Biomolecular Spectroscopy",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031760802&doi=10.1016%2fj.saa.2017.08.067&partnerID=40&md5=ee064331f00d86e7531528613b822d54","A novel method, mid-infrared (MIR) spectroscopy, which enables the determination of Chlorantraniliprole in Abamectin within minutes, is proposed. We further evaluate the prediction ability of four wavelength selection methods, including bootstrapping soft shrinkage approach (BOSS), Monte Carlo uninformative variable elimination (MCUVE), genetic algorithm partial least squares (GA-PLS) and competitive adaptive reweighted sampling (CARS) respectively. The results showed that BOSS method obtained the lowest root mean squared error of cross validation (RMSECV) (0.0245) and root mean squared error of prediction (RMSEP) (0.0271), as well as the highest coefficient of determination of cross-validation (Qcv 2) (0.9998) and the coefficient of determination of test set (Q2 test) (0.9989), which demonstrated that the mid infrared spectroscopy can be used to detect Chlorantraniliprole in Abamectin conveniently. Meanwhile, a suitable wavelength selection method (BOSS) is essential to conducting a component spectral analysis. © 2017","BOSS; Chlorantraniliprole; MIR; Wavelength selection","Genetic algorithms; Infrared devices; Infrared spectroscopy; Mean square error; Monte Carlo methods; Shrinkage; Spectrum analysis; BOSS; Chlorantraniliprole; Coefficient of determination; Genetic algorithm-partial least squares; Mid-infrared spectroscopy; Monte Carlo uninformative variable eliminations; Quantitative determinations; Wavelength selection; Least squares approximations",2-s2.0-85031760802
"Cheng G., Ma Y., Liu Z., Xie F.","Compressed sensing based missing nodes prediction in temporal communication network",2018,"Physica A: Statistical Mechanics and its Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032431963&doi=10.1016%2fj.physa.2017.08.149&partnerID=40&md5=8febfff587dafc2ffcd5d96ccea1642f","The reconstruction of complex network topology is of great theoretical and practical significance. Most research so far focuses on the prediction of missing links. There are many mature algorithms for link prediction which have achieved good results, but research on the prediction of missing nodes has just begun. In this paper, we propose an algorithm for missing node prediction in complex networks. We detect the position of missing nodes based on their neighbor nodes under the theory of compressed sensing, and extend the algorithm to the case of multiple missing nodes using spectral clustering. Experiments on real public network datasets and simulated datasets show that our algorithm can detect the locations of hidden nodes effectively with high precision. © 2017","Compressed sensing; Missing node; Network reconstruction; Spectral clustering","Complex networks; Compressed sensing; Forecasting; High-precision; Link prediction; Missing node; Network reconstruction; Network topology; Public networks; Simulated datasets; Spectral clustering; Clustering algorithms",2-s2.0-85032431963
"Sun J., Ding J., Liu N., Yang G., Li J.","Detection of multiple chemicals based on external cavity quantum cascade laser spectroscopy",2018,"Spectrochimica Acta - Part A: Molecular and Biomolecular Spectroscopy",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032437754&doi=10.1016%2fj.saa.2017.10.059&partnerID=40&md5=cf9cbfe8bf7565f75fc60b40a4dc0119","A laser spectroscopy system based on a broadband tunable external cavity quantum cascade laser (ECQCL) and a mini quartz crystal tuning fork (QCTF) detector was developed for standoff detection of volatile organic compounds (VOCs). The self-established spectral analysis model based on multiple algorithms for quantitative and qualitative analysis of VOC components (i.e. ethanol and acetone) was detailedly investigated in both closed cell and open path configurations. A good agreement was obtained between the experimentally observed spectra and the standard reference spectra. For open path detection of VOCs, the sensor system was demonstrated at a distance of 30 m. The preliminary laboratory results show that standoff detection of VOCs at a distance of over 100 m is very promising. © 2017 Elsevier B.V.","ECQCL; Open path; QCTF; VOCs detection","Acetone; Laser spectroscopy; Organic lasers; Quantum cascade lasers; Semiconductor lasers; Spectrum analysis; Volatile organic compounds; Analysis models; ECQCL; Multiple algorithms; Open-path; QCTF; Quantitative and qualitative analysis; Reference spectrum; Standoff detection; Chemical detection",2-s2.0-85032437754
"Peyton Jones J.C., Yaser K.S.A., Stevenson J.","Automatic computation and solution of generalized harmonic balance equations",2018,"Mechanical Systems and Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029694387&doi=10.1016%2fj.ymssp.2017.08.033&partnerID=40&md5=fadf5f7da222e4762cb3876b5be59542","Generalized methods are presented for generating and solving the harmonic balance equations for a broad class of nonlinear differential or difference equations and for a general set of harmonics chosen by the user. In particular, a new algorithm for automatically generating the Jacobian of the balance equations enables efficient solution of these equations using continuation methods. Efficient numeric validation techniques are also presented, and the combined algorithm is applied to the analysis of dc, fundamental, second and third harmonic response of a nonlinear automotive damper. © 2017 Elsevier Ltd","Harmonic balance; Nonlinear damper; Numerical continuation","Difference equations; Harmonic analysis; Automatic computations; Combined algorithms; Continuation method; Generalized method; Harmonic balance; Non-linear dampers; Numerical continuation; Second and third harmonics; Nonlinear equations",2-s2.0-85029694387
"Ko B., Song J.W., Chang W.","Crash forecasting in the Korean stock market based on the log-periodic structure and pattern recognition",2018,"Physica A: Statistical Mechanics and its Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032472029&doi=10.1016%2fj.physa.2017.09.074&partnerID=40&md5=f9652dd7b71dfa61b277e57c0d3461b3","The aim of this research is to propose an alarm index to forecast the crash of the Korean financial market in extension to the idea of Johansen–Ledoit–Sornette model, which uses the log-periodic functions and pattern recognition algorithm. We discover that the crashes of the Korean financial market can be classified into domestic and global crises where each category requires different window length of fitted datasets. Therefore, we add the window length as a new parameter to enhance the performance of alarm index. Distinguishing the domestic and global crises separately, our alarm index demonstrates more robust forecasting than previous model by showing the error diagram and the results of trading performance. © 2017 Elsevier B.V.","Diffusion model; Financial market; Log-periodicity; Non-linear time series; Pattern recognition; Price forecasting","Alarm systems; Commerce; Finance; Financial markets; Forecasting; Periodic structures; Diffusion model; Korean stock market; Log-periodicity; New parameters; Nonlinear time series; Pattern recognition algorithms; Periodic function; Price forecasting; Pattern recognition",2-s2.0-85032472029
"Pisoni G.O., Cismondi M., Zabaloy M.S.","Computation and analysis of surfaces and lines of three-phase equilibrium in ternary systems: Application illustrated for a CO2(1)+H2O(2)+2-propanol(3)-like system",2018,"Fluid Phase Equilibria",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032681073&doi=10.1016%2fj.fluid.2017.10.011&partnerID=40&md5=77108da806e90aa86229c59d39b4c31b","In this work the rich phenomenology of the ternary three-phase equilibrium is studied for a CO2(1)+H2O(2)+2-propanol(3)-like system which presents a highly complex behavior. This is done through computations carried out over wide ranges of conditions using a model of the equation of state type. The developed computation and analysis strategies are applicable to any ternary system as described by any equation of state model, chosen for representing real systems having a high degree of complexity in their phase behavior. A systematic identification of phase equilibrium objects (or points) from which ternary three-phase lines (T-3PLs) originate is performed. Such points are used to start the computation of a variety of T-3PLs. Several computed T-3PLs are used to visualize a number of ternary three-phase surfaces (T-3PSs). Besides, the boundaries of the T-3PSs are established. A strategy to start the calculation of a T-3PL is proposed for each type of originating point. In addition, with the aim of avoiding convergence problems, a numerical continuation method is used to calculate complete T-3PLs. The visualization of 3D projections of T-3PSs in the temperature-pressure-fugacity space is proposed. This way of looking at the T-3PSs is of much help in the understanding on how they behave and interrelate. The results suggest, among other interesting conclusions, the possibility of continuous transitions from T-3PSs of a given type to T-3PSs of a different type. © 2017 Elsevier B.V.","Calculation algorithms; Equation of state; High pressure; Ternary phase equilibrium; Three-phase lines; Three-phase surfaces","Carbon dioxide; Convergence of numerical methods; Numerical methods; Phase equilibria; Propanol; Ternary systems; Three dimensional computer graphics; Calculation algorithms; Equation of state; High pressure; Ternary phase equilibria; Three phase; Three-phase lines; Equations of state",2-s2.0-85032681073
"Wang X., Zhang F., Ding J., Kung H.-T., Latif A., Johnson V.C.","Estimation of soil salt content (SSC) in the Ebinur Lake Wetland National Nature Reserve (ELWNNR), Northwest China, based on a Bootstrap-BP neural network model and optimal spectral indices",2018,"Science of the Total Environment",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030758439&doi=10.1016%2fj.scitotenv.2017.10.025&partnerID=40&md5=b35524c863d7d40155d4317a6193057f","Soil salinity is recognized worldwide as a major threat to agriculture, particularly in arid regions. Producers and decision-makers thus require updated and accurate maps of salinity in agronomical and environmentally relevant regions. The goals of this study were to test various regression models for estimating soil salt content based on hyperspectral data, HJ-CCD images, and Landsat OLI data using; develop optimal band Difference Index (DI), Ratio Index (RI), and Normalization Index (NDI) algorithms for monitoring soil salt content using image and spectral data; and to compare the performances of the proposed models using a Bootstrap-BP neural network model (Bootstrap-BPNN) from different data sources. The results showed that previously published optimal remote sensing parameters can be applied to estimate the soil salt content in the Ebinur Lake Wetland National Nature Reserve (ELWNNR). Optimal band combination indices based on DI, RI, and NDI were developed for different data sources. Then, the Bootstrap-BP neural network model was built using 1000 groups of Bootstrap samples of remote sensing indices (DI, RI and NDI) and soil salt content. When verifying the accuracy of hyperspectral data, the model yields an R2 value of 0.95, a root mean square error (RMSE) of 4.38 g/kg, and a residual predictive deviation (RPD) of 3.36. The optimal model for remote sensing images was the first derivative model of Landsat OLI, which yielded R2 value of 0.91, RMSE of 4.82 g/kg, and RPD of 3.32; these data indicated that this model has a high predictive ability. When comparing the salinization monitoring accuracy of satellite images to that of ground hyperspectral data, the accuracy of the first derivative of the Landsat OLI model was close to that of the hyperspectral parameter model. Soil salt content was inverted using the first derivative of the Landsat OLI model in the study area. © 2017 Elsevier B.V.","Bootstrap-BP neural network; Derivative methods; Remote sensing; Soil salt content","Decision making; Lakes; Mean square error; Neural networks; Regression analysis; Soils; Wetlands; BP neural network model; BP neural networks; Derivative method; Normalization indices; Remote sensing images; Remote sensing index; Root mean square errors; Soil salt content; Remote sensing; sodium chloride; accuracy assessment; agricultural soil; algorithm; artificial neural network; back propagation; bootstrapping; Landsat; remote sensing; salinity; salt; satellite imagery; soil chemistry; spectral analysis; algorithm; Article; artificial neural network; bootstrapping; China; measurement accuracy; prediction; priority journal; regression analysis; remote sensing; salinization; soil chemistry; soil pollution; soil salinity; soil salinization; soil salt content; wetland; China; Ebinur Lake Wetland Nature Reserve; Xinjiang Uygur",2-s2.0-85030758439
"Choubin B., Darabi H., Rahmati O., Sajedi-Hosseini F., Kløve B.","River suspended sediment modelling using the CART model: A comparative study of machine learning techniques",2018,"Science of the Total Environment",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030214310&doi=10.1016%2fj.scitotenv.2017.09.293&partnerID=40&md5=7d6d5cb0aa38138b0125441ecae9344b","Suspended sediment load (SSL) modelling is an important issue in integrated environmental and water resources management, as sediment affects water quality and aquatic habitats. Although classification and regression tree (CART) algorithms have been applied successfully to ecological and geomorphological modelling, their applicability to SSL estimation in rivers has not yet been investigated. In this study, we evaluated use of a CART model to estimate SSL based on hydro-meteorological data. We also compared the accuracy of the CART model with that of the four most commonly used models for time series modelling of SSL, i.e. adaptive neuro-fuzzy inference system (ANFIS), multi-layer perceptron (MLP) neural network and two kernels of support vector machines (RBF-SVM and P-SVM). The models were calibrated using river discharge, stage, rainfall and monthly SSL data for the Kareh-Sang River gauging station in the Haraz watershed in northern Iran, where sediment transport is a considerable issue. In addition, different combinations of input data with various time lags were explored to estimate SSL. The best input combination was identified through trial and error, percent bias (PBIAS), Taylor diagrams and violin plots for each model. For evaluating the capability of the models, different statistics such as Nash-Sutcliffe efficiency (NSE), Kling-Gupta efficiency (KGE) and percent bias (PBIAS) were used. The results showed that the CART model performed best in predicting SSL (NSE = 0.77, KGE = 0.8, PBIAS < ± 15), followed by RBF-SVM (NSE = 0.68, KGE = 0.72, PBIAS < ± 15). Thus the CART model can be a helpful tool in basins where hydro-meteorological data are readily available. © 2017 Elsevier B.V.","Adaptive neuro-fuzzy inference system; Classification and regression trees; Haraz watershed; Multi-layer perceptron neural network; Support vector machine; Suspended sediment load","Efficiency; Floods; Forestry; Fuzzy neural networks; Fuzzy systems; Learning systems; Meteorology; Network layers; Radial basis function networks; Rivers; Sediment transport; Sediments; Support vector machines; Suspended sediments; Water quality; Water resources; Watersheds; Adaptive neuro-fuzzy inference system; Classification and regression tree; Machine learning techniques; Multi layer perceptron; Multi-layer perceptron neural networks; River suspended sediments; Suspended sediment loads; Water resources management; Fuzzy inference; rain; algorithm; artificial neural network; comparative study; fluvial deposit; fuzzy mathematics; machine learning; modeling; support vector machine; suspended sediment; accuracy; Article; artificial neural network; CART model; comparative study; controlled study; fuzzy system; Iran; kernel method; machine learning; meteorology; particle resuspension; perceptron; priority journal; river; statistical analysis; statistical model; support vector machine; time series analysis; watershed; Iran",2-s2.0-85030214310
"Jian H., Wei W., Li H., Yan Q.","Optimization of a pressure control valve for high power automatic transmission considering stability",2018,"Mechanical Systems and Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029672116&doi=10.1016%2fj.ymssp.2017.08.018&partnerID=40&md5=da056ce7a6f25f75387fbded7b6ca635","The pilot-operated electrohydraulic clutch-actuator system is widely utilized by high power automatic transmission because of the demand of large flowrate and the excellent pressure regulating capability. However, a self-excited vibration induced by the inherent non-linear characteristics of valve spool motion coupled with the fluid dynamics can be generated during the working state of hydraulic systems due to inappropriate system parameters, which causes sustaining instability in the system and leads to unexpected performance deterioration and hardware damage. To ensure a stable and fast response performance of the clutch actuator system, an optimal design method for the pressure control valve considering stability is proposed in this paper. A non-linear dynamic model of the clutch actuator system is established based on the motion of the valve spool and coupling fluid dynamics in the system. The stability boundary in the parameter space is obtained by numerical stability analysis. Sensitivity of the stability boundary and output pressure response time corresponding to the valve parameters are identified using design of experiment (DOE) approach. The pressure control valve is optimized using particle swarm optimization (PSO) algorithm with the stability boundary as constraint. The simulation and experimental results reveal that the optimization method proposed in this paper helps in improving the response characteristics while ensuring the stability of the clutch actuator system during the entire gear shift process. © 2017 Elsevier Ltd","Automatic transmission; Clutch actuator system; Non-linear stability; Optimization; Pressure control valve","Actuators; Clutches; Design of experiments; Excited states; Fluid dynamics; Hydraulic equipment; Optimization; Particle swarm optimization (PSO); Pressure control; Safety valves; Sensitivity analysis; Stability; System stability; Actuator system; Automatic transmission; Non-linear stabilities; Numerical stability analysis; Particle swarm optimization algorithm; Performance deterioration; Pressure control valves; Sensitivity of the stability boundaries; Control system stability",2-s2.0-85029672116
"Guida F., Battisti A., Gladich I., Buzzo M., Marangon E., Giodini L., Toffoli G., Laio A., Berti F.","Peptide biosensors for anticancer drugs: Design in silico to work in denaturizing environment",2018,"Biosensors and Bioelectronics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029598053&doi=10.1016%2fj.bios.2017.09.012&partnerID=40&md5=cd5235df5bea07e6c5df7a189e3cb601","One of the main targets in current clinical oncology is the development of a cheap device capable of monitoring in real-time the concentration of a drug in the blood of a patient. This would allow fine-tuning the dosage according to the patient's metabolism, a key condition to reduce side effects. By using surface plasmon resonance and fluorescence spectroscopy we here show that short peptides designed in silico by a recently developed algorithm are capable of binding the anticancer drug irinotecan (CPT-11) with micromolar affinity. Importantly, the recognition takes place in the denaturating solution used in standard therapeutic drug monitoring to detach the drug from the proteins that are present in human plasma, and some of the peptides are capable of distinguishing CPT-11 from its metabolite SN-38. These results suggest that the in silico design of small artificial peptides is now a viable route for designing sensing units, opening a wide range of applications in diagnostic and clinical areas. © 2017 Elsevier B.V.","Drug monitoring; In silico design; Irinotecan; Peptides","Bioinformatics; Drug interactions; Drug products; Fluorescence spectroscopy; Patient monitoring; Proteins; Surface plasmon resonance; Anticancer drug; Artificial peptides; Clinical oncology; Drug monitoring; Human plasmas; In-silico; Irinotecan; Therapeutic drug monitoring; Peptides; antineoplastic agent; firtecan; irinotecan; methanol; organic solvent; peptide; algorithm; amino acid sequence; Article; binding affinity; biosensor; computer model; controlled study; drug blood level; drug monitoring; enzyme denaturation; fluorescence spectroscopy; metabolite; pH; protein denaturation; protein targeting; surface plasmon resonance",2-s2.0-85029598053
"Ge Y., Chen B., liu L., Qiu X., Song H., Wang Y.","A synthetic computational environment: To control the spread of respiratory infections in a virtual university",2018,"Physica A: Statistical Mechanics and its Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032271803&doi=10.1016%2fj.physa.2017.09.048&partnerID=40&md5=699e0768d81764edb7729a03e0f17816","Individual-based computational environment provides an effective solution to study complex social events by reconstructing scenarios. Challenges remain in reconstructing the virtual scenarios and reproducing the complex evolution. In this paper, we propose a framework to reconstruct a synthetic computational environment, reproduce the epidemic outbreak, and evaluate management interventions in a virtual university. The reconstructed computational environment includes 4 fundamental components: the synthetic population, behavior algorithms, multiple social networks, and geographic campus environment. In the virtual university, influenza H1N1 transmission experiments are conducted, and gradually enhanced interventions are evaluated and compared quantitatively. The experiment results indicate that the reconstructed virtual environment provides a solution to reproduce complex emergencies and evaluate policies to be executed in the real world. © 2017 Elsevier B.V.","Disease transmission; Individual-based modeling; Intervention evaluation; Synthetic computational environment","Virtual reality; Computational environments; Disease transmission; Fundamental component; Individual based model; Intervention evaluation; Management interventions; Synthetic populations; Transmission experiments; Complex networks",2-s2.0-85032271803
"Krishnan M., Bhowmik B., Hazra B., Pakrashi V.","Real time damage detection using recursive principal components and time varying auto-regressive modeling",2018,"Mechanical Systems and Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029695416&doi=10.1016%2fj.ymssp.2017.08.037&partnerID=40&md5=7b8b96f04702d5fc21c1ff974fa22d6d","In this paper, a novel baseline free approach for continuous online damage detection of multi degree of freedom vibrating structures using Recursive Principal Component Analysis (RPCA) in conjunction with Time Varying Auto-Regressive Modeling (TVAR) is proposed. In this method, the acceleration data is used to obtain recursive proper orthogonal components online using rank-one perturbation method, followed by TVAR modeling of the first transformed response, to detect the change in the dynamic behavior of the vibrating system from its pristine state to contiguous linear/non-linear-states that indicate damage. Most of the works available in the literature deal with algorithms that require windowing of the gathered data owing to their data-driven nature which renders them ineffective for online implementation. Algorithms focussed on mathematically consistent recursive techniques in a rigorous theoretical framework of structural damage detection is missing, which motivates the development of the present framework that is amenable for online implementation which could be utilized along with suite experimental and numerical investigations. The RPCA algorithm iterates the eigenvector and eigenvalue estimates for sample covariance matrices and new data point at each successive time instants, using the rank-one perturbation method. TVAR modeling on the principal component explaining maximum variance is utilized and the damage is identified by tracking the TVAR coefficients. This eliminates the need for offline post processing and facilitates online damage detection especially when applied to streaming data without requiring any baseline data. Numerical simulations performed on a 5-dof nonlinear system under white noise excitation and El Centro (also known as 1940 Imperial Valley earthquake) excitation, for different damage scenarios, demonstrate the robustness of the proposed algorithm. The method is further validated on results obtained from case studies involving experiments performed on a cantilever beam subjected to earthquake excitation; a two-storey benchscale model with a TMD and, data from recorded responses of UCLA factor building demonstrate the efficacy of the proposed methodology as an ideal candidate for real time, reference free structural health monitoring. © 2017 Elsevier Ltd","Damage Sensitive Features (DSF); Recursive Principal Component Analysis (RPCA); Time-Varying Autoregressive Modeling (TVAR)","Covariance matrix; Degrees of freedom (mechanics); Earthquakes; Eigenvalues and eigenfunctions; Geophysics; Perturbation techniques; Principal component analysis; Structural analysis; Structural health monitoring; Ultrasonic devices; White noise; Damage-sensitive features; Multi degree-of-freedom; Numerical investigations; Rank one perturbations; Recursive principal component analysis; Structural damage detection; Time varying autoregressive model; White noise excitation; Damage detection",2-s2.0-85029695416
"Kumar D., Singh J., Baleanu D., Sushila","Analysis of regularized long-wave equation associated with a new fractional operator with Mittag-Leffler type kernel",2018,"Physica A: Statistical Mechanics and its Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032302868&doi=10.1016%2fj.physa.2017.10.002&partnerID=40&md5=102a431e17c6809cfd9c450ba39b1707","In this work, we aim to present a new fractional extension of regularized long-wave equation. The regularized long-wave equation is a very important mathematical model in physical sciences, which unfolds the nature of shallow water waves and ion acoustic plasma waves. The existence and uniqueness of the solution of the regularized long-wave equation associated with Atangana–Baleanu fractional derivative having Mittag-Leffler type kernel is verified by implementing the fixed-point theorem. The numerical results are derived with the help of an iterative algorithm. In order to show the effects of various parameters and variables on the displacement, the numerical results are presented in graphical and tabular form. © 2017 Elsevier B.V.","Atangana–Baleanu derivative; Existence and uniqueness; Fixed-point theorem; Fractional regularized long-wave equation; Ion acoustic plasma waves; Shallow water waves","Acoustics; Fixed point arithmetic; Functional analysis; Iterative methods; Plasma waves; Topology; Water waves; Existence and uniqueness; Fixed point theorems; Ion acoustic plasma; Regularized long wave equation; Shallow water waves; Wave equations",2-s2.0-85032302868
"Ren Y., Jiang H., Gao B., Xiang J.","A progressive intraply material deterioration and delamination based failure model for the crashworthiness of fabric composite corrugated beam: Parameter sensitivity analysis",2018,"Composites Part B: Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030862055&doi=10.1016%2fj.compositesb.2017.09.072&partnerID=40&md5=77acd3edd3e2fcc95c21477275265364","A high-accuracy progressive failure model based on continuum damage mechanics (CDM) is proposed to simulate the quasi-static axial crushing of composite corrugated beam. To predict various physical phenomena, both of the intra-ply damage and inter-ply interface damage are considered. The damages of intra-ply fiber and matrix are initiated with stress failure criteria and progressive damage propagation is modeled with a stiffness discount method and energy criteria. The deformation gradient algorithm is effectively used for the erosion of failure elements. Further, the delamination damage is predicted by a triangle traction-separation model with a mix-mode fracture energy criterion. To obtain insights into complicated failure mechanisms, a parameter sensitivity study is carried out to study effects of numerical parameters on failure responses, including element erosions, failure strengths, elasticity modulus, friction properties, etc. Results show that the established model correlates well with experiment on failure modes, impact loads and energy-absorbing characteristics. It is found that element erosion parameters are the most influential parameters for impact loads. The fiber compression strength and friction coefficients exhibit dramatic effect on energy-absorbing capability and failure modes of specimen. © 2017 Elsevier Ltd","Composite corrugated beam; Crashworthiness; Energy absorption capability; Parameter sensitivity; Progressive failure model","Continuum damage mechanics; Crashworthiness; Delamination; Energy absorption; Erosion; Friction; Sensitivity analysis; Stiffness matrix; Absorbing characteristics; Deformation gradients; Energy absorbing capability; Energy absorption capability; Material deterioration; Parameter sensitivities; Parameter sensitivity analysis; Progressive failure; Failure (mechanical)",2-s2.0-85030862055
"Kim S.-W., Choi H.-S., Park D.-U., Baek E.-R., Kim J.-M.","Water level response measurement in a steel cylindrical liquid storage tank using image filter processing under seismic excitation",2018,"Mechanical Systems and Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029678117&doi=10.1016%2fj.ymssp.2017.08.035&partnerID=40&md5=87a48f19215c561ac48eb0db08cb8254","Sloshing refers to the movement of fluid that occurs when the kinetic energy of various storage tanks containing fluid (e.g., excitation and vibration) is continuously applied to the fluid inside the tanks. As the movement induced by an external force gets closer to the resonance frequency of the fluid, the effect of sloshing increases, and this can lead to a serious problem with the structural stability of the system. Thus, it is important to accurately understand the physics of sloshing, and to effectively suppress and reduce the sloshing. Also, a method for the economical measurement of the water level response of a liquid storage tank is needed for the exact analysis of sloshing. In this study, a method using images was employed among the methods for measuring the water level response of a liquid storage tank, and the water level response was measured using an image filter processing algorithm for the reduction of the noise of the fluid induced by light, and for the sharpening of the structure installed at the liquid storage tank. A shaking table test was performed to verify the validity of the method of measuring the water level response of a liquid storage tank using images, and the result was analyzed and compared with the response measured using a water level gauge. © 2017 Elsevier Ltd","Cylindrical liquid storage tank; Image filter processing; Shaking table test; Water level response","Bandpass filters; Fluids; Image processing; Kinetic energy; Kinetics; Liquids; Stability; System stability; Tanks (containers); Water levels; Cylindrical liquid storage tanks; Image filters; Liquid storage tanks; Resonance frequencies; Response measurement; Seismic excitations; Shaking table tests; Structural stabilities; Liquid sloshing",2-s2.0-85029678117
"Zhang Q., Tan L., Xu G.","Evaluating transient performance of servo mechanisms by analysing stator current of PMSM",2018,"Mechanical Systems and Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029697551&doi=10.1016%2fj.ymssp.2017.09.011&partnerID=40&md5=175a3d6a1e16f74103e8f345a2b5f888","Smooth running and rapid response are the desired performance goals for the transient motions of servo mechanisms. Because of the uncertain and unobservable transient behaviour of servo mechanisms, it is difficult to evaluate their transient performance. Under the effects of electromechanical coupling, the stator current signals of a permanent-magnet synchronous motor (PMSM) potentially contain the performance information regarding servo mechanisms in use. In this paper, a novel method based on analysing the stator current of the PMSM is proposed for quantifying the transient performance. First, a vector control model is constructed to simulate the stator current behaviour in the transient processes of consecutive speed changes, consecutive load changes, and intermittent start-stops. It is discovered that the amplitude and frequency of the stator current are modulated by the transient load torque and motor speed, respectively. The stator currents under different performance conditions are also simulated and compared. Then, the stator current is processed using a local means decomposition (LMD) algorithm to extract the instantaneous amplitude and instantaneous frequency. The sample entropy of the instantaneous amplitude, which reflects the complexity of the load torque variation, is calculated as a performance indicator of smooth running. The peak-to-peak value of the instantaneous frequency, which defines the range of the motor speed variation, is set as a performance indicator of rapid response. The proposed method is applied to both simulated data in an intermittent start-stops process and experimental data measured for a batch of servo turrets for turning lathes. The results show that the performance evaluations agree with the actual performance. © 2017 Elsevier Ltd","Performance evaluation; PMSM; Servo mechanisms; Stator current; Transient motion","Benchmarking; Electromechanical coupling; Permanent magnets; Servomechanisms; Stators; Synchronous motors; Torque measurement; Vector control (Electric machinery); Instantaneous amplitude; Instantaneous frequency; Performance evaluation; Performance indicators; Permanent Magnet Synchronous Motor; PMSM; Stator currents; Transient motions; Power quality",2-s2.0-85029697551
"Nascimento D.S., Insausti M., Band B.S.F., Grünhut M.","Photolysis study of octyl p-methoxycinnamate loaded microemulsion by molecular fluorescence and chemometric approach",2018,"Spectrochimica Acta - Part A: Molecular and Biomolecular Spectroscopy",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031725882&doi=10.1016%2fj.saa.2017.10.025&partnerID=40&md5=b695fa93735159556f578c0335e6ae61","Octyl p-methoxycinnamate (OMC) is one of the most widely used sunscreen agents. However, the efficiency of OMC as UV filter over time is affected due to the formation of the cis-isomer which presents a markedly lower extinction coefficient (εcis = 12,600 L mol− 1 cm− 1 at 291 nm) than the original trans-isomer (εtrans = 24,000 L mol− 1 cm− 1 at 310 nm). In this work, a novel carrier for OMC based on an oil-in-water microemulsion is proposed in order to improve the photostability of this sunscreen. The formulation was composed of 29.2% (w/w) of a 3:1 mixture of ethanol (co-surfactant) and decaethylene glycol mono-dodecyl ether (surfactant), 1.5% (w/w) of oleic acid (oil phase) and 69.2% (w/w) of water. This microemulsion was prepared in a simple way, under moderate stirring at 25 °C and using acceptable, biocompatible and accessible materials for topical use. OMC was incorporated in the vehicle at a final concentration of 5.0% (w/w), taking into account the maximum permitted levels established by international norms. Then, a photolysis study of the loaded formulation was performed using a continuous flow system. The direct photolysis was monitored over time by molecular fluorescence. The recorded spectra data between 370 y 490 nm were analyzed by multivariate curve resolution-alternating least squares algorithm. The kinetic rate constants corresponding to the photolysis of the trans-OMC were calculated from the concentration profiles, resulting in 0.0049 s− 1 for the trans-OMC loaded microemulsion and 0.0131 s− 1 for the trans-OMC in aqueous media. These results demonstrate a higher photostability of the trans-OMC when loaded in the proposed vehicle with respect to the free trans-OMC in aqueous media. © 2017 Elsevier B.V.","Molecular fluorescence; Multivariate curve resolution-alternating least squares; O/W microemulsion; Octyl p-methoxycinnamate; Photolysis","Biocompatibility; Biological materials; Drug products; Fluorescence; Isomers; Photolysis; Rate constants; Sun hoods; Surface active agents; Continuous-flow system; Extinction coefficients; Kinetic rate constants; Molecular fluorescence; Multivariate curve resolution alternating least-squares; O/W microemulsions; Octyl p-methoxycinnamate; Oil-in-water microemulsions; Microemulsions",2-s2.0-85031725882
"Nezhadali A., Motlagh M.O., Sadeghzadeh S.","Spectrophotometric determination of fluoxetine by molecularly imprinted polypyrrole and optimization by experimental design, artificial neural network and genetic algorithm",2018,"Spectrochimica Acta - Part A: Molecular and Biomolecular Spectroscopy",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029404532&doi=10.1016%2fj.saa.2017.09.021&partnerID=40&md5=f455218922423891cb069b20668a5411","A selective method based on molecularly imprinted polymer (MIP) solid-phase extraction (SPE) using UV–Vis spectrophotometry as a detection technique was developed for the determination of fluoxetine (FLU) in pharmaceutical and human serum samples. The MIPs were synthesized using pyrrole as a functional monomer in the presence of FLU as a template molecule. The factors that affecting the preparation and extraction ability of MIP such as amount of sorbent, initiator concentration, the amount of monomer to template ratio, uptake shaking rate, uptake time, washing buffer pH, take shaking rate, Taking time and polymerization time were considered for optimization. First a Plackett–Burman design (PBD) consists of 12 randomized runs were applied to determine the influence of each factor. The other optimization processes were performed using central composite design (CCD), artificial neural network (ANN) and genetic algorithm (GA). At optimal condition the calibration curve showed linearity over a concentration range of 10− 7–10− 8 M with a correlation coefficient (R2) of 0.9970. The limit of detection (LOD) for FLU was obtained 6.56 × 10− 9 M. The repeatability of the method was obtained 1.61%. The synthesized MIP sorbent showed a good selectivity and sensitivity toward FLU. The MIP/SPE method was used for the determination of FLU in pharmaceutical, serum and plasma samples, successfully. © 2017 Elsevier B.V.","Artificial neural network; Fluoxetine; Genetic algorithm; Molecularly imprinted polymer; Polypyrrole; UV–Vis spectrophotometry","Body fluids; Extraction; Genetic algorithms; Monomers; Neural networks; Phase separation; Polypyrroles; Spectrophotometry; Synthesis (chemical); Central composite designs; Correlation coefficient; Fluoxetine; Molecularly Imprinted Polymer; Molecularly imprinted polypyrrole; Selectivity and sensitivity; Spectrophotometric determination; VIS spectrophotometry; Optimization",2-s2.0-85029404532
"Kutsanedzie F.Y.H., Chen Q., Hassan M.M., Yang M., Sun H., Rahman M.H.","Near infrared system coupled chemometric algorithms for enumeration of total fungi count in cocoa beans neat solution",2018,"Food Chemistry",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026380535&doi=10.1016%2fj.foodchem.2017.07.117&partnerID=40&md5=f175fa56b5973960317a1e00ad67f0ca","Total fungi count (TFC) is a quality indicator of cocoa beans when unmonitored leads to quality and safety problems. Fourier transform near infrared spectroscopy (FT-NIRS) combined with chemometric algorithms like partial least square (PLS); synergy interval-PLS (Si-PLS); synergy interval-genetic algorithm-PLS (Si-GAPLS); Ant colony optimization – PLS (ACO-PLS) and competitive-adaptive reweighted sampling-PLS (CARS-PLS) was employed to predict TFC in cocoa beans neat solution. Model results were evaluated using the correlation coefficients of the prediction (Rp) and calibration (Rc); root mean square error of prediction (RMSEP), and the ratio of sample standard deviation to RMSEP (RPD). The developed models performance yielded 0.951 ≤ Rp ≤ 0.975; and 3.15 ≤ RPD ≤ 4.32. The models’ prediction stability improved in the order of PLS < CARS-PLS < ACO-PLS < Si-PLS < Si-GAPLS. FT-NIRS combined with Si-GAPLS may be employed for in-situ and noninvasive quantification of TFC in cocoa beans for quality and safety monitoring. © 2017 Elsevier Ltd","Chemometric algorithms; Prediction; Preprocessed spectra; Spectral interval; Variable selection","Ant colony optimization; Artificial intelligence; Cocoa; Coherent scattering; Forecasting; Fungi; Genetic algorithms; Infrared devices; Mean square error; Near infrared spectroscopy; Silicon; Chemometrices; Correlation coefficient; Fourier transform near infrared spectroscopy; Interval genetic algorithm; Partial least square (PLS); Root-mean-square error of predictions; Spectral interval; Variable selection; Optimization; cacao; calibration; correlation coefficient; Fourier transformation; fungus; genetic algorithm; least square analysis; model; monitoring; near infrared spectroscopy; nonhuman; prediction; quantitative study; safety",2-s2.0-85026380535
"Nnolim U.A.","An adaptive RGB colour enhancement formulation for logarithmic image processing-based algorithms",2018,"Optik",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031099661&doi=10.1016%2fj.ijleo.2017.09.102&partnerID=40&md5=49bb1820921904de0fef6820442790c4","This paper presents an effective colour enhancement framework for statistical and logarithmic image processing (LIP)-based enhancement algorithms. The proposed approach utilizes the fusion of partial, multiple computed luminance channels with colour image channel statistics obtained from the input colour image for adaptive colour enhancement. The proposed scheme does not modify the image intensity channel, avoiding colour fading typically observed in colour images processed with conventional algorithms. The colour enhancement scheme compensates for the weaknesses of greyscale-based contrast enhancement and illumination normalization algorithms by focusing on preserving/restoring or enhancing colour. The proposed system avoids the conversion to complex, non-linear colour spaces such as HSI and HSV while producing similar results without manual adjustment of parameters. Additionally, an adaptive scheme for detection of images with unbalanced colour and uneven illumination is combined with the proposed system. Results show that the proposed scheme augments colour results of greyscale-based contrast enhancement algorithms and is relatively less complex compared to most algorithms in the literature. © 2017 Elsevier GmbH","Adaptive colour correction; Colour enhancement; Generalized un-sharp masking; Illumination normalization; Logarithmic image processing; Nonlinear colour space models","Color; Image enhancement; Image processing; Colour corrections; Colour spaces; Conventional algorithms; Enhancement algorithms; Enhancement framework; Illumination normalization; Logarithmic Image Processing; Uneven illuminations; Color image processing",2-s2.0-85031099661
"Shen X.-N., Minku L.L., Marturi N., Guo Y.-N., Han Y.","A Q-learning-based memetic algorithm for multi-objective dynamic software project scheduling",2018,"Information Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032349573&doi=10.1016%2fj.ins.2017.10.041&partnerID=40&md5=2d62574461dd4b997feba52743135b77","Software project scheduling is the problem of allocating employees to tasks in a software project. Due to the large scale of current software projects, many studies have investigated the use of optimization algorithms to find good software project schedules. However, despite the importance of human factors to the success of software projects, existing work has considered only a limited number of human properties when formulating software project scheduling as an optimization problem. Moreover, the changing environments of software companies mean that software project scheduling is a dynamic optimization problem. However, there is a lack of effective dynamic scheduling approaches to solve this problem. This work proposes a more realistic mathematical model for the dynamic software project scheduling problem. This model considers that skill proficiency can improve over time and, different from previous work, it considers that such improvement is affected by the employees’ properties of motivation and learning ability, and by the skill difficulty. It also defines the objective of employees’ satisfaction with the allocation. It is considered together with the objectives of project duration, cost, robustness and stability under a variety of practical constraints. To adapt schedules to the dynamically changing software project environments, a multi-objective two-archive memetic algorithm based on Q-learning (MOTAMAQ) is proposed to solve the problem in a proactive-rescheduling way. Different from previous work, MOTAMAQ learns the most appropriate global and local search methods to be used for different software project environment states by using Q-learning. Extensive experiments on 18 dynamic benchmark instances and 3 instances derived from real-world software projects were performed. A comparison with seven other meta-heuristic algorithms shows that the strategies used by our novel approach are very effective in improving its convergence performance in dynamic environments, while maintaining a good distribution and spread of solutions. The Q-learning-based learning mechanism can choose appropriate search operators for the different scheduling environments. We also show how different trade-offs among the five objectives can provide software managers with a deeper insight into various compromises among many objectives, and enabling them to make informed decisions. © 2017 Elsevier Inc.","Dynamic software project scheduling; Mathematical modeling; Metaheuristics; Multi-objective memetic algorithms; Q-learning","Benchmarking; Economic and social effects; Evolutionary algorithms; Heuristic algorithms; Human computer interaction; Learning algorithms; Mathematical models; Problem solving; Scheduling; Dynamic optimization problem (DOP); Dynamic softwares; Memetic algorithms; Meta heuristic algorithm; Meta heuristics; Optimization algorithms; Q-learning; Software Project Scheduling; Optimization",2-s2.0-85032349573
"Abbiati G., La Salandra V., Bursi O.S., Caracoglia L.","A composite experimental dynamic substructuring method based on partitioned algorithms and localized Lagrange multipliers",2018,"Mechanical Systems and Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028708891&doi=10.1016%2fj.ymssp.2017.07.020&partnerID=40&md5=f6099b800c431d20bff89b5556319b43","Successful online hybrid (numerical/physical) dynamic substructuring simulations have shown their potential in enabling realistic dynamic analysis of almost any type of non-linear structural system (e.g., an as-built/isolated viaduct, a petrochemical piping system subjected to non-stationary seismic loading, etc.). Moreover, owing to faster and more accurate testing equipment, a number of different offline experimental substructuring methods, operating both in time (e.g. the impulse-based substructuring) and frequency domains (i.e. the Lagrange multiplier frequency-based substructuring), have been employed in mechanical engineering to examine dynamic substructure coupling. Numerous studies have dealt with the above-mentioned methods and with consequent uncertainty propagation issues, either associated with experimental errors or modelling assumptions. Nonetheless, a limited number of publications have systematically cross-examined the performance of the various Experimental Dynamic Substructuring (EDS) methods and the possibility of their exploitation in a complementary way to expedite a hybrid experiment/numerical simulation. From this perspective, this paper performs a comparative uncertainty propagation analysis of three EDS algorithms for coupling physical and numerical subdomains with a dual assembly approach based on localized Lagrange multipliers. The main results and comparisons are based on a series of Monte Carlo simulations carried out on a five-DoF linear/non-linear chain-like systems that include typical aleatoric uncertainties emerging from measurement errors and excitation loads. In addition, we propose a new Composite-EDS (C-EDS) method to fuse both online and offline algorithms into a unique simulator. Capitalizing from the results of a more complex case study composed of a coupled isolated tank-piping system, we provide a feasible way to employ the C-EDS method when nonlinearities and multi-point constraints are present in the emulated system. © 2017 Elsevier Ltd","Composite experimental dynamic substructuring; Localized Lagrange multipliers; Online/offline substructuring methods; Partitioned algorithms; Uncertainty propagation","Bridges; Dynamics; Frequency multiplying circuits; Impulse testing; Intelligent systems; Load testing; Monte Carlo methods; Piping systems; Uncertainty analysis; Experimental dynamic substructuring; Localized Lagrange multipliers; Partitioned algorithm; Sub-structuring; Uncertainty propagation; Lagrange multipliers",2-s2.0-85028708891
"Dhein G., de Araújo O.C.B., Cardoso G., Jr.","Genetic local search algorithm for a new bi-objective arc routing problem with profit collection and dispersion of vehicles",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030211820&doi=10.1016%2fj.eswa.2017.09.050&partnerID=40&md5=1e6de142440264ec6b4444224263ef01","We present a new bi-objective arc routing problem in which routes must be constructed in order to maximize collected profit and a non linear dispersion metric. A dispersion metric calculated based on instantaneous positions, suitable to capture routing characteristics found when vehicles have to travel in hostile environments, is a novelty in the routing literature. The inherent combinatorial nature of this problem makes it difficult to solve using exact methods. We propose a Multi-objective Genetic Local Search Algorithm to solve the problem and compare the results with those obtained by a well known multi-objective evolutionary algorithm. Computational experiments were performed on a new set of benchmark instances, and the results evidence that local search plays an important role in providing good approximation sets. The proposed method can be adapted to other multi-objective problems in which the exploitation provided by local search may improve the evolutionary procedures usually adopted. © 2017 Elsevier Ltd","Bi-objective problem; Dispersion metric; Genetic algorithm; Local search; Profit; Synchronized routes","Benchmarking; Dispersions; Genetic algorithms; Learning algorithms; Local search (optimization); Network routing; Problem solving; Profitability; Routing algorithms; Bi objectives; Computational experiment; Genetic local search algorithm; Hostile environments; Local search; Multi objective evolutionary algorithms; Multi-objective problem; Synchronized routes; Evolutionary algorithms",2-s2.0-85030211820
"Altlntan D., Purutçuoǧlu V., Uǧur O.","Impulsive Expressions in Stochastic Simulation Algorithms",2018,"International Journal of Computational Methods",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009999505&doi=10.1142%2fS021987621750075X&partnerID=40&md5=6c637b38cfbebbdc68768e0baf13b08d","Jumps can be seen in many natural processes. Classical deterministic modeling approach explains the dynamical behavior of such systems by using impulsive differential equations. This modeling strategy assumes that the dynamical behavior of the whole system is deterministic, continuous, and it adds jumps to the state vector at certain times. Although deterministic approach is satisfactory in many cases, it is a well-known fact that stochasticity or uncertainty has crucial importance for dynamical behavior of many others. In this study, we propose to include this abrupt change in the stochastic modeling approach, beside the deterministic one. In our model, we introduce jumps to chemical master equation and use the Gillespie direct method to simulate the evolutionary system. To illustrate the idea and distinguish the differences, we present some numerically solved examples. © World Scientific Publishing Company.","chemical master equation; deterministic approach; direct method; impulsive differential equations; stochastic modeling; Stochastic simulation algorithm","Differential equations; Dynamics; Stochastic models; Chemical master equation; Deterministic approach; Direct method; Impulsive differential equation; Stochastic simulation algorithms; Stochastic systems",2-s2.0-85009999505
"Domingues R., Filippone M., Michiardi P., Zouaoui J.","A comparative evaluation of outlier detection algorithms: Experiments and analyses",2018,"Pattern Recognition",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032291155&doi=10.1016%2fj.patcog.2017.09.037&partnerID=40&md5=9c8dd9f9ac8e5c33e915c6405b2b8c28","We survey unsupervised machine learning algorithms in the context of outlier detection. This task challenges state-of-the-art methods from a variety of research fields to applications including fraud detection, intrusion detection, medical diagnoses and data cleaning. The selected methods are benchmarked on publicly available datasets and novel industrial datasets. Each method is then submitted to extensive scalability, memory consumption and robustness tests in order to build a full overview of the algorithms’ characteristics. © 2017 Elsevier Ltd","Fraud detection; Isolation forest; Novelty detection; Outlier detection; Variational inference","Crime; Data handling; Diagnosis; Learning algorithms; Learning systems; Signal detection; Statistics; Fraud detection; Isolation forest; Novelty detection; Outlier Detection; Variational inference; Intrusion detection",2-s2.0-85032291155
"Ruiz J., Trillo J.C.","N-dimensional error control multiresolution algorithms for the cell average discretization",2018,"Mathematics and Computers in Simulation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029218011&doi=10.1016%2fj.matcom.2017.07.009&partnerID=40&md5=3fb23d5ab8f76435650de250f8c3f21d","We present N-dimensional multiresolution algorithms with error control strategies in the cell average setting as a generalization to N dimensions of the work done in this direction. We present results proving the stability and giving explicit error bounds. We also explain how to carry out the programming and we include two numerical experiments to exemplify the utility of these algorithms. © 2017 International Association for Mathematics and Computers in Simulation (IMACS)","Cell averages; Error control; Multiresolution schemes; Nonlinearity","Error analysis; Cell averages; Dimensional errors; Error control; Explicit error bounds; Multi-resolution algorithms; Multiresolution scheme; Nonlinearity; Numerical experiments; Errors",2-s2.0-85029218011
"Gandomi A.H., Kashani A.R.","Automating pseudo-static analysis of concrete cantilever retaining wall using evolutionary algorithms",2018,"Measurement: Journal of the International Measurement Confederation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031898708&doi=10.1016%2fj.measurement.2017.10.032&partnerID=40&md5=75e969b4cd613c6b174b84f2d26a93c1","Evolutionary optimization algorithms by imitating survival of the best features and transmutation of the creatures within their generation, approach complicated engineering problems very well. Similar to many other field of research, civil engineering problems have benefited from this capacity. In the current study, optimum design of retaining walls under seismic loading case is analyzed by three evolutionary algorithms, differential evolution (DE), evolutionary strategy (ES), and biogeography-based optimization algorithms (BBO). All the results are benchmarked with the classical evolutionary algorithm, genetic algorithm (GA). To this end, two different measures, minimum-cost and minimum-weight, are considered based on ACI 318-05 requirements coupled with geotechnical considerations for retaining walls. Numerical simulations on three case studies revealed that BBO reached the best results over all the case studies decisively. © 2017 Elsevier Ltd","Evolutionary algorithms; Global optimization; Pseudo-static loading case; Retaining wall",,2-s2.0-85031898708
"Neelima P., Reddy A.R.M.","An Efficient Hybridization Algorithm Based Task Scheduling in Cloud Environment",2018,"Journal of Circuits, Systems and Computers",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029218253&doi=10.1142%2fS0218126618500184&partnerID=40&md5=3af3967eb8104ca9997877d50429327d","The present paper describes a hybrid self-adaptive learning global search algorithm and firefly algorithm (HSLGSAFA)-based model for task scheduling in cloud computing. The proposed hybrid model combines gravitational search algorithm (GSA), which has been successfully scheduling the task in the application, with the use of SL strategy and the FA. The basic scheme of our approach is to utilize the benefits of both SLGSA algorithm and firefly algorithm and not including their disadvantages. In HSLGSAFA, each dimension of a solution represents a task and a solution as a whole signifies all tasks' priorities. The vital issue is how to allocate users' tasks to exploit the income of Infrastructure as a Service (IaaS) provider while promising Quality-of-Service (QoS). The generated solution is proficient to assure user-level QoS and improve IaaS providers' credibility and economic benefit. The HSLGSAFA method also used to design the hybridization process and suitable fitness function of the corresponding task. According to the evolved results, it has been found that our algorithm always outperforms the traditional algorithms. © 2018 World Scientific Publishing Company.","Cloud computing; Gravitational search algorithm; Hybridization; Infrastructure as a Service; Quality-of-Service (QoS); SL strategy; Task scheduling","Bioluminescence; Cloud computing; Learning algorithms; Multitasking; Optimization; Quality of service; Scheduling algorithms; Global search algorithm; Gravitational search algorithm (GSA); Gravitational search algorithms; Hybridization; Hybridization algorithms; Self-adaptive learning; SL strategy; Task-scheduling; Infrastructure as a service (IaaS)",2-s2.0-85029218253
"AbuGhanem M., Homid A.H., Abdel-Aty M.","Cavity control as a new quantum algorithms implementation treatment",2018,"Frontiers of Physics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028534380&doi=10.1007%2fs11467-017-0709-3&partnerID=40&md5=4884faa4ef9d685784a6a80f1a7d3965","Based on recent experiments [Nature 449, 438 (2007) and Nature Physics 6, 777 (2010)], a new approach for realizing quantum gates for the design of quantum algorithms was developed. Accordingly, the operation times of such gates while functioning in algorithm applications depend on the number of photons present in their resonant cavities. Multi-qubit algorithms can be realized in systems in which the photon number is increased slightly over the qubit number. In addition, the time required for operation is considerably less than the dephasing and relaxation times of the systems. The contextual use of the photon number as a main control in the realization of any algorithm was demonstrated. The results indicate the possibility of a full integration into the realization of multi-qubit multiphoton states and its application in algorithm designs. Furthermore, this approach will lead to a successful implementation of these designs in future experiments. © 2018, Higher Education Press and Springer-Verlag GmbH Germany.","cavity control; quantum algorithms implementation; quantum computation",,2-s2.0-85028534380
"Al-Kaff A., Martín D., García F., Escalera A.D.L., María Armingol J.","Survey of computer vision algorithms and applications for unmanned aerial vehicles",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030657620&doi=10.1016%2fj.eswa.2017.09.033&partnerID=40&md5=0ce49d293fa8f01b588acc06a3cfef5a","This paper presents a complete review of computer vision algorithms and vision-based intelligent applications, that are developed in the field of the Unmanned Aerial Vehicles (UAVs) in the latest decade. During this time, the evolution of relevant technologies for UAVs; such as component miniaturization, the increase of computational capabilities, and the evolution of computer vision techniques have allowed an important advance in the development of UAVs technologies and applications. Particularly, computer vision technologies integrated in UAVs allow to develop cutting-edge technologies to cope with aerial perception difficulties; such as visual navigation algorithms, obstacle detection and avoidance and aerial decision-making. All these expert technologies have developed a wide spectrum of application for UAVs, beyond the classic military and defense purposes. Unmanned Aerial Vehicles and Computer Vision are common topics in expert systems, so thanks to the recent advances in perception technologies, modern intelligent applications are developed to enhance autonomous UAV positioning, or automatic algorithms to avoid aerial collisions, among others. Then, the presented survey is based on artificial perception applications that represent important advances in the latest years in the expert system field related to the Unmanned Aerial Vehicles. In this paper, the most significant advances in this field are presented, able to solve fundamental technical limitations; such as visual odometry, obstacle detection, mapping and localization, et cetera. Besides, they have been analyzed based on their capabilities and potential utility. Moreover, the applications and UAVs are divided and categorized according to different criteria. © 2017 Elsevier Ltd","Computer vision; Navigation system; Obstacle avoidance; Pose estimation; UAV; Vision-Based applications; Visual servoing","Air navigation; Aircraft detection; Collision avoidance; Decision making; Expert systems; Navigation systems; Obstacle detectors; Surveys; Unmanned aerial vehicles (UAV); Vehicles; Visual servoing; Computer vision algorithms; Computer vision techniques; Computer vision technology; Intelligent applications; Mapping and localization; Pose estimation; Technologies and applications; Vision-based applications; Computer vision",2-s2.0-85030657620
"Silva Y.L.T.V., Subramanian A., Pessoa A.A.","Exact and heuristic algorithms for order acceptance and scheduling with sequence-dependent setup times",2018,"Computers and Operations Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029853630&doi=10.1016%2fj.cor.2017.09.006&partnerID=40&md5=ac2facbbae3595ca255ed62d0c58bda8","The Order Acceptance and Scheduling (OAS) problem consists of simultaneously deciding which orders (jobs) are going to be accepted for processing as well as their associated schedule. This problem typically arises when a company does not have the capacity to meet the demand, thus being forced to reject some orders. We consider a OAS variant where each job has a processing time, due date, release date, deadline, revenue and penalty weight. In addition, for each pair of jobs i and j, there is a setup time required before starting to process j if this job is scheduled immediately after job i. The objective is to select and schedule a subset of jobs that maximizes the total profit, which is given by the total revenue minus the total weighted tardiness. To solve this NP-hard problem, we propose a new arc-time-indexed mathematical formulation that is capable of solving instances with up to 50 jobs. However, since this formulation relies on a pseudo-polynomial number of variables, larger instances cannot be solved in practice. To overcome this limitation, we developed two exact algorithms over this formulation where the first is based on Lagrangian relaxation and the second is based on column generation. We report tight upper bounds for instances with up to 100 jobs. Moreover, we also implemented a local search based metaheuristic algorithm for obtaining high quality lower bounds. Extensive computational experiments were carried out in 1500 benchmark instances ranging from 10 to 100 jobs and the results obtained suggest that the proposed exact and heuristic methods are capable of finding extremely competitive results when compared to those available in the literature. © 2017 Elsevier Ltd","Arc-time-indexed formulation; Column generation; Iterated local search; Lagrangian relaxation; Order acceptance and scheduling","Benchmarking; Computational complexity; Data storage equipment; Heuristic algorithms; Heuristic methods; Lagrange multipliers; Linear programming; Local search (optimization); Optimization; Scheduling; Arc time; Column generation; Iterated local search; LaGrangian relaxation; Order acceptance; Job shop scheduling",2-s2.0-85029853630
"Luquini E., Omar N.","Rethinking exchange market models as optimization algorithms",2018,"Physica A: Statistical Mechanics and its Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030690913&doi=10.1016%2fj.physa.2017.08.150&partnerID=40&md5=2ef59fa17ed68d5c1cb316b0e363781a","The exchange market model has mainly been used to study the inequality problem. Although the human society inequality problem is very important, the exchange market models dynamics until stationary state and its capability of ranking individuals is interesting in itself. This study considers the hypothesis that the exchange market model could be understood as an optimization procedure. We present herein the implications for algorithmic optimization and also the possibility of a new family of exchange market models © 2017","Computational optimization; Exchange market models; Optimization meta-heuristics","Commerce; Algorithmic optimization; Computational optimization; Exchange markets; Inequality problem; Meta heuristics; Optimization algorithms; Optimization procedures; Stationary state; Optimization",2-s2.0-85030690913
"Blazewicz J., Kasprzak M., Kierzynka M., Frohmberg W., Swiercz A., Wojciechowski P., Zurkowski P.","Graph algorithms for DNA sequencing – origins, current models and the future",2018,"European Journal of Operational Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85002753330&doi=10.1016%2fj.ejor.2016.06.043&partnerID=40&md5=ebda4242f804005652729fe300c3de2b","With the ubiquitous presence of next-generation sequencing in modern biological, genetic, pharmaceutical and medical research, not everyone pays attention to the underlying computational methods. Even fewer researchers know what were the origins of the current models for DNA assembly. We present original graph models used in DNA sequencing by hybridization, discuss their properties and connections between them. We also explain how these graph models evolved to adapt to the characteristics of next-generation sequencing. Moreover, we present a practical comparison of state-of-the-art DNA de novo assembly tools representing these transformed models, i.e. overlap and decomposition-based graphs. Even though the competition is tough, some assemblers perform better and certainly large differences may be observed in hardware resources utilization. Finally, we outline the most important trends in the sequencing field, and try to predict their impact on the computational models in the future. © 2016 Elsevier B.V.","DNA de novo assembly; Graph algorithms; Whole genome sequencing","Bioinformatics; Computational methods; DNA; DNA sequences; Graph theory; Computational model; De novo assemblies; DNA sequencing by hybridization; Graph algorithms; Hardware resources; Next-generation sequencing; State of the art; Whole genome sequencing; Gene encoding",2-s2.0-85002753330
"Akkan C., Gülcü A.","A bi-criteria hybrid Genetic Algorithm with robustness objective for the course timetabling problem",2018,"Computers and Operations Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029178807&doi=10.1016%2fj.cor.2017.09.007&partnerID=40&md5=4140eb3dd0cfc6d611fd73e78ef4c79c","Traditional methods of generating timetables may yield high-quality solutions, but they may not yield robust solutions that may easily be adapted to changing inputs. Incorporating late changes by making minimum modifications on the final timetable is an important need in many practical applications of timetabling. In this study, we focus on a subset of course timetabling problems, the curriculum-based timetabling problem. We first define a robustness measure for the problem, and then try to find a set of good solutions in terms of both penalty and robustness values. We model the problem as a bi-criteria optimization problem and solve it by a hybrid Multi-objective Genetic Algorithm, which makes use of Hill Climbing and Simulated Annealing algorithms in addition to the standard Genetic Algorithm approach. The algorithm is tested on the well known ITC-2007 instances and shown to identify high quality Pareto fronts. © 2017 Elsevier Ltd","Bi-criteria optimization; Course timetabling; Genetic Algorithms; Robustness","Genetic algorithms; Optimization; Robustness (control systems); Scheduling; Simulated annealing; Bicriteria optimization; Course timetabling; High-quality solutions; Hybrid genetic algorithms; Hybrid multi-objective genetic algorithm; Simulated annealing algorithms; Standard genetic algorithm; Timetabling problem; Problem solving",2-s2.0-85029178807
"Soltani A., Battikh T., Jabri I., Lakhoua N.","A new expert system based on fuzzy logic and image processing algorithms for early glaucoma diagnosis",2018,"Biomedical Signal Processing and Control",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031794032&doi=10.1016%2fj.bspc.2017.10.009&partnerID=40&md5=3bb61dd0b5dd012dc41d41ca1d463634","Decision-making systems based on images have increasingly become essential nowadays mostly in the medical field. Indeed, the image has become one of the most fundamental tools for both clinical research and sicknesses’ diagnosis. In this context, we treat glaucoma disease which can affect the optic nerve head (ONH), thus causing its destruction and leading to an irreversible vision loss. This paper presents a new glaucoma Fuzzy Expert System for early glaucoma diagnosis. Original ONH images are first pre-treated using appropriate filters to remove the noise. Canny detector algorithm is then used to detect the contours. Main parameters are then extracted, after having identified elliptical forms of both optic disc and excavation. This operation is performed by using Randomized Hough Transform. Finally, a classification algorithm, based on fuzzy logic approaches, is proposed to determine patients’ conditions. Our system is advantageous as far as it takes into consideration both instrumental parameters and risk factors (age, race, family history…) which make an important contribution to the valuable identification of cases suspected to have glaucoma. The proposed system is tested on a real dataset of ophthalmologic images of both normal and glaucomatous cases. Compared with other existing systems, the experimental results show the superiority of the proposed methods. The percentage of good predictions is more than 96%, reaching an improvement of 1–9% over earlier methods. © 2017 Elsevier Ltd","Decision-making system; Fuzzy logic; Glaucoma diagnosis; Image processing; Ophthalmologic images; Optic nerve head","Computer circuits; Decision making; Diagnosis; Edge detection; Expert systems; Eye protection; Fuzzy logic; Hough transforms; Medical imaging; Ophthalmology; Optical data processing; Classification algorithm; Decision-making systems; Fuzzy expert systems; Image processing algorithm; Instrumental parameters; Ophthalmologic images; Optic nerve head; Randomized Hough transform; Image processing",2-s2.0-85031794032
"Arakaki R.K., Usberti F.L.","Hybrid genetic algorithm for the open capacitated arc routing problem",2018,"Computers and Operations Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030319219&doi=10.1016%2fj.cor.2017.09.020&partnerID=40&md5=dc2d6cca64d5039b9b0512067d7c7c7f","The Open Capacitated Arc Routing Problem (OCARP) is an NP-hard arc routing problem where, given an undirected graph, the objective is to find the least cost set of routes that services all edges with positive demand (required edges). The routes are subjected to capacity constraints in relation to edge demands. The OCARP differs from the Capacitated Arc Routing Problem (CARP) since OCARP does not consider a depot and routes are not constrained to form cycles. A hybrid genetic algorithm with feasibilization and local search procedures is proposed for the OCARP. Computational experiments conducted on a set of benchmark instances reveal that the proposed hybrid genetic algorithm achieved the best upper bounds for almost all instances. © 2017 Elsevier Ltd","Hybrid genetic algorithm; Metaheuristic; Open capacitated arc routing problem","Benchmarking; Genetic algorithms; Routing algorithms; Arc routing problems; Capacitated arc routing problem; Capacity constraints; Computational experiment; Hybrid genetic algorithms; Local search; Metaheuristic; Undirected graph; Network routing",2-s2.0-85030319219
"Jaszkiewicz A.","Improved quick hypervolume algorithm",2018,"Computers and Operations Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029615139&doi=10.1016%2fj.cor.2017.09.016&partnerID=40&md5=e023ca5eb489451db02358e204c77686","In this paper, we present a significant improvement of the Quick Hypervolume algorithm, one of the state-of-the-art algorithms for calculating the exact hypervolume of the space dominated by a set of d-dimensional points. This value is often used as the quality indicator in the multiobjective evolutionary algorithms and other multiobjective metaheuristics and the efficiency of calculating this indicator is of crucial importance especially in the case of large sets or many dimensional objective spaces. We use a similar divide and conquer scheme as in the original Quick Hypervolume algorithm, but in our algorithm we split the problem into smaller sub-problems in a different way. Through both theoretical analysis and a computational study we show that our approach improves the computational complexity of the algorithm and practical running times. © 2017 Elsevier Ltd","Computational complexity analysis; Hypervolume indicator; Multiobjective optimization","Evolutionary algorithms; Multiobjective optimization; Optimization; Computational complexity analysis; Computational studies; Divide and conquer; Hypervolume indicators; Multi objective evolutionary algorithms; Multi-objective metaheuristics; Quality indicators; State-of-the-art algorithms; Computational complexity",2-s2.0-85029615139
"Yu D., Liu G., Guo M., Liu X.","An improved K-medoids algorithm based on step increasing and optimizing medoids",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030711436&doi=10.1016%2fj.eswa.2017.09.052&partnerID=40&md5=041790cf50fba8d6c16db8d8ffa50f02","This paper proposes an improved K-medoids clustering algorithm which preserves the computational efficiency and simplicity of the simple and fast K-medoids algorithm while improving its clustering performance. The proposed algorithm requires determining the candidate medoids subsets and calculating the distance matrix, then using both of them to incrementally increase the number of cluster and new medoids from 2 to K, as well as selecting two initial medoids. The Rand index, Jaccard index, Adjusted Rand index and F-measure are employed to evaluate how the proposed algorithm compares with three state-of-the-art algorithms: the simple and fast K-medoids (FastK), density peak optimized K-medoids (DPK), density peak optimized K-medoids with a new measure (DPNMK) algorithms. Experimental results on both real and artificial data sets show that the proposed algorithm outperforms the other three algorithms. The complexity of this proposed algorithm was analyzed and found to be lower than DPK and DPNMK, and be similar to FastK. © 2017 Elsevier Ltd","Candidate medoids subset; Clustering analysis; K-medoids; Optimizing medoids","Computational complexity; Computational efficiency; Adjusted rand index; Clustering analysis; K-medoids; K-medoids algorithms; K-medoids clustering; Medoids; Number of clusters; State-of-the-art algorithms; Clustering algorithms",2-s2.0-85030711436
"Du X., Wang J., Jegatheesan V., Shi G.","Parameter estimation of activated sludge process based on an improved cuckoo search algorithm",2018,"Bioresource Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031770915&doi=10.1016%2fj.biortech.2017.10.023&partnerID=40&md5=71c61c41cbc82136b67fb6345af77e75","It is essential to use appropriate values for kinetic parameters in activated sludge model when the model is applied for wastewater treatment processes under different environments. An improved cuckoo search (ICS) algorithm was proposed in this paper for the estimation of kinetic parameters used in Activated Sludge Model No. 1 (ASM1). ICS is tested for its speed and accuracy in reaching solution by searching global minima of six standard functions. Cyclical adjustment strategy was employed into the detected probability to increase searching ability. Meanwhile, the searching step was adaptively adjusted based on the optimal nest of the last generation and the current iteration numbers. Subsequently, ICS is used to estimate 7 sensitive parameters in ASM1 for practical applications. Field data are used to validate prediction accuracy of ASM1 with estimated parameters. Predicted results of the model are closer to the actual data with adjusted parameters. © 2017 Elsevier Ltd","Activated sludge process; ASM1; Cuckoo search algorithm; Parameter estimation; Wastewater treatment","Global optimization; Iterative methods; Kinetic parameters; Learning algorithms; Optimization; Parameter estimation; Wastewater treatment; Activated sludge model; ASM1; Cuckoo search algorithms; Estimated parameter; Prediction accuracy; Searching ability; Sensitive parameter; Wastewater treatment process; Activated sludge process; water; accuracy assessment; activated sludge; algorithm; data set; parameter estimation; prediction; probability; wastewater treatment; activated sludge; algorithm; Article; comparative study; control strategy; controlled study; kinetic parameters; measurement accuracy; periodicity; priority journal; regulatory mechanism; sewage treatment; water quality",2-s2.0-85031770915
"Mohammadi A., Asadi H., Mohamed S., Nelson K., Nahavandi S.","Optimizing Model Predictive Control horizons using Genetic Algorithm for Motion Cueing Algorithm",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029792785&doi=10.1016%2fj.eswa.2017.09.004&partnerID=40&md5=1f9dcfd56f8adef35d6a74427b63965a","Driving simulators are effective tools for producing the feeling of driving a real car through generation of a similar environment and motion cues. The main problem of motion simulators is their limited workspace which does not allow them to produce the exact motions of a real vehicle, hence they need a Motion Cueing Algorithm (MCA). A high-fidelity motion simulator can be used for vehicle prototyping and testing as well as driver/pilot training to enhance transportation safety. Using motion simulators with the capability of replacing realistic motions for these purposes is less risky for drivers and more time and cost-effective. Due to workspace limitations, washout filters have been designed to bring motion simulators back to a neutral position; however, the problem of violation of platform constraints is still an issue. Recently Model Predictive Control (MPC) has become popular in driving simulators. The primary advantage of this control method is respecting constraints and consideration of future dynamics. The horizon windows of future control and prediction affect the computational burden and the output performance. As these horizons are chosen manually by the designer, they are sub-optimal and in some cases too wide or narrow. In this paper, a novel method based on Genetic Algorithm (GA) is employed to achieve the best control and prediction horizons considering minimization of several terms such as sensation error, displacement and the computational burden. This new method is proposed to eliminate the MPC-MCA drawbacks such as time-consuming empirical guessing by iterative trial-and-error for the initial control and prediction horizons as selecting the initial control and prediction horizons based on trial-and-error can lead to large sensation error, low motion fidelity, inefficient platform usage as well as the computational burden. Therefore, this method provides a new framework for tuning not only the MPC-MCA optimally but also all the MPC-based applications while minimizing the desired cost function and computational load. The simulation results show the effectiveness of the proposed method in terms of output performance improvement and the computational burden. © 2017 Elsevier Ltd","Genetic Algorithm; Model Predictive Control; Motion Cueing Algorithm; Optimization","Automobile simulators; Cost effectiveness; Cost functions; Errors; Forecasting; Genetic algorithms; Model predictive control; Optimization; Predictive control systems; Safety testing; Simulators; Computational burden; Computational loads; Iterative trial and error; Limited workspaces; Motion cueing algorithms; Output performance; Prediction horizon; Transportation safety; Iterative methods",2-s2.0-85029792785
"Ho-Huu V., Hartjes S., Visser H.G., Curran R.","An improved MOEA/D algorithm for bi-objective optimization problems with complex Pareto fronts and its application to structural optimization",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030720481&doi=10.1016%2fj.eswa.2017.09.051&partnerID=40&md5=9493ee28fb95295c6ce32e90022dacbd","The multi-objective evolutionary algorithm based on decomposition (MOEA/D) has been recognized as a promising method for solving multi-objective optimization problems (MOPs), receiving a lot of attention from researchers in recent years. However, its performance in handling MOPs with complicated Pareto fronts (PFs) is still limited, especially for real-world applications whose PFs are often complex featuring, e.g., a long tail or a sharp peak. To deal with this problem, an improved MOEA/D (named iMOEA/D) that mainly focuses on bi-objective optimization problems (BOPs) is therefore proposed in this paper. To demonstrate the capabilities of iMOEA/D, it is applied to design optimization problems of truss structures. In iMOEA/D, the set of the weight vectors defined in MOEA/D is numbered and divided into two subsets: one set with odd-weight vectors and the other with even-weight vectors. Then, a two-phase search strategy based on the MOEA/D framework is proposed to optimize their corresponding populations. Furthermore, in order to enhance the total performance of iMOEA/D, some recent developments for MOEA/D, including an adaptive replacement strategy and a stopping criterion, are also incorporated. The reliability, efficiency and applicability of iMOEA/D are investigated through seven existing benchmark test functions with complex PFs and three optimal design problems of truss structures. The obtained results reveal that iMOEA/D generally outperforms MOEA/D and NSGA-II in both benchmark test functions and real-world applications. © 2017 Elsevier Ltd","Complicated Pareto fronts (PFs); Multi-objective evolutionary algorithm (MOEA); Multi-objective evolutionary algorithm based on decomposition (MOEA/D); Structural optimization; Truss structures","Benchmarking; Multiobjective optimization; Optimization; Shape optimization; Structural optimization; Trusses; Bi-objective optimization; Design optimization problem; Multi objective evolutionary algorithms; Multiobjective optimization problems (MOPs); Pareto front; Replacement strategy; Total performance; Truss structure; Evolutionary algorithms",2-s2.0-85030720481
"Wang L., Mak T.","A Fault-Tolerant Routing Algorithm Using Tunnels in Fault Blocks for Network-on-Chip",2018,"Journal of Circuits, Systems and Computers",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029213446&doi=10.1142%2fS0218126618500226&partnerID=40&md5=061c7d8e18d03d3e0c058ec534cf851d","In 2D mesh Network on Chips (NoCs), fault-tolerant algorithms usually deactivate healthy nodes to form rectangular or convex fault blocks. However, the deactivated nodes can possibly form an available tunnel in a faulty block. We propose a method to discover these tunnels, and propose a fault-tolerant routing algorithm to route messages through such paths such that the overall communication performance is improved. In addition, the algorithm is deadlock-free by prohibiting some turns. Simulation results demonstrate that the reuse of the sacrificed nodes in fault blocks can significantly reduce the average message latency. © 2018 World Scientific Publishing Company.","Fault block; Fault-tolerant routing; Mesh; Network on Chips; Tunnel","Distributed computer systems; Fault tolerance; Fault tolerant computer systems; Mesh generation; Network architecture; Network routing; Routers; Routing algorithms; Tunnels; Communication performance; Fault blocks; Fault tolerant algorithms; Fault tolerant routing; Fault-tolerant routing algorithm; Mesh; Message latency; Route messages; Network-on-chip",2-s2.0-85029213446
"Kobeaga G., Merino M., Lozano J.A.","An efficient evolutionary algorithm for the orienteering problem",2018,"Computers and Operations Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029506394&doi=10.1016%2fj.cor.2017.09.003&partnerID=40&md5=687b050ba9854c20cc6e6eb16e562505","This paper deals with the Orienteering Problem, which is a routing problem. In the Orienteering Problem each node has a profit assigned and the goal is to find the route that maximizes the total collected profit subject to a limitation on the total route distance. To solve this problem, we propose an evolutionary algorithm, whose key characteristic is to maintain unfeasible solutions during the search. Furthermore, it includes a novel solution codification for the Orienteering Problem, a novel heuristic for node inclusion in the route, an adaptation of the Edge Recombination crossover developed for the Travelling Salesperson Problem, specific operators to recover the feasibility of solutions when required, and the use of the Lin-Kernighan heuristic to improve the route lengths. We compare our algorithm with three state-of-the-art algorithms for the problem on 344 benchmark instances, with up to 7397 nodes. The results show a competitive behavior of our approach in instances of low-medium dimensionality, and outstanding results in the large dimensionality instances reaching new best known solutions with lower computational time than the state-of-the-art algorithms. © 2017 Elsevier Ltd","Combinatorial optimization; Evolutionary algorithm; Orienteering problem; Travelling salesperson problem","Benchmarking; Combinatorial optimization; Evolutionary algorithms; Optimization; Profitability; Competitive behavior; Computational time; Key characteristics; Orienteering problem; Routing problems; Specific operators; State-of-the-art algorithms; Travelling salesperson problems; Problem solving",2-s2.0-85029506394
"Meng Q., Lu X., Zhang B., Gu Y., Ren G., Huang X.","Research on the ROI registration algorithm of the cardiac CT image time series",2018,"Biomedical Signal Processing and Control",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029450708&doi=10.1016%2fj.bspc.2017.09.011&partnerID=40&md5=e0faaf8b8e3dd0fdecd60cfbe96b0216","Objective Based on the Scale-invariant feature transform (SIFT) features, a novel registration algorithm is proposed to solve the problems including the large amount of data emerged from the cardiac image registration process, time-consuming issue and the lower registration accuracy. Method First of all, the region of interest (ROI) of the image to be registered is extracted; then, the feature points of the image are extracted by using the SIFT algorithm; finally, a novel registration algorithm which combines the adopted K-d tree Nearest Neighbor (KNN) Best-Bin-First (BBF) algorithm with the random sampling consensus (RANSAC) algorithm is employed to achieve the registration algorithm and to enhance the registration accuracy, so as to solve the high dimensionality of feature vector and easier mismatching issues. Result The experimental results are as follows: first of all, the amount of data processed during the registration is reduced by 60%–80% after extracting the ROI without destroying the original image data. Secondly, the registration time is reduced by 50%–70%, compared with the traditional registration algorithm. Thirdly, the whole registration precision increases by 10%–20% by using the BBF algorithm to match the feature points and using the RANSAC algorithm to filter the mismatching. Conclusion The proposed algorithm equipped with the robustness and stability can greatly reduce the time required for registration, improve the registration accuracy. © 2017","Adopted K-Nearest Neighbor (KNN) Best-Bin-First (BBF); Medical image registration; Random sampling consensus (RANSAC); Region of interest","Bins; Image processing; Image registration; Image segmentation; Learning algorithms; Medical imaging; Nearest neighbor search; Object recognition; Trees (mathematics); Best bin firsts; Random sampling; Region of interest; Registration accuracy; Registration algorithms; Registration precision; Scale invariant feature transforms; The region of interest (ROI); Computerized tomography; accuracy; Article; cardiac imaging; computer assisted tomography; image processing; k nearest neighbor; learning algorithm; priority journal; random sample",2-s2.0-85029450708
"Peres W., Silva Júnior I.C., Passos Filho J.A.","Gradient based hybrid metaheuristics for robust tuning of power system stabilizers",2018,"International Journal of Electrical Power and Energy Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027525080&doi=10.1016%2fj.ijepes.2017.08.014&partnerID=40&md5=d9b48a1bf723d15d8f96d201346eefeb","Power System Stabilizers are controllers installed on synchronous generators to damp power system oscillations through the excitation control. These controllers can have either a conventional fixed structure composed by stages of gain and phase compensation or a flexible modern structure composed by three bands that correspond to a specific frequency range (low, intermediate and high frequency) in which each band is composed by two branches that are based on differential filters (with a gain, lead-lag blocks and a hybrid block). Power system stabilizers design is a hard and time consuming task and an alternative for tuning controllers is by using optimization methods. This paper presents three hybrid metaheuristics for the robust and coordinated design of power system stabilizers. The tuning procedure is modeled as an optimization problem which aims at maximizing the damping ratio coefficients in closed-loop operation. Robustness requirement is met by using multiple operating scenarios in the design stage. For solving the optimization problem, three metaheuristics (Gravitational Search Algorithm, Bat Algorithm and Particle Swarm Optimization) are combined with the Steepest Descent Method for local search capability enhancement. The proposed hybrid algorithms are applied to benchmark systems for validation. © 2017 Elsevier Ltd","Bat algorithm; Gravitational search algorithm; Hybrid metaheuristics; Particle swarm optimization; Robust design of conventional and modern power system stabilizers","Controllers; Electric power system control; Evolutionary algorithms; Heuristic algorithms; Learning algorithms; Particle swarm optimization (PSO); Steepest descent method; Bat algorithms; Closed-loop operation; Gravitational search algorithms; Hybrid metaheuristics; Optimization problems; Power system oscillations; Power System Stabilizer; Time-consuming tasks; Optimization",2-s2.0-85027525080
"Cui S., Wang Y.-W., Lin X., Liu X.-K.","Distributed auction optimization algorithm for the nonconvex economic dispatch problem based on the gossip communication mechanism",2018,"International Journal of Electrical Power and Energy Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029038327&doi=10.1016%2fj.ijepes.2017.09.012&partnerID=40&md5=b71555828634b8d7fe25006339b49507","This paper presents an efficient distributed auction optimization algorithm (DAOA) based on the gossip communication mechanism for the nonconvex economic dispatch problem. The problem contains several constraints such as generation output limits, valve-point loading effects, multiple fuels, and the supply-demand balance. The gossip communication mechanism runs as two layers. The first layer triggers the leaders to conduct the local auction optimization, and the second layer is the auction protocol that selects the optimal neighbors to cooperate with the leaders to implement the auction decision. Auction optimization is a local optimization method, in which the units evaluate the bids of a certain amount of output power and the paired bid winners update their output power to reduce the generation cost. Better solutions can be obtained through gossip communication and local optimizations. Numerous simulations are conducted to demonstrate the effectiveness of the proposed strategy. © 2017 Elsevier Ltd","Auction optimization; Distributed algorithm; Economic dispatch; Gossip mechanism; Nonconvex; Smart grid","Optimization; Parallel algorithms; Scheduling; Economic Dispatch; Gossip mechanisms; Local optimization methods; Non-convex economic dispatches; Nonconvex; Optimization algorithms; Smart grid; Valve-point loading effect; Electric load dispatching",2-s2.0-85029038327
"Pławiak P.","Novel methodology of cardiac health recognition based on ECG signals and evolutionary-neural system",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030751834&doi=10.1016%2fj.eswa.2017.09.022&partnerID=40&md5=5b76b1ca840e34dd808910f005ebcd66","This article presents an innovative research methodology that enables the efficient classification of cardiac disorders (17 classes) based on ECG signal analysis and an evolutionary-neural system. From a social point of view, it is extremely important to prevent heart diseases, which are the most common cause of death worldwide. According to statistical data, 50 million people are at risk for cardiac diseases worldwide. The subject of ECG signal analysis is very popular. However, due to the great difficulty of the task undertaken, and high computational complexity of existing methods, there remains substantial work to perform. This research collected 1000 fragments of ECG signals from the MIH-BIH Arrhythmia database for one lead, MLII, from 45 patients. An original methodology that consisted of the analysis of longer (10-s) fragments of the ECG signal was used (an average of 13 times less classifications). To enhance the characteristic features of the ECG signal, the spectral power density was estimated (using Welch's method and a discrete Fourier transform). Genetic optimization of parameters and genetic selection of features were tested. Pre-processing, normalization, feature extraction and selection, cross-validation and machine learning algorithms (SVM, kNN, PNN, and RBFNN) were used. The best evolutionary-neural system, based on the SVM classifier, obtained a recognition sensitivity of 17 myocardium dysfunctions at a level of 90.20% (98 errors per 1000 classifications, accuracy = 98.85%, specificity = 99.39%, time for classification of one sample = 0.0023 [s]). Against the background of the current scientific literature, these results are some of the best results to date. © 2017 Elsevier Ltd","Biomedical signal processing and analysis; Classification; Discrete Fourier transform; ECG; Evolutionary-neural system; Feature extraction and selection; Genetic algorithm; K-nearest neighbor algorithm; Machine learning algorithms; Neural networks; Support vector machine","Artificial intelligence; Bioinformatics; Cardiology; Classification (of information); Discrete Fourier transforms; Diseases; Electrocardiography; Evolutionary algorithms; Extraction; Feature extraction; Genetic algorithms; Heart; Learning algorithms; Learning systems; Nearest neighbor search; Neural networks; Optimization; Pattern recognition; Signal analysis; Signal processing; Support vector machines; Feature extraction and selection; Genetic optimization; Innovative research; K nearest neighbor algorithm; Neural systems; Scientific literature; Spectral power density; Statistical datas; Biomedical signal processing",2-s2.0-85030751834
"He J., Tang X., Gong P., Wang P., Wen L., Huang X., Han Z., Yan W., Gao L.","Rapid radionuclide identification algorithm based on the discrete cosine transform and BP neural network",2018,"Annals of Nuclear Energy",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030471072&doi=10.1016%2fj.anucene.2017.09.032&partnerID=40&md5=dd453453dd11eb3c0432db935bb22de1","Traditional radionuclide identification algorithm based on peak detection cannot recognize radioactive material in a short time. This study proposes a rapid radionuclide identification algorithm based on the discrete cosine transform and error back propagation neural network. Detection rate and accurate radionuclide identification distance were used to evaluate the proposed method. Experimental results show that the extracted feature vector of the spectrum is not influenced by time, activity, and distance. The proposed algorithm obtained better results in a relatively authentic environment, and it has the ability to predict the isotopic compositions of the mixed spectrum. The proposed method has a better identification performance for the spectrum of radionuclide masked by shielding material except the gamma rays emitted by related radionuclide are significantly shielded. It is also particularly recommended for the fast radionuclide identification of spectroscopic radiation portal monitors, radioisotope identification devices, and other radiation monitoring instruments. © 2017 Elsevier Ltd","BP neural network; Detection rate; Discrete cosine transform; Feature extraction; Radionuclide identification","Backpropagation; Backpropagation algorithms; Discrete cosine transforms; Feature extraction; Gamma rays; Neural networks; Nuclear reactors; Radioactive materials; BP neural networks; Detection rates; Error backpropagation neural network; Identification algorithms; Identification distances; Radiation monitoring; Radiation portal monitors; Radioisotope identification devices; Radioisotopes",2-s2.0-85030471072
"Wang D., Zhang Z., Bai R., Mao Y.","A hybrid system with filter approach and multiple population genetic algorithm for feature selection in credit scoring",2018,"Journal of Computational and Applied Mathematics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020173958&doi=10.1016%2fj.cam.2017.04.036&partnerID=40&md5=9d4c5d7405318c299c54f293e2d6e2df","With the financial crisis happened in 2007, massive credit risks are exposed to the banking sectors. So credit scoring has attracted more and more attention. Bank owns a lot of customer data. By using those data, credit scoring model can judge the applicants’ credit risk accurately. But those data are often high dimensional, and have some irrelevant features. Those irrelevant features will affect classifiers accuracy. Therefore, feature selection is an important topic. This paper proposes a two-phase hybrid approach based on filter approach and multiple population genetic algorithm-HMPGA. In phase 1, it introduces the idea of wrapper approach into three filter approaches to acquire some important prior information for initial populations setting of MPGA. In phase 2, it takes advantage of MPGA's characteristics of global optimization and quick convergence to find optimal feature subset. This paper uses two real credit scoring datasets of UCI databases to compare HMPGA, MPGA and GA. It verifies that the accuracies of feature subsets acquired from HMPGA, MPGA and GA are superior to three filter approaches. Meanwhile, nonparametric Wilcoxon signed rank test is held to confirm that HMPGA is better than MPGA and GA. HMPGA not only can be applied to feature selection of credit scoring, but also can be applied to more fields of data mining. © 2017 Elsevier B.V.","Credit scoring; Feature selection; HMPGA; Hybrid approach","Bandpass filters; Data mining; Feature extraction; Filtration; Genetic algorithms; Global optimization; Hybrid systems; Optimization; Risk assessment; Credit scoring; Credit scoring model; HMPGA; Hybrid approach; Initial population; Multiple population genetic algorithms; Prior information; Wilcoxon signed rank test; Classification (of information)",2-s2.0-85020173958
"Leng B., Xiong L., Yu Z., Zou T.","Allocation control algorithms design and comparison based on distributed drive electric vehicles",2018,"International Journal of Automotive Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030317303&doi=10.1007%2fs12239-018-0006-3&partnerID=40&md5=171d18f01a5c6a51b434a5bcf1e31bae","For a distributed drive electric vehicle (DDEV) which is equipped with redundant actuators, allocation control is a key technique. Three different allocation control algorithms are designated with fixed efficiency matrix, dynamic efficiency matrix, and direct yaw moment distribution, respectively. All these algorithms are applied in a vehicle stability control system with hierarchical control structure and evaluated from three aspects, namely, control precision, real-time characteristics, and control energy. Comparison results demonstrate that the algorithm with dynamic efficiency matrix has the best comprehensive performance, which is also validated in field tests based on a DDEV equipped with four motors. © 2018, The Korean Society of Automotive Engineers and Springer-Verlag GmbH Germany.","Allocation control; Distributed drive electric vehicle; Efficiency matrix; Stability control","Electric vehicles; Vehicles; Comprehensive performance; Dynamic efficiency; Efficiency matrix; Hierarchical control structure; Real time characteristics; Redundant actuators; Stability control; Vehicle stability control systems; Electric machine control",2-s2.0-85030317303
"Li J., Zhou T., Wang C.","On global convergence of gradient descent algorithms for generalized phase retrieval problem",2018,"Journal of Computational and Applied Mathematics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027399915&doi=10.1016%2fj.cam.2017.07.008&partnerID=40&md5=87ad61c07ad915b48d4f718386265dff","In this paper, we study the generalized phase retrieval problem: to recover a signal x∈Cn from the measurements yr=|〈ar,x〉|2, r=1,2,…,m. The problem can be reformulated as a least-squares minimization problem. Although the cost function is nonconvex, the global convergence of gradient descent algorithms from a random initialization is studied, when m is large enough. We improve the known result of the local convergence from a spectral initialization. When the signal x is real-valued, we prove that the cost function is local convex near the solution {±x}. To accelerate the gradient descent, we review and apply several efficient line search methods with exact line search stepsize. We also perform a comparative numerical study of the line search methods and the alternative projection method. Numerical simulations demonstrate the superior ability of LBFGS algorithm than other algorithms. © 2017 Elsevier B.V.","Global convergence; Gradient descent; LBFGS; Local convexity; Phase retrieval","Cost functions; Particle separators; Global conver-gence; Gradient descent; LBFGS; Local convexities; Phase retrieval; Numerical methods",2-s2.0-85027399915
"Liu X., Stechlinski P.","Switching and impulsive control algorithms for nonlinear hybrid dynamical systems",2018,"Nonlinear Analysis: Hybrid Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032588233&doi=10.1016%2fj.nahs.2017.09.004&partnerID=40&md5=9493da9903a71680e2ba254b198e475b","Control algorithms are developed for physical processes modeled as hybrid dynamical systems (HDSs). In this framework, a HDS is a nonlinear switched system of ordinary differential equations (ODEs) coupled with impulsive equations. Switching and impulsive control is applied with two performance goals in mind: First, a high-frequency switching control method is provided to drive a HDS state to the origin while only requiring the HDS state intermittently. Attractivity of the origin is proved under a shell bisection algorithm; a high-frequency switching control rule is designed for this purpose. Second, a state-dependent switching control strategy is derived for when the transient behavior of the HDS is of interest. Finite-time stabilization is guaranteed under a so-called minimum rule algorithm; for each HDS mode, the state space is divided into different control regions and a switching control rule is constructed to switch between controllers whenever a boundary is reached. The theoretical tools used in this article include the Campbell–Baker–Hausdorff formula, multiple Lyapunov functions, and average dwell-time conditions. © 2017 Elsevier Ltd","Finite-time stabilization; High-frequency switching; Hybrid systems; Multiple Lyapunov functions; State-dependent switching; Switched systems","Differential equations; Dynamical systems; Hybrid systems; Lyapunov functions; Nonlinear equations; Ordinary differential equations; Stabilization; Finite time stabilization; High-frequency switching; Multiple Lyapunov function; State dependent switching; Switched system; Switching",2-s2.0-85032588233
"Kim S.H., Koo G., Jeong J.J., Kim S.W.","An adjusting-block based convex combination algorithm for identifying block-sparse system",2018,"Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028010758&doi=10.1016%2fj.sigpro.2017.08.014&partnerID=40&md5=0bc3d0b09c939d5bb089924ca50846b9","A novel block wise convex combination algorithm with adjusting blocks is proposed for block-sparse system identification. The proposed algorithm unifies the complementary advantages of different block-induced algorithms, which are based on block proportionate matrix and block zero attracting penalty. A mixing parameter for block wise combination is designed as a block diagonal matrix. The mixing parameter is obtained using the conventional mixing parameter, which represents convergence state, and a block activeness indicator. The indicator for each block is derived from the lϵ0-norm measure of the block. Moreover, a block adjustment algorithm is developed using the indicator to overcome the main disadvantage of block-induced algorithms, i.e., the dependency on cluster location. The simulations for system identification are performed on several block-sparse systems including systems with single cluster and double clusters. The simulation results show that the proposed algorithm not only combines the different block-induced algorithms effectively but also improves the performance via the block adjustment algorithm. © 2017 Elsevier B.V.","Adaptive filter; Echo cancellation; NLMS algorithm; Proportionate matrix; Zero-attracting penalty","Adaptive filtering; Adaptive filters; Echo suppression; Mixing; Religious buildings; Block adjustment; Block diagonal matrices; Block sparse; Convergence state; Convex combinations; Mixing parameters; NLMS algorithm; Zero-attracting; Clustering algorithms",2-s2.0-85028010758
"Kvasov D.E., Mukhametzhanov M.S.","Metaheuristic vs. deterministic global optimization algorithms: The univariate case",2018,"Applied Mathematics and Computation",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019578331&doi=10.1016%2fj.amc.2017.05.014&partnerID=40&md5=6fa124048a4858e0d983e43135e41e65","Many practical problems involve the search for the global extremum in the space of the system parameters. The functions to be optimized are often highly multiextremal, black-box with unknown analytical representations, and hard to evaluate even in the case of one parameter to be adjusted in the presence of non-linear constraints. The interest of both the stochastic (in particular, metaheuristic) and mathematical programming (in particular, deterministic) communities to the comparison of metaheuristic and deterministic classes of methods is well recognized. Although both the communities have a huge number of journal and proceedings papers, a few of them are really dedicated to a systematic comparison of the methods belonging to these two classes. This paper meets the requirement of such a comparison between nature-inspired metaheuristic and deterministic algorithms (more than 125,000 launches of the methods have been performed) and presents an attempt (beneficial to practical fields including engineering design) to bring together two rather disjoint communities of metaheuristic and mathematical programming researchers and applied users. © 2017 Elsevier Inc.","Constrained global optimization; Lipschitz-based deterministic approaches; Nature-inspired metaheuristics; Numerical comparison","Constrained optimization; Global optimization; Mathematical programming; Stochastic systems; 65K05; 65Y20; 90C26; Constrained global optimization; Deterministic approach; Meta heuristics; Numerical comparison; Optimization",2-s2.0-85019578331
"Brugnano L., Kvasov D.E., Sergeyev Y.D.","Foreword to the special issue ‘‘Recent Trends in Numerical Computations: Theory and Algorithms’’",2018,"Applied Mathematics and Computation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031814590&doi=10.1016%2fj.amc.2017.09.012&partnerID=40&md5=f500ad5912001a1ebe01bbf9bb079870",[No abstract available],,,2-s2.0-85031814590
"Morini M., Pellegrino S.","Personal income tax reforms: A genetic algorithm approach",2018,"European Journal of Operational Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994297240&doi=10.1016%2fj.ejor.2016.07.059&partnerID=40&md5=3481b3522a2e934591d3738a6eb77505","Given a settled reduction in the present level of tax revenue, and by exploring a very large combinatorial space of tax structures, in this paper we employ a genetic algorithm in order to determine the ‘best’ structure of a real world personal income tax that allows for the maximisation of the redistributive effect of the tax, while preventing all taxpayers being worse off than with the present tax structure. We take Italy as a case study. © 2016 Elsevier B.V.","Genetic algorithms; Micro-simulation models; Personal income taxation; Reynolds–Smolensky index; Tax reforms","Genetic algorithms; Genetic algorithm approach; Microsimulation models; Personal income; Personal income taxes; Reynolds; Tax reform; Tax revenue; Tax structures; Taxation",2-s2.0-84994297240
"He Y., Liu C., Xu Z., Zhang Z., Li S.","Application of Inverse Patch Transfer Functions Method with Wideband Holography Algorithm to Sparsely Distributed Sources Identification",2018,"Journal of Vibration and Acoustics, Transactions of the ASME",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029168423&doi=10.1115%2f1.4037471&partnerID=40&md5=98e130149babf23cb76836d138650fce","Inverse patch transfer functions (iPTF) method has been developed to reconstruct the sound field of irregularly shaped sources in a noisy environment. The iPTF method, which uses classic regularization methods to solve the ill-posed problems generally, would incur some sidelobes ghosting in the process of identifying sparse sources. In view of the fact that the algorithm in wideband holography (WBH) can promote sparsity of results, a technique combining iPTF method with WBH algorithm is proposed to identify sparsely distributed sources in the present work. In the proposed technique, double layer pressure measurements are used to replace the measurements of the pressure and normal velocity which uses costly p-u probes. A gradient descent algorithm and a filtering process are applied to solve the minimization problem of identifying the normal velocities of target sources, which can suppress ghosting sources rapidly by an iterative process. In simulations, the field reconstruction results of two antiphase square piston sources show good sparsity and accuracy by employing the technique, nearly without ghosting sources. At different distances and frequencies of the two sources, the technique still performs well. Experimental validations at 200 Hz and 400 Hz are carried out in the end. The results of experiments are also coinciding with those of simulations. Copyright © 2018 by ASME.","inverse patch transfer functions (iPTF); sparse sources identification; WBH algorithm","Acoustic fields; Acoustics; Holography; Inverse problems; Transfer functions; Distributed sources; Experimental validations; Field reconstruction; Gradient descent algorithms; Minimization problems; Patch transfer functions; Regularization methods; Sparse sources; Iterative methods",2-s2.0-85029168423
"Nikfar M., Mayeli P.","Surface Shape Design in Different Convection Heat Transfer Problems Via a Novel Coupled Algorithm",2018,"Journal of Heat Transfer",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029782023&doi=10.1115%2f1.4037581&partnerID=40&md5=3ad5510629d905f8cf8d954d96307eeb","In this study, a new coupled surface shape design (SSD) methodology named direct design method is presented for the solution of problems containing different types of convection heat transfer in which a specific distribution of either heat flux or temperature is given instead of the shape of a boundary. In the proposed method, the governing equation, without using any mathematical transformation for the physical domains, is manipulated so that the grid generation, solving fluid flow, and heat transfer as well as shape updating can all be carried out simultaneously. Five different inverse shape design problems containing different types of convection heat transfer are solved by the proposed method. All the problems are also solved using the ball-spine algorithm (BSA), which is a recently developed de-coupled algorithm, for the sake of comparison. In all problems, the effects of using different under-relaxation parameters are investigated and the capability of both approaches is compared with each other. The results show that the proposed coupled method can solve the problems better than the BSA in the sense that the direct design method converges sooner than the BSA when the same under-relaxation parameter is used for both methods. Also, it is shown that the computational cost of solving a SSD problem using the direct design method is slightly greater than solving an analysis problem. Copyright © 2018 by ASME.","ball-spine algorithm (BSA); convection heat transfer; coupled algorithms; direct design method; surface shape design (SSD)","Design; Flow of fluids; Heat convection; Heat flux; Heat transfer; Mathematical transformations; Problem solving; Analysis problems; ball-spine algorithm (BSA); Computational costs; Coupled algorithms; Direct design method; Governing equations; Specific distribution; Surface shape; Inverse problems",2-s2.0-85029782023
"Hamamoto A.H., Carvalho L.F., Sampaio L.D.H., Abrão T., Proença M.L., Jr.","Network Anomaly Detection System using Genetic Algorithm and Fuzzy Logic",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030706780&doi=10.1016%2fj.eswa.2017.09.013&partnerID=40&md5=154a59286fbbb5b42a5f9fbac5588b63","Due to the sheer number of applications that uses computer networks, in which some are crucial to users and enterprises, network management is essential. Therefore, integrity and availability of computer networks become priorities, making it a fundamental resource to be managed. In this work, a scheme combining Genetic Algorithm and a Fuzzy Logic for network anomaly detection is discussed. The Genetic Algorithm is used to generate a Digital Signature of Network Segment using Flow Analysis, where information extracted from network flows data is used to predict the networks traffic behavior for a given time interval. Furthermore, a Fuzzy Logic scheme is applied to decide whether an instance represents an anomaly or not, differing from some approaches present in the literature. Indeed, it is proposed an expert system with the capability to monitor the network's traffic with IP flows while expected behaviors are generated in a regular time interval basis, issuing alarms when a possible problem is present. The proposed anomaly detection system exposes network problems autonomously. The results acquired from applying the proposed approach in a real network traffic flows achieve an accuracy of 96.53% and false positive rate of 0.56%. Moreover, our method succeeds in achieving higher performance compared to several other approaches. © 2017 Elsevier Ltd","Fuzzy Logic; Genetic Algorithm; Network Anomaly Detection System; Network management","Computer circuits; Computer networks; Expert systems; Genetic algorithms; Network management; Anomaly detection systems; False positive rates; Network anomaly detection; Network flows; Network problems; Network segment; Networks traffics; Real networks; Fuzzy logic",2-s2.0-85030706780
"Ge Y., Shan F., Liu Z., Liu W.","Optimal Structural Design of a Heat Sink With Laminar Single-Phase Flow Using Computational Fluid Dynamics-Based Multi-Objective Genetic Algorithm",2018,"Journal of Heat Transfer",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030149140&doi=10.1115%2f1.4037643&partnerID=40&md5=d99ddf7f85443e4020800e15490c50f0","This paper proposes a general method combining evolutionary algorithm and decision-making technique to optimize the structure of a minichannel heat sink (MCHS). Two conflicting objectives, the thermal resistance θ and the pumping power P, are simultaneously considered to assess the performance of the MCHS. In order to achieve the ultimate optimal design, multi-objective genetic algorithm is employed to obtain the nondominated solutions (Pareto solutions), while technique for order preference by similarity to an ideal solution (TOPSIS) is employed to determine which is the best compromise solution. Meanwhile, both the material cost and volumetric flow rate are fixed where this nonlinear problem is solved by applying the penalty function. The results show that θ of Pareto solutions varies from 0.03707 K W-1 to 0.10742 K W-1, while P varies from 0.00307 W to 0.05388 W, respectively. After the TOPSIS selection, it is found that P is significantly reduced without increasing too much θ. As a result, θ and P of the optimal MCHS determined by TOPSIS are 35.82% and 52.55% lower than initial one, respectively. Copyright © 2018 by ASME.",,"Computational fluid dynamics; Decision making; Genetic algorithms; Heat sinks; Structural design; Conflicting objectives; Multi-objective genetic algorithm; Nondominated solutions; Nonlinear problems; Optimal structural designs; Penalty function; Single-phase flow; Volumetric flow rate; Structural optimization",2-s2.0-85030149140
"Yuan H., Memon S.F., Newe T., Lewis E., Leen G.","Motion artefact minimization from photoplethysmography based non-invasive hemoglobin sensor based on an envelope filtering algorithm",2018,"Measurement: Journal of the International Measurement Confederation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032580096&doi=10.1016%2fj.measurement.2017.10.060&partnerID=40&md5=07fc60774cd4233c352de64e759d446a","An envelope-filtered method of enhancement of non-invasive Hemoglobin (Hb) monitoring is described. Results using a four-wavelength two-wavelength Photoplethysmography (PPG) probe gathered from five randomly selected healthy subjects demonstrate that the measurement of Hb coefficient, based on the novel envelope method filtered PPG, has a superior performance on minimization of the motion artefact than that from band-pass filtered PPG data in both stationary and non-stationary scenarios. Hemodynamic pressure variation near the sensor probe is also induced from a vertical height difference (VHD) between the finger sensor probe and the heart level. Results of this study show that the Hb coefficients determined using the proposed filtering method based on the envelope algorithm are also capable of minimization of VHD variations similar to the traditional band-pass filter method. © 2017 Elsevier Ltd","Envelope filtering method; Motion artefact removal; Non-invasive Hemoglobin sensor; Photoplethysmography signal","Hemoglobin; Photoplethysmography; Probes; Signal filtering and prediction; Envelope algorithms; Envelope method; Filtering algorithm; Filtering method; Healthy subjects; Motion artefacts; Photoplethysmography (PPG); Pressure variations; Bandpass filters",2-s2.0-85032580096
"Zhu W., Xu P., Bui T.O., Wu G., Yang Y.","Energy-efficient cell-association bias adjustment algorithm for ultra-dense networks",2018,"Science China Information Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028751450&doi=10.1007%2fs11432-016-9143-6&partnerID=40&md5=26091359898b678b430fc85b6ba701e6","In recent years, energy efficiency has become an important topic, especially in the field of ultra-dense networks (UDNs). In this area, cell-association bias adjustment and small cell on/off are proposed to enhance the performance of energy efficiency in UDNs. This is done by changing the cell association relationship and turning off the extra small cells that have no users. However, the variety of cell association relationships and the switching on/off of the small cells may deteriorate some users’ data rates, leading to nonconformance to the users’ data rate requirement. Considering the discreteness and non-convexity of the energy efficiency optimization problem and the coupled relationship between cell association and scheduling during the optimization process, it is difficult to achieve an optimal cell-association bias. In this study, we optimize the network energy efficiency by adjusting the cell-association bias of small cells while satisfying the users’ data rate requirement. We propose an energy-efficient centralized Gibbs sampling based cell-association bias adjustment (CGSCA) algorithm. In CGSCA, global information such as channel state information, cell association information, and network load information need to be collected. Then, considering the overhead of the messages that are exchanged and the implementation complexity of CGSCA to obtain the global information in UDNs, we propose an energy-efficient distributed Gibbs sampling based cell-association bias adjustment (DGSCA) algorithm with a lower message-exchange overhead and implementation complexity. Using DGSCA, we derive the updated formulas for calculating the number of users in a cell and the users’ SINR. We analyze the implementation complexities (e.g., computation complexity and communication com- plexity) of the proposed two algorithms and other existing algorithms. We perform simulations, and the results show that CGSCA and DGSCA have faster convergence speed, as well as a higher performance gain of the energy efficiency and throughput compared to other existing algorithms. In addition, we analyze the importance of the users’ data rate constraint in optimizing the energy efficiency, and we compare the energy efficiency performance of different algorithms with different number of small cells. Then, we present the number of sleeping small cells as the number of small cells increases. © 2017, Science China Press and Springer-Verlag GmbH Germany.","cell-association bias; energy efficiency; Gibbs sampling; ultra-dense networks; users’ data rate constraint","Cells; Channel state information; Complex networks; Cytology; Optimization; Adjustment algorithms; Cell associations; Computation complexity; Data rate constraints; Dense network; Energy efficiency optimizations; Gibbs sampling; Implementation complexity; Energy efficiency",2-s2.0-85028751450
"Zhang X., Zheng X., Cheng R., Qiu J., Jin Y.","A competitive mechanism based multi-objective particle swarm optimizer with fast convergence",2018,"Information Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032229386&doi=10.1016%2fj.ins.2017.10.037&partnerID=40&md5=9845048eb543ff783153c5210f1f980e","In the past two decades, multi-objective optimization has attracted increasing interests in the evolutionary computation community, and a variety of multi-objective optimization algorithms have been proposed on the basis of different population based meta-heuristics, where the family of multi-objective particle swarm optimization is among the most representative ones. While the performance of most existing multi-objective particle swarm optimization algorithms largely depends on the global or personal best particles stored in an external archive, in this paper, we propose a competitive mechanism based multi-objective particle swarm optimizer, where the particles are updated on the basis of the pairwise competitions performed in the current swarm at each generation. The performance of the proposed competitive multi-objective particle swarm optimizer is verified by benchmark comparisons with several state-of-the-art multi-objective optimizers, including three multi-objective particle swarm optimization algorithms and three multi-objective evolutionary algorithms. Experimental results demonstrate the promising performance of the proposed algorithm in terms of both optimization quality and convergence speed. © 2017 Elsevier Inc.","Competitive swarm optimizer; Evolutionary algorithm; Multi-objective optimization; Particle swarm optimization","Benchmarking; Evolutionary algorithms; Multiobjective optimization; Particle swarm optimization (PSO); Benchmark comparison; Competitive mechanisms; Multi objective evolutionary algorithms; Multi objective particle swarm optimization; Multi-objective particle swarm optimization algorithms; Multi-objective particle swarm optimizer; Optimization quality; Swarm optimizer; Optimization",2-s2.0-85032229386
"Gong D., Liu K.","A multi-objective optimization model and its evolution-based solutions for the fingertip localization problem",2018,"Pattern Recognition",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032261005&doi=10.1016%2fj.patcog.2017.09.001&partnerID=40&md5=33ffc1ea8933b911b2728c3a4416b63b","Exact fingertip positions are of particular importance to the fingertip-based human–computer interaction. We build a multi-objective optimization model for the problem of fingertip localization, and present a method to solve the above model based on evolutionary algorithms. When building the model, we take the positions of a series of pixels as the decision variable, the shape of the hand-edge curve corresponding to each of the pixels as one objective function, and the distance between each of the pixels and the gravity center of the palm as the other objective function. In addition, based on the correlation among the positions of pixels of the fingertip regions, we present a multi-objective estimation of distribution algorithm to solve the model so as to obtain the best pixel set, thus gaining the fingertip positions. The experimental results demonstrate the effectiveness of the proposed model and algorithm. © 2017 Elsevier Ltd","Estimation of distribution algorithm; Fingertip localization; Multi-objective optimization; Probability distribution model","Evolutionary algorithms; Human computer interaction; Optimization; Pixels; Probability distributions; Computer interaction; Estimation of distribution algorithms; Fingertip localization; Localization problems; Model and algorithms; Multi-objective optimization models; Objective functions; Probability distribution model; Multiobjective optimization",2-s2.0-85032261005
"Boccaccio A., Fiorentino M., Uva A.E., Laghetti L.N., Monno G.","Rhombicuboctahedron unit cell based scaffolds for bone regeneration: geometry optimization with a mechanobiology – driven algorithm",2018,"Materials Science and Engineering C",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031791808&doi=10.1016%2fj.msec.2017.09.004&partnerID=40&md5=f7e7b086d473be8d0082876dcba44b92","In a context more and more oriented towards customized medical solutions, we propose a mechanobiology-driven algorithm to determine the optimal geometry of scaffolds for bone regeneration that is the most suited to specific boundary and loading conditions. In spite of the huge number of articles investigating different unit cells for porous biomaterials, no studies are reported in the literature that optimize the geometric parameters of such unit cells based on mechanobiological criteria. Parametric finite element models of scaffolds with rhombicuboctahedron unit cell were developed and incorporated into an optimization algorithm that combines them with a computational mechanobiological model. The algorithm perturbs iteratively the geometry of the unit cell until the best scaffold geometry is identified, i.e. the geometry that allows to maximize the formation of bone. Performances of scaffolds with rhombicuboctahedron unit cell were compared with those of other scaffolds with hexahedron unit cells. We found that scaffolds with rhombicuboctahedron unit cell are particularly suited for supporting medium-low loads, while, for higher loads, scaffolds with hexahedron unit cells are preferable. The proposed algorithm can guide the orthopaedic/surgeon in the choice of the best scaffold to be implanted in a patient-specific anatomic region. © 2017 Elsevier B.V.","Computational mechanobiology; Morphology optimization; Rhombicuboctahedron; Scaffold unit cell","Bone; Cells; Cytology; Finite element method; Geometry; Iterative methods; Optimization; Bone regeneration; Computational mechanobiology; Geometry optimization; Loading condition; Optimization algorithms; Parametric finite elements; Rhombicuboctahedron; Unit cells; Scaffolds (biology)",2-s2.0-85031791808
"Xu Z., Min B., Cheung R.C.C.","A fast inter CU decision algorithm for HEVC",2018,"Signal Processing: Image Communication",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032664657&doi=10.1016%2fj.image.2017.09.008&partnerID=40&md5=de424e1a507c03532b6449ea7569ca3b","A fast CU decision algorithm is very desirable for High Efficiency Video Coding (HEVC) due to its high encoding complexity. In this paper, a fast inter CU decision algorithm is proposed, with the motion correlations between neighboring CUs discussed. Decision for splitting of collocated CU has a strong impact on current CU, high-motion CUs are early split by means of calculating motion diversity of collocated CUs. On the other hand, SKIP mode indicates a motion sharing relation among neighboring CUs and it can be used to early determine CU termination. A discriminant function minimizing expected risk is defined for both early SKIP mode detection and SKIP mode based termination decision. Experimental results show that the proposed algorithm can reduce computational complexity by 48.2% with only 0.46% BDBR increase for random access configuration. For the low-delay B configuration, it can reduce complexity by 45.9% with 0.55% BDBR increase penalty. The results show our algorithm achieves less BDBR increase compared with other state-of-the-art works. © 2017","Fast inter coding; High Efficiency Video Coding (HEVC); Motion correlation","Codes (symbols); Efficiency; Decision algorithms; Discriminant functions; Encoding complexity; Fast inter coding; High-efficiency video coding; Motion correlation; SKIP mode detection; State of the art; Video signal processing",2-s2.0-85032664657
"Duval M., Lozinski A., Passieux J.C., Salaün M.","Residual error based adaptive mesh refinement with the non-intrusive patch algorithm",2018,"Computer Methods in Applied Mechanics and Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032334415&doi=10.1016%2fj.cma.2017.09.032&partnerID=40&md5=b2c19674989f2220032df907a357a132","This paper deals with the introduction of mesh refinement techniques within the non-intrusive patch process. For this, an ad hoc residual based explicit error estimator is built, which is adapted to a multi-scale solution, associated with those non-intrusive mesh refinement technique. Moreover, to reduce the global cost of the process, one introduces an estimate of the convergence error of the non-intrusive algorithm, which allows to reduce the number of iterations. This method is discussed and illustrated in various numerical examples. © 2017 Elsevier B.V.","Error estimation; Finite elements; Mesh refinement; Multiscale; Non-intrusive coupling","Error analysis; Finite element method; Mesh generation; Numerical methods; Adaptive mesh refinement; Convergence errors; Error estimators; Mesh refinement; Multiscale; Non-intrusive; Number of iterations; Patch algorithms; Errors",2-s2.0-85032334415
"Li P., Gu W., Wang L., Xu B., Wu M., Shen W.","Dynamic equivalent modeling of two-staged photovoltaic power station clusters based on dynamic affinity propagation clustering algorithm",2018,"International Journal of Electrical Power and Energy Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029164413&doi=10.1016%2fj.ijepes.2017.08.038&partnerID=40&md5=c7a56a6634327341e46796a695d6f46b","This paper presents a novel dynamic clustering equivalent modeling method for a two-staged photovoltaic (PV) station cluster, which is a key tool to analyze the dynamic responses of the distribution network with high PV penetration. In this paper, a dynamic affinity propagation (DAP) clustering algorithm is proposed after studying the indexes that can describe the dynamic characteristics of two-staged PV power station. Then this algorithm is used to group the PV stations in the PV cluster according to their dynamic characteristics. Finally, the dynamic equivalent model of PV cluster is obtained by parameters aggregation of PV stations in the same group and simplification equivalent of the network. The proposed method is verified by a PV cluster distribution network with 20 two-staged PV stations and the simulation results show that the proposed dynamic equivalent model can accurately reflect the dynamic response characteristics of the PV cluster. At the same time, the simplified PV cluster model would reduce the computational complexity and the simulation time significantly. © 2017 Elsevier Ltd","Dynamic equivalent modeling; Dynamic response; High PV penetration; PV station cluster; Two-staged photovoltaic (PV) station","Dynamic response; Photovoltaic cells; Affinity propagation clustering; Dynamic characteristics; Dynamic equivalent models; Dynamic response characteristics; Photovoltaic; Photovoltaic power stations; Pv penetrations; PV station cluster; Clustering algorithms",2-s2.0-85029164413
"Lu Y., Benlic U., Wu Q.","A hybrid dynamic programming and memetic algorithm to the Traveling Salesman Problem with Hotel Selection",2018,"Computers and Operations Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030110626&doi=10.1016%2fj.cor.2017.09.008&partnerID=40&md5=5e90cbae0edb816497673c8f385b88bd","The Traveling Salesman Problem with Hotel Selection (TSPHS) is a variant of the classic Traveling Salesman Problem. It arises from a number of real-life applications where the maximum travel time for each “day trip” is limited. In this paper, we present a highly effective hybrid between dynamic programming and memetic algorithm for TSPHS. The main features of the proposed method include a dynamic programming approach to find an optimal hotel sequence for a given tour, three dedicated crossover operators for solution recombination, an adaptive rule for crossover selection, and a two-phase local refinement procedure that alternates between feasible and infeasible searches. Experiments on four sets of 131 benchmark instances from the literature show a remarkable performance of the proposed approach. In particular, it finds improved best solutions for 22 instances and matches the best known results for 103 instances. Additional analyses highlight the contribution of the dynamic programming approach, the joint use of crossovers and the two local search phases to the performance of the proposed algorithm. © 2017 Elsevier Ltd","Dynamic programming; Infeasible local search; The traveling salesman problem","Benchmarking; Hotels; Local search (optimization); Travel time; Traveling salesman problem; Crossover operator; Hotel selections; Local refinement procedure; Local search; Maximum travel time; Memetic algorithms; Real-life applications; Two phase; Dynamic programming",2-s2.0-85030110626
"Chevtchenko S.F., Vale R.F., Macario V.","Multi-objective optimization for hand posture recognition",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030093519&doi=10.1016%2fj.eswa.2017.09.046&partnerID=40&md5=770eed2e63231515bfc21e1ead0ce6f7","Hand gestures are an intuitive way for humans to interact with computers. They are becoming increasingly popular in several applications, such as smart houses, games, vehicle infotainment systems, kitchens and operating theaters. An effective human–computer interaction system should aim at both good recognition accuracy and speed. This paper proposes a new approach for static hand gesture recognition. A benchmark database with 36 gestures is used, containing variations in scale, illumination and rotation. Several common image descriptors, such as Fourier, Zernike moments, pseudo-Zernike moments, Hu moments, complex moments and Gabor features are comprehensively compared in terms of their respective accuracy and speed. Gesture recognition is undertaken by a multilayer perceptron which has a flexible structure and fast recognition. In order to achieve improved accuracy and minimize computational cost, both the feature vector and the neural network are tuned by a multi-objective evolutionary algorithm based on the Nondominated Sorting Genetic Algorithm II (NSGA-II). The proposed method is compared with state-of-the-art methods. A real-time gesture recognition system based on the proposed descriptor is constructed and evaluated. Experimental results show a good recognition rate, using a descriptor with low computational cost and reduced size. © 2017 Elsevier Ltd","Feature selection; Gesture recognition; Sign language","Evolutionary algorithms; Feature extraction; Flexible structures; Genetic algorithms; Human computer interaction; Multiobjective optimization; Optimization; Palmprint recognition; Hand posture recognition; Multi objective evolutionary algorithms; Non dominated sorting genetic algorithm ii (NSGA II); Pseudo- Zernike Moments; Real time gesture recognition system; Sign language; State-of-the-art methods; Static hand gesture recognition; Gesture recognition",2-s2.0-85030093519
"Chen J., Zhang Y., Qi L., Fu C., Xu L.","Exploiting chaos-based compressed sensing and cryptographic algorithm for image encryption and compression",2018,"Optics and Laser Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030030493&doi=10.1016%2fj.optlastec.2017.09.008&partnerID=40&md5=313c5aee79976eecba0aae792db93889","This paper presents a solution for simultaneous image encryption and compression. The primary introduced techniques are compressed sensing (CS) using structurally random matrix (SRM), and permutation-diffusion type image encryption. The encryption performance originates from both the techniques, whereas the compression effect is achieved by CS. Three-dimensional (3-D) cat map is employed for key stream generation. The simultaneously produced three state variables of 3-D cat map are respectively used for the SRM generation, image permutation and diffusion. Numerical simulations and security analyses have been carried out, and the results demonstrate the effectiveness and security performance of the proposed system. © 2017 Elsevier Ltd","3-D cat map; Compressed sensing; Image encryption; Structurally random matrix","Compressed sensing; Image compression; Image processing; Cat map; Cryptographic algorithms; Image encryptions; Key stream generations; Permutation diffusions; Random Matrix; Security performance; Threedimensional (3-d); Cryptography",2-s2.0-85030030493
"Orlandi A.","Reduction of Total Radiated Power from a Planar EBG by Using a Multiple Objectives Sequential Optimization",2018,"IEEE Transactions on Electromagnetic Compatibility",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030321012&doi=10.1109%2fTEMC.2017.2747639&partnerID=40&md5=f2b4590089b4c658cb6d8d65f5cc9f49","The multiple objective sequential optimization (MOSO) is one of the recent fronteers of the multiple objectives optimization strategies. Such an optimization is applied, for the first time in the open literature, to the optimization of the performances of a commonmode filter based on a planar electromagnetic (EM) bandgap structure. The relevant design variables of this component are evaluated to increase the Scc21 bandwidth around the design frequency and to decrease the unwanted total EM radiated power. The MOSO implements, for the optimization, a differential evolutionary (DE) algorithm. The results are validated either by measurement or by the computations obtained by substituting the DE with a standard genetic algorithm. © 1964-2012 IEEE.","Common mode (CM) filter; differential evolutionary (DE) algorithm; electromagnetic (EM) radiation; electromagnetic bandgap (EBG); genetic algorithm; multiple objective sequential optimization (MOSO); total radiated power (TRP)","Cost functions; Energy gap; Genetic algorithms; Metamaterials; Multiobjective optimization; Numerical models; Optimization; Periodic structures; Structural design; Algorithm design and analysis; Commonmode; Differential evolutionary; Electromagnetic band gaps; Frequency measurements; Sequential optimization; Total radiated power; Evolutionary algorithms",2-s2.0-85030321012
"Luo K., Niu S., Shah D., Lonkar A., Liu Y., Ravichandran J.","Prediction of perovskite and other ternary oxide multilayers as mirrors for soft X-rays",2018,"Materials Research Bulletin",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032855611&doi=10.1016%2fj.materresbull.2017.10.018&partnerID=40&md5=bc81d0fdd28cc054b922ddd266528c1e","We propose multilayers of perovskite and related ternary oxides with a general formula of ABO3 as high reflectivity mirrors, especially for use in water window region (2.3–4.4 nm). The high reflectivity combinations of oxide multilayers were deduced using evolutionary search algorithms such as genetic algorithms, and the calculation speed was accelerated via parallel computing methods We also propose a figure of merit for X-ray reflectivity in periodic multilayers systems, which can simplify the future efforts on identifying material combinations, and the search through this multi-dimensional parameter space. The highest reflectivity value was found to be over 33% at 3.1 nm in the water window region. The effect of interface roughness was simulated and the decrease in reflectivity was found to be modest for practically achievable roughness values. This work establishes the foundation for future experimental and theoretical studies towards achieving high reflectivity x-ray mirrors of complex oxide multilayers. © 2017 Elsevier Ltd","Ceramics; Multilayers; Optical materials; Optical properties; Oxides","Evolutionary algorithms; Genetic algorithms; Mirrors; Multilayers; Optical materials; Optical properties; Oxides; Perovskite; Reflection; Ceramics; Evolutionary search algorithms; High reflectivity mirrors; Material combination; Multi-dimensional parameters; Parallel com- puting; Periodic multilayers; Reflectivity values; Optical multilayers",2-s2.0-85032855611
"Piotrowski A.P., Napiorkowski J.J.","Some metaheuristics should be simplified",2018,"Information Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032205209&doi=10.1016%2fj.ins.2017.10.039&partnerID=40&md5=6ce0789474956a72986618d30b25338e","Users have a large and constantly increasing number of optimization metaheuristics at their disposal. In pursuit of ever better approaches, popular and successful methods are often improved a number of times in a row, or various methods are hybridized. One should, however, pay attention to whether such deliberately improved or hybridized methods do not become unnecessarily complicated, or if some of their elements do not introduce a structural bias. In the first case the algorithm should be simplified by eliminating the unneeded elements. This will make it more clear to the users, and, as shown in this study, may even improve the results. In the second case, operators that are responsible for over-frequent sampling of some part of the search space have to be removed. In this study we address the problem of over-complexity of metaheuristics, focusing on two joint winners of the CEC2016 competition on single-objective numerical optimization, L-SHADE-EpSin and UMOEA-II algorithms. It is shown that each of them includes a procedure which introduces a structural bias by attracting population towards the origin O. As discussed in the text, in the case of seven out of 30 benchmark problems considered in the CEC2016 competition the objective function values in the origin O are better than those found by the vast majority of algorithms, hence structural bias affects the results obtained by L-SHADE-EpSin and UMOEA-II. In this work we simplify both algorithms by removing operators that are the main cause of structural bias. Further, we show that in the L-SHADE-EpSin algorithm the Ensemble Sinusoidal adaptation mechanism of control parameter F, that is used during the first half of the search, is not needed. Slightly better results on both artificial benchmarks used in the CEC2016 competition and on a wide set of real-world problems may be obtained if, during that period of the search, the value of F is simply set to 0.5. Such a simplified algorithm is competitive against a large number of metaheuristics and may be much easier for the users to understand. © 2017 Elsevier Inc.","CMA-ES; Complexity; Differential evolution; Evolutionary algorithms; Structural bias; Swarm intelligence","Evolutionary algorithms; Heuristic algorithms; Swarm intelligence; Adaptation mechanism; Bench-mark problems; Complexity; Differential Evolution; Numerical optimizations; Objective function values; Simplified algorithms; Structural bias; Optimization",2-s2.0-85032205209
"Wu Y., Yu K., Jiao J., Cao D., Chi W., Tang J.","Dynamic isotropy design and analysis of a six-DOF active micro-vibration isolation manipulator on satellites",2018,"Robotics and Computer-Integrated Manufacturing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028453295&doi=10.1016%2fj.rcim.2017.08.003&partnerID=40&md5=3caf052e5de32ccc9d9289fe0484fcdb","The payload and strut mass plays significant roles in the dynamic analysis of Stewart platforms. However, until now there is little literature considering these effects on optimization and vibration isolation. In this paper, a new decoupling condition of stiffness matrix is proposed base on elegant algebraic approach, with which the dynamic isotropy index can be expressed in terms of natural frequencies. When the height of the mass center of the payload is zero, dynamic decoupling as well as translational and combined dynamic isotropy can be satisfied at the same time. Since the dynamic mass matrix is coupled when the height is not zero, an objective function that concerns the dynamic isotropy index and strut masses is formulated. The effects of the strut masses and payload on the natural frequencies and dynamic isotropy index are discussed. The genetic algorithm and differential evolution algorithm are implemented to obtain the suitable parameters for optimization design and vibration isolation purpose. That the optimization results of the two algorithms are nearly the same indicates that the optimized configurations are convincible. On the basis of the optimization process, we take into account a real link and fabricate a real optimized configuration in our laboratory. The dynamic model is also verified by both horizontal and vertical experimental results. It can be concluded that after optimization, a combined dynamic isotropy configuration is achieved, and the frequency range of vibration isolation can be extended. © 2017 Elsevier Ltd","Decoupling configuration; Dynamic isotropy index; Payload; Stewart platform; Strut mass","Dynamic analysis; Evolutionary algorithms; Genetic algorithms; Matrix algebra; Natural frequencies; Optimization; Stiffness matrix; Struts; Algebraic approaches; Decoupling conditions; Decoupling configuration; Differential evolution algorithms; Optimized configuration; Payload; Stewart platforms; Vibration isolations; Vibration analysis",2-s2.0-85028453295
"Yang G., Zhou F., Ma Y., Yu Z., Zhang Y., He J.","Identifying Lightning Channel-Base Current Function Parameters by Powell Particle Swarm Optimization Method",2018,"IEEE Transactions on Electromagnetic Compatibility",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019928749&doi=10.1109%2fTEMC.2017.2705485&partnerID=40&md5=eb2f1b94494aff48c345458b1fcb93de","This paper proposes the Powell (PPSO) method. The particle swarm optimization (PSO) algorithm is combined with the Powell algorithm to identify the parameters of lightning channel-base current function. The method can overcome the problem of premature convergence for PSO algorithm, and improve the analysis accuracy. The Heidler function is used to represent the lightning channel-base current. We have compared the PPSO method and genetic algorithm (GA) on reaching the desired peak value of the current I-{m} and the maximum time rate of change of current (di/dt)max. The results show that the parameters of Heidler function evaluated by the PPSO method can achieve more accurate values of I-{m} and (di/dt )max than those evaluated by GA. Also, we have compared the PPSO method, the Nelder-Mead particle swarm optimization (NMPSO) method, and PSO method using the measured channel-base current. The results show that the PPSO method is better than the NMPSO and PSO method to determine the channel-base current function parameters. The PPSO method is an efficient method to identify the channel-base function parameters, which can improve the digitalization of lightning monitoring equipment. This approach is also useful in research related to lightning characteristics and lightning protection. © 1964-2012 IEEE.","Channel-base current; genetic algorithm (GA); heidler function; nelder-Mead particle swarm optimization (NMPSO) method; powell particle swarm optimization (PPSO) method","Genetic algorithms; Lightning; Lightning protection; Optimization; Channel base current; Lightning channel; Lightning characteristics; Monitoring equipment; Particle swarm optimization algorithm; Particle swarm optimization method; Powell algorithms; Pre-mature convergences; Particle swarm optimization (PSO)",2-s2.0-85019928749
"Dou P., Chen Y., Yue H.","Remote-sensing imagery classification using multiple classification algorithm-based AdaBoost",2018,"International Journal of Remote Sensing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032872235&doi=10.1080%2f01431161.2017.1390276&partnerID=40&md5=aa51eabc9f0d1f791d4c3787e3003662","AdaBoost demonstrates excellent performance in remote sensing (RS) image classification, but as it works on only one classification algorithm, the disadvantage of the classification algorithm itself is difficult to overcome, resulting in limitations in the improvement of classification accuracy. In this article, a modified AdaBoost, a multiple classification algorithm-based AdaBoost (MCA AdaBoost), is proposed to improve remote sensing image classification. The new method works on more than one classification algorithm and can make full use of the advantages of different learning algorithms. Based on a Landsat 8 Operational Land Imager (OLI) image whose spatial resolution was enhanced to 15 m with a panchromatic band, a C4.5 decision tree, Naïve Bayes, and artificial neural network were used as objects to verify and compare the performance of both AdaBoost and MCA AdaBoost. The experimental results show that MCA AdaBoost successfully inherits the benefits of the original AdaBoost, combines the advantages of different classification algorithms and lowers overfitting. By increasing diversity and complementarity among base classifiers, MCA AdaBoost outperforms AdaBoost in terms of RS classification accuracy improvement. © 2017 Informa UK Limited, trading as Taylor & Francis Group.",,"Adaptive boosting; Data mining; Decision trees; Image enhancement; Neural networks; Remote sensing; C4.5 decision trees; Classification accuracy; Classification algorithm; Multiple Classification; Operational land imager; Remote sensing image classification; Remote sensing imagery; Remote sensing images; Image classification; accuracy assessment; algorithm; artificial neural network; image classification; Landsat; panchromatic image; remote sensing",2-s2.0-85032872235
"Katzir Z., Elovici Y.","Quantifying the resilience of machine learning classifiers used for cyber security",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030724887&doi=10.1016%2fj.eswa.2017.09.053&partnerID=40&md5=34556dd676a2d62924a88f3f7035ebf3","The use of machine learning algorithms for cyber security purposes gives rise to questions of adversarial resilience, namely: Can we quantify the effort required of an adversary to manipulate a system that is based on machine learning techniques? Can the adversarial resilience of such systems be formally modeled and evaluated? Can we quantify this resilience such that different systems can be compared using empiric metrics? Past works have demonstrated how an adversary can manipulate a system based on machine learning techniques by changing some of its inputs. However, comparatively little work has emphasized the creation of a formal method for measuring and comparing the adversarial resilience of different machine learning models to these changes. In this work we study the adversarial resilience of detection systems based on supervised machine learning models. We provide a formal definition for adversarial resilience while focusing on multisensory fusion systems. We define the model robustness (MRB) score, a metric for evaluating the relative resilience of different models, and suggest two novel feature selection algorithms for constructing adversary aware classifiers. The first algorithm selects only features that cannot realistically be modified by the adversary, while the second algorithm allows control over the resilience versus accuracy tradeoff. Finally, we evaluate our approach with a real-life use case of dynamic malware classification using an extensive, up-to-date corpus of benign and malware executables. We demonstrate the potential of using adversary aware feature selection for building more resilient classifiers and provide empirical evidence supporting the inherent resilience of ensemble algorithms compared to single model algorithms. © 2017 Elsevier Ltd","Adversarial Learning; Classifier Resilience; Cyber Security","Artificial intelligence; Computer crime; Feature extraction; Formal methods; Learning systems; Malware; Supervised learning; Adversarial learning; Cyber security; Ensemble algorithms; Feature selection algorithm; Machine learning models; Malware classifications; Multi-sensory fusion; Supervised machine learning; Learning algorithms",2-s2.0-85030724887
"Xu Y., Sun H., Liu H., Fu Q.","Distributed solution to DC optimal power flow with congestion management",2018,"International Journal of Electrical Power and Energy Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027492307&doi=10.1016%2fj.ijepes.2017.08.009&partnerID=40&md5=fbffa2c9f4706796ada672cac6dd95c7","Distributed generations contribute to the supply diversity as well as competitiveness of the electric market. Electric power supplies and load users all seek to optimally allocate/utilize the energy to maximize their benefits. However, maximizing the social welfare should not be the sole objective since line congestion can lead to serious problems. This paper proposes a fully distributed solution to DC optimal power flow with congestion management. The objective is to maximize the social welfare, while maintaining the supply-demand balance and relieving transmission line congestion. The proposed algorithm only requires information exchange among neighboring participants which leads to simpler realization and less expenditure for communication network and powerful central controller comparing to traditional centralized algorithms. It is adaptive to topology changes and scalable to large systems. Simulation results of the 5-& IEEE 30-bus systems demonstrate the effectiveness of the proposed distributed algorithm and indicate its promising applications to the electric market. © 2017 Elsevier Ltd","Congestion management; DC optimal power flow; Distributed algorithm; Distributed generation; Social welfare","Acoustic generators; Commerce; Distributed power generation; Electric power systems; Electric power transmission; Parallel algorithms; Centralized algorithms; Congestion management; Dc optimal power flow; Distributed solutions; Electric power supply; Information exchanges; Social welfare; Supply-demand balances; Electric load flow",2-s2.0-85027492307
"Laruelle A., da Silva Rocha A.B., Escobedo R.","The Hawk–Dove game in phenotypically homogeneous and heterogeneous populations of finite dimension",2018,"Communications in Nonlinear Science and Numerical Simulation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021414436&doi=10.1016%2fj.cnsns.2017.06.028&partnerID=40&md5=143e93123735e95a295cab54fe45d966","The Hawk–Dove game played between individuals in populations of finite dimension is analyzed by means of a stochastic model. We take into account both cases when all individuals in the population are either phenotypically homogeneous or heterogeneous. A strategy in the model is a gene representing the probability of playing the Hawk strategy. Individual interactions at the microscopic level are described by a genetic algorithm where evolution results from the interplay among selection, mutation, drift and cross-over of genes. We show that the behavioral patterns observed at the macroscopic level can be reproduced as the emergent result of individual interactions governed by the rules of the Hawk–Dove game at the microscopic level. We study how the results of the genetic algorithm compare with those obtained in evolutionary game theory, finding that, although genes continuously change both their presence and frequency in the population over time, the population average behavior always achieves stationarity and, when this happens, the final average strategy played in the population oscillates around the evolutionarily stable strategy in the homogeneous population case or the neutrally stable set in the heterogeneous population case. © 2017 Elsevier B.V.","Evolutionary games; Genetic algorithm; Hawk–Dove game; Heterogeneous populations; Stability","Convergence of numerical methods; Evolutionary algorithms; Game theory; Genes; Genetic algorithms; Stochastic systems; Behavioral patterns; Evolutionarily stable strategy; Evolutionary game theory; Evolutionary games; Finite dimensions; Heterogeneous populations; Macroscopic levels; Microscopic levels; Stochastic models",2-s2.0-85021414436
"Karim M.A., Currie J., Lie T.-T.","A machine learning based optimized energy dispatching scheme for restoring a hybrid microgrid",2018,"Electric Power Systems Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032268622&doi=10.1016%2fj.epsr.2017.10.015&partnerID=40&md5=a86ce18e642cd2dadbb76fa6c91514bc","A microgrid operated in stand alone mode is highly vulnerable to instability when the integration of intermittent energy sources are considered. If a short circuit fault occurs in a microgrid while operating at its design limit, often cost effective system recovery becomes a challenging task. Under such contingencies predictive analysis can be used to strengthen the system restoration schemes. In this study, a system based on machine learning algorithm is implemented to forecast the security of a standalone microgrid and based on the forecasting, schedule multiple backup diesel generators under the contingency of loss of a major generating unit. The underlying objective is to maintain the voltage stability with an optimized economic dispatch scheme, right after clearing a critical three phase short circuit fault. Finally, a promising set of outcomes are observed and discussed. © 2017 Elsevier B.V.","Distributed generation; Genetic algorithm; Hybrid microgrid; Machine learning; Monte Carlo simulation","Artificial intelligence; Cost effectiveness; Distributed power generation; Electric fault currents; Electric load dispatching; Genetic algorithms; Intelligent systems; Learning systems; Monte Carlo methods; Scheduling; Cost effective systems; Diesel generators; Economic Dispatch; Intermittent energy source; Micro grid; Short-circuit fault; System restoration; Three-phase short circuit faults; Learning algorithms",2-s2.0-85032268622
"Ruiz L.G.B., Rueda R., Cuéllar M.P., Pegalajar M.C.","Energy consumption forecasting based on Elman neural networks with evolutive optimization",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030686265&doi=10.1016%2fj.eswa.2017.09.059&partnerID=40&md5=d8a60c2b9b1c3be284426a7fd4a2ba50","Buildings are an essential part of our social life. People spend a substantial fraction of their time and spend a high amount of energy in them. There is a grand variety of systems and services related to buildings, in order to better control and monitoring. The prompt taking of decisions may prevent costs and contamination. This paper proposes a method for energy consumption forecasting in public buildings, and thus, achieve energy savings, in order to improve the energy efficiency, without affecting the comfort and wellness. The prediction of the energy consumption is indispensable for the intelligent systems operations and planning. We propose an Elman neural network for forecasting such consumption and we use a genetic algorithm to optimize the weight of the models. This paper concludes that the proposed method optimizes the energy consumption forecasting and improves results attained in previous studies. © 2017 Elsevier Ltd","Energy efficiency; Evolutionary algorithm; Neural networks; Time series forecasting","Energy conservation; Energy utilization; Evolutionary algorithms; Forecasting; Genetic algorithms; Intelligent systems; Neural networks; Optimization; Control and monitoring; Elman neural network; Public buildings; Social life; Time series forecasting; Energy efficiency",2-s2.0-85030686265
"Dai D., Yuan F., Long R., Liu Z., Liu W.","Performance analysis and multi-objective optimization of a Stirling engine based on MOPSOCD",2018,"International Journal of Thermal Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032790859&doi=10.1016%2fj.ijthermalsci.2017.10.030&partnerID=40&md5=c65c14f9c5bf600ad7ec856e9d91c7df","A Stirling engine displays an aptitude for utilizing sustainable energy (such as solar energy) and exhibits the same theoretical efficiency as that of a Carnot cycle. However, the actual efficiency of a Stirling engine is far from the ideal Carnot efficiency due to irreversibilities. Models proposed in previous studies that focused on the imperfect regenerative process are crude and require improvements. In this study, finite time thermodynamics is employed to construct a refined model that considers the finite rate of heat transfer, conductive thermal bridging loss, and regenerative loss that is supplied by the heat source. Based on the model, three objective functions including power, efficiency, and ecological coefficient of performance (ECOP) of a Stirling engine are simultaneously optimized for maximization. A multi-objective optimization method based on a multi-objective particle swarm optimization algorithm using crowding distance (MOPSOCD) is employed to optimize the Stirling engine for the first time. Solutions obtained using the MOPSOCD comprise the Pareto set. The optimal solution is then selected using the technique for order of preference by similarity to ideal solution. The performance under the multi-objective optimization is compared with those of single-objective optimization methods in terms of power, efficiency, and ECOP. The results reveal that MOPSOCD exhibits good coordination in terms of the power, efficiency, and ECOP of the Stirling engine and may serve as a promising guide for operating and designing Stirling engines. © 2017 Elsevier Masson SAS","Finite time thermodynamics; Multi-objective optimization; Particle swarm optimization algorithm using crowding distance; Stirling engine","Engines; Evolutionary algorithms; Heat transfer; Optimization; Particle swarm optimization (PSO); Solar energy; Stirling engines; Thermodynamics; Crowding distance; Ecological coefficient of performance; Finite time thermodynamics; Multi-objective particle swarm optimization algorithms; Objective functions; Performance analysis; Regenerative process; Single objective optimization; Multiobjective optimization",2-s2.0-85032790859
"Choudhury A.R., Das S., Garg N., Kumar A.","Rejecting jobs to minimize load and maximum flow-time",2018,"Journal of Computer and System Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029223351&doi=10.1016%2fj.jcss.2017.07.006&partnerID=40&md5=23d1f85844c430397d2194e0b30e9d52","The notion of competitive ratio often turns out to be too pessimistic for the analysis of online algorithms. Although the approach of resource augmentation (introduced by Kalyanasundaram and Pruhs) has been very successful in dealing with a variety of objective functions, there are problems for which even a (arbitrary) constant speedup cannot lead to a constant competitive algorithm. Here we propose a rejection model which permits the online algorithm to not serve epsilon-fraction of requests. We present O(log2⁡1/ε) and O(1/ε4)-competitive algorithms for the problems of load balancing and minimizing maximum flow time in the restricted assignment setting. © 2017 Elsevier Inc.","Competitive ratio; Flow-time; Online job scheduling; Rejection model; Restricted assignment","Systems science; Competitive algorithms; Competitive ratio; Flow-time; Job scheduling; Objective functions; On-line algorithms; Resource augmentation; Restricted assignment; Computer networks",2-s2.0-85029223351
"Wei G., Ma H., Qian W., Han F., Jiang H., Qi S., Qiu M.","Lung nodule classification using local kernel regression models with out-of-sample extension",2018,"Biomedical Signal Processing and Control",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029362423&doi=10.1016%2fj.bspc.2017.08.026&partnerID=40&md5=c55775ba39c60d1c39ca3443594dcfbb","Computer-aided classification is a major research task for computer-aided diagnosis of pulmonary nodules. In radiology domain, labeled data can be expensive to generate. Therefore, in this study, a novel unsupervised spectral clustering algorithm was presented to distinguish benign and malignant nodules. In this algorithm, a new Laplacian matrix was constructed by using local kernel regression models (LKRM) and incorporating a regularization term, the regularization term can tackle the out-of-sample problem. To verify the feasibility of our algorithm, a ground truth dataset was assembled from the LIDC-IDRI database, including 371 benign and 375 malignant lung nodules. All nodules were represented by the texture features, which were computed from the regions of interest (ROIs). Extensive experiments on lung nodules showed that the proposed algorithm not only achieved a higher classification performance than existing popular unsupervised algorithms, but also had superiority comparing to some supervised algorithms (linear discriminant analysis and extreme learning machine). © 2017 Elsevier Ltd","Kernel trick; Linear regression; Lung nodules; Out-of-sample; Spectral clustering","Biological organs; Computer aided diagnosis; Discriminant analysis; Learning systems; Linear regression; Matrix algebra; Natural language processing systems; Regression analysis; Classification performance; Computer Aided Classification; Extreme learning machine; Kernel trick; Linear discriminant analysis; Lung nodule; Spectral clustering; Spectral clustering algorithms; Clustering algorithms; Article; cancer classification; cancer diagnosis; data base; discriminant analysis; human; image segmentation; kernel method; linear regression analysis; lung cancer; lung nodule; machine learning; priority journal; radiodiagnosis",2-s2.0-85029362423
"Singh V., Gupta I., Jana P.K.","A novel cost-efficient approach for deadline-constrained workflow scheduling by dynamic provisioning of resources",2018,"Future Generation Computer Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032290197&doi=10.1016%2fj.future.2017.09.054&partnerID=40&md5=4b9868389af6407664c806f8f62054c5","Workflow scheduling is a crucial aspect of cloud computing that should be performed in an efficient manner for optimal utilization of resources. The development of a cost-efficient algorithm has always been an important topic of research in this regard. In this paper, we propose a novel workflow scheduling algorithm, which is cost-efficient and deadline-constrained. The proposed algorithm is consolidated by dynamic provisioning of the resources, using k-means clustering technique and a variant of the Subset-Sum problem. In the algorithm, we consider level based scheduling using the concept of Bag of Tasks (bots) and develop a new technique for associating deadlines with each bot. Through extensive simulation runs, we show that the proposed algorithm outperforms the existing algorithms like Dynamic Provisioning Dynamic Scheduling (DPDS) and Infrastructure as a Service (IaaS) Cloud-Partial Critical Path (IC-PCP). The effectiveness of our algorithm over these two algorithms is also illustrated through the popular statistical test ANOVA and its subsequent post-hoc analysis. © 2017 Elsevier B.V.","Cost; Deadline; Dynamic provisioning; k-means clustering; Partition problem; Workflow scheduling","Costs; Infrastructure as a service (IaaS); Scheduling; Scheduling algorithms; Deadline; Dynamic provisioning; K-means clustering; Partition problem; Workflow scheduling; Clustering algorithms",2-s2.0-85032290197
"Chen P.-A.","Generalized mirror descents with non-convex potential functions in atomic congestion games: Continuous time and discrete time",2018,"Information Processing Letters",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032191351&doi=10.1016%2fj.ipl.2017.10.003&partnerID=40&md5=54f275b5ebea2322e1e08d0af52c94e6","When playing certain specific classes of no-regret algorithms such as multiplicative updates and replicator dynamics in atomic congestion games, some previous convergence analyses were done with the standard Rosenthal potential function in terms of mixed strategy profiles (i.e., probability distributions on atomic flows), which could be non-convex. In several other works, the convergence, when playing the mirror-descent algorithm (a more general family of no-regret algorithms including multiplicative updates, gradient descents, etc.), was guaranteed with a convex potential function in terms of nonatomic flows as an approximation of the Rosenthal one. The convexity of the potential function provides convenience for analysis. One may wonder if the convergence of mirror descents can still be guaranteed directly with the non-convex Rosenthal potential function. In this paper, we answer the question affirmatively for discrete-time generalized mirror descents with the smoothness property (similarly adopted in many previous works for congestion games and markets) and for continuous-time generalized mirror descents with the separability of regularization functions. © 2017 Elsevier B.V.","Analysis of algorithms; Congestion games; Convergence; Mirror descents; Non-convex","Approximation algorithms; Atoms; Continuous time systems; Probability distributions; Analysis of algorithms; Congestion Games; Convergence; Convergence analysis; Multiplicative updates; Non-convex; Regularization function; Replicator dynamics; Mirrors",2-s2.0-85032191351
"Umeo H., Hirota M., Nozaki Y., Imai K., Sogabe T.","A new reconstruction and the first implementation of Goto's FSSP algorithm",2018,"Applied Mathematics and Computation",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020043797&doi=10.1016%2fj.amc.2017.05.015&partnerID=40&md5=8e0bc93d99505de03a0b1536192ed413","The firing squad synchronization problem (FSSP) on cellular automata has been studied extensively for more than fifty years, and a rich variety of synchronization algorithms has been proposed. Goto's FSSP algorithm (Goto 1962) has been known as the first minimum-time FSSP algorithm, however the paper itself had been a completely unknown one in the research community of cellular automata for a long time due to its hard accessibility. In the present paper, we reconstruct the Goto's FSSP algorithm and present the first small-state implementation. The implementation is realized on a cellular automaton having 165-state and 4378 state-transition rules and the realization is far smaller than Goto (1962) imagined, where he thought that it would require many thousands of thousands states. It is shown that the reconstructed algorithm uses a quite different synchronization mechanism in comparison with the designs employed in Waksman (1966), Balzer (1967), Gerken (1987) and Mazoyer (1987). We show that the algorithm has Θ(nlog n) minimum-state-change complexity for synchronizing n cells. The algorithm is optimum not only in time but also in state-change complexities. We show that the reconstructed algorithm can be generalized as to the initial general's position and its implementation on a cellular automaton with 434 internal states and 13,328 state-transition rules is also given. The general purpose of this investigation is to achieve more insights into the structure of the classical minimum-time FSSP solutions and such insights would be helpful in the design of new FSSP algorithms. © 2017 Elsevier Inc.","Cellular automaton; Firing squad synchronization problem; FSSP","Cellular automata; Firing squad synchronization problems; FSSP; Internal state; Research communities; State transition rule; State-change complexity; Synchronization algorithm; Synchronization mechanisms; Synchronization",2-s2.0-85020043797
"Xie J., Indraswari K., Schwarzkopf L., Towsey M., Zhang J., Roe P.","Acoustic classification of frog within-species and species-specific calls",2018,"Applied Acoustics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032259785&doi=10.1016%2fj.apacoust.2017.10.024&partnerID=40&md5=91a78c27a41b2549f912af476b399329","There have been various studies using automated recognisers of acoustic features and machine learning algorithms to classify frog species within a chorusing community. Such studies rarely consider within-species call variation in the classification process. Individual frog species may make a range of different calls, with different purposes. Including modification of calls in automated recognition has the potential to not only increase the accuracy of classification of calls to species, but also to provide information on frog calling behaviour within species. Here we use acoustic feature extraction and machine learning algorithms (1) to investigate the acoustic feature importance of identifying species-specific calls; (2) to determine which acoustic features can be used to classify within-species calls. Our method was tested for its performance in recognising four frog species (Litoria bicolor, Litoria rothii, Litoria wotjulumensis, and Uperoleia inundata) and four call types of L.wotjulumensis (normal, click, response, and long trill). Mean classification accuracy was high, with 84.0% at the species level, and 83.7% at the call type level. The overall classification accuracy can be up to 93.0%, when considering four call types of L. wotjulumensis as individual classes and being combined with other three frog species. Two techniques, principal component analysis and Fisher discriminant ratio were used for dimension reduction and to select important features for discriminating among calls of different species, and call types within species. In conclusion, our proposed classification mechanism could effectively not only classify different frog species but also identify different call types within the same species. Moreover, we found that time-domain features were important for classification of within-species calls, whereas frequency-domain features were more useful for classification of species-specific calls. © 2017 Elsevier Ltd","Acoustic features; Frog community interactions; Machine learning algorithms; Soundscape ecology","Artificial intelligence; Feature extraction; Frequency domain analysis; Learning algorithms; Learning systems; Principal component analysis; Time domain analysis; Accuracy of classifications; Acoustic classification; Acoustic feature extraction; Acoustic features; Classification accuracy; Classification mechanism; Classification process; Soundscapes; Classification (of information)",2-s2.0-85032259785
"Bubba T.A., Porta F., Zanghirati G., Bonettini S.","A nonsmooth regularization approach based on shearlets for Poisson noise removal in ROI tomography",2018,"Applied Mathematics and Computation",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029514366&doi=10.1016%2fj.amc.2017.09.001&partnerID=40&md5=aabe1d55aa5325c168d18922ea7348e4","Due to its potential to lower exposure to X-ray radiation and reduce the scanning time, region-of-interest (ROI) computed tomography (CT) is particularly appealing for a wide range of biomedical applications. To overcome the severe ill-posedness caused by the truncation of projection measurements, ad hoc strategies are required, since traditional CT reconstruction algorithms result in instability to noise, and may give inaccurate results for small ROI. To handle this difficulty, we propose a nonsmooth convex optimization model based on ℓ1 shearlet regularization, whose solution is addressed by means of the variable metric inexact line search algorithm (VMILA), a proximal-gradient method that enables the inexact computation of the proximal point defining the descent direction. We compare the reconstruction performance of our strategy against a smooth total variation (sTV) approach, by using both Poisson noisy simulated data and real data from fan-beam CT geometry. The results show that, while for synthetic data both shearets and sTV perform well, for real data, the proposed nonsmooth shearlet-based approach outperforms sTV, since the localization and directional properties of shearlets allow to detect finer structures of a textured image. Finally, our approach appears to be insensitive to the ROI size and location. © 2017 Elsevier Inc.","Computed tomography; Forward-backward algorithms; Nonsmooth optimization; Region-of-interest tomography; Shearlets; Wavelets","Convex optimization; Gradient methods; Image segmentation; Medical applications; Optimization; Tomography; 42C40; 44A12; 65F22; 65K10; 92C55; Forward / backward algorithms; Nonsmooth optimization; Region of interest; Shearlets; Wavelets; Computerized tomography",2-s2.0-85029514366
"Zhang C., Zhu L., Xu C., Lu R.","PPDP: An efficient and privacy-preserving disease prediction scheme in cloud-based e-Healthcare system",2018,"Future Generation Computer Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029543737&doi=10.1016%2fj.future.2017.09.002&partnerID=40&md5=5ce951a391e8b7b0d96a45ffa60df7e2","Disease prediction systems have played an important role in people's life, since predicting the risk of diseases is essential for people to lead a healthy life. The recent proliferation of data mining techniques has given rise to disease prediction systems. Specifically, with the vast amount of medical data generated every day, Single-Layer Perceptron can be utilized to obtain valuable information to construct a disease prediction system. Although the disease prediction system is quite promising, many challenges may limit it in practical use, including information security and prediction efficiency. In this paper, we propose an efficient and privacy-preserving disease prediction system, called PPDP. In PPDP, patients’ historical medical data are encrypted and outsourced to the cloud server, which can be further utilized to train prediction models by using Single-Layer Perceptron learning algorithm in a privacy-preserving way. The risk of diseases for new coming medical data can be computed based on the prediction models. In particular, PPDP builds on new medical data encryption, disease learning and disease prediction algorithms that novelly utilize random matrices. Security analysis indicates that PPDP offers a required level of privacy protection. In addition, real experiments on different datasets show that computation costs of data encryption, disease learning and disease prediction are several magnitudes lower than existing disease prediction schemes. © 2017 Elsevier B.V.","Cloud computing; Disease prediction; Privacy-preserving; Single-Layer Perceptron","Cloud computing; Cryptography; Data mining; Data privacy; Forecasting; Learning algorithms; Security of data; Computation costs; Prediction algorithms; Prediction schemes; Prediction systems; Privacy preserving; Privacy protection; Security analysis; Single layer perceptron; Medical information systems",2-s2.0-85029543737
"Zhang F., Cen Y., Zhao R., Hu S., Mladenovic V.","Multi-separable dictionary learning",2018,"Signal Processing",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021197238&doi=10.1016%2fj.sigpro.2017.06.023&partnerID=40&md5=ff716edab2ebeaae71c1f7bd6fb164e5","As the extensive applications of sparse representation, the methods of dictionary learning have received widespread attentions. In this paper, we propose a multi-separable dictionary learning (MSeDiL) algorithm for sparse representation, which is based on the Lagrange Multiplier and the QR decomposition. Different with the traditional dictionary learning methods, the training samples are clustered firstly. Then the separable dictionaries for each cluster are optimized by the QR decomposition. The efficiency of the reconstruction process is improved in our algorithm because of the under-determinedness of the dictionaries for each cluster. Experimental results show that with the similar PSNR (Peak Signal to Noise Ratio) and SSIM (Structure Similarity Index), the reconstruction speed of our algorithm is much faster than other dictionary learning methods, especially when the size of samples is large. © 2017 Elsevier B.V.","Lagrange Multiplier; Multi-separable dictionary learning; Separable dictionary learning; Sparse representation","Clustering algorithms; Lagrange multipliers; Learning algorithms; Learning systems; Signal to noise ratio; Dictionary learning; PSNR (peak signal to noise ratio); Q R decomposition; Reconstruction process; Reconstruction speed; Sparse representation; Structure similarity; Training sample; Education",2-s2.0-85021197238
"Testa M., Magli E.","Compressive Bayesian K-SVD",2018,"Signal Processing: Image Communication",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029058384&doi=10.1016%2fj.image.2017.08.009&partnerID=40&md5=de44a1a04267f3648c242f75349c2090","Compressed Sensing (CS) is an established way to perform efficient dimensionality reduction during a signal's acquisition process. However, the common transform bases used in CS to represent a signal often lead to a compressible representation that is not optimal in terms of compactness. In this paper we present a novel dictionary learning algorithm designed to work with CS data. Following our approach, dictionaries learned directly from the signal's random projections are specifically suited to the signal class of interest, resulting in very sparse representations. Moreover, since the proposed method lays its foundation in a Bayesian dictionary learning algorithm, no prior information such as the signals’ sparsity is needed because it is inferred directly from the data. We show the superiority of our approach by comparing it with a state-of-the-art CS dictionary learning algorithm. © 2017 Elsevier B.V.","Bayesian inference; Classification; Compressed sensing; Dictionary learning; Sparse representation","Bayesian networks; Classification (of information); Compressed sensing; Inference engines; Signal processing; Signal reconstruction; Acquisition process; Bayesian inference; Compressive sensing; Dictionary learning; Dictionary learning algorithms; Dimensionality reduction; Random projections; Sparse representation; Learning algorithms",2-s2.0-85029058384
"Deeba F., Islam M., Bui F.M., Wahid K.A.","Performance assessment of a bleeding detection algorithm for endoscopic video based on classifier fusion method and exhaustive feature selection",2018,"Biomedical Signal Processing and Control",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032219760&doi=10.1016%2fj.bspc.2017.10.011&partnerID=40&md5=3b63d5b4581f714cbc49b95735571115","Capsule Endoscopy (CE) is a non-invasive clinical procedure that allows examination of the entire gastrointestinal tract including parts of small intestine beyond the scope of conventional endoscope. It requires computer-aided approach for the assessment of video frames to reduce diagnosis time. This paper presents a computer-assisted method based on a classifier fusion algorithm which combines two optimized Support Vector Machine (SVM) classifiers to automatically detect bleeding regions present in CE frames. The classifiers are based on RGB and HSV color spaces; the image regions are characterized on the basis of statistical features derived from the first-order histogram probability of respective color channels. A nested cross validation strategy has been adopted for the parameter tuning and feature selection to optimize the classifiers. The optimum feature sets for the best performance are evaluated after exhaustive analysis. The proposed fusion approach achieves an average accuracy of 95%, sensitivity of 94% and specificity of 95.3% for a dataset of 8872 CE frames, which is higher than that obtained from a single classifier. Comparison with the state-of-the-art algorithms exhibits that the proposed method yields superior performance for diverse dataset. © 2017 Elsevier Ltd","Automated bleeding detection; Capsule endoscopy; Classifier fusion; Color features; Nested cross validation; SVM score","Color; Computer aided diagnosis; Endoscopy; Feature extraction; Signal detection; Support vector machines; Bleeding detections; Capsule endoscopy; Classifier fusion; Color features; Nested cross validations; SVM score; Classification (of information); algorithm; Article; bleeding; capsule endoscopy; classifier; color; computer aided design; histogram; human; image analysis; measurement accuracy; priority journal; sensitivity and specificity; support vector machine",2-s2.0-85032219760
"Lin M.C., Mestre J., Vasiliev S.","Approximating weighted neighborhood independent sets",2018,"Information Processing Letters",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030465939&doi=10.1016%2fj.ipl.2017.09.014&partnerID=40&md5=b404b29a46bed8b560ca4e7ffe1a1067","A neighborhood independent set (NI-set) is a subset of edges in a graph such that the closed neighborhood of any vertex contains at most one edge of the subset. Finding a maximum cardinality NI-set is an NP-complete problem. We consider the weighted version of this problem. For general graphs we give an algorithm with approximation ratio Δ, and for diamond-free graphs we give a ratio Δ/2+1, where Δ is the maximum degree of the input graph. Furthermore, we show that the problem is polynomially solvable on cographs. Finally, we give a tight upper bound on the cardinality of a NI-set on regular graphs. © 2017","Approximation algorithms; Graph algorithms; Weighted neighborhood independent set","Approximation algorithms; Computational complexity; Problem solving; Approximation ratios; Diamond-free graphs; General graph; Graph algorithms; Independent set; Maximum degree; Polynomially solvable; Regular graphs; Graph theory",2-s2.0-85030465939
"Yu J., Huang D., Wei Z.","Unsupervised image segmentation via Stacked Denoising Auto-encoder and hierarchical patch indexing",2018,"Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024092380&doi=10.1016%2fj.sigpro.2017.07.009&partnerID=40&md5=dd6ea74f4708c5f33e0d304a06e18f93","For decades, image segmentation is a hot research direction in computer vision because of its extensive and practical applications. In this work, we propose a method of image segmentation based on auto-encoders and hierarchical clustering algorithm, aiming at dealing with the segmentation problem in an unsupervised way. More specifically, this proposed method consists of two stages: training and segmenting. In training stage, we divide sample images into non-overlapped patches and extract deep-level feature representations from the patches using Stacked Denoising Auto-encoder (SDA), then we perform unsupervised and hierarchical K-means clustering on these feature representations and build an indexing tree structure. In segmenting stage, we achieve segmentation of an arbitrary image based on the indexing tree structure. This unsupervised methodology is demonstrated to be an improvement over traditional unsupervised segmentation methods owing to the introduction of sample images. Experimental evaluations on several benchmark datasets indicate that our algorithm outperforms several other methods in both time efficiency and accuracy. © 2017","Auto-encoders; Hierarchical clustering; Image segmentation; Unsupervised learning","Clustering algorithms; Indexing (of information); Learning systems; Trees (mathematics); Unsupervised learning; Auto encoders; Experimental evaluation; Feature representation; Hier-archical clustering; Hierarchical clustering algorithms; Hierarchical K-means clustering; Unsupervised image segmentation; Unsupervised segmentation method; Image segmentation",2-s2.0-85024092380
"Chen Y., Liu Z.-Q., Liu H.-L.","Parameters identification for crack in elastic structures based on fiber Bragg grating",2018,"Optik",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032218315&doi=10.1016%2fj.ijleo.2017.10.126&partnerID=40&md5=a06452b6747b886f955a343bc59abfae","A novel parameters identification method is proposed in this paper, which adopts the rectangular strain rosette structure with three FBGs, BFM (Body Force Method, BFM) theory and improved PSO (Particle Swarm Optimization, PSO) algorithm to identify the parameters for crack. To detect the strains, a rectangular strain rosette structure with three FBGs is adopted, and the transverse effect correction factor is established to improve the accuracy. The position of crack can be determined by improved PSO algorithm. By utilizing the principal strain direction angle to coarsely get the center coordinates of the crack which can initialize the particle, the local optimum problem of PSO can be solved. To improve the performance of PSO, the weight and termination condition are modified, and the selection of learning factors is discussed. To test performance of improved PSO algorithm, a well-known benchmark problem of the mathematical test function is first solved, and the numerical experiments have shown that the proposed PSO obtains better results among the compared algorithms. © 2017","Body force method; Fiber Bragg grating (FBG); Modified dynamic particle swarm optimization algorithm; Parameters identification; Rectangular strain rosette","Benchmarking; Bragg gratings; Cracks; Fiber Bragg gratings; Functions; Optimization; Parameter estimation; Strain; Stress intensity factors; Body force method; Improved pso algorithms; Numerical experiments; Parameters identification; Particle swarm optimization algorithm; Principal strain direction; Rectangular strain rosette; Termination condition; Particle swarm optimization (PSO)",2-s2.0-85032218315
"Massawe B.H.J., Subburayalu S.K., Kaaya A.K., Winowiecki L., Slater B.K.","Mapping numerically classified soil taxa in Kilombero Valley, Tanzania using machine learning",2018,"Geoderma",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007173765&doi=10.1016%2fj.geoderma.2016.11.020&partnerID=40&md5=d91cb82e890b8cc632052a5c831f4077","Inadequacy of spatial soil information is one of the limiting factors to making evidence-based decisions to improve food security and land management in the developing countries. Various digital soil mapping (DSM) techniques have been applied in many parts of the world to improve availability and usability of soil data, but less has been done in Africa, particularly in Tanzania and at the scale necessary to make farm management decisions. The Kilombero Valley has been identified for intensified rice production. However the valley lacks detailed and up-to-date soil information for decision-making. The overall objective of this study was to develop a predictive soil map of a portion of Kilombero Valley using DSM techniques. Two widely used decision tree algorithms and three sources of Digital Elevation Models (DEMs) were evaluated for their predictive ability. Firstly, a numerical classification was performed on the collected soil profile data to arrive at soil taxa. Secondly, the derived taxa were spatially predicted and mapped following SCORPAN framework using Random Forest (RF) and J48 machine learning algorithms. Datasets to train the model were derived from legacy soil map, RapidEye satellite image and three DEMs: 1 arc SRTM, 30 m ASTER, and 12 m WorldDEM. Separate predictive models were built using each DEM source. Mapping showed that RF was less sensitive to the training set sampling intensity. Results also showed that predictions of soil taxa using 1 arc SRTM and 12 m WordDEM were identical. We suggest the use of RF algorithm and the freely available SRTM DEM combination for mapping the soils for the whole Kilombero Valley. This combination can be tested and applied in other areas which have relatively flat terrain like the Kilombero Valley. © 2016 Elsevier B.V.","Decision tree analysis; DEM; Kilombero Valley; Machine learning; Numerical classification; Soil mapping","Artificial intelligence; Data mining; Decision making; Decision trees; Developing countries; Food supply; Forestry; Landforms; Learning algorithms; Learning systems; Mapping; Soil surveys; Surveying; Tracking radar; Decision tree analysis; Decision-tree algorithm; Digital elevation model; Digital soil mappings; Evidence- based decisions; Kilombero Valley; Numerical classification; Soil mapping; Soils; algorithm; crop production; decision support system; developing world; digital elevation model; land management; machine learning; mapping; numerical method; RapidEye; rice; satellite imagery; Shuttle Radar Topography Mission; soil analysis; soil biota; soil classification; soil profile; terrain; Kilombero Valley; Morogoro [Tanzania]; Tanzania",2-s2.0-85007173765
"Wu H., Prasad S.","Semi-supervised dimensionality reduction of hyperspectral imagery using pseudo-labels",2018,"Pattern Recognition",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032285895&doi=10.1016%2fj.patcog.2017.09.003&partnerID=40&md5=c6444db6bb6cc716d4dbbb16a7068756","Dimensionality reduction has been proven to be efficient in preparing high dimensional data for various tasks in machine learning. As supervised dimensionality reduction methods such as Fisher discriminant analysis (FDA) and local Fisher discriminant analysis (LFDA) tend to suffer from overfitting when only a small number of labeled samples are available, the abundant unlabeled samples could be helpful in finding a better embedding space. However, applying discriminant analysis on unlabeled data is challenging since we do not have labels for unlabeled data. In this paper, we propose a semi-supervised Semi-Supervised Local Fisher Discriminant Analysis (SSLFDA) using pseudo labels, aiming to perform discriminant analysis on both labeled and unlabeled samples. SSLFDA makes use of pseudo labels, learned from the Dirichlet process mixture model (DPMM) based clustering algorithm, to enable local Fisher discriminant analysis on unlabeled data. In addition, a kernel extension of SSLFDA is derived for non-linear dimensionality reduction. We present experimental results with real hyperspectral data to show that our method provides better classification performance compared to other existing dimensionality reduction methods. © 2017 Elsevier Ltd","Dimensionality reduction; Dirichlet process mixture model; Hyperspectral data classification; Semi-supervised learning","Clustering algorithms; Data reduction; Discriminant analysis; Fisher information matrix; Learning algorithms; Learning systems; Mixtures; Spectroscopy; Supervised learning; Dimensionality reduction; Dimensionality reduction method; Dirichlet process mixture model; Fisher discriminant analysis; Hyperspectral data classification; Local Fisher Discriminant Analysis; Nonlinear dimensionality reduction; Semi- supervised learning; Classification (of information)",2-s2.0-85032285895
"Zhang H., Tang L., Fang Z., Xiang C., Li C.","Nonconvex and nonsmooth total generalized variation model for image restoration",2018,"Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028560671&doi=10.1016%2fj.sigpro.2017.08.021&partnerID=40&md5=915da368492455d2d17895d13259c290","In this paper, we propose a nonconvex and nonsmooth total generalized variation (TGV) model for image restoration, which can provide an even sparser representation of the variation of the image function than the traditional TGV model that uses convex l1 norm to measure the variation. New model combines the advantages of nonconvex regularization and TGV regularization, and can preserve image edges well and simultaneously alleviate the staircase effects often arising in the total variation based models. Two different iteratively reweighed algorithms are introduced to numerically solve the proposed nonconvex and nonsmooth TGV model. Numerical results show that the proposed model is effective in edge-preserving and staircase-reduction in image restoration. In addition, compared with several state-of-the-art variational models, the proposed model has the best performance in terms of PSNR and MSSIM values. © 2017 Elsevier B.V.","Image restoration; Iteratively reweighed algorithm; Nonconvex; Primal-dual algorithm; Total generalized variation (TGV)","Image reconstruction; Restoration; Stairs; Edge preserving; Generalized variation; Nonconvex; Numerical results; Primal dual algorithms; Staircase effect; State of the art; Variational models; Iterative methods",2-s2.0-85028560671
"Cao C., Sun K., Liu W.","A novel bit-level image encryption algorithm based on 2D-LICM hyperchaotic map",2018,"Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028715223&doi=10.1016%2fj.sigpro.2017.08.020&partnerID=40&md5=c5473c0444038dfe994bb538bb0c7b3d","In this paper, a new two-dimensional Logistic ICMIC cascade map (2D-LICM) is proposed based on cascade modulation couple (CMC) model. Performance evaluations show that it has hyperchaotic behavior, wide chaotic range and large complexity. Based on this map, a novel image encryption algorithm is designed by employing bit-level permutation and diffusion simultaneously. The bit-level permutation is performed by circular shifting, and the bit-level diffusion is carried out by exclusive or (xor) and reverse operations. In addition, the initial values of chaotic system are updated in real time according to the obtained ciphertext and it greatly improves the ability of resisting known plaintext attack and chosen plaintext attack. Simulation results and performance analysis show that this algorithm has good encryption effect and high efficiency. It can resist typical attacks including statistical, brute-force, differential attacks and so forth. © 2017 Elsevier B.V.","2D-LICM hyperchaotic map; Bit-level encryption; Chaos; Image encryption","Chaos theory; Chaotic systems; Image processing; Bit level; Chosen-plaintext attack; Differential attacks; Hyperchaotic maps; Image encryption algorithm; Image encryptions; Known-plaintext attacks; Performance analysis; Cryptography",2-s2.0-85028715223
"Wu J., Guo Z., Luo C.","Development of a parallel adaptive multigrid algorithm for solving the multi-scale thermal-solute 3D phase-field problems",2018,"Computational Materials Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031501578&doi=10.1016%2fj.commatsci.2017.09.045&partnerID=40&md5=351c86dc9a216a7bd6694bec81516ed5","A parallel adaptive multigrid algorithm was developed to solve the coupled thermal-solute phase field equations so that the multi-scale difficulty of the problem when both thermal and solute fields were presented could be resolved. Comparing with the explicit method, it was showed that the proposed algorithm even converged when the time step was enlarged to be 4 orders of magnitude larger, and combined with Para-AMR algorithm [1] the computation efficiency could be improved by about 4–5 orders of magnitude with little accuracy compromised, when a much higher and realistic Lewis number was used, e.g. Le = 10,000. With this numerical capability, 3D phase field simulations on dendrite growth in a much larger scale, in particular under multi-scale thermal-solute conditions, could be performed in a much more sensible manner with moderate amount of computing resources. Dendrite growth simulations with Le varying from 1 to 10,000 in 3D were carried out for the first time, and the result showed that variation of Le led to a great difference of both tip velocity and tip radius, which was similar to the 2D case reported by [2]. © 2017 Elsevier B.V.","Adaptive mesh refinement; Implicit multigrid method; Parallel computing; Phase-field model","Parallel processing systems; Phase interfaces; Adaptive mesh refinement; Computation efficiency; Implicit multigrid methods; Orders of magnitude; Parallel adaptive multigrid algorithm; Phase field equation; Phase field models; Phase-field simulation; Computational efficiency",2-s2.0-85031501578
"Liu B., Xin X., Zhang L., Wang F., Zhang Q.","A digital clock recovery algorithm based on chromatic dispersion and polarization mode dispersion feedback dual phase detection for coherent optical transmission systems",2018,"Optics Communications",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027518244&doi=10.1016%2fj.optcom.2017.07.092&partnerID=40&md5=75df8dedf63c5e1eb5e9867f1f19a3da","A new feedback symbol timing recovery technique using timing estimation joint equalization is proposed for digital receivers with two samples/symbol or higher sampling rate. Different from traditional methods, the clock recovery algorithm in this paper adopts another algorithm distinguishing the phases of adjacent symbols, so as to accurately estimate the timing offset based on the adjacent signals with the same phase. The addition of the module for eliminating phase modulation interference before timing estimation further reduce the variance, thus resulting in a smoothed timing estimate. The Mean Square Error (MSE) and Bit Error Rate (BER) of the resulting timing estimate are simulated to allow a satisfactory estimation performance. The obtained clock tone performance is satisfactory for MQAM modulation formats and the Roll-off Factor (ROF) close to 0. In the back-to-back system, when ROF=0, the maximum of MSE obtained with the proposed approach reaches 0.0125. After 100-km fiber transmission, BER decreases to 10−3 with ROF=0 and OSNR =11 dB. With the increase in ROF, the performances of MSE and BER become better. © 2017 The Authors","Coherent optical transmission; Digital clock recovery algorithm; Dispersion feedback; Optical fiber communication; Phase modulation noise","Bit error rate; Chromatic dispersion; Clocks; Electric clocks; Mean square error; Modulation; Optical communication; Optical fiber communication; Optical fibers; Phase modulation; Polarization mode dispersion; Recovery; Signal detection; Back-to-back system; Coherent optical transmissions; Digital clocks; Fiber transmissions; Modulation formats; Phase modulation noise; Satisfactory estimation; Symbol timing recovery; Light transmission",2-s2.0-85027518244
"Mehdi J.K., Nejat A., Panahi M.S.","Heat transfer improvement in automotive brake disks via shape optimization of cooling vanes using improved TPSO algorithm coupled with artificial neural network",2018,"Journal of Thermal Science and Engineering Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028544507&doi=10.1115%2f1.4036966&partnerID=40&md5=53150bc77df06d6b4e2647891ec4c5d6","One important safety issue in automotive industry is the efficient cooling of brake system. This research work aims to introduce an optimized cooling vane geometry to enhance heat removal performance of ventilated brake disks. The novel idea of using airfoil vanes is followed as the basis of this investigation (Nejat et al., 2011, ""Heat Transfer Enhancement in Ventilated Brake Disk Using Double Airfoil Vanes,"" ASME J. Therm. Sci. Eng. Appl., 3(4), p. 045001). In order to perform the optimization technique efficiently, an integrated shape optimization process is designed. According to the aerodynamic and heat transfer considerations, first an appropriate airfoil is selected as the base profile to be optimized. For the shape modification purpose, a curve parameterization method named class shape transformation (CST) is utilized. The control parameters defined in CST method are then established as the geometrical design variables of an improved territorial particle swarm optimization (TPSO) algorithm. In order to overcome the potential bottleneck of high computational cost associated with the required computational fluid dynamics (CFD)-based function evaluations, TPSO algorithm is coupled with a predictive artificial neural networks (ANN), well trained with an input dataset designed based on the Taguchi method. The obtained profile shows an evident convective heat dissipation improvement accomplished mainly via airflow acceleration over the vanes, avoiding early flow detachment and adjusting the flow separation region at the rear part of the suction sides. The results also reveal the approaches by which such a superior performance is achieved by means of the modified surface curvatures. © 2018 by ASME.","Artificial neural network; CFD; Class shape transformation; Integrated shape optimization; TPSO algorithm; Ventilated brake disks","Accident prevention; Airfoils; Automobile parts and equipment; Automotive industry; Brakes; Computational fluid dynamics; Cooling; Flow separation; Heat transfer; Neural networks; Optimization; Particle swarm optimization (PSO); Taguchi methods; Ventilation; Aerodynamic and heat transfers; Brake disks; Computational costs; Convective heat dissipation; Heat Transfer enhancement; Optimization techniques; Parameterization method; Shape transformation; Shape optimization",2-s2.0-85028544507
"Deng S.-W., Han J.-Q.","Adaptive overlapping-group sparse denoising for heart sound signals",2018,"Biomedical Signal Processing and Control",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029354342&doi=10.1016%2fj.bspc.2017.08.027&partnerID=40&md5=23bd94273bf9b151816791b6a5be17d9","The heart sound (HS) is an important physiological signal of the human body and can provide valuable diagnostic information in the clinical auscultation. The HS signal, however, is often contaminated by noise and the noisy HS signal will cause adverse influence of making the diagnosis. In this paper, we proposed an adaptive denoising algorithm, named adaOGS denoising, based on the overlapping-group sparsity (OGS) of the first-order difference of the HS signal. Under the Bayesian framework, the adaOGS algorithm is derived and solved as an optimization problem with OGS regularization based on the majorization–minimization (MM) algorithm. Compared with the conventional wavelet method, the proposed algorithm has the advantage that it does not need the predefined base functions and can also be performed in an adaptive way according to the noise level. Moreover, the experimental results show that the proposed algorithm outperforms the conventional wavelet methods such as ‘db10’, ‘db5’, and ‘bior5.5’, for denoising the noisy HS signals in lower noise level. © 2017 Elsevier Ltd","Adaptive denoising; Heart sound signal denoising; Majorization–minimization (MM) algorithm; Overlapping-group sparsity; Regularization optimization","Acoustic noise; Cardiology; Optimization; Signal denoising; Adaptive de-noising algorithms; Adaptive denoising; Bayesian frameworks; De-noising; First order differences; Optimization problems; Overlapping groups; Physiological signals; Biomedical signal processing; algorithm; Article; Bayesian learning; comparative study; controlled study; density; heart sound; normal distribution; overlapping group sparsity; priority journal; signal noise ratio",2-s2.0-85029354342
"Ak R., Li Y.-F., Vitelli V., Zio E.","Adequacy assessment of a wind-integrated system using neural network-based interval predictions of wind power generation and load",2018,"International Journal of Electrical Power and Energy Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028621360&doi=10.1016%2fj.ijepes.2017.08.012&partnerID=40&md5=1ccb27cec5fa1b11ef54d657378c2d3d","In this paper, a modeling and simulation framework is presented for conducting the adequacy assessment of a wind-integrated power system accounting for the associated uncertainties. A multi-layer perceptron artificial neural network (MLP NN) is trained by the non-dominated sorting genetic algorithm-II (NSGA-II) to forecast prediction intervals (PIs) of the wind power and load. The output of the adequacy assessment is given in terms of point-valued and interval-valued Expected Energy Not Supplied (EENS). Different scenarios of wind power and load levels are considered to explore the influence of uncertainty in wind and load predictions on the estimation of system adequacy. © 2017 Elsevier Ltd","Adequacy assessment; Multi-objective genetic algorithm; Neural networks; Prediction intervals; Wind energy","Electric power generation; Genetic algorithms; Neural networks; Uncertainty analysis; Wind power; Adequacy assessment; Expected energy not supplied; Integrated Power Systems; Model and simulation; Multi layer perceptron; Multi-objective genetic algorithm; Non dominated sorting genetic algorithm ii (NSGA II); Prediction interval; Forecasting",2-s2.0-85028621360
"Bei Z., Yu Z., Luo N., Jiang C., Xu C., Feng S.","Configuring in-memory cluster computing using random forest",2018,"Future Generation Computer Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029354873&doi=10.1016%2fj.future.2017.08.011&partnerID=40&md5=ae9d88cdf73e3e5494d648c0a3878131","Recently, in-memory cluster computing (IMC) gains momentum because it accelerates traditional on-disk cluster computing (ODC) up to several tens of times for iterative and interaction applications. The most popular IMC framework is Spark and it has more than 100 configuration parameters. However, it is unclear how significantly these parameters affect the system performance because IMC is a quite new computing paradigm. Consequently, there is yet no study addressing how to optimally configure IMC frameworks. In this paper, we first investigate how significantly the configuration parameters affect the performance of Spark workloads. We find that the configuration caused performance variation can be as large as 20.7, indicating configuring Spark workloads is extremely important to their performance. However, manually configuring Spark workloads is notoriously difficult because there are so many configuration parameters which might interfere with each other in a complex way. To address this issue, we propose an approach to Automatically Configure Spark workloads, named ACS. It firstly constructs performance models as functions of Spark configuration parameters by using random forest which is an ensemble learning algorithm. Subsequently, ACS leverages genetic algorithm to search the optimum configuration by taking configurations and the corresponding performance predicted by the performance models as inputs. We employ six Spark programs, each with five input data sets to evaluate the performance improvements. The results show that ACS speeds up the 30 program-input pairs by a factor of 2.2× on average and up to 8.2×. In addition, the performance improvements obtained by ACS increase along with the increments of the input data set sizes of Spark workloads, which is a nice property for big data analytics. © 2017 Elsevier B.V.","Automatically configuration; Genetic algorithm; Random forest; Spark","Big data; Cluster computing; Computer architecture; Decision trees; Electric sparks; Genetic algorithms; Input output programs; Iterative methods; Automatically configuration; Computing paradigm; Configuration parameters; Ensemble learning algorithm; Optimum configurations; Performance Model; Performance variations; Random forests; Parameter estimation",2-s2.0-85029354873
"Claeys T., Vanoost D., Peuteman J., Vandenbosch G.A.E., Pissoort D.","An iterative interpolated DFT to remove spectral leakage in time-domain near-field scanning",2018,"IEEE Transactions on Electromagnetic Compatibility",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019913789&doi=10.1109%2fTEMC.2017.2699738&partnerID=40&md5=67dd1d218b4fc36efe5f0d9bea7ab192","Time-domain near-field scanning is gaining more and more interest within EMC engineering to analyze electromagnetic near-fields of, e.g., quasi-stationar devices. When using a digital oscilloscope to scan the near-fields of an electronic device, the oscilloscope measures time-domain signals that comprise in most cases a large number of frequency components. For many of these components, noncoherent sampling occurs, resulting in spectral leakage when calculating the frequency spectrum of the time-domain signals with the discrete Fourier transform. This paper proposes an improved method to detect the presence of such noncoherently sampled signals as well as an iterative algorithm to obtain accurate approximations of all the frequency components with their accompanying amplitudes and phase angles. The algorithm excels over existing algorithms in obtaining these values especially in situations where several sinusoidal components are close to each other in the spectrum. This is achieved, thanks to an iterative process of removing the influence of the multiple sinusoidal components on each other. This paper contains the mathematical description of the algorithm and a numerical example evaluating the accuracy of the algorithm. The algorithm has a higher accuracy than the existing approaches, e.g., multipoint Interpolated Discrete Fourier Transform (IpDFTs), with only a slight increase of the computational cost. © 1964-2012 IEEE.","Amplitude estimation; discrete Fourier transform (DFT); frequency estimation; near-field scanning; phase estimation; spectral leakage","Approximation algorithms; Cathode ray oscilloscopes; Discrete Fourier transforms; Electromagnetic compatibility; Digital oscilloscope; Electromagnetic near fields; Frequency components; Iterative algorithm; Mathematical descriptions; Near-field scanning; Noncoherent sampling; Sinusoidal components; Iterative methods",2-s2.0-85019913789
"Sun S., Wang S., Wang Y., Lim T.C., Yang Y.","Prediction and optimization of hobbing gear geometric deviations",2018,"Mechanism and Machine Theory",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031495742&doi=10.1016%2fj.mechmachtheory.2017.09.002&partnerID=40&md5=c2846055c56665708b83ee6296476415","Hobbing is a precision gear manufacturing process with high efficiency and low cost. High precision gears are essential components for high-end equipment to meet the requirement of extreme operation conditions. In order to further improve the precision of gear hobbing process as well as lower the gear manufacturing cost, this paper proposes a model for predicting the hobbing gear geometric deviations and optimizing the hobbing processing technique. The relationship between gear hobbing processing technique and gear geometric deviation is modeled applying the improved Particle Swarm Optimization and Back Propagation algorithm. The performance of the proposed method is compared with the existing optimization and back propagation method and validated by experiments. The accuracy of both algorithms is evaluated by the Root Mean Square Error between the predicted and experimental values. The result shows that the gear geometric deviations predicted by the proposed algorithm yields better performance and are in reasonably good agreement with experimental data. Employing the proposed model, the gear hobbing process parameters can be optimized to minimize gear geometric errors, and thus improve the gear manufacturing precision. © 2017","Gear geometric deviation; Gear hobbing process; IPSO-BP neural network algorithm; Parameters optimization; Precision prediction","Backpropagation; Backpropagation algorithms; Forecasting; Gears; Geometry; Machining; Manufacture; Mean square error; Neural networks; Optimization; Particle swarm optimization (PSO); BP neural networks; Gear hobbing; Geometric deviations; Parameters optimization; Precision prediction; Gear manufacture",2-s2.0-85031495742
"Qian J., Wang F., Zhu C.","Scattered data interpolation based upon bivariate recursive polynomials",2018,"Journal of Computational and Applied Mathematics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021704835&doi=10.1016%2fj.cam.2017.05.033&partnerID=40&md5=c62da9c040d8b6e6e6892b2871ecd1d9","In this paper, firstly, based on new recursive algorithms of non-tensor-product-typed bivariate divided differences, scattered data interpolation schemes are constructed in the cases of odd and even interpolating nodes, respectively. Moreover, the corresponding error estimation is worked out, and equivalent formulae are obtained between bivariate high-order non-tensor-product-typed divided differences and high-order partial derivatives. Furthermore, the operation count for the addition/subtractions, multiplication, and divisions approximates O(n2) in the computation of the interpolating polynomials presented, while the operation count approximates O(n3) in the case of radial basis functions for sufficiently large n. Finally, several numerical examples show that it is valid for the recursive interpolating polynomial schemes, and these interpolating polynomials change as the order of the interpolating nodes, although the node collection is the same. © 2017 Elsevier B.V.","Bivariate divided difference; Non tensor product type; Radial basis function; Recursive algorithm; Scattered data interpolation","Functions; Image segmentation; Polynomials; Radial basis function networks; Tensors; Divided difference; Non tensors; Radial basis functions; Recursive algorithms; Scattered data interpolation; Interpolation",2-s2.0-85021704835
"Benedetto F., Giunta G., Vandendorpe L.","A theoretical note on the generalized ML optimality of constant modulus equalizers",2018,"Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029786882&doi=10.1016%2fj.sigpro.2017.09.018&partnerID=40&md5=88d60747f289b6a4ecc0535921f0d061","In this work, we derive the optimum equalizer according to the General Maximum Likelihood (GML) principle and show the optimality of the constant-modulus algorithm (CMA) according to the GML principle. This reported discussion illustrates why CMA works well and hence is so popular. Moreover, we show that the minimization of normalized variance algorithm (MNVA) previously introduced by the authors, as much as the asymptotically equivalent Kurtosis maximization algorithm and “Rayleigh-ness” test criteria, are asymptotically optimum according to the GML criterion. © 2017 Elsevier B.V.","Blind equalization; Constant-modulus algorithm; Maximum likelihood principle; Optimality; Wireless communications","Equalizers; Maximum likelihood; Wireless telecommunication systems; Constant moduli; Constant modulus algorithms; Kurtosis maximization; Maximum likelihood Principle; Optimality; Rayleigh; Test criteria; Wireless communications; Blind equalization",2-s2.0-85029786882
"Wu X., Grassi F., Manfredi P., Vande Ginste D.","Perturbative Analysis of Differential-to-Common Mode Conversion in Asymmetric Nonuniform Interconnects",2018,"IEEE Transactions on Electromagnetic Compatibility",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028915370&doi=10.1109%2fTEMC.2017.2727339&partnerID=40&md5=56c684539f751637dc641cd3aecf18b2","In this paper, a perturbative technique and the related computational algorithms are presented for the prediction of differential mode (DM) to common mode (CM) conversion arising from asymmetry and nonuniformity in differential interconnects. It is shown that discontinuities evolving from nonuniformities and geometrical imbalance along the (usually desired uniform) lines give rise to equivalent distributed sources that couple the (ideally decoupled) DM and CM circuits. The prediction of modal quantities is then achieved numerically, as an iterative perturbative refinement of the frequency response of an ideal differential line. Different levels of approximation are introduced and discussed. Specifically, the assumption of weak imbalance allows analyzing the propagation of the two modes separately. Moreover, the assumption of weak nonuniformity allows avoiding CM refinements. The proposed technique applies to both ideally uniform and inherently nonuniform interconnects, and leads to a significant simulation speed-up compared to traditional approaches that analyze nonuniform lines by their subdivision into uniform sections. The methodology is illustrated based on two differential microstrip lines, one tapered and one with sinusoidally varying trace edges. Validation against full-wave simulations and measurements is provided. © 1964-2012 IEEE.","Common mode (CM); differential interconnects; mixed-mode S-parameters; mode conversion; nonuniform transmission lines (TLs); perturbation approach","Approximation algorithms; Electric lines; Frequency response; Iterative methods; Scattering parameters; Algorithm design and analysis; Commonmode; Differential interconnects; Electromagnetics; Integrated circuit interconnections; Microstripes; Mixed-mode S-parameters; Mode conversions; Non uniform transmission lines; Perturbation approach; Transmission-line measurements; Integrated circuit interconnects",2-s2.0-85028915370
"De Marsico M., Nappi M., Narducci F., Proença H.","Insights into the results of MICHE I - Mobile Iris CHallenge Evaluation",2018,"Pattern Recognition",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032256511&doi=10.1016%2fj.patcog.2017.08.028&partnerID=40&md5=54e394cbe05b5edf52c573e56dc75524","Mobile biometrics technologies are nowadays the new frontier for secure use of data and services, and are considered particularly important due to the massive use of handheld devices in the entire world. Among the biometric traits with potential to be used in mobile settings, the iris/ocular region is a natural candidate, even considering that further advances in the technology are required to meet the operational requirements of such ambitious environments. Aiming at promoting these advances, we organized the Mobile Iris Challenge Evaluation (MICHE)-I contest. This paper presents a comparison of the performance of the participant methods by various Figures of Merit (FoMs). A particular attention is devoted to the identification of the image covariates that are likely to cause a decrease in the performance levels of the compared algorithms. Among these factors, interoperability among different devices plays an important role. The methods (or parts of them) implemented by the analyzed approaches are classified into segmentation (S), which was the main target of MICHE-I, and recognition (R). The paper reports both the results observed for either S or R, and also for different recombinations (S+R) of such methods. Last but not least, we also present the results obtained by multi-classifier strategies. © 2017 Elsevier Ltd","Biometric algorithm fusion; Evaluation; Mobile Iris Recognition","Pattern recognition; Software engineering; Biometric algorithms; Evaluation; Figures of merits; Iris recognition; Mobile biometrics; Multi-classifier; Operational requirements; Performance level; Biometrics",2-s2.0-85032256511
"Liu Z.-G., Ji X.-H., Liu Y.-X.","Hybrid non-parametric particle swarm optimization and its stability analysis",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030183434&doi=10.1016%2fj.eswa.2017.09.012&partnerID=40&md5=13800f77df4faddf9b983085e91137f8","As a population-based random search optimization technique, particle swarm optimization (PSO) has become an important branch of swarm intelligence (SI). The tuning of parameters in PSO has attracted the attention of many researchers. This study proposes an alternative technology called hybrid non-parametric PSO (HNPPSO) algorithm. Other SI operations, including a multi-crossover operation, a vertical crossover, and an exemplar-based learning strategy, are combined with the proposed algorithm to balance the global and local search capabilities. The first- and second-order stability analyses conducted for the present study showed that the particle positions are expected to converge at a fixed point in the search space and that the variance of the particle positions converges to zero. In the experiments, the proposed algorithm was compared with 10 other advanced PSO techniques using 40 widely used benchmark functions. The experimental results indicated that the proposed algorithm yields better solution accuracy and convergence speed than the other PSO techniques. The proposed algorithm significantly outperformed the other PSO approaches in terms of convergence speed. © 2017 Elsevier Ltd","Hybrid algorithm; Parameter selection; Particle swarm optimization; Stability analysis","Optimization; Parameter estimation; Alternative technologies; Benchmark functions; Crossover operations; Exemplar based learning; Hybrid algorithms; Parameter selection; Stability analysis; Tuning of parameters; Particle swarm optimization (PSO)",2-s2.0-85030183434
"Zhan Q., Ren Q., Zhuang M., Sun Q., Liu Q.H.","An exact Riemann solver for wave propagation in arbitrary anisotropic elastic media with fluid coupling",2018,"Computer Methods in Applied Mechanics and Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032004348&doi=10.1016%2fj.cma.2017.09.007&partnerID=40&md5=1d77670867613981d065b32108b9cb9a","We present a nonconformal mesh discontinuous Galerkin pseudospectral time domain algorithm for arbitrary anisotropic elastic/acoustic wave propagation problems. An exact Riemann solver is compactly derived to resolve the accurate coupling of multiple domains in the discontinuous Galerkin framework, including heterogeneous anisotropic solid–solid, acoustic–acoustic, and anisotropic solid–fluid interactions. We simplify the eigenvalue problem in the Riemann solution from the rank of 9 to 3, and introduce the generalized wave impedance with more physical insight. Validations and verifications with independent codes and analytical solutions illustrate the accuracy, flexibility, and stability of our algorithm. © 2017 Elsevier B.V.","Discontinuous Galerkin; Generalized wave impedance; Nonconformal meshes; Pseudospectral time domain algorithm; Riemann solver; Solid–fluid coupling","Acoustic impedance; Acoustics; Anisotropic media; Anisotropy; Eigenvalues and eigenfunctions; Galerkin methods; Time domain analysis; Wave propagation; Discontinuous galerkin; Fluid couplings; Non-conformal meshes; Pseudospectral time domain algorithms; Riemann solver; Wave impedances; Anisotropic fluids",2-s2.0-85032004348
"Mazurek P., Wagner J., Morawski R.Z.","Use of kinematic and mel-cepstrum-related features for fall detection based on data from infrared depth sensors",2018,"Biomedical Signal Processing and Control",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029698638&doi=10.1016%2fj.bspc.2017.09.006&partnerID=40&md5=f2a78c3a275b24bcc3e9fc8dac4c743b","A methodology for acquisition and preprocessing of measurement data from infrared depth sensors, when applied for fall detection, combined with several approaches to the classification of those data, is proposed. Data processing is initiated with extraction of the silhouette from the depth image and estimation of the coordinates of the center of that silhouette. Next, two groups of features to be applied for a fall/non-fall classification are extracted: kinematic features (various statistics defined on the position, velocity and acceleration trajectories of the monitored person) and mel-cepstrum-related features (components of the mel-cepstrum obtained by means of an unconventional set of mel-filters). Finally, the utility of these features in fall detection is assessed using three classification algorithms − viz. support vector machine, artificial neural network, and naïve Bayes classifier − trained and tested on two datasets consisting of, respectively, 160 data sequences (representative of 80 falls and 80 other human behaviours) and 264 data sequences (representative of 132 falls and 132 other human behaviours). The application of the combination of the kinematic and mel-cepstrum-related features yields highly accurate classification results − all classifiers achieved, depending on the dataset, 98.6–100% and 93.9–97.7% sensitivity. Thus, infrared depth sensors can be promising tools for unobtrusive fall detection. They provide data which can be in various ways preprocessed to form a basis for reliable fall detection. Appropriate selection of the feature sets directly affects the reliability of unobtrusive monitoring systems, and − indirectly − the quality of life of the monitored persons. © 2017","Classification algorithms; Data acquisition; Data processing; Event detection; Infrared image sensors; Public healthcare; Sensor systems and applications","Behavioral research; Data acquisition; Data handling; Data mining; Data processing; Feature extraction; Image processing; Image retrieval; Infrared imaging; Kinematics; Neural networks; Social sciences; Bayes Classifier; Classification algorithm; Classification results; Event detection; Measurement data; Public healthcares; Sensor systems and applications; Unobtrusive monitoring; Classification (of information); acceleration; Article; artificial neural network; classification; classification algorithm; controlled study; data analysis; kinematics; near infrared imaging system; priority journal; sensitivity analysis; sensor; signal detection; support vector machine",2-s2.0-85029698638
"Garikayi T., Van den Heever D., Matope S.","Analysis of surface electromyography signal features on osteomyoplastic transtibial amputees for pattern recognition control architectures",2018,"Biomedical Signal Processing and Control",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029351108&doi=10.1016%2fj.bspc.2017.09.007&partnerID=40&md5=05b96a8be4e52a32ec0aa4684a179796","This paper presents the characterisation of electromyography signals for the purpose of controlling a powered prosthetic ankle using pattern recognition algorithms. The goal is to identify the specific muscles that can be used to guarantee optimal control of a multichannel powered prosthetic ankle. SENIAM and ISEK protocols were used for signal acquisition, processing and reporting. A set of paired surface electrodes were placed above selected muscles on the residual limb. Participants were instructed to perform normal gait. The signals were recorded, labelled and analysed using the Vicon Nexus Motion Capturing System and Noraxon Myomotion System. Signal processing was performed using MR3 Software and further post processing was performed using Matlab. Time and frequency domain features were analysed. The protocol revealed that the tibialis anterior, medial and lateral gastrocnemius muscles actively generate myoelectric signals on the residual limb. A total of 12 time domain and 4 frequency domain features were successfully extracted and used in the analysis. The tibialis anterior muscle was identified as a candidate for classifying dorsiflexion with a mean amplitude of 35.08 μV. The soleus muscle was inaccessible on the amputated leg and as a result only the medial and lateralis gastrocnemius muscles, with 17.40% signal power and 43.73% mean amplitude as compared to the soleus, were available for plantarflexion. There was significant difference (p < 0.05) between features from the amputated residual limb and those from the intact normal leg. However, there was no significant difference (p > 0.05) between signal features from two different participants. Sagittal plane movements were linearly discriminated with 100% accuracy for tibialis anterior and medial gastrocnemius. However, lateralis gastrocnemius exhibited a 0.0769% classification error as a result of the amputation technique. © 2017 Elsevier Ltd","Amputee; Electromyography; Myoelectric control; Pattern recognition; Prosthetic; SENIAM","Artificial limbs; Electromyography; Frequency domain analysis; MATLAB; Muscle; Pattern recognition; Prosthetics; Signal processing; Time domain analysis; Amputee; Classification errors; Electromyography signals; Myoelectric control; Pattern recognition algorithms; SENIAM; Surface electromyography signals; Time and frequency domains; Biomedical signal processing; amputee; ankle; ankle prosthesis; Article; controlled study; data analysis software; electromyography; gait; gastrocnemius muscle; human; human experiment; learning algorithm; leg amputation; leg movement; leg muscle; limb; male; myoelectric control; priority journal; signal processing; soleus muscle; tibialis anterior muscle",2-s2.0-85029351108
"Márquez-Nolasco A., Conde-Gutiérrez R.A., Hernández J.A., Huicochea A., Siqueiros J., Pérez O.R.","Optimization and Estimation of the Thermal Energy of an Absorber With Graphite Disks by Using Direct and Inverse Neural Network",2018,"Journal of Energy Resources Technology, Transactions of the ASME",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030531725&doi=10.1115%2f1.4036544&partnerID=40&md5=92996114e6835043a962c729683dc4f6","The most critical component of an absorption heat transformer (AHT) is the absorber, by which the exothermic reaction is carried out, resulting in a useful thermal energy. This article proposed a model based on improving the performance of energy for an absorber with disks of graphite during the exothermic reaction, through an optimal strategy. Two models of artificial neural networks (ANN) were developed to predict the thermal energy, through two important factors: internal heat in the absorber (QAB) and the temperature of the working solution of the absorber outlet (TAB). Confronting the simulated and real data, a satisfactory agreement was appreciated, obtaining a mean absolute percentage error (MAPE) value of 0.24% to calculate QAB and of 0.17% to calculate TAB. Furthermore, from these ANN models, the inverse neural network (ANNi) allowed improves the thermal efficiency of the absorber (QAB and TAB). To find the optimal values, it was necessary to propose an objective function, where the genetic algorithms (GAs) were indicated. Finally, by applying the ANNi-GAs model, the optimized network configuration was to find an optimal value of concentrated solution of LiBr-H2O and the vapor inlet temperature to the absorber. The results obtained from the optimization allowed to reach a value of QAB from 1.77 kW to 2.44 kW, when a concentrated solution of LiBr-H2O at 59% was used and increased the value of TAB from 104.66 °C to 109.2 °C when a vapor inlet temperature of 73 °C was used. Copyright © 2018 by ASME.","exothermic reaction; genetic algorithms; heat transformer by absorption; inverse artificial neural network; useful thermal energy","Exothermic reactions; Genetic algorithms; Graphite; Heat exchangers; Lithium compounds; Neural networks; Optimal systems; Optimization; Absorption heat transformer; Concentrated solution; Genetic algorithm (GAs); Heat transformer; Inverse neural network; Mean absolute percentage error; Network configuration; Objective functions; Thermal energy",2-s2.0-85030531725
"Martín-Sotoca J.J., Saa-Requejo A., Grau J.B., Tarquis A.M.","Local 3D segmentation of soil pore space based on fractal properties using singularity maps",2018,"Geoderma",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007486199&doi=10.1016%2fj.geoderma.2016.11.029&partnerID=40&md5=129c9d0b70bf685c64bbe5983f64cc28","Over the last decade, major technological advances in X-ray computed tomography (CT) have allowed for the investigation and reconstruction of three-dimensional (3D) natural porous media architectures at very fine scales. Soil scientists can use the internal structure information to develop predictive models for a range of physical, chemical and biological processes in soil. Image segmentation and thresholding are crucial steps when applying these methods to extract complex pore space geometry information from images. Traditional thresholding algorithms face challenges related to the heterogeneity of soil samples, noise and artefacts introduced during the image acquisition process. This study proposes a new segmentation method using local greyscale value (GV) concentration variabilities based on fractal concepts. Singularity maps were created to measure the GV concentration at each point. The C-V method was combined with the singularity map approach (Singularity-CV method) to define thresholds that can be applied to binarize CT images. This study also introduces a new method for creating 3D synthetic soil images based on truncated multifractals that simulate low-contrast and non-bimodal GV histograms. A synthetic soil image was created with the objective to compare traditional segmentation methods (Otsu and maximum entropy) with the Singularity-CV method. We obtained better results in porosity and more amount of pores at all scales than traditional methods, although some small pores were incorrectly identified due to the ability to amplify every anomalous GVs. Misclassification error (ME) was low and similar to Otsu. Two different 3D CT soil images were also used in this analysis, corresponding to samples of the same soil with 1.2 and 1.6 g cm− 3 bulk densities. After applying the Singularity-CV method to the GV images, the results were compared with the aforementioned traditional segmentation methods. The image comparison was based on the porosity, pore size distribution (PSD) and cumulative pore size distribution (CPSD). The Otsu method achieves a higher porosity than the Singularity-CV method because it defines the largest pores. However, the Singularity-CV method detected more pores at all sizes. The maximum entropy method always yielded the lowest porosity. © 2016 Elsevier B.V.","3D image segmentation; Fractals; Singularity maps; Soil structure; Synthetic soil image","Computerized tomography; Fractals; Image acquisition; Image processing; Maximum entropy methods; Pore size; Porosity; Porous materials; Size distribution; Soils; 3D image segmentation; Chemical and biologicals; Misclassification error; Soil structure; Synthetic soil images; Threedimensional (3-d); Thresholding algorithms; X-ray computed tomography; Image segmentation; algorithm; geometry; heterogeneity; image analysis; map; maximum entropy analysis; pore space; porous medium; soil structure; three-dimensional modeling",2-s2.0-85007486199
"Sun P., Veelenturf L.P., Dabia S., Van Woensel T.","The time-dependent capacitated profitable tour problem with time windows and precedence constraints",2018,"European Journal of Operational Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025106601&doi=10.1016%2fj.ejor.2017.07.004&partnerID=40&md5=4d5fb260a1497416c1d1fb9979e8acbc","We introduce the time-dependent capacitated profitable tour problem with time windows and precedence constraints. This problem concerns determining a tour and its departure time at the depot that maximizes the collected profit minus the total travel cost (measured by total travel time). To deal with road congestion, travel times are considered to be time-dependent. We develop a tailored labeling algorithm to find the optimal tour. Furthermore, we introduce dominance criteria to discard unpromising labels. Our computational results demonstrate that the algorithm is capable of solving instances with up to 150 locations (75 pickup and delivery requests) to optimality. Additionally, we present a restricted dynamic programing heuristic to improve the computation time. This heuristic does not guarantee optimality, but is able to find the optimal solution for 32 instances out of the 34 instances. © 2017 Elsevier B.V.","Pickup and delivery problem; Profitable tour problem; Tailored labeling algorithm; Time-dependent travel times; Transportation","Motor transportation; Pickups; Profitability; Traffic congestion; Transportation; Travel time; Computational results; Dynamic programing; Labeling algorithms; Pickup and delivery; Pickup and delivery problems; Precedence constraints; Profitable tour problem; Time dependent; Optimization",2-s2.0-85025106601
"Li C.-Y., Zhu C.-G.","G1 continuity of four pieces of developable surfaces with Bézier boundaries",2018,"Journal of Computational and Applied Mathematics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015785013&doi=10.1016%2fj.cam.2017.02.044&partnerID=40&md5=cb8a56565bf320f6f49112d0736008bc","For potential applications in geometric design and manufacturing of material, the G1 connection of many pieces of developable surfaces is an important issue. In this paper, by using de Casteljau algorithm we study the G1 connection of four pieces of developable surfaces with Bézier boundary curves. We convert these surfaces to tensor form firstly, then characterize the constrains of the control points of the surfaces need to satisfy when G1 connecting them. This method can also be extended to the case when the developable surfaces possess Bézier boundary curves with different degrees. © 2017 Elsevier B.V.","de Casteljau algorithm; Developable surface; G1 connection","Computational methods; Mathematical techniques; Boundary curves; Control point; De Casteljau algorithms; Developable surfaces; G1 connection; G1 continuity; Geometric design; Tensor forms; Curve fitting",2-s2.0-85015785013
"Tan W., Sun L., Yang F., Che W., Ye D., Zhang D., Zou B.","Study on bruising degree classification of apples using hyperspectral imaging and GS-SVM",2018,"Optik",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032231199&doi=10.1016%2fj.ijleo.2017.10.090&partnerID=40&md5=218a93f661f1e9d96d9354a688dd355c","Bruising degree can affect the end use and sales price of apples directly. In order to identify the bruising degrees of apples quickly and accurately, using hyperspectral imaging technology, this study proposed a method combining successive projections algorithm (SPA) with support vector machine based on grid search parameter optimization (GS-SVM) to classify and identify apple samples with different degrees of bruising. In the process of research, firstly, random forest method was used to extract spectral data of bruised areas of apples with a high accuracy, then Kennard-Stone algorithm was performed to partition sample set reasonably to improve performance of the model. After comparing different pretreatment methods, standard normal variate (SNV) transformation method with the best performance was selected to process the spectral data. Finally, in order to reduce the time required to build the model, the GS-SVM models were set up based on the characteristic variables selected by SPA and competitive adaptive reweighted sampling (CARS), and the classification results were compared with the results of the model constructed with the full spectra. The experimental results showed that the SNV-SPA-GS-SVM model had the best prediction effect, and the prediction accuracy of apples with four kinds of bruising degrees was 95%. © 2017 Elsevier GmbH","Apple; Bruising degree classification; GS-SVM; Hyperspectral imaging","Decision trees; Fruits; Imaging techniques; Metadata; Optimization; Spectroscopy; Support vector machines; Apple; Classification results; GS-SVM; Hyperspectral imaging technologies; Kennard-Stone algorithm; Random forest methods; Standard normal variate transformations; Successive projections algorithms (SPA); Hyperspectral imaging",2-s2.0-85032231199
"Gruzdeva T.V., Strekalovsky A.S.","On solving the sum-of-ratios problem",2018,"Applied Mathematics and Computation",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027987396&doi=10.1016%2fj.amc.2017.07.074&partnerID=40&md5=8f8b36ce0d8aaeb5009eb6ab4afab480","This paper addresses the development of efficient global search methods for fractional programming problems. Such problems are, in general, nonconvex (with numerous local extremums) and belong to a class of global optimization problems. First, we reduce a rather general fractional programming problem with d.c. functions to solving an equation with a vector parameter that satisfies some nonnegativity assumption. This theorem allows the justified use of the generalized Dinkelbach's approach for solving fractional programming problems with a d.c. goal function. Based on solving of some d.c. minimization problem, we developed a global search algorithm for fractional programming problems, which was tested on a set of low-dimensional test problems taken from the literature as well as on randomly generated problems with up to 200 variables or 200 terms in the sum. © 2017 Elsevier Inc.","Difference of convex functions; Equation with vector parameter; Fractional optimization; Global search algorithm; Nonconvex optimization","Functions; Global optimization; Learning algorithms; Mathematical programming; Optimization; 90C26; 90C30; Difference of convex functions; Global search algorithm; Nonconvex optimization; Vector parameter; Problem solving",2-s2.0-85027987396
"Yang Y., Cao L., Zhou Q., Wang C., Wu Q., Jiang P.","Multi-objective process parameters optimization of Laser-magnetic hybrid welding combining Kriging and NSGA-II",2018,"Robotics and Computer-Integrated Manufacturing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024869638&doi=10.1016%2fj.rcim.2017.07.003&partnerID=40&md5=71753317c7d4f08f1e194425a5d75bf2","Laser-magnetic hybrid welding (LMW), which utilizes the stirring effect of magnetic field on molten pool to restrain the welding defect and increasing welding penetration, provides a promising way to improve the quality of welding joint. The process parameters of LMW have crucial effects on the welding seam profile which related to the quality of welding joint. This paper presents an integrated methodology by combining Kriging metamodel and Non-dominated sorting genetic algorithm-II (NSGA-II) for process parameters optimization of LMW. Firstly, a three-factor, five-level experiment using Taguchi L25 orthogonal array is conducted considering magnetic flux density (MF), laser power (LP) and welding speed (WS). Secondly, Kriging metamodel is introduced to establish the relationships between LMW process parameters and welding seam profile. A set of actual tests was carried out to verify the prediction accuracy of the constructed Kriging metamodels. Thirdly, NSGA-II is employed to finish multi-objective process parameters optimization and Pareto optimal solutions searching. Finally, the obtained optimal process parameters are validated by macro-weld profile, microstructure and micro-hardness in the confirmation tests. Results illustrate that the proposed integrated methodology is helpful for reducing welding defects and obtaining high-quality joints for LMW in practical production. © 2017 Elsevier Ltd","Kriging metamodel; Laser-magnetic hybrid welding; Multi-objective optimization","Defects; Genetic algorithms; Interpolation; Laser beam welding; Magnetism; Multiobjective optimization; Pareto principle; Seam welding; Hybrid welding; Integrated methodology; Kriging meta models; Non dominated sorting genetic algorithm ii (NSGA II); Pareto optimal solutions; Practical production; Process parameters optimizations; Welding penetration; Welding",2-s2.0-85024869638
"Ragalo A., Pillay N.","An investigation of dynamic fitness measures for genetic programming",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029801750&doi=10.1016%2fj.eswa.2017.08.022&partnerID=40&md5=37f4d5c06e9a2586f2b705c702138196","This research investigates the hypothesis that the use of different fitness measures at the different generations of genetic programming (GP) is more effective than the convention of applying the same fitness measure individually throughout GP. A genetic algorithm (GA) is used to induce the sequence in which fitness measures should be applied over the GP generations. Subsequently, the performance of a GP system applying the evolved fitness measure sequence is compared with the conventional GP approach. The former approach is shown to significantly outperform standard GP on varied benchmark problems. Furthermore, the evolved fitness measure sequences are shown to generalize within a problem class: therefore, the sequences can be evolved off-line for different problem classes. Critically, sequences trained on the problem classes are also shown to generalize to complex, real-world problems. Overall, the findings of the study are in favor of the hypothesis. This study has revealed the effectiveness of dynamic fitness measures when applied to benchmark and real-world problems. © 2017 Elsevier Ltd","Fitness; Genetic algorithm; Genetic programming","Genetic algorithms; Genetic programming; Bench-mark problems; Fitness; Fitness measures; Real-world problem; Health",2-s2.0-85029801750
"Elhoseny M., Tharwat A., Yuan X., Hassanien A.E.","Optimizing K-coverage of mobile WSNs",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029783514&doi=10.1016%2fj.eswa.2017.09.008&partnerID=40&md5=541f4d97db65c95bd12e09a803a5730a","Recently, Wireless Sensor Networks (WSNs) are widely used for monitoring and tracking applications. Sensor mobility adds extra flexibility and greatly expands the application space. Due to the limited energy and battery lifetime for each sensor, it can remain active only for a limited amount of time. To avoid the drawbacks of the classical coverage model, especially if a sensor died, K-coverage model requires at least k sensor nodes monitor any target to consider it covered. This paper proposed a new model that uses the Genetic Algorithm (GA) to optimize the coverage requirements in WSNs to provide continuous monitoring of specified targets for longest possible time with limited energy resources. Moreover, we allow sensor nodes to move to appropriate positions to collect environmental information. Our model is based on the continuous and variable speed movement of mobile sensors to keep all targets under their cover all times. To further prove that our proposed model is better than other related work, a set of experiments in different working environments and a comparison with the most related work are conducted. The improvement that our proposed method achieved regarding the network lifetime was in a range of 26%–41.3% using stationary nodes while it was in a range of 29.3%–45.7% using mobile nodes. In addition, the network throughput is improved in a range of 13%–17.6%. Moreover, the running time to form the network structure and switch between nodes’ modes is reduced by 12%. © 2017 Elsevier Ltd","Genetic Algorithm (GA); K-coverage problem; Mobility sensor networks; Wireless Sensor Networks (WSN)","Energy resources; Genetic algorithms; Sensor nodes; Continuous monitoring; Environmental information; K-coverage; Limited energy resource; Mobility sensors; Monitoring and tracking; Wireless sensor network (WSNs); Working environment; Wireless sensor networks",2-s2.0-85029783514
"Al-Shemarry M.S., Li Y., Abdulla S.","Ensemble of adaboost cascades of 3L-LBPs classifiers for license plates detection with low quality images",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030122214&doi=10.1016%2fj.eswa.2017.09.036&partnerID=40&md5=5d7cae2338af2e1721ffcd4ca56219ce","Due to the plate formats and multiform outdoor illumination conditions during the image acquisition phase, it is challenging to find effective license plate detection (LPD) method. This paper aims to develop a new detection method for identifying vehicle license plates under low quality images using image processing techniques. In this research, a robust method using a large number of AdaBoost cascades with three levels pre-processing local binary patterns classifiers (3L-LBPs) are used to detect license plates (LPs) regions. The method achieves a very high accuracy for detecting LP number from one vehicle image. The proposed method was tested and trained with the images from 630 and 400 vehicles, respectively. The images involve many difficult conditions, such as low/high contrast, dusk, dirt, fogy, and distortion problems. The experimental results demonstrate very satisfactory performance for LP detection in term of speed and accuracy, and were better than the most of the existing methods. The processing time for the whole testing LPD system was about 1.63 seconds to 2 seconds. The overall probability detection, precision, and f-measurement are 98.56%, 95.9% and 97.19%, respectively; with false positive rate 5.6%. © 2017 Elsevier Ltd","Adaboost Learning algorithm; Cascade classifier; License plate detection (LPD); Local binary pattern classifiers (LBP); Region of interest (ROI)","Adaptive boosting; Bins; Classification (of information); Content based retrieval; Image classification; Image processing; Image segmentation; Vehicles; Adaboost learning algorithms; Cascade classifiers; License plate detection; Local binary patterns; Region of interest; License plates (automobile)",2-s2.0-85030122214
"Galvis A.F., Rodríguez R.Q., Sollero P.","Analysis of three-dimensional hexagonal and cubic polycrystals using the boundary element method",2018,"Mechanics of Materials",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032179945&doi=10.1016%2fj.mechmat.2017.10.009&partnerID=40&md5=32e1590c90b12b9cb2b113689759b761","This work presents the analysis of three-dimensional polycrystals in the microscale with different lattice structures, hexagonal closed package (HCP) and face centered cubic (FCC). In these materials, the grained medium is considered as a continuum elastic body. An artificial polycrystalline structure is modeled using the Voronoi tessellation to generate random morphological microstructures. To reproduce the stochastic effects, arbitrary crystalline orientations are distributed over the structure. The boundary element method (BEM) is used to obtain the static displacement and traction fields, with a fundamental solution for 3D general anisotropic materials based on double Fourier's series. The macroscopic effective elastic properties are evaluated using the average homogenization technique and compared to the reference values through convergence statistical analysis. Explicit schemes are presented in order to improve the computational load and decrease the time required by the main BEM application implemented on distributed memory architectures. Numeral examples are presented showing the convergence of the results and comparisons of anisotropy level between these FCC and HCP materials using a recently proposed anisotropy factor. © 2017","Anisotropy; Boundary elements; Homogenization; Parallelized algorithms; Polycrystals","Anisotropy; Elasticity; Fourier series; Homogenization method; Memory architecture; Polycrystals; Sailing vessels; Stochastic systems; Boundary elements; Crystalline orientations; Distributed memory architecture; Effective elastic property; Homogenization techniques; Parallelized algorithm; Polycrystalline structure; Voronoi tessellations; Boundary element method",2-s2.0-85032179945
"Wang W., Zhao H., Chen B.","Bias compensated zero attracting normalized least mean square adaptive filter and its performance analysis",2018,"Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028597004&doi=10.1016%2fj.sigpro.2017.08.017&partnerID=40&md5=7ba86675f24e690d6640c1d6efdcbcf1","This paper presents a new normalized least mean square (NLMS) algorithm for sparse system identification where the input signal is corrupted by white measurement noise. The proposed algorithm, which is called bias-compensated zero attracting NLMS (BC-ZA-NLMS) algorithm, introduces the bias-compensation vector to get rid of the bias resulting from noisy input and introduces an l1-norm penalty in the cost function of the NLMS algorithm to make full use of the special property of the sparse system. In addition, to address the time variant sparsity, the bias-compensated reweight ZA-NLMS (BC-RZA-NLMS)) algorithm is also proposed, where the l1-norm penalty in the cost function of BC-ZA-NLMS algorithm is replaced by a log-sum function. Owing to the zero attractors in update equation, the proposed algorithms are superior to the conventional NLMS and bias-compensated NLMS (BC-NLMS) algorithms in the application of identifying the sparse system. A transient analysis of the proposed algorithms is also derived, which is able to accurately predict the behaviors of proposed algorithms. In addition, a stability analysis is introduced. Monte Carlo (MC) simulations are conducted to demonstrate the advantage of the proposed algorithms and to validate the theoretical results. © 2017 Elsevier B.V.","Bias compensated; Noisy input; Normalized least mean square; Zero attractor","Adaptive filters; Bandpass filters; Cost functions; Monte Carlo methods; Transient analysis; Bias compensated; Noisy input; Normalized least mean square; Normalized least mean square algorithms; Performance analysis; Sparse system identification; Special properties; Zero attractor; Adaptive filtering",2-s2.0-85028597004
"Schultz D., Jain B.","Nonsmooth analysis and subgradient methods for averaging in dynamic time warping spaces",2018,"Pattern Recognition",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032307803&doi=10.1016%2fj.patcog.2017.08.012&partnerID=40&md5=3ae8256b06f856419e4768467cce6c99","Time series averaging in dynamic time warping (DTW) spaces has been successfully applied to improve pattern recognition systems. This article proposes and analyzes subgradient methods for the problem of finding a sample mean in DTW spaces. The class of subgradient methods generalizes existing sample mean algorithms such as DTW Barycenter Averaging (DBA). We show that DBA is a majorize-minimize algorithm that converges to necessary conditions of optimality after finitely many iterations. Empirical results show that for increasing sample sizes the proposed stochastic subgradient (SSG) algorithm is more stable and finds better solutions in shorter time than the DBA algorithm on average. Therefore, SSG is useful in online settings and for non-small sample sizes. The theoretical and empirical results open new paths for devising sample mean algorithms: nonsmooth optimization methods and modified variants of pairwise averaging methods. © 2017 Elsevier Ltd","Dynamic time warping; Fréchet function; Sample mean; Subgradient methods; Time series averaging","Pattern recognition; Pattern recognition systems; Stochastic systems; Time series; Dynamic time warping; Majorize-minimize algorithms; Necessary conditions of optimality; Non-smooth analysis; Nonsmooth optimization; Pairwise averaging; Sample means; Sub-gradient methods; Optimization",2-s2.0-85032307803
"Cantó-Navarro E., López-García M., Ramos-Lara R.","Floating-point accelerator for biometric recognition on FPGA embedded systems",2018,"Journal of Parallel and Distributed Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031996404&doi=10.1016%2fj.jpdc.2017.09.010&partnerID=40&md5=a652affc1827cbc36c60385942bf38fa","This paper aims at presenting a Floating-Point Biometric Accelerator (FPBA) specially designed to speed-up processing kernels used in biometric algorithms. The FPBA was developed in order to facilitate its inclusion as part of an embedded system that was implemented on a low-cost FPGA family from Xilinx. The advantage of this approach is that such algorithms can be programmed on the same hardware architecture following a software design flow. The internal design includes several blocks that compute basic operations and transcendental functions useful in biometrics. For comparison purposes, the execution time of four typical biometric kernels resolved by the FPBA were compared against the floating-point unit (FPU) provided by Xilinx. In all cases, the experimental results show that the FPBA reduces the execution time by a factor ranging from x7 to x22. The results also show the execution of two biometric recognition algorithms that are accelerated by x7 and x16. © 2017 Elsevier Inc.","Accelerator; Biometrics; DTW; Embedded system; FFT; Floating-point; FPGA; GMM; SVM","Biometrics; Digital arithmetic; Fast Fourier transforms; Field programmable gate arrays (FPGA); Integrated circuit design; Particle accelerators; Software design; Basic operation; Biometric algorithms; Biometric recognition; Floating point units; Floating points; Hardware architecture; Internal design; Transcendental functions; Embedded systems",2-s2.0-85031996404
"Furini F., Monaci M., Traversi E.","Exact approaches for the knapsack problem with setups",2018,"Computers and Operations Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030164757&doi=10.1016%2fj.cor.2017.09.019&partnerID=40&md5=a7bfcc817b87977b91a290830e4e7ea2","We consider a generalization of the knapsack problem in which items are partitioned into classes, each characterized by a fixed cost and capacity. We study three alternative Integer Linear Programming formulations. For each formulation, we design an efficient algorithm to compute the linear programming relaxation (one of which is based on Column Generation techniques). We theoretically compare the strength of the relaxations and derive specific results for a relevant case arising in benchmark instances from the literature. Finally, we embed the algorithms above into a unified implicit enumeration scheme which is run in parallel with an improved Dynamic Programming algorithm to effectively solve the problem to proven optimality. An extensive computational analysis shows that our new exact algorithm is capable of efficiently solving all the instances of the literature and turns out to be the best algorithm for instances with a low number of classes. © 2017 Elsevier Ltd","Branch-and-bound algorithms; Column generation; Computational experiments; Knapsack problems; Relaxations","Benchmarking; Branch and bound method; Combinatorial optimization; Computational efficiency; Dynamic programming; Integer programming; Branch-and-bound algorithms; Column generation; Computational experiment; Knapsack problems; Relaxations; Problem solving",2-s2.0-85030164757
"Su S., Ge H., Tong Y.","Multi-graph embedding discriminative correlation feature learning for image recognition",2018,"Signal Processing: Image Communication",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032455949&doi=10.1016%2fj.image.2017.10.005&partnerID=40&md5=eb5503556831f27e262d676360a140c7","Most of existing graph-based correlation analysis algorithms construct one graph for one view. However, only one graph is difficult to well reveal intrinsic geometry structure of the view. In this paper, we construct multiple graphs for each view by means of a dimensionality partitioning method, and then propose a novel multi-graph embedding discriminative correlation feature learning algorithm that focuses on multiple graph learning and label-based discriminating enhancement under the multi-view correlation analysis framework. In the algorithm, an effective combination of multiple graphs in each view can be automatically learned in order to better capture the intrinsic geometry structure of each view. Moreover, the algorithm can learn nonlinear correlation features with well discriminating power by maximizing multi-graph intrinsic correlations of different views and simultaneously minimizing intraclass scatter of each view. Extensive experiments on several real-world image datasets have demonstrated the superiority of the algorithm in image recognition. © 2017 Elsevier B.V.","Canonical correlation analysis; Image recognition; Label-based discriminating enhancement; Multi-view feature learning; Multiple graph learning","Carrier communication; Correlation methods; Graphic methods; Image recognition; Learning algorithms; Canonical correlation analysis; Correlation analysis; Correlation features; Discriminating power; Feature learning; Multiple graph learning; Non-linear correlations; Partitioning methods; Image enhancement",2-s2.0-85032455949
"Raduła M.W., Szymura T.H., Szymura M.","Topographic wetness index explains soil moisture better than bioindication with Ellenberg's indicator values",2018,"Ecological Indicators",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032013122&doi=10.1016%2fj.ecolind.2017.10.011&partnerID=40&md5=2f00b504cff1c2f6f2b4efef3bad9e84","Topography is an important determinant of soil moisture (SM) distribution and thus drives the functioning of terrestrial ecosystems, including vegetation composition and structure. To assess soil water spatial variability, a number of indices have been used. In this study, we compared the ability of the topographic wetness index (TWI) and Ellenberg's indicator values (EIV) for moisture to explain the spatial variation of SM in central European forests. Further, we tested the potential heat load (HL) and soil water capacity (SWC) as additional factors that could improve the regressions between TWI and SM as well as EIV and SM. TWI was calculated using 10 different flow routing algorithms. The average EIV for moisture was calculated on the basis of the presence/absence of plant species. We observed that the flow routing algorithms explain SM variability better than the average EIV. The strongest relationship between TWI and SM was obtained by the MFD-md algorithm. The inclusion of SWC increased the explanatory power of both TWI and EIV. On the other hand, HL did not improve the regressions. The relative increase in the explanatory ability by SWC was particularly pronounced in case of EIV. We interpreted this to be a result of the fact that EIV reflect the synergistic effect of multiple environmental gradients on plant distribution. TWI calculated by any of the flow routing algorithms remains a better explanatory factor of SM than EIV, even if the latter was enhanced by the addition of SWC. © 2017 Elsevier Ltd","EIV; Flow routing algorithms; MFD-md; Potential heat load (HL); Soil water capacity (SWC); TWI","Forestry; Moisture; Soils; Thermal load; Central European forests; Environmental gradient; Potential heat load (HL); Soil water; Spatial variability; Terrestrial ecosystems; Topographic wetness index; Vegetation composition; Soil moisture",2-s2.0-85032013122
"Ghaffarinasab N., Motallebzadeh A., Jabarzadeh Y., Kara B.Y.","Efficient simulated annealing based solution approaches to the competitive single and multiple allocation hub location problems",2018,"Computers and Operations Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030116028&doi=10.1016%2fj.cor.2017.09.022&partnerID=40&md5=fb7d3afb22b279d2bc66a8af981243fc","Hub location problems (HLPs) constitute an important class of problems in logistics with numerous applications in passenger/cargo transportation, postal services, telecommunications, etc. This paper addresses the competitive single and multiple allocation HLPs where the market is assumed to be a duopoly. Two firms (decision makers) sequentially decide on the configuration of their hub networks trying to maximize their own market shares. The customers choose one firm based on the cost of service provided by these firms. Mathematical formulations are presented for the problems of the first and second firms (the leader and the follower, respectively) and Simulated Annealing (SA) based solution algorithms are proposed for solving these problems both in single and multiple allocation settings. Extensive computational experiments show the capability of the proposed solution algorithms to obtain the optimal solutions in short computational times. Some managerial insights are also derived based on the obtained results. © 2017 Elsevier Ltd","Hub location; Market competition; Mathematical formulation; Simulated annealing","Commerce; Competition; Decision making; Location; Postal services; Simulated annealing; Computational experiment; Computational time; Hub location; Hub location problems; Market competition; Mathematical formulation; Multiple allocation; Solution algorithms; Problem solving",2-s2.0-85030116028
"Chen H., Schall M.C., Jr., Fethke N.","Accuracy of angular displacements and velocities from inertial-based inclinometers",2018,"Applied Ergonomics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030872529&doi=10.1016%2fj.apergo.2017.09.007&partnerID=40&md5=422cbafcf2c4ca00cd464e14f14e80d9","The objective of this study was to evaluate the accuracy of various sensor fusion algorithms for measuring upper arm elevation relative to gravity (i.e., angular displacement and velocity summary measures) across different motion speeds. Thirteen participants completed a cyclic, short duration, arm-intensive work task that involved transfering wooden dowels at three work rates (slow, medium, fast). Angular displacement and velocity measurements of upper arm elevation were simultaneously measured using an inertial measurement unit (IMU) and an optical motion capture (OMC) system. Results indicated that IMU-based inclinometer solutions can reduce root-mean-square errors in comparison to accelerometer-based inclination estimates by as much as 87%, depending on the work rate and sensor fusion approach applied. The findings suggest that IMU-based inclinometers can substantially improve inclinometer accuracy in comparison to traditional accelerometer-based inclinometers. Ergonomists may use the non-proprietary sensor fusion algorithms provided here to more accurately estimate upper arm elevation. © 2017 Elsevier Ltd","Inclinometer; Inertial measurement units; Inertial-based motion capture; Kalman filter","Accelerometers; Kalman filters; Mean square error; Units of measurement; Angular displacement; Inclinometer; Inertial measurement unit; Motion capture; Optical motion capture; Root mean square errors; Sensor fusion algorithms; Traditional accelerometers; Displacement measurement",2-s2.0-85030872529
"Drovandi C.C., Moores M.T., Boys R.J.","Accelerating pseudo-marginal MCMC using Gaussian processes",2018,"Computational Statistics and Data Analysis",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029819485&doi=10.1016%2fj.csda.2017.09.002&partnerID=40&md5=f2e59b39b1563750c77d639096881ec0","The grouped independence Metropolis–Hastings (GIMH) and Markov chain within Metropolis (MCWM) algorithms are pseudo-marginal methods used to perform Bayesian inference in latent variable models. These methods replace intractable likelihood calculations with unbiased estimates within Markov chain Monte Carlo algorithms. The GIMH method has the posterior of interest as its limiting distribution, but suffers from poor mixing if it is too computationally intensive to obtain high-precision likelihood estimates. The MCWM algorithm has better mixing properties, but tends to give conservative approximations of the posterior and is still expensive. A new method is developed to accelerate the GIMH method by using a Gaussian process (GP) approximation to the log-likelihood and train this GP using a short pilot run of the MCWM algorithm. This new method called GP-GIMH is illustrated on simulated data from a stochastic volatility and a gene network model. The new approach produces reasonable posterior approximations in these examples with at least an order of magnitude improvement in computing time. Code to implement the method for the gene network example can be found at http://www.runmycode.org/companion/view/2663. © 2017 Elsevier B.V.","Gaussian processes; Likelihood-free methods; Markov processes; Particle Markov chain Monte Carlo; Pseudo-marginal methods; State space models","Approximation algorithms; Bayesian networks; Chains; Gaussian distribution; Gaussian noise (electronic); Genes; Inference engines; Markov processes; Mixing; State space methods; Stochastic models; Stochastic systems; Gaussian Processes; Likelihood-free methods; Particle markov chain monte carlo; Pseudo-marginal methods; State - space models; Monte Carlo methods",2-s2.0-85029819485
"Zhang D., Lee K., Lee I.","Hierarchical trajectory clustering for spatio-temporal periodic pattern mining",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029718478&doi=10.1016%2fj.eswa.2017.09.040&partnerID=40&md5=a4bc1ceb160791672e8140d926b9c61b","Spatio-temporal periodic pattern mining is to find temporal regularities for interesting places. Many real world spatio-temporal phenomena present sequential and hierarchical nature. However, traditional spatio-temporal periodic pattern mining ignores the consideration of sequence, and fails to take into account inherent hierarchy. This paper proposes a hierarchical trajectory clustering based periodic pattern mining that overcomes the two common drawbacks from traditional approaches: hierarchical reference spots and consideration of sequence. We propose a new trajectory clustering algorithm which considers semantic spatio-temporal information such as direction, speed and time based on Traclus and present comparative experimental results with three popular clustering methods: Kernel function, Grid-based, and Traclus. We further extend the proposed trajectory clustering to hierarchical clustering with the use of the single linkage approach to generate a hierarchy of reference spots. Experimental results reveal various hierarchical periodic patterns, and demonstrate that our algorithm outperforms traditional reference spot detection algorithms. © 2017 Elsevier Ltd","Hierarchical trajectory clustering; Periodic pattern mining; Reference spots; Single-linkage; Traclus","Data mining; Semantics; Trajectories; Hierarchical trajectory; Periodic pattern; Reference spots; Single linkage; Traclus; Clustering algorithms",2-s2.0-85029718478
"Ghasemi M.S., Afzalian A.A.","Invariant convex approximations of the minimal robust invariant set for linear difference inclusions",2018,"Nonlinear Analysis: Hybrid Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032031235&doi=10.1016%2fj.nahs.2017.09.001&partnerID=40&md5=b8203b065ded12172b14b9d2c9119d2d","In this article, we propose a new computationally efficient algorithm for computing an outer convex robust positively invariant (RPI) approximation to the minimal robust positively invariant (mRPI) set for polytypic linear difference inclusion (PLDI) systems with additive disturbances. The LDI modelling framework is useful to analyse parametrically uncertain, time-varying linear system or switching linear discrete-time systems. The disturbance which is considered in this paper, is bounded by a polytypic set and acts additively on the state of the system. It is also assumed that the nominal LDI system is absolutely asymptotically stable by a stabilizing linear state feedback. The accuracy of the approximation can be set in advance. The proposed algorithm has far less computational burden in comparison with existing algorithms. © 2017 Elsevier Ltd","Convex approximation; Linear difference inclusions; Minimal robust invariant set; Switched linear systems","Digital control systems; Discrete time control systems; Large scale systems; Linear systems; State feedback; Asymptotically stable; Computationally efficient; Convex approximation; Linear difference inclusion; Linear discrete-time systems; Robust invariant set; Switched linear system; Time varying linear systems; Approximation algorithms",2-s2.0-85032031235
"Wang J., Bi J., Wang L., Wang X.","A non-reference evaluation method for edge detection of wear particles in ferrograph images",2018,"Mechanical Systems and Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028732826&doi=10.1016%2fj.ymssp.2017.08.014&partnerID=40&md5=f5754276df24f5ab4fb8f0f6421dc6dd","Edges are one of the most important features of wear particles in a ferrograph image and are widely used to extract parameters, recognize types of wear particles, and assist in the identification of the wear mode and severity. Edge detection is a critical step in ferrograph image processing and analysis. Till date, there has been no single algorithm that guarantees the production of good quality edges in ferrograph images for a variety of applications. Therefore, it is desirable to have a reliable evaluation method for measuring the performance of various edge detection algorithms and for aiding in the selection of the optimal parameter and algorithm for ferrographic applications. In this paper, a new non-reference method for the objective evaluation of wear particle edge detection is proposed. In this method, a comprehensive index of edge evaluation is composed of three components, i.e., the reconstruction based similarity sub-index between the original image and the reconstructed image, the confidence degree sub-index used to show the true or false degree of the edge pixels, and the edge form sub-index that is used to determine the direction consistency and width uniformity of the edges. Two experiments are performed to illustrate the validity of the proposed method. First, this method is used to select the best parameters for an edge detection algorithm, and it is then used to compare the results obtained using various edge detection algorithms and determine the best algorithm. Experimental results of various real ferrograph images verify the effectiveness of the proposed method. © 2017 Elsevier Ltd","Edge detection; Edge evaluation; Ferrograph image; Wear particle analysis","Image analysis; Image processing; Parameter estimation; Signal detection; Comprehensive indices; Edge detection algorithms; Edge evaluation; Ferrograph images; Objective evaluation; Reconstructed image; Reliable evaluation method; Wear particle analysis; Edge detection",2-s2.0-85028732826
"Qin C., He Z., Yao H., Cao F., Gao L.","Visible watermark removal scheme based on reversible data hiding and image inpainting",2018,"Signal Processing: Image Communication",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032358891&doi=10.1016%2fj.image.2017.10.003&partnerID=40&md5=04327c7a772c2c4ea19da03d31c29d7c","In this paper, we propose two schemes for visible-watermark removal and reversible image recovery. In the first scheme, we consider the scenario for the image generated by a specific visible (not completely reversible) watermarking algorithm Chen et al. (2017). A run-length coding based method is utilized to compress the difference between the preliminary recovered image and original image. After embedding the difference information invisibly and reversibly, the final embedded image can be exactly recovered to its original version after visible-watermark removal, which avoids the problem of overflow and underflow in Chen et al. (2017). In the second scheme, the scenario of visible-watermark removal for the image generated by any visible watermarking algorithms (no matter the sender and the receiver know the algorithms or not) is considered. The scheme can perfectly remove the embedded visible watermark and can also exactly recover original image with the assist of image inpainting technique. In addition, for both two proposed schemes, the invalid user without the knowledge of secret key cannot achieve reversible recovery for original image. Experimental results demonstrate the effectiveness and superiority of our schemes. © 2017 Elsevier B.V.","Data compression; Inpainting; Reversible recovery; Visible watermarking; Watermark removal","Data compression; Digital watermarking; Image coding; Image watermarking; Recovery; Embedded images; Image Inpainting; Inpainting; Original images; Reversible data hiding; Run-length coding; Visible watermarking; Watermarking algorithms; Image processing",2-s2.0-85032358891
"Lee U., Jung J., Jung S., Shim D.H.","Development of a self-driving car that can handle the adverse weather",2018,"International Journal of Automotive Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030325979&doi=10.1007%2fs12239-018-0018-z&partnerID=40&md5=231983f34df8ccd0ff98753dbf7b7f2e","Lane and road recognition are essential for self-driving where GPS solution is inaccurate due to the signal block or multipath in an urban environment. Vision based lane or road recognition algorithms have been studied extensively, but they are not robust to changes in weather or illumination due to the characteristic of the sensor. Lidar is a sensor for measuring distance, but it also contains intensity information. The road mark on the road is made to look good with headlight at night by using a special paint with good reflection on the light. With this feature, road marking can be detected with lidar even in the case of changes in illumination due to the rain or shadow. In this paper, we propose equipping autonomous cars with sensor fusion algorithms intended to operate in a different weather conditions. The proposed algorithm was applied to the self-driving car EureCar (KAIST) in order to test its feasibility for real-time use. © 2018, The Korean Society of Automotive Engineers and Springer-Verlag GmbH Germany.","Adverse weather; Autonomous driving; Lane detection; Obstacle detection; Path planning","Motion planning; Obstacle detectors; Optical radar; Roads and streets; Transportation; Adverse weather; Autonomous driving; Intensity information; Lane detection; Measuring distances; Obstacle detection; Sensor fusion algorithms; Urban environments; Road and street markings",2-s2.0-85030325979
"Zhang W., Li C., Peng G., Chen Y., Zhang Z.","A deep convolutional neural network with new training methods for bearing fault diagnosis under noisy environment and different working load",2018,"Mechanical Systems and Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028727944&doi=10.1016%2fj.ymssp.2017.06.022&partnerID=40&md5=ecc45cf07b492474df8776b1c90d3c44","In recent years, intelligent fault diagnosis algorithms using machine learning technique have achieved much success. However, due to the fact that in real world industrial applications, the working load is changing all the time and noise from the working environment is inevitable, degradation of the performance of intelligent fault diagnosis methods is very serious. In this paper, a new model based on deep learning is proposed to address the problem. Our contributions of include: First, we proposed an end-to-end method that takes raw temporal signals as inputs and thus doesn't need any time consuming denoising preprocessing. The model can achieve pretty high accuracy under noisy environment. Second, the model does not rely on any domain adaptation algorithm or require information of the target domain. It can achieve high accuracy when working load is changed. To understand the proposed model, we will visualize the learned features, and try to analyze the reasons behind the high performance of the model. © 2017","Anti-noise; Convolutional neural networks; End-to-end; Intelligent fault diagnosis; Load domain adaptation","Convolution; Deep neural networks; Failure analysis; Learning algorithms; Learning systems; Neural networks; Anti noise; Convolutional neural network; Domain adaptation; End to end; Intelligent fault diagnosis; Fault detection",2-s2.0-85028727944
"Gong R., Zhang X., Li X., Shao X.","A method for optimising settings of colour primaries for wide colour gamut displays",2018,"Optik",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031093389&doi=10.1016%2fj.ijleo.2017.09.072&partnerID=40&md5=0488e90a6b3908d1c5361107bf0ec5f6","Recently, wide colour gamut displays which adopt highly saturated primaries of red, green, blue have been rapidly applied. These displays can evoke more vivid and more pleasing effects for images. However, images shown on these newly developing wide gamut devices cannot achieve preferred quality under the control of conventional signal standards that are developed based on smaller colour gamut. To achieve the preferred display effects on wide gamut devices in digital image reproduction, a whole procedure to optimise gamut settings of colour primaries were proposed, in which particular algorithms were designed to render images from signal standard such as sRGB via simulating various gamut settings on the given display. Thus, the optimum specifications of colour primaries can be determined by calculations of the proposed preference index. Furthermore, a psychophysical experiment along with a detailed discussion were carried out as a verification, in which the consistence between the preference index calculation and the visual data could certify the effectiveness of the proposed procedure and algorithms. This study may help display researchers and manufactories by supporting some recommendations to determine the primaries of wide gamut devices in applications. © 2017 Elsevier GmbH","Colour gamut; Colour rendering; Colour reproduction; Displays","Color printing; Digital devices; Display devices; Rendering (computer graphics); Colour rendering; Digital image; Display effect; Index calculation; Particular algorithms; Psychophysical experiments; Visual data; Color",2-s2.0-85031093389
"Deokar R., Tamma K.K.","A novel model order reduction framework via staggered reduced basis space-time finite elements in linear first order transient systems",2018,"International Journal of Heat and Mass Transfer",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032035932&doi=10.1016%2fj.ijheatmasstransfer.2017.10.039&partnerID=40&md5=cb63059dd234d66a3d835850e8664267","A novel model order reduction framework for space and time domain discretizations is proposed. Iterative convergence of a Galerkin approximation in space and a Least Squares Petrov Galerkin approximation in time is obtained through a staggered reduced basis method in space-time. In every iteration, one of the two domains (space or time) is refined; and the other is reduced and a posteriori error indicators in space and time are used to drive the convergence iterations. Numerical results for 2D heat transfer and convection-diffusion problems demonstrate the significant computational efficiency of the proposed methodology. Comparisons of wall-clock times and solution accuracy with traditional time integration algorithms has been presented to validate the efficacy of the proposed framework and demonstrate computational savings of an order of magnitude. © 2017 Elsevier Ltd","A posteriori error estimation; Computational thermal/fluid dynamics; Proper orthogonal decomposition; Space-time discretization; Space-time finite elements","Computational efficiency; Galerkin methods; Heat convection; Heat transfer; Iterative methods; Least squares approximations; Principal component analysis; A-posteriori error estimations; Convection diffusion problems; Galerkin approximations; Posteriori error indicator; Proper orthogonal decompositions; Space time finite element; Space-time discretization; Time integration algorithms; Finite element method",2-s2.0-85032035932
"Hu Y., Xie J., Liu Z., Ding Q., Zhu W., Zhang J., Zhang W.","CA method with machine learning for simulating the grain and pore growth of aluminum alloys",2018,"Computational Materials Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032278638&doi=10.1016%2fj.commatsci.2017.09.059&partnerID=40&md5=a7d3046220e39bf9ab099138e7cb4794","A cellular automata (CA) method assisted by a back-propagation neural network (BPNN), named CA-BPNN, is proposed to simulate grain and pore growth. First, CA-BPNN uses the BPNN to detect the relations between porosity and solidification parameters and then uses the relations to establish extra transformation rules of pore growth, which are finally implemented on A356 alloy directly. Compared with the computational results, the shapes and volume fraction of pores from experimental observation are consistent. CA-BPNN can reduce the difficulty of simulating the whole solidification process of casting without solving the high-dimensional continuous governing equations of porosity. This work can be further extended to other useful industrial alloys, such as aluminum alloys and various grades of industrial steels, if the experimental data sets are improved and other machine learning algorithms are introduced. © 2017 Elsevier B.V.","Aluminum alloy; CA-BPNN method; Grain and pore growth; Porosity","Alloy steel; Aluminum; Aluminum alloys; Artificial intelligence; Backpropagation; Learning algorithms; Learning systems; Neural networks; Porosity; Solidification; Back-propagation neural networks; Computational results; Governing equations; Industrial alloys; Pore growth; Solidification parameter; Solidification process; Transformation rules; Grain growth",2-s2.0-85032278638
"Briot S., Goldsztejn A.","Topology optimization of industrial robots: Application to a five-bar mechanism",2018,"Mechanism and Machine Theory",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030690147&doi=10.1016%2fj.mechmachtheory.2017.09.011&partnerID=40&md5=098f7c4f163b2aae4318bb52d381c4e3","Recent works introduced topology optimization in the design of robots, but the proposed methodologies led to a local optimization of the performance. Moreover, most of performance indices used are not in strong relation with easy-to-understand technological requirements. We propose a methodology that is able to perform a topology optimization for robots, valid globally in the workspace or for a set of given trajectories, and which is based on the use of technology-oriented performance criteria. In order to enforce the chosen performance indices to be valid globally, optimal robot configurations or trajectories for which extreme performance will be attained are computed, and iteratively updated. In order to decrease the computational time associated with these performance indices, we exploit the structure of the elastic models in order to reduce their computational complexity. Finally, we use an optimization algorithm called the Linearization Method which gives results in a computational time equivalent to standard topology optimization algorithms, but its implementation is less complex and makes it quite easy to perform modification or improvement. The methodology is applied for the design of a five-bar mechanism. We show that our approach leaded to a robust optimization of the robot performance over the whole workspace. © 2017 Elsevier Ltd","Deformation; Linearization method; Natural frequency; Robot design; Topological optimization","Bars (metal); Deformation; Industrial robots; Iterative methods; Linearization; Machine design; Natural frequencies; Optimal systems; Robots; Topology; Linearization methods; Local optimizations; Optimization algorithms; Performance criterion; Performance indices; Robot configurations; Robot designs; Topological optimization; Optimization",2-s2.0-85030690147
"Aparajeeta J., Mahakud S., Nanda P.K., Das N.","Variable Variance Adaptive Mean-Shift and possibilistic fuzzy C-means based recursive framework for brain MR image segmentation",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030218390&doi=10.1016%2fj.eswa.2017.09.049&partnerID=40&md5=5916578551964bc476618a40348ad653","Segmentation of brain MR image tissues has been a challenge because of the embedded nonlinear bias field acquired during the image acquisition process. This problem is further compounded due to the presence of noise. In order to deal with such issues, we have proposed a Variable Variance Adaptive Mean-Shift (VVAMS) algorithm which not only removes noise but also reinforces the clustering attribute by its mode seeking ability. We have formulated the problem for jointly estimating the bias field, tissue class labels and noise free pixels. Since, all the parameters are unknown and interdependent it is hard to obtain optimal estimates. In this regard, we have proposed a recursive framework to obtain the estimates of the parameters, which are partial optimal ones. In the first step of the recursion, the possibilistic fuzzy clustering algorithms has been applied to determine different clusters and bias field. These clusters are noisy and hence in the second step of the recursion, VVAMS algorithm has been applied on each cluster to eliminate noise and reinforce the modes of the clusters. These two steps constitute one combined iteration. Theoretically, the recursive framework is supposed to converge after large number of recursions but in practice it converges after a few iterations. This proposed scheme has successfully been tested with 50 biased noisy slices from Brainweb database and some real brain MR image data from IBSR database. The results have been quantitatively evaluated by percentage of misclassification, Rand Index, t-test, fuzzy partition coefficient (Vpc), fuzzy partition entropy (Vpe) and Tanimoto index. The quantitative evaluations of the tissue class labels demonstrate the superiority of proposed scheme over the existing methods. © 2017 Elsevier Ltd","Adaptive Mean-Shift filter; Bias estimation; Fuzzy clustering; Possibilistic clustering; Segmentation","Fuzzy clustering; Fuzzy filters; Image segmentation; Iterative methods; Magnetic resonance imaging; Parameter estimation; Tissue; Acquisition process; Adaptive mean shift filters; Adaptive mean shifts; Bias estimation; Brain MR image segmentation; Clustering attributes; Possibilistic clustering; Quantitative evaluation; Clustering algorithms",2-s2.0-85030218390
"Liu C., Wang C., Zhang Z.-H., Zheng L.","Scheduling with job-splitting considering learning and the vital-few law",2018,"Computers and Operations Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016520666&doi=10.1016%2fj.cor.2017.02.011&partnerID=40&md5=46b28f3ffab352194c2611ee67ea9a08","This research, which is motivated by real cases in labor-intensive industries where learning effects and the vital-few law take place, integrates learning and job splitting in parallel machine scheduling problems to minimize the makespan. We propose the lower bound of the problem and a job-splitting algorithm corresponding to the lower bound. Subsequently, a heuristic called SLMR is proposed based on the job-splitting algorithm with a proven worst case ratio. Furthermore, a branch-and-bound algorithm, which can obtain optimal solutions for very small problems, and a hybrid differential evolution algorithm are proposed, which can not only solve the problem, but also serve as a benchmark to evaluate the solution quality of the heuristic SLMR. The performance of the heuristic on a large number of randomly generated instances is evaluated. Results show that the proposed heuristic has good solution quality and calculation efficiency. © 2017","Job splitting; Learning effect; Makespan; Parallel machine scheduling; Vital-few law; Worst-case analysis","Benchmarking; Branch and bound method; Evolutionary algorithms; Machinery; Optimization; Problem solving; Quality control; Scheduling; Job splitting; Learning effects; Makespan; Parallel machine scheduling; Vital-few law; Worst-case analysis; Job shop scheduling",2-s2.0-85016520666
"Xia X., Zhou Y.","On the effectiveness of immune inspired mutation operators in some discrete optimization problems",2018,"Information Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031765008&doi=10.1016%2fj.ins.2017.10.038&partnerID=40&md5=0ee09b820a0af3093ca1642bed206093","Artificial immune systems have been widely applied to a variety of complex real-world problems. However, theoretical studies on artificial immune system are still limited and there is a strong need for building a rigorous theoretical foundation to better understand these heuristics. This paper contributes to a theoretical runtime analysis of immune inspired hypermutations on some discrete optimization problems. In particular, we are interested in the performance comparison among somatic contiguous hypermutations (CHM), standard bit mutations (SBM) and local mutation. We reveal that the immune inspired hypermutations can significantly outperform the standard bit mutation most often used in evolutionary algorithms on some well-known pseudo-Boolean functions including Trap and Hierarchical-if-and-only-if functions and instances of two combinatorial optimization problems, namely the Max-Cut problem and the Minimum s-t-cut problem. The proofs give some insights into the relationships between the problem characteristics and algorithmic features. The results of the analysis help strengthen the usefulness of Artificial immune systems. © 2017 Elsevier Inc.","Artificial immune systems; Discrete optimization; Evolutionary algorithms; Runtime analysis; Somatic contiguous hypermutations","Combinatorial optimization; Evolutionary algorithms; Immune system; Artificial Immune System; Combinatorial optimization problems; Discrete optimization; Discrete optimization problems; Pseudo-Boolean function; Run-time analysis; Somatic contiguous hypermutations; Theoretical foundations; Optimization",2-s2.0-85031765008
"Morsali J., Zare K., Tarafdar Hagh M.","A novel dynamic model and control approach for SSSC to contribute effectively in AGC of a deregulated power system",2018,"International Journal of Electrical Power and Energy Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028708565&doi=10.1016%2fj.ijepes.2017.08.033&partnerID=40&md5=b1297ac2fde64163ef1e3b3bd563b9b0","This paper presents a new dynamic model and control approach for static synchronous series compensator (SSSC) to participate effectively in automatic generation control (AGC) of an interconnected deregulated power system. In doing so, a new mathematical formulation is extracted to present the participation of the SSSC in the tie-line power flow exchange. Besides, fractional order controllers (FOCs) are employed to design an effective SSSC damping controller. The effectiveness of the proposed SSSC-based damping controller in preparing an efficient AGC ancillary service is compared with its earlier model. Two heuristic algorithms of improved particle swarm optimization (IPSO) and modified group search optimization (MGSO) are compared to optimize the controller parameters. To achieve realistic results under a competitive scenario, a diverse-GENCOs multi-DISCOs power system with the physical nonlinear constraints, bilateral contracts, and pool-co transactions are taken into consideration, simultaneously. Dynamic simulation results reveal that the proposed FOC-based SSSC damping controller is superior to the earlier one to improve the restructured AGC performance. Comprehensive examinations are carried out under the un-contracted step, higher degree step, and random load demands which act as contract violation scenarios to validate the damping performance of the proposed controller. To demonstrate the robustness of the proposed control approach, sensitivity analysis is accomplished in a wide range of loading condition and system parameters. © 2017 Elsevier Ltd","Deregulated power system; Fractional order controller (FOC); Load frequency control (LFC); Modified group search optimization (MGSO); Static synchronous series compensator (SSSC)","Damping; Dynamic models; Electric control equipment; Electric frequency control; Electric load flow; Electric power system control; Heuristic algorithms; Optimization; Particle swarm optimization (PSO); Sensitivity analysis; Static synchronous compensators; Deregulated power systems; Fractional-order controllers; Load-frequency control; Search optimization; Static synchronous series compensator; Controllers",2-s2.0-85028708565
"Li H., Wang J., Lu H., Guo Z.","Research and application of a combined model based on variable weight for short term wind speed forecasting",2018,"Renewable Energy",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031110924&doi=10.1016%2fj.renene.2017.09.089&partnerID=40&md5=af80ad660b2531682b27f27fbe2094cc","Wind speed forecasting plays a prominent part in the operation of wind power plants and power systems. However, it is often difficult to obtain satisfactory prediction results because wind speed data comprise random nonlinear series. Current some statistical models are not proficient in predicting nonlinear time series, whereas artificial intelligence models often fall into local optima. For these reasons, a novel combined forecasting model, which combines hybrid models based on decomposed methods and optimization algorithms, is successfully developed with variable weighting combination theory for multi-step wind speed forecasting. In this model, three different hybrid models are proposed and to further improve the forecasting performance, a modified support vector regression is used to integrate all the results obtained by each hybrid model and obtain the final forecasting results. To verify the forecasting effectiveness of the proposed forecasting model, 10-min wind speed series from Penglai, China, are used as case studies. The experimental results indicate that the developed combined model not only outperforms other benchmark models but also can be satisfactorily used for planning for smart grids. © 2017 Elsevier Ltd","Combined model; Forecasting accuracy; Short-term wind speed forecasting; Variable weight","Forecasting; Optimization; Speed; Wind effects; Wind power; Combined model; Forecasting accuracy; Forecasting performance; Optimization algorithms; Research and application; Satisfactory predictions; Short-term wind speed forecasting; Variable weight; Wind; accuracy assessment; artificial intelligence; forecasting method; optimization; prediction; research work; weight; wind power; wind velocity; China; Penglai; Shandong",2-s2.0-85031110924
"Sundaray M., Tripathy S.K., Das C.","FDTD analysis of diffraction efficiency in a hologram for application in optical fiber communication",2018,"Optik",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031732214&doi=10.1016%2fj.ijleo.2017.10.003&partnerID=40&md5=21db6cfed5a0e9707cce3d040eb7853a","Finite Difference Time Domain (FDTD) algorithm is developed and implemented for the first time in this paper to investigate the diffraction efficiency of a holographic coupler. FDTD simulation is found to be in better agreement with the results of diffraction efficiency for holographic coupler reported in literature using other theories. Further this algorithm is used to investigate the variation of diffraction efficiency with respect to wavelength at different grating period and angle of incidence in three different optical communication windows. It is found that First window is the most suitable for holographic coupler. © 2017 Elsevier GmbH","Diffraction efficiency; FDTD; Hologram; Optical fiber","Diffraction; Diffraction efficiency; Efficiency; Finite difference time domain method; Holograms; Holography; Optical communication; Optical fibers; Angle of Incidence; FDTD analysis; FDTD simulations; Finite-difference time-domain algorithms; Grating periods; Optical fiber communication",2-s2.0-85031732214
"Gultekin H., Coban B., Akhlaghi V.E.","Cyclic scheduling of parts and robot moves in m-machine robotic cells",2018,"Computers and Operations Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030097791&doi=10.1016%2fj.cor.2017.09.018&partnerID=40&md5=3c1807e6d59f038c104649c4dcf62c39","We consider a flow shop type manufacturing cell consisting of m machines and a material handling robot producing multiple parts. The robot transfers the parts between the machines and loads/unloads the machines. We consider the cyclic scheduling of the parts and the robot moves with the objective of maximizing the throughput rate. We develop a mixed integer linear programming formulation of the problem. The formulation is improved with several valid inequalities and reformulations of the constraints. We also develop a hybrid metaheuristic algorithm for this strongly NP-Hard problem. The algorithm is modified to handle both 1-unit and multi-unit robot cycles. Multi-threading is used to parallelize the algorithm in order to improve its efficiency. After calibrating the parameters of the heuristic algorithm, an extensive computational study is performed to evaluate its performance. The results of this study revealed that the developed heuristic provides near-optimal solutions in reasonable solution times. The effects of parallelization and the benefits of considering multi-unit cycles instead of 1-unit cycles are also quantified. Our computational tests show that multi-unit cycles improve the throughput rate by 9% on the average. The improvement can reach to 20% depending on the problem parameters. © 2017 Elsevier Ltd","Hybrid metaheuristic; Mixed integer linear programming formulation; Multiple parts; Robotic cell scheduling; Throughput maximization","Computational complexity; Embedded systems; Heuristic algorithms; Integer programming; Marking machines; Materials handling; Robotics; Robots; Scheduling; Throughput; Hybrid Meta-heuristic; Mixed integer linear programming; Multiple parts; Robotic-cell scheduling; Throughput maximization; Robot programming",2-s2.0-85030097791
"Conti C., Romani L., Schenone D.","Semi-automatic spline fitting of planar curvilinear profiles in digital images using the Hough transform",2018,"Pattern Recognition",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032300062&doi=10.1016%2fj.patcog.2017.09.017&partnerID=40&md5=2fa1d25367a8865000bab17e6a950b9d","We develop a novel method for the recognition of curvilinear profiles in digital images. The proposed method, semi-automatic for both closed and open planar profiles, essentially consists of a preprocessing step exploiting an edge detection algorithm, and a main step involving the Hough transform technique. In the preprocessing step, a Canny edge detection algorithm is applied in order to obtain a reduced point set describing the profile curve to be reconstructed. Also, to identify in the profile possible sharp points like cusps, we additionally use an algorithm to find the approximated tangent vector of every edge point. In the subsequent main step, we then use a piecewisely defined Hough transform to locally recognize from the point set a low-degree piecewise polynomial curve. The final outcome of the algorithm is thus a spline curve approximating the underlined profile image. The output curve consists of polynomial pieces connected G1 continuously, except in correspondence of the identified cusps, where the order of continuity is only C0, as expected. To illustrate effectiveness and efficiency of the new profile detection technique we present several numerical results dealing with detection of open and closed profiles in images of different type, i.e., medical and photographic images. © 2017 Elsevier Ltd","Cusps; G1-continuity; Hough transform; Profile recognition; Spline fitting","Edge detection; Geometry; Hough transforms; Image processing; Medical imaging; Photography; Polynomial approximation; Signal detection; Canny edge detection; Cusps; Edge detection algorithms; Effectiveness and efficiencies; G^1-continuity; Piecewise polynomials; Profile recognition; Spline fitting; Feature extraction",2-s2.0-85032300062
"Nan Y., Li W., Bao W., Delicato F.C., Pires P.F., Zomaya A.Y.","A dynamic tradeoff data processing framework for delay-sensitive applications in Cloud of Things systems",2018,"Journal of Parallel and Distributed Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032446267&doi=10.1016%2fj.jpdc.2017.09.009&partnerID=40&md5=b02ccb86db7df439e74ad5f2ec8fd1dc","The steep rise of Internet of Things (IoT) applications along with the limitations of Cloud Computing to address all IoT requirements leveraged a new distributed computing paradigm called Fog Computing, which aims to process data at the edge of the network. With the help of Fog Computing, the transmission latency, monetary spending and application loss caused by Cloud Computing can be effectively reduced. However, as the processing capacity of fog nodes is more limited than that of cloud platforms, running all applications indiscriminately on these nodes can cause some QoS requirement to be violated. Therefore, there is important decision-making as to where executing each application in order to produce a cost effective solution and fully meet application requirements. In particular, we are interested in the tradeoff in terms of average response time, average cost and average number of application loss. In this paper, we present an online algorithm, called unit-slot optimization, based on the technique of Lyapunov optimization. The unit-slot optimization is a quantified near-optimal online solution to balance the three-way tradeoff among average response time, average cost and average number of application loss. We evaluate the performance of the unit-slot optimization algorithm by a number of experiments. The experimental results not only match up the theoretical analyses properly, but also demonstrate that our proposed algorithm can provide cost-effective processing, while guaranteeing average response time and average number of application loss in a three-tier Cloud of Things system. © 2017 Elsevier Inc.","Average response time; Fog computing; Internet of Things; Lyapunov optimization","Cloud computing; Cost benefit analysis; Cost effectiveness; Costs; Data handling; Decision making; Economics; Fog; Internet of things; Optimization; Response time (computer systems); Application loss; Application requirements; Cost-effective solutions; Delay-sensitive applications; Internet of Things (IOT); On-line algorithms; Processing capacities; Slot optimization; Distributed computer systems",2-s2.0-85032446267
"Hao R., Su Z.","A patch-based low-rank tensor approximation model for multiframe image denoising",2018,"Journal of Computational and Applied Mathematics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013952073&doi=10.1016%2fj.cam.2017.01.022&partnerID=40&md5=ac6d3b1cfeb68b67d1cc428b9a9925aa","Compared with matrix, tensor is a more natural representation for multiframe image, such as hyperspectral image and MRI image. Low-rankness of tensor is essential to describe the intrinsic geometrical structure of these data. Patch-based low-rank models have shown their ability to exploit spatial redundancy of computer vision data especially for natural image denoising. However, most of the existed patch-based matrix models are based on two dimensional low-rankness, which cannot fully reveal the correlation of every direction in high-order multiframe images; the existed patch-based tensor models either need additional assumptions or need SVD in every loop of iteration which is computationally expensive. In this paper, we propose a novel patch-based model to recover a low-rank tensor by simultaneously performing low-rank matrix factorizations to the all-mode matricizations of the underlying low-rank tensor. An augmented Lagrangian alternating minimization algorithm is implemented to solve the model along with two adaptive rank-adjusting strategies when the exact rank is unknown. We apply the proposed algorithm to multiframe image denoising by exploiting the nonlocal self-similarity. Experimental results show that our algorithm can better preserve the sharpness of important image structures and outperforms several state-of-the-art denoising methods. © 2017 Elsevier B.V.","Augmented Lagrangian alternating; Image denoising; Low-rank tensor; Patch-based model","Computerized tomography; Constrained optimization; Iterative methods; Lagrange multipliers; Magnetic resonance imaging; Matrix algebra; Optimization; Spectroscopy; Tensors; Alternating minimization algorithms; Augmented Lagrangians; Geometrical structure; Low-rank matrices; Low-rank tensor approximations; Natural representation; Patch based; Spatial redundancy; Image denoising",2-s2.0-85013952073
"Yaghoubi V., Vakilzadeh M.K., Abrahamsson T.J.S.","Automated modal parameter estimation using correlation analysis and bootstrap sampling",2018,"Mechanical Systems and Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028731583&doi=10.1016%2fj.ymssp.2017.07.004&partnerID=40&md5=ddebfc30c830cfd58291aeecaf04afaa","The estimation of modal parameters from a set of noisy measured data is a highly judgmental task, with user expertise playing a significant role in distinguishing between estimated physical and noise modes of a test-piece. Various methods have been developed to automate this procedure. The common approach is to identify models with different orders and cluster similar modes together. However, most proposed methods based on this approach suffer from high-dimensional optimization problems in either the estimation or clustering step. To overcome this problem, this study presents an algorithm for autonomous modal parameter estimation in which the only required optimization is performed in a three-dimensional space. To this end, a subspace-based identification method is employed for the estimation and a non-iterative correlation-based method is used for the clustering. This clustering is at the heart of the paper. The keys to success are correlation metrics that are able to treat the problems of spatial eigenvector aliasing and nonunique eigenvectors of coalescent modes simultaneously. The algorithm commences by the identification of an excessively high-order model from frequency response function test data. The high number of modes of this model provides bases for two subspaces: one for likely physical modes of the tested system and one for its complement dubbed the subspace of noise modes. By employing the bootstrap resampling technique, several subsets are generated from the same basic dataset and for each of them a model is identified to form a set of models. Then, by correlation analysis with the two aforementioned subspaces, highly correlated modes of these models which appear repeatedly are clustered together and the noise modes are collected in a so-called Trashbox cluster. Stray noise modes attracted to the mode clusters are trimmed away in a second step by correlation analysis. The final step of the algorithm is a fuzzy c-means clustering procedure applied to a three-dimensional feature space to assign a degree of physicalness to each cluster. The proposed algorithm is applied to two case studies: one with synthetic data and one with real test data obtained from a hammer impact test. The results indicate that the algorithm successfully clusters similar modes and gives a reasonable quantification of the extent to which each cluster is physical. © 2017 Elsevier Ltd","Bootstrapping; Correlation-based clustering; Frequency responses; Fuzzy c-means clustering; Modal Observability Correlation; Modal parameter estimation; QR- and singular value decomposition; Subspace-based identification","Clustering algorithms; Composite beams and girders; Correlation methods; Eigenvalues and eigenfunctions; Frequency estimation; Frequency response; Fuzzy systems; Iterative methods; Modal analysis; Optimization; Singular value decomposition; Bootstrapping; Correlation based clustering; Fuzzy C means clustering; Modal parameter estimation; Subspace-based identification; Parameter estimation",2-s2.0-85028731583
"Willner A.E., Zhao Z., Ren Y., Li L., Xie G., Song H., Liu C., Zhang R., Bao C., Pang K.","Underwater optical communications using orbital angular momentum-based spatial division multiplexing",2018,"Optics Communications",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028314264&doi=10.1016%2fj.optcom.2017.08.002&partnerID=40&md5=c43e7169a064ddc69ce696d98ef52926","In this paper, we review high-capacity underwater optical communications using orbital angular momentum (OAM)-based spatial division multiplexing. We discuss methods to generate and detect blue–green optical data-carrying OAM beams as well as various underwater effects, including attenuation, scattering, current, and thermal gradients on OAM beams. Attention is also given to the system performance of high-capacity underwater optical communication links using OAM-based space division multiplexing. The paper closes with a discussion of a digital signal processing (DSP) algorithm to mitigate the inter-mode crosstalk caused by thermal gradients. © 2017 Elsevier B.V.","Orbital angular momentum; Spatial division multiplexing; Underwater communications","Angular momentum; Digital signal processing; Momentum; Signal processing; Space division multiple access; Telecommunication links; Thermal gradients; Digital signal processing algorithms; High capacity; Optical data; Orbital angular momentum; Space division multiplexing; Spatial Division Multiplexing; Underwater communication; Underwater optical communications; Optical communication",2-s2.0-85028314264
"Schröder T., Lauven L.-P., Geldermann J.","Improving biorefinery planning: Integration of spatial data using exact optimization nested in an evolutionary strategy",2018,"European Journal of Operational Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011008962&doi=10.1016%2fj.ejor.2017.01.016&partnerID=40&md5=4ca98924ae973c1c97ca0833fc05c172","Biorefineries can provide a product portfolio from renewable biomass similar to that of crude oil refineries. To operate biorefineries of any kind, however, the availability of biomass inputs is crucial and must be considered during planning. Here, we develop a planning approach that uses Geographic Information Systems (GIS) to account for spatially scattered biomass when optimizing a biorefinery's location, capacity, and configuration. To deal with the challenges of a non-smooth objective function arising from the geographic data, higher dimensionality, and strict constraints, the planning problem is repeatedly decomposed by nesting an exact nonlinear program (NLP) inside an evolutionary strategy (ES) heuristic, which handles the spatial data from the GIS. We demonstrate the functionality of the algorithm and show how including spatial data improves the planning process by optimizing a synthesis gas biorefinery using this new planning approach. © 2017 Elsevier B.V.","Biorefinery; Evolutionary computations; Evolutionary strategy; Geographic Information System; Location planning; NLP","Bioconversion; Biomass; Crude oil; Evolutionary algorithms; Information systems; Natural language processing systems; Nonlinear programming; Optimization; Planning; Refining; Biorefineries; Evolutionary strategies; Location planning; Nonlinear programs; Objective functions; Planning problem; Product portfolios; Strict constraint; Geographic information systems",2-s2.0-85011008962
"Xu S., Sun G., Liu J., Li Z.","Reliable Finite-Time Robust Control for Sampled-Data Mechanical Systems under Stochastic Actuator Failures",2018,"Journal of Dynamic Systems, Measurement and Control, Transactions of the ASME",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029169310&doi=10.1115%2f1.4037333&partnerID=40&md5=999cff8bcb69bf4e7af61f5d7a2a35ad","This paper considers the problem of reliable finite-time robust control for uncertain mechanical systems with stochastic actuator failures and aperiodic sampling. A novel model of actuator failure capable of depicting various faulty modes is developed on the basis of homogenous Markov variable. To guarantee the finite-time stability (FTS) and boundedness, a novel fault-tolerant switching controller is developed by virtue of Lyapunov-Krasovskii functional and stochastic analysis technique, simultaneously, the finite-time H∞ performance is also ensured to attenuate the mechanical vibration caused by external disturbances. With convex optimization algorithm, the anticipated controller can be procured by solving a set of linear matrix inequalities (LMIs). Finally, two practical examples of mechanical systems, one of which is governed by lumped parameters and the other is described by distributed parameters, are proposed to prove the effectiveness of the theoretical developments of this study. Copyright © 2018 by ASME.",,"Actuators; Controllers; Convex optimization; Failure (mechanical); Linear matrix inequalities; Lyapunov functions; Mechanical actuators; Mechanics; Optimization; Robust control; Sampled data control systems; Stochastic systems; Uncertain systems; Vibration analysis; Convex optimization algorithms; Distributed parameter; External disturbances; Finite time stability; Lyapunov-Krasovskii functionals; Stochastic analysis; Switching controllers; Theoretical development; Vibrations (mechanical)",2-s2.0-85029169310
"Gu J., Jiao L., Liu F., Yang S., Wang R., Chen P., Cui Y., Xie J., Zhang Y.","Random subspace based ensemble sparse representation",2018,"Pattern Recognition",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032278032&doi=10.1016%2fj.patcog.2017.09.016&partnerID=40&md5=85f99efd3fa094b75ca804720b73318a","In this paper, a new random subspace based ensemble sparse representation (RS_ESR) algorithm is proposed, where the random subspace is introduced into sparse representation model. For high-dimensional data, the random subspace method can not only reduce dimension of data but also make full use of effective information of data. It is not like traditional dimensionality reduction methods that may lose some information of original data. Additionally, a joint sparse representation model is emloyed to obtain the sparse representation of a sample set in the low dimensional random subspace. Then the sparse representations in multiple random subspaces are integrated as an ensemble sparse representation. Moreover, the obtained RS_ESR is applied in classical clustering and semi-supervised classification. The experimental results on different real-world data sets show the superiority of RS_ESR over traditional methods. © 2017 Elsevier Ltd","Clustering; Random subspace; Semi-supervised classification; Sparse representation","Clustering algorithms; Clustering; Dimensionality reduction method; High dimensional data; Low dimensional; Random subspace method; Random subspaces; Semi-supervised classification; Sparse representation; Supervised learning",2-s2.0-85032278032
"Huang Z., Yang S., Su T.","Nonlinear Jitter of a Clock Path Due to Electromagnetic Interference on the Supply",2018,"IEEE Transactions on Electromagnetic Compatibility",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020069959&doi=10.1109%2fTEMC.2017.2707301&partnerID=40&md5=70aaa6799229be15a7e4cbc0af02dc40","The paper presents a simple time-domain model for the nonlinear behavior of the jitter of a clock path due to electromagnetic interference on the power supply. A programming algorithm based on the model is developed to calculate the numerical value of the jitter. Transistor-level simulations and test-board measurements are performed on clock paths of various lengths to verify the jitter model. Good agreement between the experiments and MATLAB calculations are observed over wide ranges of interference frequencies and amplitudes. Interesting phenomena, such as the jitter-minimum shift and jitter inflection, can be explained and precisely predicted using the jitter model. An analytical equation is derived for the relationship between the interference frequency and amplitude for the jitter-minimum. The model requires only simple information from the gate circuit for the jitter calculation. It can be further developed into an analytical tool for predicting clock jitter under external electromagnetic interference. © 1964-2012 IEEE.","Clock path; electromagnetic interference; integrated circuits (ICs); jitter","Clocks; Electromagnetic pulse; Electromagnetic wave interference; MATLAB; Signal interference; Time domain analysis; Analytical equations; Interference frequency; Nonlinear behavior; Numerical values; Programming algorithms; Simple informations; Time domain modeling; Transistor-level simulation; Jitter",2-s2.0-85020069959
"Levitin G., Finkelstein M., Dai Y.","Optimizing availability of heterogeneous standby systems exposed to shocks",2018,"Reliability Engineering and System Safety",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032442205&doi=10.1016%2fj.ress.2017.10.021&partnerID=40&md5=dced0860ccdfbc5f8c9a2a3e47ed4600","The paper considers heterogeneous 1-out-of-N warm standby systems when all components can experience internal failures whereas operating components are exposed to the external shocks as well. The components’ resilience to shocks decreases with the number of experienced shocks describing the corresponding deterioration in time. Therefore, a preventive replacement policy when the operating component is replaced after it survives a certain number of shocks (that becomes a decision parameter) is considered. The replacement time is random and not negligible. The distributions of corrective and preventive replacement times are assumed to be known for each component. The expression for the instantaneous (point) availability is derived and the original numerical algorithm for its evaluation is suggested. Then an optimization problem for a replacement policy that maximizes the overall mission availability over a finite time horizon is formulated and solved. Illustrative examples are provided. © 2017 Elsevier Ltd","Optimization; Preventive replacement; Random shocks; Standby system","Optimization; Finite time horizon; Mission availabilities; Numerical algorithms; Operating components; Optimization problems; Preventive replacements; Random shocks; Stand-by systems; Availability",2-s2.0-85032442205
"Farham M.S., Süral H., Iyigun C.","A column generation approach for the location-routing problem with time windows",2018,"Computers and Operations Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030461824&doi=10.1016%2fj.cor.2017.09.010&partnerID=40&md5=3ab658429f14d0c98364afc0a2bbb188","The location-routing problem with time windows consists of opening a subset of depots, assigning customers to depots, and determining routes within allowable times such that the sum of depot opening, vehicle usage, and traveling costs is minimized. Customers have to be visited only once during their time windows and depot capacities and load limits of vehicles cannot be violated. In order to find the exact solution to the problem, we propose a branch-and-price algorithm based on set-partitioning approach. The pricing problem is solved using dynamic programming. We introduce several strategies to improve the lower and upper bounds as well as acceleration techniques to generate improving columns more rapidly. Computational results show the higher performance of the proposed method on a set of small and medium size instances in the literature and demonstrate its efficiency in solving generated large size instances. © 2017 Elsevier Ltd","Branch-and-price; Column generation; Location-routing problem; Time windows","Costs; Dynamic programming; Integer programming; Location; Acceleration technique; Branch and price; Branch-and-price algorithms; Column generation; Column generation approach; Location routing problem; Lower and upper bounds; Time windows; Linear programming",2-s2.0-85030461824
"Ta T.T., Lin C.-Y., Lu C.L.","Two-string consensus problem under non-overlapping inversion and transposition distance",2018,"Information Processing Letters",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032439187&doi=10.1016%2fj.ipl.2017.10.006&partnerID=40&md5=44c3f5da51c00fc7d16667a802d9ee00","For biological sequences that can be represented as strings over a finite alphabet, inversion and transposition are commonly observed mutation operations. The non-overlapping inversion and transposition distance (also simply called mutation distance) between two strings is defined as the minimum number of non-overlapping inversion and transposition operations used to transform one string into the other. Given two strings of the same length n and a constant c≥0, the two-string consensus problem under mutation distance is to determine whether or not there exists a string s⁎ such that the mutation distance from s⁎ to each input string does not exceed c. In this study, we present an O(n5) time and O(n4) space algorithm to solve this problem. © 2017 Elsevier B.V.","Algorithms; Computational biology; Inversion; Transposition; Two-string consensus problem","Algorithms; Computer applications; Data processing; Biological sequences; Computational biology; Consensus problems; Inversion; Mutation operations; Non-overlapping inversions; Transposition; Transposition distances; Problem solving",2-s2.0-85032439187
"Li H., Shu D., Zhang Y., Yi G.Y.","Simultaneous variable selection and estimation for multivariate multilevel longitudinal data with both continuous and binary responses",2018,"Computational Statistics and Data Analysis",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031023931&doi=10.1016%2fj.csda.2017.09.004&partnerID=40&md5=c0beccad695261de2fa04da3425df8fb","Complex structured data settings are studied where outcomes are multivariate and multilevel and are collected longitudinally. Multivariate outcomes include both continuous and discrete responses. In addition, the data contain a large number of covariates but only some of them are important in explaining the dynamic features of the responses. To delineate the complex association structures of the responses, a model with correlated random effects is proposed. To handle the large dimensionality of covariates, a simultaneous variable selection and parameter estimation method is developed. To implement the method, a computationally feasible algorithm is described. The proposed method is evaluated empirically by simulation studies and illustrated by analyzing the data arising from the Waterloo Smoking Prevention Project. © 2017 Elsevier B.V.","Longitudinal data; Mixed effects model; Multivariate multilevel longitudinal data; Penalized quasi-likelihood; Variable selection","Graphical user interfaces; Random processes; Association structures; Complex structured datum; Feasible algorithms; Longitudinal data; Mixed effects models; Parameter estimation method; Quasi-likelihood; Variable selection; Multivariant analysis",2-s2.0-85031023931
"Greenwood M., Shampur K.N., Ofori-Opoku N., Pinomaa T., Wang L., Gurevich S., Provatas N.","Quantitative 3D phase field modelling of solidification using next-generation adaptive mesh refinement",2018,"Computational Materials Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031711943&doi=10.1016%2fj.commatsci.2017.09.029&partnerID=40&md5=7d4552db661a7c5aa374cd49be817c00","Phase field (PF) models are one of the most popular methods for simulating solidification microstructures due to their fundamental connections to the physics of phase transformations. However, these methods are numerically very stiff due to the multiple length scales in a solidifying material, from the nanoscopic solid-liquid interface, to dendritic structures on the order of hundreds of microns. While this problem can be greatly alleviated by thin-interface analytical treatments of the PF equations, additional numerical methods are required to explore experimentally relevant sample sizes and times scales. It was shown about 18 years ago that the use of dynamic adaptive mesh refinement (AMR) can alleviate this problem by exploiting the simple fact that the majority of the solidification kinetics occur at the solid-liquid interface, which scales with a lower dimensionality than the embedding system itself. AMR methods, together with asymptotic analysis, nowadays provide one of the most efficient numerical strategies for self-consistent quantitative PF modelling of solidification microstructure processes. This paper highlights the latest developments in the AMR technique for 3D modelling of solidification using classical phase field equations. This includes a move away from finite element techniques to faster finite differencing through the use of dynamic mini-meshes which are each associated with each node of a 3D Octree data structure, and distributed MPI parallelism that uses a new communication algorithm to decompose a 3D domain into multiple adaptive meshes that are spawned on separate cores. The numerical technique is discussed, followed by demonstrations of the new AMR algorithm on select benchmark solidification problems, as well as some illustrations of multi-phase modelling using a recently developed multi-order parameter phase field model. © 2017","Adaptive meshing; Large scale simulation; Parallel computing; Phase field; Solidification","Asymptotic analysis; Interfaces (materials); Mesh generation; Microstructure; Numerical analysis; Parallel processing systems; Phase interfaces; Solidification; Adaptive mesh refinement; Adaptive meshing; Communication algorithms; Finite element techniques; Large scale simulations; Phase fields; Solid-liquid interfaces; Solidification microstructures; Numerical methods",2-s2.0-85031711943
"Fazli Shahri H.R., Mahdavinejad R.","Prediction of temperature and HAZ in thermal-based processes with Gaussian heat source by a hybrid GA-ANN model",2018,"Optics and Laser Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029602511&doi=10.1016%2fj.optlastec.2017.09.024&partnerID=40&md5=d82d05eff5970f5da0862462f8e77f05","Thermal-based processes with Gaussian heat source often produce excessive temperature which can impose thermally-affected layers in specimens. Therefore, the temperature distribution and Heat Affected Zone (HAZ) of materials are two critical factors which are influenced by different process parameters. Measurement of the HAZ thickness and temperature distribution within the processes are not only difficult but also expensive. This research aims at finding a valuable knowledge on these factors by prediction of the process through a novel combinatory model. In this study, an integrated Artificial Neural Network (ANN) and genetic algorithm (GA) was used to predict the HAZ and temperature distribution of the specimens. To end this, a series of full factorial design of experiments were conducted by applying a Gaussian heat flux on Ti-6Al-4 V at first, then the temperature of the specimen was measured by Infrared thermography. The HAZ width of each sample was investigated through measuring the microhardness. Secondly, the experimental data was used to create a GA-ANN model. The efficiency of GA in design and optimization of the architecture of ANN was investigated. The GA was used to determine the optimal number of neurons in hidden layer, learning rate and momentum coefficient of both output and hidden layers of ANN. Finally, the reliability of models was assessed according to the experimental results and statistical indicators. The results demonstrated that the combinatory model predicted the HAZ and temperature more effective than a trial-and-error ANN model. © 2017 Elsevier Ltd","GA-ANN; Gaussian distribution; HAZ; Infrared thermography; Temperature; Thermal-based process","Aluminum alloys; Binary alloys; Design of experiments; Forecasting; Gaussian distribution; Genetic algorithms; Heat flux; Neural networks; Temperature; Temperature distribution; Thermography (imaging); Titanium alloys; Affected layers; Critical factors; Design and optimization; Full factorial design; Gaussian heat flux; Momentum coefficient; Process parameters; Statistical indicators; Heat affected zone",2-s2.0-85029602511
"Zanella R., Porta F., Ruggiero V., Zanetti M.","Serial and parallel approaches for image segmentation by numerical minimization of a second-order functional",2018,"Applied Mathematics and Computation",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025654894&doi=10.1016%2fj.amc.2017.07.021&partnerID=40&md5=4b4e28725def51dec85358885d2c3c10","Because of its attractive features, second order segmentation has shown to be a promising tool in remote sensing. A known drawback about its implementation is computational complexity, above all for large set of data. Recently in Zanetti et al. [1], an efficient version of the block-coordinate descent algorithm (BCDA) has been proposed for the minimization of a second order elliptic approximation of the Blake–Zissermann functional. Although the parallelization of linear algebra operations is expected to increase the performance of BCDA when addressing the segmentation of large-size gridded data (e.g., full-scene images or Digital Surface Models (DSMs)), numerical evidence shows that this is not sufficient to get significant reduction of computational time. Therefore a novel approach is proposed which exploits a decomposition technique of the image domain into tiles. The solution can be computed by applying BCDA on each tile in parallel way and combining the partial results corresponding to the different blocks of variables through a proper interconnection rule. We prove that this parallel method (OPARBCDA) generates a sequence of iterates which converges to a critical point of the functional on the level set devised by the starting point. Furthermore, we show that the parallel method can be efficiently implemented even in a commodity multicore CPU. Numerical results are provided to evaluate the efficiency of the parallel scheme on large images in terms of computational cost and its effectiveness with respect to the behavior on the tile junctions. © 2017 Elsevier Inc.","Blake–Zisserman functional; Block coordinate descent methods; Domain decomposition; Parallel interconnection rule; Segmentation","Approximation algorithms; Domain decomposition methods; Linear algebra; Numerical methods; Blake-Zisserman functional; Block coordinate descents; Decomposition technique; Digital surface models; Linear algebra operations; Numerical minimization; Parallel interconnection; Second order elliptic; Image segmentation",2-s2.0-85025654894
"Hemmat Esfe M., Tatar A., Ahangar M.R.H., Rostamian H.","A comparison of performance of several artificial intelligence methods for predicting the dynamic viscosity of TiO2/SAE 50 nano-lubricant",2018,"Physica E: Low-Dimensional Systems and Nanostructures",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031997614&doi=10.1016%2fj.physe.2017.08.019&partnerID=40&md5=a307068e196f8839300b39fd46156610","Since the conventional thermal fluids such as water, oil, and ethylene glycol have poor thermal properties, the tiny solid particles are added to these fluids to increase their heat transfer improvement. As viscosity determines the rheological behavior of a fluid, studying the parameters affecting the viscosity is crucial. Since the experimental measurement of viscosity is expensive and time consuming, predicting this parameter is the apt method. In this work, three artificial intelligence methods containing Genetic Algorithm-Radial Basis Function Neural Networks (GA-RBF), Least Square Support Vector Machine (LS-SVM) and Gene Expression Programming (GEP) were applied to predict the viscosity of TiO2/SAE 50 nano-lubricant with Non-Newtonian power-law behavior using experimental data. The correlation factor (R2), Average Absolute Relative Deviation (AARD), Root Mean Square Error (RMSE), and Margin of Deviation were employed to investigate the accuracy of the proposed models. RMSE values of 0.58, 1.28, and 6.59 and R2 values of 0.99998, 0.99991, and 0.99777 reveal the accuracy of the proposed models for respective GA-RBF, CSA-LSSVM, and GEP methods. Among the developed models, the GA-RBF shows the best accuracy. © 2017 Elsevier B.V.","GEP; LSSVM; Nano-fluid; New correlation; Non-Newtonian; RBF; Viscosity","Artificial intelligence; Ethylene; Ethylene glycol; Forecasting; Gene expression; Genetic algorithms; Heat transfer; Least squares approximations; Mean square error; Non Newtonian flow; Solid lubricants; Support vector machines; Titanium dioxide; Viscosity; Artificial intelligence methods; Average absolute relative deviations; Least square support vector machines; LSSVM; Nanofluids; New correlations; Non-newtonian; Radial basis function neural networks; Radial basis function networks",2-s2.0-85031997614
"Pigani L., Vasile Simone G., Foca G., Ulrici A., Masino F., Cubillana-Aguilera L., Calvini R., Seeber R.","Prediction of parameters related to grape ripening by multivariate calibration of voltammetric signals acquired by an electronic tongue",2018,"Talanta",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029517639&doi=10.1016%2fj.talanta.2017.09.027&partnerID=40&md5=0170a01a546b128ea23259bdcb17e4f3","An electronic tongue (ET) consisting of two voltammetric sensors, namely a poly-ethylendioxythiophene modified Pt electrode and a sonogel carbon electrode, has been developed aiming at monitoring grape ripening. To test the effectiveness of device and measurement procedures developed, samples of three varieties of grapes have been collected from veraison to harvest of the mature grape bunches. The derived musts have been then submitted to electrochemical investigation using Differential Pulse Voltammetry technique. At the same time, quantitative determination of specific analytical parameters for the evaluation of technological and phenolic maturity of each sample has been performed by means of conventional analytical techniques. After a preliminary inspection by principal component analysis, calibration models were calculated both by partial least squares (PLS) on the whole signals and by the interval partial least squares (iPLS) variable selection algorithm, in order to estimate physico-chemical parameters. Calibration models have been obtained both considering separately the signals of each sensor of the ET, and by proper fusion of the voltammetric data selected from the two sensors by iPLS. The latter procedure allowed us to check the possible complementarity of the information brought by the different electrodes. Good predictive models have been obtained for estimation of pH, total acidity, sugar content, and anthocyanins content. The application of the ET for fast evaluation of grape ripening and of most suitable harvesting time is proposed. © 2017 Elsevier B.V.","Data fusion; Electronic tongue; Grape ripening; Partial least squares regression; Variable selection; Voltammetric sensors","Calibration; Carbon; Chemical analysis; Data fusion; Electrodes; Electronic tongues; Least squares approximations; Parameter estimation; Principal component analysis; Sensor data fusion; Differential pulse voltammetry techniques; Electrochemical investigations; Grape ripening; Interval partial least-squares (iPLS); Partial least squares regression; Variable selection; Variable selection algorithms; Voltammetric sensor; Voltammetry",2-s2.0-85029517639
"Hernández-García R., Ramos-Cózar J., Guil N., García-Reyes E., Sahli H.","Improving Bag-of-Visual-Words model using visual n-grams for human action classification",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030103988&doi=10.1016%2fj.eswa.2017.09.016&partnerID=40&md5=7f7b236d6ac6a4ccf9545d9c8deffff1","The Bag-of-Visual-Words model has emerged as an effective approach to represent local video features for human actions classification. However, one of the major challenges in this model is the generation of the visual vocabulary. In the case of human action recognition, losing spatial-temporal relationships is one of the important reasons that provokes the low descriptive power of classic visual words. In this work we propose a three-level approach to construct visual n-grams for human action classification. First, in order to reduce the number of non-descriptive words generated by K-means clustering of the spatio-temporal interest points, we propose to apply a variant of the classical Leader-Follower clustering algorithm to create an optimal vocabulary from a pre-established number of visual words. Second, with the aim of incorporating spatial and temporal constraints to the Bag-of-Visual-Words model, we exploit the spatio-temporal relationships between interest points to build a graph-based representation of the video. Frequent subgraphs are extracted for each action class and a visual vocabulary of n-grams is constructed from the labels (descriptors) of selected subgraphs. Finally, we build a histogram by using the frequency of each n-gram in the graph representing a video of human action. The proposed approach combines the representational power of graphs with the efficiency of the Bag-of-Visual-Words model. Extensive validation on five challenging human actions datasets demonstrates the effectiveness of the proposed model compared to state-of-the-art methods. © 2017 Elsevier Ltd","Bag-of-Visual-Words; Graph-based representation; Human action classification; Visual n-grams","Graphic methods; Image recognition; Bag-of-visual-words; Graph-based representations; Human action classifications; Leader-follower clustering; N-grams; Spatial temporal relationship; Spatio-temporal interest points; Spatio-temporal relationships; Clustering algorithms",2-s2.0-85030103988
"Khaki M., Shahsavar A., Khanmohammadi S.","Scenario-Based Multi-Objective Optimization of an Air-Based Building-Integrated Photovoltaic/Thermal System",2018,"Journal of Solar Energy Engineering, Transactions of the ASME",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031709648&doi=10.1115%2f1.4038050&partnerID=40&md5=2136712240a2cf676c57632f7bc04f44","In this paper, a genetic algorithm-based multi-objective optimization of a building-integrated photovoltaic/thermal (BIPV/T) system is carried out to find the best system configurations which lead to maximum energetic and exergetic performances for Kermanshah, Iran climatic condition. In the proposed BIPV/T system, the cooling potential of ventilation and exhaust airs are used in buildings for cooling the PV panels and also heating the ventilation air by heat rejection of PV panels. Four scenarios with various criteria in the form of system efficiencies and useful outputs are considered to reflect all possible useful outputs in the optimization procedure. This study models a glazed BIPV/T system with various collector areas (Apv=10,15,25,and30m2) and different length to width ratio (L/W=0.5,1,1.5,and2) to determine the optimum air mass flow rate, bottom heat loss coefficient, depth of the channel as well as the optimum depth of the air gap between PV panel and glass cover that maximize two defined objective functions in different scenarios. Results showed that using fourth scenario (with the annual total useful thermal and electrical outputs as objective functions) and first scenario (with the annual average first- and second-law efficiencies as objective functions) for optimizing the proposed BIPV/T system leads to the highest amount of useful thermal and overall outputs, respectively. Moreover, it was concluded that, if the electrical output of the system is more important than the thermal output, the first scenario gives better results. © 2018 by ASME.",,"Efficiency; Genetic algorithms; Heat losses; Photovoltaic cells; Ventilation exhausts; Building integrated photovoltaic; Climatic conditions; Exergetic performance; Heat loss coefficients; Length-to-width ratio; Optimization procedures; Second law efficiencies; System configurations; Multiobjective optimization",2-s2.0-85031709648
"Ge X., Stein J.L., Ersal T.","A Frequency-Dependent Filter Design Approach for Norm- Optimal Iterative Learning Control and Its Fundamental Trade-Off between Robustness, Convergence Speed, and Steady-State Error",2018,"Journal of Dynamic Systems, Measurement and Control, Transactions of the ASME",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029759673&doi=10.1115%2f1.4037271&partnerID=40&md5=c8b1984a953ef29643477f079517313b","This paper focuses on norm-optimal iterative learning control (NO-ILC) for single-inputsingle- output (SISO) linear time invariant (LTI) systems and presents an infinite time horizon approach for a frequency-dependent design of NO-ILC weighting filters. Because NO-ILC is a model-based learning algorithm, model uncertainty can degrade its performance; hence, ensuring robust monotonic convergence (RMC) against model uncertainty is important. This robustness, however, must be balanced against convergence speed (CS) and steady-state error (SSE). The weighting filter design approaches for NOILC in the literature provide limited design freedom to adjust this trade-off. Moreover, even though qualitative guidelines to adjust the trade-off exist, a quantitative characterization of the trade-off is not yet available. To address these two gaps, a frequencydependent weighting filter design is proposed in this paper and the robustness, convergence speed, and steady-state error are analyzed in the frequency domain. An analytical expression characterizing the fundamental trade-off of NO-ILC with respect to robustness, convergence speed, and steady-state error at each frequency is presented. Compared to the state of the art, a frequency-dependent filter design gives increased freedom to adjust the trade-off between robustness, convergence speed, and steady-state error because it allows the design to meet different performance requirements at different frequencies. Simulation examples are given to confirm the analysis and demonstrate the utility of the developed filter design technique. Copyright © 2018 by ASME.",,"Bandpass filters; Design; Economic and social effects; Errors; Frequency domain analysis; Iterative methods; Learning algorithms; Linear control systems; Robustness (control systems); Speed; Uncertainty analysis; Analytical expressions; Infinite time horizon; Linear time-invariant system; Modeling-based learning; Monotonic convergence; Norm-optimal iterative learning control; Performance requirements; Quantitative characterization; Two term control systems",2-s2.0-85029759673
"Rekik R., Kallel I., Casillas J., Alimi A.M.","Assessing web sites quality: A systematic literature review by text and association rules mining",2018,"International Journal of Information Management",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031735902&doi=10.1016%2fj.ijinfomgt.2017.06.007&partnerID=40&md5=73789b1ed7be471cf18ed82d68845c8a","Nowadays society is deeply affected by web content. A web site, regardless of its category, can provide or not for users their needs. To identify its strengths and weaknesses, a process of analyzing and assessing its quality, via some criteria, is necessary. Assessing web sites is considered as a Multiple Criteria Decision Making problem (MCDM), with a massive number of criteria; a reduction phase is needed. This paper presents, firstly a Systematic Literature Review (SLR) to identify the purposes of recent researches from the assessment and determine the affected categories; secondly, it proposes a process of collecting and extracting data (criteria featuring web sites) from a list of studies. Text mining is applied for this SLR to construct a dataset. Then, a method based on Apriori algorithm is assigned and implemented to find association rules between criteria and the category of the web site, and to get a set of frequent criteria. This paper also presents a review on soft computing assessing methods. It aims to help the research community to have a scope in existing research and to derive future developments. The obtained results motivate us to further probe datasets and association rule mining. © 2017 Elsevier Ltd","Assessing web sites; Association rules mining; Multiple criteria decision making; Systematic literature review; Text mining","Association rules; Decision making; Soft computing; Websites; Apriori algorithms; Association rules mining; Multiple criteria decision making; Multiple criteria decision-making problems; Research communities; Systematic literature review; Systematic literature review (SLR); Text mining; Data mining",2-s2.0-85031735902
"Lu K., Lian Z., Gu F., Liu H.","Model-based chatter stability prediction and detection for the turning of a flexible workpiece",2018,"Mechanical Systems and Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028711127&doi=10.1016%2fj.ymssp.2017.08.022&partnerID=40&md5=f3124a86791234faba69e35aa1581d3b","Machining long slender workpieces still presents a technical challenge on the shop floor due to their low stiffness and damping. Regenerative chatter is a major hindrance in machining processes, reducing the geometric accuracies and dynamic stability of the cutting system. This study has been motivated by the fact that chatter occurrence is generally in relation to the cutting position in straight turning of slender workpieces, which has seldom been investigated comprehensively in literature. In the present paper, a predictive chatter model of turning a tailstock supported slender workpiece considering the cutting position change during machining is explored. Based on linear stability analysis and stiffness distribution at different cutting positions along the workpiece, the effect of the cutting tool movement along the length of the workpiece on chatter stability is studied. As a result, an entire stability chart for a single cutting pass is constructed. Through this stability chart the critical cutting condition and the chatter onset location along the workpiece in a turning operation can be estimated. The difference between the predicted tool locations and the experimental results was within 9% at high speed cutting. Also, on the basis of the predictive model the dynamic behavior during chatter that when chatter arises at some cutting location it will continue for a period of time until another specified location is arrived at, can be inferred. The experimental observation is in good agreement with the theoretical inference. In chatter detection respect, besides the delay strategy and overlap processing technique, a relative threshold algorithm is proposed to detect chatter by comparing the spectrum and variance of the acquired acceleration signals with the reference saved during stable cutting. The chatter monitoring method has shown reliability for various machining conditions. © 2017 Elsevier Ltd","Chatter detection; Chatter stability; Feed direction; Flexible workpieces; Turning","Cutting tools; Linear stability analysis; Location; Machining; Stability; Stiffness; Turning; Chatter stability; Feed direction; Flexible workpieces; Processing technique; Regenerative chatters; Stiffness and damping; Stiffness distributions; Threshold algorithms; Cutting",2-s2.0-85028711127
"Li Y., Sun Y., Han Q., Zhang G., Horváth I.","Enhanced beads overlapping model for wire and arc additive manufacturing of multi-layer multi-bead metallic parts",2018,"Journal of Materials Processing Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032746794&doi=10.1016%2fj.jmatprotec.2017.10.017&partnerID=40&md5=4e49b5e64de0028eeaed749542422908","Wire and arc additive manufacturing (WAAM) is a competitive technology for fabricating metallic parts with complex structure and geometry. It enables the fabrication of multi-layer multi-bead (MLMB) parts. The basis of planning the deposition paths is the beads overlapping model (BOM). The existing overlapping models consider only the geometric area of adjacent beads, but ignore the spreading of the melted weld beads. The objective of the research was to develop an enhanced BOM (E.BOM) for WAAM, which takes the spreading of the weld beads into consideration. A deposited bead spreads to the already deposited neighboring bead and as a consequence, its center point deviates from the center point of the fed (to be melted) wire. Experiments were designed to explore the relationships between the geometries of the beads, and the offset distance between the center of a weld bead and the center of the fed wire. An artificial neural network was used to predict the offset distance of a certain weld bead based on the results of the experiments. In addition, a reasoning algorithm was implemented to calculate the optimal distance between the centers of adjacent deposition paths in order to achieve a planned center distance between adjacent beads. This enables the control of the actual center distance of the adjacent beads according to an expected value. The E.BOM has been tested by validation experiments. On the one hand, it improves the surface flatness of layers of MLMB parts produced by WAAM. On the other hand, it prevents formation of defects inside the parts. © 2017 Elsevier B.V.","Additive manufacturing; Beads overlapping model; Gas metal arc welding; Multi-layer multi-bead parts; Spreading effect","Deposition; Electric welding; Gas metal arc welding; Gas welding; Geometry; Manufacture; Neural networks; Welds; Wire; Center distance; Complex structure; Expected values; Multi beads; Offset distances; Reasoning algorithms; Spreading effects; Surface flatness; 3D printers",2-s2.0-85032746794
"Ong Z.C., Seet Y.C., Khoo S.Y., Noroozi S.","Development of an economic wireless human motion analysis device for quantitative assessment of human body joint",2018,"Measurement: Journal of the International Measurement Confederation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032726509&doi=10.1016%2fj.measurement.2017.10.056&partnerID=40&md5=4014af428fd123eef823873bbad4c894","In recent years, the study of human body dynamics has been attracting a significant amount of attention. Currently there are many camera or active sensor based motion analysis systems available on the market. They have been extensively adopted and used by the film and animation or entertainment industries such as film and video game producers. More recently their potential in studying human dynamics/motion for medical purposes has been realised to the extent that they are now used to study full body human biomechanics in the form of gait analysis systems. Most orthopaedic surgeries are usually about joint repair or implants. According health line, revision surgery is usually due to infection, continued pain, joint stiffness, wear, instability, loosening. Apart from infection, the rest can be linked to the operation itself. Currently, surgical planning and placing implants is performed in a subjective manner, relying on the surgeon's experience and instinct, current systems to help the surgeon to place implant are also bulky, expensive, slow and not user friendly. The aim of this project is to develop an economic and portable motion assessment system which involves a wireless inertial measurement unit (IMU) dedicated to study and assess body joints. Through the data collected from the IMU, the system is capable real time measurement of relative position and orientation of the human joint. Several tests were conducted to validate the data extracted from gyroscope and accelerometer of the IMU. The joint motion results analysed using the device was compared with the results analysed using commercial video motion analysis software and it shows good correlation. It is found that the gyroscope of the IMU under DMP sensor fusion algorithm and calibration capability is able to give the angular velocity with less than 5% error. This has led to a more accurate orientation data which gives 7% error in average bending angle. © 2017 Elsevier Ltd","Bio-mechanics; Gait analysis; Human dynamics; Kinematics; Orthopaedic implant assessment","Animation; Biomechanics; Gait analysis; Gyroscopes; Implants (surgical); Kinematics; Motion analysis; Surgery; Units of measurement; Calibration capabilities; Human dynamics; Inertial measurement unit; Motion analysis system; Orthopaedic implants; Quantitative assessments; Real time measurements; Sensor fusion algorithms; Economic analysis",2-s2.0-85032726509
"Wang J., Wang Z., Liang C., Gao C., Sang N.","Equidistance constrained metric learning for person re-identification",2018,"Pattern Recognition",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032261863&doi=10.1016%2fj.patcog.2017.09.014&partnerID=40&md5=a1bbef149c7167b182a5e92dc46ab8c6","Person re-identification (re-id), aiming to search a specific person among a non-overlapping camera network, has attracted plenty of interest in recent years. This task is highly challenging, especially when there exists only single image per person in the database. In this paper, we present an algorithm for learning a Mahalanobis distance for person re-identification. Our method has two distinctive features: (1) to obtain the best separability of the training data, we first minimize the intra-class distances to the most extent by forcing intra-class distances to be zero, and (2) to promote the generalization ability of the learned metric, we then maximize the minimum margin between different classes. Inspired by the simple geometric intuition that a regular simplex maximizes its minimum side length, provided the sum of all side length is fixed, our method, called EquiDistance constrained Metric Learning (EquiDML), applies least-square regression technique to map images of the same person to the same vertex of a regular simplex, and images of different persons to different vertices of a regular simplex. Consequently, under the learned metric, images of the same class are collapsed to a single point, while images of different classes are transformed to be equidistant. This simple motivation is further formulated as a convex optimization problem, solved by the projected gradient descent method and proved to be very effective in person re-identification task. Although it is fairly simple, our method outperforms the state-of-the-art methods on CUHK01, CUHK03, Market1501 and DukeMTMC-reID datasets, and achieves very competitive performance on the widely used VIPeR dataset. © 2017 Elsevier Ltd","Equidistance embedding; Metric learning; Person re-identification","Convex optimization; Learning algorithms; Optimization; Competitive performance; Convex optimization problems; Equidistance embedding; Least square regression; Metric learning; Non-overlapping camera networks; Person re identifications; State-of-the-art methods; Least squares approximations",2-s2.0-85032261863
"Qin Y., Yu Z.L., Wang C.-D., Gu Z., Li Y.","A Novel clustering method based on hybrid K-nearest-neighbor graph",2018,"Pattern Recognition",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032258285&doi=10.1016%2fj.patcog.2017.09.008&partnerID=40&md5=d8e7cf4df5bcfcdcbac6abc4c57cb449","Most of the existing clustering methods have difficulty in processing complex nonlinear data sets. To remedy this deficiency, in this paper, a novel data model termed Hybrid K-Nearest-Neighbor (HKNN) graph, which combines the advantages of mutual k-nearest-neighbor graph and k-nearest-neighbor graph, is proposed to represent the nonlinear data sets. Moreover, a Clustering method based on the HKNN graph (CHKNN) is proposed. The CHKNN first generates several tight and small subclusters, then merges these subclusters by exploiting the connectivity among them. In order to select the optimal parameters for CHKNN, we further propose an internal validity index termed K-Nearest-Neighbor Index (KNNI), which can also be used to evaluate the validity of nonlinear clustering results by varying a control parameter. Experimental results on synthetic and real-world data sets, as well as that on the video clustering, have demonstrated the significant improvement on performance over existing nonlinear clustering methods and internal validity indices. © 2017 Elsevier Ltd","Graph clustering; Hybrid k-nearest-neighbor graph; Internal validity index; Nonlinear data set; Video clustering","Cluster analysis; Clustering algorithms; Data handling; Lattice constants; Nearest neighbor search; Graph clustering; K-nearest neighbor graphs; Nonlinear data set; Validity index; Video clustering; Motion compensation",2-s2.0-85032258285
"Fianu S., Davis L.B.","A Markov decision process model for equitable distribution of supplies under uncertainty",2018,"European Journal of Operational Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026307025&doi=10.1016%2fj.ejor.2017.07.017&partnerID=40&md5=6164b2fe48dba0cb4038b7c4e57e6336","Many individuals suffering from food insecurity obtain assistance from governmental programs and nonprofit agencies such as food banks. Much of the food distributed by food banks come from donations which are received from various sources in uncertain quantities at random points in time. This paper presents a model that can assist food banks in distributing these uncertain supplies equitably and measure the performance of their distribution efforts. We formulate this decision problem as a discrete-time, discrete state Markov decision process that considers stochastic supply, deterministic demand and an equity-based objective. We investigate three different allocation rules and describe the optimal policy as a function of available inventory. We also provide county level estimates of unmet need and determine the probability distribution associated with the number of underserved counties. A numerical study is performed to show how the allocation policy and unmet need are impacted by uncertain supply and deterministic, time-varying demand. We also compare different allocation rules in terms of equity and effectiveness. © 2017 Elsevier B.V.","Donations; Dynamic programming; Equity; Food insecurity; Markov decision processes","Dynamic programming; Learning algorithms; Markov processes; Stochastic systems; Allocation policies; Deterministic demand; Donations; Equity; Food insecurity; Markov decision process models; Markov Decision Processes; Time varying demand; Probability distributions",2-s2.0-85026307025
"Kumova Metin S.","Feature selection in multiword expression recognition",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029703177&doi=10.1016%2fj.eswa.2017.09.047&partnerID=40&md5=3fc000154cd44717ecbb477606723a10","In multiword expression (MWE) recognition, there exist many studies where different learning methods are employed to decide whether given word combination is a multiword expression. The recognition methods commonly utilize a number of features that are extracted from a data source, frequently from the given text. Though the recognition methods and the features are well studied, we believe that to achieve the best possible performance with a learning method, different subsets of features should also be considered and the best performing subset must be selected. In this paper, we propose a procedure that covers the performance comparison of well-known feature selection methods to obtain the best feature subset in MWE recognition. The evaluation tests are performed on a Turkish MWE data set and the performance is measured by precision, recall and F1 values. The highest F1 value =0.731 is obtained by C4.5 classifier employing either wrapper or filtering method in feature selection. In the regarding setting(s), it is examined that the performance is increased by 1.11% compared to the setting where all features are employed in classification. Based on the experimental results, it may be stated that feature selection improves the performance of MWE recognition by eliminating the noisy/non-effective features. Moreover, it is obvious that proposed feature selection method contributes to the overall MWE recognition system by reducing the measurement and storage requirements due to the lower number of features in classification, providing a faster and more-cost effective learning model. © 2017 Elsevier Ltd","Feature selection; Learning algorithms; Multiword expression; Multiword expression recognition","Character recognition; Classification (of information); Cost effectiveness; Digital storage; Learning algorithms; Learning systems; Statistical tests; Feature selection methods; Learning methods; Multi-word expressions; Performance comparison; Recognition methods; Recognition systems; Storage requirements; Word combinations; Feature extraction",2-s2.0-85029703177
"De B.P., Maji K.B., Kar R., Mandal D., Ghoshal S.P.","Design of Optimal CMOS Analog Amplifier Circuits Using a Hybrid Evolutionary Optimization Technique",2018,"Journal of Circuits, Systems and Computers",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021784084&doi=10.1142%2fS0218126618500299&partnerID=40&md5=a5fb4aa8a7fdf4ddfa6e6a3fb9c13cef","This paper proposes an efficient design technique for two commonly used VLSI circuits, namely, CMOS current mirror load-based differential amplifier circuit and CMOS two-stage operational amplifier. The hybrid evolutionary method utilized for these optimal designs is random particle swarm optimization with differential evolution (RPSODE). Random PSO utilizes the weighted particles for monitoring the search directions. DE is a robust evolutionary technique. It has demonstrated an exclusive performance for the optimization problems which are continuous and global but suffers from the uncertainty issues. PSO is a robust optimization method but suffers from sub-optimality problem. This paper effectively hybridizes the random PSO and DE to remove the limitations related to both the techniques individually. In this paper, RPSODE is employed to optimize the sizes of the MOS transistors to reduce the overall area taken by the circuit while satisfying the design constraints. The results obtained from RPSODE technique are validated in SPICE environment. SPICE-based simulation results justify that RPSODE is a much better technique than other formerly reported methods for the designs of the above mentioned circuits in terms of MOS area, gain, power dissipation, etc. © 2018 World Scientific Publishing Company.","DE; Differential amplifier; Op-amp; Optimization; PSO; RPSODE; Transistor sizing","Amplifiers (electronic); Circuit simulation; CMOS integrated circuits; Design; Differential amplifiers; Evolutionary algorithms; Integrated circuit design; Operational amplifiers; Optimization; Particle swarm optimization (PSO); Timing circuits; Differential Evolution; Evolutionary techniques; Hybrid evolutionary method; Hybrid evolutionary optimizations; Robust optimization method; RPSODE; Transistor sizing; Two-stage operational amplifiers; SPICE",2-s2.0-85021784084
"Zhi R., Cao L., Cao G.","Translation and scale invariants of Krawtchouk moments",2018,"Information Processing Letters",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031506934&doi=10.1016%2fj.ipl.2017.09.010&partnerID=40&md5=f693873049eedc598c908808a2e65941","Krawtchouk moments are discrete orthogonal moments which are effective for image representation. The translation and scale invariants of Krawtchouk moments are achieved either by normalizing the image or by using a combination of the corresponding invariants of geometric moments. However, the derivation of these functions is not based on Krawtchouk polynomials. In this paper, we propose a new method to derive the translation and scale invariants of Krawtchouk moments directly from the Krawtchouk polynomials. The performance of the proposed method is verified using binary characters. Experimental results show that the values of the Krawtchouk moments are invariant under image translation and scale. Furthermore, the speed of the proposed method is faster than conventional methods. © 2017","Algorithms; Image normalization; Krawtchouk moments; Scale invariants; Translation invariants","Algorithms; Computer applications; Conventional methods; Discrete orthogonal moments; Image normalization; Image representations; Krawtchouk moment; Krawtchouk polynomials; Scale invariant; Translation invariants; Data processing",2-s2.0-85031506934
"Jiao X., Wu T., Qin X.","Mesh segmentation by combining mesh saliency with spectral clustering",2018,"Journal of Computational and Applied Mathematics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023739867&doi=10.1016%2fj.cam.2017.05.007&partnerID=40&md5=06a6db3a099a713c8f2c76b64cf91cce","In this paper, we present a new mesh segmentation method that achieves visually meaningful segmentation by combining mesh saliency with spectral clustering. Our method solves the segmentation problem by embedding the original mesh model into spectral space. Firstly, the mesh concave regions are determined according to the minimum rule in visual theory, and then a Laplacian matrix is defined by considering the mesh saliency and curvature information. Next, we calculate the first k eigenvectors of the Laplacian matrix by eigen-decomposition process, and embed the original mesh into a k-dimensional spectral space. Finally, we can achieve the visually meaningful segmentation by utilizing the Gaussian Mixture method, and the initial cluster centers are decided by mesh saliency. The experimental results have demonstrated the effectiveness of the proposed segmentation method. Especially for the model with convex regions and branch components, our method can achieve better visual quality. © 2017 Elsevier B.V.","Clustering; Mesh saliency; Mesh segmentation; Spectral embedding","Clustering algorithms; Image segmentation; Laplace transforms; Matrix algebra; Clustering; Curvature information; Gaussian mixture methods; Initial cluster centers; Mesh saliencies; Mesh segmentation; Segmentation methods; Spectral embedding; Mesh generation",2-s2.0-85023739867
"Nogueira B., Pinheiro R.G.S.","A CPU-GPU local search heuristic for the maximum weight clique problem on massive graphs",2018,"Computers and Operations Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030459722&doi=10.1016%2fj.cor.2017.09.023&partnerID=40&md5=b7da85caa9df786af404c1023aecd74c","Given an undirected graph with positive weights on the vertices, the Maximum Weight Clique Problem (MWCP) consists in finding a clique with maximum total weight. In this paper, we present a CPU-GPU local search heuristic for solving the MWCP on massive graphs. The heuristic is based on two new neighborhood structures for the problem. These neighborhoods are explored using an efficient procedure that is suitable to be mapped onto a GPU-based massively parallel architecture. We test the proposed heuristic on real-world massive graphs with millions of edges and vertices. The results indicate that, even when the heuristic is executed on a CPU-only architecture, it is able to outperform the best-known heuristics for the MWCP. Moreover, the hybrid CPU-GPU implementation obtained an average speedup of up to 12 times over the CPU-only implementation. © 2017 Elsevier Ltd","Clique; Combinatorial optimization; GPU; Local search; Maximum weight clique; Metaheuristics","Combinatorial optimization; Graph theory; Graphics processing unit; Heuristic algorithms; Parallel architectures; Clique; GPU implementation; Local search; Local search heuristics; Maximum weight clique problems; Maximum weight cliques; Meta heuristics; Neighborhood structure; Local search (optimization)",2-s2.0-85030459722
"Wang L., Zhu J., Sheng M., Cribb A., Zhu S., Pu J.","Simultaneous segmentation and bias field estimation using local fitted images",2018,"Pattern Recognition",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032305081&doi=10.1016%2fj.patcog.2017.08.031&partnerID=40&md5=a07e8998e624dc5a7cc2f4f8e4446981","Level set methods often suffer from boundary leakage and inadequate segmentation when used to segment images with inhomogeneous intensities. To handle this issue, a novel region-based level set method was developed, in which two different local fitted images are used to construct a hybrid region intensity fitting energy functional. This novel method enables simultaneous segmentation of the regions of interest and estimation of the bias fields from inhomogeneous images. Our experiments on both synthetic images and a publicly available dataset demonstrate the feasibility and reliability of the proposed method. © 2017 Elsevier Ltd","Bias field; Image segmentation; Intensity inhomogeneity; Level set; Local fitted images","Drop breakup; Evolutionary algorithms; Hydrogels; Level measurement; Numerical methods; Bias field; Energy functionals; Inhomogeneous images; Intensity inhomogeneity; Level Set; Level Set method; Local fitted images; Regions of interest; Image segmentation",2-s2.0-85032305081
"Lemire D., Kurz N., Rupp C.","STREAM VBYTE: Faster byte-oriented integer compression",2018,"Information Processing Letters",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030464357&doi=10.1016%2fj.ipl.2017.09.011&partnerID=40&md5=c244b84781542a1bde5648e1342722f5","Arrays of integers are often compressed in search engines. Though there are many ways to compress integers, we are interested in the popular byte-oriented integer compression techniques (e.g., VByte or Google's VARINT-GB). Although not known for their speed, they are appealing due to their simplicity and engineering convenience. Amazon's VARINT-G8IU is one of the fastest byte-oriented compression technique published so far. It makes judicious use of the powerful single-instruction-multiple-data (SIMD) instructions available in commodity processors. To surpass VARINT-G8IU, we present STREAM VBYTE, a novel byte-oriented compression technique that separates the control stream from the encoded data. Like VARINT-G8IU, STREAM VBYTE is well suited for SIMD instructions. We show that STREAM VBYTE decoding can be up to twice as fast as VARINT-G8IU decoding over real data sets. In this sense, STREAM VBYTE establishes new speed records for byte-oriented integer compression, at times exceeding the speed of the memcpy function. On a 3.4 GHz Haswell processor, it decodes more than 4 billion differentially-coded integers per second from RAM to L1 cache. © 2017 Elsevier B.V.","Algorithms; Data compression; Indexing; SIMD instructions; Vectorization","Algorithms; Data compression; Indexing (of information); Search engines; Commodity processors; Compression techniques; L1 caches; Real data sets; SIMD instructions; Single instruction multiple data instructions; Vectorization; Decoding",2-s2.0-85030464357
"Le Thi H.A., Ta A.S., Pham Dinh T.","An efficient DCA based algorithm for power control in large scale wireless networks",2018,"Applied Mathematics and Computation",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029635713&doi=10.1016%2fj.amc.2017.08.061&partnerID=40&md5=1ef79f0f0cc515cebed819988354e388","In recent years, power control and resource allocation techniques for cellular communication systems are very active research areas. Power control is typically used in wireless cellular networks in order to optimize the transmission subject to quality of service (QoS) constraints. One of the most popular power control problems is based on maximizing the weighted sum of data rates under the peak power constraints for all users. It is a difficult nonconvex optimization problem for which standard approach Geometric Programming is not applicable in large scale setting. In this paper, we propose an efficient method based on DC (Difference of Convex functions) programming and DCA (DC Algorithm), an innovative approach in nonconvex programming framework for solving this problem. The purpose is to develop fast and scalable algorithms able to handle large scale systems. The two main challenges in DC programming and DCA that are the effect of DC decomposition and the efficiency of solution methods to convex subproblems are carefully studied. The computational results on several datasets show the robustness as well as the efficiency of the proposed method in terms of both quality and rapidity, and their superiority compared with the standard approach Geometric Programming. © 2017","DC programming; DCA; Power control; Quality of service (QoS); Wireless communications","Efficiency; Functions; Large scale systems; Mathematical programming; Mobile telecommunication systems; Optimization; Problem solving; Quality control; Quality of service; Wireless networks; Wireless telecommunication systems; D-C programming; DC programming and DCA; Non-convex programming; Nonconvex optimization problem; Quality of Service constraints; Resource allocation techniques; Wireless cellular networks; Wireless communications; Power control",2-s2.0-85029635713
"Wei L.-Y., Qi H., Ren Y.-T., Sun J.-P., Wen S., Ruan L.-M.","Application of hybrid SPSO-SQP algorithm for simultaneous estimation of space-dependent absorption coefficient and scattering coefficient fields in participating media",2018,"International Journal of Thermal Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032828470&doi=10.1016%2fj.ijthermalsci.2017.10.031&partnerID=40&md5=2d85010314bee23a0480fd5078e4d0c2","A hybrid stochastic particle swarm optimization (SPSO) and sequential quadratic programming (SQP) algorithm is proposed to estimate the space-dependent absorption coefficient (κa) and scattering coefficient (κs) fields simultaneously. The retrieval results of SQP algorithm are highly affected by the initial guess, and thus, SPSO is adopted to obtain the initial value of SQP because of its global search capability and lesser dependence on initial guess. The regularization term based on the generalized Gaussian Markov random field model is employed to overcome the ill-posed characteristic of the inverse problem. The inverse coupled radiation-conduction problem is solved in a one-dimensional participating medium with uniform refractive and graded refractive indices exposed to a pulse laser, respectively. All the results show that the separate space-dependent κa and κs fields can be estimated simultaneously and accurately from the coupled optical and thermal signals. © 2017 Elsevier Masson SAS","Absorption coefficient; Coupled radiation-conduction problem; Scattering coefficient; Sequential quadratic programming; Stochastic particle swarm optimization","Image segmentation; Markov processes; Optimization; Particle swarm optimization (PSO); Quadratic programming; Refractive index; Stochastic systems; Absorption co-efficient; Radiation conduction; Scattering co-efficient; Sequential quadratic programming; Stochastic particle swarm optimizations; Inverse problems",2-s2.0-85032828470
"Bayada G.","A fast algorithm for boundary slippage including mass flow conserving cavitation model",2018,"Tribology International",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030170288&doi=10.1016%2fj.triboint.2017.09.008&partnerID=40&md5=294d422286681cfc0b52fa8225df966e","This study investigates a new fast algorithm to solve the tangential velocity slip problem for infinitely long device (1-dimensional Reynolds equation). Solution of the Reynolds equation is obtained by solving a sequence of ordinary differential equation. This approach is used for different models of slippage including shear limited model and two-component slip model. It can be applied also for possible slippage on both upper and lower surfaces of the contact. Cavitation can also be included using a mass flow conserving model. The algorithm has been tested on numerous examples from the literature. Compared to usual methods which solve partial differential equations, this method of solving differential equations is very fast and makes it possible to test various sliding conditions. © 2017 Elsevier Ltd","Cavitation; Friction; Hydrodynamic lubrication; Sliding",,2-s2.0-85030170288
"Choudhary R., Ahuja K.","Stability analysis of Bilinear Iterative Rational Krylov Algorithm",2018,"Linear Algebra and Its Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031731918&doi=10.1016%2fj.laa.2017.10.006&partnerID=40&md5=8c64025c5f54363c26ae9798c51802e4","Models coming from different physical applications are very large in size. Simulation with such systems is expensive so one usually obtains a reduced model (by model reduction) that replicates the input-output behavior of the original full model. A recently proposed algorithm for model reduction of bilinear dynamical systems, Bilinear Iterative Rational Krylov Algorithm (BIRKA), does so in a locally optimal way. This algorithm requires solving very large linear systems of equations. Usually these systems are solved by direct methods (e.g., LU), which are very expensive. A better choice is iterative methods (e.g., Krylov). However, iterative methods introduce errors in linear solves because they are not exact. They solve the given linear system up to a certain tolerance. We prove that under some mild assumptions BIRKA is stable with respect to the error introduced by the inexact linear solves. We also analyze the accuracy of the reduced system obtained from using these inexact solves and support all our results by numerical experiments. © 2017 Elsevier Inc.","Backward stability; Bilinear dynamical systems; Iterative solves; Krylov subspace methods; Model reduction; Petrov–Galerkin","Dynamical systems; Linear systems; Backward stabilities; Input-output behavior; Iterative solves; Krylov subspace method; Linear systems of equations; Model reduction; Numerical experiments; Physical application; Iterative methods",2-s2.0-85031731918
"Jin X., Vora A., Hoshing V., Saha T., Shaver G., Wasynczuk O., Varigonda S.","Applicability of available Li-ion battery degradation models for system and control algorithm design",2018,"Control Engineering Practice",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032840006&doi=10.1016%2fj.conengprac.2017.10.002&partnerID=40&md5=7995b1fdaa63384d70c57b1ccbc08251","Within electrified vehicle powertrains, lithium-ion battery performance degrades with aging and usage, resulting in a loss in both energy and power capacity. As a result, models used for system design and control algorithm development would ideally capture the impact of those efforts on battery capacity degradation, be computationally efficient, and simple enough to be used for algorithm development. This paper provides an assessment of the state-of-the-art in lithium-ion battery degradation models, including accuracy, computational complexity, and amenability to control algorithm development. Various aging and degradation models have been studied in the literature, including physics-based electrochemical models, semi-empirical models, and empirical models. Some of these models have been validated with experimental data; however, comparisons of pre-existing degradation models across multiple experimental data sets have not been previously published. Three representative models, a 1-d electrochemical model (a combination of performance model and degradation model), a semi-empirical degradation model (the performance is predicted by an equivalent circuit model) and an empirical degradation model (the performance is predicted by an equivalent circuit model), are compared against four published experimental data sets for a 2.3-Ah commercial graphite/LiFePO4 cell. Based on simulation results and comparisons to experimental data, the key differences in the aging factors captured by each of the models are summarized. The results show that the physics-based model is best able to capture results across all four representative data sets with an error less than 10%, but is 20x slower than the empirical model, and 134x slower than the semi-empirical model, making it unsuitable for powertrain system design and model-based algorithm development. Despite being computationally efficient, the semi-empirical and empirical models, when used under conditions that lie outside the calibration data set, exhibit up to 71% error in capacity loss prediction. Such models require expensive experimental data collection to recalibrate for every new application. Thus, in the author's opinion, there exists a need for a physically-based model that generalizes well across operating conditions, is computationally efficient for model-based design, and simple enough for control algorithm development. © 2017 Elsevier Ltd","Battery degradation models; Commercial A123 2.3 Ah graphite/LiFePO4 cell; Control design; Electrochemical model; Empirical model; Semi-empirical model; System design","Circuit simulation; Circuit theory; Computational efficiency; Dielectric properties; Electric batteries; Equivalent circuits; Graphite; Ions; Lithium; Powertrains; Secondary batteries; Systems analysis; Battery degradation; Control design; Electrochemical modeling; Empirical model; Semi-empirical modeling; Lithium-ion batteries",2-s2.0-85032840006
"Yin H., Cai H., Yang E., Zhou Y., Wu J.","An efficient all-zero block detection algorithm for high efficiency video coding with RDOQ",2018,"Signal Processing: Image Communication",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030858615&doi=10.1016%2fj.image.2017.09.004&partnerID=40&md5=d3f7af4272034c43e3393db95a08fc60","Rate distortion optimized HEVC video coding is challenged by the extremely high complexity caused by hierarchical prediction structure and advanced coding tools. All-zero-block (AZB) detection is an efficient tool to decrease the complexity of mode decision in HEVC coders in the sense of rate distortion optimization (RDO). Traditional AZB detection schemes were usually designed by employing hard-decision quantization (HDQ), and the AZB detection thresholds were generally derived according to the individual block's characteristic parameter such as SAD or SATD. However, soft-decision quantization (SDQ) is preferably employed in HEVC encoders for coding performance improvement, and the AZB detection thresholds are supposed to be determined according to the ensemble's statistical characteristics in the sense of statistical inference. This paper proposes an adaptive AZB detection algorithm well-suited for SDQ, more specifically RD optimized quantization (RDOQ). Inspired by Bayesian inference, a more accurate coefficient-level zero-quantized threshold model in the RDO sense is proposed by fully simulating RDOQ to aid in the following AZB detection. In addition, a local parameter depicting the individual block's characteristics regarding the inter-coefficient distribution is jointly combined with SATD to derive an adaptive threshold model for AZB detection. The experimental results demonstrate that the proposed algorithm detects 91.9% 4×4 AZB with smaller than 1.9% FAR and 8.1% FRR false alarm rate on average, at the cost of negligible rate-distortion performance loss. This work is well-suited for fast RD optimized HEVC coding. © 2017","All zero block detection; HEVC; Rate distortion optimized quantization; Video coding","Bayesian networks; Codes (symbols); Electric distortion; Image coding; Inference engines; Optimization; Signal detection; Signal distortion; All-zero block detection; HEVC; Hierarchical prediction structures; High-efficiency video coding; Rate distortion performance; Rate distortions; Rate-distortion optimization; Statistical characteristics; Video signal processing",2-s2.0-85030858615
"Liu T., Li J., Cai X., Yan S.","A time-frequency analysis algorithm for ultrasonic waves generating from a debonding defect by using empirical wavelet transform",2018,"Applied Acoustics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031500704&doi=10.1016%2fj.apacoust.2017.10.002&partnerID=40&md5=66c8c7337108b63881036141b4079c94","Time-frequency distributions (TFDs) are key indicators for inspecting debonding defects using ultrasonic nondestructive testing (NDT) or nondestructive examination (NDE). A novel algorithm combining empirical wavelet transform (EWT), Hilbert transform (HT) and short time Fourier transform (STFT) is presented to obtain the TFD of ultrasonic testing waves. First, we decompose the signal into mono-components by means of EWT to satisfy the mono-component requirement of HT. Next, correlation coefficients between the empirical modes and the decomposed signal are computed to extract valuable components. Further, the instantaneous amplitude (IA) of the extracted valuable components are calculated using HT. Finally, using the computed IAs, the peak time representing the arrival time of the component is obtained. To calculate the corresponding frequency, a method based on STFT is applied on the valuable components. The principle of the proposed method is illustrated by a numerical signal. The effectiveness of the proposed method in extracting the TFD of ultrasonic testing wave is validated by an experimental analysis of the ultrasonic NDT used for the detection of debonding defect in a composite construction. In comparison with STFT, smoothed pseudo Wigner-Ville distribution (SPWVD), and empirical mode decomposition (EMD), a higher accuracy of the TFD can be obtained using the proposed algorithm. © 2017 Elsevier Ltd","Composite constructions; Debonding defects; Empirical wavelet transform; Hilbert transform; Time-frequency distribution; Ultrasonic nondestructive testing","Composite materials; Concrete slabs; Debonding; Defects; Mathematical transformations; Nondestructive examination; Numerical methods; Robustness (control systems); Signal processing; Ultrasonic applications; Wavelet transforms; Wigner-Ville distribution; Composite construction; Empirical Mode Decomposition; Hilbert transform; Short time Fourier transforms; Smoothed pseudo Wigner Ville distribution; Time frequency analysis; Time-frequency distributions; Ultrasonic non-destructive testing; Ultrasonic testing",2-s2.0-85031500704
"Bashir S.B., Beig A.R.","An improved voltage balancing algorithm for grid connected MMC for medium voltage energy conversion",2018,"International Journal of Electrical Power and Energy Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029477951&doi=10.1016%2fj.ijepes.2017.09.002&partnerID=40&md5=f18468b2ec6f4d769be5d3d25c9c7678","Modular multi-level converter (MMC) is one of the promising topologies for medium voltage, high power energy conversion applications. The balancing of the capacitor voltage of the MMC Submodules (SMs) plays a critical role for proper operation of MMC. This paper proposes an improved balancing approach based on space vector PWM (SVPWM). The proposed method uses only one SVPWM, which not only simplifies the calculation but also reduces the circulating current in the MMC, thereby reducing the inductor size and improving the converter efficiency. The above balancing algorithm is applied to a MMC-based DC to AC converter connected to the strong AC grid as well as weak AC grid. The power injection capacity and instability problem when MMC is connected to weak AC grid is addressed. The closed loop operation and satisfactory energy conversion in the MMC-based grid connected DC to AC is verified through simulation and the results are presented. © 2017 Elsevier Ltd","AC grid; DC to AC converter; Energy conversion; Modular multi-level converters; Pulse width modulation; PWM converter; Short circuit ratio; Space vector pulse width modulation; Voltage balancing","Energy conversion; Modulation; Power converters; Pulse width modulation; Vector spaces; Voltage control; AC converter; AC-grid; Modular multi-level converters; PWM converter; Short circuit ratio; Space vector pulse width modulation; Voltage balancing; Electric inverters",2-s2.0-85029477951
"Cococcioni M., Pappalardo M., Sergeyev Y.D.","Lexicographic multi-objective linear programming using grossone methodology: Theory and algorithm",2018,"Applied Mathematics and Computation",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020121970&doi=10.1016%2fj.amc.2017.05.058&partnerID=40&md5=9dd2f9bb13f902208d3c2d5854443b7e","Numerous problems arising in engineering applications can have several objectives to be satisfied. An important class of problems of this kind is lexicographic multi-objective problems where the first objective is incomparably more important than the second one which, in its turn, is incomparably more important than the third one, etc. In this paper, Lexicographic Multi-Objective Linear Programming (LMOLP) problems are considered. To tackle them, traditional approaches either require solution of a series of linear programming problems or apply a scalarization of weighted multiple objectives into a single-objective function. The latter approach requires finding a set of weights that guarantees the equivalence of the original problem and the single-objective one and the search of correct weights can be very time consuming. In this work a new approach for solving LMOLP problems using a recently introduced computational methodology allowing one to work numerically with infinities and infinitesimals is proposed. It is shown that a smart application of infinitesimal weights allows one to construct a single-objective problem avoiding the necessity to determine finite weights. The equivalence between the original multi-objective problem and the new single-objective one is proved. A simplex-based algorithm working with finite and infinitesimal numbers is proposed, implemented, and discussed. Results of some numerical experiments are provided. © 2017 Elsevier Inc.","Grossone infinity computing; Lexicographic problems; Multi-objective optimization; Numerical infinitesimals","Computation theory; Linear programming; Multiobjective optimization; Optimization; Computational methodology; Engineering applications; Grossone infinity computing; Lexicographic problems; Linear programming problem; Multi-objective linear programming; Multi-objective problem; Numerical infinitesimals; Problem solving",2-s2.0-85020121970
"Zheng H., Zhang Y., Liu J., Wei H., Zhao J., Liao R.","A novel model based on wavelet LS-SVM integrated improved PSO algorithm for forecasting of dissolved gas contents in power transformers",2018,"Electric Power Systems Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032296746&doi=10.1016%2fj.epsr.2017.10.010&partnerID=40&md5=6115f67f2b8c6b41e92ccf19cfb54a80","Finding out the transformer incipient faults and their development trend has always been a central issue for electric power companies. In this paper, a novel approach combing wavelet technique with least squares support vector machine (LS-SVM) for forecasting of dissolved gases in oil-immersed power transformers has been proposed. The algorithm of particle swarm optimization (PSO) with mutation is developed to optimize the parameters of constructed wavelet LS-SVM regression (W-LSSVR). The existence of admissible wavelet kernels is proven by theoretic analysis. Evaluation of forecasting performance is based upon the measures of mean absolute percentage error (MAPE) and squared correlation coefficient (r2). On the basis of the proposed approach, a procedure is put forward to serve as an effective tool and experimental results show that this approach is capable of forecasting the dissolved gas contents accurately. Comparing with the back propagation neural network (BPNN), the radial basis function neural network (RBFNN), the generalized regression neural network (GRNN), and the SVM regression (SVR) in two practical cases (taken hydrogen as an example here), the MAPEs of the proposed approach are significantly better than that of the four methods (5.4238% vs 19.1458%, 11.7361%, 7.7395%, 8.3248%; 2.1567% vs 18.9453%, 10.2451%, 7.8636%, 2.4628%) respectively. © 2017 Elsevier B.V.","Dissolved gases; Forecasting; Least squares support vector machine; Oil-immersed power transformers; Particle swarm optimization; Wavelet technique","Backpropagation; Dissolution; Electric utilities; Forecasting; Neural networks; Oil filled transformers; Optimization; Power transformers; Radial basis function networks; Regression analysis; Support vector machines; Two phase flow; Back-propagation neural networks; Dissolved gas; Generalized Regression Neural Network(GRNN); Least squares support vector machines; Oil immersed power transformer; Radial basis function neural networks; Squared correlation coefficients; Wavelet techniques; Particle swarm optimization (PSO)",2-s2.0-85032296746
"Demšar J., Bosnić Z.","Detecting concept drift in data streams using model explanation",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030859587&doi=10.1016%2fj.eswa.2017.10.003&partnerID=40&md5=c39740f79f7c2432a84f58ffb58aa786","Learning from data streams (incremental learning) is increasingly attracting research focus due to many real-world streaming problems and due to many open challenges, among which is the detection of concept drift – a phenomenon when the data distribution changes and makes the current prediction model inaccurate or obsolete. Current state-of-the art detection methods can be roughly split into performance monitoring algorithms and distribution comparing algorithms. In this work we propose a novel concept drift detector that can be combined with an arbitrary classification algorithm. The proposed concept drift detector is based on computing multiple model explanations over time and observing the magnitudes of their changes. The model explanation is computed using a methodology that yields attribute-value contributions for prediction outcomes and thus provides insight into the model's decision-making process and enables its transparency. The evaluation has revealed that the methods surpass the baseline methods in terms of concept drift detection, accuracy, robustness and sensitivity. To even further augment interpretability, we visualized the detection of concept drift, enabling macro and micro views of the data. © 2017 Elsevier Ltd","Concept drift; Data stream; Explanation; Visualization","Data visualization; Decision making; Flow visualization; Classification algorithm; Comparing algorithm; Concept drifts; Data stream; Decision making process; Explanation; Incremental learning; Performance monitoring; Data mining",2-s2.0-85030859587
"Ying K.-C., Lin S.-W.","Minimizing makespan for the distributed hybrid flowshop scheduling problem with multiprocessor tasks",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029782486&doi=10.1016%2fj.eswa.2017.09.032&partnerID=40&md5=187fa9be19871b6ce4d4067e5cf95173","The trend of globalization has recently seen the study of distributed scheduling problems. This study attempts to solve the distributed hybrid flowshop scheduling problem with multiprocessor tasks, and is the first attempt to address this problem. To solve this strongly NP-hard problem, a mixed integer linear programming formulation and self-tuning iterated greedy (SIG) algorithm that incorporates an adaptive cocktail decoding mechanism are presented to minimize the makespan. Comprehensive computational results demonstrate that the proposed SIG algorithm is extremely efficient and effective. This paper successfully expands the research area of distributed scheduling problems. © 2017 Elsevier Ltd","Adaptive cocktail decoding mechanism; Distributed hybrid flowshop; Scheduling; Self-tuning iterated greedy algorithm","Computational complexity; Computational efficiency; Decoding; Distributed computer systems; Integer programming; Multiprocessing systems; Real time systems; Scheduling; Computational results; Distributed scheduling problem; Hybrid flow shop; Hybrid flow shop scheduling; Iterated greedy algorithm; Minimizing makespan; Mixed integer linear programming; Multiprocessor tasks; Problem solving",2-s2.0-85029782486
"Yan Y., Liu X., Wang F., Li X., Ou J., Wen Y., Liang X.","Assessing the impacts of urban sprawl on net primary productivity using fusion of Landsat and MODIS data",2018,"Science of the Total Environment",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030986782&doi=10.1016%2fj.scitotenv.2017.09.139&partnerID=40&md5=4b69f959c0a6278a054559fcda01e1d6","Urbanization has profoundly altered the terrestrial ecosystem carbon cycle, especially the net primary productivity (NPP). Many attempts have been made to assess the influence of urbanization on NPP at coarse resolutions (e.g., 250 m or larger), which may ignore many smaller and highly fragmented urban lands, and to a large extent, underestimate the NPP variations induced by urban sprawl. Hence, we attempted to analyze the NPP variations influenced by urban sprawl at a fine resolution (e.g., 30 m), toward which the accuracy of NPP was improved using remotely sensed data fusion algorithm. In this paper, this assumption was tested in the Pearl River Delta of China. The land cover datasets from the Landsat Thematic Mapper (TM)/Enhanced Thematic Mapper Plus (ETM +) were acquired to quantify the urban sprawl. The synthetic Normal Differential Vegetation Index (NDVI) data was obtained by fusing Landsat and Moderate Resolution Imaging Spectroradiometer (MODIS) NDVI via spatiotemporal fusion algorithm. The Carnegie-Ames-Stanford Approach (CASA) model was driven by land cover map, synthetic NDVI and meteorological data to estimate the 30-m resolution NPP. Then, we analyzed the influence of urban sprawl on 30-m resolution NPP during the period of 2001–2009. Additionally, we also simulated the spatiotemporal change of future urban sprawl under different scenarios using the Future Land Use Simulation (FLUS) model, and further analyzed its influence on 30-m resolution NPP. Our results showed that the accuracy of 30-m resolution NPP from synthetic NDVI is better than 500-m resolution NPP from MODIS NDVI. The loss in 30-m resolution NPP due to urban sprawl was much higher than 500-m resolution NPP. Moreover, the harmonious development scenario, characterized by a reasonable size of urban sprawl and a corresponding lower NPP loss from 2009 to 2050, would be considered as a more human-oriented and sustainable development strategy. © 2017 Elsevier B.V.","CASA model; FLUS model; NPP; Spatiotemporal fusion algorithm; Urban sprawl","Carbon; Coastal zones; Data fusion; Ecosystems; Land use; Meteorology; Photosynthesis; Phytoplankton; Planning; Radiometers; Satellite imagery; Carnegie-ames-stanford approach (CASA); Casa models; Landsat Thematic Mapper; Moderate resolution imaging spectroradiometer; Net primary productivity; Spatio-temporal changes; Spatio-temporal fusions; Urban sprawl; Urban growth; accuracy assessment; algorithm; carbon cycle; future prospect; Landsat thematic mapper; MODIS; NDVI; net primary production; satellite data; spatiotemporal analysis; sustainable development; terrestrial ecosystem; urban sprawl; urbanization; algorithm; Article; China; environmental change; environmental impact assessment; environmental parameters; human impact (environment); measurement accuracy; net primary productivity; priority journal; quantitative analysis; satellite imagery; seasonal variation; simulation; spatiotemporal analysis; sustainable development; thematic analysis; urban area; urbanization; vegetation; China; Guangdong; Zhujiang Delta",2-s2.0-85030986782
"Chang K., Lee J., Jun C.-H., Chung H.","Interleaved incremental association Markov blanket as a potential feature selection method for improving accuracy in near-infrared spectroscopic analysis",2018,"Talanta",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030097025&doi=10.1016%2fj.talanta.2017.09.039&partnerID=40&md5=23f86d54557c183025d43c0c25724ba1","The interleaved Incremental Association Markov Blanket (inter-IAMB) is described herein as a feature selection method for the NIR spectroscopic analysis of several samples (diesel, gasoline, and etchant solutions). Although the Markov blanket (MB) has been proven to be the minimal optimal set of features (variables) that does not change the original target distribution, variables selected by the existing IAMB algorithm could be redundant and/or misleading as the IAMB requires an unnecessarily large amount of learning data to identify the MB. Use of the inter-IAMB interleaving the grow phase with the shrink phase to maintain the size of the MB as small as possible by immediately eliminating invalid candidates could overcome this drawback. In this report, a likelihood-ratio (LR)-based conditional independence test, able to handle spectroscopic data normally comprising a large number of continuous variables in a small number of samples, was uniquely embedded in the inter-IAMB and its utility was evaluated. The variables selected by the inter-IAMB in complexly overlapped and feature-indistinct NIR spectra were used to determine the corresponding sample properties. For comparison, the properties were also determined using the IAMB-selected variables as well as the whole variables. The inter-IAMB was more effective in the selection of variables than the IAMB and thus able to improve the accuracy in the determination of the sample properties, even though a smaller number of variables was used. The proposed LR-embedded inter-IAMB could be a potential feature selection method for vibrational spectroscopic analysis, especially when the obtained spectral features are specificity-deficient and extensively overlapped. © 2017 Elsevier B.V.","Conditional independence test; Diesel, Gasoline; Etchant solution; Likelihood-ratio test; Markov blanket discovery algorithm","Feature extraction; Gasoline; Infrared devices; Conditional independence tests; Continuous variables; Discovery algorithm; Etchant solution; Feature selection methods; Likelihood ratio tests; Selection of variables; Vibrational spectroscopic analysis; Spectroscopic analysis",2-s2.0-85030097025
"Burghignoli P., Lovat G., Araneo R., Celozzi S.","Time-Domain Shielding of a Thin Conductive Sheet in the Presence of Pulsed Vertical Dipoles",2018,"IEEE Transactions on Electromagnetic Compatibility",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020742028&doi=10.1109%2fTEMC.2017.2702560&partnerID=40&md5=38a5a3b78ba3b30fc92c65dbfb79d6ec","The classical problem represented by a planar thin conductive shield in the presence of vertical dipole field sources (electric or magnetic) is solved analytically in the time domain via the Cagniard-de Hoop technique. Comparisons with numerical solutions carried out by means of efficient integration algorithms are provided and discussed. © 2017 IEEE.","Electromagnetic (EM) shielding; near field; time domain (TD); vertical dipoles","Condensed matter physics; Electromagnetic compatibility; Classical problems; Conductive sheet; Integration algorithm; Numerical solution; Time domain; Vertical dipole; Time domain analysis",2-s2.0-85020742028
"Sun L., Kudo M.","Optimization of classifier chains via conditional likelihood maximization",2018,"Pattern Recognition",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032297443&doi=10.1016%2fj.patcog.2017.09.034&partnerID=40&md5=ca59972f993cc04e5c22132cb7cba040","Multi-label classification associates an unseen instance with multiple relevant labels. In recent years, a variety of methods have been proposed to handle the multi-label problems. Classifier chains is one of the most popular multi-label methods because of its efficiency and simplicity. In this paper, we consider to optimize classifier chains from the viewpoint of conditional likelihood maximization. In the proposed unified framework, classifier chains can be optimized in either or both of two aspects: label correlation modeling and multi-label feature selection. In this paper we show that previous classifier chains algorithms are specified in the unified framework. In addition, previous information theoretic multi-label feature selection algorithms are specified with different assumptions on the feature and label spaces. Based on these analyses, we propose a novel multi-label method, k-dependence classifier chains with label-specific features, and demonstrate the effectiveness of the method. © 2017 Elsevier Ltd","Classifier chains; Conditional likelihood maximization; k-dependence Bayesian network; Multi-label classification; Multi-label feature selection","Bayesian networks; Chains; Feature extraction; Information theory; Optimization; Classifier chains; Conditional likelihood; Feature selection algorithm; Label correlations; Multi label classification; Multi-label; Multi-label problems; Unified framework; Classification (of information)",2-s2.0-85032297443
"Grishagin V., Israfilov R., Sergeyev Y.","Convergence conditions and numerical comparison of global optimization methods based on dimensionality reduction schemes",2018,"Applied Mathematics and Computation",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025428828&doi=10.1016%2fj.amc.2017.06.036&partnerID=40&md5=b6e33c1a01a547522b0ae4c1ead22cbe","This paper is devoted to numerical global optimization algorithms applying several ideas to reduce the problem dimension. Two approaches to the dimensionality reduction are considered. The first one is based on the nested optimization scheme that reduces the multidimensional problem to a family of one-dimensional subproblems connected in a recursive way. The second approach as a reduction scheme uses Peano-type space-filling curves mapping multidimensional domains onto one-dimensional intervals. In the frameworks of both the approaches, several univariate algorithms belonging to the characteristical class of optimization techniques are used for carrying out the one-dimensional optimization. Theoretical part of the paper contains a substantiation of global convergence for the considered methods. The efficiency of the compared global search methods is evaluated experimentally on the well-known GKLS test class generator used broadly for testing global optimization algorithms. Results for representative problem sets of different dimensions demonstrate a convincing advantage of the adaptive nested optimization scheme with respect to other tested methods. © 2017 Elsevier Inc.","Comparison of efficiency; Convergence; Dimensionality reduction; Global optimization; Multiextremal functions; Numerical methods","Convergence of numerical methods; Efficiency; Global optimization; Numerical methods; 65K05; 90C26; Convergence; Dimensionality reduction; Global optimization algorithm; Global optimization method; Multidimensional problems; Optimization techniques; Optimization",2-s2.0-85025428828
"Kamal M., Rahman M.M.","Advances in fatigue life modeling: A review",2018,"Renewable and Sustainable Energy Reviews",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030700984&doi=10.1016%2fj.rser.2017.09.047&partnerID=40&md5=fe1384548ec1e5075745bb05bf14ec58","The purpose of this paper is to examine the state-of-the-art research efforts linked with the development of fatigue life estimation models. The main objective is to identify new concepts for fatigue life estimation other than the classical models and their hybrids. Various techniques to estimate fatigue life have been identified, such as critical plane deviation, 5D deviatoric space enclosed surface, modified Wholer curve. However, the most notable one to be found is the application of evolutionary optimization algorithms for, e.g., genetic algorithms, artificial neural networking, and differential ant-stigmergy algorithms. Initially, a brief history of fatigue life estimation and modeling is presented. In subsequent sections, some familiar classical models are discussed, and then various innovative approaches to fatigue life prediction are reviewed. The survey is fairly detailed, and best efforts have been made to the net in as many new methodologies as possible. The review is organized to offer insight on how past research efforts have provided the groundwork for subsequent studies. © 2017 Elsevier Ltd","Classical fatigue models; Critical plane; Fatigue; Hybrid models; Optimization algorithm",,2-s2.0-85030700984
"Zhu P., Xu Q., Hu Q., Zhang C., Zhao H.","Multi-label feature selection with missing labels",2018,"Pattern Recognition",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032306908&doi=10.1016%2fj.patcog.2017.09.036&partnerID=40&md5=dee58fb593e6b2383576f2c12bb10790","The consistently increasing of the feature dimension brings about great time complexity and storage burden for multi-label learning. Numerous multi-label feature selection techniques are developed to alleviate the effect of high-dimensionality. The existing multi-label feature selection algorithms assume that the labels of the training data are complete. However, this assumption does not always hold true for labeling data is costly and there is ambiguity among classes. Hence, in real-world applications, the data available usually have an incomplete set of labels. In this paper, we present a novel multi-label feature selection model under the circumstance of missing labels. With the proposed algorithm, the most discriminative features are selected and missing labels are recovered simultaneously. To remove the irrelevant and noisy features, the effective l2, p-norm (0 &lt; p ≤ 1) regularization item is imposed on the feature selection matrix. To solve the optimization problem, we developed an iterative reweighted least squares (IRLS) algorithm with guaranteed convergence. Experimental results on benchmark datasets show that the proposed method outperforms the state-of-the-art multi-label feature selection algorithms. © 2017 Elsevier Ltd","Feature selection; Missing labels; Multi-label learning","Digital storage; Iterative methods; Learning systems; Optimization; Discriminative features; Feature selection algorithm; Guaranteed convergence; High dimensionality; Iterative reweighted least square; Multi-label learning; Optimization problems; Selection techniques; Feature extraction",2-s2.0-85032306908
"Freudenberger J., Rajab M., Rohweder D., Safieh M.","A Codec Architecture for the Compression of Short Data Blocks",2018,"Journal of Circuits, Systems and Computers",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020732096&doi=10.1142%2fS0218126618500196&partnerID=40&md5=ed5957fc5c1f4fe4b6b5e19d2b6ce339","This work proposes a lossless data compression algorithm for short data blocks. The proposed compression scheme combines a modified move-to-front algorithm with Huffman coding. This algorithm is applicable in storage systems where the data compression is performed on block level with short block sizes, in particular, in non-volatile memories. For block sizes in the range of 1kB, it provides a compression gain comparable to the Lempel-Ziv-Welch algorithm. Moreover, encoder and decoder architectures are proposed that have low memory requirements and provide fast data encoding and decoding. © 2018 World Scientific Publishing Company.","Data compression; Error correction codes; Flash memories; Huffman coding; Lempel-Ziv-Welch coding; Move-to-front","Codes (symbols); Data storage equipment; Decoding; Digital storage; Error correction; Flash memory; Memory architecture; Signal encoding; Compression gain; Compression scheme; Decoder architecture; Error correction codes; Huffman coding; Lossless data compression algorithm; Move-to-front; Non-volatile memory; Data compression",2-s2.0-85020732096
"Akmaz D., Mamiş M.S., Arkan M., Tağluk M.E.","Transmission line fault location using traveling wave frequencies and extreme learning machine",2018,"Electric Power Systems Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030091064&doi=10.1016%2fj.epsr.2017.09.019&partnerID=40&md5=a067eb8e2e0c75a0500facd75b471898","In this research, a new approach was proposed for determining the fault location in transmission lines. Traveling wave frequencies and an extreme learning machine (ELM) were used to determine fault location. Transient signals in the time domain were transformed to the frequency domain using the fast Fourier transform (FFT) and the traveling wave frequencies were detected from the transient frequency spectrum. In order to detect the location of fault, traveling wave frequency was used initially to predict the fault location. The prediction of this fault location was tested for many different fault conditions and was found to be adversely affected by only the source inductance value. This is due to the negative effect of source inductance on wave velocity. Regression feature of ELM was used in order to improve the prediction of fault location and to minimize the negative effect of source inductance. For ELM regression training, values of the fault distance estimated from the traveling-wave frequencies and the source inductance values were used as ELM input data, and the actual distance values were used as ELM output data. After ELM regression training, ELM predicted a new fault location using the input data. The Alternative Transients Program (ATP/EMTP) was used to model J. Marti frequency dependent line model, and the MATLAB program was used to perform fault-detection algorithms. Simulation results show that the proposed method is very successful against many variables such as different fault resistances, source inductances, transmission line characteristics, transmission line lengths. © 2017 Elsevier B.V.","Extreme learning machine; Fast Fourier transform; Fault-location estimation; Transmission lines; Traveling wave frequencies","Electric lines; Fast Fourier transforms; Forecasting; Frequency domain analysis; Frequency estimation; Inductance; Input output programs; Knowledge acquisition; Learning systems; Location; MATLAB; Regression analysis; Wave propagation; Wave transmission; Alternative transients program; Extreme learning machine; Fault detection algorithm; Fault location estimation; Frequency dependent line model; Transmission line characteristics; Transmission line fault location; Traveling wave; Fault detection",2-s2.0-85030091064
"Fan Q., Li K.","Non-contact remote estimation of cardiovascular parameters",2018,"Biomedical Signal Processing and Control",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030158713&doi=10.1016%2fj.bspc.2017.09.022&partnerID=40&md5=1c8320249da2cfd3f2d159b28d9a2109","Cardiovascular disease is a serious threat to human health. It is crucial to monitor the cardiovascular parameters reliably and conveniently. Non-contact measurement has been widely studied. However, there are some inevitable factors that limit the use of the platform and even lead to inaccuracy estimation. Hence, a novel non-contact method that estimates cardiovascular parameters under ambient light is proposed. The most suitable region of interest (ROI) is determined by a colormap, which is a map consists of Fast Fourier Transform (FFT) peak amplitude of every pixel. Comparisons suggest that the region includes cheeks and nose is the most appropriate, followed by the forehead. To remove the motion artifacts caused by body movement, face detection and tracking algorithms are performed. Further, a multi-step signal process that combines independent component analysis (ICA) and wavelet de-noising is utilized to extract clean signal from the noise-corrupted raw waveform. Moreover, various distance between subject and camera and the change of ambient light intensity are considered, where statistics results reveal that this non-contact methodology is blind to these factors. Compared with the gold standard pulse oximeter, the proposed method shows a high accuracy even in the presence of motion artifacts. © 2017 Elsevier Ltd","Heart rate; Imaging photoplethysmography; Independent component analysis; Motion artifact; Oxygen saturation; Wavelet decomposition","Face recognition; Fast Fourier transforms; Health risks; Image segmentation; Independent component analysis; Noninvasive medical procedures; Oximeters; Signal processing; Wavelet decomposition; Cardio-vascular disease; Cardiovascular parameters; Face detection and tracking; Heart rates; Independent component analysis(ICA); Motion artifact; Noncontact measurements; Oxygen saturation; Parameter estimation; adult; algorithm; Article; artifact; body movement; cardiovascular parameters; female; Fourier transformation; gold standard; human; human experiment; independent component analysis; light intensity; male; measurement accuracy; normal human; priority journal; pulse oximeter; signal processing; waveform; wavelet analysis",2-s2.0-85030158713
"Sanz-Estébanez S., Rabanillo-Viloria I., Royuela-del-Val J., Aja-Fernández S., Alberola-López C.","Joint groupwise registration and ADC estimation in the liver using a B-value weighted metric",2018,"Magnetic Resonance Imaging",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031503231&doi=10.1016%2fj.mri.2017.10.002&partnerID=40&md5=2052a0a1fa5a4419daf753c68e508f27","Purpose The purpose of this work is to develop a groupwise elastic multimodal registration algorithm for robust ADC estimation in the liver on multiple breath hold diffusion weighted images. Methods We introduce a joint formulation to simultaneously solve both the registration and the estimation problems. In order to avoid non-reliable transformations and undesirable noise amplification, we have included appropriate smoothness constraints for both problems. Our metric incorporates the ADC estimation residuals, which are inversely weighted according to the signal content in each diffusion weighted image. Results Results show that the joint formulation provides a statistically significant improvement in the accuracy of the ADC estimates. Reproducibility has also been measured on real data in terms of the distribution of ADC differences obtained from different b-values subsets. Conclusions The proposed algorithm is able to effectively deal with both the presence of motion and the geometric distortions, increasing accuracy and reproducibility in diffusion parameters estimation. © 2017 Elsevier Inc.","ADC estimation; Diffusion weighted imaging; Groupwise registration; Joint optimization; Residual minimization metric","algorithm; anatomical variation; apparent diffusion coefficient; Article; b value; controlled study; diffusion weighted imaging; geometry; human; image analysis; image enhancement; liver; measurement accuracy; motion; priority journal; reproducibility; signal noise ratio; simulation",2-s2.0-85031503231
"Ma G., Xu G., Chen Y., Ju R.","Voltage stability control method of electric springs based on adaptive PI controller",2018,"International Journal of Electrical Power and Energy Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028387652&doi=10.1016%2fj.ijepes.2017.08.029&partnerID=40&md5=a296c8620ca4b23d8f83068350dca990","With the continuous development of distributed generation technology, the permeability of wind, solar and other renewable energy continues to increase. As a new kind of voltage control device, electric spring can suppress the voltage fluctuation caused by the power change of distributed generation effectively. In this paper, based on the analysis of the principle of voltage stability control for the electric spring, the optimization of control effect and non-critical load change are taken into consideration. Combined with advanced particle swarm optimization algorithm and fuzzy control algorithm, a method of voltage control for electric spring based on adaptive PI control is proposed, and the digital simulation is carried out. The simulation results show that the adaptive PI control has better voltage regulation effect than the traditional PI control, and can solve the adverse effect of the load variation on the electric spring. © 2017 Elsevier Ltd","Adaptation; Electric spring; Fuzzy control; Particle swarm optimization","Distributed power generation; Fuzzy control; Particle swarm optimization (PSO); Two term control systems; Voltage control; Voltage regulators; Adaptation; Adaptive pi controllers; Adaptive pi controls; Continuous development; Distributed generation technologies; Particle swarm optimization algorithm; Voltage fluctuations; Voltage stability controls; Optimization",2-s2.0-85028387652
"Feng X.-F., Pan D.-F.","A camera calibration method based on plane mirror and vanishing point constraint",2018,"Optik",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032194715&doi=10.1016%2fj.ijleo.2017.10.086&partnerID=40&md5=f66d3366bc6e87ac28982b09279ca30e","In order to avoid a cumbersome calibration of camera parameters, a method of self-calibration using the imaging features of a plane mirror and the vanishing point pair constraint is proposed. A plane mirror and calibration template were placed at a certain angle and non-vertical geometric constraints were obtained from the calibration template, as well as from the virtual image of the calibration template. So all the internal parameters were calibrated at once. In order to reduce the influence on the calibration parameters of the vanishing point position, the least squares algorithm and the LM algorithm were used to optimize the parameters. Simulations and real experimental results show that the method has a high accuracy and robustness. © 2017 Elsevier GmbH","Machine vision; Parameter calibration; Plane mirror; Vanishing point pair","Cameras; Computer vision; Mirrors; Calibration parameters; Camera calibration; Geometric constraint; Internal parameters; Least squares algorithm; Parameter calibration; Plane mirrors; Vanishing point; Calibration",2-s2.0-85032194715
"Mariani M.C., Bhuiyan M.A.M., Tweneboah O.K.","Estimation of stochastic volatility by using Ornstein–Uhlenbeck type models",2018,"Physica A: Statistical Mechanics and its Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030549949&doi=10.1016%2fj.physa.2017.08.153&partnerID=40&md5=e4b2fa84fae949189de1fe452059b3e1","In this study, we develop a technique for estimating the stochastic volatility (SV) of a financial time series by using Ornstein–Uhlenbeck type models. Using the daily closing prices from developed and emergent stock markets, we conclude that the incorporation of stochastic volatility into the time varying parameter estimation significantly improves the forecasting performance via Maximum Likelihood Estimation. Furthermore, our estimation algorithm is feasible with large data sets and have good convergence properties. © 2017","Financial time series; Maximum likelihood estimation; Ornstein–Uhlenbeck processes; Stochastic volatility","Financial data processing; Maximum likelihood; Stochastic models; Stochastic systems; Time series; Convergence properties; Estimation algorithm; Financial time series; Forecasting performance; Large datasets; Stochastic volatility; Time-varying parameter estimation; Maximum likelihood estimation",2-s2.0-85030549949
"Taxt T., Reed R.K., Pavlin T., Rygh C.B., Andersen E., Jiřík R.","Semi-parametric arterial input functions for quantitative dynamic contrast enhanced magnetic resonance imaging in mice",2018,"Magnetic Resonance Imaging",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032255225&doi=10.1016%2fj.mri.2017.10.004&partnerID=40&md5=c5ba1c44e4d05eac5576159e1c48ee7e","Objective An extension of single- and multi-channel blind deconvolution is presented to improve the estimation of the arterial input function (AIF) in quantitative dynamic contrast enhanced magnetic resonance imaging (DCE-MRI). Methods The Lucy-Richardson expectation-maximization algorithm is used to obtain estimates of the AIF and the tissue residue function (TRF). In the first part of the algorithm, nonparametric estimates of the AIF and TRF are obtained. In the second part, the decaying part of the AIF is approximated by three decaying exponential functions with the same delay, giving an almost noise free semi-parametric AIF. Simultaneously, the TRF is approximated using the adiabatic approximation of the Johnson-Wilson (aaJW) pharmacokinetic model. Results In simulations and tests on real data, use of this AIF gave perfusion values close to those obtained with the corresponding previously published nonparametric AIF, and are more noise robust. Conclusion When used subsequently in voxelwise perfusion analysis, these semi-parametric AIFs should give more correct perfusion analysis maps less affected by recording noise than the corresponding nonparametric AIFs, and AIFs obtained from arteries. Significance This paper presents a method to increase the noise robustness in the estimation of the perfusion parameter values in DCE-MRI. © 2017","Arterial input function; Blind deconvolution; DCE-MRI","gadodiamide; algorithm; animal experiment; arterial input fraction; Article; blood vessel parameters; contrast to noise ratio; controlled study; dynamic contrast-enhanced magnetic resonance imaging; female; mouse; nonhuman; priority journal; quantitative analysis; simulation; tissue residue function",2-s2.0-85032255225
"Philip J.G., Jain T.","Analysis of low frequency oscillations in power system using EMO ESPRIT",2018,"International Journal of Electrical Power and Energy Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029363218&doi=10.1016%2fj.ijepes.2017.08.037&partnerID=40&md5=fd3f7bfeb2378f06bd0731cc41247546","Identification of poorly damped low frequency oscillations present in the densely interconnected power system is of paramount importance to maintain its stable operation. Estimation of signal parameters via rotational invariance technique (ESPRIT) is a parametric method used for analysing such signals even under noisy conditions. However, this method requires precise information about the number of modes present in the signal. Hence, this work uses a combination of Exact Model Order (EMO) algorithm and ESPRIT for analysing these low frequency oscillations. The performance of the proposed method is tested using various synthetic signals with different levels of noise and PMU reporting rates. Further, the robustness of the proposed method towards noise resistance is compared with modified Prony, TLS-ESPRIT and ARMA methods. Finally, the proposed method is tested using real time probing test data obtained from Western Electricity Coordinating Council (WECC) network. Results reveal that the proposed method is accurate, precise and outperforms the other methods. © 2017 Elsevier Ltd","Autocorrelation matrix; ESPRIT; Exact Model Order algorithm; Low frequency oscillations; Model order estimation","Frequency estimation; Autocorrelation matrix; ESPRIT; Low frequency oscillations; Model order; Model order estimation; Signal analysis",2-s2.0-85029363218
"Chao C., Silverberg M.J., Chen L.-H., Xu L., Martínez-Maza O., Abrams D.I., Zha H.D., Haque R., Said J.","Novel tumor markers provide improved prediction of survival after diagnosis of human immunodeficiency virus (HIV)-related diffuse large B-cell lymphoma",2018,"Leukemia and Lymphoma",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020698249&doi=10.1080%2f10428194.2017.1334121&partnerID=40&md5=4129a79dffaa7b2cf559b320ace06630","Existing prognostic tools for HIV + diffuse large B-cell lymphoma (DLBCL) fail to accurately predict patient outcomes. To develop a novel prognostic algorithm incorporating molecular tumor characteristics and HIV disease factors, we included 80 patients with HIV-related DLBCL diagnosed between 1996 and 2007. Immunohistochemistry staining was used to analyze the expression of 26 tumor markers. Clinical data were collected from medical records. Logistic regression and bootstrapping were used to select and assess stability of the prognostic model, respectively. Of the tumor markers examined, expression of cMYC, Ki 67, CD44, EBV, SKP2, BCL6, p53, CD20 and IgM were associated with two-year mortality. The final prognostic model, confirmed in bootstrapped samples, included IPI, circulating CD4 cell count, history of clinical AIDS, and expression of CD44, p53, IgM and EBV. This model incorporating HIV disease history and tumor markers, achieved better prediction for two-year mortality [AUC = 0.87, 95% CI: 0.78–0.96] compared with IPI alone [AUC = 0.63 (0.51–0.75)]. © 2017 Informa UK Limited, trading as Taylor & Francis Group.","AIDS; CD4; diffuse large B-cell lymphoma; HIV; Lymphoma; prognosis","CD20 antigen; Epstein Barr virus antigen; Hermes antigen; immunoglobulin M; Ki 67 antigen; lactate dehydrogenase; Myc protein; protein bcl 6; protein p53; rituximab; S phase kinase associated protein 2; tumor marker; acquired immune deficiency syndrome; adult; algorithm; Article; bootstrapping; cancer chemotherapy; cancer diagnosis; cancer mortality; cancer patient; cancer prognosis; cancer survival; CD4 lymphocyte count; cohort analysis; controlled study; diffuse large B cell lymphoma; female; human; Human immunodeficiency virus; immunohistochemistry; major clinical study; male; medical history; medical record review; middle aged; observational study; priority journal; retrospective study; survival prediction",2-s2.0-85020698249
"Chatterjee S., Dey D., Munshi S.","Optimal selection of features using wavelet fractal descriptors and automatic correlation bias reduction for classifying skin lesions",2018,"Biomedical Signal Processing and Control",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030859370&doi=10.1016%2fj.bspc.2017.09.028&partnerID=40&md5=a70d3375d79575987b981b9c72be8d1f","The non-invasive computerized image analysis techniques have a great impact on accurate and uniform evaluation of skin abnormalities. The paper reports a method for the texture and morphological feature extraction from skin lesion images to differentiate common melanoma from benign nevi. In this work, a 2D wavelet packet decomposition (WPD) based fractal texture analysis has been proposed to extract the irregular texture pattern of the skin lesion area. On the whole 6214 features have been extracted from each of the 4094 skin lesion images, by analyzing the textural pattern and morphological structure of the lesion area. For the identification of the most efficient feature set, an improved correlation bias reduction method has been introduced in combination with support vector machine recursive feature elimination (SVM-RFE). An automatic selection of correlation threshold value has been introduced in this proposed work to eliminate the correlation bias problem associated with SVM-RFE algorithm. With these selected features, the support vector machine (SVM) classifier with radial basis function is found to achieve the classification performance of 97.63% sensitivity, 100% specificity and 98.28% identification accuracy. The results show that the scheme presented in this paper surpasses the performance of the other state-of-the art techniques for the differentiation of melanoma from other skin abnormalities. © 2017 Elsevier Ltd","Correlation bias reduction; Fractal descriptor; Melanoma; Recursive feature elimination; Support vector machine; Wavelet packet decomposition","Dermatology; Fractals; Image analysis; Image processing; Oncology; Radial basis function networks; Support vector machines; Wavelet analysis; Wavelet decomposition; Correlation bias; Descriptors; Melanoma; Recursive feature elimination; Wavelet Packet Decomposition; Feature extraction; algorithm; Article; artifact reduction; classification; classifier; decomposition; fractal analysis; image analysis; image processing; image segmentation; imaging and display; melanoma; priority journal; skin defect; support vector machine; wavelet packet decomposition",2-s2.0-85030859370
"Jia T., Wang H., Shen X., Jiang Z., He K.","Target localization based on structured total least squares with hybrid TDOA-AOA measurements",2018,"Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029396590&doi=10.1016%2fj.sigpro.2017.09.011&partnerID=40&md5=efe997163b8f462056563bebf77dd371","In this paper, we focus on the target localization problem which finds broad applications in radar, sonar and wireless sensor networks. A pseudolinear overdetermined system of equations is constructed from the nonlinear hybrid TDOA-AOA measurements about target location. Considering the matrix and vector in the constructed pseudolinear system are both contaminated by the measurement noise, a new weight least squares (WLS) method which is based on the first order Taylor expansions of the noise terms is developed in this paper and it can reduce the estimation bias that arise from the least squares (LS) method. In particular we focus on constructing a localization algorithm to reduce the bias that easily arise from the traditional methods. Thus in addition, a novel structured total least squares (STLS) method is also developed in this paper to further reduce the estimation bias specially when the target is outside the convex hull formed by sensors. Numerical examples show the superiority of the proposed STLS method in estimation accuracy compared with the LS method, total least squares (TLS) method and the proposed WLS method. © 2017 Elsevier B.V.","Angle of arrival (AOA); Cramér–Rao bound; Structured total least squares (STLS); Target localization; Time difference of arrival (TDOA); Weighted least squares (WLS)","Direction of arrival; Nonlinear equations; Numerical methods; Time difference of arrival; Wireless sensor networks; Angle of arrival; Least squares methods; Localization algorithm; Overdetermined systems; Pseudolinear systems; Structured total least squares; Target localization; Weighted least squares; Least squares approximations",2-s2.0-85029396590
"Zhao M., Liu X.","Development of decision support tool for optimizing urban emergency rescue facility locations to improve humanitarian logistics management",2018,"Safety Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031792613&doi=10.1016%2fj.ssci.2017.10.007&partnerID=40&md5=af0142148af3e981c2595cc65df9f6ed","Emergency rescue facility is an essential component of urban emergency logistics system, and selection of their locations is significant for urban public safety. Urban emergency rescue facility locations (UERFLs) problem is essentially a geospatial multi-objective optimization problem (Geospatial-MOP), which presents a challenge for both researchers and managers. In this study, a user-friendly decision support tool was designed and developed for facilitating the process of optimizing UERFLs in large-scale urban areas. We described the design, architecture and implementation of the tool and its core optimization component. Based on a hypothetical case study, we introduced its functionalities as well as the decision making workflow. The results provide evidences that the tool can successfully generate Pareto-optimal frontier and capture a pool of alternative solutions to the decision maker for trade-off. This work offers new insights on promoting future urban emergency logistics management with the use of GIS and emerging artificial intelligence technologies, and makes contributions in integrating multi-objective optimization algorithm with GIS for solving geospatial multi-objective optimization problem. © 2017 Elsevier Ltd","Emergency facility locations; Geospatial multi-objective optimization; GIS; Humanitarian logistics management; Urban public safety","Decision support systems; Economic and social effects; Geographic information systems; Location; Logistics; Multiobjective optimization; Optimization; Pareto principle; Artificial intelligence technologies; Emergency facility locations; Emergency logistics systems; Geo-spatial; Humanitarian logistics; Multi-objective optimization problem; Pareto-optimal frontiers; Urban public safety; Decision making; algorithm; Article; case study; controlled study; decision support system; emergency rescue facility; financial management; health care facility; human; humanitarian logistics management; priority journal; probability; process optimization; risk factor; statistical model; traffic accident; trend study; urban area",2-s2.0-85031792613
"Wu D., Wang F., Cai Y.","High-order nonuniformly correlated beams",2018,"Optics and Laser Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029552534&doi=10.1016%2fj.optlastec.2017.09.007&partnerID=40&md5=28817d27c10ada7e9df351be27f6adc3","We have introduced a class of partially coherent beams with spatially varying correlations named high-order nonuniformly correlated (HNUC) beams, as an extension of conventional nonuniformly correlated (NUC) beams. Such beams bring a new parameter (mode order) which is used to tailor the spatial coherence properties. The behavior of the spectral density of the HNUC beams on propagation has been investigated through numerical examples with the help of discrete model decomposition and fast Fourier transform (FFT) algorithm. Our results reveal that by selecting the mode order appropriately, the more sharpened intensity maxima can be achieved at a certain propagation distance compared to that of the NUC beams, and the lateral shift of the intensity maxima on propagation is closed related to the mode order. Furthermore, analytical expressions for the r.m.s width and the propagation factor of the HNUC beams on free-space propagation are derived by means of Wigner distribution function. The influence of initial beam parameters on the evolution of the r.m.s width and the propagation factor, and the relation between the r.m.s width and the occurring of the sharpened intensity maxima on propagation have been studied and discussed in detail. © 2017 Elsevier Ltd","Nonuniformly correlated; Partially coherent beams; Propagation","Fast Fourier transforms; Spectral density; Wave propagation; Analytical expressions; Fast Fourier transform algorithm; Free space propagation; Nonuniformly correlated; Partially coherent beam; Propagation distances; Spatial coherence properties; Wigner distribution functions; Distribution functions",2-s2.0-85029552534
"Huang Z., Zhang Y., Li Q., Zhang T., Sang N.","Spatially adaptive denoising for X-ray cardiovascular angiogram images",2018,"Biomedical Signal Processing and Control",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029812453&doi=10.1016%2fj.bspc.2017.09.019&partnerID=40&md5=87910f173602d98e49f25ee88bea71a2","The X-ray angiogram image denoising is always one of the most popular research in the field of computer vision. While the methods removed the noise, the useful structure (such as peripheral vascular) had also been smoothed, the fundamental reason is that the denoising methods cannot efficiently distinguish structural areas from flat areas. In this paper, we have proposed a spatially adaptive image denoising (SAID) method which contains two steps: spatially adaptive gradient descent (SAGD) image denoising and dual-domain filter (DDF). The SAGD denoising method contains the following parts: first of all, the wavelet shrinkage method is used to estimate redundant information which is composed of the noise and useful structures; secondly, according to the characteristic of second order matrix, a spatially adaptive gradient factor (SAGF) has been constructed to distinguish the structure from flat areas; finally, the SAGF replaces the original gradient factor and then the SAGD image denoising method is formed. To further improve the quality of the SAGD image, the SAGD image is re-denoised by a modified DDF which is guided with a rotationally invariant non-local filter (RINLF) in spatial domain and gets structural details by wavelet shrinkage in frequency domain. The results of simulation experiments verify that the proposed SAID method can get well quantitative and qualitative results which are even superior to those using the state-of-the-art denoising methods. Even more, the fluctuation of peak signal-to-noise ratio (PSNR) value is very small with a small disturbance of SAGF, which illustrates that our algorithm is more robust than the prior progressive image denoising (PID) method. Moreover, the comparison results of the extensive experiments on clinical X-ray cardiovascular angiogram images further illustrate that our method can yield clearer cardiovascular images which can provide more useful vascular information for clinicians to analyze and diagnose the cardiovascular diseases. © 2017 Elsevier Ltd","Gradient factor; Spatially adaptive denoising; Wavelet shrinkage; X-ray cardiovascular angiogram image","Frequency domain analysis; Shrinkage; Signal to noise ratio; Cardio-vascular disease; Gradient factor; Image denoising methods; Peak signal to noise ratio; Spatially adaptive; Structural details; Wavelet shrinkage; X-ray angiogram images; Image denoising; algorithm; angiocardiography; Article; Fourier transformation; image analysis; image quality; mathematical analysis; noise reduction; priority journal; qualitative analysis; quantitative analysis; signal noise ratio",2-s2.0-85029812453
"Eliacik A.B., Erdogan N.","Influential user weighted sentiment analysis on topic based microblogging community",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030679791&doi=10.1016%2fj.eswa.2017.10.006&partnerID=40&md5=25c2bcf59481245ad6b31d7f611e6c13","Nowadays, social microblogging services have become a popular expression platform of what people think. People use these platforms to produce content on different topics from finance, politics and sports to sociological fields in real-time. With the proliferation of social microblogging sites, the massive amount of opinion texts have become available in digital forms, thus enabling research on sentiment analysis to both deepen and broaden in different sociological fields. Previous sentiment analysis research on microblogging services generally focused on text as the unique source of information, and did not consider the social microblogging service network information. Inspired by the social network analysis research and sentiment analysis studies, we find that people's trust in a community have an important place in determining the community's sentiment polarity about a topic. When studies in the literature are examined, it is seen that trusted users in a community are actually influential users. Hence, we propose a novel sentiment analysis approach that takes into account the social network information as well. We concentrate on the effect of influential users on the sentiment polarity of a topic based microblogging community. Our approach extends the classical sentiment analysis methods, which only consider text content, by adding a novel PageRank-based influential user finding algorithm. We have carried out a comprehensive empirical study of two real-world Twitter datasets to analyze the correlation between the mood of the financial social community and the behavior of the stock exchange of Turkey, namely BIST100, using Pearson correlation coefficient method. Experimental results validate our assumptions and show that the proposed sentiment analysis method is more effective in finding topic based microblogging community's sentiment polarity. © 2017 Elsevier Ltd","Influential user; Microblogging service; Sentiment analysis; Social network analysis","Correlation methods; Data mining; Empirical studies; Finding algorithm; Influential users; Micro-blogging services; Pearson correlation coefficients; Sentiment analysis; Social communities; Social network informations; Social networking (online)",2-s2.0-85030679791
"Xiao J., Jia M., Chang Y., Li Y., Xu Z., Xu G., Liu H., Wang T.","Numerical optimization and comparative study of n-butanol concentration stratification combustion and n-butanol/diesel reactivity stratification combustion for advanced compression ignition (CI) engine",2018,"Fuel",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032502660&doi=10.1016%2fj.fuel.2017.10.104&partnerID=40&md5=f757ff5698b255881f8e5a6ff3eb2b1b","Previous studies show that satisfactory engine performance can be achieved by using both the reactivity stratification combustion (RSC) and the concentration stratification combustion (CSC) fueled with n-butanol. However, the different ignition and combustion characteristics between RSC and CSC have not been well explored yet. In this study, the n-butanol/diesel RSC and n-butanol CSC strategies were compared by integrating the KIVA-3V code and the non-dominated sort genetic algorithm II (NSGA-II). For both RCS and CSC, n-butanol was premixed in the initial port. However, diesel and n-butanol were injected into the cylinder for RSC and CSC, respectively. Five important operating parameters were selected as the variables for optimization, including premixed fraction (PF), start of injection (SOI), the initial in-cylinder pressure at the initial valve close (IVC) timing, the initial in-cylinder temperature at the IVC timing (Tivc), and exhaust gas recirculation (EGR) rate. The optimization results show that, for the realization of the clean and high-efficiency combustion, a wide range of SOI and the high PF are introduced in RSC, whereas a wide range of PF and the early SOI are employed in CSC. Due to the lower reactivity of n-butanol than diesel, CSC requires the higher Tivc than RSC. As a fixed EGR rate, the optimal operating range of the initial temperature is restricted in a narrow range, especially for CSC. The optimal operating range of SOI and PF of RSC is larger than that of CSC. In RSC, the homogeneous charge compression ignition (HCCI)-like combustion shows the lowest fuel consumption and NOx emissions, and the highest ringing intensity (RI). The reactivity control compression ignition (RCCI) combustion demonstrates the overall balanced engine performance. The benefit of the diesel induced ignition combustion on RI is evident, but the high NOx emissions are still a challenge. For CSC, the optimal case with the low concentration stratification of n-butanol achieves the good EISFC, the low NOx emissions, and the high RI. Generally, the RSC strategy is superior to the CSC strategy in terms of the control of combustion phasing, fuel efficiency, and emissions. © 2017 Elsevier Ltd","Alternative fuels; Combustion efficiency; Concentration stratification combustion (CSC); Genetic algorithm; Multi-dimensional simulation; Reactivity stratification combustion (RSC)",,2-s2.0-85032502660
"Zhu S., Wu L., Mousavian S., Roh J.H.","An optimal joint placement of PMUs and flow measurements for ensuring power system observability under N-2 transmission contingencies",2018,"International Journal of Electrical Power and Energy Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028499676&doi=10.1016%2fj.ijepes.2017.08.025&partnerID=40&md5=ff6a7e8579887a4c9269a5fbafe071c5","This paper discusses an optimal joint placement of phasor measurement units (PMUs) and flow measurement devices for ensuring observability of power systems under N-2 transmission contingencies while excluding single-bus islanding situations. Previous studies mainly focus on system observability under N-1 contingencies, and consider the PMU placement only or the joint placement while restricting PMUs and flow measurements to be adjacent. In comparison, this paper first proposes a single-stage optimal joint placement model which minimizes the total investment cost of PMUs and flow measurements for achieving system observability under N-2 transmission contingencies while excluding single-bus islanding situations. Different topologies corresponding to double-line outage situations and the effect of zero power injection nodes are accurately considered, and system disintegration is adequately addressed for guaranteeing system observability under N-2 transmission contingencies. Moreover, the proposed model allows a flow measurement on a branch to observe one terminal node even if the other terminal is not adjacent to a PMU. The proposed single-stage optimal joint placement model is formulated as a mixed-integer nonlinear programming (MINLP) problem, and is equivalently transformed into a mixed-integer linear programming (MILP) problem and solved via a decomposition algorithm. Furthermore, as system operators may prefer a multi-stage placement plan so as to well spread limited financial budgets among multiple years, the proposed single-stage joint placement model is further extended to a three-stage strategy for incrementally ensuring system observability with respect to the original topology, N-1 contingencies, and N-2 contingencies. Both models are verified via several IEEE power systems. Numerical results show that, as compared to previous studies, the proposed optimal joint placement approaches are advantageous in reducing total investment cost while ensuring system observability, and the three-stage placement model presents an effective strategy to handle limited financial budgets among multiple years. In addition, impacts of other factors on the proposed model, including single PMU failure, substation based optimization, branch PMU based optimization, single-bus islanding inclusion, and zero power injection effect verification, are analyzed and discussed via extensive case studies. © 2017 Elsevier Ltd","Joint placement; N-2 transmission contingencies; Observability","Budget control; Buses; Distributed power generation; Electric power system measurement; Electric power transmission; Flow measurement; Integer programming; Investments; Nonlinear programming; Observability; Outages; Topology; Units of measurement; Decomposition algorithm; Measurement device; Mixed integer non-linear programming problems; Mixed-integer linear programming; Phasor measurement unit (PMUs); Power system observabilities; System observability; Three stage strategy; Phasor measurement units",2-s2.0-85028499676
"Wu Q., Yan X., Xiao K., Guan J., Li T., Liang P., Huang X.","Optimization of membrane unit location in a full-scale membrane bioreactor using computational fluid dynamics",2018,"Bioresource Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031808839&doi=10.1016%2fj.biortech.2017.09.209&partnerID=40&md5=15e7e1e2b5f7aadfbdc5ed8e0c59316a","The location of membrane units in the membrane tank is a key factor in the construction of a full-scale membrane bioreactor (MBR), as it would greatly affect the hydrodynamics in the tank, which could in turn affect the membrane fouling rate while running. Yet, in most cases, these units were empirically installed in tanks, no theory guides were currently available for the design of a proper location. In this study, the hydrodynamics in the membrane tank of a full-scale MBR was simulated using computational fluid dynamics (CFD). Five indexes (iLu, iLa, iLb, iLint, iLw) were used to indicate the unit location, and each of them was discussed for their individual impact on the risk water velocity (v0.05) in the membrane unit region. An optimal design with all the indexes equaling 0.6 was proposed, and was found to have a promotion of 146.9% for v0.05. © 2017 Elsevier Ltd","Computational fluid dynamics; Full-scale membrane bioreactor; Hydrodynamics; Membrane unit location","Bioconversion; Biological water treatment; Bioreactors; Computation theory; Dynamics; Fluid dynamics; Hydrodynamics; Location; Membrane fouling; Membranes; Tanks (containers); Membrane bio reactor (MBR); Membrane bioreactor; Membrane fouling rates; Membrane tanks; Membrane units; Optimal design; Optimization of membranes; Water velocities; Computational fluid dynamics; biofouling; bioreactor; computational fluid dynamics; hydrodynamics; membrane; optimization; activated sludge; algorithm; Article; computational fluid dynamics; controlled study; density; priority journal; reactor optimization; shear rate; shear stress; steady state; surface property; suspended particulate matter; velocity; viscosity",2-s2.0-85031808839
"Román-Sánchez A., Vanwalleghem T., Peña A., Laguna A., Giráldez J.V.","Controls on soil carbon storage from topography and vegetation in a rocky, semi-arid landscapes",2018,"Geoderma",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006067121&doi=10.1016%2fj.geoderma.2016.10.013&partnerID=40&md5=0d5696d37d1c86f2e2708f9d5a61140c","Soil properties can exhibit strong spatial variation, even at the small catchment scale. Especially soil carbon pools in semi-arid, mountainous areas are highly uncertain because bulk density and stoniness are very heterogeneous and rarely measured explicitly. The effect of topographic and vegetation variables, on stoniness, bulk density and soil carbon has been explored in a 2.7 km2 watershed of Sierra Morena in south Spain. Soil core samples were collected from 67 locations at 6 depths up to 0,3 m. Stoniness and bulk density were measured with standard methods, total organic carbon through elemental analysis. These soil properties were then used to calculate carbon stock and related to solar insolation, elevation, slope, curvature, TWI, TPI, SPI and NDVI. Stone content depends on slope, indicating the importance of water erosion on long-term soil development. Spatial distribution of bulk density was found to be highly random. By means of conventional statistical methods, with the help of a random forest method, solar radiation and NDVI proved to be the key variable controlling soil carbon distribution. Total soil organic carbon stocks were 4.38 kg m− 2 on average, with stocks about double as high on north versus south-facing slopes. These results confirm the importance of the coupled soil moisture and vegetation dynamics on the carbon balance in semi-arid ecosystems. However, validation of the random forest model showed that the different covariates only explained 18% of the variation in the dataset. Apparently, present-day landscape and vegetation properties are not sufficient to fully explain the full variability in the soil carbon stocks in this complex terrain under natural vegetation. This is attributed to a high spatial variability in bulk density and stoniness, key variables controlling carbon stocks. Future improvement of mechanistic soil formation models could help estimating these soil properties better. © 2016 Elsevier B.V.","Critical zone; Random forest; Soil carbon; Solar radiation; Stoniness; Vegetation","Carbon; Catchments; Decision trees; Ecosystems; Soil moisture; Soils; Solar radiation; Vegetation; Critical zones; Random forest methods; Random forest modeling; Random forests; Soil carbon; Soil organic Carbon stocks; Stoniness; Vegetation properties; Organic carbon; algorithm; bulk density; carbon balance; carbon sequestration; data set; ecosystem dynamics; mountain region; organic carbon; semiarid region; soil analysis; soil carbon; soil property; soil texture; solar radiation; spatial variation; topography; vegetation structure; Sierra Morena; Spain",2-s2.0-85006067121
"Koundal D., Gupta S., Singh S.","Computer aided thyroid nodule detection system using medical ultrasound images",2018,"Biomedical Signal Processing and Control",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029838733&doi=10.1016%2fj.bspc.2017.08.025&partnerID=40&md5=b8662e23c71da517536d8ad62133f669","Thyroid nodule is one of the endocrine problem caused due to abnormal growth of cells. This survival rate can be enhanced by earlier detection of nodules. Thus, the accurate detection of nodule is of utmost importance in providing effective diagnosis to increase the survival rate. However, accuracy of nodule detection from ultrasound images is suffered due to speckle noise. It considerably deteriorates the image quality and makes the differentiation of fine details quite difficult. Most of the detection systems for the thyroid nodules are semi-automated entailing manual intervention to draw rough outline of the nodule at some level or require manual segmentation in training or testing phases that increase the inaccuracies and evaluation time. To handle this, a fully Computer-Aided Detection system is presented for speckle reduction and segmentation of nodules from thyroid ultrasound images. The proposed system has three components: speckle reduction to reduce speckle noise and preserve the diagnostic features of ultrasound image, automatic generation of Region of interest (ROI) that identifies suspicious regions and fully automatic segmentation of nodule in processed ROI image. The proposed segmentation method outperformed other methods by gaining high True Positive (TP) value (95.92 ± 3.70%), False Positive (FP) value (7.04 ± 4.21%), Dice Coefficient (DC) value (93.88 ± 2.59%), Overlap Metric (OM) (91.18 ± 7.04 pixels) and Hausdroff Distance (HD) (0.52 ± 0.20 pixels). This system can facilitate the endocrinologists by providing second opinion to improve diagnosis of nodules as benign or malignant. © 2017 Elsevier Ltd","Computer aided detection; Graphical user interface; Image segmentation; Neutrosophic; Speckle reduction","Diagnosis; Graphical user interfaces; Medical imaging; Pixels; Speckle; Ultrasonic applications; User interfaces; Automatic Generation; Automatic segmentations; Computer aided detection; Computer aided detection systems; Medical ultrasound images; Neutrosophic; Segmentation methods; Speckle reduction; Image segmentation; adolescent; adult; aged; algorithm; Article; automation; clinical article; computer aided design; computer assisted diagnosis; computer interface; controlled study; diagnostic accuracy; echography; female; filtration; human; image segmentation; male; noise reduction; priority journal; thyroid nodule; tumor diagnosis; ultrasound scanner",2-s2.0-85029838733
"Qian J., He Z., Zhang W., Huang Y., Fu N., Chambers J.","Robust adaptive beamforming for multiple-input multiple-output radar with spatial filtering techniques",2018,"Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028924015&doi=10.1016%2fj.sigpro.2017.09.004&partnerID=40&md5=dc79f7b3e4a3e68380743fb061fd0fb0","In this paper, we consider robust adaptive beamformer design for multiple-input multiple-output (MIMO) radar systems. The desired transmit-receive steering vector is estimated through maximizing the output power subject to constraints upon correlation coefficient and steering vector norm. The original nonconvex problem is reformulated as two reduced dimension semi-definite programming (SDP) problems. An iterative procedure is devised to tackle the two SDP problems, whose convergence is analytically proven. Based on the estimated desired signal, we are then able to obtain the interference covariance matrix via the matrix rank-constrained minimization method. Compared to other robust adaptive beamforming methods for MIMO radar, the proposed approach has the advantages of high efficiency and accuracy. Simulation results are presented to confirm the effectiveness and robustness of the proposed approach. © 2017","Convex quadratic program; Iterative algorithm; MIMO Radar; Robust beamforming","Beamforming; Codes (symbols); Constrained optimization; Covariance matrix; Feedback control; Iterative methods; MIMO radar; MIMO systems; Quadratic programming; Radar; Radar systems; Telecommunication repeaters; Interference covariance matrix; Iterative algorithm; Multiple input multiple output (MIMO) radars; Quadratic programs; Robust adaptive beamforming; Robust beamforming; Semi-definite programming; Spatial filtering techniques; Radar signal processing",2-s2.0-85028924015
"Al-Bander B., Al-Nuaimy W., Williams B.M., Zheng Y.","Multiscale sequential convolutional neural networks for simultaneous detection of fovea and optic disc",2018,"Biomedical Signal Processing and Control",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029711683&doi=10.1016%2fj.bspc.2017.09.008&partnerID=40&md5=fbe82353c6bde45be980d7a8b094bca7","Detecting the locations of the optic disc and fovea is a crucial task towards developing automatic diagnosis and screening tools for retinal disease. We propose to address this challenging problem by investigating the potential of applying deep learning techniques to this field. In the proposed method, simultaneous detection of the centers of the fovea and the optic disc (OD) from color fundus images is considered as a regression problem. A deep multiscale sequential convolutional neural network (CNN) is designed and trained. The publically available MESSIDOR and Kaggle datasets are used to train the network and evaluate its performance. The centers of the fovea and the OD in each image were marked by expert graders as the ground truth. The proposed method achieves an accuracy of 97%, 96.7% for the detection of the OD center and 96.6%, 95.6% for the detection of the foveal center of the MESSIDOR and Kaggle test sets respectively. Our promising results demonstrate the excellent performance of the proposed CNNs in simultaneously detecting the centers of both the fovea and OD without human intervention or handcrafted features. Moreover, we can localize the landmarks of an image in 0.007s. This approach could be used as a crucial part of automated diagnosis systems for better management of eye disease. © 2017 The Author(s)","Convlutional neural networks; Diabetes; Fovea detection; Optic disc detection","Convolution; Medical problems; Neural networks; Automated diagnosis system; Automatic diagnosis; Convolutional neural network; Fovea detections; Learning techniques; Optic disc detections; Regression problem; Simultaneous detection; Diagnosis; accuracy; Article; artificial neural network; convolutional neural network; eye fundus; human; image enhancement; learning algorithm; optic disk; perceptron; priority journal; retina fovea; signal detection",2-s2.0-85029711683
"Penthia T., Panda A.K., Sarangi S.K.","Implementing dynamic evolution control approach for DC-link voltage regulation of superconducting magnetic energy storage system",2018,"International Journal of Electrical Power and Energy Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028602771&doi=10.1016%2fj.ijepes.2017.08.022&partnerID=40&md5=61db45206fb1683262e6b6decfa11c1f","A Dynamic Evolution Control (DEC) scheme for the Superconducting Magnetic Energy Storage (SMES) system is presented in this article. The DC-link voltage of Power Converter Unit (PCU) is strictly regulated by the proposed control scheme irrespective of load transients. In SMES system, the PCU interfaces the SMES magnet and the AC system in order to give an efficient power exchange, and high quality power flow in the grid. Especially, this paper focuses on power quality improvement, and homogeneous voltage distribution & AC loss reduction across the magnet by achieving excellent DC-link voltage regulation. The harmonic components of magnet current are analyzed which are responsible for AC losses. It has been observed that the 3rd, 4th, 5th, 6th and 7th order harmonic components of the magnet current are significantly reduced. Particularly, a homogeneous voltage profile and less distorted magnet current are attained using the control scheme. The system supply current is found almost balanced, and its Total Harmonic Distortion (THD) is found well below 5%. Moreover, the control performance of DEC scheme is compared with that of the Proportional-Integral (PI) control technique. The proposed system is validated both in MATLAB/SIMULINK and real-time environment using a digital signal processor (dSPACE1104). © 2017 Elsevier Ltd","AC loss reduction; Dynamic evolution control algorithm; Magnet voltage distribution; Power quality; Superconducting magnetic energy storage; System stability","Digital signal processors; Electric energy storage; Electric load flow; Energy storage; Harmonic analysis; Magnetic storage; Magnetism; Magnets; Power quality; Signal processing; Superconducting cables; Superconducting devices; Superconducting magnets; System stability; Two term control systems; Voltage distribution measurement; Voltage regulators; AC loss; Dynamic evolution controls; Proportional-integral control; Superconducting magnetic energy storage system; Superconducting Magnetic Energy Storage systems; Superconducting magnetic energy storages; Total harmonic distortion (THD); Voltage distribution; Quality control",2-s2.0-85028602771
"Stout Q.F.","Weighted L∞ isotonic regression",2018,"Journal of Computer and System Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029510966&doi=10.1016%2fj.jcss.2017.09.001&partnerID=40&md5=cad6e3fb33024a82ee409039556423dd","Algorithms are given for determining weighted L∞ isotonic regressions satisfying order constraints given by a directed acyclic graph with n vertices and m edges. An Θ(mlog⁡n) algorithm is given, but it uses parametric search, so a practical approach is introduced, based on calculating prefix solutions. For linear and tree orderings it yields isotonic and unimodal regressions in Θ(nlog⁡n) time. Practical algorithms are given for when the values are constrained to a specified set, and when the number of different weights, or different values, is ≪n. We also give a simple randomized algorithm taking Θ(mlog⁡n) expected time. L∞ isotonic regressions are not unique, so we examine properties of the regressions an algorithm produces. In this regard the prefix approach is superior to algorithms, such as parametric search and the randomized algorithm, which are based on feasibility tests. © 2017 Elsevier Inc.","Dag; Isotonic regression; L∞; Linear order; Monotonic; Tree; Unimodal","Directed graphs; Forestry; Graph theory; Regression analysis; Isotonic regression; Linear order; Monotonic; Tree; Unimodal; Parameter estimation",2-s2.0-85029510966
"Belhaj S., Ben Kahla H., Dridi M., Moakher M.","Blind image deconvolution via Hankel based method for computing the GCD of polynomials",2018,"Mathematics and Computers in Simulation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028802052&doi=10.1016%2fj.matcom.2017.07.008&partnerID=40&md5=fa71b716c7525015630ff588f1e7e359","In this paper we present an algorithm, that is based on computing approximate greatest common divisors (GCD) of polynomials, for solving the problem of blind image deconvolution. Specifically, we design a specialized algorithm for computing the GCD of bivariate polynomials corresponding to z-transforms of blurred images to recover the original image. The new algorithm is based on the fast GCD algorithm for univariate polynomials in which the successive transformation matrices are upper triangular Toeplitz matrices. The complexity of our algorithm is O(n2log(n)) where the size of blurred images is n×n. All algorithms have been implemented in Matlab and experimental results with synthetically blurred images are included to illustrate the effectiveness of our approach. © 2017 International Association for Mathematics and Computers in Simulation (IMACS)","Approximate GCD; Blind image deconvolution; Fast Fourier transform; Hankel matrix; Triangular Toeplitz inversion","Computational complexity; Fast Fourier transforms; Linear transformations; MATLAB; Matrix algebra; Polynomial approximation; Polynomials; Z transforms; Approximate gcd; Approximate greatest common divisors; Bivariate polynomials; Blind image deconvolution; Hankel matrix; Toeplitz inversions; Toeplitz matrices; Transformation matrices; Deconvolution",2-s2.0-85028802052
"Buonocore A., Nobile A.G., Pirozzi E.","Generating random variates from PDF of Gauss–Markov processes with a reflecting boundary",2018,"Computational Statistics and Data Analysis",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029849809&doi=10.1016%2fj.csda.2017.08.008&partnerID=40&md5=3218a8ced9158478166d7dd50defc8fc","Algorithms to generate random variates from probability density function of Gauss–Markov processes restricted by special lower reflecting boundary are formulated. They are essentially obtained by means of discretizations of stochastic equations or via acceptance–rejection methods. Particular attention is dedicated to restricted Wiener and Ornstein–Uhlenbeck processes. © 2017 Elsevier B.V.","Acceptance–Rejection method; Inverse transform method; Restricted Wiener and Ornstein–Uhlenbeck processes","Inverse problems; Inverse transforms; Markov processes; Stochastic systems; Discretizations; Inverse transform method; Random variates; Reflecting boundary; Rejection methods; Stochastic equations; Probability density function",2-s2.0-85029849809
"Shayesteh E., Gayme D.F., Amelin M.","System reduction techniques for storage allocation in large power systems",2018,"International Journal of Electrical Power and Energy Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027683518&doi=10.1016%2fj.ijepes.2017.08.007&partnerID=40&md5=76233491f23b00660d5a2a6664bbe77a","Semi-Definite Relaxation (SDR) techniques for AC optimal power flow (OPF) have recently been proposed as a means of obtaining a provably global optimal solution for many IEEE benchmark power systems. Solving the resulting semi-definite programs (SDP) can, however, be computationally intensive. Therefore new algorithms and techniques that enable more efficient computations are needed to extend the applicability of SDP based AC OPF algorithms to very large power networks. This paper proposes a three-stage algorithm for AC OPF based storage placement in large power systems. The first step involves network reduction whereby a small equivalent system that approximates the original power network is obtained. The AC OPF problem for this equivalent system is then solved by applying an SDR to the non-convex problem. Finally, the results from the reduced system are transferred to the original system using a set of repeating optimizations. The efficacy of the algorithm is tested through case studies using two IEEE benchmark systems and comparing the solutions obtained to those of DC OPF based storage allocation. The simulation results demonstrate that the proposed algorithm produces more accurate results than the DC OPF based algorithm. © 2017 Elsevier Ltd","Equivalent power system; Large power system planning; Optimal Power Flow (OPF); Semi-Definite Programming (SDP); Storage allocation","Acoustic generators; Electric load flow; Electric network analysis; Electric power transmission networks; Storage allocation (computer); Ac optimal power flows; Equivalent power system; Global optimal solutions; Large power systems; Optimal power flows; Semi-definite program (SDP); Semi-definite programming; Semidefinite relaxation; Optimization",2-s2.0-85027683518
"Liddy J.J., Haddad J.M.","Evenly spaced Detrended Fluctuation Analysis: Selecting the number of points for the diffusion plot",2018,"Physica A: Statistical Mechanics and its Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030569714&doi=10.1016%2fj.physa.2017.08.099&partnerID=40&md5=ab6c671a7af9c128caa16dc74900a2e4","Detrended Fluctuation Analysis (DFA) has become a widely-used tool to examine the correlation structure of a time series and provided insights into neuromuscular health and disease states. As the popularity of utilizing DFA in the human behavioral sciences has grown, understanding its limitations and how to properly determine parameters is becoming increasingly important. DFA examines the correlation structure of variability in a time series by computing α, the slope of the logSD–logn diffusion plot. When using the traditional DFA algorithm, the timescales, n, are often selected as a set of integers between a minimum and maximum length based on the number of data points in the time series. This produces non-uniformly distributed values of n in logarithmic scale, which influences the estimation of α due to a disproportionate weighting of the long-timescale regions of the diffusion plot. Recently, the evenly spaced DFA and evenly spaced average DFA algorithms were introduced. Both algorithms compute α by selecting k points for the diffusion plot based on the minimum and maximum timescales of interest and improve the consistency of α estimates for simulated fractional Gaussian noise and fractional Brownian motion time series. Two issues that remain unaddressed are (1) how to select k and (2) whether the evenly-spaced DFA algorithms show similar benefits when assessing human behavioral data. We manipulated k and examined its effects on the accuracy, consistency, and confidence limits of α in simulated and experimental time series. We demonstrate that the accuracy and consistency of α are relatively unaffected by the selection of k. However, the confidence limits of α narrow as k increases, dramatically reducing measurement uncertainty for single trials. We provide guidelines for selecting k and discuss potential uses of the evenly spaced DFA algorithms when assessing human behavioral data. © 2017 Elsevier B.V.","Detrended Fluctuation Analysis; Diffusion plot; Even spacing; Gait variability; Method comparison","Behavioral research; Brownian movement; Diffusion; Gaussian noise (electronic); Scales (weighing instruments); Social sciences; Time series; Uncertainty analysis; Correlation structure; Detrended fluctuation analysis; Even spacing; Fractional brownian motion; Fractional Gaussian noise; Gait variability; Measurement uncertainty; Method comparison; Time series analysis",2-s2.0-85030569714
"Li C.-J., Xie L.-L., Du W.-B., Li H.-D., Bao H.","Curve and surface fitting models based on the diagonalizable differential systems",2018,"Journal of Computational and Applied Mathematics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020715970&doi=10.1016%2fj.cam.2017.04.037&partnerID=40&md5=fcb94ec7216302af095160fa74e3789b","Curve and surface fitting is an important problem in computer aided geometric design, including many methods, such as the B-spline method, the NURBS method and so on. However, many curves and surfaces in the natural or engineering fields need to be described by differential equations. In this paper, we propose a new curve and surface fitting method based on the homogeneous linear differential systems. In order to approximate general curves or surfaces well, the diagonalizable differential systems with variable coefficients are adopted, which have explicit solutions. The fitting algorithms are presented for curves and surfaces from discrete points. Some numerical examples show that the two algorithms can obtain good fitting accuracy as the B-spline method. © 2017 Elsevier B.V.","B-spline; Curve fitting; Differential system; Explicit solution; Surface fitting","Computer aided design; Differential equations; Fiber optic sensors; Interpolation; Numerical methods; Splines; B splines; Computer aided geometric designs; Curve and surface fittings; Differential systems; Explicit solutions; Linear differential systems; Surface fitting; Variable coefficients; Curve fitting",2-s2.0-85020715970
"Zhao Y., Zhao Y., Zhao C.","A novel algebraic solution for moving target localization in multi-transmitter multi-receiver passive radar",2018,"Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029786557&doi=10.1016%2fj.sigpro.2017.09.014&partnerID=40&md5=83b9881af91bd25347add59720420918","This paper investigates the problem of locating a moving target using a passive radar system with multiple transmitters and multiple receivers. The bistatic range and bistatic range rate between each transmitter and receiver are used as the measurements. A novel algebraic solution employing two-step weighted least squares (2WLS) minimizations is proposed. In the first step, the measurement equations are linearized by introducing multiple additional parameters and a WLS minimization is used to obtain a rough estimate; then in the second step, the known relation between the additional parameters and the target location parameters is utilized to refine the estimate. Theoretical accuracy analysis indicates that the proposed algorithm achieves the Cramer-Row lower bound, and Monte-Carlo simulations demonstrate that the proposed algorithm outperforms existing algorithms. © 2017 Elsevier B.V.","Bistatic range; Bistatic range rate; Passive radar; Target localization; Two-step weighted least squares","Algebra; Intelligent systems; Monte Carlo methods; Radar signal processing; Radar systems; Transmitters; Bistatic range; Measurement equations; Moving target localization; Multiple transmitters; Passive radars; Target localization; Transmitter and receiver; Weighted least squares; Radar",2-s2.0-85029786557
"Pagel C., Ramnarayan P., Ray S., Peters M.J.","Development and implementation of a real time statistical control method to identify the start and end of the winter surge in demand for paediatric intensive care",2018,"European Journal of Operational Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994164422&doi=10.1016%2fj.ejor.2016.08.023&partnerID=40&md5=a7be687f8ad649c7d50869d253896e4d","Winter surge management in intensive care is hampered by the annual variability in the winter surge. We aimed to develop a real-time monitoring system that could promptly identify the start, and accurately predict the end, of the winter surge in a paediatric intensive care (PIC) setting. We adapted a statistical process control method from the stock market called “Bollinger bands” that compares current levels of demand for PIC services to thresholds based on the medium term average demand. Algorithms to identify the start and end of the surge were developed for a specific PIC service: the North Thames Children's Acute Transport Service (CATS) using eight winters of data (2005–12) to tune the algorithms and one winter to test the final method (2013/14). The optimal Bollinger band thresholds were 1.2 and 1 standard deviations above and below a 41-day moving average of demand respectively. A simple linear model was found to predict the end of the surge and overall demand volume as soon as the start had been identified. Applying the method to the validation winter of 2013/14 showed excellent performance, with the surge identified from 18th November 2013 to 4th January 2014. An Excel tool running the algorithms has been in use within CATS since September 2014. There were three factors which facilitated the successful implementation of this tool: the perceived problem was pressing and identified by the clinical team; there was close clinical engagement throughout and substantial effort was made to develop an easy-to-use Excel tool for sustainable use. © 2016 Elsevier B.V.","Analytics; Emergency medical services; Implementation; OR in health services; Statistical process control","Electronic trading; Emergency services; Pediatrics; Process control; Analytics; Annual variability; Emergency medical services; Implementation; OR in health services; Real time monitoring system; Standard deviation; Statistical control; Statistical process control",2-s2.0-84994164422
"Vann J.M., Karnowski T.P., Kerekes R., Cooke C.D., Anderson A.L.","A Dimensionally Aligned Signal Projection for Classification of Unintended Radiated Emissions",2018,"IEEE Transactions on Electromagnetic Compatibility",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018648873&doi=10.1109%2fTEMC.2017.2692962&partnerID=40&md5=83e19b09033a24767f2c33858e23d572","Characterization of unintended radiated emissions (URE) from electronic devices plays an important role in many research areas from electromagnetic interference to nonintrusive load monitoring to information system security. URE can provide insights for applications ranging from load disaggregation and energy efficiency to condition-based maintenance of equipment-based upon detected fault conditions. URE characterization often requires subject matter expertise to tailor transforms and feature extractors for the specific electrical devices of interest. We present a novel approach, named dimensionally aligned signal projection (DASP), for projecting aligned signal characteristics that are inherent to the physical implementation of many commercial electronic devices. These projections minimize the need for an intimate understanding of the underlying physical circuitry and significantly reduce the number of features required for signal classification. We present three possible DASP algorithms that leverage frequency harmonics, modulation alignments, and frequency peak spacings, along with a two-dimensional image manipulation method for statistical feature extraction. To demonstrate the ability of DASP to generate relevant features from URE, we measured the conducted URE from 14 residential electronic devices using a 2 MS/s collection system. A linear discriminant analysis classifier was trained using DASP generated features and was blind tested resulting in a greater than 90% classification accuracy for each of the DASP algorithms and an accuracy of 99.1% when DASP features are used in combination. Furthermore, we show that a rank reduced feature set of the combined DASP algorithms provides a 98.9% classification accuracy with only three features and outperforms a set of spectral features in terms of general classification as well as applicability across a broad number of devices. © 1964-2012 IEEE.","Harmonic; linear discriminant analysis (LDA); modulation; nonintrusive load monitoring (NILM); unintended radiated emissions (URE)","Computerized tomography; Discriminant analysis; Electromagnetic pulse; Electron devices; Electronic equipment; Energy efficiency; Feature extraction; Thermoelectric equipment; Classification accuracy; Commercial electronics; Condition based maintenance; Information system security; Linear discriminant analysis; Nonintrusive load monitoring; Statistical feature extractions; Two dimensional image manipulation method; Classification (of information)",2-s2.0-85018648873
"Chang C.-Y., Kuo S.M., Huang C.-W.","Secondary path modeling for narrowband active noise control systems",2018,"Applied Acoustics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032750588&doi=10.1016%2fj.apacoust.2017.10.026&partnerID=40&md5=feb99877f6242e57e33e5c5a60ba6307","This work examines the performance of both offline and online secondary path modeling algorithms that are used in narrowband active noise control (NANC) systems. Theoretical analysis reveals that disturbances that are sensed by error sensors reduce the convergence rate and accuracy of adaptive system identification. In a parallel-structure narrowband active noise control system, a filterbank is applied to partition the full-band excitation and error signals to utilize an independent and lower-order secondary-path modeling filter for every channel. This method increases convergence speed and modeling accuracy. The results of an analysis and improved performance are confirmed by simulations in which measured transfer functions are used. © 2017 Elsevier Ltd","Adaptive system; Convergence; Filterbank; Identification accuracy; Narrowband active noise control; Secondary path modeling","Acoustic variables control; Active noise control; Adaptive systems; Control systems; Filter banks; Online systems; Convergence; Convergence rates; Identification accuracy; Narrow bands; Narrowband active noise control systems; Online secondary-path modeling; Parallel structures; Secondary path modeling; Adaptive control systems",2-s2.0-85032750588
"Nagata Y.","Random partial neighborhood search for the post-enrollment course timetabling problem",2018,"Computers and Operations Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029677495&doi=10.1016%2fj.cor.2017.09.014&partnerID=40&md5=bcb38900c0a3b6c9edec0f13f118179e","In this study, we present a local search-based algorithm for the post-enrollment-based course timetabling problem, which incorporates a mechanism for adapting the neighborhood size during the course of the search. At each iteration, the neighborhood size is changed simply by constructing a random partial neighborhood, which is defined as a random subset of the entire neighborhood. The main reason for using a random partial neighborhood is to control the trade-off between exploration and exploitation during search, and two updating strategies are considered for changing the neighborhood size. The proposed algorithms were tested using well-known benchmark sets and the results obtained were highly competitive with those produced by the leading solvers developed for these benchmark sets. © 2017 Elsevier Ltd","Candidate list; Partial neighborhood; Tabu search; Timetabling","Economic and social effects; Iterative methods; Optimization; Tabu search; Candidate list; Course timetabling; Exploration and exploitation; Neighborhood search; Neighborhood size; Partial neighborhood; Timetabling; Updating strategy; Scheduling",2-s2.0-85029677495
"Tomic S., Beko M.","A bisection-based approach for exact target localization in NLOS environments",2018,"Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029803772&doi=10.1016%2fj.sigpro.2017.09.019&partnerID=40&md5=5fd03e7dfd9a67cf4d08a8c84d38623c","This work addresses the range-based target localization problem in adverse non-line-of-sight (NLOS) environments. We start by deriving the maximum likelihood (ML) estimator from the measurement model, since it is asymptotically efficient. However, this estimator is highly non-convex and difficult to solve directly. Hence, we convert the localization problem into a generalized trust region sub-problem (GTRS) framework. Although still non-convex in general, the derived estimator is strictly decreasing over a readily obtained interval, and thus, can be solved exactly by a bisection procedure. In huge contrast to existing algorithms, which either require the knowledge about the magnitude of the NLOS bias or to a priori distinguish between line-of-sight (LOS) and NLOS links, the new one does not require such prerequisites. Also, the computational complexity of the proposed algorithm is linear in the number of reference nodes, unlike the majority of existing ones. Our simulation results show that the new algorithm possesses a steady NLOS bias mitigation capacity and that it represents an excellent alternative in the sense of the trade off between accuracy and complexity. To be more specific, it not only matches the performance of existing methods (majority of which significantly more computationally complex) but outperforms them in general. Moreover, the performance of the proposed algorithm is validated through real-indoor experimental data. © 2017 Elsevier B.V.","Generalized trust region sub-problem (GTRS); Non-line-of-sight (NLOS); Range-based localization; Target localization; Wireless sensor network (WSN)","Complex networks; Economic and social effects; Maximum likelihood; Maximum likelihood estimation; Asymptotically efficient; Localization problems; Maximum likelihood estimator; Non-line-of-sight environments; Nonline of sight; Range-based localizations; Sub-problems; Target localization; Wireless sensor networks",2-s2.0-85029803772
"Jonnalagadda A., Kuppusamy L.","A cooperative game framework for detecting overlapping communities in social networks",2018,"Physica A: Statistical Mechanics and its Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030833439&doi=10.1016%2fj.physa.2017.08.111&partnerID=40&md5=670b033a8888217feee018d74d630d70","Community detection in social networks is a challenging and complex task, which received much attention from researchers of multiple domains in recent years. The evolution of communities in social networks happens merely due to the self-interest of the nodes. The interesting feature of community structure in social networks is the multi membership of the nodes resulting in overlapping communities. Assuming the nodes of the social network as self-interested players, the dynamics of community formation can be captured in the form of a game. In this paper, we propose a greedy algorithm, namely, Weighted Graph Community Game (WGCG), in order to model the interactions among the self-interested nodes of the social network. The proposed algorithm employs the Shapley value mechanism to discover the inherent communities of the underlying social network. The experimental evaluation on the real-world and synthetic benchmark networks demonstrates that the performance of the proposed algorithm is superior to the state-of-the-art overlapping community detection algorithms. © 2017 Elsevier B.V.","Coalitional game; Game theory; Overlapping community detection; Shapley value; Weighted graph game","Benchmarking; Graph theory; Graphic methods; Population dynamics; Coalitional game; Community detection; Community structures; Experimental evaluation; Overlapping communities; Overlapping community detections; Shapley value; Weighted graph; Game theory",2-s2.0-85030833439
"Zhang J., Hong W.","Equivalent system model for the calibration of polarimetric SAR under Faraday rotation conditions",2018,"Science China Information Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028748998&doi=10.1007%2fs11432-016-9032-6&partnerID=40&md5=3daf99886edf52e8747df8af2dcada8c","An equivalent system model (ESM) that can be used to calibrate a SAR system affected by both the effect of system errors and the Faraday rotation (FR) is proposed. This ESM contains only system-distortion-like parameters but includes a distortion matrix (DM) that is identical to the original, which contains the effects of both the system errors and the Faraday rotation angle (FRA). With this model, the conventional distributed-target-based (DT-based) algorithms which have not taken FR effect into account are readily applicable. The conditions on FRA for the successful application of DT-based algorithms are studied, and the results suggest that reliable estimates can be obtained for a well-designed system whose true system crosstalk level is lower than −20 dB provided that the mean FRA at the calibration site is within ±15° and that the FRA can be suitably modeled as Gaussian. Thus, the requirements on the crosstalk level or the FRA that are commonly employed in other calibration methods designed for data affected by FR are relaxed. © 2017, Science China Press and Springer-Verlag GmbH Germany.","calibration; distibuted target (DT); Faraday rotation (FR); polarimetry; synthetic aperture radar (SAR)","Calibration; Crosstalk; Polarimeters; Rotation; Calibration method; Cross-talk levels; distibuted target (DT); Distortion matrices; Distributed target; Equivalent system; Faraday rotation angle; Reliable estimates; Synthetic aperture radar",2-s2.0-85028748998
"Vo Q.N., Kim S.H., Yang H.J., Lee G.","Binarization of degraded document images based on hierarchical deep supervised network",2018,"Pattern Recognition",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028975652&doi=10.1016%2fj.patcog.2017.08.025&partnerID=40&md5=b6151be8623018f69b924e7e25d7f874","The binarization of degraded document images is a challenging problem in terms of document analysis. Binarization is a classification process in which intra-image pixels are assigned to either of the two following classes: foreground text and background. Most of the algorithms are constructed on low-level features in an unsupervised manner, and the consequent disenabling of full utilization of input-domain knowledge considerably limits distinguishing of background noises from the foreground. In this paper, a novel supervised-binarization method is proposed, in which a hierarchical deep supervised network (DSN) architecture is learned for the prediction of the text pixels at different feature levels. With higher-level features, the network can differentiate text pixels from background noises, whereby severe degradations that occur in document images can be managed. Alternatively, foreground maps that are predicted at lower-level features present a higher visual quality at the boundary area. Compared with those of traditional algorithms, binary images generated by our architecture have cleaner background and better-preserved strokes. The proposed approach achieves state-of-the-art results over widely used DIBCO datasets, revealing the robustness of the presented method. © 2017 Elsevier Ltd","Convolutional neural network; Document analysis; Document image binarization","Bins; Image analysis; Network architecture; Neural networks; Pixels; Text processing; Classification process; Convolutional neural network; Degraded document images; Document analysis; Document image binarization; Domain knowledge; Low-level features; Supervised network; Binary images",2-s2.0-85028975652
"Wang Z., Zhang H., Lu T., Sun Y., Liu X.","A new range-free localisation in wireless sensor networks using support vector machine",2018,"International Journal of Electronics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026414210&doi=10.1080%2f00207217.2017.1357198&partnerID=40&md5=210494bab8226ab572c1cb69d6d6f308","Location information of sensor nodes is of vital importance for most applications in wireless sensor networks (WSNs). This paper proposes a new range-free localisation algorithm using support vector machine (SVM) and polar coordinate system (PCS), LSVM-PCS. In LSVM-PCS, two sets of classes are first constructed based on sensor nodes’ polar coordinates. Using the boundaries of the defined classes, the operation region of WSN field is partitioned into a finite number of polar grids. Each sensor node can be localised into one of the polar grids by executing two localisation algorithms that are developed on the basis of SVM classification. The centre of the resident polar grid is then estimated as the location of the sensor node. In addition, a two-hop mass-spring optimisation (THMSO) is also proposed to further improve the localisation accuracy of LSVM-PCS. In THMSO, both neighbourhood information and non-neighbourhood information are used to refine the sensor node location. The results obtained verify that the proposed algorithm provides a significant improvement over existing localisation methods. © 2017 Informa UK Limited, trading as Taylor & Francis Group.","mass-spring optimisation; node localisation; polar coordinate system; support vector machine; Wireless sensor networks","Location; Optimization; Support vector machines; Wireless sensor networks; Location information; Node localisation; Operation regions; Optimisations; Polar coordinate; Polar coordinate systems; SVM classification; Wireless sensor network (WSNs); Sensor nodes",2-s2.0-85026414210
"Hao Y.-X., Li C.-J.","The C1 and C2 quasi-Plateau problems",2018,"Journal of Computational and Applied Mathematics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020128360&doi=10.1016%2fj.cam.2017.04.039&partnerID=40&md5=8f83de78ce77572e7fbe0594d2f7c31a","In this paper, we study the Ck quasi-Plateau problem: to find the parametric surface of minimal area defined on a rectangular parametric domain among all the surfaces which are Ck continuous on the border (k=1,2). An approach is proposed based on the Coons surface and the MRA (Multi-Resolution Analysis) formed by the B-spline of orders 3 and 4. The Coons surface is constructed firstly to satisfy the prescribed border conditions. Then replacing the area functional with the Dirichlet functional and using MRA, the problem reduces into solving a system of linear equations. The linear equations have simple and sparse structure. Finally, the method is concluded into six algorithms according to the different boundary conditions. Examples are provided to illustrate that the proposed method is effective and flexible. © 2017 Elsevier B.V.","Dirichlet functional; Minimal surface; Multi-resolution analysis","Linear equations; Multiresolution analysis; Coons surface; Different boundary condition; Dirichlet functional; Minimal area; Minimal surfaces; Parametric domains; Parametric surfaces; System of linear equations; Problem solving",2-s2.0-85020128360
"Xu Y., Shan S., Qiu Z., Jia Z., Shen Z., Wang Y., Shi M., Chang E.I.-C.","End-to-end subtitle detection and recognition for videos in East Asian languages via CNN ensemble",2018,"Signal Processing: Image Communication",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032028544&doi=10.1016%2fj.image.2017.09.013&partnerID=40&md5=798dd9d57cddd283cd33cac91ce2dda0","In this paper, we propose an innovative end-to-end subtitle detection and recognition system for videos in East Asian languages. Our end-to-end system consists of multiple stages. Subtitles are firstly detected by a novel image operator based on the sequence information of consecutive video frames. Then, an ensemble of Convolutional Neural Networks (CNNs) trained on synthetic data is adopted for detecting and recognizing East Asian characters. Finally, a dynamic programming approach leveraging language models is applied to constitute results of the entire body of text lines. The proposed system achieves average end-to-end accuracies of 98.2% and 98.3% on 40 videos in Simplified Chinese and 40 videos in Traditional Chinese respectively, which is a significant outperformance of other existing methods. The near-perfect accuracy of our system dramatically narrows the gap between human cognitive ability and state-of-the-art algorithms used for such a task. © 2017 Elsevier B.V.","Convolutional neural networks; East Asian language; Subtitle text detection; Subtitle text recognition; Synthetic training data; Video sequence information","Convolution; Dynamic programming; Neural networks; Asian languages; Convolutional neural network; Synthetic training data; Text detection; Text recognition; Video sequences; Character recognition",2-s2.0-85032028544
"Yang B., Kostková J., Flusser J., Suk T., Bujack R.","Rotation invariants of vector fields from orthogonal moments",2018,"Pattern Recognition",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032255391&doi=10.1016%2fj.patcog.2017.09.004&partnerID=40&md5=b86b79166d354fbf4d7c0e1648328154","Vector field images are a type of new multidimensional data that appear in many engineering areas. Although the vector fields can be visualized as images, they differ from graylevel and color images in several aspects. To analyze them, special methods and algorithms must be originally developed or substantially adapted from the traditional image processing area. In this paper, we propose a method for the description and matching of vector field patterns under an unknown rotation of the field. Rotation of a vector field is so-called total rotation, where the action is applied not only on the spatial coordinates but also on the field values. Invariants of vector fields with respect to total rotation constructed from orthogonal Gaussian–Hermite moments and Zernike moments are introduced. Their numerical stability is shown to be better than that of the invariants published so far. We demonstrate their usefulness in a real world template matching application of rotated vector fields. © 2017 Elsevier Ltd","Gaussian–Hermite moments; Invariants; Numerical stability; Total rotation; Vector field; Zernike moments","Convergence of numerical methods; Image processing; Rotation; Template matching; Hermite moment; Invariants; Multidimensional data; Orthogonal moments; Rotation invariant; Spatial coordinates; Vector fields; Zernike moments; Vectors",2-s2.0-85032255391
"Aytekin C., Iosifidis A., Gabbouj M.","Probabilistic saliency estimation",2018,"Pattern Recognition",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032271491&doi=10.1016%2fj.patcog.2017.09.023&partnerID=40&md5=00ef3b0274ba244bef8e3b2d2f563ff9","In this paper, we model the salient object detection problem under a probabilistic framework encoding the boundary connectivity saliency cue and smoothness constraints into an optimization problem. We show that this problem has a closed form global optimum solution, which estimates the salient object. We further show that along with the probabilistic framework, the proposed method also enjoys a wide range of interpretations, i.e. graph cut, diffusion maps and one-class classification. With an analysis according to these interpretations, we also find that our proposed method provides approximations to the global optimum to another criterion that integrates local/global contrast and large area saliency cues. The proposed unsupervised approach achieves mostly leading performance compared to the state-of-the-art unsupervised algorithms over a large set of salient object detection datasets including around 17k images for several evaluation metrics. Furthermore, the computational complexity of the proposed method is favorable/comparable to many state-of-the-art unsupervised techniques. © 2017 Elsevier Ltd","Diffusion maps; One-class classification; Probabilistic model; Saliency; Salient object detection; Spectral graph cut","Graphic methods; Object recognition; Optimization; Diffusion maps; Graph cut; One-class Classification; Probabilistic modeling; Saliency; Salient object detection; Object detection",2-s2.0-85032271491
"Wang X., Song H., Cui H.","Pedestrian abnormal event detection based on multi-feature fusion in traffic video",2018,"Optik",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031009054&doi=10.1016%2fj.ijleo.2017.09.104&partnerID=40&md5=b54a3f51a0d2d757f964df66c4bd5e62","Pedestrian abnormal event detection is an active research area to improve traffic safety for intelligent transportation systems (ITS). This paper proposes an efficient method to automatically detect and track far-away pedestrians in traffic video to determine the abnormal behavior events. Firstly, pedestrian features are extracted by the multi-feature fusion method. Then, the similar features in current frame of all candidate objects are matched with the characteristic information of pedestrians in the previous frame which is considered as a template. Finally, pedestrian trajectory analysis algorithms are employed on the tracking trajectories and the motion information is attained, which can realize the early classification warning of pedestrian events. Experimental results on different traffic scenes in practice demonstrate that this method has good robustness in complex traffic. Moreover, the proposed method performs better compared with some other methods. © 2017 Elsevier GmbH","Abnormal behavior event; Event classification; Multi-feature fusion; Pedestrian trajectory analysis","Classification (of information); Image processing; Intelligent systems; Intelligent vehicle highway systems; Trajectories; Abnormal behavior; Abnormal event detections; Event classification; Intelligent transportation systems; Motion information; Multi-feature fusion; Pedestrian trajectories; Tracking trajectory; Pedestrian safety",2-s2.0-85031009054
"Gaudioso M., Giallombardo G., Mukhametzhanov M.","Numerical infinitesimals in a variable metric method for convex nonsmooth optimization",2018,"Applied Mathematics and Computation",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026870535&doi=10.1016%2fj.amc.2017.07.057&partnerID=40&md5=6dc1df37c26286cb9fea89b671623ef1","The objective of the paper is to evaluate the impact of the infinity computing paradigm on practical solution of nonsmooth unconstrained optimization problems, where the objective function is assumed to be convex and not necessarily differentiable. For such family of problems, the occurrence of discontinuities in the derivatives may result in failures of the algorithms suited for smooth problems. We focus on a family of nonsmooth optimization methods based on a variable metric approach, and we use the infinity computing techniques for numerically dealing with some quantities which can assume values arbitrarily small or large, as a consequence of nonsmoothness. In particular we consider the case, treated in the literature, where the metric is defined via a diagonal matrix with positive entries. We provide the computational results of our implementation on a set of benchmark test-problems from scientific literature. © 2017 Elsevier Inc.","Infinity computing; Nonsmooth optimization; Variable-metric methods","Benchmarking; Optimization; Bench-mark-test problems; Computational results; Computing techniques; Infinity computing; Nonsmooth optimization; Scientific literature; Unconstrained optimization problems; Variable metric methods; Numerical methods",2-s2.0-85026870535
"Xiong S., Mondal S., Ray A.","Detection of Thermoacoustic Instabilities Via Nonparametric Bayesian Markov Modeling of Time-Series Data",2018,"Journal of Dynamic Systems, Measurement and Control, Transactions of the ASME",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029762539&doi=10.1115%2f1.4037288&partnerID=40&md5=e5c04dc2bbec0de4a858efc2bf2ed5b3","Real-time detection and decision and control of thermoacoustic instabilities in confined combustors are challenging tasks due to the fast dynamics of the underlying physical process. The objective here is to develop a dynamic data-driven algorithm for detecting the onset of instabilities with short-length time-series data, acquired by available sensors (e.g., pressure and chemiluminescence), which will provide sufficient lead time for active decision and control. To this end, this paper proposes a Bayesian nonparametric method of Markov modeling for real-time detection of thermoacoustic instabilities in gas turbine engines; the underlying algorithms are formulated in the symbolic domain and the resulting patterns are constructed from symbolized pressure measurements as probabilistic finite state automata (PFSA). These PFSA models are built upon the framework of a (low-order) finitememory Markov model, called the D-Markov machine, where a Bayesian nonparametric structure is adopted for: (i) automated selection of parameters in D-Markov machines and (ii) online sequential testing to provide dynamic data-driven and coherent statistical analyses of combustion instability phenomena without solely relying on computationally intensive (physics-based) models of combustion dynamics. The proposed method has been validated on an ensemble of pressure time series from a laboratory-scale combustion apparatus. The results of instability prediction have been compared with those of other existing techniques. Copyright © 2018 by ASME.",,"Combustion; Dynamics; Gas turbines; Markov processes; Signal detection; Thermoacoustic engines; Thermoacoustics; Time series; Automated selection; Combustion instabilities; Non-parametric Bayesian; Nonparametric methods; Onset of instabilities; Probabilistic finite state automaton; Real-time detection; Thermoacoustic instability; Statistical tests",2-s2.0-85029762539
"Sadeghianpourhamami N., Refa N., Strobbe M., Develder C.","Quantitive analysis of electric vehicle flexibility: A data-driven approach",2018,"International Journal of Electrical Power and Energy Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029172313&doi=10.1016%2fj.ijepes.2017.09.007&partnerID=40&md5=a90c6e275c2e44966e0909d058a92a40","The electric vehicle (EV) flexibility, indicates to what extent the charging load can be coordinated (i.e., to flatten the load curve or to utilize renewable energy resources). However, such flexibility is neither well analyzed nor effectively quantified in literature. In this paper we fill this gap and offer an extensive analysis of the flexibility characteristics of 390k EV charging sessions and propose measures to quantize their flexibility exploitation. Our contributions include: (1) characterization of the EV charging behavior by clustering the arrival and departure time combinations that leads to the identification of type of EV charging behavior, (2) in-depth analysis of the characteristics of the charging sessions in each behavioral cluster and investigation of the influence of weekdays and seasonal changes on those characteristics including arrival, sojourn and idle times, and (3) proposing measures and an algorithm to quantitatively analyze how much flexibility (in terms of duration and amount) is used at various times of a day, for two representative scenarios. Understanding the characteristics of that flexibility (e.g., amount, time and duration of availability) and when it is used (in terms of both duration and amount) helps to develop more realistic price and incentive schemes in DR algorithms to efficiently exploit the offered flexibility or to estimate when to stimulate additional flexibility. © 2017 Elsevier Ltd","Electric vehicles; Flexibility quantization; Smart grid","Electric power transmission networks; Electric vehicles; Energy resources; Renewable energy resources; Vehicles; Additional flexibilities; Charging loads; Data-driven approach; Flexibility quantization; In-depth analysis; Incentive schemes; Seasonal changes; Smart grid; Smart power grids",2-s2.0-85029172313
"Berkholz C., Verbitsky O.","On the speed of constraint propagation and the time complexity of arc consistency testing",2018,"Journal of Computer and System Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029695061&doi=10.1016%2fj.jcss.2017.09.003&partnerID=40&md5=dac16cc20fbaf93fc20722a7ca01daa0","Establishing arc consistency on two relational structures is one of the most popular heuristics for the constraint satisfaction problem. We aim at determining the time complexity of arc consistency testing. The input structures G and H can be supposed to be connected colored graphs, as the general problem reduces to this particular case. We first observe the upper bound O(e(G)v(H)+v(G)e(H)), which implies the bound O(e(G)e(H)) in terms of the number of edges and the bound O((v(G)+v(H))3) in terms of the number of vertices. We then show that both bounds are tight as long as an arc consistency algorithm is based on constraint propagation (as all current algorithms are). Our lower bounds are based on examples of slow constraint propagation. We measure the speed of constraint propagation observed on a pair G,H by the size of a combinatorial proof that Spoiler wins the existential 2-pebble game on G,H. © 2017 Elsevier Inc.","Arc consistency; Constraint propagation; Constraint satisfaction problem; Existential 2-pebble game; Existential-positive two-variable logic; Time complexity","Computer networks; Systems science; Arc consistency; Constraint propagation; Existential 2-pebble game; Existential-positive two-variable logic; Time complexity; Constraint satisfaction problems",2-s2.0-85029695061
"Hamdi S., Abdallah A.B., Bedoui M.H.","A robust QRS complex detection using regular grammar and deterministic automata",2018,"Biomedical Signal Processing and Control",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030857302&doi=10.1016%2fj.bspc.2017.09.032&partnerID=40&md5=b9c29244c5b964e9443fea60fb2fed55","A novel approach is proposed for medical analysis and clinical decision support of the Electrocardiogram (ECG) signals based on the deterministic finite automata (DFA) with the addition of some requirements. This paper proves regular grammar is effective in the extraction of QRS complex and interpretation of ECG signals. The DFA will be used to represent a normalized QRS complex as a sequence of negative and positive peaks. A QRS is considered as a set of adjacent peaks that satisfy certain criteria of standard deviation and duration. The proposed method is applied on several kinds of ECG signals collected from the standard MIT-BIH arrhythmia database. Several metrics are calculated including QRS durations, RR distances and peak amplitudes. Furthermore, σRR and σQRS metrics were added to quantify RR distances regularity and QRS durations, respectively. Regular grammar with the addition of some requirements and deterministic automata proved functional for both biomedical signals and ECG signal diagnosis. The suggested method provided a sensitivity rate of 99.74% and the positive predictivity rate of 99.86%. The algorithm was compared to other works in the literature and the quality performance detection was compared with several algorithms tested and validated on the MIT-BIH database. A head-to-head comparison in terms of sensitivity and CPU runtime was provided with the wavelet method. © 2017 Elsevier Ltd","DFA; ECG; Grammar; QRS; R peak; RR; σQRS; σRR","Bioelectric phenomena; Complexation; Decision support systems; Diagnosis; Electrocardiography; Clinical decision support; Deterministic automata; Deterministic finite automata; Electrocardiogram signal; Grammar; QRS complex detection; Quality performance; R peak; Finite automata",2-s2.0-85030857302
"Cao Y., He Z., Yang J., Ye X., Cao Y.","A multi-scale non-uniformity correction method based on wavelet decomposition and guided filtering for uncooled long wave infrared camera",2018,"Signal Processing: Image Communication",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029481180&doi=10.1016%2fj.image.2017.08.013&partnerID=40&md5=7570975a3af646768f12ef0791125ec1","In uncooled long-wave infrared (LWIR) imaging systems, non-uniformity of the amplifier in readout circuit will generate significant noise in captured infrared images. This type of noise, if not eliminated, may manifest as vertical and horizontal strips in the raw image and human observers are particularly sensitive to these types of image artifacts. In this paper we propose an effective non-uniformity correction (NUC) method to remove strip noise without loss of fine image details. This multi-scale destriping method consists of two consecutive steps. Firstly, wavelet-based image decomposition is applied to separate the original input image into three individual scale levels: large, median and small scales. In each scale level, the extracted vertical image component contains strip noise and vertical-orientated image textures. Secondly, a novel multi-scale 1D guided filter is proposed to further separate strip noise from image textures in each individual scale level. More specifically, in the small scale level, we choose a small filtering window for guided filter to eliminate strip noise. On the contrary, a large filtering window is used to better preserve image details from blurring in large scale level. Our proposed algorithm is systematically evaluated using real-captured infrared images and the quantitative comparison results with the state-of-the-art destriping algorithms demonstrate that our proposed method can better remove the strip noise without blurring image fine details. © 2017","Destriping; Fixed pattern noise; Infrared imaging; Multi-scale; Non-uniformity correction","Infrared devices; Infrared imaging; Infrared radiation; Thermography (imaging); Wavelet analysis; Wavelet decomposition; Destriping; Fixed pattern noise; Longwave infrared; Multi-scale; Nonuniformity correction; Quantitative comparison; Read-out circuit; Wavelet-based images; Image texture",2-s2.0-85029481180
"Swärd J., Adalbjörnsson S.I., Jakobsson A.","Generalized sparse covariance-based estimation",2018,"Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029722145&doi=10.1016%2fj.sigpro.2017.09.010&partnerID=40&md5=2926ae8b082abcc5de7e9ffe85c86e20","In this work, we generalize the recent sparse iterative covariance-based estimator (SPICE) by extending the problem formulation to allow for different norm constraints on the signal and noise parameters in the covariance model. The resulting extended SPICE algorithm offers the same benefits as the regular SPICE algorithm, including being hyper-parameter free, but the choice of norms allows further control of the sparsity in the resulting solution. We also show that the proposed extension is equivalent to solving a penalized regression problem, providing further insight into the differences between the extended and original SPICE formulations. The performance of the method is evaluated for different choices of norms, indicating the preferable performance of the extended formulation as compared to the original SPICE algorithm. Finally, we introduce two implementations of the proposed algorithm, one gridless formulating for the sinusoidal case, resulting in a semi-definite programming problem, and one grid-based, for which an efficient implementation is given. © 2017 Elsevier B.V.","Convex optimization; Covariance fitting; Sparse reconstruction","Circuit simulation; Convex optimization; Iterative methods; Optimization; Covariance fitting; Covariance modeling; Efficient implementation; Extended formulations; Problem formulation; Semi-definite programming; Signal and noise parameters; Sparse reconstruction; Parameter estimation",2-s2.0-85029722145
"Rao S.D., Tylavsky D.J.","Theoretical convergence guarantees versus numerical convergence behavior of the holomorphically embedded power flow method",2018,"International Journal of Electrical Power and Energy Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028366815&doi=10.1016%2fj.ijepes.2017.08.018&partnerID=40&md5=6253eaedd51ed69233ccf811238f0155","The holomorphic embedding load flow method (HELM) is an application for solving the power-flow problem based on a novel method developed by Dr. Trias. The advantage of the method is that it comes with a theoretical guarantee of convergence to the high-voltage (operable) solution, if it exists, provided the equations are suitably framed. While theoretical convergence is guaranteed by Stahl's theorem, numerical convergence is not; it depends on the analytic continuation algorithm chosen. Since the holomorphic embedding method (HEM) has begun to find a broader range of applications (it has been applied to nonlinear structure-preserving network reduction, weak node identification and saddle-node bifurcation point determination), examining which algorithms provide the best numerical convergence properties, which do not, why some work and not others, and what can be done to improve these methods, has become important. The numerical Achilles heel of HEM is the calculation of the Padé approximant, which is needed to provide both the theoretical convergence guarantee and accelerated numerical convergence. In the past, only two ways of obtaining Padé approximants applied to the power series resulting from power-system-type problems have been discussed in detail: the matrix method and the Viskovatov method. This paper explores several methods of accelerating the convergence of these power series and/or providing analytic continuation and distinguishes between those that are backed by the theoretical convergence guarantee of Stahl's theorem (i.e., those computing Pade approximants), and those that are not. For methods that are consistent with Stahl's theoretical convergence guarantee, we identify which methods are computationally less expensive, which have better numerical performance and what remedies exist when these methods fail to converge numerically. © 2017 Elsevier Ltd",,"Computation theory; Electric load flow; Functional analysis; Numerical methods; Analytic continuation; Node identifications; Nonlinear structure; Numerical convergence; Numerical performance; Power flow problem; Saddle node bifurcation point; Theoretical guarantees; Convergence of numerical methods",2-s2.0-85028366815
"Nogueira T.P., Braga R.B., de Oliveira C.T., Martin H.","FrameSTEP: A framework for annotating semantic trajectories based on episodes",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030869758&doi=10.1016%2fj.eswa.2017.10.004&partnerID=40&md5=63b0edd48cfb10de24da890c0626c127","We are witnessing an increasing usage of location data by a variety of applications. Consequently, information systems are required to deal with large datasets containing raw data to build high level abstractions. Semantic Web technologies offer powerful representation tools for pervasive applications. The convergence of location-based services and Semantic Web standards allows an easier interlinking and annotation of trajectories. However, due to the wide range of requirements on modeling mobile object trajectories, it is important to define a high-level data model for representing trajectory episodes and contextual elements with multiple levels of granularity and different options to represent spatial and temporal extents, as well as to express quantitative and qualitative semantic descriptions. In this article, we focus on modeling mobile object trajectories in the context of Semantic Web. First, we introduce a new version of the Semantic Trajectory Episodes (STEP) ontology to represent generic spatiotemporal episodes. Then, we present FrameSTEP as a new framework for annotating semantic trajectories based on episodes. As a result, we combine our ontology, which can represent spatiotemporal phenomena at different levels of granularity, with annotation algorithms, which allow to create instances of our model. The proposed spatial annotation algorithm explores the Linked Open Data cloud and OpenStreetMap tags to find relevant types of spatial features in order to describe the environment where the trajectory took place. Our framework can guide the development of future expert systems in trajectory analysis. It enables reasoning about knowledge gathered from large trajectory data and linked datasets in order to create several intelligent services. © 2017 Elsevier Ltd","Semantic web; Trajectory annotation; Trajectory modeling","Expert systems; Location based services; Ontology; Telecommunication services; Trajectories; High-level abstraction; Pervasive applications; Reasoning about knowledge; Semantic descriptions; Semantic trajectories; Semantic web standards; Semantic Web technology; Trajectory modeling; Semantic Web",2-s2.0-85030869758
"Pavlinić A., Komen V., Uzelac M.","Application of direct collocation method in short-term line ampacity calculation",2018,"Electric Power Systems Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032373986&doi=10.1016%2fj.epsr.2017.10.018&partnerID=40&md5=890f42418187586e6f0fc7f0bf493bfa","Commonly for the calculation of line ampacity (rating) the steady-state heat balance equation is used. In this paper a novel method for the calculation of line ampacity is developed. This method is based on the definition of an optimal control problem and its solution represents the line ampacity in the desired time range. The solution of the defined optimal control problem is obtained by applying the direct collocation method. In this manner the short-term line ampacity is obtained by solving a nonlinear programming problem. Nowadays, many algorithms and hardware implementations are available for solving similar nonlinear programming problems. Thus, the usage of this method is suitable for simplifying the calculation of the short-term line ampacity in contemporary dynamical line rating systems. Finally, the developed is compared with existing methods for the short-term line ampacity calculation and the advantages and the disadvantages of each method are discussed. At the end of the paper for a 240/40 mm2 aluminium steel-reinforced conductor, the methods are tested on several cases and the results compared. The effectiveness of each method is checked by simulating the conductor non-steady-state heat balance equation with the obtained results for the line ampacities. From the obtained results it is proven that the developed method effectively calculates the short-term line ampacity, and at the same time simplifies the calculation process. This paper is recommended for researchers focused in the field of dynamical rating systems. © 2017 Elsevier B.V.","Direct collocation method; Line; Line ampacity; Optimal control; Short-term line ampacity","Hardware; Nonlinear programming; Optimal control systems; Rating; Specific heat; Ampacity; Direct collocation methods; Hardware implementations; Heat balance equations; Line; Nonlinear programming problem; Optimal control problem; Optimal controls; Equations of state",2-s2.0-85032373986
"Gallego A.-J., Calvo-Zaragoza J., Valero-Mas J.J., Rico-Juan J.R.","Clustering-based k-nearest neighbor classification for large-scale data with neural codes representation",2018,"Pattern Recognition",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032305830&doi=10.1016%2fj.patcog.2017.09.038&partnerID=40&md5=b7d00b06d297261b4f9e125f4a81963a","While standing as one of the most widely considered and successful supervised classification algorithms, the k-nearest Neighbor (kNN) classifier generally depicts a poor efficiency due to being an instance-based method. In this sense, Approximated Similarity Search (ASS) stands as a possible alternative to improve those efficiency issues at the expense of typically lowering the performance of the classifier. In this paper we take as initial point an ASS strategy based on clustering. We then improve its performance by solving issues related to instances located close to the cluster boundaries by enlarging their size and considering the use of Deep Neural Networks for learning a suitable representation for the classification task at issue. Results using a collection of eight different datasets show that the combined use of these two strategies entails a significant improvement in the accuracy performance, with a considerable reduction in the number of distances needed to classify a sample in comparison to the basic kNN rule. © 2017 Elsevier Ltd","Clustering; Deep neural networks; Efficient kNN classification","Deep neural networks; Efficiency; Motion compensation; Nearest neighbor search; Classification tasks; Cluster boundaries; Clustering; Instance-based methods; K-nearest neighbor classification; K-nearest neighbor classifiers (KNN); K-NN classifications; Supervised classification; Classification (of information)",2-s2.0-85032305830
"Mortera P., Zuljan F.A., Magni C., Bortolato S.A., Alarcón S.H.","Multivariate analysis of organic acids in fermented food from reversed-phase high-performance liquid chromatography data",2018,"Talanta",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029141966&doi=10.1016%2fj.talanta.2017.09.005&partnerID=40&md5=2e16b116c4ba81e9683009226961aef7","Multivariate calibration coupled to RP-HPLC with diode array detection (HPLC-DAD) was applied to the identification and the quantitative evaluation of the short chain organic acids (malic, oxalic, formic, lactic, acetic, citric, pyruvic, succinic, tartaric, propionic and α-cetoglutaric) in fermented food. The goal of the present study was to get the successful resolution of a system in the combined occurrence of strongly coeluting peaks, of distortions in the time sensors among chromatograms, and of the presence of unexpected compounds not included in the calibration step. Second-order HPLC-DAD data matrices were obtained in a short time (10 min) on a C18 column with a chromatographic system operating in isocratic mode (mobile phase was 20 mmol L−1 phosphate buffer at pH 2.20) and a flow-rate of 1.0 mL min−1 at room temperature. Parallel factor analysis (PARAFAC) and unfolded partial least-squares combined with residual bilinearization (U-PLS/RBL) were the second-order calibration algorithms select for data processing. The performance of the analytical parameters was good with an outstanding limit of detection (LODs) for acids ranging from 0.15 to 10.0 mmol L−1 in the validation samples. The improved method was applied to the analysis of many dairy products (yoghurt, cultured milk and cheese) and wine. The method was shown as an effective means for determining and following acid contents in fermented food and was characterized by reducibility with simple, high resolution and rapid procedure without derivatization of analytes. © 2017 Elsevier B.V.","Dairy products; Multivariate analysis; RP-HPLC; Short chain organic acids","Calibration; Chains; Chromatographic analysis; Chromatography; Dairies; Dairy products; Data handling; High performance liquid chromatography; Least squares approximations; Liquid chromatography; Organic acids; Oxalic acid; Propionic acid; Chromatographic systems; Multi variate analysis; Multivariate calibration; Parallel factor analysis; Partial least square (PLS); Reversed phase high performance liquid chromatography; RP-HPLC; Second-order calibration; Multivariant analysis",2-s2.0-85029141966
"Zhang Y., Zhou Z., Tang K.","Sweep scan path planning for five-axis inspection of free-form surfaces",2018,"Robotics and Computer-Integrated Manufacturing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027877627&doi=10.1016%2fj.rcim.2017.08.010&partnerID=40&md5=75fd437188ee99284cfc10a83e736bd8","Five-axis inspection machine is an emerging powerful means to inspect the product quality of free-form surfaces in mechanical manufacturing. However, the inspection efficiency is always a bottleneck to its better usage. Sweep scan, which is an emerging five-axis surface inspection technology, takes full account of the unique characteristics and working capacities of the five-axis inspection machine and hence has a greater efficiency advantage over the traditional five-axis surface inspection technologies. This paper presents a practical strategy for automatically generating an efficient sweep scan path for an arbitrary free-form surface. The strategy is based on the idea of first decomposing the given free-form surface into patches of elementary shapes and then devising algorithms to plan optimal sweep scan paths for each type of the elementary shapes. Four case studies on scanning different free-form surface shapes are reported to test the developed methodology. Experimental comparison between the proposed method and the popular isoplanar zigzag method demonstrates the significant improvement in terms of inspection efficiency, and a further analysis explicitly verifies the advantages of the proposed sweep scan methodology. © 2017 Elsevier Ltd","Five-axis inspection; Inspection efficiency; Path planning; Sweep scan","Efficiency; Inspection equipment; Motion planning; Surface measurement; Surface morphology; Experimental comparison; Five-axis; Free-form surface; Inspection efficiency; Inspection machines; Mechanical manufacturing; Surface inspection; Sweep scan; Inspection",2-s2.0-85027877627
"Le J., Zhang H., Chen X.","Realization of rectangular fillet weld tracking based on rotating arc sensors and analysis of experimental results in gas metal arc welding",2018,"Robotics and Computer-Integrated Manufacturing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025639334&doi=10.1016%2fj.rcim.2017.06.004&partnerID=40&md5=464944e4c8acce35684eb32b90b8a7ad","In order to improve the welding quality and efficiency of the rectangular fillet weld in the shipyard and the steel structure workshop, reduce the labor cost, and improve the welding automation, it is necessary to study a welding robot that can track rectangular fillet weld. The working principle of the rotating arc sensor has been studied, and the mathematical model of the space posture of the arc welding gun has been established. The equivalent link coordinate systems of the wheeled mobile robot have been built, and the jacobian matrix of the robot and its inverse matrix have been calculated. The transformation from the operational space speed to the joint space speed has been realized by using the inverse matrix of the jacobian matrix, and the trajectory planning of the welding robot has been finished. The tracking algorithms of the linear fillet weld and the rectangular fillet weld have been studied, and the rectangular fillet weld tracking experiment has been done in the laboratory and the factory. Experimental results showed that the welding robot can track the rectangular fillet weld with high accuracy and good reliability. © 2017 Elsevier Ltd","Experimental data analysis; Kinematics analysis; Rectangular fillet weld tracking; Robot; Rotating arc sensors","Compensation (personnel); Electric arc welding; Electric welding; Gas metal arc welding; Industrial robots; Inverse problems; Jacobian matrices; Linear transformations; Matrix algebra; Mobile robots; Robot applications; Robot programming; Robots; Ships; Wages; Welding; Co-ordinate system; Experimental data analysis; Fillet welds; Kinematics analysis; Rotating arc sensor; Trajectory Planning; Welding automation; Wheeled mobile robot; Welds",2-s2.0-85025639334
"Sundh J., Juslin P.","Compound risk judgment in tasks with both idiosyncratic and systematic risk: The “Robust Beauty” of additive probability integration",2018,"Cognition",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032735789&doi=10.1016%2fj.cognition.2017.10.023&partnerID=40&md5=5492fda1ab7f76a5d57cbb173cef3680","In this study, we explore how people integrate risks of assets in a simulated financial market into a judgment of the conjunctive risk that all assets decrease in value, both when assets are independent and when there is a systematic risk present affecting all assets. Simulations indicate that while mental calculation according to naïve application of probability theory is best when the assets are independent, additive or exemplar-based algorithms perform better when systematic risk is high. Considering that people tend to intuitively approach compound probability tasks using additive heuristics, we expected the participants to find it easiest to master tasks with high systematic risk – the most complex tasks from the standpoint of probability theory – while they should shift to probability theory or exemplar memory with independence between the assets. The results from 3 experiments confirm that participants shift between strategies depending on the task, starting off with the default of additive integration. In contrast to results in similar multiple cue judgment tasks, there is little evidence for use of exemplar memory. The additive heuristics also appear to be surprisingly context-sensitive, with limited generalization across formally very similar tasks. © 2017 Elsevier B.V.","Linear additive integration; Multiple risk integration; Probability; Risk",,2-s2.0-85032735789
"Boroomandi Barati S., Pionnier N., Pinoli J.-C., Valette S., Gavet Y.","Investigation spatial distribution of droplets and the percentage of surface coverage during dropwise condensation",2018,"International Journal of Thermal Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032701878&doi=10.1016%2fj.ijthermalsci.2017.10.020&partnerID=40&md5=a40fed46a8225d57b19529d27517201d","The aim of this research is to develop an algorithm to simulate droplets nucleation and growth during dropwise condensation in order to study the droplets spatial distribution. The proposed algorithm starts with droplets distributed based on the Poisson point process and investigates the spatial distribution of droplets using Ripley's L function method. Also, the effects of substrate temperature (Tw) and initial density (ND) on the percentage of area occupied by droplets (ϕ) are studied. Good agreement between model predictions and experimental data for the rate of growth and changes in droplets density (Nt) as well as spatial distribution of droplets verifies the validity of the simulating model. © 2017","Dropwise condensation; Percentage of surface coverage; Poisson point process; Ripley function","Condensation; Drops; Poisson distribution; Dropwise condensation; Initial density; L functions; Model prediction; Nucleation and growth; Poisson point process; Substrate temperature; Surface coverages; Spatial distribution",2-s2.0-85032701878
"da Cruz M.D.O.R., Weksler M.","Impact of tree priors in species delimitation and phylogenetics of the genus Oligoryzomys (Rodentia: Cricetidae)",2018,"Molecular Phylogenetics and Evolution",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032804769&doi=10.1016%2fj.ympev.2017.10.021&partnerID=40&md5=972f25e1c4e814a6f2ba91c9548ef879","The use of genetic data and tree-based algorithms to delimit evolutionary lineages is becoming an important practice in taxonomic identification, especially in morphologically cryptic groups. The effects of different phylogenetic and/or coalescent models in the analyses of species delimitation, however, are not clear. In this paper, we assess the impact of different evolutionary priors in phylogenetic estimation, species delimitation, and molecular dating of the genus Oligoryzomys (Mammalia: Rodentia), a group with complex taxonomy and morphological cryptic species. Phylogenetic and coalescent analyses included 20 of the 24 recognized species of the genus, comprising of 416 Cytochrome b sequences, 26 Cytochrome c oxidase I sequences, and 27 Beta-Fibrinogen Intron 7 sequences. For species delimitation, we employed the General Mixed Yule Coalescent (GMYC) and Bayesian Poisson tree processes (bPTP) analyses, and contrasted 4 genealogical and phylogenetic models: Pure-birth (Yule), Constant Population Size Coalescent, Multiple Species Coalescent, and a mixed Yule-Coalescent model. GMYC analyses of trees from different genealogical models resulted in similar species delimitation and phylogenetic relationships, with incongruence restricted to areas of poor nodal support. bPTP results, however, significantly differed from GMYC for 5 taxa. Oligoryzomys early diversification was estimated to have occurred in the Early Pleistocene, between 0.7 and 2.6 MYA. The mixed Yule-Coalescent model, however, recovered younger dating estimates for Oligoryzomys diversification, and for the threshold for the speciation-coalescent horizon in GMYC. Eight of the 20 included Oligoryzomys species were identified as having two or more independent evolutionary units, indicating that current taxonomy of Oligoryzomys is still unsettled. © 2017 Elsevier Inc.","Coalescent; DNA barcoding; Genealogical models; Sigmodontinae; Species tree; Yule",,2-s2.0-85032804769
"Yang J., Yao H., Wu B.","An efficient numerical method for variable order fractional functional differential equation",2018,"Applied Mathematics Letters",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031797162&doi=10.1016%2fj.aml.2017.08.020&partnerID=40&md5=d4bb52a287818f074fc40c1d47ef93ba","In this paper, we consider a new technique for variable order fractional functional differential equations (FDE for short). The proposed method relies on the reproducing kernel splines method (RKSM). The method can lessen computation cost and provide highly precise approximate solutions. Numerical results demonstrate that the algorithm is more effective and efficient. © 2017","Functional differential equations; Reproducing kernel splines method; Variable fractional order","Differential equations; Approximate solution; Computation costs; Efficient numerical method; Fractional functional differential equations; Fractional order; Functional differential equations; Numerical results; Reproducing kernel; Numerical methods",2-s2.0-85031797162
"Sonmezoglu A., Ekici M., Arnous A.H., Zhou Q., Triki H., Moshokoa S.P., Ullah M.Z., Biswas A., Belic M.","Embedded solitons with χ(2) and χ(3) nonlinear susceptibilities by extended trial equation method",2018,"Optik",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030835822&doi=10.1016%2fj.ijleo.2017.10.014&partnerID=40&md5=238e574ae402305631e329fc8c30503b","This paper employs the extended trial equations algorithm to extract soliton and other forms of waves in quadratic-cubic nonlinear medium. These waves stem from the continuous spectrum. The solutions appear with their corresponding constraints, also known as the existence criteria for the waves. © 2017 Elsevier GmbH","Extended trial function approach; Solitons; χ(2) and χ(3) nonlinearities","Control nonlinearities; Solitons; Continuous spectrum; Embedded solitons; Nonlinear medium; Nonlinear susceptibilities; Trial equation methods; Trial functions; Nonlinear equations",2-s2.0-85030835822
"Zhang T., Liang J., Yang Y., Cui G., Kong L., Yang X.","Antenna deployment method for multistatic radar under the situation of multiple regions for interference",2018,"Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029813565&doi=10.1016%2fj.sigpro.2017.09.006&partnerID=40&md5=3e041d57fed2b4d003e91b1684148fa7","In this paper, considering multiple regions for interference simultaneously, an optimal antenna deployment problem for distributed multistatic radar is investigated. The optimal antenna deployment problem is solved by proposing an antenna deployment method based on Multi-Objective Particle Swarm Optimization (MOPSO). Firstly, we construct a multi-objective optimization problem for multistatic radar antenna deployment by choosing the interference power densities of different regions as objective functions. Then, to obtain the optimal deployment result without wasting time and computational resources, an iteration convergence criterion based on interval distance is proposed. The iteration convergence criterion can be used to stop the MOPSO optimization process efficiently when the optimal antenna deployment algorithm reaches the desired convergence level. Finally, numerical results are provided to verify the validity of the proposed algorithm. © 2017 Elsevier B.V.","Antenna deployment; Convergence criterion; Interval distance; MOPSO; Multistatic radar","Antennas; Iterative methods; Multiobjective optimization; Optimization; Particle swarm optimization (PSO); Radar; Radar antennas; Radar signal processing; Antenna deployments; Computational resources; Convergence criterion; Interval distance; MOPSO; Multi objective particle swarm optimization; Multi-objective optimization problem; Objective functions; Multistatic radars",2-s2.0-85029813565
"Xiong Y., Quan C., Tay C.J.","Multiple image encryption scheme based on pixel exchange operation and vector decomposition",2018,"Optics and Lasers in Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032026440&doi=10.1016%2fj.optlaseng.2017.10.010&partnerID=40&md5=d6d5a4a23a97ec6b15a00ddeabe4b5bb","We propose a new multiple image encryption scheme based on a pixel exchange operation and a basic vector decomposition in Fourier domain. In this algorithm, original images are imported via a pixel exchange operator, from which scrambled images and pixel position matrices are obtained. Scrambled images encrypted into phase information are imported using the proposed algorithm and phase keys are obtained from the difference between scrambled images and synthesized vectors in a charge-coupled device (CCD) plane. The final synthesized vector is used as an input in a random phase encoding (DRPE) scheme. In the proposed encryption scheme, pixel position matrices and phase keys serve as additional private keys to enhance the security of the cryptosystem which is based on a 4-f system. Numerical simulations are presented to demonstrate the feasibility and robustness of the proposed encryption scheme. © 2017 Elsevier Ltd","Multiple image encryption; Pixel exchange; Vector decomposition","Charge coupled devices; Image processing; Pixels; Vectors; Encryption schemes; Exchange operators; Multiple-image encryptions; Original images; Phase information; Random-phase encoding; Scrambled images; Vector decompositions; Cryptography",2-s2.0-85032026440
"Zhou J., Wang W., Zhang J., Yin B., Liu X.","3D shape segmentation using multiple random walkers",2018,"Journal of Computational and Applied Mathematics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018771539&doi=10.1016%2fj.cam.2017.03.025&partnerID=40&md5=b8def3e8ebcfa2e16bab513e612a16b3","Recently, 3D shapes are widely available in many ways, and the demand for shape analysis and understanding is increasing in the field of computer graphics. Shape segmentation is a significant step towards shape analysis. In this paper, we propose an interactive shape segmentation algorithm based on multiple random walkers (MRW). In the MRW system, a restart rule is designed among multiple agents on a single graph to achieve desired interactions. The process of our algorithm is different from conventional random walk. Restart distribution of each agent is computed according to the probability distributions of all agents. The experimental results demonstrate the accuracy and stability of our approach. Furthermore, our method can well handle the complex 3D shapes. In addition, we expand this MRW to the field of co-segmentation, and the results yielded by our approach are comparable to state-of-the-art co-segmentation techniques. © 2017 Elsevier B.V.","Interactive; MRW system; Restart rule; Segmentation","Computer graphics; Image segmentation; Multi agent systems; Random processes; Three dimensional computer graphics; Co segmentations; Complex 3D shapes; Interactive; MRW system; Multiple agents; Restart rule; Shape segmentation; State of the art; Probability distributions",2-s2.0-85018771539
"Wu X., Weng J., Yan W.","Adopting secret sharing for reversible data hiding in encrypted images",2018,"Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029783301&doi=10.1016%2fj.sigpro.2017.09.017&partnerID=40&md5=500565451671b99a0599229e33023917","Secret sharing is an alternative method for protecting an image by dividing it into multiple encrypted shares. When sufficient shares are collected, the image can be losslessly recovered. In this paper, secret sharing is adopted to reversible data hiding in encrypted images. A basic model by using secret sharing for reversible data hiding in encrypted images is firstly introduced. Then, an image encryption algorithm by using Shamir's secret sharing is proposed. Theoretical analysis is provided for substantiating that the shares generated by the proposed encryption algorithm are suitable for data embedding. Finally, two basic methods by using difference expansion and difference histogram shifting are given, as well as some extensions. Experimental results are demonstrated, illustrating the merits of the proposed methods such as low computational complexity, high embedding capacity and real reversibility are achieved. © 2017 Elsevier B.V.","Difference expansion; Encrypted images; Histogram shifting; Pixel difference; Reversible data hiding; Secret sharing","Graphic methods; Image processing; Steganography; Difference expansion; Encrypted images; Histogram shifting; Reversible data hiding; Secret sharing; Cryptography",2-s2.0-85029783301
"Lin S.-C., Tuan H.-W., Tung C.-T., Julian P.","Partition network into communities based on group action on sets",2018,"Physica A: Statistical Mechanics and its Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030705454&doi=10.1016%2fj.physa.2017.08.124&partnerID=40&md5=83d5f1e0477852e177357ee366c0a4cd","In this paper an improved algorithm is provided to detect communities within a network based on group action on sets (GAS). Modularity has been used as the criterion to revise the results of three previous papers, deriving a better method of partition for the network of Karate club. We developed a new method to replace the complicated GAS to achieve the same effect as GAS. Through four examples, we demonstrated that our revised approach reduced the computation amount of modularity values. Based on a branch marked example, a detailed example is provided by us to illustrate that there is too many cores in the initial stage of GAS approach to induce too many communities in the final partition. The findings shown here, will allow scholars to understand using GAS algorithm to partition a network into communities is an unreliable method. © 2017 Elsevier B.V.","Community in network; Group action on sets (GAS); Intersection–union operation; r-cycle","Physics; Group actions; In networks; Many core; Network-based; r-cycle; Union operations; Gases",2-s2.0-85030705454
"Khodabakhshi F., Sarlak M.","A noncommunication adaptive single phase auto-reclosure of transmission lines using phase space based criteria",2018,"International Journal of Electrical Power and Energy Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029538524&doi=10.1016%2fj.ijepes.2017.09.013&partnerID=40&md5=c5fbf818a23685b0ab094cf582b091e5","This paper presents two phase space (PS) based criteria, and then on the basis of which it illustrates the preparation of a new non-intelligent and noncommunication adaptive single phase auto-reclosure (ASPAR) scheme to detect the secondary arc extinction for reclosure of transmission lines after self-clearing of transient faults. This scheme, which is fed by local voltage signal, can accurately distinguish between transient and permanent faults in transmission lines. Moreover, in the case of transient faults, the secondary arc extinction can be detected by the proposed algorithm within 8 ms and under effective operational and structural conditions, including different fault locations, load amounts, number of circuits, ideally transposed, partially transposed and un-transposed circuits, existence of shunt reactors and measurement noise. Besides, the presented PS based algorithm can be implemented sample by sample and does not need complicated integral computation, which connotes that it can be embedded in reclosing relays in transmission systems. © 2017 Elsevier Ltd","Adaptive auto-reclosure; Permanent fault; Phase space; Secondary arc; Transient fault","Electric lines; Embedded systems; Fault tree analysis; Auto-reclosure; Permanent faults; Secondary arc; Secondary arc extinction; Single-phase auto-reclosure; Transient and permanent fault; Transient faults; Transmission systems; Phase space methods",2-s2.0-85029538524
"Long Y., Du Z.-J., Wang W.-D., Dong W.","Human motion intent learning based motion assistance control for a wearable exoskeleton",2018,"Robotics and Computer-Integrated Manufacturing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027548318&doi=10.1016%2fj.rcim.2017.08.007&partnerID=40&md5=3e9b289293ca1b94f17dfd9bdb41f948","Human motion intent (HMI) acquiring by using physical human robot interaction (pHRI) information is one of the most crucial issues for lower extremity exoskeleton control. The mapping from the pHRI information to the HMI is complicated and nonlinear since the wearer is in the control loop, which is difficult to be modeled directly via mathematical tools. The nonlinear approximation can be learned by using machine learning approaches, e.g., Gaussian Process (GP) regression, which is suitable for high-dimensional and small-sample nonlinear regression problems. However, GP regression is restrictive for large scale datasets due to its computation complexity. In this paper, an online sparse GP algorithm is proposed to learn the HMI, where the input is the pHRI signal and the output is the angular increment of the active joints, i.e., the knee joints. The data of HRI is collected by the torque sensor and the angular position of the active joint is measured by the optical position sensor respectively. The pHRI signal is dealt with Kalman smoother to achieve the following functions, i.e., (1) eliminating noise and (2) predicting forward. The learned HMI via the online sparse GP regression algorithm is regarded as the reference trajectory of the lower extremity exoskeleton. A fuzzy-PID control strategy is designed to drive the robotic exoskeleton to follow the estimated HMI. Prototype experiments are performed on the subjects who wear the exoskeleton system to walk on different terrains without any transition. The experimental results validated the effectiveness of the proposed algorithm. The online sparse GP regression algorithm is capable of learning the HMI based on the pHRI and the fuzzy-PID can shadow the HMI quite well. © 2017 Elsevier Ltd","Exoskeleton; GP regression; Human motion intent; Human robot interaction; Motion assistance","Digital storage; Exoskeleton (Robotics); Joints (anatomy); Learning systems; Man machine systems; Regression analysis; Robots; Three term control systems; Wearable sensors; Wearable technology; Human motions; Lower extremity exoskeletons; Machine learning approaches; Motion assistance; Nonlinear approximation; Nonlinear regression problems; Optical position sensors; Physical humanrobot interaction (phri); Human robot interaction",2-s2.0-85027548318
"Lee G.","Fast computation of the compressive hyperspectral imaging by using alternating least squares methods",2018,"Signal Processing: Image Communication",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031289784&doi=10.1016%2fj.image.2017.10.001&partnerID=40&md5=ae4e28402717a57c2a4f8dc9ea92e0f3","Hyperspectral imaging acquires up to several hundreds of narrow and adjacent spectral band images simultaneously. However, since the dimension of the hyperspectral imaging data, which typically forms a third order tensor, is increased in proportion to the size of spatial and the spectral information at the same time, the higher order singular value decomposition (HOSVD) is appropriate to reduce its dimension. One of the simplest and most accurate approaches for computing the HOSVD is higher order orthogonal iteration (HOOI), which computes the factor matrices from the unfolding matrices of the given tensor by using singular value decomposition alternatively until convergence is achieved. However, because of its expensive computational complexity, we propose a faster algorithm to compute the HOSVD even though the output shows no meaningful difference from that obtained by HOOI. Specifically instead of computing the factor matrix from the updated tensor in every iteration along each mode, we reuse the intermediate result after updating one factor matrix to modify the others in a single iteration. Numerical experiments reveal that the proposed algorithm computes the dimension-reduced hyperspectral imaging much faster than HOOI with fewer outer iterations. Moreover, the difference in accuracy between the proposed algorithm and HOOI is negligible. © 2017 Elsevier B.V.","Alternating least squares; Higher order orthogonal iteration; Higher order singular value decomposition; Hyperspectral imaging","Hyperspectral imaging; Iterative methods; Least squares approximations; Matrix algebra; Spectroscopy; Tensors; Alternating least squares; Higher order singular value decomposition; Hyperspectral imaging datum; Intermediate results; Numerical experiments; Orthogonal iteration; Spectral information; Third-order tensors; Singular value decomposition",2-s2.0-85031289784
"Chitra S., Kumaratharan N.","Multimedia transmission in MC-CDMA using adaptive subcarrier power allocation and CFO compensation",2018,"International Journal of Electronics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026208973&doi=10.1080%2f00207217.2017.1357201&partnerID=40&md5=ae6de81c7b2d7101f47cee49d8b03b3a","Multicarrier code division multiple access (MC-CDMA) system is one of the most effective techniques in fourth-generation (4G) wireless technology, due to its high data rate, high spectral efficiency and resistance to multipath fading. However, MC-CDMA systems are greatly deteriorated by carrier frequency offset (CFO) which is due to Doppler shift and oscillator instabilities. It leads to loss of orthogonality among the subcarriers and causes intercarrier interference (ICI). Water filling algorithm (WFA) is an efficient resource allocation algorithm to solve the power utilisation problems among the subcarriers in time-dispersive channels. The conventional WFA fails to consider the effect of CFO. To perform subcarrier power allocation with reduced CFO and to improve the capacity of MC-CDMA system, residual CFO compensated adaptive subcarrier power allocation algorithm is proposed in this paper. The proposed technique allocates power only to subcarriers with high channel to noise power ratio. The performance of the proposed method is evaluated using random binary data and image as source inputs. Simulation results depict that the bit error rate performance and ICI reduction capability of the proposed modified WFA offered superior performance in both power allocation and image compression for high-quality multimedia transmission in the presence of CFO and imperfect channel state information conditions. © 2017 Informa UK Limited, trading as Taylor & Francis Group.","CSI; ICI; MC-CDMA; MWFA; residual CFO compensated MWFA","Bit error rate; Channel state information; Fading channels; Frequency allocation; Image compression; Multicarrier modulation; Turbo codes; Wireless telecommunication systems; Bit error rate (BER) performance; Efficient resource allocation; Imperfect channel state information; MC-CDMA; Multi carrier code-division multiple-access systems; MWFA; residual CFO compensated MWFA; Sub-carrier power allocations; Code division multiple access",2-s2.0-85026208973
"Poplawski B., Mikułowski G., Mróz A., Jankowski Ł.","Decentralized semi-active damping of free structural vibrations by means of structural nodes with an on/off ability to transmit moments",2018,"Mechanical Systems and Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028691830&doi=10.1016%2fj.ymssp.2017.08.012&partnerID=40&md5=795c205c552b5291a1ea5dd311fe838c","This paper proposes, tests numerically and verifies experimentally a decentralized control algorithm with local feedback for semi-active mitigation of free vibrations in frame structures. The algorithm aims at transferring the vibration energy of low-order, lightly-damped structural modes into high-frequency modes of vibration, where it is quickly damped by natural mechanisms of material damping. Such an approach to mitigation of vibrations, known as the prestress–accumulation release (PAR) strategy, has been earlier applied only in global control schemes to the fundamental vibration mode of a cantilever beam. In contrast, the decentralization and local feedback allows the approach proposed here to be applied to more complex frame structures and vibration patterns, where the global control ceases to be intuitively obvious. The actuators (truss–frame nodes with controllable ability to transmit moments) are essentially unblockable hinges that become unblocked only for very short time periods in order to trigger local modal transfer of energy. The paper proposes a computationally simple model of the controllable nodes, specifies the control performance measure, yields basic characteristics of the optimum control, proposes the control algorithm and then tests it in numerical and experimental examples. © 2017 Elsevier Ltd","Damping of vibrations; Decentralized control; Semi-active control; Smart structures; Truss-frame nodes","Damping; Decentralized control; Energy transfer; Intelligent structures; Structural dynamics; Structural frames; Trusses; Basic characteristics; Control performance; Fundamental vibrations; High-frequency mode; Semiactive control; Semiactive damping; Structural vibrations; Vibration energies; Feedback",2-s2.0-85028691830
"Liu Y., Fan X., Lv C., Wu J., Li L., Ding D.","An innovative information fusion method with adaptive Kalman filter for integrated INS/GPS navigation of autonomous vehicles",2018,"Mechanical Systems and Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028709221&doi=10.1016%2fj.ymssp.2017.07.051&partnerID=40&md5=b8f65d27bea81052c95a4743721f66a6","Information fusion method of INS/GPS navigation system based on filtering technology is a research focus at present. In order to improve the precision of navigation information, a navigation technology based on Adaptive Kalman Filter with attenuation factor is proposed to restrain noise in this paper. The algorithm continuously updates the measurement noise variance and processes noise variance of the system by collecting the estimated and measured values, and this method can suppress white noise. Because a measured value closer to the current time would more accurately reflect the characteristics of the noise, an attenuation factor is introduced to increase the weight of the current value, in order to deal with the noise variance caused by environment disturbance. To validate the effectiveness of the proposed algorithm, a series of road tests are carried out in urban environment. The GPS and IMU data of the experiments were collected and processed by dSPACE and MATLAB/Simulink. Based on the test results, the accuracy of the proposed algorithm is 20% higher than that of a traditional Adaptive Kalman Filter. It also shows that the precision of the integrated navigation can be improved due to the reduction of the influence of environment noise. © 2017 Elsevier Ltd","Autonomous vehicle; IAE-AKF; Information fusion; Integrated navigation","Adaptive filtering; Air navigation; Bandpass filters; Inertial navigation systems; Information filtering; Information fusion; Kalman filters; Navigation systems; Spurious signal noise; White noise; Adaptive kalman filter; Autonomous Vehicles; IAE-AKF; Influence of environments; Information fusion method; Integrated navigation; Navigation in formation; Navigation technology; Adaptive filters",2-s2.0-85028709221
"Zheng Z., Sun J., Wang W.-Q., Yang H.","Classification and localization of mixed near-field and far-field sources using mixed-order statistics",2018,"Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028704269&doi=10.1016%2fj.sigpro.2017.08.025&partnerID=40&md5=bacb3103ed7cbdba23379bfe81aec234","In this paper, a novel algorithm based on mixed-order statistics is proposed for mixed near-field and far-field source localization. Firstly, the direction-of-arrivals (DOAs) of far-field signals are estimated using the conventional MUSIC method based on second-order statistics. Then, a special fourth-order cumulant matrix of the array output is constructed, which is only related to DOA parameters of mixed sources. After estimating the kurtosis of far-field signals, the related far-field components can be removed from the constructed cumulant matrix and the near-field components can be derived. With the near-field data in the cumulant domain, the DOA estimations of near-field sources can be performed using high-order MUSIC spectrum. Finally, with the near-field DOA estimates, the range parameters of near-field sources can be obtained via one-dimensional search. The proposed algorithm involves neither two-dimensional search nor additional parameter pairing processing. Moreover, it can achieve a more reasonable classification of the source types. Simulations results demonstrate the advantages of the proposed algorithm in comparison to the existing methods. © 2017 Elsevier B.V.","Far-field; Fourth-order cumulant; Mixed sources; Near-field; Source localization","Estimation; Parameter estimation; Far field; Fourth order cumulant; Near fields; Near-field source; One-dimensional search; Second order statistics; Source localization; Two-dimensional search; Direction of arrival",2-s2.0-85028704269
"Lam L.H., Ilea V., Bovo C.","European day-ahead electricity market coupling: Discussion, modeling, and case study",2018,"Electric Power Systems Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031710407&doi=10.1016%2fj.epsr.2017.10.003&partnerID=40&md5=d96070040f6b49d742187b6a4b185858","Currently, the integration of European Electricity Market (EEM) has led to a single European Day-Ahead Market (DAM) with multiple-areas considered as bidding zones. In the near future, the EEM will spread to the Intra-day and Balancing market. To operate the DAM, a market clearing tool (algorithm) has been developed by market operators. The development of this algorithm corresponds to three primary principles: (i) one single framework, (ii) robust operation, and (iii) individual accountability. However, this algorithm is not available to the research community. In this paper, the authors develop a complete European DAM model in General Algebraic Modelling System (GAMS), formulating it as a Mix Integer Quadratic Constraint Problem (MIQCP) and iterative procedure, to mitigate the non-convexity of electricity prices across Europe due to the “fill or kill” condition of block, complex and Prezzo Unico Nazionale (PUN) orders. Eventually, two case studies reflecting the current European DAM evaluated the model, aiming to confirm its robustness and reliability. © 2017 Elsevier B.V.","EUPHEMIA; European day-ahead electricity market; Iterative procedure; MIQCP; Non-convexity; Public data","Commerce; Dams; Electric industry; Iterative methods; Day-ahead electricity market; EUPHEMIA; MIQCP; Nonconvexity; Public data; Power markets",2-s2.0-85031710407
"Zhao J., Itti L.","shapeDTW: Shape Dynamic Time Warping",2018,"Pattern Recognition",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032256380&doi=10.1016%2fj.patcog.2017.09.020&partnerID=40&md5=f635ee5a5fc366ebcb1e47d2674f35f6","Dynamic Time Warping (DTW) is an algorithm to align temporal sequences with possible local non-linear distortions, and has been widely applied to audio, video and graphics data alignments. DTW is essentially a point-to-point matching method under some boundary and temporal consistency constraints. Although DTW obtains a global optimal solution, it does not necessarily achieve locally sensible matchings. Concretely, two temporal points with entirely dissimilar local structures may be matched by DTW. To address this problem, we propose an improved alignment algorithm, named shape Dynamic Time Warping (shapeDTW), which enhances DTW by taking point-wise local structural information into consideration. shapeDTW is inherently a DTW algorithm, but additionally attempts to pair locally similar structures and to avoid matching points with distinct neighborhood structures. We apply shapeDTW to align audio signal pairs having ground-truth alignments, as well as artificially simulated pairs of aligned sequences, and obtain quantitatively much lower alignment errors than DTW and its two variants. When shapeDTW is used as a distance measure in a nearest neighbor classifier (NN-shapeDTW) to classify time series, it beats DTW on 64 out of 84 UCR time series datasets, with significantly improved classification accuracies. By using a properly designed local structure descriptor, shapeDTW improves accuracies by more than 10% on 18 datasets. To the best of our knowledge, shapeDTW is the first distance measure under the nearest neighbor classifier scheme to significantly outperform DTW, which had been widely recognized as the best distance measure to date. Our code is publicly accessible at: https://github.com/jiapingz/shapeDTW. © 2017 Elsevier Ltd","Dynamic Time Warping; Sequence alignment; Time series classification","Time series; Classification accuracy; Dynamic time warping; Global optimal solutions; Nearest Neighbor classifier; Neighborhood structure; Sequence alignments; Structural information; Time series classifications; Classification (of information)",2-s2.0-85032256380
"Guo C., Shen C., Tan J., Bao X., Liu S., Liu Z.","A robust multi-image phase retrieval",2018,"Optics and Lasers in Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029698798&doi=10.1016%2fj.optlaseng.2017.09.014&partnerID=40&md5=6904e5e36ff995d592c26d1aee7620b9","The phase evaluation is not perfect by using three kinds of existing multi-image phase retrieval methods. The amplitude-phase retrieval scheme is employed for initializing the input of the Multi-stage algorithm to obtain a robust result. The synthesized axial multi-image phase retrieval technique is able to be highly accurate convergent with continuous phase distribution of [0, 2π] and random phase distribution of [0, π], which is also demonstrated to have sharper edge for reconstructed phase map in experiment. This paper will provide a powerful and useful guidance for axial multi-image phase retrieval. © 2017 Elsevier Ltd","Diffraction; Phase retrieval","Diffraction; Electrical engineering; Engineering; Magnetic materials; Continuous phase; Highly accurate; Multi stage; Multi-images; Phase evaluation; Phase maps; Phase retrieval; Random-phase; Optical testing",2-s2.0-85029698798
"Le Mézo T., Jaulin L., Zerr B.","Bracketing the solutions of an ordinary differential equation with uncertain initial conditions",2018,"Applied Mathematics and Computation",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026805400&doi=10.1016%2fj.amc.2017.07.036&partnerID=40&md5=8b73aa7f1648ac7b3674260ae470b0e6","In this paper, we present a new method for bracketing (i.e., characterizing from inside and from outside) all solutions of an ordinary differential equation in the case where the initial time is inside an interval and the initial state is inside a box. The principle of the approach is to cast the problem into bracketing the largest positive invariant set which is included inside a given set X. Although there exists an efficient algorithm to solve this problem when X is bounded, we need to adapt it to deal with cases where X is unbounded. © 2017 Elsevier Inc.","Abstract interpretation; Dynamical systems; Infinity; Interval computation; ODE","Differential equations; Dynamical systems; Abstract interpretations; All solutions; Infinity; Initial state; Initial time; Interval computations; Positive invariant set; Uncertain initial condition; Ordinary differential equations",2-s2.0-85026805400
"Huang W., Lai P.-C., Bessler D.A.","On the changing structure among Chinese equity markets: Hong Kong, Shanghai, and Shenzhen",2018,"European Journal of Operational Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011599390&doi=10.1016%2fj.ejor.2017.01.019&partnerID=40&md5=c039613b084c64c68b26250f0b41d3e4","This study investigates information discovery among five Chinese equity markets measured daily over the period 1995–2014. We employ time series methods for finding structural breaks (if any) and uncovering both short-run and long-run fluctuations. We apply a new algorithm of inductive causation for use with non-Gaussian data to study the information flows in contemporaneous time. The empirical results show that there are four break dates and that the underlying causal models changed over our study period. The Shanghai A-share market dominates the other markets in the most recent period. © 2017 Elsevier B.V.","Chinese stock market; Information flow; Linear non-Gaussian acyclic model; Structural VAR; Structure change","Commerce; Gaussian noise (electronic); Chinese stock market; Information flows; Non-Gaussian; Structural VAR; Structure change; Financial markets",2-s2.0-85011599390
"Belomestny D., Häfner S., Nagapetyan T., Urusov M.","Variance reduction for discretised diffusions via regression",2018,"Journal of Mathematical Analysis and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029455679&doi=10.1016%2fj.jmaa.2017.09.002&partnerID=40&md5=a01806c80709f02917928e6323b804d3","In this paper we present a novel approach towards variance reduction for discretised diffusion processes. The proposed approach involves specially constructed control variates and allows for a significant reduction in the variance for the terminal functionals. In this way the complexity order of the standard Monte Carlo algorithm (ε−3 in the case of a first order scheme and ε−2.5 in the case of a second order scheme) can be reduced down to ε−2+δ for any δ∈[0,0.25) with ε being the precision to be achieved. These theoretical results are illustrated by several numerical examples. © 2017 Elsevier Inc.","Control variates; Monte Carlo methods; Regression methods; Stochastic differential equations; Weak schemes",,2-s2.0-85029455679
"Przybył A.","Hard real-time communication solution for mechatronic systems",2018,"Robotics and Computer-Integrated Manufacturing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027506211&doi=10.1016%2fj.rcim.2017.08.001&partnerID=40&md5=7a6738992ca7f917fc1086e85f84b9d8","The paper proposes a method to build a highly efficient real-time communication solution for mechatronic systems. The method is based on the Ethernet physical layer (PHY) and on field programmable gate array (FPGA) technology and offers a better performance when compared to commercially available communication solutions. Although it is not directly compatible with the OSI/ISO model of TCP/IP protocol, vertical integration is done with a gateway. This provides simplicity and safety. Moreover, the use of the FPGA allows for integrating the communication solution with the user algorithm of particular distributed device inside a single chip. Therefore, the proposed solution is efficient and highly integrated. © 2017 Elsevier Ltd","Computer numerical control; Industrial distributed control systems; Real-time communication","Computer control systems; Distributed computer systems; Distributed parameter control systems; Field programmable gate arrays (FPGA); Gateways (computer networks); Network layers; Communication solutions; Computer numerical control; Distributed devices; Hard real-time communication; Mechatronic systems; Physical layers; Real-time communication; Vertical integration; Real time systems",2-s2.0-85027506211
"Yu X., Lei N., Zheng X., Gu X.","Surface parameterization based on polar factorization",2018,"Journal of Computational and Applied Mathematics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011568111&doi=10.1016%2fj.cam.2017.01.003&partnerID=40&md5=d7b643cd21696f68f8a585d0e22b2df6","A mapping between measurable subsets of Euclidean space can be uniquely factorized to the composition of a measure-preserving mapping and an optimal transportation map, the later is also the gradient map of a convex function. This work introduces an algorithm based on variational approach to compute this type of polar factorization for mappings between planar domains and some direct applications. Our method greatly increases the flexibility for surface parameterizations by balancing between area distortion and angle distortion, and improves the accuracy and numerical stability for down steam geometric processing tasks. © 2017 Elsevier B.V.","Conformal mapping; Optimal mass transportation; Polar factorizations","Conformal mapping; Functions; Mapping; Mass transportation; Numerical methods; Convex functions; Euclidean spaces; Geometric processing; Optimal transportations; Polar factorization; Preserving mappings; Surface parameterization; Variational approaches; Factorization",2-s2.0-85011568111
"Biboulet N., Lubrecht A.A.","Efficient solver implementation for reynolds equation with mass-conserving cavitation",2018,"Tribology International",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031731947&doi=10.1016%2fj.triboint.2017.10.008&partnerID=40&md5=bd8d4bd3e1a84341126fdada399df217","A global grid refinement solver implementation for the Iso-Viscous-Rigid Reynolds equation with cavitation (mass-conservation) using the Fischer-Burmeister equation for complementarity is presented and shows a quasi linear time complexity. The global grid refinement strategy allows a fast and stable convergence. It is applied to several examples of dimple textured flat/parallel surfaces in order to, first illustrate the algorithm performance, and second, to point out discretisation error issues which may occur for textured surfaces and justify the need of an efficient numerical method to solve such cases. © 2017 Elsevier Ltd","Cavitation; Free boundary; Mass-conserving; Texture",,2-s2.0-85031731947
"Wei Y., Dong Y., Huang X., Zhang Z.","Nonlinearity measurement for low-pressure encapsulated MEMS gyroscopes by transient response",2018,"Mechanical Systems and Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028708506&doi=10.1016%2fj.ymssp.2017.07.034&partnerID=40&md5=fab524cf47bc76653d4ce8d07da231bb","To measure the nonlinear dynamic features of micromechanical gyroscopes, a non-parametric method based on Hilbert transform is proposed. Using a sequence of frequency stepping sinusoidal pulses as the excitation signal, a set of transient responses in the vicinity of the resonant frequency are obtained. The envelopes of the time-domain response signals are calculated by Hilbert transform. The location of the resonant frequency, as well as whether the gyroscope is working in linear or nonlinear region, can be approximately assessed from the waveform of the envelopes. In order to obtain the dynamic parameters of the gyroscope, a modified FREEVIB algorithm is designed for analyzing the free damped oscillation signals. The instantaneous amplitudes and instantaneous frequencies that extracted by Hilbert transform are further processed by singular spectrum analysis (SSA). Numerical simulation results indicate that the algorithm behaves better anti-noise performance and can be practically used for processing the experimentally sampled transient signals. Vibrating ring microgyroscopes are experimentally tested under different air pressure (10–100 Pa). From the largest response segment of the response sequences, qualification of the operation state, i.e. whether the gyroscope is working in the nonlinear region, is obtained from the envelope of the forced transient signal. Other parameters, including the Backbone, frequency response function (FRF) and Q-value curves, are calculated from the free damped oscillation signals. The results are in good agreement with those obtained by traditional frequency sweeping method. © 2017 Elsevier Ltd","Backbone curve; Hilbert transform; MEMS gyroscopes; Nonlinear features; Q-value curves; Transient response","Frequency response; Gyroscopes; Natural frequencies; Spectrum analysis; Time domain analysis; Transient analysis; Backbone curves; Hilbert transform; MEMS gyroscope; Nonlinear features; Q-values; Mathematical transformations",2-s2.0-85028708506
"Silvestre D., Rosa P., P. Hespanha J., Silvestre C.","Self-Triggered and Event-Triggered Set-Valued Observers",2018,"Information Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032858828&doi=10.1016%2fj.ins.2017.10.029&partnerID=40&md5=312cffd0a5f4dd61033a89645b4e15f5","This paper addresses the problem of reducing the required network load and computational power for the implementation of Set-Valued Observers (SVOs) in Networked Control System (NCS). Event- and self-triggered strategies for NCS, modeled as discrete-time Linear Parameter-Varying (LPV) systems, are studied by showing how the triggering condition can be selected. The methodology provided can be applied to determine when it is required to perform a full (“classical”) computation of the SVOs, while providing low-complexity state overbounds for the remaining time, at the expenses of temporarily reducing the estimation accuracy. As part of the procedure, an algorithm is provided to compute a suitable centrally symmetric polytope that allows to find hyper-parallelepiped and ellipsoidal overbounds to the exact set-valued state estimates calculated by the SVOs. By construction, the proposed triggering techniques do not influence the convergence of the SVOs, as at some subsequent time instants, set-valued estimates are computed using the conventional SVOs. Results are provided for the triggering frequency of the self-triggered strategy and two interesting cases: distributed systems when the dynamics of all nodes are equal up to a reordering of the matrix; and when the probability distribution of the parameters influencing the dynamics is known. The performance of the proposed algorithm is demonstrated in simulation by using a time-sensitive example. © 2017 Elsevier Inc.","Fault detection; Networked control systems; Self-triggered; State estimation","Control systems; Fault detection; Nanofibers; Probability distributions; State estimation; Computational power; Discrete time linear parameter varying (LPV) system; Distributed systems; Event-triggered; Self-triggered; Set valued estimates; Set-valued observers; State estimates; Networked control systems",2-s2.0-85032858828
"Jia F., Shi C., He K., Wang C., Xiao B.","Degraded document image binarization using structural symmetry of strokes",2018,"Pattern Recognition",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032291959&doi=10.1016%2fj.patcog.2017.09.032&partnerID=40&md5=35388bc5d6ac717b4c7c1970022068d9","This paper presents an effective approach for the local threshold binarization of degraded document images. We utilize the structural symmetric pixels (SSPs) to calculate the local threshold in neighborhood and the voting result of multiple thresholds will determine whether one pixel belongs to the foreground or not. The SSPs are defined as the pixels around strokes whose gradient magnitudes are large enough and orientations are symmetric opposite. The compensated gradient map is used to extract the SSP so as to weaken the influence of document degradations. To extract SSP candidates with large magnitudes and distinguish the faint characters and bleed-through background, we propose an adaptive global threshold selection algorithm. To further extract pixels with opposite orientations, an iterative stroke width estimation algorithm is applied to ensure the proper size of neighborhood used in orientation judgement. At last, we present a multiple threshold vote based framework to deal with some inaccurate detections of SSP. The experimental results on seven public document image binarization datasets show that our method is accurate and robust compared with many traditional and state-of-the-art document binarization approaches based on multiple evaluation measures. © 2017 Elsevier Ltd","Document image binarization; Local threshold; Stroke width estimation; Structural symmetry of strokes","Bins; Iterative methods; Degraded document images; Document image binarization; Effective approaches; Evaluation measures; Gradient magnitude; Local thresholds; Stroke widths; Structural symmetry; Pixels",2-s2.0-85032291959
"Su W.-H., Bakalis S., Sun D.-W.","Fourier transform mid-infrared-attenuated total reflectance (FTMIR-ATR) microspectroscopy for determining textural property of microwave baked tuber",2018,"Journal of Food Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028722901&doi=10.1016%2fj.jfoodeng.2017.08.016&partnerID=40&md5=08a7e7495216249d44f19be99db05084","Time series spectroscopic and textural analysis data were obtained from 5 varieties of tuber samples during microwave baking. These data were analyzed using evolutionary computing methods including partial least square discriminant analysis (PLSDA), partial least square regression (PLSR) and locally weighted partial least squares regression (LWPLSR). PLSDA was able to discriminate the tuber samples into three separate classes corresponding to their spectral properties. The predictability of spectra in full wavenumber region (4000–600 cm−1) and fingerprint region (1500–900 cm−1) were calculated using PLSR and LWPLSR and the relative performances of developed models were compared. It was observed that similar or even better predictions were obtained by models using spectra in the fingerprint region. Then, first-derivative and mean centering iteration algorithm (FMCIA) was carried out to select potential effective wavelengths and these selected wavelengths were further simplified using successive projections algorithm (SPA) for improving the model efficiency. Based on the FMCIA-SPA method for wavelength selection, the optimized models were established using LWPLSR for determination of tuber textural property (TTP) in terms of hardness, resilience, springiness, cohesiveness, gumminess and chewiness, with correlation coefficient of prediction (RP) of 0.797, 0.881, 0.584, 0.574, 0.728 and 0.690, respectively. The results of this study demonstrated that FTMIR-ATR spectroscopy could be used reliably and rapidly for the non-destructive assessment of textural property of microwave baked tuber. © 2017 Elsevier Ltd","FTMIR-ATR; Multivariate regression; Non-destructive testing; Potato; Textural property","Discriminant analysis; Iterative methods; Nondestructive examination; Principal component analysis; Regression analysis; Spectroscopic analysis; Time series analysis; Tubes (components); FTMIR-ATR; Multivariate regression; Non destructive testing; Potato; Textural properties; Least squares approximations",2-s2.0-85028722901
"Rivera J., Dueñas I., Ortega S., Del Valle J.L.","Field-programmable analogue arrays for the sensorless control of DC motors",2018,"International Journal of Electronics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026498452&doi=10.1080%2f00207217.2017.1357085&partnerID=40&md5=6c67f71bde8bb8afc816a7dc0165e039","This work presents the analogue implementation of a sensorless controller for direct current motors based on the super-twisting (ST) sliding mode technique, by means of field programmable analogue arrays (FPAA). The novelty of this work is twofold, first is the use of the ST algorithm in a sensorless scheme for DC motors, and the implementation method of this type of sliding mode controllers in FPAAs. The ST algorithm reduces the chattering problem produced with the deliberate use of the sign function in classical sliding mode approaches. On the other hand, the advantages of the implementation method over a digital one are that the controller is not digitally approximated, the controller gains are not fine tuned and the implementation does not require the use of analogue-to-digital and digital-to-analogue converter circuits. In addition to this, the FPAA is a reconfigurable, lower cost and power consumption technology. Simulation and experimentation results were registered, where a more accurate transient response and lower power consumption were obtained by the proposed implementation method when compared to a digital implementation. Also, a more accurate performance by the DC motor is obtained with proposed sensorless ST technique when compared with a classical sliding mode approach. © 2017 Informa UK Limited, trading as Taylor & Francis Group.","direct current motors; Field programmable analogue arrays; observers; sensorless control; sliding modes","Analog to digital conversion; Controllers; DC motors; Electric machine control; Electric power utilization; Field programmable gate arrays (FPGA); Sliding mode control; Digital implementation; Direct current motors; Field-programmable analogue arrays; Lower-power consumption; observers; Sliding mode controller; Sliding mode techniques; Sliding modes; Sensorless control",2-s2.0-85026498452
"Francomano E., Hilker F.M., Paliaga M., Venturino E.","Separatrix reconstruction to identify tipping points in an eco-epidemiological model",2018,"Applied Mathematics and Computation",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026485372&doi=10.1016%2fj.amc.2017.07.022&partnerID=40&md5=89ab2cf10869a05a7e22cfede463b0aa","Many ecological systems exhibit tipping points such that they suddenly shift from one state to another. These shifts can be devastating from an ecological point of view, and additionally have severe implications for the socio-economic system. They can be caused by overcritical perturbations of the state variables such as external shocks, disease emergence, or species removal. It is therefore important to be able to quantify the tipping points. Here we present a study of the tipping points by considering the basins of attraction of the stable equilibrium points. We address the question of finding the tipping points that lie on the separatrix surface, which partitions the space of system trajectories. We present an algorithm that reconstructs the separatrix by using a Moving Least Squares approximant based on radial basis functions. The algorithm is applied to an eco-epidemiological model of pack hunting predators that suffer disease infection. Our analysis reveals that strong hunting cooperation considerably promotes the survival of predators and renders the predators resilient to perturbations. © 2017 Elsevier Inc.","Allee threshold; Dynamical system; Group hunting; Moving Least Squares approximation; Radial basis function; Regime shift","Dynamical systems; Ecology; Functions; Image segmentation; Radial basis function networks; Allee threshold; Group hunting; Moving least squares approximation; Radial basis functions; Regime shift; Least squares approximations",2-s2.0-85026485372
"Nasr-Esfahani E., Karimi N., Jafari M.H., Soroushmehr S.M.R., Samavi S., Nallamothu B.K., Najarian K.","Segmentation of vessels in angiograms using convolutional neural networks",2018,"Biomedical Signal Processing and Control",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030682708&doi=10.1016%2fj.bspc.2017.09.012&partnerID=40&md5=0405a56ed142fe6304e4780c4ad1735c","Coronary artery disease (CAD) is the most common type of heart disease and it is the leading cause of death in most parts of the world. About fifty percent of all middle-aged men and thirty percent of all middle-aged women in North America develop some type of CAD. The main tool for diagnosis of CAD is the X-ray angiography. Usually these images lack high quality and they contain noise. Accurate segmentation of vessels in these images could help physicians in accurate CAD diagnosis. Many image processing techniques have been used by researchers for vessel segmentation but achieving high accuracy is still a challenge in this regard. In this paper a method for detecting vessel regions in angiography images is proposed which is based on deep learning approach using convolutional neural networks (CNN). The intended angiogram is first processed to enhance the image quality. Then a patch around each pixel is fed into a trained CNN to determine whether the pixel is of vessel or background regions. Different elements of the proposed method, including the image enhancement method, the architecture of the CNN, and the training procedure of the CNN, all lead to a highly accurate mechanism. Experiments performed on angiograms of a dataset show that the proposed algorithm has a Dice score of 81.51 and an accuracy of 97.93. Results of the proposed algorithm show its superiority in extraction of vessel regions in comparison to state of the art methods. © 2017","Angiograms; Convolutional neural networks; Deep learning; Vessel segmentation","Angiography; Computer aided diagnosis; Convolution; Deep learning; Diagnosis; Diseases; Image enhancement; Image segmentation; Neural networks; Pixels; Angiograms; Angiography images; Convolutional neural network; Coronary artery disease; Image processing technique; State-of-the-art methods; Training procedures; Vessel segmentation; Image processing",2-s2.0-85030682708
"Siless V., Chang K., Fischl B., Yendiki A.","AnatomiCuts: Hierarchical clustering of tractography streamlines based on anatomical similarity",2018,"NeuroImage",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032745260&doi=10.1016%2fj.neuroimage.2017.10.058&partnerID=40&md5=328f174f8cf761ff3138270f8f818929","Diffusion MRI tractography produces massive sets of streamlines that contain a wealth of information on brain connections. The size of these datasets creates a need for automated clustering methods to group the streamlines into meaningful bundles. Conventional clustering techniques group streamlines based on their spatial coordinates. Neuroanatomists, however, define white-matter bundles based on the anatomical structures that they go through or next to, rather than their spatial coordinates. Thus we propose a similarity measure for clustering streamlines based on their position relative to cortical and subcortical brain regions. We incorporate this measure into a hierarchical clustering algorithm and compare it to a measure that relies on Euclidean distance, using data from the Human Connectome Project. We show that the anatomical similarity measure leads to a 20% improvement in the overlap of clusters with manually labeled tracts. Importantly, this is achieved without introducing any prior information from a tract atlas into the clustering algorithm, therefore without imposing the existence of any named tracts. © 2017 Elsevier Inc.","Diffusion MRI; Hierarchical clustering; Normalized cuts; Tractography",,2-s2.0-85032745260
"Liu X., Mei W., Du H.","Multi-modality medical image fusion based on image decomposition framework and nonsubsampled shearlet transform",2018,"Biomedical Signal Processing and Control",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031726408&doi=10.1016%2fj.bspc.2017.10.001&partnerID=40&md5=6f084546a6878ae173692c98d347af0a","Medical image fusion increases accuracy of clinical diagnosis and analysis through integrating complementary information of multi-modality medical images. A novel multi-modality medical image fusion algorithm exploiting a moving frame based decomposition framework (MFDF) and the nonsubsampled shearlet transform (NSST) is proposed. The MFDF is applied to decompose source images into texture components and approximation components. Maximum selection fusion rule is employed to fuse texture components aimed at transferring salient gradient information to the fused image. The approximate components are merged using NSST. Finally, a components synthesis process is adopted to produce the fused image. Experimental results verify that the proposed method achieves better performance than other compared state-of-art methods in both visual effects and objective criteria. © 2017 Elsevier Ltd","Image decomposition framework; Medical image fusion; Mutual information; Nonsubsampled shearlet transform","Diagnosis; Image fusion; Medical imaging; Clinical diagnosis; Gradient informations; Image decomposition; Mutual informations; Objective criteria; Shearlet transforms; State-of-art methods; Texture components; Image texture",2-s2.0-85031726408
"Zheng P., Shi X.","The use of the dyadic partition in elementary real analysis",2018,"Journal of Computational and Applied Mathematics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020883303&doi=10.1016%2fj.cam.2017.05.010&partnerID=40&md5=548dec7e6ad6b96bcce37fe8dbd02c2b","In Gordon (1998), Gordon presented alternate proofs of several well known results in elementary real analysis using tagged partitions. In this paper, we provide a set of alternative proofs based on the dyadic partitions. An important difference between tagged and dyadic partitions is that the results based on the dyadic partition can be obtained constructively, i.e. an algorithm is supplied to reach the conclusion of each proof. In addition, the construction involves only concepts and results presented in a first course real analysis, which is the reason why, comparing tagged partition and its theory, the proofs based on dyadic partition are more straightforward and accessible to a wide range of audience. © 2017 Elsevier B.V.","Dyadic interval; Real analysis","Computational methods; Dyadic interval; Real analysis; Mathematical techniques",2-s2.0-85020883303
"Briffod F., Shiraiwa T., Enoki M.","Numerical investigation of the influence of rolling texture and microstructure on fatigue crack initiation in BCC polycrystals",2018,"International Journal of Fatigue",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032742621&doi=10.1016%2fj.ijfatigue.2017.10.019&partnerID=40&md5=f013546c307ba0714bc35c60b7d1a609","The study aims to investigate the influence of the grain morphology and rolling texture on the fatigue crack initiation in BCC polycrystals. Several 2D polycrystalline aggregates having different grain size and shape distributions are generated based on an anisotropic tessellation and an ellipse packing algorithm. Uniform and typical BCC rolled textures containing both the α and γ fibers are considered for the crystallographic texture of the material. Finite element simulations using a crystal plasticity model are performed under cyclic uniaxial tension-compression condition. Twenty simulations are conducted for each type of microstructure in order to obtain significant statistical data. A critical plane fatigue indicator parameter (FIP) following the Tanaka-Mura model is applied to quantify the sensitivity of the microstructure against fatigue crack initiation. The distributions of relevant geometrical, crystallographic and mechanical quantities are analyzed. The effect of the grain size distribution, morphology and texture on the fatigue performance and scattering are discussed. © 2017 Elsevier Ltd","Crystal plasticity; Fatigue crack initiation; Fatigue indicator parameter; Finite element analysis; Microstructure modeling","Crack initiation; Cracks; Crystal microstructure; Fatigue crack propagation; Grain size and shape; Microstructure; Plasticity; Polycrystals; Single crystals; Crystal plasticity; Crystal plasticity models; Crystallographic textures; Fatigue crack initiation; Finite element simulations; Indicator parameters; Microstructure model; Polycrystalline aggregates; Finite element method",2-s2.0-85032742621
"Lin C.-Y., Yang P.","Robust multistratum baseline designs",2018,"Computational Statistics and Data Analysis",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030459805&doi=10.1016%2fj.csda.2017.08.009&partnerID=40&md5=032fc812297434251aa9585e7a1f399e","Baseline designs have received considerable attention recently. Most existing methods for finding best baseline designs were developed for completely randomized experiments. How to select baseline designs for experiments under multistratum structures has not been studied in the literature. The purpose of this paper is to fill this gap and extend the use of the baseline design for experiments with complex structures, such as split-plot experiments. A framework for baseline designs under multistratum structures is established and a generalized minimax A-criterion for selecting multistratum baseline designs which are efficient and model robust is proposed. The coordinate-exchange algorithm is applied and robust baseline designs under split-plot, split-split-plot, and block-split-plot structures, which can be constructed via nesting operators repeatedly, are exemplified. A real case study for industrial experiments is provided to demonstrate the application and data analysis of multistratum baseline designs. © 2017 Elsevier B.V.","A-criterion; Coordinate-exchange; Generalized least square; Loss function; Mean squared error; Minimax; Restricted maximum likelihood; Split-plot","Maximum likelihood; A-criterion; Coordinate exchange; Generalized least square; Loss functions; Mean squared error; Minimax; Restricted maximum likelihood; Split-plot; Mean square error",2-s2.0-85030459805
"Zheng S.-M., Feng W.-Q., Wang S.-Q.","Elastic properties of high entropy alloys by MaxEnt approach",2018,"Computational Materials Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032444952&doi=10.1016%2fj.commatsci.2017.09.060&partnerID=40&md5=150a66ccf6f2ccce2a6958ba3d0b590f","By first-principles calculation, elastic properties of seven single phase high-entropy alloys (HEAs) with excellent properties are presented in our work. A new method Maximum Entropy (MaxEnt) was adopted. The method is an algorithm that can be used to study the lattice distortion effect of HEAs. CP2K first-principles simulation package was employed for calculation. The comparison of calculated elastic properties of TaNbHfZrTi with experimental data is made and the agreement is found to be quite good. Elastic properties of AlMoNbTiV are close to the calculated data from Coherent Potential Approximation (CPA), and the reasons were discussed. The influence of lattice distortions on elastic properties were also studied. Furthermore, elastic properties of a series of refractory HEAs were predicted. These results demonstrate that MaxEnt model can properly describe HEAs. © 2017 Elsevier B.V.","Elastic properties; First-principles calculation; High-entropy alloys; Maximum entropy","Aluminum alloys; Calculations; Elasticity; Hafnium alloys; Molybdenum alloys; Niobium alloys; Tantalum alloys; Titanium alloys; Vanadium alloys; Zirconium alloys; Coherent-potential approximation; Elastic properties; First-principles calculation; First-principles simulations; High entropy alloys; Lattice distortions; MaxEnt models; Single phase; Maximum entropy methods",2-s2.0-85032444952
"Liu Y., Wang Z., Ma L., Cui Y., Alsaadi F.E.","Synchronization of directed switched complex networks with stochastic link perturbations and mixed time-delays",2018,"Nonlinear Analysis: Hybrid Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031742909&doi=10.1016%2fj.nahs.2017.07.006&partnerID=40&md5=79cee6c3816bb7b948075d92dcc02814","In this paper, the synchronization problem is studied for a class of directed switched complex networks. The links among the nodes are perturbed by stochastic noises and the topology varies according to certain predetermined switching rules. The coupled networks under consideration are subject to mixed delays comprising both discrete and distributed ones. A new estimate of the general algebraic connectivity is firstly given for the directed complex networks, based on which the exponential synchronization problem is analyzed by virtue of the average-dwell-time technique. Then, sufficient conditions are derived to guarantee the synchronization in mean square provided that the switching is slow on the average. Subsequently, the switched complex networks with link failures are investigated and it is shown that the synchronization can be achieved if the average link failure ratio does not exceed certain threshold. Finally, a numerical simulation example is presented to demonstrate the effectiveness of the proposed algorithm. © 2017 Elsevier Ltd","Average dwell time; General algebraic connectivity; Link failure; Switched complex networks; Synchronization","Algebra; Multivariable control systems; Stochastic systems; Synchronization; Telecommunication links; Time delay; Algebraic connectivity; Average dwell time; Coupled networks; Exponential synchronization; Link failures; Mixed time delays; Stochastic noise; Synchronization problem; Complex networks",2-s2.0-85031742909
"Naitsat A., Cheng S., Qu X., Fan X., Saucan E., Zeevi Y.Y.","Geometric approach to detecting volumetric changes in medical images",2018,"Journal of Computational and Applied Mathematics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031499959&doi=10.1016%2fj.cam.2017.07.024&partnerID=40&md5=908cb3c82a4edcbd4c2647b446317cf2","We present a new quantitative method for detecting changes in 3D medical images. The dissimilarity between shapes is quantified as a measure of the effort it takes to deform one 3D region into another. Our main tool is an assessment of conformal and isometric distortions of mappings between volumes. Unlike most existing techniques for shape comparison, our algorithm operates both on triangular and tetrahedral meshes, and therefore can be applied both for closed simply connected surfaces, as well as for volumetric domains homeomorphic to a ball, with geometrically complicated boundaries. Furthermore we extend our main geometric distortion measure to higher dimensions, in a manner that allows for the dealing with spatial data at the maximal, as well as at all the lower dimensions. © 2017 Elsevier B.V.","3D medical images; Change detection; Distortion measures; Quasiconformal mapping","Conformal mapping; D region; Mapping; 3D medical image; Change detection; Distortion measures; Geometric approaches; Geometric distortion; Quantitative method; Quasi-conformal mappings; Tetrahedral meshes; Medical imaging",2-s2.0-85031499959
"Zhou Y., Wu J., Ji L., Yu Z., Lin K., Hao L.","Transient stability preventive control of power systems using chaotic particle swarm optimization combined with two-stage support vector machine",2018,"Electric Power Systems Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031784844&doi=10.1016%2fj.epsr.2017.10.007&partnerID=40&md5=43b6d9505a3e9214500cc62b4fddc5dd","This paper presents a chaotic particle swarm optimization (CPSO) algorithm combined with data mining method for transient stability preventive control. The data mining method is utilized to approximate the security region considering transient stability. Therefore, the application effects of different input features and data-mining classifiers are compared first. Then, a two-stage support vector machine (SVM) approach is proposed to generate two models, including a linear SVM model with controllable features provides preventive adjustment rules, and a more accurate SVM model to approximate the actual security region. Finally, the CPSO in combination with the two-stage SVM is proposed to calculate the optimal preventive control strategies. Comprehensive studies are conducted on a 16-machine 68-bus system and 48-machine 140-bus system to verify the effectiveness. © 2017 Elsevier B.V.","Chaotic particle swarm optimization; Data mining; Preventive control; Support vector machine; Transient stability","Classification (of information); Data mining; Electric power system stability; Particle swarm optimization (PSO); Stability; Adjustment rules; Application effect; Chaotic particle swarm optimizations; Data mining methods; Input features; Linear SVM; Preventive control; Security region; Support vector machines",2-s2.0-85031784844
"Hamedmoghadam H., Jalili M., Yu X.","An opinion formation based binary optimization approach for feature selection",2018,"Physica A: Statistical Mechanics and its Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030314095&doi=10.1016%2fj.physa.2017.08.048&partnerID=40&md5=eeb264ea0969de499971d552f0e705d7","This paper proposed a novel optimization method based on opinion formation in complex network systems. The proposed optimization technique mimics human–human interaction mechanism based on a mathematical model derived from social sciences. Our method encodes a subset of selected features to the opinion of an artificial agent and simulates the opinion formation process among a population of agents to solve the feature selection problem. The agents interact using an underlying interaction network structure and get into consensus in their opinions, while finding better solutions to the problem. A number of mechanisms are employed to avoid getting trapped in local minima. We compare the performance of the proposed method with a number of classical population-based optimization methods and a state-of-the-art opinion formation based method. Our experiments on a number of high dimensional datasets reveal outperformance of the proposed algorithm over others. © 2017 Elsevier B.V.","Complex networks; Feature selection; Opinion formation; Population-based optimization; Social dynamics","Complex networks; Management science; Complex network systems; Feature selection problem; High dimensional datasets; Opinion formation; Optimization techniques; Population-based optimization; Population-based optimization methods; Social dynamics; Feature extraction",2-s2.0-85030314095
"Cui Z., Yang Z., Jiang H.-Z., Huang W.-X., Shen L.","A Sharp-Interface Immersed Boundary Method for Simulating Incompressible Flows with Arbitrarily Deforming Smooth Boundaries",2018,"International Journal of Computational Methods",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030240047&doi=10.1142%2fS0219876217500803&partnerID=40&md5=5b0fa0fdcc689ac3ac286acc20d91195","We develop a sharp interface immersed boundary (IB) method to simulate the interactions between fluid flows and deformable moving bodies. Fluid-solid interfaces are captured using a level-set (LS) function, which is updated at every time step by a reinitialization procedure. Motions of solid bodies are dynamically coupled with fluid flows by calculating the fluid forces exerted on solid bodies. The accuracy and robustness of the LS-based IB method are tested systematically in the context of several benchmark cases and self-propelled fish swimming. The effects of computational parameters on the accuracy of deformable body capturing are analyzed. It is found that the algorithm performs well in simulating the flow motions surrounding the deforming and moving bodies. © World Scientific Publishing Company.","Computational fluid dynamics; fluid-structure interaction; immersed boundary method; level-set method","Computational fluid dynamics; Deformation; Fluid structure interaction; Numerical methods; Plates (structural components); Turbulent flow; Computational parameters; Deformable bodies; Fluid-solid interfaces; Immersed boundary; Immersed boundary methods; Level Set method; Reinitialization procedure; Smooth boundary; Flow of fluids",2-s2.0-85030240047
"Lianghua W., Yang P., Shuai W., Wenjing L., Shanqiu C., Xu B.","A high speed model-based approach for wavefront sensorless adaptive optics systems",2018,"Optics and Laser Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029208817&doi=10.1016%2fj.optlastec.2017.08.022&partnerID=40&md5=866270ef7b45cb2d6de04b73902bbaa2","To improve temporal-frequency property of wavefront sensorless adaptive optics (AO) systems, a fast general model-based aberration correction algorithm is presented. The fast general model-based approach is based on the approximately linear relation between the mean square of the aberration gradients and the second moment of far-field intensity distribution. The presented model-based method is capable of completing a mode aberration effective correction just applying one disturbing onto the deformable mirror(one correction by one disturbing), which is reconstructed by the singular value decomposing the correlation matrix of the Zernike functions’ gradients. Numerical simulations of AO corrections under the various random and dynamic aberrations are implemented. The simulation results indicate that the equivalent control bandwidth is 2–3 times than that of the previous method with one aberration correction after applying N times disturbing onto the deformable mirror (one correction by N disturbing). © 2017 Elsevier Ltd","Adaptive optics systems; Control bandwidth; Dynamic aberrations; Model reconstruction; Wavefront sensing","Adaptive control systems; Bandwidth; Deformation; Mirrors; Wavefronts; Adaptive optics systems; Control bandwidth; Dynamic aberrations; Model reconstruction; Wave-front sensing; Adaptive optics",2-s2.0-85029208817
"Levrard C.","Sparse oracle inequalities for variable selection via regularized quantization",2018,"Bernoulli",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026325866&doi=10.3150%2f16-BEJ876&partnerID=40&md5=46a830f00f96dc4c58ab6c4eeb426121","We give oracle inequalities on procedures which combines quantization and variable selection via a weighted Lasso k-means type algorithm. The results are derived for a general family of weights, which can be tuned to size the influence of the variables in different ways. Moreover, these theoretical guarantees are proved to adapt the corresponding sparsity of the optimal codebooks, suggesting that these procedures might be of particular interest in high dimensional settings. Even if there is no sparsity assumption on the optimal codebooks, our procedure is proved to be close to a sparse approximation of the optimal codebooks, as has been done for the Generalized Linear Models in regression. If the optimal codebooks have a sparse support, we also show that this support can be asymptotically recovered, providing an asymptotic consistency rate. These results are illustrated with Gaussian mixture models in arbitrary dimension with sparsity assumptions on the means, which are standard distributions in model-based clustering. © 2018 ISI/BS.","Clustering; High dimension; K-means; Lasso; Oracle inequalities; Sparsity; Variable selection",,2-s2.0-85026325866
"Shihabudheen K.V., Mahesh M., Pillai G.N.","Particle swarm optimization based extreme learning neuro-fuzzy system for regression and classification",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030679056&doi=10.1016%2fj.eswa.2017.09.037&partnerID=40&md5=17da58230cab0d3530cf7704c233277b","This paper improves the performance of adaptive neuro-fuzzy inference system (ANFIS) using extreme learning machines (ELM) concept and particle swarm optimization (PSO). The proposed learning machine, particle swarm optimization (PSO) based regularized extreme learning adaptive neuro-fuzzy inference system (PSO-RELANFIS), has the advantages of reduced randomness, reduced computational complexity and better generalization. The fuzzy membership function parameters of the proposed system are randomly selected with in constraint ranges. A regularized loss function is developed using constrained optimization and the optimized regularization parameter is obtained using PSO technique. Performance analysis on regression and classification problems shows that proposed algorithm achieves similar or better generalization performance compared to well-known kernel based methods and ELM based neuro-fuzzy systems. © 2017 Elsevier Ltd","ELM based neuro-fuzzy system; Regression and multi-class classification; Regularization; Takagi–Sugeno–Kang (TSK) fuzzy inference system","Constrained optimization; Fuzzy neural networks; Fuzzy systems; Learning systems; Membership functions; Particle swarm optimization (PSO); Regression analysis; Swarm intelligence; Adaptive neuro-fuzzy inference system; Fuzzy inference systems; Fuzzy membership function; Generalization performance; Multi-class classification; Neurofuzzy system; Regularization; Regularization parameters; Fuzzy inference",2-s2.0-85030679056
"Chen P.-Y., Chen R.-B., Lin C.D.","Optimizing two-level orthogonal arrays for simultaneously estimating main effects and pre-specified two-factor interactions",2018,"Computational Statistics and Data Analysis",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030320685&doi=10.1016%2fj.csda.2017.08.012&partnerID=40&md5=b9dd0add0152eacc33ee026e496cb396","This paper considers the construction of D-optimal two-level orthogonal arrays that allow for the joint estimation of all main effects and a specified set of two-factor interactions. A sharper upper bound on the determinant of the related matrix is derived. To numerically obtain D-optimal and nearly D-optimal orthogonal arrays of large run sizes, an efficient search procedure is proposed based on a discrete optimization algorithm. Results on designs of 20, 24, 28, 36, 44 and 52 runs with three or fewer two-factor interactions are illustrated here to demonstrate the performance of the proposed approach. In addition, two cases with four two-factor interactions are also demonstrated here. © 2017 Elsevier B.V.","D-optimal design; Fractional factorial design; Hadamard matrix; Swarm intelligence optimization","Hadamard matrices; D-optimal designs; Discrete optimization; Fractional factorial designs; Joint estimation; Orthogonal array; Related matrices; Search procedures; Swarm intelligence optimization; Optimization",2-s2.0-85030320685
"Lee J.-S., Lee S.-J., Lee K.-B.","Novel switching method for single-phase NPC three-level inverter with neutral-point voltage control",2018,"International Journal of Electronics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026403973&doi=10.1080%2f00207217.2017.1357202&partnerID=40&md5=323bc97f86b1eae864400c28c8e7ff8c","This paper proposes a novel switching method with the neutral-point voltage control in a single-phase neutral-point-clamped three-level inverter (SP-NPCI) used in photovoltaic systems. A proposed novel switching method for the SP-NPCI improves the efficiency. The main concept is to fix the switching state of one leg. As a result, the switching loss decreases and the total efficiency is improved. In addition, it enables the maximum power-point-tracking operation to be performed by applying the proposed neutral-point voltage control algorithm. This control is implemented by modifying the reference signal. Simulation and experimental results provide verification of the performance of a novel switching method with the neutral-point voltage control. © 2017 Informa UK Limited, trading as Taylor & Francis Group.","natural-point voltage control; neutral-point-clamped inverter; pulse-width modulation method; Single-phase; three-level inverter","Efficiency; Electric inverters; Photovoltaic cells; Pulse width modulation; Voltage control; Maximum Power Point Tracking; Neutral point clamped inverters; Neutral point voltage control; Neutral-point clamped three-level inverter; NPC three- level inverters; Photovoltaic systems; Single phase; Three-level inverters; Switching",2-s2.0-85026403973
"Grivet-Talocia S., Trinchero R.","Behavioral, Parameterized, and Broadband Modeling of Wired Interconnects with Internal Discontinuities",2018,"IEEE Transactions on Electromagnetic Compatibility",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028935786&doi=10.1109%2fTEMC.2017.2723629&partnerID=40&md5=11d86eee25c75166b567cd3ce9bbd62d","We present a complete workflow for the extraction of behavioral reduced-order models of wired interconnect links, including an explicit dependence on geometrical or material parameters describing internal discontinuities that may affect the quality of signal transmission. Thanks to the adopted structure, the models are easily identified from sampled frequency responses at discrete points in the parameter space. Such responses are obtained from off-The-shelf full-wave solvers. A novel algorithm is used for checking and enforcing model stability and passivity, two fundamental requirements for reliably running stable transient simulations. Finally, an ad hoc procedure is devised to synthesize the models as parameterized circuit equivalents, compatible with any SPICE solver. Several examples illustrate and validate the workflow, confirming the suitability of the proposed approach for what-if, parameter sweep, design centering, and optimization through time-domain simulations, possibly including nonlinear devices and terminations. © 2017 IEEE.","Behavioral modeling; circuit equivalent; high-speed interconnects; macromodeling; parameterized modeling; passivity; rational approximation; scattering; SPICE; transmission lines","Circuit simulation; Electric lines; Electric network analysis; Equivalent circuits; Frequency response; Integrated circuit interconnects; Matrix algebra; Parameterization; Scattering; Structural analysis; Time domain analysis; Behavioral model; Circuit stability; High-speed interconnects; Integrated circuit interconnections; Integrated circuit modeling; Macromodeling; Parameterized model; passivity; Rational approximations; Stability analysis; Transmission line matrix methods; SPICE",2-s2.0-85028935786
"Azaïs J.-M., De Castro Y., Mourareau S.","Power of the spacing test for least-angle regression",2018,"Bernoulli",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026322761&doi=10.3150%2f16-BEJ885&partnerID=40&md5=002116408adf489bdca58935e1baa873","Recent advances in Post-Selection Inference have shown that conditional testing is relevant and tractable in high-dimensions. In the Gaussian linear model, further works have derived unconditional test statistics such as the Kac-Rice Pivot for general penalized problems. In order to test the global null, a prominent offspring of this breakthrough is the Spacing test that accounts the relative separation between the first two knots of the celebrated least-angle regression (LARS) algorithm. However, no results have been shown regarding the distribution of these test statistics under the alternative. For the first time, this paper addresses this important issue for the Spacing test and shows that it is unconditionally unbiased. Furthermore, we provide the first extension of the Spacing test to the frame of unknown noise variance. More precisely, we investigate the power of the Spacing test for LARS and prove that it is unbiased: its power is always greater or equal to the significance level α. In particular, we describe the power of this test under various scenarii: we prove that its rejection region is optimal when the predictors are orthogonal; as the level α goes to zero, we show that the probability of getting a true positive is much greater than α; and we give a detailed description of its power in the case of two predictors. Moreover, we numerically investigate a comparison between the Spacing test for LARS, the Pearson's chi-squared test (goodness of fit) and a numerical testing procedure based on the maximal correlation. When the noise variance is unknown, our analysis unleashes a new test statistic that can be computed in cubic time in the population size and which we refer to as the t-Spacing test for LARS. The t-Spacing test involves the first two knots of the LARS algorithm and we give its distribution under the null hypothesis. Interestingly, numerical experiments witness that the t-Spacing test for LARS enjoys the same aforementioned properties as the Spacing test. © 2018 ISI/BS.","1-minimization; Hypothesis testing; Power; Spacing test",,2-s2.0-85026322761
"Menke J.-H., Hegemann J., Gehler S., Braun M.","Heuristic monitoring method for sparsely measured distribution grids",2018,"International Journal of Electrical Power and Energy Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028385732&doi=10.1016%2fj.ijepes.2017.08.023&partnerID=40&md5=4553debcf9a5ebdd4e53eebf89329c56","There is an increasing interest in operating the power system close to its limits in order to avoid grid reinforcements. Distribution management requires the knowledge of grid state parameters, but outfitting grids with a large amount of measurements is costly. Therefore, we developed a new heuristic monitoring method (HMM) for balanced grids that relies only on few mandatory measurements and enables a fast way to monitor the grid for off-limit conditions. Due to a new formulation of the power flow equations, it has a low computational complexity for radial grids. The method analyzes the network topology; network buses are categorized and sorted into branches. Depending on the location of available voltage measurements, the bus powers of the corresponding branches are adjusted iteratively to better fit the measured voltage. To test the performance of our new algorithm, we design an evaluation process to compare our approach with the standard weighted least squares (WLS) state estimation (SE) method. Simulation results on artificial and real unmeshed distribution grids on the medium voltage (MV) level show very promising results, outperforming the WLS estimator even with a high amount of distributed generation (DG). © 2017 Elsevier Ltd","Distribution grid monitoring; Distribution system state estimation; Power system monitoring","Electric load flow; Electric power system measurement; Electric power transmission networks; Iterative methods; Least squares approximations; Monitoring; State estimation; Distribution grid; Distribution management; Distribution system state estimations; Grid reinforcement; Low computational complexity; Power flow equations; State estimation methods; Weighted least squares; Heuristic methods",2-s2.0-85028385732
"Porebski S., Straszecka E.","Extracting easily interpreted diagnostic rules",2018,"Information Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031713267&doi=10.1016%2fj.ins.2017.10.034&partnerID=40&md5=9fa6efaf6f512eb33e22f8ac33819aba","Diagnosis support systems are often disregarded because of their high costs, complicated inference and inability to modify the knowledge base. The aim of this work is to propose a method that helps to resolve these problems by extracting diagnostic rules that can be easily interpreted and verified by experts. The rules can be obtained from data, even if the latter are imperfect, which is usual in medical databases. Next, intuitively clear reasoning is suggested to elaborate on the diagnosis. Rules are focal elements in the framework of the Dempster–Shafer theory. They include fuzzy sets in their premises. Thus, a measure of imprecision as a fuzzy membership function and a measure of uncertainty as the basic probability value are used. Moreover, a rule selection algorithm and a rule evaluation method that prevent some of the imperfections of the existing methods are proposed. Particular attention is paid to the evaluation of the extracted rule set according to its reliability and clarity for a human user. Experimental results obtained for popular medical data sets demonstrate the advantages of the proposed approach. For each data set, simple and readable rule sets are determined. They provide comparable or better results than the approaches published so far. © 2017 Elsevier Inc.","Dempster–Shafer theory; Fuzzy focal elements; Medical diagnosis support; Rule extraction","Formal logic; Knowledge based systems; Medical computing; Membership functions; Diagnosis support systems; Fuzzy membership function; Measure of uncertainty; Medical data sets; Medical database; Medical diagnosis support; Rule extraction; Shafer theory; Diagnosis",2-s2.0-85031713267
"Huang R., Liu Y., Xu Z., Wu P., Shi Y.","Multiple rotation symmetry group detection via saliency-based visual attention and Frieze expansion pattern",2018,"Signal Processing: Image Communication",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031739373&doi=10.1016%2fj.image.2017.09.010&partnerID=40&md5=9e8e678fabce5ea475b5fb11daa3e589","Global maximum symmetry center probability-based rotation symmetry detection methods are unable to identify small-scale rotation symmetry centers in real-world images and come with a costly computational burden. This paper presents a novel strategy comprised of multiple-local-region searching in the whole image and multiple-model computation to map rotation symmetry strength (RSS) in the local region. The multiple-local-region searching method creates local regions in which the global maximum symmetry center detection method changes to a local maximum symmetry center detection method. In the local region, the multiple-model computation efficiently detects regular, small-scale, and skewed symmetry centers. This strategy improves the detection ability for regular, small-scale, and skewed rotation symmetry centers while minimizing the complexity of the algorithm based on a rotation symmetry strength (RSS) map and symmetry shape density (SSD) map. Experimental results indicate that this strategy not only allows more rotation symmetry centers to be identified successfully, but is simpler than traditional strategies as it only employs RSS maps. © 2017 Elsevier B.V.","Multiple-local-region searching; Multiple-model computation; RSS; SSD","Behavioral research; Computational complexity; RSS; Computational burden; Detection ability; Local region; Multiple rotation; Multiple-modeling; Novel strategies; Rotation symmetry; Searching methods; Rotation",2-s2.0-85031739373
"Yue H., Lu Y., Deng Z., Tzou H.","Modal sensing and control of paraboloidal shell structronic system",2018,"Mechanical Systems and Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028726007&doi=10.1016%2fj.ymssp.2017.08.005&partnerID=40&md5=60de04615d3842c1a22b8b06510f5fc3","Paraboloidal shells of revolution are commonly used as important components in the field of advanced aerospace structures and aviation mechanical systems. This study is to investigate the modal sensing behavior and the modal vibration control effect of distributed PVDF patches laminated on the paraboloidal shell. A paraboloidal shell sensing and control testing platform is set up first. Frequencies of lower order modes of the shell are obtained with the PVDF sensor and compared with the previous testing results to prove its accuracy. Then sensor patches are laminated on different positions (or different sides) of the shell and tested to reveal the relation between the sensing behaviors and their locations. Finally, a mathematical model of the structronic system is built by parameter identifications and the transfer function is derived. Independent and coupled modal controllers are designed based on the pole placement method and modal vibration control experiments are performed. The amplitude suppression ratio of each mode controlled by the pole placement controller is calculated and compared with the results obtained by using a PPF controller. Advantages of both methods are concluded and suggestions are given on how to choose control algorithm for different purpose. © 2017 Elsevier Ltd","Modal sensing analysis; Modal vibration control; Paraboloidal shell; Pole placement method; PVDF","Functions; Laminating; Poles; Poles and zeros; Shells (structures); Speed control; Vibration analysis; Vibration control; Aerospace structure; Modal sensing analysis; Paraboloidal shell; Pole placement controller; Pole placement methods; PVDF; Shells of revolution; Suppression ratios; Controllers",2-s2.0-85028726007
"Wu X., Zhang M., Xu M., Kakogawa Y.","Adaptive feedforward control of a steer-by-wire system by online parameter estimator",2018,"International Journal of Automotive Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030327080&doi=10.1007%2fs12239-018-0015-2&partnerID=40&md5=4b3b9343a7dc7b5b2d43171013f68efa","The tracking control of the steer-by-wire (SBW) system to achevie desired steering motion is the core issue for the design of algorithm. Most of model-based tracking control assumed the constant parameters without the consideration of dynamic characteristics. The external disturbances and model nonlinearities can bring uncertainties of the system parameters. To reduce the influence of parameter uncertainties, an online estimator by output error identification method is proposed to estimate the dynamic parameters of a SBW system. Meanwhile, the parameter gradient projection method is applied to eliminate the parameter drift, while a full order state observer is developed to weaken the effects of noise disturbance during the parameter identification. Since the sensitivity of parameter uncertainties for the feedforward control, the online estimator is incorporated into the control model and improve the controlled robustness. The proposed adaptive feedforward controller is conducted by the real-time experiments to show the tracking performance. © 2018, The Korean Society of Automotive Engineers and Springer-Verlag GmbH Germany.","Feedforward control; Online parameter estimator; Steer-by-wire","Adaptive control systems; Feedforward control; Navigation; Uncertainty analysis; Wire; Adaptive feedforward control; Dynamic characteristics; External disturbances; Gradient projection methods; On-line parameter estimator; Output error identification; Sensitivity of parameters; Steer-by-wire; Parameter estimation",2-s2.0-85030327080
"Corona E., Alenyà G., Gabas A., Torras C.","Active garment recognition and target grasping point detection using deep learning",2018,"Pattern Recognition",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030791138&doi=10.1016%2fj.patcog.2017.09.042&partnerID=40&md5=37b534b14259d04db2202827e1251bab","Identification and bi-manual handling of deformable objects, like textiles, is one of the most challenging tasks in the field of industrial and service robotics. Their unpredictable shape and pose makes it very difficult to identify the type of garment and locate the most relevant parts that can be used for grasping. In this paper, we propose an algorithm that first, identifies the type of garment and second, performs a search of the two grasping points that allow a robot to bring the garment to a known pose. We show that using an active search strategy it is possible to grasp a garment directly from predefined grasping points, as opposed to the usual approach based on multiple re-graspings of the lowest hanging parts. Our approach uses a hierarchy of three Convolutional Neural Networks (CNNs) with different levels of specialization, trained both with synthetic and real images. The results obtained in the three steps (recognition, first grasping point, second grasping point) are promising. Experiments with real robots show that most of the errors are due to unsuccessful grasps and not to the localization of the grasping points, thus a more robust grasping strategy is required. © 2017 Elsevier Ltd","Deep learning; Depth images; Garment classification; Garment grasping","Neural networks; Convolutional neural network; Deformable object; Depth image; Garment grasping; Manual handling; Point detection; Service robotics; Target grasping; Deep learning",2-s2.0-85030791138
"Abellán J., Mantas C.J., Castellano J.G.","AdaptativeCC4.5: Credal C4.5 with a rough class noise estimator",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030540807&doi=10.1016%2fj.eswa.2017.09.057&partnerID=40&md5=e1d4ee2da5a99bb2c5c0aea3912cc103","The application of classifiers on data represents an important help in a process of decision making. Any classifier, or other method used for knowledge extraction, suffers a deterioration when it is applied on data with noise. Credal C4.5 (CC4.5) is a recent method of classification, that introduces imprecise probabilities in the algorithm of the classic C4.5. It is very suitable in classification noise tasks, but it has a clear dependency of a parameter. It has been proved that this parameter is related with the level of overfitting of the model on the data used for training. In noisy domains, this characteristic is important in the sense that variations of this parameter can reduce the variance of the model. Depending on the degree of noise that a data set has, the application of different values of this parameter can produce different performance of the CC4.5 model. Hence, the use of the correct parameter is fundamental to attain a high level of performance for this model. In this paper, that problem is solved via a rough procedure to estimate the level of class noise in the training data. Combining this new noise estimation process with the CC4.5, it is presented a direct method that has an equivalent performance than the one of the CC4.5 when it is used with the best value of its parameter for each level of class noise. © 2017 Elsevier Ltd","Classification; Decision support system; Decision tree; Imprecise probabilities; Noisy data; Uncertainty measures","Artificial intelligence; Classification (of information); Decision making; Decision support systems; Decision trees; Equivalence classes; Probability; Trees (mathematics); Degree of noise; Direct method; Imprecise probabilities; Knowledge extraction; Noise estimation; Noisy data; Training data; Uncertainty measures; Data mining",2-s2.0-85030540807
"Gulizzi V., Rycroft C.H., Benedetti I.","Modelling intergranular and transgranular micro-cracking in polycrystalline materials",2018,"Computer Methods in Applied Mechanics and Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032394363&doi=10.1016%2fj.cma.2017.10.005&partnerID=40&md5=c6d812fdd8e3770348e354ed7be17cf7","In this work, a grain boundary formulation for intergranular and transgranular micro-cracking in three-dimensional polycrystalline aggregates is presented. The formulation is based on the displacement and stress boundary integral equations of solid mechanics and it has the advantage of expressing the polycrystalline problem in terms of grain boundary variables only. The individual grains within the polycrystalline morphology are modelled as generally anisotropic linear elastic domains with random spatial orientation. Transgranular micro-cracking is assumed to occur along specific cleavage planes, whose orientation in space within the grains depend upon the crystallographic lattice. Both intergranular and transgranular micro-cracking are modelled using suitably defined cohesive laws, whose parameters characterise the behaviour of the two mechanisms. The algorithm developed to track the inter/transgranular micro-cracking history is presented and discussed. Several numerical tests involving pseudo-3D and fully 3D morphologies are performed and analysed. The presented numerical results show that the developed formulation is capable of tracking the initiation and evolution of both intergranular and transgranular cracking as well as their competition, thus providing a useful tool for the study of damage micro-mechanics. © 2017","Boundary element method; Cohesive zone modelling; Intergranular cracking; Micro-mechanics; Polycrystalline materials; Transgranular cracking","Boundary element method; Boundary integral equations; Cracks; Grain boundaries; Integral equations; Mechanics; Polycrystalline materials; Sailing vessels; Stress corrosion cracking; Cohesive zone modelling; Crystallographic lattices; Displacement and stress; Intergranular cracking; Polycrystalline aggregates; Polycrystalline morphology; Spatial orientations; Transgranular cracking; Textures",2-s2.0-85032394363
"Chen S., Mao J., Chen F., Hou P., Li Y.","Development of ANN model for depth prediction of vertical ground heat exchanger",2018,"International Journal of Heat and Mass Transfer",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031782068&doi=10.1016%2fj.ijheatmasstransfer.2017.10.006&partnerID=40&md5=5eabc562cebeb466ac8ac1628e182be5","In the design of a ground heat exchanger (GHE), it is difficult to take all the factors into consideration. In this study, an artificial neural network (ANN) model has been developed, which can predict the depth of a vertical GHE according to the given design parameters. A three-dimensional model has been developed to obtain the training and testing data. Using the soil thermal conductivity, grout thermal conductivity, inlet flow, inlet water temperature, underground water velocity and heat flux as the input parameters, and the borehole depth as the output parameter, a three-layer ANN model has been developed. The performances of different training functions and neuron numbers have been investigated. The results show that the effects of the volumetric heat capacity and the porosity on the heat transfer of the GHE can be neglected, and the depth of a GHE can be predicted by the three-layer ANN model for given input parameters. The optimal ANN model uses the LM algorithm, and there are 10 neurons in the hidden layer. © 2017","Artificial neural network; Ground heat exchanger; Numerical simulation","Boreholes; Computer simulation; Groundwater; Heat flux; Heat pump systems; Heat transfer; Neural networks; Specific heat; Thermal conductivity; Artificial neural network models; Ground heat exchangers; Inlet water temperatures; Soil thermal conductivity; Three-dimensional model; Training and testing; Vertical ground heat exchangers; Volumetric heat capacity; Heat exchangers",2-s2.0-85031782068
"Bosi F., Pellegrino S.","Nonlinear thermomechanical response and constitutive modeling of viscoelastic polyethylene membranes",2018,"Mechanics of Materials",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031722896&doi=10.1016%2fj.mechmat.2017.10.004&partnerID=40&md5=03db532e37cd045d541c08d07dd3b5f4","Thin films of linear low-density polyethylene show a significant time-dependent behavior, strongly reliant on temperature and strain rate effects. A constitutive nonlinear thermo-viscoelastic relation is developed to characterize the response of thin membranes up to yielding, in a wide range of temperatures, strain rates, and mechanical loading conditions. The presented plane stress orthotropic formulation involves the free volume theory of viscoelasticity and the time-temperature superposition principle, necessary to describe non-linearities and non-isothermal conditions. Uniaxial tension tests at constant strain rate and long-duration biaxial inflation experiments have been employed in the calibration of the material parameters. The model has been implemented in the Abaqus finite element code by means of a user-defined subroutine based on a recursive integration algorithm. The accuracy of the constitutive relation has been validated against experimental data of full field diaphragm inflation tests and uniaxial tension, relaxation and cyclic experiments, covering sub-ambient temperatures and strain rate ranges observed during the operation of stratospheric balloons. © 2017 Elsevier Ltd","Balloons; Free volume model; Nonlinear viscoelasticity; Polymers; Thin films","ABAQUS; Balloons; Finite element method; Free volume; Linear low density polyethylenes; Meteorological balloons; Polyethylenes; Polymers; Tensile testing; Thin films; Viscoelasticity; Constitutive relations; Free volume models; Non-isothermal condition; Non-linear viscoelasticity; Temperature and strain rate effects; Thermo-mechanical response; Time dependent behavior; Time-temperature superposition principles; Strain rate",2-s2.0-85031722896
"Yan H., Ye Q., Zhang T., Yu D.-J., Yuan X., Xu Y., Fu L.","Least squares twin bounded support vector machines based on L1-norm distance metric for classification",2018,"Pattern Recognition",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032265090&doi=10.1016%2fj.patcog.2017.09.035&partnerID=40&md5=a3e11aaf80ddba016cca67c77f70b36b","In this paper, we construct a least squares version of the recently proposed twin bounded support vector machine (TBSVM) for binary classification. As a valid classification tool, TBSVM attempts to seek two non-parallel planes that can be produced by solving a pair of quadratic programming problems (QPPs), but this is time-consuming. Here, we solve two systems of linear equations rather than two QPPs to avoid this deficiency. Furthermore, the distance in least squares TBSVM (LSTBSVM) is measured by L2-norm, but L1-norm distance is usually regarded as an alternative to L2-norm to improve model robustness in the presence of outliers. Inspired by the advantages of least squares twin support vector machine (LSTWSVM), TBSVM and L1-norm distance, we propose a LSTBSVM based on L1-norm distance metric for binary classification, termed as L1-LSTBSVM, which is specially designed for suppressing the negative effect of outliers and improving computational efficiency in large datasets. Then, we design a powerful iterative algorithm to solve the L1-norm optimal problems, and it is easy to implement and its convergence to an optimum solution is theoretically ensured. Finally, the feasibility and effectiveness of L1-LSTBSVM are validated by extensive experimental results on both UCI datasets and artificial datasets. © 2017 Elsevier Ltd","L1-LSTBSVM; L1-norm distance; Outliers; TBSVM","Bins; Classification (of information); Computational efficiency; Iterative methods; Quadratic programming; Statistics; Bounded support vector machines; L1 norm; L1-LSTBSVM; Least squares twin support vector machines; Outliers; Quadratic programming problems; Systems of linear equations; TBSVM; Support vector machines",2-s2.0-85032265090
"Huynh-The T., Hua C.-H., Tu N.A., Hur T., Bang J., Kim D., Amin M.B., Ho Kang B., Seung H., Lee S.","Selective bit embedding scheme for robust blind color image watermarking",2018,"Information Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031736784&doi=10.1016%2fj.ins.2017.10.016&partnerID=40&md5=78a94516dbaaf9fc69fa7119c7f2aa68","In this paper, we propose a novel robust blind color image watermarking method, namely SMLE, that allows to embed a gray-scale image as watermark into a host color image in the wavelet domain. After decomposing the gray-scale watermark to component binary images in digits ordering from least significant bit (LSB) to most significant bit (MSB), the retrieved binary bits are then embedded into wavelet blocks of two optimal color channels by using an efficient quantization technique, where the wavelet coefficient difference in each block is quantized to either two pre-defined thresholds for corresponding 0-bits and 1-bits. To optimize the watermark imperceptibility, we equally split the coefficient modified quantity on two middle-frequency sub-bands instead of only one as in existing approaches. The improvement of embedding rule increases approximately 3 dB of watermarked image quality. An adequate trade-off between robustness and imperceptibility is controlled by a factor representing the embedding strength. As for extraction process, we exploit 2D Otsu algorithm for higher accuracy of watermark detection than that of 1D Otsu. Experimental results prove the robustness of our SMLE watermarking model against common image processing operations along with its efficient retention of the imperceptibility of the watermark in the host image. Compared to state-of-the-art methods, our approach outperforms in most of robustness tests at a same high payload capacity. © 2017 Elsevier Inc.","2D Otsu thresholding; Binary bit decomposition; Color image watermarking; Discrete wavelet transform; Quantization technique","Binary images; Bins; Color; Color image processing; Discrete wavelet transforms; Economic and social effects; Image enhancement; Image processing; Watermarking; Wavelet decomposition; Wavelet transforms; Color image watermarking; Least significant bits; Most significant bit; Otsu thresholding; Quantization technique; State-of-the-art methods; Watermark detection; Wavelet coefficients; Image watermarking",2-s2.0-85031736784
"Nagata Y., Ono I.","A guided local search with iterative ejections of bottleneck operations for the job shop scheduling problem",2018,"Computers and Operations Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029630823&doi=10.1016%2fj.cor.2017.09.017&partnerID=40&md5=07e4290eba50b51366c47728e97d1885","This paper presents a local search-based method that works in partial solution space for solving the job shop scheduling problem (JSP). The proposed method iteratively solves a series of constraint satisfaction problems (CSPs), where the current CSP is defined as the original JSP with an additional constraint that the makespan is smaller than that of the schedule obtained by solving the previous CSP. To obtain a solution to the current CSP, a local search-based procedure is performed in a partial solution space where the current solution is represented as a partial schedule. The neighborhood consists of a set of partial schedules whose makespan is less than that of the best-so-far complete schedule obtained by solving the previous CSP. The existence of the additional constraint on the makespan restricts possible local moves to those that satisfy necessary conditions to improve the best-so-far complete schedule. These moves are efficiently enumerated by using a dynamic programming-based algorithm we present in this paper. We also present an effective strategy of selecting next partial solution from the neighborhood, perturbation procedure, and tabu-search procedure, all of which are embedded into the basic framework to enhance the performance. © 2017 Elsevier Ltd","Dynamic programming; Job shop scheduling; Local search; Metaheuristics","Constraint satisfaction problems; Dynamic programming; Iterative methods; Local search (optimization); Optimization; Scheduling; Tabu search; Bottleneck operations; Guided Local Search; Job shop scheduling problems; Local moves; Local search; Meta heuristics; Search procedures; Solution space; Job shop scheduling",2-s2.0-85029630823
"Conti C., Nunes P., Ducla Soares L.","Light field image coding with jointly estimated self-similarity bi-prediction",2018,"Signal Processing: Image Communication",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032356212&doi=10.1016%2fj.image.2017.10.006&partnerID=40&md5=17e5ad9c89f169dbbb12f8ed94b7dff8","This paper proposes an efficient light field image coding (LFC) solution based on High Efficiency Video Coding (HEVC) and a novel Bi-prediction Self-Similarity (Bi-SS) estimation and compensation approach to efficiently explore the inherent non-local spatial correlation of this type of content, where two predictor blocks are jointly estimated from the same search window by using a locally optimal rate constrained algorithm. Moreover, a theoretical analysis of the proposed Bi-SS prediction is also presented, which shows that other non-local spatial prediction schemes proposed in literature are suboptimal in terms of Rate-Distortion (RD) performance and, for this reason, can be considered as restricted cases of the jointly estimated Bi-SS solution proposed here. These theoretical insights are shown to be consistent with the presented experimental results, and demonstrate that the proposed LFC scheme is able to outperform the benchmark solutions with significant gains with respect to HEVC (with up to 61.1% of bit savings) and other state-of-the-art LFC solutions in the literature (with up 16.9% of bit savings). © 2017","Bi-Prediction; HEVC; Holoscopic; Image coding; Integral imaging; Light field; Plenoptic; Self-similarity","Bismuth compounds; Codes (symbols); Electric distortion; Forecasting; Signal distortion; Video signal processing; HEVC; Holoscopic; Integral imaging; Light fields; Plenoptic; Self-similarities; Image coding",2-s2.0-85032356212
"Chen Y., Wang Z., Qian W., Alsaadi F.E.","Asynchronous observer-based H∞ control for switched stochastic systems with mixed delays under quantization and packet dropouts",2018,"Nonlinear Analysis: Hybrid Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031718270&doi=10.1016%2fj.nahs.2017.07.005&partnerID=40&md5=31031cc40bf7815ca35372d9e725e2d0","In this paper, the observer-based H∞ control problem is investigated for a class of discrete-time switched stochastic systems with mixed delays comprising both discrete and distributed delays. The measurement output of the addressed system is subject to quantizations and packet dropouts. The observer/controller switching is allowed to be asynchronous with the subsystem switching. An observer-based controller is designed such that, in the simultaneous presence of system switches, mixed delays, quantizations and packet dropouts, the closed-loop system is guaranteed to be mean-square exponentially stable while achieving the prescribed H∞ performance constraints. Based on the piecewise Lyapunov-like functionals and the average dwell-time switching, sufficient conditions are first established under which the closed-loop system is mean-square exponentially stable with a weighted disturbance attenuation level. Then, the explicit characterizations of the observer/controller gains are obtained by means of certain nonlinear matrix inequalities that can be effectively solved by applying the cone complementary linearization algorithm. Finally, a numerical example is given to show the effectiveness of the proposed design scheme. © 2017 Elsevier Ltd","Asynchronous H∞ control; Mixed delays; Packet dropouts; Quantization; Switched stochastic systems","Closed loop systems; Discrete time control systems; Packet loss; Packet networks; Robustness (control systems); Stochastic control systems; Stochastic systems; Cone complementary linearization; Discrete and distributed delays; Disturbance attenuation levels; Mean-square exponentially stables; Mixed delays; Packet dropouts; Quantization; Switched stochastic systems; Packet switching",2-s2.0-85031718270
"Han D., Nie H., Chen J., Chen M.","Dynamic obstacle avoidance for manipulators using distance calculation and discrete detection",2018,"Robotics and Computer-Integrated Manufacturing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020870479&doi=10.1016%2fj.rcim.2017.05.013&partnerID=40&md5=fb7f164f390860a4c4fd712f530c40cb","In order to avoid dynamic obstacle timely during manufacturing tasks performed by manipulators, a novel method based on distance calculation and discrete detection is proposed. The nearest distances between the links of a manipulator and the convex hull of an arbitrarily-shaped dynamic obstacle obtained from Kinect-V2 camera in real-time are calculated by Gilbert–Johnson–Keerthi algorithm, and the minimum one is defined as the closest distance between the manipulator and the obstacle. When the closest distance is less than a safe value, whether the dynamic obstacle is located in the global path of the manipulator is determined by improved discrete collision detection, which can adjust detection step-size adaptively for accuracy and efficiency. If the obstacle will collide with the manipulator, set a local goal and re-plan a local path for the manipulator. The proposed method is implemented in Robot Operating System (ROS) using C++. The experiments indicate that the proposed method can perform safe and timely dynamic avoidance for redundant manipulators in human-robot interaction. © 2017 Elsevier Ltd","Collision detection; Distance calculation; Dynamic obstacle avoidance; Human-robot interaction; Redundant manipulators","Collision avoidance; Human robot interaction; Industrial manipulators; Man machine systems; Redundant manipulators; Robots; Closest distance; Collision detection; Convex hull; Distance calculation; Dynamic obstacle avoidance; Dynamic obstacles; Manufacturing tasks; Robot operating systems (ROS); Manipulators",2-s2.0-85020870479
"António-Ferreira A., Collados-Rodríguez C., Gomis-Bellmunt O.","Modulation techniques applied to medium voltage modular multilevel converters for renewable energy integration: A review",2018,"Electric Power Systems Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030476591&doi=10.1016%2fj.epsr.2017.08.015&partnerID=40&md5=38624c83c6148133653aed1c99e3398b","Modular multilevel converters (MMC) inherent features are gaining more attention for dc voltage transmission systems. One of the main research paths regarding the converter performance deals with its voltage modulation. Specifically, for medium voltage applications with relatively small number of submodules, the voltage modulation techniques impact on the MMC performance needs to be studied. This work provides an extensive review of the carrier-based pulse with modulation (CB-PWM) techniques proposed to be applied on previous multilevel inverter versions. The CB-PWM methods were adapted to be compatible with an additional cell ranking and selection algorithm to ensure equal energy distribution on the arm cells. The state-of-the-art of zero sequence signals (ZSS) applied on three-phase inverters is also reviewed. The alliance between the ZSS with the CB-PWM, as well as the nearest level modulation (NLM), has an important impact on the MMC harmonic content, efficiency and voltage ripple of its cells capacitors. A 15 MW 28-cell-based MMC is used to investigate each particular combination between the modulation method and the common mode ZSS. © 2017 Elsevier B.V.","Losses; MMC; Power quality; Pulse width modulation (PWM)","Electric inverters; Electric power transmission; Losses; Modulation; Power quality; Pulse width modulation; Voltage control; Converter performance; Modular multi-level converters; Modulation techniques; Multilevel inverter; Pulse with modulation; Ranking and selection; Renewable energy integrations; Three-phase inverter; Power converters",2-s2.0-85030476591
"Wang H.E., Friston K.J., Bénar C.G., Woodman M.M., Chauvel P., Jirsa V., Bernard C.","MULAN: Evaluation and ensemble statistical inference for functional connectivity",2018,"NeuroImage",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032791296&doi=10.1016%2fj.neuroimage.2017.10.036&partnerID=40&md5=662960019e1a7a98728976238977fea0","Many analysis methods exist to extract graphs of functional connectivity from neuronal networks. Confidence in the results is limited because, (i) different methods give different results, (ii) parameter setting directly influences the final result, and (iii) systematic evaluation of the results is not always performed. Here, we introduce MULAN (MULtiple method ANalysis), which assumes an ensemble based approach combining multiple analysis methods and fuzzy logic to extract graphs with the most probable structure. In order to reduce the dependency on parameter settings, we determine the best set of parameters using a genetic algorithm on simulated datasets, whose temporal structure is similar to the experimental one. After a validation step, the selected set of parameters is used to analyze experimental data. The final step cross-validates experimental subsets of data and provides a direct estimate of the most likely graph and our confidence in the proposed connectivity. A systematic evaluation validates our strategy against empirical stereotactic electroencephalography (SEEG) and functional magnetic resonance imaging (fMRI) data. © 2017",,,2-s2.0-85032791296
"Mikno Z., Pilarczyk A., Korzeniowski M., Kustroń P., Ambroziak A.","Analysis of resistance welding processes and expulsion of liquid metal from the weld nugget",2018,"Archives of Civil and Mechanical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032796504&doi=10.1016%2fj.acme.2017.08.003&partnerID=40&md5=41acb6ebede526974fdb8ab527e2dca4","The article presents the process of resistance welding in relation to the expulsion of liquid metal from the weld nugget. The research-related tests involved the synchronic recording of welding process parameters such as welding current and voltage as well as electrode force and travel. The phenomenon of expulsion was filmed using a high speed camera. The tests aimed to determine the most effective parameter as regards the detection of expulsion as well as the accurate determination of the moment of expulsion in relation to the above-named parameter. During the tests it appeared that the most favourable parameter was the force of electrodes. The tests required the precise synchronisation of the recording of process parameters with the recording of images (using the camera). The uncertainty of expulsion time determination was estimated at 0.1 ms. The research-related experimental tests were focused on the possibility of eliminating expulsion by stopping (blocking) the flow of welding current. In the case of expulsion, the process of welding was continued with a delayed second current pulse. The force signal, on the basis of which the expulsion detection was performed, was analysed using a dedicated controller which implementing the algorithm of discreet differentiation. The tests were performed using an inverter welding machine having an internal transformation frequency of 10 kHz. In this study, SORPAS software-aided FEM analysis was performed to analyse the possibility of the effective reduction of the expulsion phenomenon. © 2017 Politechnika Wrocławska","Expulsion from welding nugget; Resistance spot welding; Resistance spot welding process controller","Cameras; Electric welding; Electrodes; High speed cameras; Liquid metals; Metal analysis; Process control; Resistance welding machines; Spot welding; Uncertainty analysis; Welding; Welding electrodes; Welds; Dedicated controllers; Effective parameters; Expulsion from welding nugget; Process parameters; Resistance spot welding; Time determination; Transformation frequency; Welding process parameters; Resistance welding",2-s2.0-85032796504
"Marten D., Pechlivanoglou G., Nayeri C.N., Paschereit C.O.","Nonlinear lifting line theory applied to vertical axis wind turbines: Development of a practical design tool",2018,"Journal of Fluids Engineering, Transactions of the ASME",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032616419&doi=10.1115%2f1.4037978&partnerID=40&md5=01f7d50b712757652e6fdd1dadc4d3ea","Recently, a new interest in vertical axis wind turbine (VAWT) technology is fueled by research on floating support structures for large-scale offshore wind energy application. For the application on floating structures at multimegawatt size, the VAWT concept may offer distinct advantages over the conventional horizontal axis wind turbine (HAWT) design. As an example, VAWT turbines are better suited for upscaling, and at multimegawatt size, the problem of periodic fatigue cycles reduces significantly due to a very low rotational speed. Additionally, the possibility to store the transmission and electricity generation system at the bottom, compared to the tower top as in a HAWT, can lead to a considerable reduction of material logistics costs. However, as most VAWT research stalled in the mid 1990s, no sophisticated and established tools to investigate this concept further exist today. Due to the complex interaction between unsteady aerodynamics and movement of the floating structure, fully coupled simulation tools modeling both aero and structural dynamics are needed. A nonlinear lifting line free vortex wake (LLFVW) code was recently integrated into the open source wind turbine simulation suite QBLADE. This paper describes some of the necessary adaptions of the algorithm, which differentiates it from the usual application in HAWT simulations. A focus is set on achieving a high robustness and computational efficiency. A short validation study compares LLFVW results with those of a two-dimensional (2D) unsteady Reynolds-averaged Navier-Stokes (URANS) simulation. Copyright © 2018 by ASME.",,"Computation theory; Computational efficiency; Navier Stokes equations; Open systems; Structural dynamics; Vortex flow; Wind power; Electricity-generation system; Horizontal axis wind turbines; Off-shore wind energy; Two Dimensional (2 D); Unsteady aerodynamics; Unsteady reynolds-averaged navier-stokes; Vertical axis wind turbines; Wind turbine simulation; Wind turbines",2-s2.0-85032616419
"Guo T., Huang M., Zhu Q., Guo Y., Qin J.","Hyperspectral image-based multi-feature integration for TVB-N measurement in pork",2018,"Journal of Food Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029230417&doi=10.1016%2fj.jfoodeng.2017.09.003&partnerID=40&md5=1e2321d71de94b2004af2c59f69dcf52","Total volatile basic nitrogen (TVB-N) content is an important index used to evaluate the freshness of pork. In this paper, a strategy for measurement of TVB-N content in pork through hyperspectral imaging (HSI) (400–1000 nm) was developed. Firstly, image textural features based on Gabor filter and spectral features were obtained from the hyperspectral image after determining the region of interest. Then, nine feature wavelengths were selected using partial least-squares projection algorithm. And, major components were obtained from the 2D principal component analysis (2DPCA). Finally, a calibration model was established based on major components using least-squares support vector machine to predict TVB-N values. The results of two methods for data fusion, which are 2DPCA and principal component analysis (PCA), are compared. The correlation coefficients of prediction (RP) and root-mean-square errors of prediction (RMSEP) obtained through 2DPCA were 0.955 and 1.86 mg/100 g respectively, which was superior to the results based on PCA (RP = 0.944, RMSEP = 2.07 mg/100 g). Compared to PCA, the residual prediction deviations (RPD) based on 2DPCA was raised from 3.01 to 3.35. Results demonstrated that the proposed model based on 2DPCA exhibited potential for nondestructive detection of TVB-N content in pork. © 2017 Elsevier Ltd","Gabor filter; Hyperspectral imaging; Nondestructive detection; Total volatile basic nitrogen; Two-dimensional principal component analysis","Data fusion; Forecasting; Gabor filters; Hyperspectral imaging; Image segmentation; Least squares approximations; Machine components; Mean square error; Meats; Nitrogen; Spectroscopy; 2d principal component analysis; Correlation coefficient; Least squares support vector machines; Nondestructive detection; Partial least square (PLS); Root mean square errors; Total volatile basic nitrogens; Two dimensional principal component analysis; Principal component analysis",2-s2.0-85029230417
"Vinayagam A., Alqumsan A.A., Swarna K.S.V., Khoo S.Y., Stojcevski A.","Intelligent control strategy in the islanded network of a solar PV microgrid",2018,"Electric Power Systems Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031711084&doi=10.1016%2fj.epsr.2017.10.006&partnerID=40&md5=46744bdb80c5b72904b310663bcdb291","In the islanded mode of MG network, due to the lack of inertia and under performance of PI based inverter control, variation in power and frequency level can be expected more during the transient conditions as compared to the grid connected mode. Thus, in this study, a Particle Swarm Optimization (PSO) algorithm with the proposed cost function was implemented in the Grid-support grid-forming (GsGfm) type Voltage Source Inverter (VSI) of the DG sources (solar PV and battery unit) for the islanded photovoltaic (PV) based MG model (built in Matlab-Simulink software environment) to reduce the variation in power and frequency level. The islanded MG model was also implemented with a reverse droop based on virtual impedance control strategy for the VSI and power management control strategy to ensure better power sharing among DG sources with regulation of frequency level and power balance with co-ordinated control operation of DG sources. Implementation of PSO based intelligent control strategy for the inverters of DG units, showed substantial improvement in the performance of controller in terms of reduced settling time and overshoot in power level along with the significant reduction of the power variation and frequency variation during the transient conditions (change in load and change in solar irradiance of PV units). Also proposed PSO control strategy ensured the frequency level to be within the acceptable operating range (Australian network standard) in the islanded MG network. © 2017 Elsevier B.V.","Distributed generation; intelligent control strategy; Microgrid; Particle swarm optimization; Power management","Cost functions; Distributed power generation; Electric inverters; Electric power transmission networks; Energy management; Intelligent control; MATLAB; Particle swarm optimization (PSO); Power control; Power management; Solar power generation; Co-ordinated control; Frequency variation; Grid-connected modes; Intelligent control strategies; Matlab-Simulink software; Micro grid; Transient conditions; Voltage source inverter; Electric power system control",2-s2.0-85031711084
"Liu Z., Wang Z., Lv X., Zhu X., Chen L., Ni L.","Comparison study of the volatile profiles and microbial communities of Wuyi Qu and Gutian Qu, two major types of traditional fermentation starters of Hong Qu glutinous rice wine",2018,"Food Microbiology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029579915&doi=10.1016%2fj.fm.2017.07.019&partnerID=40&md5=878d10c255f384c05728757bc8c9fca9","Hong Qu, which mainly contains Monascus sp. and other microorganisms, as well as numerous microbial metabolites, is used as the fermentation starter of Hong Qu glutinous rice wine, a traditional alcoholic beverage. Two widely-used types of Hong Qu, namely Wuyi Qu (WYQ) and Gutian Qu (GTQ), were thoroughly compared for their fermentation properties, volatile profiles, and microbiota structures in this study. Significantly higher color value, glucoamylase and α-amylase activities were discovered in WYQ. And substantial variation in volatile components and microbial communities were also observed between them. It was identified that bacterial genus Burkholderia dominated GTQ (71.62%) and Bacillus dominated WYQ (44.73%), while Monascus purpureus was the most abundant fungal species in both types of starters (76.99%). In addition, 213 bacterial genera and 150 fungal species with low-abundance were also detected. Since the Linear Discriminant Analysis Effect Size algorithm, 14 genus-level bacterial taxa and 10 species-level fungal taxa could be utilized to distinguish these two types of starters. Moreover, the potential correlation of the volatile components and microbiota within WYQ and GTQ were further analyzed, by utilizing Partial Least Squares Discriminant Analysis. Ultimately, this study provides detailed insight into the volatile profiles and microbial communities presented in Hong Qu. © 2017 Elsevier Ltd","Bacterial community; Fungal community; High throughput sequencing; Hong Qu glutinous rice wine starter; Monascus purpureus; Volatile components",,2-s2.0-85029579915
"Wang L., Liu Y., Zhao L., Wang Q., Zeng X., Chen K.","Acoustic source localization in strong reverberant environment by parametric Bayesian dictionary learning",2018,"Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029529734&doi=10.1016%2fj.sigpro.2017.09.005&partnerID=40&md5=1570ef514695a7ed7abdf9a868991ee5","Sparse representation techniques have become increasingly promising for localizing the sound source in reverberant environment, where the multipath channel effects can be accurately characterized by the image model. In this paper, a dictionary is constructed by discretizing the inner space of the enclosure, which is parameterized by the unknown energy reflective ratio. More specifically, each atom of the dictionary can characterize a specific source-to-microphone multipath channel. Subsequently, source localization can be reformulated as a joint sparse signal recovery and parametric dictionary learning problem. In particular, a sparse Bayesian framework is utilized for modeling, where its solution can be obtained by variational Bayesian expectation maximization technique. Moreover, the joint sparsity in frequency domain is exploited to improve the dictionary learning performances. A remarkably advantage of this approach is that no laborious parameter tuning procedure is required and statistical information can be provided. Numerical simulation results have shown that the proposed algorithm achieves high source localization accuracy, low sidelobes and high robustness for multiple sources with low computational complexity in strong reverberant environments, compared with other state-of-the-art methods. © 2017 Elsevier B.V.","Parametric dictionary learning; Reverberant environment; Source localization; Sparse Bayesian method","Acoustics; Bayesian networks; Frequency domain analysis; Maximum principle; Multipath propagation; Numerical methods; Acoustic source localization; Dictionary learning; Low computational complexity; Reverberant environment; Source localization; Sparse bayesian; State-of-the-art methods; Statistical information; Reverberation",2-s2.0-85029529734
"Xiao S., Lu Z., Wang P.","Multivariate global sensitivity analysis for dynamic models based on wavelet analysis",2018,"Reliability Engineering and System Safety",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032014238&doi=10.1016%2fj.ress.2017.10.007&partnerID=40&md5=8255d92572b201a9300084a1b155af48","Dynamic models with time-dependent output are widely used in engineering for risk assessment and decision making. Global sensitivity analysis for these models is very useful for simplifying the model, improving the model performance, etc. The existent covariance decomposition based global sensitivity analysis method combines the variance based sensitivity analysis results of the model output at all the instants, which just utilizes the information of the time-dependent output in time domain. However, many significant features of time-dependent output may not be obtained from the time domain. Thus, performing global sensitivity analysis for dynamic models just with the information in time domain may be incomplete. In this paper, a new kind of sensitivity indices based on wavelet analysis is proposed. The energy distribution of model output over different frequency bands is extracted as a quantitative feature of the time-dependent output, and it contains the information of model output in both time and frequency domains. Then, a vector projection method is utilized to measure the effects of input variables on the energy distribution of model output. An efficient algorithm is also proposed to estimate the new sensitivity indices. The numerical examples show the difference between the new sensitivity indices and the covariance decomposition based sensitivity indices. Finally, the new sensitivity indices are applied to an environmental model to tell the relative importance of the input variables, which can be useful for improving the model performance. © 2017 Elsevier Ltd","Dynamic model; Energy distribution; Global sensitivity analysis; Wavelet analysis","Decision making; Dynamic models; Frequency bands; Risk assessment; Sensitivity analysis; Wavelet analysis; Covariance decompositions; Different frequency; Energy distributions; Environmental model; Global sensitivity analysis; Quantitative features; Time and frequency domains; Variance-based sensitivity analysis; Time domain analysis",2-s2.0-85032014238
"Santhosh T.V., Gopika V., Ghosh A.K., Fernandes B.G.","An approach for reliability prediction of instrumentation & control cables by artificial neural networks and Weibull theory for probabilistic safety assessment of NPPs",2018,"Reliability Engineering and System Safety",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032202427&doi=10.1016%2fj.ress.2017.10.010&partnerID=40&md5=d289f12bf803111be871473fe0903d7b","The polymeric materials used for insulation and sheath in instrumentation and control (I&C) cables of nuclear power plants (NPPs) are subjected to degradation due to various stressors. The prediction of long-term aging and lifetime of cables is generally determined based on accelerated life testing (ALT) experiments which are not only expensive but also time consuming. Application of artificial neural networks (ANNs) in the field of transient diagnosis and condition assessment of electrical and other equipment has been a promising technique; however the use of ANN for reliability prediction of I&C cables has not yet been studied. This paper presents an integrated approach to predict the lifetime and reliability of I&C cables by ANN from the accelerated aging data. In order to validate the proposed methodology for use in probabilistic safety assessment (PSA) of NPP to account for the cable failures, ALT data on a typical cross-linked polyethylene (XLPE) insulated I&C cable has been referred from the literature. The time dependent reliability was predicted by considering the various failure rates. Study demonstrates that by an appropriate training algorithm with suitable network architecture, it is possible to predict the reliability of I&C cables by ANN with the minimal accelerated life testing. © 2017 Elsevier Ltd","Accelerated life testing; Artificial neural networks; Insulation resistance; Nuclear power plants; Probabilistic safety assessment; Weibull reliability","Cables; Electron emission; Failure analysis; Forecasting; Network architecture; Neural networks; Nuclear energy; Nuclear fuels; Nuclear power plants; Polyethylenes; Reliability; Reliability theory; Safety engineering; Safety testing; Accelerated life testing; Crosslinked polyethylene; Instrumentation and control; Insulation resistance; Probabilistic safety assessment; Reliability prediction; Time dependent reliability; Weibull; Cable sheathing",2-s2.0-85032202427
"Kim K., Kang S., Cho H., Kang W., Seo C., Park C., Lee D., Lim H., Lee H., Kim G., Park S., Park J., Kim W., Jeon D., Woo T., Oh J.","A model-based radiography restoration method based on simple scatter-degradation scheme for improving image visibility",2018,"Optics and Lasers in Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031115535&doi=10.1016%2fj.optlaseng.2017.09.022&partnerID=40&md5=e8fbc151fe344615f8c2f670f2d9b6bb","In conventional planar radiography, image visibility is often limited mainly due to the superimposition of the object structure under investigation and the artifacts caused by scattered x-rays and noise. Several methods, including computed tomography (CT) as a multiplanar imaging modality, air-gap and grid techniques for the reduction of scatters, phase-contrast imaging as another image-contrast modality, etc., have extensively been investigated in attempt to overcome these difficulties. However, those methods typically require higher x-ray doses or special equipment. In this work, as another approach, we propose a new model-based radiography restoration method based on simple scatter-degradation scheme where the intensity of scattered x-rays and the transmission function of a given object are estimated from a single x-ray image to restore the original degraded image. We implemented the proposed algorithm and performed an experiment to demonstrate its viability. Our results indicate that the degradation of image characteristics by scattered x-rays and noise was effectively recovered by using the proposed method, which improves the image visibility in radiography considerably. © 2017 Elsevier Ltd","Image visibility; Model-based restoration; Scatter-degradation scheme","Image enhancement; Image reconstruction; Photodegradation; Radiography; Restoration; Visibility; X ray radiography; Image characteristics; Imaging modality; Model-based OPC; Object structure; Phase-contrast imaging; Restoration methods; Scattered X-rays; Transmission function; Computerized tomography",2-s2.0-85031115535
"Zhen X., Yong Y., Chun Guang X., Ding Guo X., Fang Fang L., Xin Liang L.","Profile tracking with ultrasonic alignment for automatic Non-destructive testing of complex structures",2018,"Robotics and Computer-Integrated Manufacturing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021648740&doi=10.1016%2fj.rcim.2017.06.007&partnerID=40&md5=54d74e63ad4311d4daf7bf4439c51ecd","Micro-defects located on complex geometrical structures are difficult to inspect using traditional non-destructive testing (NDT) equipment, especially for those aerospace components that have obvious variation of thickness. This is because the tracking of the profile of the test surface cannot usually satisfy the requirements of high-accuracy measurement so that the inspection results are inaccurate. In this paper, an industrial robot is used as an auxiliary test method to realize the inspection scanning motion. Matrix transformation of the robotic orientation is proposed to investigate the correct spatial relationship between the specimen and the ultrasonic probe, based on the mathematical models of coordinate conversion between the user frame and the robotic tool frame. The ultrasonic waves reflected by the test surface were used to find and represent the character of the defects in the specimen. Moreover, robotic orientation is calibrated by the ultrasonic alignment method based on the quaternion algorithm, so the robot can adjust the orientation of the tool frame to satisfy the ultrasonic incident angle constraints, and the precision of robotic trajectory is enhanced compared to that of other NDT methods. Our experimental results verified the accuracy of robotic scanning trajectory while the defect character can be captured from the ultrasonic echo waves. If the proposed approach is used, the trajectory error is no more than 0.275 mm with respect to the test specimen. Signals collected from echo waves can be transformed into ultrasonic images and the integrity of the specimen is evaluated based on those signals. In addition, the distribution of defects in the specimen was shown with a higher resolution of 0.15 mm derived from the distance between the adjacent points, if the robotic orientation is correct at each point in the scanning trajectory. © 2017 Elsevier Ltd","Coordinate conversion; Matrix transform; Quaternion; Robotic scanning trajectory; Ultrasonic alignment","Alignment; Inspection; Linear transformations; Mathematical transformations; Nanocomposites; Nondestructive examination; Robotics; Scanning; Surface defects; Trajectories; Ultrasonic applications; Ultrasonic imaging; Coordinate conversion; High-accuracy measurements; Matrix transformation; Matrix transforms; Non destructive testing; Quaternion; Scanning trajectory; Spatial relationships; Ultrasonic testing",2-s2.0-85021648740
"Shao W.J., Huang Y., Zhang Y.","A novel weld seam detection method for space weld seam of narrow butt joint in laser welding",2018,"Optics and Laser Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030708248&doi=10.1016%2fj.optlastec.2017.09.037&partnerID=40&md5=9dc447eb7f1e0ff00c0e3154076b1f2e","Structured light measurement is widely used for weld seam detection owing to its high measurement precision and robust. However, there is nearly no geometrical deformation of the stripe projected onto weld face, whose seam width is less than 0.1 mm and without misalignment. So, it's very difficult to ensure an exact retrieval of the seam feature. This issue is raised as laser welding for butt joint of thin metal plate is widely applied. Moreover, measurement for the seam width, seam center and the normal vector of the weld face at the same time during welding process is of great importance to the welding quality but rarely reported. Consequently, a seam measurement method based on vision sensor for space weld seam of narrow butt joint is proposed in this article. Three laser stripes with different wave length are project on the weldment, in which two red laser stripes are designed and used to measure the three dimensional profile of the weld face by the principle of optical triangulation, and the third green laser stripe is used as light source to measure the edge and the centerline of the seam by the principle of passive vision sensor. The corresponding image process algorithm is proposed to extract the centerline of the red laser stripes as well as the seam feature. All these three laser stripes are captured and processed in a single image so that the three dimensional position of the space weld seam can be obtained simultaneously. Finally, the result of experiment reveals that the proposed method can meet the precision demand of space narrow butt joint. © 2017 Elsevier Ltd","Butt joint; Laser welding; Seam detection; Structure light; Vision sensor","Butt welding; Image processing; Laser beam welding; Light sources; Optical data processing; Plate metal; Welding; Butt joints; Geometrical deformation; Optical triangulations; Seam detection; Structure light; Structured-light measurement; Three-dimensional profiles; Vision sensors; Welds",2-s2.0-85030708248
"Wang C., Guan W., Wang J.Y., Zhong B., Lai X., Chen Y., Xiang L.","Adaptive operational modal identification for slow linear time-varying structures based on frozen-in coefficient method and limited memory recursive principal component analysis",2018,"Mechanical Systems and Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028735151&doi=10.1016%2fj.ymssp.2017.06.018&partnerID=40&md5=b04f638f9af13ff0ae5a5512ec3c0d8f","To adaptively identify the transient modal parameters for linear weakly damped structures with slow time-varying characteristics under unmeasured stationary random ambient loads, this paper proposes a novel operational modal analysis (OMA) method based on the frozen-in coefficient method and limited memory recursive principal component analysis (LMRPCA). In the modal coordinate, the random vibration response signals of mechanical weakly damped structures can be decomposed into the inner product of modal shapes and modal responses, from which the natural frequencies and damping ratios can be well acquired by single-degree-of-freedom (SDOF) identification approach such as FFT. Hence, for the OMA method based on principal component analysis (PCA), it becomes very crucial to examine the relation between the transformational matrix and the modal shapes matrix, to find the association between the principal components (PCs) matrix and the modal responses matrix, and to turn the operational modal parameter identification problem into PCA of the stationary random vibration response signals of weakly damped mechanical structures. Based on the theory of “time-freezing”, the method of frozen-in coefficient, and the assumption of “short time invariant” and “quasistationary”, the non-stationary random response signals of the weakly damped and slow linear time-varying structures (LTV) can approximately be seen as the stationary random response time series of weakly damped and linear time invariant structures (LTI) in a short interval. Thus, the adaptive identification of time-varying operational modal parameters is turned into decompositing the PCs of stationary random vibration response signals subsection of weakly damped mechanical structures after choosing an appropriate limited memory window. Finally, a three-degree-of-freedom (DOF) structure with weakly damped and slow time-varying mass is presented to illustrate this method of identification. Results show that the LMRPCA algorithm, which is robustness to Gauss measurement noise disturbances, can well identify the transient modal parameters (transient natural frequencies & transient modal shapes) for weakly damped and slow LTV structures online only from non-stationary random response signals. © 2017","Frozen-in coefficient method; Limited memory; Non-stationary random response signals; Operational modal analysis; Recursive principal component analysis; Slow linear time-varying structure; Time-freezing; Weakly damped","Composite beams and girders; Degrees of freedom (mechanics); Freezing; Identification (control systems); Matrix algebra; Modal analysis; Natural frequencies; Parameter estimation; Vibration analysis; Vibrations (mechanical); Coefficient methods; Limited memory; Linear time varying; Nonstationary; Operational modal analysis; Recursive principal component analysis; Weakly damped; Principal component analysis",2-s2.0-85028735151
"Rastak R., Linder C.","A non-affine micro-macro approach to strain-crystallizing rubber-like materials",2018,"Journal of the Mechanics and Physics of Solids",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032692127&doi=10.1016%2fj.jmps.2017.10.007&partnerID=40&md5=2681d46d794985ed8e6a25c0d0637702","Crystallization can occur in rubber materials at large strains due to a phenomenon called strain-induced crystallization. We propose a multi-scale polymer network model to capture this process in rubber-like materials. At the microscopic scale, we present a chain formulation by studying the thermodynamic behavior of a polymer chain and its crystallization mechanism inside a stretching polymer network. The chain model accounts for the thermodynamics of crystallization and presents a rate-dependent evolution law for crystallization based on the gradient of the free energy with respect to the crystallinity variables to ensures the dissipation is always non-negative. The multiscale framework allows the anisotropic crystallization of rubber which has been observed experimentally. Two different approaches for formulating the orientational distribution of crystallinity are studied. In the first approach, the algorithm tracks the crystallization at a finite number of orientations. In contrast, the continuous distribution describes the crystallization for all polymer chain orientations and describes its evolution with only a few distribution parameters. To connect the deformation of the micro with that of the macro scale, our model combines the recently developed maximal advance path constraint with the principal of minimum average free energy, resulting in a non-affine deformation model for polymer chains. Various aspects of the proposed model are validated by existing experimental results, including the stress response, crystallinity evolution during loading and unloading, crystallinity distribution, and the rotation of the principal crystallization direction. As a case study, we simulate the formation of crystalline regions around a pre-existing notch in a 3D rubber block and we compare the results with experimental data. © 2017 Elsevier Ltd","Homogenization; Maximal advance path constraint; Micromechanics; Rubber-like materials; Strain-induced crystallization","Deformation; Free energy; Homogenization method; Micromechanics; Polymers; Strain; Stress analysis; Thermodynamics; Unloading; Continuous distribution; Crystallinity distribution; Crystallization mechanisms; Orientational distributions; Path constraint; Polymer chain orientation; Rubberlike materials; Straininduced crystallization; Rubber",2-s2.0-85032692127
"Jouen A.L., Ellmore T.M., Madden-Lombardi C.J., Pallier C., Dominey P.F., Ventre-Dominey J.","Beyond the word and image: II- Structural and functional connectivity of a common semantic system",2018,"NeuroImage",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032838050&doi=10.1016%2fj.neuroimage.2017.10.039&partnerID=40&md5=fc0b9a85c9135ef7b3b55ef0c6b4eee0","Understanding events requires interplaying cognitive processes arising in neural networks whose organisation and connectivity remain subjects of controversy in humans. In the present study, by combining diffusion tensor imaging and functional interaction analysis, we aim to provide new insights on the organisation of the structural and functional pathways connecting the multiple nodes of the identified semantic system -shared by vision and language (Jouen et al., 2015). We investigated a group of 19 healthy human subjects during experimental tasks of reading sentences or seeing pictures. The structural connectivity was realised by deterministic tractography using an algorithm to extract white matter fibers terminating in the selected regions of interest (ROIs) and the functional connectivity by independent component analysis to measure correlated activities among these ROIs. The major connections link ventral neural stuctures including the parietal and temporal cortices through inferior and middle longitudinal fasciculi, the retrosplenial and parahippocampal cortices through the cingulate bundle, and the temporal and prefrontal structures through the uncinate fasciculus. The imageability score provided when the subject was reading a sentence was significantly correlated with the factor of anisotropy of the left parieto-temporal connections of the middle longitudinal fasciculus. A large part of this ventrally localised structural connectivity corresponds to functional interactions between the main parietal, temporal and frontal nodes. More precisely, the strong coactivation both in the anterior temporal pole and in the region of the temporo-parietal cortex suggests dual and cooperating roles for these areas within the semantic system. These findings are discussed in terms of two semantics-related sub-systems responsible for conceptual representation. © 2017 Elsevier Inc.","Cognitive functions- semantic framework- human; Diffusion tension imaging- functional interaction; Multimodal",,2-s2.0-85032838050
"Wang S., Chen X., Selesnick I.W., Guo Y., Tong C., Zhang X.","Matching synchrosqueezing transform: A useful tool for characterizing signals with fast varying instantaneous frequency and application to machine fault diagnosis",2018,"Mechanical Systems and Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028700576&doi=10.1016%2fj.ymssp.2017.07.009&partnerID=40&md5=5f9c8fb9d9f2c8e8be62ac954661c912","Synchrosqueezing transform (SST) can effectively improve the readability of the time-frequency (TF) representation (TFR) of nonstationary signals composed of multiple components with slow varying instantaneous frequency (IF). However, for signals composed of multiple components with fast varying IF, SST still suffers from TF blurs. In this paper, we introduce a time-frequency analysis (TFA) method called matching synchrosqueezing transform (MSST) that achieves a highly concentrated TF representation comparable to the standard TF reassignment methods (STFRM), even for signals with fast varying IF, and furthermore, MSST retains the reconstruction benefit of SST. MSST captures the philosophy of STFRM to simultaneously consider time and frequency variables, and incorporates three estimators (i.e., the IF estimator, the group delay estimator, and a chirp-rate estimator) into a comprehensive and accurate IF estimator. In this paper, we first introduce the motivation of MSST with three heuristic examples. Then we introduce a precise mathematical definition of a class of chirp-like intrinsic-mode-type functions that locally can be viewed as a sum of a reasonably small number of approximate chirp signals, and we prove that MSST does indeed succeed in estimating chirp-rate and IF of arbitrary functions in this class and succeed in decomposing these functions. Furthermore, we describe an efficient numerical algorithm for the practical implementation of the MSST, and we provide an adaptive IF extraction method for MSST reconstruction. Finally, we verify the effectiveness of the MSST in practical applications for machine fault diagnosis, including gearbox fault diagnosis for a wind turbine in variable speed conditions and rotor rub-impact fault diagnosis for a dual-rotor turbofan engine. © 2017 Elsevier Ltd","Dual-rotor engine; Gearbox; Instantaneous frequency; Machine fault diagnosis; Matching synchrosqueezing transform; Reassignment; Synchrosqueezing transform; Time-frequency analysis","Chirp modulation; Engines; Estimation; Failure analysis; Fault detection; Frequency estimation; Functions; Gears; Numerical methods; Turbofan engines; Wind turbines; Dual rotors; Gearbox; Instantaneous frequency; Machine fault diagnosis; Reassignment; Synchrosqueezing; Time frequency analysis; Group delay",2-s2.0-85028700576
"Conde A., Arriandiaga A., Sanchez J.A., Portillo E., Plaza S., Cabanes I.","High-accuracy wire electrical discharge machining using artificial neural networks and optimization techniques",2018,"Robotics and Computer-Integrated Manufacturing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019980913&doi=10.1016%2fj.rcim.2017.05.010&partnerID=40&md5=bf46014e8aaaba17078035c01c2e6aa9","For many industrial sectors, high-added value components are related to high accuracy manufacturing technologies. Wire Electrical Discharge Machining (WEDM) is an advanced non-conventional machining method commonly used in the production of precision components in extremely hard materials. The precision of the process depends largely on the deformation of the wire tool. Whilst theoretical models allow a scientific understanding of the causes of a lack of accuracy, they still lack the level of precision required to predict actual deviations in industrial products. In this work, we propose a way to predict the accuracy of components produced by WEMD by using an Elman-based Layer Recurrent Neural Network (LRNN). The results reveal that the average deviation between network predictions and actual components is below 6Î¼m, which implies extremely good performance of the net. In a further step, an algorithm was proposed for designing wire paths of variable radius, so that the deviations in the machined parts can be corrected via software. By combining the predictions of the developed LRNN with the Simulated Annealing (SA) optimization technique, wire paths of variable radius can be designed, so that radial deviations due to wire deformations can be minimized. The results show that the new proposal is very efficient in those situations in which wire deformation is greatest. In other words, when the part radius is low and part height is large, the stiffness of the wire is reduced and the error of the part sharply increases. In these cases, the average deviation was reduced by as much as 80%, and the Coefficient of Variation (CV) was decreased by 43%. The solution can be readily implemented on any existing WEDM machine. © 2017 Elsevier Ltd","Advanced manufacturing; Artificial neural networks; Path optimization; Simulated annealing; Wire electrical discharge machining","Deformation; Electric discharge machining; Electric discharges; Forecasting; Manufacture; Network layers; Neural networks; Recurrent neural networks; Simulated annealing; Advanced manufacturing; Coefficient of variation; Manufacturing technologies; Nonconventional machining; Optimization techniques; Path optimizations; Precision components; Wire electrical discharge machining; Wire",2-s2.0-85019980913
"Dagla I., Benaki D., Baira E., Lemonakis N., Poudyal H., Brown L., Tsarbopoulos A., Skaltsounis A.-L., Mikros E., Gikas E.","Alteration in the liver metabolome of rats with metabolic syndrome after treatment with Hydroxytyrosol. A Mass Spectrometry And Nuclear Magnetic Resonance - based metabolomics study",2018,"Talanta",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029707140&doi=10.1016%2fj.talanta.2017.09.029&partnerID=40&md5=84197c2eee72f5c369e49611f57d158a","Metabolic syndrome (MetS) represents a group of abnormalities that enhances the risk for cardiovascular disease, diabetes and stroke. The Mediterranean diet seems to be an important dietary pattern, which reduces the incidence of MetS. Hydroxytyrosol (HT) - a simple phenol found in olive oil - has received increased attention for its antioxidant activity. Recently, the European Foods Safety Authority (EFSA) claimed that dietary consumption of HT exhibits a protective role against cardiovascular disease. In this study, an experimental protocol has been setup, including isolated HT administration in a diet induced model of MetS in young Wistar rats, in order to find out whether HT has a protective effect against MetS. Rats were randomly divided into two groups nurtured by high-carbohydrate high-fat (H) (MetS inducing diet) and high-carbohydrate high-fat + HT (HHT). HT (20 mg/kg/d oral gavage, water vehicle) was administered for 8 weeks on the basal diet. Previous pharmacological evaluation of HT showed that hepatic steatosis was reduced and the inflammatory cells into the liver were infiltrated. These indicate that HT shows bioactivity against metabolic syndrome. Therefore, the metabolomics evaluation of liver extracts would indicate the putative biochemical mechanisms of HT activity. Thus, the extracts of liver tissues were analyzed using Ultra Performance Liquid Chromatography – High Resolution Mass Spectrometry (UPLC-HRMS, Orbitrap Discovery) and Nuclear Magnetic Resonance (NMR) spectroscopy (Bruker Avance III 600 MHz). Multivariate analysis was performed in order to gain insight on the metabolic effects of HT administration on the liver metabolome. Normalization employing multiple internal standards and Quality Control–based Robust LOESS (LOcally Estimated Scatterplot Smoothing) Signal Correction algorithm (QC-RLSC) was added in the processing pipeline to enhance the reliability of metabolomic analysis by reducing unwanted information. Experimentally, HHT rats were clearly distinguished from H in PLS-DA, showing differences in the liver metabolome between the groups and specific biomarkers were determined supporting the pharmacological findings. More specifically, HT has shown to be effective towards the mobilization of lipids as various lipid classes being differentially regulated between the H and HHT groups. Interestingly branched fatty acid esters of hydroxy oleic acids (OAHSA) lipids have been shown to be up regulated to the HHT group, denoting the alleviation of the MetS to the animals administered with HT. © 2017 Elsevier B.V.","Hydroxytyrosol; Metabolic syndrome; Metabolomics; MS; NMR","Bioactivity; Carbohydrates; Cardiology; Diseases; Fatty acids; Lipids; Liquid chromatography; Magnetic levitation vehicles; Mass spectrometry; Metabolism; Multivariant analysis; Nuclear magnetic resonance spectroscopy; Oils and fats; Olive oil; Plants (botany); Quality control; Rats; Reliability analysis; Spectrometry; Anti-oxidant activities; High resolution mass spectrometry; Hydroxytyrosol; Metabolic syndromes; Metabolomics; Multiple internal standards; Nuclear magnetic resonance(NMR); Ultra performance liquid chromatography; Nuclear magnetic resonance",2-s2.0-85029707140
"Vincent S., Lemercier B., Berthier L., Walter C.","Spatial disaggregation of complex Soil Map Units at the regional scale based on soil-landscape relationships",2018,"Geoderma",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994357191&doi=10.1016%2fj.geoderma.2016.06.006&partnerID=40&md5=cfeb68a146b8f2aeec2e1b03eaece9b7","Digital soil mapping is becoming a powerful tool to increase the spatial detail of soil information over large areas, which is essential to address agronomic and environmental issues. When it exists, information about soil is often sparse or available at a coarser resolution than required. The spatial distribution of soil at the regional scale is usually represented as a set of polygons defining Soil Map Units (SMUs), each including several Soil Type Units (STUs), which are not spatially delineated but semantically described in a database. Delineation of STUs within SMUs, i.e. spatial disaggregation of SMU, should improve the precision of soil information derived from legacy and ancillary data. The aim of this study was to predict STUs by spatially disaggregating SMUs through a decision-tree approach that considered expert knowledge about soil-landscape relationships embedded in soil databases. In a 27,376 km2 study area in north-western France (Brittany), 434 SMUs were delineated at 1:250,000 scale, and 320 STUs, their relative area in the SMUs, and their geomorphological and geological contexts were described. A calibration dataset of points was established using stratified random sampling (n = 352,188). To retrieve soil-landscape relationships, expert rules for soil distribution defined by soil surveyors and based on topography, parent material and waterlogging index were considered in order to allocate an STU to 83% of the calibration dataset. The calibration dataset and covariates (i.e. pedological, geological and terrain attributes; land use; airborne gamma-ray spectrometry) were then used to build and extrapolate the decision tree using the C.5 algorithm in DSMART software. Several iterations were performed, providing a probability of occurrence of each possible STU within the study area. External validation was performed by comparing predictions of the disaggregation procedure to available soil maps at scales of 1:25,000 or 1:50,000 and observed profiles. Overall accuracies ranged from 41 to 72%, depending on the validation method (per pixel vs. 3 × 3 windows of pixels, per STU vs. STU grouped by semantic proximity (n = 204)). Introducing expert rules based on soil-landscape relationships to allocate STUs to calibration samples enabled production of a soil map with clear spatial structures, yielding expected spatial patterns of soil organisation. Future work notably concerns estimating soil properties at multiple depths deriving from STU predictions, according to the GlobalSoilMap project. © 2016","Classification trees; Digital soil mapping; Regional scale; Soil map units; Soil type units; Soil-landscape ruleset; Spatial disaggregation","Calibration; Data mining; Decision trees; Forecasting; Forestry; Gamma ray spectrometers; Gamma rays; Geology; Land use; Mapping; Pixels; Semantics; Soils; Trees (mathematics); Classification trees; Digital soil mappings; Regional scale; Soil map units; Soil types; Spatial disaggregation; Soil surveys; classification; database; digital map; knowledge; landscape; map; parent material; pixel; regional pattern; soil; soil type; spatial analysis; spatial distribution; topography; waterlogging; Bretagne; France",2-s2.0-84994357191
"Suo T., Wang H., Shi X., Feng L., Cai J., Duan Y., Bao H., Wu X., Zhang Y., Yu H., Li Z.","Combining near infrared spectroscopy with predictive model and expertise to monitor herb extraction processes",2018,"Journal of Pharmaceutical and Biomedical Analysis",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031797714&doi=10.1016%2fj.jpba.2017.10.004&partnerID=40&md5=8bee27f983ebe32992170a8873171b16","Albeit extensively utilized, herb extraction process (HEP) is hard to be monitored because of its batch nature and the fluctuating quality of raw materials. Process analytical tools like near infrared spectroscopy (NIRS) can offer nondestructive examinations and collect abundant data of the process, which in principle contain the information about the quality of both the product and the process itself. However, extra effort is often required for the data mining of such process measurements, and extracting knowledge of the quality of process can be even harder. In this study, we take the extraction process of licorice as a typical HEP instance, and combine NIRS with classical partial least squared regression (PLSR) and expertise for its on-line monitoring. We show that our scheme effectively extracts information with clear physical meanings, through which we can even uncover the process fault that does not induce evident abnormalities in the product quality. Moreover, the constructed model can continuously evolve with more process data from daily operations, and the idea of the whole framework can be directly generalized to other HEP. © 2017 Elsevier B.V.","Batch process monitoring; Herb extraction process; Near infrared spectroscopy; Partial least squared regression; Quality of process; Traditional Chinese medicine","Glycyrrhiza extract; liquiritin; solvent; algorithm; Article; batch process; calibration; chemometrics; extraction; Glycyrrhiza; herb; herb extraction; near infrared spectroscopy; nonhuman; online monitoring; power supply; prediction; priority journal; ultra performance liquid chromatography; workflow",2-s2.0-85031797714
"Ali W., Qyyum M.A., Qadeer K., Lee M.","Energy optimization for single mixed refrigerant natural gas liquefaction process using the metaheuristic vortex search algorithm",2018,"Applied Thermal Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032030292&doi=10.1016%2fj.applthermaleng.2017.10.078&partnerID=40&md5=dc6e35b0c60234f9cfbb2c8595f2ec16","A metaheuristic vortex search algorithm was investigated for the optimization of a single mixed refrigerant (SMR) natural gas liquefaction process. The optimal design of a natural gas liquefaction processes involves multivariable non-linear thermodynamic interactions, which lead to exergy destruction and contribute to process irreversibility. As key decision variables, the optimal values of mixed refrigerant flow rates and process operating pressures were determined in the vortex pattern corresponding to the minimum required energy. In addition, the rigorous SMR process was simulated using Aspen Hysys® software and the resulting model was connected with the vortex search optimization algorithm coded in MATLAB. The optimal operating conditions found by the vortex search algorithm significantly reduced the required energy of the single mixed refrigerant process by ≤41.5% and improved the coefficient of performance by ≤32.8% in comparison with the base case. The vortex search algorithm was also compared with other well-proven optimization algorithms, such as genetic and particle swarm optimization algorithms, and was found to exhibit a superior performance over these existing approaches. © 2017 Elsevier Ltd","Energy efficiency; LNG; Metaheuristics; Natural gas liquefaction; Single mixed refrigerant process; Vortex search optimization","Energy efficiency; Learning algorithms; Liquefaction of gases; Liquefied natural gas; MATLAB; Natural gas; Optimal systems; Particle swarm optimization (PSO); Refrigerants; Vortex flow; Coefficient of Performance; Meta heuristics; Mixed refrigerants; Natural gas liquefaction; Optimal operating conditions; Particle swarm optimization algorithm; Search optimization; Thermodynamic interactions; Optimization",2-s2.0-85032030292
"Kou J., Sun S.","A stable algorithm for calculating phase equilibria with capillarity at specified moles, volume and temperature using a dynamic model",2018,"Fluid Phase Equilibria",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030678351&doi=10.1016%2fj.fluid.2017.09.018&partnerID=40&md5=bed981c7bf2d9150bb0b15f6b104fc8c","Capillary pressure can significantly affect the phase properties and flow of liquid-gas fluids in porous media, and thus, the phase equilibrium calculation incorporating capillary pressure is crucial to simulate such problems accurately. Recently, the phase equilibrium calculation at specified moles, volume and temperature (NVT-flash) becomes an attractive issue. In this paper, capillarity is incorporated into the phase equilibrium calculation at specified moles, volume and temperature. A dynamical model for such problem is developed for the first time by using the laws of thermodynamics and Onsager's reciprocal principle. This model consists of the evolutionary equations for moles and volume, and it can characterize the evolutionary process from a non-equilibrium state to an equilibrium state in the presence of capillarity effect at specified moles, volume and temperature. The phase equilibrium equations are naturally derived. To simulate the proposed dynamical model efficiently, we adopt the convex-concave splitting of the total Helmholtz energy, and propose a thermodynamically stable numerical algorithm, which is proved to preserve the second law of thermodynamics at the discrete level. Using the thermodynamical relations, we derive a phase stability condition with capillarity effect at specified moles, volume and temperature. Moreover, we propose a stable numerical algorithm for the phase stability testing, which can provide the feasible initial conditions. The performance of the proposed methods in predicting phase properties under capillarity effect is demonstrated on various cases of pure substance and mixture systems. © 2017 Elsevier B.V.","Capillarity; Convex-concave splitting; NVT flash; Phase equilibria; Phase stability; Thermodynamical modeling","Capillarity; Capillary flow; Capillary tubes; Evolutionary algorithms; Liquefied gases; Phase stability; Porous materials; Temperature; Thermodynamics; Convex-concave splitting; Evolutionary equation; Laws of thermodynamics; NVT flash; Phase equilibrium calculation; Second Law of Thermodynamics; Thermodynamical model; Thermodynamically stable; Phase equilibria",2-s2.0-85030678351
"Nabipour M.","Prediction of surface tension of binary refrigerant mixtures using artificial neural networks",2018,"Fluid Phase Equilibria",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032257572&doi=10.1016%2fj.fluid.2017.10.020&partnerID=40&md5=310f4ae6c941bcb01869a4f49db3b355","In this work, a trainable feed-forward back-propagation network was developed by employing the Levenberg-Marquardt training algorithm to predict the surface tension of binary refrigerant mixtures. 1260 experimental data were collected from reliable literature to train and test the network. Temperature, critical pressure, critical temperature, critical volume and acentric factor of the binary mixtures were selected as input variables of the proposed network. The optimum number of hidden layers was determined to be 1, with 19 neurons in the hidden layer. Tan−sigmoid and purelin functions was chosen as the transfer functions in the hidden and output layers, respectively. The results revealed that the ANN has the capability to correlate and estimate the surface tension accurately with an overall %AARD and correlation coefﬁcient values of 0.7582 and 0.9997, respectively. In addition, the results were compared to different well-known correlations and models which indicated a better performance of the developed ANN. © 2017 Elsevier B.V.","Artificial neural network; Binary refrigerant mixtures; Modeling; Surface tension","Backpropagation; Backpropagation algorithms; Bins; Mixtures; Models; Neural networks; Refrigerants; Surface tension; Acentric factors; Critical pressures; Critical temperatures; Critical volume; Feed-forward back propagation networks; Input variables; Levenberg-Marquardt training algorithm; Refrigerant mixtures; Binary mixtures",2-s2.0-85032257572
"He K.-L., Chen Q., Dong E.-F., Ge W.-C., Hao J.-H., Xu F.","An improved unit circuit model for transient heat conduction performance analysis and optimization in multi-layer materials",2018,"Applied Thermal Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032696645&doi=10.1016%2fj.applthermaleng.2017.10.149&partnerID=40&md5=5b43e3a8716c96fe30768265cf4dc490","Transient heat conduction analysis and optimization in multi-layer thermal insulation materials (MLTIMs) requires an effective simplified model with certain accuracy. This paper proposes an improved unit circuit model (IUCM) based on the thermo-electrical analogy, where the interface nodes between every two adjacent layers are considered to describe the rapid variations of temperature gradients and heat fluxes at the interfaces. Then, the IUCM for three-layer materials is solved with jump and sinusoidal temperature boundaries, and the obtained temperatures and the outlet heat fluxes are compared to the solutions obtained by the finite volume method as well as other two existing lumped parameter models. The comparison shows that the IUCM reduces the relative mean outlet heat flux error by more than 50% compared to the other models in the studied cases. Applying the IUCM together with the genetic algorithm offers the optimal geometrical structures of three-layer materials, where the optimal structure reduced the outlet heat per unit area by more than 50% compared to the feasible structures. Meanwhile, arranging the mechanical layer with high thermal conductivity between two thermal insulation materials leads to a decrease of about 35% in the outlet heat during a certain time. © 2017","Improved unit circuit model; Multi-layer material; Structure optimization; Thermo-electrical analogy; Transient heat conduction","Circuit simulation; Circuit theory; Finite volume method; Fluxes; Genetic algorithms; Heat conduction; Heat flux; Insulating materials; Thermal conductivity; Thermal insulating materials; Thermal insulation; Timing circuits; Circuit modeling; Electrical analogy; High thermal conductivity; Lumped parameter models; Performance analysis and optimizations; Structure optimization; Thermal insulation materials; Transient heat conduction; Structural optimization",2-s2.0-85032696645
"Mohammed J.A.-K., Mohammed F.M., Jabbar M.A.-S.","Investigation of high performance split air conditioning system by using Hybrid PID controller",2018,"Applied Thermal Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032433945&doi=10.1016%2fj.applthermaleng.2017.10.113&partnerID=40&md5=7a278af84a0b622f052462c657ac2d66","In this paper, the performance improvement of a split air conditioning system has been experimentally investigated to be efficiently utilized in the hot and dry weathers. To examine these improvements, a hybrid proportional integral differential controller was designed and implemented. This controller depends upon dual Proportional Integral Deferential successive algorithms, starting with air conditioning fan variable speed algorithm and followed by water mist variable flow rate algorithm according to the ambient temperature. These algorithms were integrated with a PIC16F877A microcontroller. Both of the air and water flow rates were controlled via a pulse width modulation technique. The proposed controller provides an additional operating stability for the air conditioning system during the instantaneous variation of weather conditions. The results show that the integration of the proposed control system with the modified air conditioning system leads to increase the energy saving and improve the coefficient of performance over a wide range of ambient temperatures (35–57) °C. It was found that the coefficient of performance for the improved system was increased by around 17.14% and 109.1% at ambient temperature 40 °C and 57 °C, respectively, and the energy saving was increased by about 20.67% and 46.63% at ambient temperatures 45 °C and 57 °C, respectively, compared to the conventional air conditioning system. © 2017","COP; Energy saving; Hybrid PID controller; PIC16F877A Microcontroller; Split A/C system; Variable speed fan; Water mist",,2-s2.0-85032433945
"Sanaye S., Taheri M.","Modeling and multi-objective optimization of a modified hybrid liquid desiccant heat pump (LD-HP) system for hot and humid regions",2018,"Applied Thermal Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030839784&doi=10.1016%2fj.applthermaleng.2017.09.116&partnerID=40&md5=725de1ac24c4b5814abc63127f317c09","A hybrid liquid desiccant-heat pump (LD-HP) system for cooling in hot and humid regions is modeled and optimized in this paper. This hybrid LD-HP system contained dehumidifying and cooling sections. The whole system was modeled and analyzed in four energy, exergy, economic and environmental aspects. Then the system was optimized using multi-objective Genetic Algorithm (GA) method. With two objective functions (total annual cost and exergy efficiency) and eight system design parameters the optimum values of design parameters were estimated. Results for our case study showed that the proposed optimized LD-HP system decreased the electricity consumption for 33.2% in comparison with that for an electrical HP system during seven months of operation in a year (18.9% due to using desiccant dehumidifying system and 81.1% due to using a heat exchanger instead of an electrical heater). This amount of lower electricity consumption also provided 1.85×105 kgCO2/year lower CO2 production (33.2%) in comparison with that for a conventional HP system. The COP of LD-HP system at the optimum point was also about 4.83 (in comparison with 2.74 for the conventional case in which heat pump and electrical heater were used). Finally, added equipment to the traditional HP system (dehumidifier, regenerator, heat exchangers, pumps and fans) had 3.04 years payback period. © 2017 Elsevier Ltd","Air-conditioning; Heat pump; Hybrid liquid desiccant",,2-s2.0-85030839784
"Dalvand E. S., Ebrahimi M., Pouryoussefi S.G.","Experimental investigation, modeling and prediction of transition from uniform discharge to filamentary discharge in DBD plasma actuators using artificial neural network",2018,"Applied Thermal Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030785450&doi=10.1016%2fj.applthermaleng.2017.10.004&partnerID=40&md5=d5b55516b2140ba10c94c29e2da5f8fe","The process of plasma discharge in dielectric barrier discharge (DBD) plasma actuators can occur under two different regimes, namely uniform discharge regime and filamentary discharge regime. When the discharge becomes filamentary, the induced flow velocity and consequently, the performance of the actuator starts to decrease. Therefore, it is crucial to prevent the transition to filamentary discharge. In this paper, a model is developed to predict the formation of filamentary regime. For this purpose, the full factorial design of experiments is applied to investigate the effects of geometrical variables and electrical variables on induced flow velocity and power consumption. Then, artificial neural network (ANN) is employed to develop two models for velocity and power consumption. The models are validated both experimentally and statistically. The models show that every variable has a different effect on the start of the filamentary discharge. Finally, the Sequential quadratic programming (SQP) optimization algorithm have been applied to obtain critical value for each variable, in which the plasma discharge begins to become filamentary for any given set of other variables. The results show that the predicted data are in good agreement with the experimental values. Thus, the ANN model can effectively identify the start of filamentary regime. © 2017","Artificial neural network; Filamentary regime; Flow control; Induced velocity; Plasma actuator; Power consumption",,2-s2.0-85030785450
"Duda P., Felkowski Ł., Cyklis P.","Identification of overheating of an industrial fluidized catalytic cracking regenerator",2018,"Applied Thermal Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032474678&doi=10.1016%2fj.applthermaleng.2017.10.130&partnerID=40&md5=5fd503101b7798e3a85a4ec6f361259f","Considerable overheating can be observed on the outer surface of the fluidized catalytic cracking regenerator. The maximum temperature values and the location of overheating areas change over time. Considering the long times between overhauls (of up to 5 years), it is difficult to pinpoint the factors that cause overheating. An examination of the insulation layer during renovation works does not reveal any obvious damage that could have been responsible for the phenomenon. In order to explain the observed overheating process, a thermal and strength analysis of the fluid catalytic cracking regenerator was conducted. A new algorithm is formulated for identification of the refractory lining state and the heat transfer coefficient between the FCC zeolite catalyst particles and the regenerator walls. The heat transfer coefficient on the regenerator inner surface is estimated after its repair, when no overheating areas are visible. The heat transfer coefficients due to radiation and natural and forced convection are determined based on measured values of the regenerator shell and air temperatures, wind velocity and air pressure. The regenerator outer steel surface temperature is measured using an infrared camera. The presented numerical model of the catalytic cracking regenerator wall enables identification of the wall overheating process. The numerical simulation shows how cracks can open and close in the insulation layer depending on atmospheric conditions. This paper puts forward a new method of identifying heat transfer coefficients and cracks in the refractory lining. The unknown heat transfer coefficient on the regenerator inner surface and the crack dimensions will be calculated by means of the inverse method. A least squares objective function is defined to select parameters such that the computed temperatures will agree within certain limits with the temperature values measured experimentally. The information about the crack size can be used for an on-line assessment of the refractory lining, during the lining modification, and also to estimate the remnant life of steel pressure elements. The method accuracy is presented during real measurements performed by means of an infrared camera using the Gaussian error propagation rule. © 2017 Elsevier Ltd","Fluidized catalytic cracking; Heat transfer; Inverse method; Monitoring; Refractory lining","Air; Cameras; Catalytic cracking; Cracks; Fluidization; Heat transfer; Heat transfer coefficients; Infrared devices; Inverse problems; Linings; Monitoring; Numerical models; Refractory materials; Regenerators; Temperature indicating cameras; Atmospheric conditions; Fluidized catalytic crackings; Inverse methods; Maximum temperature value; Natural and forced convections; Objective functions; On-line assessment; Refractory lining; Fluid catalytic cracking",2-s2.0-85032474678
"Darvish-Molla S., Chin K., Prestwich W.V., Byun S.H.","Development of a compact and cost effective multi-input digital signal processing system",2018,"Nuclear Instruments and Methods in Physics Research, Section A: Accelerators, Spectrometers, Detectors and Associated Equipment",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032255834&doi=10.1016%2fj.nima.2017.10.005&partnerID=40&md5=5a886c8098d8f58d29192dae6e76c3be","A prototype digital signal processing system (DSP) was developed using a microcontroller interfaced with a 12-bit sampling ADC, which offers a considerably inexpensive solution for processing multiple detectors with high throughput. After digitization of the incoming pulses, in order to maximize the output counting rate, a simple algorithm was employed for pulse height analysis. Moreover, an algorithm aiming at the real-time pulse pile-up deconvolution was implemented. The system was tested using a NaI(Tl) detector in comparison with a traditional analogue and commercial digital systems for a variety of count rates. The performance of the prototype system was consistently superior to the analogue and the commercial digital systems up to the input count rate of 61 kcps while was slightly inferior to the commercial digital system but still superior to the analogue system in the higher input rates. Considering overall cost, size and flexibility, this custom made multi-input digital signal processing system (MMI-DSP) was the best reliable choice for the purpose of the 2D microdosimetric data collection, or for any measurement in which simultaneous multi-data collection is required. © 2017 Elsevier B.V.","Compact multi-input digital signal processing system; Multiple detector data collection","Cost effectiveness; Data acquisition; Piles; Signal processing; Size exclusion chromatography; Counting rates; Data collection; Digital signal processing systems; High throughput; Multiple detectors; Prototype system; Pulse-height analysis; SIMPLE algorithm; Digital signal processing",2-s2.0-85032255834
"Liu J., Bai Z., Zhang T.","A periodic two-patch SIS model with time delay and transport-related infection",2018,"Journal of Theoretical Biology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032857504&doi=10.1016%2fj.jtbi.2017.10.011&partnerID=40&md5=f89bc21b3ea05cbc8a8e27393c1c2b19","In this paper, we propose a periodic SIS epidemic model with time delay and transport-related infection in a patchy environment. The basic reproduction number R0 is derived which determines the global dynamics of the model system: if R0 &lt; 1, the disease-free periodic state is globally attractive while there exists at least one positive periodic state and the disease persists if R0 &gt; 1. Numerical simulations are performed to confirm the analytical results and to explore the dependence of R0 on the transport-related infection parameters and the amplitude of fluctuations. © 2017 Elsevier Ltd","Basic reproduction number; Patch; Periodic solution; SIS epidemic model; Uniform persistence","epidemic; infectious disease; numerical model; algorithm; Article; basic reproduction number; dynamics; epidemic; influenza; population dispersal; priority journal; severe acute respiratory syndrome; simulation; statistical model; traffic and transport; two patch SIS model; virus infection",2-s2.0-85032857504
"Zhang X.F., Hajdas W., Xiao H.L., Wen X., Wu B.B., Bao T.W., Batsch T., Bernasconi T., Cadoux F., Cernuda I., Chai J.Y., Dong Y.W., Gauvin N., He J.J., Kole M., Kong M.N., Lechanoine-Leluc C., Li L., Li Z.H., Liu J.T., Liu X., Marcinkowski R., Orsi S., Rapin D., Rybka D., Shi H.L., Song L.M., Sun J.C., Szabelski J., Wang R.J., Wang Y.H., Wu X., Xiong S.L., Xu M., Zhang L., Zhang L.Y., Zhang P., Zhang S.N., Zhang Y.J., Zwolinska A.","Optimization of the gain factors and parameter settings for the new gamma-ray burst polarimeter, POLAR",2018,"Nuclear Instruments and Methods in Physics Research, Section A: Accelerators, Spectrometers, Detectors and Associated Equipment",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032436950&doi=10.1016%2fj.nima.2017.10.012&partnerID=40&md5=f71380e353db5b70781cf701a4afde8a","As a space-borne detector POLAR is designed to conduct hard X-ray polarization measurements of gamma-ray bursts on a statistically significant sample of events and with an unprecedented accuracy. During its development phase a number of tests, calibrations and verification measurements were carried out in order to validate instrument functionality and optimize operational parameters. In this article we present results on gain optimization together with verification data obtained in the course of broad laboratory and environmental tests. In particular we focus on exposures to the 137Cs radioactive source and determination of the gain dependence on the high voltage for all 1600 detection channels of the polarimeter. Performance of the instrument is described in detail with respect to the dynamic range, energy resolution and temperature dependence. Gain optimization algorithms and response non-uniformity studies are also discussed. Results presented below are important for the development of the POLAR calibration and operation database. © 2017 Elsevier B.V.","Calibration; Gain; Hard X-rays; High voltage; POLAR; Polarimeter","Calibration; Environmental testing; Optimization; Polarimeters; Radioactivity; Stars; Temperature distribution; Energy resolutions; Gain; Hard X ray; High voltage; Operational parameters; POLAR; Radioactive sources; Temperature dependence; Gamma rays",2-s2.0-85032436950
"Lockhart M., Henzlova D., Croft S., Cutler T., Favalli A., McGahee C., Parker R.","Experimental evaluation of the extended Dytlewski-style dead time correction formalism for neutron multiplicity counting",2018,"Nuclear Instruments and Methods in Physics Research, Section A: Accelerators, Spectrometers, Detectors and Associated Equipment",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032820629&doi=10.1016%2fj.nima.2017.09.025&partnerID=40&md5=ceb416e934fada61d39a86225131c0f8","Over the past few decades, neutron multiplicity counting has played an integral role in Special Nuclear Material (SNM) characterization pertaining to nuclear safeguards. Current neutron multiplicity analysis techniques use singles, doubles, and triples count rates because a methodology to extract and dead time correct higher order count rates (i.e. quads and pents) was not fully developed. This limitation is overcome by the recent extension of a popular dead time correction method developed by Dytlewski. This extended dead time correction algorithm, named Dytlewski–Croft–Favalli(DCF), is detailed in reference Croft and Favalli (2017), which gives an extensive explanation of the theory and implications of this new development. Dead time corrected results can then be used to assay SNM by inverting a set of extended point model equations which as well have only recently been formulated. The current paper discusses and presents the experimental evaluation of practical feasibility of the DCF dead time correction algorithm to demonstrate its performance and applicability in nuclear safeguards applications. In order to test the validity and effectiveness of the dead time correction for quads and pents, 252Cf and SNM sources were measured in high efficiency neutron multiplicity counters at the Los Alamos National Laboratory (LANL) and the count rates were extracted up to the fifth order and corrected for dead time. In order to assess the DCF dead time correction, the corrected data is compared to traditional dead time correction treatment within INCC. The DCF dead time correction is found to provide adequate dead time treatment for broad range of count rates available in practical applications. © 2017 Elsevier B.V.","Dead time correction; Neutron multiplicity counting; Pents; Quads","Nuclear materials safeguards; Radioactive materials; Dead-time correction; Experimental evaluation; Los Alamos National Laboratory; Neutron multiplicity counting; Pents; Point model equations; Quads; Special nuclear materials; Neutrons",2-s2.0-85032820629
"Nian T., Li P., Mao Y., Zhang G., Liu Y.","Connections between chemical composition and rheology of aged base asphalt binders during repeated freeze-thaw cycles",2018,"Construction and Building Materials",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032824033&doi=10.1016%2fj.conbuildmat.2017.10.097&partnerID=40&md5=507916e4ab409105ad5996e55c914f3d","The chemical composition and rheological properties of asphalt binder play a key role in the performance of the asphalt pavement. However, pavement diseases (cracks, pitted surface, potholes and slurry) caused by the degradation of pavement performance have shortened the service life of the asphalt pavement and increased maintenance and repair costs, seriously affected the smooth flow of traffic and traffic safety. In this study, the sum of the different absorption peak areas of the asphalt binder spectroscopy was selected as a reference. Fourier Transform Infrared Spectroscopy (FT-IR) quantitative analysis was carried out on the Rolling Thin Film Oven (RTFO) test with different aging cycles and Pressure Aging Vessel (PAV) test of the asphalt binder after aging. Based on the above analysis, the author tries to establish a reliable FT-IR quantitative analysis method. An FT-IR specimen which could be subjected to multiple freeze-thaw cycles could be prepared by the self-designed test sample preparation device. By carrying out the freeze-thaw cycle aging test of asphalt binder for 0, 3, 6, 9, 12, 15 and 18 times, combining FT-IR and Dynamic Shear Rheological (DSR) testing techniques, the author explored the relationship between chemical composition and rheological performance parameters of asphalt binder in cold region, which were based on the Levenberg-Macquarie method and test data of universal global optimization algorithm regression analysis. The results show that FT-IR can not only qualitatively analyze and study the structure and chemical composition of asphalt binder before and after aging on a micro level, but also quantitatively represent the changes of characteristic functional groups before and after aging of asphalt binder. It is feasible to calculate the absorption peak area for FT-IR quantitative analysis using the tangent at the lowest point on both sides of the spectral absorption peak as the calibration baseline. It is recommended to use the range of 2000–650 cm−1 absorption peak area sum as a benchmark for FT-IR quantitative analysis. The complex shear modulus of the asphalt binder shows a linear growth with the increase of freeze-thaw cycles, and phase angle of asphalt binder also shows a linear growth with the increase of Ln T. There is a multivariate linear relationship between the rheological index and chemical functional groups after the aging freeze-thaw cycle. © 2017 Elsevier Ltd","Base asphalts; Cross-correlation analysis; Dynamic shear rheological; Fourier transform infrared spectroscopy; Freeze-thaw cycles","Asphalt; Asphalt pavements; Binders; Bins; Chemical analysis; Degradation; Film preparation; Fourier transform infrared spectroscopy; Freezing; Global optimization; Optimization; Regression analysis; Repair; Specimen preparation; Spectrum analysis; Testing; Thawing; Base asphalt; Chemical functional groups; Cross-correlation analysis; Dynamic shears; Fourier transform infra red (FTIR) spectroscopy; Freeze-thaw cycles; Rolling thin film ovens; Universal global optimizations; Aging of materials",2-s2.0-85032824033
"Huang X., Wang Y., Sun Y., Zhang Q., Zhang Z., You Z., Ma Y.","Research on horizontal displacement monitoring of deep soil based on a distributed optical fibre sensor",2018,"Journal of Modern Optics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030710006&doi=10.1080%2f09500340.2017.1382594&partnerID=40&md5=790c7e6fb01a6b99f5cd8d482ce9b209","The traditional measurement method for the horizontal displacement of deep soil usually uses an inclinometer for piecewise measurement and then generates an artificial reading, which takes a long time and often contains errors; in addition, the anti-jamming and long-term stability of the inclinometer is poor. In this paper, a technique for monitoring horizontal displacement based on distributed optical fibres is introduced. The relationship between the strain and the deflection was described by a theoretical model, and the strain distribution of the inclinometer tube was measured by the cables laid on its surface so that the deflection of the inclinometer tube could be calculated by the difference algorithm and regarded as the horizontal displacement of deep soil. The horizontal displacement monitoring technology of deep soil based on distributed optical fibre sensors developed in this paper not only overcame the shortcomings of traditional inclinometer technology to realize automatic real-time monitoring but also allowed for distributed measurement. The experiment was similar to the expected engineering situations, and the deflection calculated from the strain was compared with an inclinometer. The results demonstrated that the relative error between the distributed optical fibre sensors and the inclinometer was less than 8.0%, and the results also verified both the feasibility of using distributed optical fibre to monitor the horizontal displacement of soil as well as the rationality of the theoretical model and difference algorithm. The application of distributed optical fibre in monitoring the horizontal displacement of deep soil in the engineering of foundation pits and slopes can more accurately evaluate the safety of engineering during construction. © 2017 Informa UK Limited, trading as Taylor & Francis Group.","differential algorithm; displacement monitoring; Distributed fibre; foundation pit; real-time monitoring","Fibers; Monitoring; Optical fibers; Soil surveys; Soils; Difference algorithms; Differential algorithms; Displacement monitoring; Distributed measurements; Distributed optical fibre sensors; Foundation pits; Horizontal displacements; Real time monitoring; Displacement measurement",2-s2.0-85030710006
"Zhou R., Shen X., Niu L.","A fast algorithm for nonsmooth penalized clustering",2018,"Neurocomputing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029223758&doi=10.1016%2fj.neucom.2017.08.048&partnerID=40&md5=e5319aecb9415eac81e302eb6e351c21","As a novel framework of clustering analysis, penalized clustering is able to learn the number of clusters automatically, and therefore has aroused widespread interest recently. To address the computational difficulties arising from the nonsmoothness of the penalty, a simple iterative algorithm based on smoothing trust region (STR) can be used. However, since STR only needs first-order information of the model, it might exhibit slow convergence rate sometimes. To accelerate STR and further improve the efficiency of penalized clustering, we propose a nonmonotone smoothing trust region (NSTR) algorithm, in which nonmonotone technique and the Barzilai and Borwein (BB) method are utilized together. We also prove that the new algorithm is globally convergent and estimate its worst case computational complexity. Experimental results on both simulated and real-life data sets validate the effectiveness and efficiency of the proposed method. © 2017 Elsevier B.V.","BB method; Nonmonotone technique; Nonsmooth penalized clustering; Smoothing trust region","Efficiency; Iterative methods; Clustering analysis; Effectiveness and efficiencies; Globally convergent; Iterative algorithm; Nonmonotone technique; Nonsmooth penalized clustering; Number of clusters; Trust region; Clustering algorithms",2-s2.0-85029223758
"Zhang Y., Ye D., Liu Y.","Robust locally linear embedding algorithm for machinery fault diagnosis",2018,"Neurocomputing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029764189&doi=10.1016%2fj.neucom.2017.07.048&partnerID=40&md5=49f342d162f4ed7c5ba3ad3be0411788","Locally linear embedding (LLE) is a classical nonlinear dimensionality reduction algorithm, and it has been widely used in machinery fault diagnosis. LLE reduces the dimensions of a data set only by exploring the geometry structure, that is, the geometry structure is one of the key factors for the embedding result. In conventional LLE algorithm, the geometry structure is calculated by ordinary least square (OLS) algorithm, which makes the embedding result be sensitive to noise. In order to resolve the problem, a robust LLE (RLLE) is investigated. In RLLE algorithm, the Least Angle Regression and the Elastic Net (LARS-EN) technologies are employed to compute the local structure. Besides, a novel fault diagnosis method based on RLLE and support vector machine (SVM) are proposed for machinery fault diagnosis. Experiments performed on both synthetic and real data sets demonstrate the advantages of the proposed method in the term of fault diagnosis. © 2017","Elastic Net; Fault diagnosis; l1 Regularization; Least Angle Regression; Local linear embedding","Failure analysis; Geometry; Machinery; Support vector machines; Elastic net; L1 regularizations; Least angle regressions; Local Linear Embedding; Locally linear embedding; Locally linear embedding algorithms; Machinery fault diagnosis; Nonlinear dimensionality reduction; Fault detection",2-s2.0-85029764189
"Jiang H., Zhang H., Cui Y., Xiao G.","Robust control scheme for a class of uncertain nonlinear systems with completely unknown dynamics using data-driven reinforcement learning method",2018,"Neurocomputing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028857157&doi=10.1016%2fj.neucom.2017.07.058&partnerID=40&md5=ad019f371019986782fc2f6081441c7e","This paper deals with the robust control issues for a class of uncertain nonlinear systems with completely unknown dynamics via a data-driven reinforcement learning method. Firstly, we formulate the optimal regulation control problem for the nominal system, and then, the robust controller for the original uncertain system is designed by adding a constant feedback gain to the optimal controller of the nominal system. Then, this scheme is extended to the optimal tracking control by means of augmented system and discount factor. It is also demonstrated that the proposed robust controller can achieve optimality with a new defined performance index function when there is no control perturbation. It is well known that the nonlinear optimal control problem relies on the solution of Hamilton–Jacobi–Bellman (HJB) equation, which is a nonlinear partial differential equation and impossible to be solved analytically. In order to overcome this difficulty, we introduce a model-based iterative learning algorithm to successively approximate the solution of HJB equation and provide its convergence proof. Subsequently, based on the structure of the model-based approach, a data-driven reinforcement learning method is derived, which only requires the sampling data from real system with different control inputs rather than the accurate mathematical system models. Neural networks (NNs) are utilized to implement this model-free method to approximate the optimal solutions and the least-square approach is employed to minimize the NN approximation residual errors. Finally, two numerical simulation examples are given to illustrate the effectiveness of our proposed method. © 2017","Adaptive dynamic programming; Data-driven; Model-free; Neural networks; Reinforcement learning","Controllers; Discrete time control systems; Dynamic programming; Iterative methods; Learning algorithms; Learning systems; Least squares approximations; Neural networks; Nonlinear equations; Nonlinear systems; Numerical methods; Optimal control systems; Partial differential equations; Robust control; Adaptive dynamic programming; Data driven; Hamilton-Jacobi-Bellman equations; Iterative learning algorithms; Model free; Nonlinear optimal control problems; Nonlinear partial differential equations; Reinforcement learning method; Reinforcement learning",2-s2.0-85028857157
"Qi M., Wang T., Liu F., Zhang B., Wang J., Yi Y.","Unsupervised feature selection by regularized matrix factorization",2018,"Neurocomputing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029232973&doi=10.1016%2fj.neucom.2017.08.047&partnerID=40&md5=8f37711e252642bc4f296361ed45c2a8","Feature selection is an interesting and challenging task in data analysis process. In this paper, a novel algorithm named Regularized Matrix Factorization Feature Selection (RMFFS) is proposed for unsupervised feature selection. Compared with other matrix factorization based feature selection methods, a main advantage of our algorithm is that it takes the correlation among features into consideration. Through introducing an inner product regularization into our algorithm, the features selected by RMFFS would not only well represent the original high-dimensional data, but also contain low redundancy. Moreover, a simple yet efficient iteratively updating algorithm is also developed to solve the proposed RMFFS. Extensive experimental results on nine real world databases demonstrate that our proposed method can achieve better performance than some state-of-the-art unsupervised feature selection methods. © 2017","Dimensionality reduction; Feature selection; Matrix factorization; Sparsity and redundancy","Clustering algorithms; Factorization; Iterative methods; Matrix algebra; Redundancy; Analysis process; Dimensionality reduction; Feature selection methods; High dimensional data; Matrix factorizations; Real-world database; Unsupervised feature selection; Updating algorithm; Feature extraction",2-s2.0-85029232973
"Du B., Huang Z., Wang N., Zhang Y., Jia X.","Joint weighted nuclear norm and total variation regularization for hyperspectral image denoising",2018,"International Journal of Remote Sensing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031420066&doi=10.1080%2f01431161.2017.1382742&partnerID=40&md5=1fc6bd5d754de311667557c8d06d72be","A hyperspectral image is typically corrupted by multiple types of noise including Gaussian noise and impulse noise. On the other hand, a hyperspectral image possesses a high correlation in its spectral dimensions, and its Casorati matrix has a very low rank. Inspired by the recent development of robust principal component analysis, which can be used to remove sparse and arbitrarily large noise from a low-rank matrix, we propose a joint weighted nuclear norm and total variation regularization method to denoise a hyperspectral image data. First, weighted nuclear norm regularization is constructed for sparse noise removal. Total variation regularization is then imposed on each band of the hyperspectral image to further remove the Gaussian noise. A concrete optimization algorithm is developed to implement the two-stage regularization. The combined approach is expected to effectively denoise hyperspectral images even with varying data structures and under varying imaging conditions. Extensive experiments on both simulated and real data sets validate the performance of our proposed method. © 2017 Informa UK Limited, trading as Taylor & Francis Group.",,"Gaussian noise (electronic); Hyperspectral imaging; Impulse noise; Independent component analysis; Matrix algebra; Optimization; Principal component analysis; Spectroscopy; Hyperspectral image datas; Imaging conditions; Low-rank matrices; Nuclear norm regularizations; Optimization algorithms; Robust principal component analysis; Spectral dimensions; Total variation regularization; Image denoising; algorithm; correlation; data set; Gaussian method; matrix; multispectral image; principal component analysis",2-s2.0-85031420066
"Muralitharan K., Sakthivel R., Vishnuvarthan R.","Neural network based optimization approach for energy demand prediction in smart grid",2018,"Neurocomputing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029185636&doi=10.1016%2fj.neucom.2017.08.017&partnerID=40&md5=eff30b734c38dc0a75b98484d13d7f4b","Energy usage and demand forecasting is an essential and complex task in real time implementation. Proper coordination is required between the consumer and power companies for monitoring, scheduling and operating the electrical devices without any damages. In this paper, we propose a novel neural network based optimization approach for energy demand prediction. Initially, the Conventional Neural Network (CNN) approach is employed to find the required energy demand prediction at the consumer end. Secondly, Neural Network based Genetic Algorithm (NNGA) and Neural Network based Particle Swarm Optimization (NNPSO) approaches are implemented where the weights of the neural network are automatically adjusted. Closer observation from the result reveals that the proposed NNGA approach performs better for short term load forecasting and proposed NNPSO is more suitable for the long term energy prediction. For the experimental results, real time data are taken from pecan street (Pecan Street Inc.). From the simulations, it can be concluded that the proposed optimization approach algorithm yield better results than the CNN approach in predicting the future energy demand. Further, the result reveals that it is possible to manage the demand and supply, planning of power grid and prediction of future energy requirement in the smart grid. © 2017 Elsevier B.V.","Demand side management; Energy usage; Load prediction; Neural networks; Optimization techniques","Demand side management; Electric power transmission networks; Electric utilities; Energy management; Energy utilization; Forecasting; Genetic algorithms; Neural networks; Optimization; Particle swarm optimization (PSO); Real time control; Energy demand prediction; Energy usage; Load predictions; Novel neural network; Optimization approach; Optimization techniques; Real-time implementations; Short term load forecasting; Smart power grids",2-s2.0-85029185636
"Zhou P., Fang C., Lin Z., Zhang C., Chang E.Y.","Dictionary learning with structured noise",2018,"Neurocomputing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028619668&doi=10.1016%2fj.neucom.2017.07.041&partnerID=40&md5=0266c6c2a94338b020b6c337e9751495","Recently, lots of dictionary learning methods have been proposed and successfully applied. However, many of them assume that the noise in data is drawn from Gaussian or Laplacian distribution and therefore they typically adopt the ℓ2 or ℓ1 norm to characterize these two kinds of noise, respectively. Since this assumption is inconsistent with the real cases, the performance of these methods is limited. In this paper, we propose a novel dictionary learning with structured noise (DLSN) method for handling noisy data. We decompose the original data into three parts: clean data, structured noise, and Gaussian noise, and then characterize them separately. We utilize the low-rank technique to preserve the inherent subspace structure of clean data. Instead of only using the predefined distribution to fit the real distribution of noise, we learn an adaptive dictionary to characterize structured noise and employ the ℓ2 norm to depict Gaussian noise. Such a mechanism can characterize noise more precisely. We also prove that our proposed optimization method can converge to a critical point and the convergence rate is at least sublinear. Experimental results on the data clustering task demonstrate the effectiveness and robustness of our method. © 2017 Elsevier B.V.","Dictionary learning; Low rank representation; Sparse representation; Structured noise","Clustering algorithms; Gaussian distribution; Gaussian noise (electronic); Image coding; Convergence rates; Dictionary learning; Laplacian distribution; Low-rank representations; Optimization method; Real distribution; Sparse representation; Structured noise; Data handling",2-s2.0-85028619668
"Viegas F., Rocha L., Gonçalves M., Mourão F., Sá G., Salles T., Andrade G., Sandin I.","A Genetic Programming approach for feature selection in highly dimensional skewed data",2018,"Neurocomputing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029469710&doi=10.1016%2fj.neucom.2017.08.050&partnerID=40&md5=75d35e22ef3f85eb93a951109168c810","High dimensionality, also known as the curse of dimensionality, is still a major challenge for automatic classification solutions. Accordingly, several feature selection (FS) strategies have been proposed for dimensionality reduction over the years. However, they potentially perform poorly in face of unbalanced data. In this work, we propose a novel feature selection strategy based on Genetic Programming, which is resilient to data skewness issues, in other words, it works well with both, balanced and unbalanced data. The proposed strategy aims at combining the most discriminative feature sets selected by distinct feature selection metrics in order to obtain a more effective and impartial set of the most discriminative features, departing from the hypothesis that distinct feature selection metrics produce different (and potentially complementary) feature space projections. We evaluated our proposal in biological and textual datasets. Our experimental results show that our proposed solution not only increases the efficiency of the learning process, reducing up to 83% the size of the data space, but also significantly increases its effectiveness in some scenarios. © 2017 Elsevier B.V.","Classification; Feature selection; Genetic Programming","Feature extraction; Genetic algorithms; Genetic programming; Automatic classification; Curse of dimensionality; Dimensionality reduction; Discriminative features; Feature selection metrics; High dimensionality; Learning process; Unbalanced data; Classification (of information)",2-s2.0-85029469710
"Filioglou M., Siomos N., Poupkou A., Dimopoulos S., Chaikovsky A., Balis D.","A sensitivity study of the LIdar-Radiometer Inversion Code (LIRIC) using selected cases from Thessaloniki, Greece database",2018,"International Journal of Remote Sensing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030460917&doi=10.1080%2f01431161.2017.1384589&partnerID=40&md5=34a7cf14111be214967c8aa422e9692d","We investigate the uncertainty introduced to the optical and microphysical properties estimated with the lidar radiometer inversion code (LIRIC) by user-defined input parameters based on measurements carried out with a multi-wavelength Raman lidar and a sun photometer located at Thessaloniki, Greece (40.6° N, 22.9° E, 60 m above sea level). The sensitivity study involves three tests. We first evaluate the selection of the regularization parameters needed for the algorithm to initialize the iteration process. The latter two tests consider the impact of the boundary limits at the top/bottom (upper/lower limit) of the signal to the derived concentration profiles. The aforementioned tests were applied to two different cases, a Saharan dust event and a continental pollution case. We concluded that the largest uncertainties are introduced when varying the lower limit (more than 35%) regardless of the aerosol type or mode (fine/coarse). Varying the regularization parameters resulted in an uncertainty of 20%, and the selection of upper limit led to discrepancies of less than 3%. In conclusion, this sensitivity study indicates that future LIRIC users should apply an overlap function to the lidar signals before applying the methodology for minimizing the uncertainties in the near range. © 2017 Informa UK Limited, trading as Taylor & Francis Group.",,"Iterative methods; Parameter estimation; Parameterization; Radiometers; Sea level; Uncertainty analysis; Concentration profiles; Iteration process; Microphysical property; Multi-wavelengths; Overlap functions; Regularization parameters; Sensitivity studies; Thessaloniki , Greece; Optical radar; aerosol; algorithm; database; dust; lidar; parameterization; photometer; radiometer; sensitivity analysis; Central Macedonia; Greece; Thessaloniki [Central Macedonia]; Thessaloniki [Thessaloniki (DPR)]",2-s2.0-85030460917
"Hayashi Y., Iiduka H.","Optimality and convergence for convex ensemble learning with sparsity and diversity based on fixed point optimization",2018,"Neurocomputing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028376856&doi=10.1016%2fj.neucom.2017.07.046&partnerID=40&md5=cf741c9d0de63f4c539ec759ecadbaf4","This paper discusses the classifier ensemble problem with sparsity and diversity learning, which is a central issue in machine learning. The current approach for reducing the size and increasing the accuracy of a classifier ensemble is to formulate it as a convex quadratic programming problem, which is a relaxation problem, and then solve it by using the existing methods for convex quadratic programming or by computing closed-form solutions. This paper presents a novel computational approach for solving the classifier ensemble problem with sparsity and diversity learning without any recourse to relaxation problems and their associated methods. We first show that the classifier ensemble problem can be expressed as a minimization problem for the sum of certain convex functions over the intersection of fixed point sets of quasi-nonexpansive mappings. Next, we propose fixed point optimization algorithms for solving the minimization problem and show that the algorithms converge to the solution of the minimization problem. It is shown that the proposed algorithms can directly solve the classifier ensemble problem with sparsity and diversity learning. Finally, we compare the performance of the proposed sparsity and diversity learning methods against an existing method in classification experiments using data sets from the UCI machine learning repository and the LIBSVM. The experimental results show that the proposed methods have higher classification accuracies than the existing method. © 2017 Elsevier B.V.","Convex ensemble learning; Fixed point; Incremental subgradient method; Quasi-nonexpansive mapping","Artificial intelligence; Classification (of information); Functions; Learning systems; Mapping; Optimization; Quadratic programming; 65K05; 68Q32; 90C25; Ensemble learning; Fixed points; Quasi-nonexpansive mapping; Sub-gradient methods; Problem solving",2-s2.0-85028376856
"Lei J., Mu H.P., Liu Q.B., Wang X.Y., Liu S.","Data-driven reconstruction method for electrical capacitance tomography",2018,"Neurocomputing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028311314&doi=10.1016%2fj.neucom.2017.08.006&partnerID=40&md5=a95906a903ae986511ec4070ede2c96f","The appealing superiorities, including high-speed data acquisition, nonintrusive measurement, low cost, high safety and visual presentation, lead to the success of the electrical capacitance tomography (ECT) technique in the monitoring of industrial processes. High-accuracy tomographic images play a crucial role in the reliability of the ECT measurement results, which provide the powerful scientific evidences for investigating the complicated mechanisms behind the behaviors of the imaging objects (IOs). Beyond the existing numerical algorithms that are developed for the solution of the inverse problem in the ECT area, a data-driven two-stage reconstruction method is proposed to improve the reconstruction quality (RQ) in this paper. At the first stage, i.e., the learning stage, the regularized extreme learning machine (RELM) model solved by the split Bregman technique is developed to extract the mapping between the tomographic images reconstructed by the some algorithm and the true images according to a set of training samples. At the second stage, i.e., the prediction stage, a new IO is reconstructed by the same algorithm used in computing training samples, and then the imaging result is considered as an input of the trained RELM model to predict the final result. The performances of the proposed reconstruction method are compared and evaluated by the means of the numerical simulation approach using the clean and noisy capacitance data with different noise levels (NLs). Quantitative and qualitative comparison results validate the practicability and effectiveness of the proposed data-driven reconstruction method. Research findings provide a new insight for the improvement of the reconstruction accuracy and robustness in the ECT area. © 2017","Electrical capacitance tomography; Extreme learning machine; Image reconstruction; Inverse problem; Reconstruction method","Accident prevention; Capacitance; Data acquisition; Electric impedance tomography; Image processing; Inverse problems; Knowledge acquisition; Learning systems; Numerical methods; Sampling; Tomography; Electrical Capacitance Tomography; Extreme learning machine; High speed data acquisition; Non-intrusive measurements; Numerical simulation approaches; Reconstruction accuracy; Reconstruction method; Reconstruction quality; Image reconstruction",2-s2.0-85028311314
"Wang L., Liu J.","Local stability analysis for continuous-time Takagi–Sugeno fuzzy systems with time delay",2018,"Neurocomputing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030032416&doi=10.1016%2fj.neucom.2017.08.021&partnerID=40&md5=4dc21bdfadccb1841d35a21c3b4a7c17","In this brief paper, a membership function dependent Lyapunov–Krasovskii functional is designed to investigate the stability analysis of T–S (Takagi–Sugeno) fuzzy systems with time delay. According to the time derivatives of the membership function, both local and global stability conditions are obtained. For the local case, the local stability region is obtained by designing an algorithm. In the end, an example is given to illustrate the effectiveness of the method in this paper. © 2017","Membership dependent Lyapunov function; Parallel distributed compensation law; Takagi–Sugeno's fuzzy model; Time delay","Feedback control; Fuzzy systems; Lyapunov functions; Membership functions; Stability; System stability; Time delay; Timing circuits; Local and global stabilities; Local stability analysis; Lyapunov-Krasovskii functionals; Parallel distributed compensation; Stability analysis; Systems with time delay; Takagi Sugeno fuzzy systems; Takagi-sugeno; Continuous time systems",2-s2.0-85030032416
"Lu A.-Y., Zhai D., Dong J., Zhang Q.-L.","Network-based fuzzy H∞ controller design for T-S fuzzy systems via a new event-triggered communication scheme",2018,"Neurocomputing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028311578&doi=10.1016%2fj.neucom.2017.07.042&partnerID=40&md5=531e6ab2635c5229ad9dee85fa0da459","This paper is concerned with network-based fuzzy H∞ control for a class of T-S fuzzy systems under an event-triggered communication scheme. Considering the fact that the network-induced delays are inevitable, the closed-loop system is modeled with asynchronous membership functions. To deal with the asynchronous membership functions, a new condition that limits the deviation bounds of membership functions, is introduced into the event-triggered scheme (ET scheme). Besides, by introducing a fuzzy event-triggered weighting matrix, a new ET scheme is proposed. Based on the proposed ET scheme, a novel criterion for the asymptotic stability and H∞ performance analysis is established in terms of linear matrix inequalities. Then some sufficient conditions and an algorithm to co-design the controller and the parameters of the ET scheme are presented. The effectiveness of the proposed method is illustrated through a mass-spring-damper system. © 2017 Elsevier B.V.","Asynchronous membership functions; Event-triggered scheme; Network-based fuzzy H∞ control; T-S fuzzy system","Asymptotic stability; Closed loop systems; Controllers; Fuzzy logic; Fuzzy systems; Linear matrix inequalities; Robustness (control systems); Communication schemes; Event-triggered; Mass-spring-damper system; Network-based; Network-induced delays; Performance analysis; T S fuzzy system; Weighting matrices; Membership functions",2-s2.0-85028311578
"Xiao H., Meng G., Wang L., Pan C.","Facade repetition detection in a fronto-parallel view with fiducial lines extraction",2018,"Neurocomputing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028337574&doi=10.1016%2fj.neucom.2017.07.040&partnerID=40&md5=4bec3ef22feb1c66ed0b23b9f582b91a","Detecting repetitive structures on building facades plays an important role in facade image analysis. Observing that repetitions are usually horizontally and vertically aligned, and thereby can be localized by the horizontal and vertical lines passing along the repetition boundaries, we propose to detect repetitions by extracting these fiducial lines. Firstly, candidate lines are detected, containing both the fiducial lines and some mistaken lines passing across facade wall or repetitive structures. Secondly, to pick out the fiducial lines, we formulate a maximum a posterior problem to measure the probabilities that the lines can localize the repetitions. Finally, a dynamic programming based algorithm is developed to solve the problem efficiently. To evaluate the proposed approach, we implement a series of experiments on a dataset containing 60 facade images as well as the public Ecole Central Paris facade dataset. Both qualitative and quantitative results demonstrate the effectiveness of our approach. © 2017 Elsevier B.V.","Facade labeling; Line detection; Line extraction; Repetition detection","Character recognition; Dynamic programming; Extraction; Building facades; Line detection; Line extraction; Maximum a posteriors; Quantitative result; Repetition detections; Repetitive structure; Vertically aligned; Facades",2-s2.0-85028337574
"Burdett R.L., Kozan E.","An integrated approach for scheduling health care activities in a hospital",2018,"European Journal of Operational Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024126176&doi=10.1016%2fj.ejor.2017.06.051&partnerID=40&md5=fbdf2ad2734d6126cdf2c2ccde3302e9","To effectively utilise hospital beds, operating rooms (OR) and other treatment spaces, it is necessary to precisely plan patient admissions and treatments in advance. As patient treatment and recovery times are unequal and uncertain, this is not easy. In response, a sophisticated flexible job-shop scheduling (FJSS) model is introduced, whereby patients, beds, hospital wards and health care activities are respectively treated as jobs, single machines, parallel machines and operations. Our approach is novel because an entire hospital is describable and schedulable in one integrated approach. The scheduling model can be used to recompute timings after deviations, delays, postponements and cancellations. It also includes advanced conditions such as activity and machine setup times, transfer times between activities, blocking limitations and no wait conditions, timing and occupancy restrictions, buffering for robustness, fixed activities and sequences, release times and strict deadlines. To solve the FJSS problem, constructive algorithms and hybrid meta-heuristics have been developed. Our numerical testing shows that the proposed solution techniques are capable of solving problems of real world size. This outcome further highlights the value of the scheduling model and its potential for integration into actual hospital information systems. © 2017 Elsevier B.V.","Disjunctive graph model; Flexible job shop; Hospital scheduling; Hybrid meta-heuristics; Scheduling","Health care; Hospitals; Integrated control; Optimization; Patient rehabilitation; Patient treatment; Scheduling; Scheduling algorithms; Constructive algorithms; Disjunctive graphs; Flexible job shops; Flexible job-shop scheduling; Hospital information systems; Hybrid metaheuristics; Integrated approach; Solution techniques; Job shop scheduling",2-s2.0-85024126176
"Du W.S., Hu B.Q.","A fast heuristic attribute reduction approach to ordered decision systems",2018,"European Journal of Operational Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016411459&doi=10.1016%2fj.ejor.2017.03.029&partnerID=40&md5=c970f9b0289e7c048331566bcbd1f9c5","Rough set theory has shown success in being a filter-based feature selection approach for analyzing information systems. One of its main aims is to search for a feature subset called a reduct, which preserves the classification ability of the original system. In this paper, we consider ordered decision systems, where the preference order, a fundamental concept in dominance-based rough set approach, plays a critical role. In recent literature, based on the greedy hill climbing method, many heuristic attribute reduction algorithms are proposed by utilizing significance measures of attributes, and they are extended to deal with ordered decision systems. Unfortunately, they are often time-consuming, especially when applied to deal with large scale data sets with high dimensions. To reduce the complexity, a novel accelerator is introduced in heuristic algorithms from the perspectives of objects and criteria. Based on the new accelerator, the number of objects and the dimension of criteria are lessened thus making the accelerated algorithms faster than their original counterparts while maintaining the same reducts. Experimental analysis shows the validity and efficiency of the proposed methods. © 2017 Elsevier B.V.","Accelerator; Dominance-based rough set approach; Heuristic attribute reduction algorithm; Ordered decision system","Heuristic algorithms; Heuristic methods; Particle accelerators; Attribute reduction algorithm; Classification ability; Decision systems; Dominance-based rough set approach; Experimental analysis; Hill-climbing methods; Large scale data sets; Significance measures; Rough set theory",2-s2.0-85016411459
"Maher S.J., Desaulniers G., Soumis F.","The daily tail assignment problem under operational uncertainty using look-ahead maintenance constraints",2018,"European Journal of Operational Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021970469&doi=10.1016%2fj.ejor.2017.06.041&partnerID=40&md5=8a3c9e02ed1a03840317a7bbfabd1011","The tail assignment problem is a critical part of the airline planning process that assigns specific aircraft to sequences of flights, called lines-of-flight, to satisfy operational constraints. The aim of this paper is to develop an operationally flexible method, based upon the one-day routes business model, to compute tail assignments that satisfy short-range—within the next three days—aircraft maintenance requirements. While maintenance plans commonly span multiple days, the methods used to compute tail assignments for the given plans can be overly complex and provide little recourse in the event of schedule perturbations. The presented approach addresses operational uncertainty by using solutions from the one-day routes aircraft maintenance routing approach as input. The daily tail assignment problem is solved with an objective to satisfy maintenance requirements explicitly for the current day and implicitly for the subsequent two days. A computational study will be performed to assess the performance of exact and heuristic solution algorithms that modify the input lines-of-flight to reduce maintenance misalignments. The daily tail assignment problem and the developed algorithms are demonstrated to compute solutions that effectively satisfy maintenance requirements when evaluated using input data collected from three different airlines. © 2017 Elsevier B.V.","Branch-and-price; Iterative algorithm; Maintenance planning; Tail assignment; Transportation","Air transportation; Combinatorial optimization; Heuristic algorithms; Integer programming; Iterative methods; Planning; Transportation; Aircraft maintenance; Branch and price; Computational studies; Iterative algorithm; Maintenance planning; Maintenance requirement; Operational constraints; Tail assignment; Maintenance",2-s2.0-85021970469
"Bulhões T., Subramanian A., Erdoğan G., Laporte G.","The static bike relocation problem with multiple vehicles and visits",2018,"European Journal of Operational Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023615614&doi=10.1016%2fj.ejor.2017.06.028&partnerID=40&md5=68c5f97e8275d376a980d2bb31745b94","This paper introduces the static bike relocation problem with multiple vehicles and visits, the objective of which is to rebalance at minimum cost the stations of a bike sharing system using a fleet of vehicles. The vehicles have identical capacities and service time limits, and are allowed to visit the stations multiple times. We present an integer programming formulation, implemented under a branch-and-cut scheme, in addition to an iterated local search metaheuristic that employs efficient move evaluation procedures. Results of computational experiments on instances ranging from 10 to 200 vertices are provided and analyzed. We also examine the impact of the vehicle capacity and of the number of visits and vehicles on the performance of the proposed algorithms. © 2017 Elsevier B.V.","Bike sharing; Pickup and delivery; Routing; Shared mobility systems","Bicycles; Fleet operations; Integer programming; Bike sharing; Computational experiment; Integer programming formulations; Iterated local search; Mobility systems; Pickup and delivery; Relocation problem; Routing; Vehicles",2-s2.0-85023615614
"Bozóki S., Fülöp J.","Efficient weight vectors from pairwise comparison matrices",2018,"European Journal of Operational Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023642971&doi=10.1016%2fj.ejor.2017.06.033&partnerID=40&md5=a999fb0efbc18e6559af5090292136f7","Pairwise comparison matrices are frequently applied in multi-criteria decision making. A weight vector is called efficient if no other weight vector is at least as good in approximating the elements of the pairwise comparison matrix, and strictly better in at least one position. A weight vector is weakly efficient if the pairwise ratios cannot be improved in all non-diagonal positions. We show that the principal eigenvector is always weakly efficient, but numerical examples show that it can be inefficient. The linear programs proposed test whether a given weight vector is (weakly) efficient, and in case of (strong) inefficiency, an efficient (strongly) dominating weight vector is calculated. The proposed algorithms are implemented in Pairwise Comparison Matrix Calculator, available at pcmc.online. © 2017 Elsevier B.V.","Efficiency; Linear programming; Multiple criteria analysis; Pairwise comparison matrix; Pareto optimality","Efficiency; Linear programming; Pareto principle; Vectors; Linear programs; Multi criteria decision making; Multiple criteria analysis; Pairwise comparison matrices; Pareto-optimality; Principal eigen-vector; Weight vector; Matrix algebra",2-s2.0-85023642971
"Santini A., Plum C.E.M., Ropke S.","A branch-and-price approach to the feeder network design problem",2018,"European Journal of Operational Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024133954&doi=10.1016%2fj.ejor.2017.06.063&partnerID=40&md5=30c08748c0798d1991e473dd9639251b","In this paper we consider the problem of designing a container liner shipping feeder network. The designer has to choose which port to serve during many rotations that start and end at a central hub. Many operational characteristics are considered, such as variable leg-by-leg speeds and cargo transit times. Realistic instances are generated from the LinerLib benchmark suite. The problem is solved with a branch-and-price algorithm, which can solve most instances to optimality within one hour. The results also provide insights on the cost structure and desirable features of optimal routes. These insights were obtained by means of an analysis where scenarios are generated varying internal and external conditions, such as fuel costs and port demands. © 2017 Elsevier B.V.","Branch and price; Liner shipping; Network design; OR in maritime industry; Vehicle routing problem","Cost benefit analysis; Integer programming; Ships; Vehicle routing; Branch and price; Liner shipping; Maritime industry; Network design; Vehicle Routing Problems; Costs",2-s2.0-85024133954
"Xing L., Levitin G.","Connectivity modeling and optimization of linear consecutively connected systems with repairable connecting elements",2018,"European Journal of Operational Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022094532&doi=10.1016%2fj.ejor.2017.06.047&partnerID=40&md5=15b62dd751c44b584eaaafece781ecd1","Linear consecutively connected systems (LCCSs) are systems containing a linear sequence of ordered nodes. Connection elements (CE) characterized by diverse connection ranges, time-to-failure and time-to-repair distributions are allocated to different nodes to provide the system connectivity, i.e., a connection between the source and sink nodes of the LCCS. Examples of LCCSs abound in practical applications such as flow transmission systems and radio communication systems. Considerable research efforts have been expended in modeling and optimizing LCCSs. However, most of the existing works have assumed that CEs either are non-repairable or undergo a restrictive minimal repair policy with constant repair time. This paper makes new technical contributions by modeling and optimizing LCCSs with CEs under corrective maintenance with random repair time and different repair policies (minimal, perfect, and imperfect). The characteristics of CEs can depend on their location because the distance between adjacent nodes and conditions of CE operation and maintenance at different nodes can be different, which further complicates the problem. We first propose a discrete numerical algorithm to evaluate the instantaneous availability of each CE. A universal generating function based method is then implemented for assessing instantaneous and expected system connectivity for a specific CE allocation. As the CE allocation can have significant impacts on the system connectivity, we further define and solve the optimal CE allocation problem, whose objective is to find the CE allocation among LCCS nodes maximizing the expected system connectivity over a given mission time. Effects of different parameters including repair efficiency, mission time and repair time are investigated. As illustrated through examples, optimization results can facilitate optimal decisions on robust design and effective operation and maintenance managements of LCCSs. © 2017 Elsevier B.V.","Applied probability; Connectivity optimization; Linear consecutively connected system; Operation management; Random repair time","Maintenance; Radio communication; Radio transmission; Applied probability; Connected systems; Corrective maintenance; Instantaneous availabilities; Operation and maintenance; Operation management; Repair time; Universal generating functions; Repair",2-s2.0-85022094532
"Ma X., Wang B., Yu L.","Semi-supervised spectral algorithms for community detection in complex networks based on equivalence of clustering methods",2018,"Physica A: Statistical Mechanics and its Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029002632&doi=10.1016%2fj.physa.2017.08.116&partnerID=40&md5=76935f538b9ed4488ed9c040d90c90e2","Community detection is fundamental for revealing the structure-functionality relationship in complex networks, which involves two issues—the quantitative function for community as well as algorithms to discover communities. Despite significant research on either of them, few attempt has been made to establish the connection between the two issues. To attack this problem, a generalized quantification function is proposed for community in weighted networks, which provides a framework that unifies several well-known measures. Then, we prove that the trace optimization of the proposed measure is equivalent with the objective functions of algorithms such as nonnegative matrix factorization, kernel K-means as well as spectral clustering. It serves as the theoretical foundation for designing algorithms for community detection. On the second issue, a semi-supervised spectral clustering algorithm is developed by exploring the equivalence relation via combining the nonnegative matrix factorization and spectral clustering. Different from the traditional semi-supervised algorithms, the partial supervision is integrated into the objective of the spectral algorithm. Finally, through extensive experiments on both artificial and real world networks, we demonstrate that the proposed method improves the accuracy of the traditional spectral algorithms in community detection. © 2017 Elsevier B.V.","Community structure; Complex networks; Nonnegative matrix factorization; Spectral clustering","Complex networks; Factorization; Matrix algebra; Optimization; Population dynamics; Community structures; Equivalence relations; Generalized quantification; Nonnegative matrix factorization; Semi-supervised algorithm; Spectral clustering; Spectral clustering algorithms; Theoretical foundations; Clustering algorithms",2-s2.0-85029002632
"Asdrubali F., Baldinelli G., Bianchi F., Costarelli D., Rotili A., Seracini M., Vinti G.","Detection of thermal bridges from thermographic images by means of image processing approximation algorithms",2018,"Applied Mathematics and Computation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029724171&doi=10.1016%2fj.amc.2017.08.058&partnerID=40&md5=bb8e12ea0315be34e9cc4dc4a381a2fa","In this paper, we develop a procedure for the detection of the contours of thermal bridges from thermographic images, in order to study the energy performance of buildings. Two main steps of the above method are: the enhancement of the thermographic images by an optimized version of the mathematical algorithm for digital image processing based on the theory of sampling Kantorovich operators, and the application of a suitable thresholding based on the analysis of the histogram of the enhanced thermographic images. Finally, an improvement of the parameter defining the thermal bridge is obtained. © 2017 Elsevier Inc.","Approximation results; Image processing; Sampling Kantorovich operators; Thermal bridges; Thermographic images","Approximation algorithms; Mathematical operators; Approximation results; Energy performance of buildings; Mathematical algorithms; Thermal bridge; Thermographic images; Thresholding; Image processing",2-s2.0-85029724171
"Attouch H., Peypouquet J., Redont P.","Backward–forward algorithms for structured monotone inclusions in Hilbert spaces",2018,"Journal of Mathematical Analysis and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008402274&doi=10.1016%2fj.jmaa.2016.06.025&partnerID=40&md5=b63e9644b19afea6ddd5acd98531c187","In this paper, we study the backward–forward algorithm as a splitting method to solve structured monotone inclusions, and convex minimization problems in Hilbert spaces. It has a natural link with the forward–backward algorithm and has the same computational complexity, since it involves the same basic blocks, but organized differently. Surprisingly enough, this kind of iteration arises when studying the time discretization of the regularized Newton method for maximally monotone operators. First, we show that these two methods enjoy remarkable involutive relations, which go far beyond the evident inversion of the order in which the forward and backward steps are applied. Next, we establish several convergence properties for both methods, some of which were unknown even for the forward–backward algorithm. This brings further insight into this well-known scheme. Finally, we specialize our results to structured convex minimization problems, the gradient-projection algorithms, and give a numerical illustration of theoretical interest. © 2016 Elsevier Inc.","Forward–backward algorithm; Monotone inclusion; Proximal-gradient method",,2-s2.0-85008402274
"Lieu Q.X., Do D.T.T., Lee J.","An adaptive hybrid evolutionary firefly algorithm for shape and size optimization of truss structures with frequency constraints",2018,"Computers and Structures",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031108115&doi=10.1016%2fj.compstruc.2017.06.016&partnerID=40&md5=01bbca5bdb43f0dd0d07df2975fb75b6","This paper presents a novel adaptive hybrid evolutionary firefly algorithm (AHEFA) for shape and size optimization of truss structures under multiple frequency constraints. This algorithm is a hybridization of the differential evolution (DE) algorithm and the firefly algorithm (FA). An automatically adapted parameter is utilized to select an appropriate mutation scheme for an effective trade-off between the global and local search abilities. An elitist technique is applied to the selection phase to choose the best individuals. Accordingly, the convergence rate is significantly improved with the high solution accuracy. Six numerical examples are examined for the validity of the present algorithm. © 2017 Elsevier Ltd","Adaptive hybrid evolutionary firefly algorithm (AHEFA); Differential evolution (DE); Elitist technique; Firefly algorithm (FA); Frequency constraints; Truss structures","Bioluminescence; Economic and social effects; Mechanical variables measurement; Optimization; Structural optimization; Trusses; Differential Evolution; Elitist technique; Firefly algorithms; Frequency constraint; Truss structure; Evolutionary algorithms",2-s2.0-85031108115
"Fang L., Zhang X., Zuo H., Pang L.","Focusing light through random scattering media by four-element division algorithm",2018,"Optics Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030529259&doi=10.1016%2fj.optcom.2017.08.062&partnerID=40&md5=e4fde61986b290cc16159329ee973b9a","The focusing of light through random scattering materials using wavefront shaping is studied in detail. We propose a newfangled approach namely four-element division algorithm to improve the average convergence rate and signal-to-noise ratio of focusing. Using 4096 independently controlled segments of light, the intensity at the target is 72 times enhanced over the original intensity at the same position. The four-element division algorithm and existing phase control algorithms of focusing through scattering media are compared by both of the numerical simulation and the experiment. It is found that four-element division algorithm is particularly advantageous to improve the average convergence rate of focusing. © 2017 Elsevier B.V.","Focusing light; Four-element division algorithm; Interference; Phase modulation","Phase modulation; Signal to noise ratio; Wave interference; Convergence rates; Division algorithms; Random scattering; Random scattering media; Scattering media; Wave front shaping; Focusing",2-s2.0-85030529259
"Juno J., Hakim A., TenBarge J., Shi E., Dorland W.","Discontinuous Galerkin algorithms for fully kinetic plasmas",2018,"Journal of Computational Physics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031775604&doi=10.1016%2fj.jcp.2017.10.009&partnerID=40&md5=ca50fa58b69ea13195fe78b54d574ad7","We present a new algorithm for the discretization of the non-relativistic Vlasov–Maxwell system of equations for the study of plasmas in the kinetic regime. Using the discontinuous Galerkin finite element method for the spatial discretization, we obtain a high order accurate solution for the plasma's distribution function. Time stepping for the distribution function is done explicitly with a third order strong-stability preserving Runge–Kutta method. Since the Vlasov equation in the Vlasov–Maxwell system is a high dimensional transport equation, up to six dimensions plus time, we take special care to note various features we have implemented to reduce the cost while maintaining the integrity of the solution, including the use of a reduced high-order basis set. A series of benchmarks, from simple wave and shock calculations, to a five dimensional turbulence simulation, are presented to verify the efficacy of our set of numerical methods, as well as demonstrate the power of the implemented features. © 2017 Elsevier Inc.","Discontinuous Galerkin; Vlasov–Maxwell",,2-s2.0-85031775604
"Qin P., Wu J., Li X., Tang Y.","Multipoint to multipoint routing and wavelength assignment in multi-domain optical networks",2018,"Physica A: Statistical Mechanics and its Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029718866&doi=10.1016%2fj.physa.2017.08.112&partnerID=40&md5=678f20614ac1f6d8133746bfe88d2aee","In multi-point to multi-point (MP2MP) routing and wavelength assignment (RWA) problems, researchers usually assume the optical networks to be a single domain. However, the optical networks develop toward to multi-domain and larger scale in practice. In this context, multi-core shared tree (MST)-based MP2MP RWA are introduced problems including optimal multicast domain sequence selection, core nodes belonging in which domains and so on. In this letter, we focus on MST-based MP2MP RWA problems in multi-domain optical networks, mixed integer linear programming (MILP) formulations to optimally construct MP2MP multicast trees is presented. A heuristic algorithm base on network virtualization and weighted clustering algorithm (NV-WCA) is proposed. Simulation results show that, under different traffic patterns, the proposed algorithm achieves significant improvement on network resources occupation and multicast trees setup latency in contrast with the conventional algorithms which were proposed base on a single domain network environment. © 2017","MILP model; MP2MP; Multi-domain; Optical networks; RWA","Fiber optic networks; Heuristic algorithms; Integer programming; Multicasting; Network routing; Optimization; Trees (mathematics); Conventional algorithms; MILP model; Mixed-integer linear programming; MP2MP; Multi domains; Routing and wavelength assignment; Routing and wavelength assignment problems; Weighted clustering algorithms; Clustering algorithms",2-s2.0-85029718866
"Prawin J., Rama Mohan Rao A.","An online input force time history reconstruction algorithm using dynamic principal component analysis",2018,"Mechanical Systems and Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026871645&doi=10.1016%2fj.ymssp.2017.06.031&partnerID=40&md5=1b470ce984f15a175832db00bf0ce2fb","The knowledge of dynamic loads acting on a structure is always required for many practical engineering problems, such as structural strength analysis, health monitoring and fault diagnosis, and vibration isolation. In this paper, we present an online input force time history reconstruction algorithm using Dynamic Principal Component Analysis (DPCA) from the acceleration time history response measurements using moving windows. We also present an optimal sensor placement algorithm to place limited sensors at dynamically sensitive spatial locations. The major advantage of the proposed input force identification algorithm is that it does not require finite element idealization of structure unlike the earlier formulations and therefore free from physical modelling errors. We have considered three numerical examples to validate the accuracy of the proposed DPCA based method. Effects of measurement noise, multiple force identification, different kinds of loading, incomplete measurements, and high noise levels are investigated in detail. Parametric studies have been carried out to arrive at optimal window size and also the percentage of window overlap. Studies presented in this paper clearly establish the merits of the proposed algorithm for online load identification. © 2017 Elsevier Ltd","Deconvolution; Effective independence method; Force identification; Principal component analysis; Scaled principal coordinate time history","Deconvolution; Dynamic loads; Fault detection; Numerical methods; Structural health monitoring; Vibration analysis; Acceleration-time history; Dynamic principal component analysis; Effective independence methods; Force identification; Optimal sensor placement; Practical engineering problems; Principal coordinates; Reconstruction algorithms; Principal component analysis",2-s2.0-85026871645
"Hu L., Ren L., Lin W.","A reconsideration of negative ratings for network-based recommendation",2018,"Physica A: Statistical Mechanics and its Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028967320&doi=10.1016%2fj.physa.2017.08.119&partnerID=40&md5=54b8fce9ce8e40bcf13a6e6dbcc166f0","Recommendation algorithms based on bipartite networks have become increasingly popular, thanks to their accuracy and flexibility. Currently, many of these methods ignore users’ negative ratings. In this work, we propose a method to exploit negative ratings for the network-based inference algorithm. We find that negative ratings play a positive role regardless of sparsity of data sets. Furthermore, we improve the efficiency of our method and compare it with the state-of-the-art algorithms. Experimental results show that the present method outperforms the existing algorithms. © 2017","Bipartite network; Negative ratings; Recommender systems","Physics; Recommender systems; Bipartite network; Inference algorithm; Network-based; Recommendation algorithms; State-of-the-art algorithms; Inference engines",2-s2.0-85028967320
"Cheng W., Sun D.-W., Pu H., Wei Q.","Characterization of myofibrils cold structural deformation degrees of frozen pork using hyperspectral imaging coupled with spectral angle mapping algorithm",2018,"Food Chemistry",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024121223&doi=10.1016%2fj.foodchem.2017.07.011&partnerID=40&md5=027ada27a58abb02e168a1a0d79e9a09","The study investigated the possibility of using hyperspectral imaging (HSI) in the spectral range of 1000–2200 nm to characterize myofibrils cold structural deformation degrees of frozen pork samples. The HSI images of pork samples frozen under different freezing rates were acquired in the frozen state without thawing. The myofibrils cold structural deformation degrees were evaluated by surface hydrophobicity (S0ANS) and Ca2+-ATPase activity. Spectral angle mapping (SAM) algorithm was used for the first time to extract the spectral information for regression. Compared with the optimized partial least square regression (PLSR) models based on selected wavebands by successive projections algorithm (SPA), the optimized PLSR models developed based on the spectral angles calculated by the SAM algorithm achieved comparable or even better performance with R2 P of 0.896 for S0ANS and 0.879 for Ca2+-ATPase activity, respectively. The implications of the frozen meat spectrum were also analyzed in the current study. © 2017 Elsevier Ltd","Ca2+-ATPase activity; Cold structural deformation; Myofibril; Spectral angle mapping algorithm; Spectral imaging; Surface hydrophobicity","Calcium; Conformal mapping; Deformation; Hydrophobicity; Mapping; Meats; Photomapping; Spectroscopy; ATP-ase activity; Myofibril; Spectral angle mapping; Spectral imaging; Structural deformation; Surface hydrophobicity; Hyperspectral imaging; adenosine triphosphatase (calcium); ice; algorithm; Article; cold; freezing; hydrophobicity; hyperspectral imaging; imaging; longissimus muscle; muscle fibril; pork; prediction; spectral angle mapping algorithm",2-s2.0-85024121223
"Diogo A.F., Barros L.T., Santos J., Temido J.S.","An effective and comprehensive model for optimal rehabilitation of separate sanitary sewer systems",2018,"Science of the Total Environment",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028747820&doi=10.1016%2fj.scitotenv.2017.08.315&partnerID=40&md5=2674218f02c16500d84cbf0054d7d238","In the field of rehabilitation of separate sanitary sewer systems, a large number of technical, environmental, and economic aspects are often relevant in the decision-making process, which may be modelled as a multi-objective optimization problem. Examples are those related with the operation and assessment of networks, optimization of structural, hydraulic, sanitary, and environmental performance, rehabilitation programmes, and execution works. In particular, the cost of investment, operation and maintenance needed to reduce or eliminate Infiltration from the underground water table and Inflows of storm water surface runoff (I/I) using rehabilitation techniques or related methods can be significantly lower than the cost of transporting and treating these flows throughout the lifespan of the systems or period studied. This paper presents a comprehensive I/I cost–benefit approach for rehabilitation that explicitly considers all elements of the systems and shows how the approximation is incorporated as an objective function in a general evolutionary multi-objective optimization model. It takes into account network performance and wastewater treatment costs, average values of several input variables, and rates that can reflect the adoption of different predictable or limiting scenarios. The approach can be used as a practical and fast tool to support decision-making in sewer network rehabilitation in any phase of a project. The fundamental aspects, modelling, implementation details and preliminary results of a two-objective optimization rehabilitation model using a genetic algorithm, with a second objective function related to the structural condition of the network and the service failure risk, are presented. The basic approach is applied to three real world cases studies of sanitary sewerage systems in Coimbra and the results show the simplicity, suitability, effectiveness, and usefulness of the approximation implemented and of the objective function proposed. © 2017 Elsevier B.V.","Cost–benefit approach; Evolutionary algorithms; Infiltration/inflow; Multi-objective optimization; Sewer rehabilitation; Wastewater treatment","Costs; Decision making; Environmental management; Evolutionary algorithms; Genetic algorithms; Groundwater; Infiltration; Optimization; Risk assessment; Runoff; Sanitary sewers; Sewers; Structural optimization; Wastewater treatment; Environmental performance; Evolutionary multiobjective optimization; Multi-objective optimization problem; Rehabilitation techniques; Sewer network rehabilitation; Sewer rehabilitation; Two-objective optimization; Wastewater treatment costs; Multiobjective optimization; cost-benefit analysis; genetic algorithm; infiltration; inflow; optimization; sewer network; wastewater treatment; Article; cost; environmental economics; environmental sanitation; genetic algorithm; mathematical model; Portugal; priority journal; process optimization; sewer; waste water management; waste water recycling; Coimbra [Portugal]; Portugal",2-s2.0-85028747820
"Stamatiou I.S.","A boundary preserving numerical scheme for the Wright–Fisher model",2018,"Journal of Computational and Applied Mathematics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027416261&doi=10.1016%2fj.cam.2017.07.011&partnerID=40&md5=02a6576f134e194ec4bc29727c13c5e4","We are interested in the numerical approximation of non-linear stochastic differential equations (SDEs) with solution in a certain domain. Our goal is to construct explicit numerical schemes that preserve that structure. We generalize the semi-discrete method (Halidias and Stamatiou, 2016), and propose a numerical scheme, for which we prove a strong convergence result, to a class of SDEs that appears in population dynamics and ion channel dynamics within cardiac and neuronal cells. We furthermore extend our scheme to a multidimensional case. © 2017 Elsevier B.V.","Boundary preserving numerical algorithm; Explicit numerical scheme; Non-linear SDEs; Semi-discrete method; Strong approximation error; Wright–Fisher model","Approximation algorithms; Differential equations; Numerical methods; Population statistics; Stochastic systems; Discrete method; Fisher model; Non linear; Numerical algorithms; Numerical scheme; Strong approximation; Convergence of numerical methods",2-s2.0-85027416261
"Xu X., Kargoll B., Bureick J., Yang H., Alkhatib H., Neumann I.","TLS-based profile model analysis of major composite structures with robust B-spline method",2018,"Composite Structures",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032305066&doi=10.1016%2fj.compstruct.2017.10.057&partnerID=40&md5=daee1bdb9bfcf446252031fe29256e58","With the development of city constructions, tunnels are becoming important structures for underground transportation. Tunnels constitute layered composite structures with concrete, reinforcement, waterproof layers, etc. Deformation monitoring of this kind of wide-ranging composite structure is significant to assure their safety considering the development of their complexity. Terrestrial laser scanning (TLS) is one of the most accurate and fast measurement technologies for deformation analysis. It has been applied widely in survey fields with the advantages of non-contact and panoramic acquisition of information. In this situation, TLS instruments are being developed rapidly, which necessitates high requirements regarding software aspects, especially concerning high-accuracy model construction. Therefore, developing a reliable method for 3D modeling with complex and massive point clouds is urgent. In this paper, we propose an adaptive expectation maximization (EM) method based on the scaled t-distribution for B-spline estimation, where automation is achieved for the best approximation with the maximum probability density. The innovation of this paper lies in offering a robust, automatic and time-efficient solution to model practical tunnel structures with a complex point cloud. © 2017 Elsevier Ltd","B-spline approximation; EM algorithm; Point cloud; Probability density; Robust estimation; Terrestrial laser scanning; Tunnel structure","Approximation algorithms; Deformation; Interpolation; Laser applications; Maximum principle; Probability density function; Probability distributions; Seebeck effect; Steel beams and girders; Structure (composition); Surface analysis; B-spline approximation; EM algorithms; Point cloud; Probability densities; Robust estimation; Terrestrial laser scanning; Tunnel structures; Surveying instruments",2-s2.0-85032305066
"Liu P., Cui G., Xiao Y., Chen J.","A new heuristic algorithm with the step size adjustment strategy for heat exchanger network synthesis",2018,"Energy",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032815243&doi=10.1016%2fj.energy.2017.10.115&partnerID=40&md5=d91abc606c466da830564d5731a8a860","The major difficulty in the heat exchanger network synthesis (HENS) is dealing with the simultaneous optimization of large-scale continuous and integer variables. Heuristic algorithms are used in HENS due to their efficient global search ability and the step size (ΔL) constitutes one of the critical concepts in it. In this paper, by analyzing the influence of ΔL in Random Walk Algorithm with Compulsive Evolution (RWCE), it was pronounced that evolution speed got faster when ΔL increased in the early stage and evolution accuracy was higher by ΔL declination, in the late stage. Hence, five new different ΔL adjustment functions were proposed. This case-study concluded that ΔL adjustment functions in an upward parabola declination could maintain high speed in the early stage and improve the accuracy of solutions in late stage respectively. However, during the late stage, the minor ΔL led to the decline of the global search ability and it was difficult to jump out of the local minimum. Furthermore certain individuals in the population were randomly given a relatively large ΔL in late stage. Thus, an integrated RWCE algorithm with ΔL adjustment strategy was presented and demonstrated satisfying global and local search ability. © 2017 Elsevier Ltd","Heat exchanger network synthesis (HENS); Optimization; Random Walk algorithm with compulsive evolution (RWCE); Step size",,2-s2.0-85032815243
"Moezi S.A., Zakeri E., Zare A.","Structural single and multiple crack detection in cantilever beams using a hybrid Cuckoo-Nelder-Mead optimization method",2018,"Mechanical Systems and Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026872220&doi=10.1016%2fj.ymssp.2017.07.013&partnerID=40&md5=1bc48b884762bae4146034b54c4b3280","In this study, the number, location and depth of cracks created in several Euler-Bernoulli beams, such as a simple beam and a more complex multi-step beam are investigated. The location and depth of the created cracks are determined using the hybrid Cuckoo-Nelder-Mead Optimization Algorithm (COA-NM) with high accuracy. The natural frequencies of the cracked beams are determined by solving frequency response equations, and performing modal test experiments. Results of COA-NM show a higher accuracy and convergence speed compared with other methods such as GA-NM, PSO-NM, GA, PSO, COA and several previous studies. Amount of calculations performed by COA-NM to achieve this accuracy is much less compared to other methods. © 2017 Elsevier Ltd","COA; Euler-Bernoulli cantilever beams; Modal analysis; Multi-step beams; Multiple crack detection; Nelder-Mead; Transfer matrix method","Cantilever beams; Cracks; Frequency response; Genetic algorithms; Modal analysis; Nanocantilevers; Optimization; Particle swarm optimization (PSO); Transfer matrix method; Convergence speed; Euler Bernoulli beams; Euler-Bernoulli; Frequency response equations; Multi-step; Nelder meads; Optimization algorithms; Optimization method; Crack detection",2-s2.0-85026872220
"Ahmed H.O.A., Wong M.L.D., Nandi A.K.","Intelligent condition monitoring method for bearing faults from highly compressed measurements using sparse over-complete features",2018,"Mechanical Systems and Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026870301&doi=10.1016%2fj.ymssp.2017.06.027&partnerID=40&md5=e828be9c481bcc6d3f289c06795b1bc5","Condition classification of rolling element bearings in rotating machines is important to prevent the breakdown of industrial machinery. A considerable amount of literature has been published on bearing faults classification. These studies aim to determine automatically the current status of a roller element bearing. Of these studies, methods based on compressed sensing (CS) have received some attention recently due to their ability to allow one to sample below the Nyquist sampling rate. This technology has many possible uses in machine condition monitoring and has been investigated as a possible approach for fault detection and classification in the compressed domain, i.e., without reconstructing the original signal. However, previous CS based methods have been found to be too weak for highly compressed data. The present paper explores computationally, for the first time, the effects of sparse autoencoder based over-complete sparse representations on the classification performance of highly compressed measurements of bearing vibration signals. For this study, the CS method was used to produce highly compressed measurements of the original bearing dataset. Then, an effective deep neural network (DNN) with unsupervised feature learning algorithm based on sparse autoencoder is used for learning over-complete sparse representations of these compressed datasets. Finally, the fault classification is achieved using two stages, namely, pre-training classification based on stacked autoencoder and softmax regression layer form the deep net stage (the first stage), and re-training classification based on backpropagation (BP) algorithm forms the fine-tuning stage (the second stage). The experimental results show that the proposed method is able to achieve high levels of accuracy even with extremely compressed measurements compared with the existing techniques. © 2017 The Authors","Bearing fault classification; Compressed sensing; Deep neural network; Machine condition monitoring; Sparse autoencoder; Sparse over-complete representations","Backpropagation algorithms; Bearings (machine parts); Compressed sensing; Deep learning; Deep neural networks; Fault detection; Learning algorithms; Learning systems; Machinery; Roller bearings; Signal reconstruction; Auto encoders; Bearing fault; Classification performance; Fault detection and classification; Intelligent condition monitoring; Machine condition monitoring; Over-complete representations; Unsupervised feature learning; Condition monitoring",2-s2.0-85026870301
"Tang J., Qiao J., Wu Z., Chai T., Zhang J., Yu W.","Vibration and acoustic frequency spectra for industrial process modeling using selective fusion multi-condition samples and multi-source features",2018,"Mechanical Systems and Signal Processing",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026861305&doi=10.1016%2fj.ymssp.2017.06.008&partnerID=40&md5=1ff780228d6af7c2575c75cc3ba2ab1f","Frequency spectral data of mechanical vibration and acoustic signals relate to difficult-to-measure production quality and quantity parameters of complex industrial processes. A selective ensemble (SEN) algorithm can be used to build a soft sensor model of these process parameters by fusing valued information selectively from different perspectives. However, a combination of several optimized ensemble sub-models with SEN cannot guarantee the best prediction model. In this study, we use several techniques to construct mechanical vibration and acoustic frequency spectra of a data-driven industrial process parameter model based on selective fusion multi-condition samples and multi-source features. Multi-layer SEN (MLSEN) strategy is used to simulate the domain expert cognitive process. Genetic algorithm and kernel partial least squares are used to construct the inside-layer SEN sub-model based on each mechanical vibration and acoustic frequency spectral feature subset. Branch-and-bound and adaptive weighted fusion algorithms are integrated to select and combine outputs of the inside-layer SEN sub-models. Then, the outside-layer SEN is constructed. Thus, “sub-sampling training examples”-based and “manipulating input features”-based ensemble construction methods are integrated, thereby realizing the selective information fusion process based on multi-condition history samples and multi-source input features. This novel approach is applied to a laboratory-scale ball mill grinding process. A comparison with other methods indicates that the proposed MLSEN approach effectively models mechanical vibration and acoustic signals. © 2017 Elsevier Ltd","Frequency spectrum; Genetic algorithm; Kernel partial least squares; Mechanical vibration and acoustic signals; Multi-layer selective ensemble; Selective information fusion","Acoustic waves; Genetic algorithms; Grinding (machining); Information fusion; Least squares approximations; Spectroscopy; Acoustic signals; Adaptive weighted fusion algorithm; Complex industrial process; Ensemble construction; Frequency spectra; Industrial processs; Kernel partial least squares; Selective ensembles; Vibrations (mechanical)",2-s2.0-85026861305
"Krepper G., Romeo F., Fernandes D.D.D.S., Diniz P.H.G.D., de Araújo M.C.U., Di Nezio M.S., Pistonesi M.F., Centurión M.E.","Determination of fat content in chicken hamburgers using NIR spectroscopy and the Successive Projections Algorithm for interval selection in PLS regression (iSPA-PLS)",2018,"Spectrochimica Acta - Part A: Molecular and Biomolecular Spectroscopy",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027549170&doi=10.1016%2fj.saa.2017.08.046&partnerID=40&md5=e161a025e4119e8373c14d1151351e43","Determining fat content in hamburgers is very important to minimize or control the negative effects of fat on human health, effects such as cardiovascular diseases and obesity, which are caused by the high consumption of saturated fatty acids and cholesterol. This study proposed an alternative analytical method based on Near Infrared Spectroscopy (NIR) and Successive Projections Algorithm for interval selection in Partial Least Squares regression (iSPA-PLS) for fat content determination in commercial chicken hamburgers. For this, 70 hamburger samples with a fat content ranging from 14.27 to 32.12 mg kg− 1 were prepared based on the upper limit recommended by the Argentinean Food Codex, which is 20% (w w− 1). NIR spectra were then recorded and then preprocessed by applying different approaches: base line correction, SNV, MSC, and Savitzky-Golay smoothing. For comparison, full-spectrum PLS and the Interval PLS are also used. The best performance for the prediction set was obtained for the first derivative Savitzky-Golay smoothing with a second-order polynomial and window size of 19 points, achieving a coefficient of correlation of 0.94, RMSEP of 1.59 mg kg− 1, REP of 7.69% and RPD of 3.02. The proposed methodology represents an excellent alternative to the conventional Soxhlet extraction method, since waste generation is avoided, yet without the use of either chemical reagents or solvents, which follows the primary principles of Green Chemistry. The new method was successfully applied to chicken hamburger analysis, and the results agreed with those with reference values at a 95% confidence level, making it very attractive for routine analysis. © 2017 Elsevier B.V.","Fat; Hamburgers; Interval selection; NIR spectroscopy; Partial Least Squares; Successive Projections Algorithm","Animals; Disease control; Fatty acids; Infrared devices; Near infrared spectroscopy; Oils and fats; Saturated fatty acids; Spectrum analysis; Hamburgers; Interval selection; NIR spectroscopy; Partial least square (PLS); Successive projections algorithm; Least squares approximations",2-s2.0-85027549170
"Gong J.M., Yang H., Lin S.H., Li R., Zivkovic V.","Spatial filtering velocimetry for surface velocity measurement of granular flow",2018,"Powder Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032353022&doi=10.1016%2fj.powtec.2017.10.041&partnerID=40&md5=c44e83dcbdfde4c58fe455f248f528e3","In this study, we develop the spatial filtering velocimetry (SFV) technique to measure the velocity distribution of small spherical and irregular particle flows using a linear CCD camera. In addition, energy barycentre correction algorithm is used to enhance the measurement accuracy. A constantly running conveyor belt is used to test the accuracy of this SFV system. Furthermore, the velocity distributions of the spherical and irregular particle flows in a rotating drum are measured to demonstrate the usability of this method in a granular system. We further discuss the effect of the key system parameters on the results of the measurement, and the optimal thresholds of the parameters are given in this paper. © 2017 Elsevier B.V.","Granular flow; Irregular particle; Spatial filtering velocimetry; Surface velocity measurement","Beamforming; Belt conveyors; CCD cameras; Confined flow; Granular materials; Particles (particulate matter); Velocimeters; Velocity; Velocity measurement; Correction algorithms; Granular flows; Irregular particle; Linear ccd cameras; Measurement accuracy; Optimal threshold; Spatial filtering velocimetry; Surface velocity; Velocity distribution; algorithm; angle of repose; Article; energy; energy barycentre correction algorithm; feasibility study; flow; granular flow; image analysis; kinetic energy; mathematical computing; measurement; measurement accuracy; signal noise ratio; spatial filtering velocimetry; surface velocity; velocity",2-s2.0-85032353022
"Gonsamo A., Walter J.-M., Chen J.M., Pellikka P., Schleppi P.","A robust leaf area index algorithm accounting for the expected errors in gap fraction observations",2018,"Agricultural and Forest Meteorology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030658525&doi=10.1016%2fj.agrformet.2017.09.024&partnerID=40&md5=b8315c6f66e1735edd555dbf784b9196","The leaf area index, LAI, representing the physiological and structural functions of vegetation canopies, can be estimated from gap fraction measurements obtained at different zenith angles. Earlier works have provided practical and convenient theoretical solution to retrieve LAI based on the integration of contact numbers (a projected area of leaves on a plane perpendicular to the view or solar zenith angle) over zenith angles as obtained by a linear regression, i.e., LAI = 2(A + B), where A and B are the coefficients of the regression of contact numbers against zenith angles. This graphical procedure is equivalent to the more accurate method of LAI retrieval by integrating gap fraction measurements from nadir through horizon angles. However, using an ordinary least-squares regression on inherently unsteady relationship between contact numbers and zenith angles limited the use of a simple graphical procedure for LAI estimation. In this study, we introduce the use of robust procedure to retrieve regression coefficients (i.e., A and B), and assess the performance of the new procedure using numerically derived hypothetical data, computer simulated and real measurements of hemispherical photographs. Our results indicated, the new procedure not only outperformed the ordinary least-squares solution for graphical procedure, but also outperformed all existing LAI methods We conclude from analyses using numerically derived hypothetical data, computer simulated and real measurements of hemispherical photographs that estimating A and B (where LAI = 2(A + B)) using a robust procedure is a convenient and sufficiently accurate method for estimating LAI from field measurements of gap fractions at different zenith angles. © 2017 Elsevier B.V.","CIMES; Gap fraction; Hemispherical photograph; Leaf area index; Least Absolute Deviations; Robust regression","accuracy assessment; algorithm; graphical method; leaf area index; least squares method; photography; regression analysis; vegetation dynamics; zenith angle",2-s2.0-85030658525
"Sirumbal-Zapata L.F., Málaga-Chuquitaype C., Elghazouli A.Y.","A three-dimensional plasticity-damage constitutive model for timber under cyclic loads",2018,"Computers and Structures",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030756483&doi=10.1016%2fj.compstruc.2017.09.010&partnerID=40&md5=c67747f2d4d0015d2d3b4f3f1e3c96a4","The performance of timber structures is governed by the nonlinear response at their connections, where high deformation levels and stress concentrations are developed, particularly when subjected to load reversals. To date, no constitutive model for wood under cyclic load exists which is able to incorporate its most important failure modes while considering plastic deformations and cyclic stiffness and strength degradation simultaneously. This paper presents the formulation and implementation of a plasticity-damage model with these characteristics within a continuum mechanics approach. The theoretical framework of both plasticity and damage models is described, and a detailed derivation of the constitutive equations required for their computational implementation and coupling as well as the return mapping and iterative algorithms for their integration are presented. The damage evolution process is handled by two independent scalar variables for tension and compression. A general orthotropic plasticity yield surface with isotropic hardening is employed to incorporate timber plastic flow in compression. A closed-form expression for the plasticity-damage consistent tangent operator is derived. It is demonstrated that the proposed constitutive model captures all the key characteristics required for an accurate modelling of timber under large deformation levels until failure. © 2017 Elsevier Ltd","Continuum damage mechanics; Cyclic loading; Numerical algorithm; Orthotropy; Plasticity; Timber","Constitutive models; Continuum damage mechanics; Continuum mechanics; Cyclic loads; Deformation; Iterative methods; Plasticity; Timber; Closed-form expression; Computational implementations; Damage constitutive model; Damage evolution process; Numerical algorithms; Orthotropic plasticity; Orthotropy; Tension and compression; Constitutive equations",2-s2.0-85030756483
"Ma X., Huang X., Du S., Liu H., Ning X.","Symbolic joint entropy reveals the coupling of various brain regions",2018,"Physica A: Statistical Mechanics and its Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029493728&doi=10.1016%2fj.physa.2017.08.089&partnerID=40&md5=54d12822a56fd5dc3d6258ace600d73c","The convergence and divergence of oscillatory behavior of different brain regions are very important for the procedure of information processing. Measurements of coupling or correlation are very useful to study the difference of brain activities. In this study, EEG signals were collected from ten subjects under two conditions, i.e. eyes closed state and idle with eyes open. We propose a nonlinear algorithm, symbolic joint entropy, to compare the coupling strength among the frontal, temporal, parietal and occipital lobes and between two different states. Instead of decomposing the EEG into different frequency bands (theta, alpha, beta, gamma etc.), the novel algorithm is to investigate the coupling from the entire spectrum of brain wave activities above 4Hz. The coupling coefficients in two states with different time delay steps are compared and the group statistics are presented as well. We find that the coupling coefficient of eyes open state with delay consistently lower than that of eyes close state across the group except for one subject, whereas the results without delay are not consistent. The differences between two brain states with non-zero delay can reveal the intrinsic inter-region coupling better. We also use the well-known Hénon map data to validate the algorithm proposed in this paper. The result shows that the method is robust and has a great potential for other physiologic time series. © 2017 Elsevier B.V.","Coupling coefficient; EEG; Symbolic joint entropy (SJE); Time-delay","Electroencephalography; Entropy; Frequency bands; Time delay; Coupling coefficient; Coupling strengths; Different frequency; Joint entropy; Non zero delays; Nonlinear algorithms; Novel algorithm; Oscillatory behaviors; Brain",2-s2.0-85029493728
"Morse L., Sharif Khodaei Z., Aliabadi M.H.","Reliability based impact localization in composite panels using Bayesian updating and the Kalman filter",2018,"Mechanical Systems and Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026885377&doi=10.1016%2fj.ymssp.2017.05.047&partnerID=40&md5=89517db7b9b66660c86956f6fa21d2e4","In this work, a reliability based impact detection strategy for a sensorized composite structure is proposed. Impacts are localized using Artificial Neural Networks (ANNs) with recorded guided waves due to impacts used as inputs. To account for variability in the recorded data under operational conditions, Bayesian updating and Kalman filter techniques are applied to improve the reliability of the detection algorithm. The possibility of having one or more faulty sensors is considered, and a decision fusion algorithm based on sub-networks of sensors is proposed to improve the application of the methodology to real structures. A strategy for reliably categorizing impacts into high energy impacts, which are probable to cause damage in the structure (true impacts), and low energy non-damaging impacts (false impacts), has also been proposed to reduce the false alarm rate. The proposed strategy involves employing classification ANNs with different features extracted from captured signals used as inputs. The proposed methodologies are validated by experimental results on a quasi-isotropic composite coupon impacted with a range of impact energies. © 2017 The Authors","Artificial Neural Network (ANN); Bayesian updating; False alarm; Kalman filter; Low velocity impact; Structural Health Monitoring (SHM)","Bandpass filters; Errors; Guided electromagnetic wave propagation; Neural networks; Reliability; Structural health monitoring; Bayesian updating; Decision-fusion algorithms; Detection algorithm; False alarms; Kalman filter technique; Low velocity impact; Operational conditions; Structural health monitoring (SHM); Kalman filters",2-s2.0-85026885377
"Xu Z., Xia X., Lai S., He Z.","Improvement of interior sound quality for passenger car based on optimization of sound pressure distribution in low frequency",2018,"Applied Acoustics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029519409&doi=10.1016%2fj.apacoust.2017.08.019&partnerID=40&md5=fd56a6e4ac4525e86f7d3e87ae3308d5","The low-frequency acoustic response model of car is established with finite element method (FEM) and boundary element method (BEM), and the model is validated via road test. Utilizing the equal rectangle bandwidth critical band within 20–200 Hz, the 16 sound samples are designed by orthogonal experiment with the collected signal of driver at 50 km/h as example. The psychoacoustical indices of each sample are calculated through the program compilation, and the annoyance of each sample is obtained via subjective test. The prediction model for sound quality is completed under the comprehension of genetic algorithm (GA), particle swam optimization (PSO) and support vector machine (SVM). Taking the sound pressure level of each equal rectangle bandwidth band in low frequency as variables and taking the minimal subjective annoyance of samples as optimization objective, an optimization model for sound quality is established. Subsequently, the optimal sound quality is obtained. An extra subjective evaluation validates this proposed optimization method. © 2017 Elsevier Ltd","Equal rectangle bandwidth; Genetic algorithm; Improvement of sound quality; Low frequency; Support vector machine","Acoustic variables measurement; Bandwidth; Boundary element method; Finite element method; Genetic algorithms; Geometry; Optimization; Particle swarm optimization (PSO); Sailing vessels; Software testing; Support vector machines; Low frequency acoustic; Low-frequency; Optimization modeling; Orthogonal experiment; Particle swam optimizations (PSO); Sound pressure distribution; Sound Quality; Subjective evaluations; Sound reproduction",2-s2.0-85029519409
"Zhang X., Cui Y., Wang Y., Sun M., Hu H.","An improved AE detection method of rail defect based on multi-level ANC with VSS-LMS",2018,"Mechanical Systems and Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026872122&doi=10.1016%2fj.ymssp.2017.06.029&partnerID=40&md5=2512291eced5201d6afe5e3cbfd32d0a","In order to ensure the safety and reliability of railway system, Acoustic Emission (AE) method is employed to investigate rail defect detection. However, little attention has been paid to the defect detection at high speed, especially for noise interference suppression. Based on AE technology, this paper presents an improved rail defect detection method by multi-level ANC with VSS-LMS. Multi-level noise cancellation based on SANC and ANC is utilized to eliminate complex noises at high speed, and tongue-shaped curve with index adjustment factor is proposed to enhance the performance of variable step-size algorithm. Defect signals and reference signals are acquired by the rail-wheel test rig. The features of noise signals and defect signals are analyzed for effective detection. The effectiveness of the proposed method is demonstrated by comparing with the previous study, and different filter lengths are investigated to obtain a better noise suppression performance. Meanwhile, the detection ability of the proposed method is verified at the top speed of the test rig. The results clearly illustrate that the proposed method is effective in detecting rail defects at high speed, especially for noise interference suppression. © 2017 Elsevier Ltd","Acoustic emission; Adaptive noise cancellation; Rail defect detection; Variable step-size algorithm","Acoustic emissions; Acoustic noise; Defects; Inspection; Railroad transportation; Spurious signal noise; Adaptive noise cancellations; Adjustment factors; Detection ability; Detection methods; Noise cancellation; Noise suppression; Rail defects; Variable step-size algorithms; Acoustic emission testing",2-s2.0-85026872122
"Giannini Kurina F., Hang S., Cordoba M.A., Negro G.J., Balzarini M.G.","Enhancing edaphoclimatic zoning by adding multivariate spatial statistics to regional data",2018,"Geoderma",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029850124&doi=10.1016%2fj.geoderma.2017.09.011&partnerID=40&md5=ec01886e00922c9171d20bd13f70f7cd","Joint spatial variability of soil and climate variables offers the opportunity to delimit contiguous edaphoclimatic zones. These zones can be useful to improve natural resource management. The aim of this work was to develop a statistical protocol for multivariate zoning at regional scales. A zoning of Córdoba, Argentina, was generated using data from a sample of 355 sites involving edaphic and climatic data (pH, TN, TOC, Na, K, CEC, Cu, Clay, Sand, WHC, elevation, annual precipitation and mean temperature). We proposed a two-step algorithm that considers the spatial correlation of these variables in a clustering of sites. The protocol was run after modeling the spatial pattern of each soil variable to adapt information from different sources and formats to a fine grid. In the first step of the protocol, MULTISPATI-PCA, an extension of the principal component analysis that considers the spatial co-variability between variables, was used to obtain linear combinations of original data. In the second step, such synthetic variables (spatial principal components) were used as input of the fuzzy k-mean clustering method to delineate homogeneous zones. The number of clusters was established by internal validation indices. The use of MULlTISPATI-PCA was compared with the more conventional and non-spatial PCA. Results suggest that previous geostatistical interpolation and spatially constrained multivariate analysis create meaningful and spatially coherent zones. Four zones were identified in Córdoba region, Argentina. © 2017 Elsevier B.V.","Fuzzy k-means; Multivariate zoning; Spatial principal components","Clustering algorithms; Multivariant analysis; Natural resources management; Zoning; Annual precipitation; Fuzzy k-means; Geostatistical interpolation; Multi variate analysis; Natural resource management; Principal Components; Spatial correlations; Statistical protocol; Principal component analysis; algorithm; geostatistics; interpolation; multivariate analysis; natural resource; principal component analysis; spatial variation; zoning; Argentina; Cordoba [Argentina]",2-s2.0-85029850124
"Huang Y., Pu M., Zhao Z., Li X., Ma X., Luo X.","Broadband metamaterial as an “invisible” radiative cooling coat",2018,"Optics Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029690602&doi=10.1016%2fj.optcom.2017.09.036&partnerID=40&md5=3599d8f667d345bb139aa6b499817384","In this paper, we propose a compact planar device in infrared (3–12μm) that has a high emission range from 5μm to 8μm while simultaneously serving as a broadband mirror for the rest wavelengths by engineering its thermal emission characteristics. The structure utilizes a random-stacked multilayer to reduce the thickness required for ideal spectrum engineering. In addition, it is also convenient to fabricate and scale up. All the features above makes it an “invisible” radiative cooling coat by taking advantage of the atmospheric transparency window. We believe that this device may fundamentally enable new technological possibilities for stealth techniques by integrating the device with traditional cloaking methods. © 2017","Broadband thermal emission engineering; Genetic algorithm; Metamaterials; Radiative cooling","Genetic algorithms; Metamaterials; Multilayers; Atmospheric transparency; Broadband mirrors; Emission range; Planar devices; Radiative cooling; Scale-up; Stealth technique; Thermal emissions; Cooling",2-s2.0-85029690602
"Zhang F., Sun Y., Wang X.D., Cao Q.P., Jiang J.Z., Wang C.Z., Ho K.M.","Structural connection between gallium crystals and near-Tm liquids under ambient pressure",2018,"Scripta Materialia",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029468683&doi=10.1016%2fj.scriptamat.2017.09.019&partnerID=40&md5=16341168ae89350cdafbd0264c1df859","We study the short-range structural order in liquid gallium prepared by ab initio molecular dynamics simulations. We found that at 400 K, which is close to the melting point (Tm) of Ga, the dominant motif in the liquid phase is identical to that in the stable solid phase Ga-I. Strong directional bonding in this motif prevents it from nucleation in the liquid phase. Meanwhile, a newly identified motif, topologically distinct from yet related to those in β-Ga and Ga-III phases, is also abundant in Ga liquid. This new motif could serve as precursors for β-Ga or Ga-III during crystallization. © 2017","Crystallization; Genetic algorithm; Liquids; Molecular dynamics; Short-range ordering","Crystallization; Genetic algorithms; Liquids; Molecular dynamics; Ab initio molecular dynamics simulation; Ambient pressures; Liquid gallium; Liquid Phase; Short range ordering; Solid-phase; Structural connections; Structural ordering; Gallium",2-s2.0-85029468683
"Huang C., Fu M.","A composite collocation method with low-period elongation for structural dynamics problems",2018,"Computers and Structures",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030773382&doi=10.1016%2fj.compstruc.2017.09.012&partnerID=40&md5=6f9f0132ffd7117f7ec2053c3408b634","This paper presents a novel time integration algorithm for solving linear structural dynamic problems in the framework of the high-order collocation method. When two Gauss points in the integration interval are selected as collocation points, both an A-stable algorithm with third order accuracy and a non-dissipative algorithm with fourth order accuracy can be derived from a second order collocation polynomial. The only difference is that the former obtains a numerical solution at the middle point of the time interval, while the latter has a solution at the end of the interval. A new composite method is established through applying these two algorithms alternately, which combines the advantages of the numerical dissipation property of the third order algorithm and the high-order accuracy of the fourth order algorithm. The usage frequency of the two algorithms during the whole step-by-step integration procedure is an important parameter affecting the numerical dissipation, which is investigated in this study. As the algebraic equations systems solved by the two algorithms are exactly same, no extra computation effort is introduced. © 2017 Elsevier Ltd","Collocation methods; Controllable numerical dissipation; High-order accuracy; Sparse linear algebra equations system; Structural dynamics; Time integration algorithms","Algebra; Integration; Linear algebra; Structural analysis; Structural dynamics; Collocation method; High-order accuracy; Linear algebra equations; Numerical dissipation; Time integration algorithms; Numerical methods",2-s2.0-85030773382
"Roy F., K. Gupta D.","Sufficient regularity conditions for complex interval matrices and approximations of eigenvalues sets",2018,"Applied Mathematics and Computation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029672361&doi=10.1016%2fj.amc.2017.08.056&partnerID=40&md5=6f727571c5589b7dc7f4fa569eed25bd","In this paper, two approaches are described to establish verifiable sufficient regularity conditions of complex interval matrices. In the first approach, a complex interval matrix is mapped to a real block interval matrix and then its sufficient regularity conditions are obtained. In the second approach, a necessary condition for the singularity of a complex interval matrix is derived and used to get its sufficient regularity conditions. As an application, the above derived sufficient regularity conditions are used to investigate the location of the outer approximations of individual eigenvalue sets of complex interval matrices. Two algorithms are proposed and results obtained are compared with those obtained by earlier methods and Monte Carlo simulations. The advantages of these algorithms are that they can detect gaps in between the approximations of the whole eigenvalue sets. The second algorithm is very effective compared to the first algorithm from the computational time point of view. Several numerical examples and statistical experiments are worked out to validate and demonstrate the efficacy of our work. © 2017 Elsevier Inc.","Complex interval matrices; Eigenvalue sets; Interval analysis; Monte-Carlo simulations; Regularity conditions; Sufficient regularity conditions","Approximation algorithms; Intelligent systems; Matrix algebra; Monte Carlo methods; Complex interval; Computational time; Eigen-value; Interval analysis; Interval matrix; Outer approximation; Regularity condition; Statistical experiments; Eigenvalues and eigenfunctions",2-s2.0-85029672361
"Sobie C., Freitas C., Nicolai M.","Simulation-driven machine learning: Bearing fault classification",2018,"Mechanical Systems and Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026874827&doi=10.1016%2fj.ymssp.2017.06.025&partnerID=40&md5=c40d375025b51a8496fdb7f8844e601d","Increasing the accuracy of mechanical fault detection has the potential to improve system safety and economic performance by minimizing scheduled maintenance and the probability of unexpected system failure. Advances in computational performance have enabled the application of machine learning algorithms across numerous applications including condition monitoring and failure detection. Past applications of machine learning to physical failure have relied explicitly on historical data, which limits the feasibility of this approach to in-service components with extended service histories. Furthermore, recorded failure data is often only valid for the specific circumstances and components for which it was collected. This work directly addresses these challenges for roller bearings with race faults by generating training data using information gained from high resolution simulations of roller bearing dynamics, which is used to train machine learning algorithms that are then validated against four experimental datasets. Several different machine learning methodologies are compared starting from well-established statistical feature-based methods to convolutional neural networks, and a novel application of dynamic time warping (DTW) to bearing fault classification is proposed as a robust, parameter free method for race fault detection. © 2017 Elsevier Ltd","Condition monitoring; Fault detection; Machine learning; Prognostic health monitoring; Roller bearing","Artificial intelligence; Condition monitoring; Fault detection; Learning systems; Machine components; Neural networks; Roller bearings; Rollers (machine components); Systems engineering; Computational performance; Convolutional neural network; Dynamic time warping; Health monitoring; High resolution simulations; Parameter-free methods; Scheduled maintenance; Statistical features; Learning algorithms",2-s2.0-85026874827
"Žalik K.R., Žalik B.","A framework for detecting communities of unbalanced sizes in networks",2018,"Physica A: Statistical Mechanics and its Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027712040&doi=10.1016%2fj.physa.2017.07.028&partnerID=40&md5=ab64c99400e4175b77af357a653be215","Community detection in large networks has been a focus of recent research in many of fields, including biology, physics, social sciences, and computer science. Most community detection methods partition the entire network into communities, groups of nodes that have many connections within communities and few connections between them and do not identify different roles that nodes can have in communities. We propose a community detection model that integrates more different measures that can fast identify communities of different sizes and densities. We use node degree centrality, strong similarity with one node from community, maximal similarity of node to community, compactness of communities and separation between communities. Each measure has its own strength and weakness. Thus, combining different measures can benefit from the strengths of each one and eliminate encountered problems of using an individual measure. We present a fast local expansion algorithm for uncovering communities of different sizes and densities and reveals rich information on input networks. Experimental results show that the proposed algorithm is better or as effective as the other community detection algorithms for both real-world and synthetic networks while it requires less time. © 2017 Elsevier B.V.","Community detection; Complex networks; Network analysis; Social networks","Complex networks; Electric network analysis; Social networking (online); Community detection; Community detection algorithms; Different sizes; Large networks; Local expansion; Node degree; Recent researches; Synthetic networks; Population dynamics",2-s2.0-85027712040
"Do T.H., Yoo M.","Visible light communication based vehicle positioning using LED street light and rolling shutter CMOS sensors",2018,"Optics Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029595659&doi=10.1016%2fj.optcom.2017.09.022&partnerID=40&md5=b5231fe883a811f0315b55893d750d9a","This paper proposes a vehicle positioning system using LED street lights and two rolling shutter CMOS sensor cameras. In this system, identification codes for the LED street lights are transmitted to camera-equipped vehicles through a visible light communication (VLC) channel. Given that the camera parameters are known, the positions of the vehicles are determined based on the geometric relationship between the coordinates of the LEDs in the images and their real world coordinates, which are obtained through the LED identification codes. The main contributions of the paper are twofold. First, the collinear arrangement of the LED street lights makes traditional camera-based positioning algorithms fail to determine the position of the vehicles. In this paper, an algorithm is proposed to fuse data received from the two cameras attached to the vehicles in order to solve the collinearity problem of the LEDs. Second, the rolling shutter mechanism of the CMOS sensors combined with the movement of the vehicles creates image artifacts that may severely degrade the positioning accuracy. This paper also proposes a method to compensate for the rolling shutter artifact, and a high positioning accuracy can be achieved even when the vehicle is moving at high speeds. The performance of the proposed positioning system corresponding to different system parameters is examined by conducting Matlab simulations. Small-scale experiments are also conducted to study the performance of the proposed algorithm in real applications. © 2017 Elsevier B.V.","CMOS sensor; Positioning; Rolling shutter; Vehicle; Visible light communication","Cameras; CMOS integrated circuits; Codes (symbols); Light; Light emitting diodes; MATLAB; Vehicles; Visible light communication; CMOS sensors; Collinear arrangement; Geometric relationships; Positioning; Positioning algorithms; Rolling shutters; Small-scale experiment; Visible light communications (VLC); Vehicle to vehicle communications",2-s2.0-85029595659
"Albanesi A., Bre F., Fachinotti V., Gebhardt C.","Simultaneous ply-order, ply-number and ply-drop optimization of laminate wind turbine blades using the inverse finite element method",2018,"Composite Structures",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032585436&doi=10.1016%2fj.compstruct.2017.10.051&partnerID=40&md5=21860fcbcc667e75e45916e0150c5c76","This paper presents a novel methodology to simultaneously determine the optimal ply-order, ply-number and ply-drop configuration of laminate wind turbine blades using simulation-based optimization, considering the shape that the laminates are expected to attain after large elastic deformations. This methodology combines Genetic Algorithms with the Inverse Finite Element Method. As an actual engineering application, we redesigned the composite stacking layout of a medium-power 40-kW wind turbine blade to reduce its weight, subjected to mechanical and manufacturing constraints such as allowable tip deflection, maximum stress, natural frequencies, and maximum number of successive identical plies. Results demonstrate weight reductions of up to 15% compared to the initial layout, proving that the proposed methodology is a robust redesign tool capable of effectively determining the optimal composite stacking layout of laminate wind turbine blades. © 2017 Elsevier Ltd","Composite materials; Inverse finite element; Multilayered shells; Optimization; Wind turbine blade","Composite materials; Drops; Genetic algorithms; Inverse problems; Laminated composites; Laminates; Optimization; Paper laminates; Turbine components; Turbomachine blades; Wind turbines; Drop configurations; Engineering applications; Inverse finite element methods; Inverse finite elements; Manufacturing constraint; Multi-layered shells; Simulation-based optimizations; Wind turbine blades; Finite element method",2-s2.0-85032585436
"Jia X., Jin C., Buzza M., Di Y., Siegel D., Lee J.","A deviation based assessment methodology for multiple machine health patterns classification and fault detection",2018,"Mechanical Systems and Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026865921&doi=10.1016%2fj.ymssp.2017.06.015&partnerID=40&md5=2f621185b218ad927a0d234ead889e3b","Successful applications of Diffusion Map (DM) in machine failure detection and diagnosis have been reported in several recent studies. DM provides an efficient way to visualize the high-dimensional, complex and nonlinear machine data, and thus suggests more knowledge about the machine under monitoring. In this paper, a DM based methodology named as DM-EVD is proposed for machine degradation assessment, abnormality detection and diagnosis in an online fashion. Several limitations and challenges of using DM for machine health monitoring have been analyzed and addressed. Based on the proposed DM-EVD, a deviation based methodology is then proposed to include more dimension reduction methods. In this work, the incorporation of Laplacian Eigen-map and Principal Component Analysis (PCA) are explored, and the latter algorithm is named as PCA-Dev and is validated in the case study. To show the successful application of the proposed methodology, case studies from diverse fields are presented and investigated in this work. Improved results are reported by benchmarking with other machine learning algorithms. © 2017 Elsevier Ltd","Bearing; Diffusion map; Principal component analysis; Prognostic and health management; Semiconductor; Wind turbine","Bearings (structural); Fault detection; Health; Learning algorithms; Learning systems; Semiconductor materials; Wind turbines; Abnormality detection; Assessment methodologies; Degradation assessment; Diffusion maps; Dimension reduction method; Machine health monitoring; Patterns classification; Prognostic and health management; Principal component analysis",2-s2.0-85026865921
"Zhang S., Tang J.","Integrating angle-frequency domain synchronous averaging technique with feature extraction for gear fault diagnosis",2018,"Mechanical Systems and Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026888365&doi=10.1016%2fj.ymssp.2017.07.001&partnerID=40&md5=57a26d2f950054312a631db3435d7cb8","Gear fault diagnosis relies heavily on the scrutiny of vibration responses measured. In reality, gear vibration signals are noisy and dominated by meshing frequencies as well as their harmonics, which oftentimes overlay the fault related components. Moreover, many gear transmission systems, e.g., those in wind turbines, constantly operate under non-stationary conditions. To reduce the influences of non-synchronous components and noise, a fault signature enhancement method that is built upon angle-frequency domain synchronous averaging is developed in this paper. Instead of being averaged in the time domain, the signals are processed in the angle-frequency domain to solve the issue of phase shifts between signal segments due to uncertainties caused by clearances, input disturbances, and sampling errors, etc. The enhanced results are then analyzed through feature extraction algorithms to identify the most distinct features for fault classification and identification. Specifically, Kernel Principal Component Analysis (KPCA) targeting at nonlinearity, Multilinear Principal Component Analysis (MPCA) targeting at high dimensionality, and Locally Linear Embedding (LLE) targeting at local similarity among the enhanced data are employed and compared to yield insights. Numerical and experimental investigations are performed, and the results reveal the effectiveness of angle-frequency domain synchronous averaging in enabling feature extraction and classification. © 2017 Elsevier Ltd","Feature extraction; Gear fault diagnosis; Non-stationary operation; Signal processing; Synchronous averaging","Classification (of information); Extraction; Failure analysis; Fault detection; Feature extraction; Principal component analysis; Signal processing; Time domain analysis; Uncertainty analysis; Vibrations (mechanical); Wind turbines; Experimental investigations; Feature extraction algorithms; Feature extraction and classification; Gear fault diagnosis; Kernel principal component analyses (KPCA); Multilinear principal component analysis (MPCA); Nonstationary; Synchronous averaging; Frequency domain analysis",2-s2.0-85026888365
"Dal Molin J.P., Caliri A.","Entropic formulation for the protein folding process: Hydrophobic stability correlates with folding rates",2018,"Physica A: Statistical Mechanics and its Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029481046&doi=10.1016%2fj.physa.2017.07.027&partnerID=40&md5=09981da463b38f6d55f1212935f6a1fb","Here we focus on the conformational search for the native structure when it is ruled by the hydrophobic effect and steric specificities coming from amino acids. Our main tool of investigation is a 3D lattice model provided by a ten-letter alphabet, the stereochemical model. This minimalist model was conceived for Monte Carlo (MC) simulations when one keeps in mind the kinetic behavior of protein-like chains in solution. We have three central goals here. The first one is to characterize the folding time (τ) by two distinct sampling methods, so we present two sets of 103 MC simulations for a fast protein-like sequence. The resulting sets of characteristic folding times, τ and τq were obtained by the application of the standard Metropolis algorithm (MA), as well as by an enhanced algorithm (MqA). The finding for τq shows two things: (i) the chain-solvent hydrophobic interactions {hk} plus a set of inter-residues steric constraints {ci,j} are able to emulate the conformational search for the native structure. For each one of the 103MC performed simulations, the target is always found within a finite time window; (ii) the ratio τq∕τ≅1∕10 suggests that the effect of local thermal fluctuations, encompassed by the Tsallis weight, provides to the chain an innate efficiency to escape from energetic and steric traps. We performed additional MC simulations with variations of our design rule to attest this first result, both algorithms the MA and the MqA were applied to a restricted set of targets, a physical insight is provided. Our second finding was obtained by a set of 600 independent MC simulations, only performed with the MqA applied to an extended set of 200 representative targets, our native structures. The results show how structural patterns should modulate τq, which cover four orders of magnitude; this finding is our second goal. The third, and last result, was obtained with a special kind of simulation performed with the purpose to explore a possible connection between the hydrophobic component of protein stability and the native structural topology. We simulated those same 200 targets again with the MqA, only. However, this time we evaluated the relative frequency {ϕq} in which each target visits its corresponding native structure along an appropriate simulation time. Due to the presence of the hydrophobic effect in our approach we obtained a strong correlation between the stability and the folding rate (R=0.85). So, as faster a sequence found its target, as larger is the hydrophobic component of its stability. The strong correlation fulfills our last goal. This final finding suggests that the hydrophobic effect could not be a general stabilizing factor for proteins. © 2017",,"Chains; Monte Carlo methods; Proteins; Respiratory mechanics; Stability; Conformational search; Hydrophobic components; Hydrophobic interactions; Hydrophobic stability; Metropolis algorithms; Stereochemical models; Structural topologies; Thermal fluctuations; Hydrophobicity",2-s2.0-85029481046
"Shen L., Chu Z., Yang Y., Wang G.","Periodic boundary based FFT-FISTA for sound source identification",2018,"Applied Acoustics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029694366&doi=10.1016%2fj.apacoust.2017.09.009&partnerID=40&md5=50655dd1a8eb1fc639d843bc579e5ffb","Compared with the conventional beamforming, the Fourier-based fast iterative shrinkage thresholding algorithm (FFT-FISTA) can effectively improve the spatial resolution and suppress the sidelobe. To furtherly achieve higher computational efficiency and better sound source identification performance, an alternative periodic boundary is utilized to replace the zero boundary of Fourier transform, a periodic boundary based FFT-FISTA is proposed in this paper. And its superiority is demonstrated by the simulation and validation experiment of equal and unequal intensity sources. © 2017 Elsevier Ltd","Acoustic source identification; Beamforming; Deconvolution; FFT-FISTA; Periodic boundary; Zero boundary","Acoustic generators; Acoustics; Beamforming; Computational efficiency; Deconvolution; Iterative methods; Acoustic sources; Conventional beamforming; Iterative shrinkage-thresholding algorithms; Periodic boundaries; Simulation and validation; Sound source identification; Spatial resolution; Zero boundary; Fast Fourier transforms",2-s2.0-85029694366
"Amin M.J., Riza N.A.","Machine learning enhanced optical distance sensor",2018,"Optics Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030225987&doi=10.1016%2fj.optcom.2017.09.028&partnerID=40&md5=f8f87666b013457e3e2515b48aa697ce","Presented for the first time is a machine learning enhanced optical distance sensor. The distance sensor is based on our previously demonstrated distance measurement technique that uses an Electronically Controlled Variable Focus Lens (ECVFL) with a laser source to illuminate a target plane with a controlled optical beam spot. This spot with varying spot sizes is viewed by an off-axis camera and the spot size data is processed to compute the distance. In particular, proposed and demonstrated in this paper is the use of a regularized polynomial regression based supervised machine learning algorithm to enhance the accuracy of the operational sensor. The algorithm uses the acquired features and corresponding labels that are the actual target distance values to train a machine learning model. The optimized training model is trained over a 1000 mm (or 1 m) experimental target distance range. Using the machine learning algorithm produces a training set and testing set distance measurement errors of <0.8 mm and <2.2 mm, respectively. The test measurement error is at least a factor of 4 improvement over our prior sensor demonstration without the use of machine learning. Applications for the proposed sensor include industrial scenario distance sensing where target material specific training models can be generated to realize low <1% measurement error distance measurements. © 2017 Elsevier B.V.","Electronic lens; Machine learning; Optical distance sensing; Polynomial regression; Regularization","Artificial intelligence; Distance measurement; Errors; Learning systems; Lenses; Measurement errors; Supervised learning; Electronic lens; Machine learning models; Measurement techniques; Optical distance; Polynomial regression; Regularization; Sensor demonstrations; Supervised machine learning; Learning algorithms",2-s2.0-85030225987
"Wang J., Guo Z., Song Y., Han J.","Volume moiré tomography based on projection extraction by spatial phase shifting of double crossed gratings",2018,"Optics Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030696154&doi=10.1016%2fj.optcom.2017.09.029&partnerID=40&md5=7f714d2c6a1ce30dcdfb32fc384d84b3","To realize volume moiré tomography (VMT) for the real three-dimensional (3D) diagnosis of combustion fields, according to 3D filtered back projection (FBP) reconstruction algorithm, the radial derivatives of the projected phase should be measured firstly. In this paper, a simple spatial phase-shifting moiré deflectometry with double cross gratings is presented to measure the radial first-order derivative of the projected phase. Based on scalar diffraction theory, the explicit analytical intensity distributions of moiré patterns on different diffracted orders are derived, and the spatial shifting characteristics are analyzed. The results indicate that the first-order derivatives of the projected phase in two mutually perpendicular directions are involved in moiré patterns, which can be combined to compute the radial first-order derivative. And multiple spatial phase-shifted moiré patterns can be simultaneously obtained; the phase-shifted values are determined by the parameters of the system. A four-step phase-shifting algorithm is proposed for phase extraction, and its accuracy is proved by numerical simulations. Finally, the moiré deflectometry is used to measure the radial first-order derivative of projected phase of a propane flame with plane incident wave, and the 3D temperature distribution is reconstructed. © 2017 Elsevier B.V.","Moiré deflectometry; Phase retrieval; Phase shift; Tomographic image processing","Diffraction gratings; Extraction; Image processing; Phase shift; Tomography; 3d temperature distributions; Deflectometry; Filtered back projection; Four-step phase-shifting; Phase retrieval; Reconstruction algorithms; Scalar diffraction theory; Tomographic images; Image reconstruction",2-s2.0-85030696154
"Attia K.A.M., El-Abasawi N.M., El-Olemy A., Abdelazim A.H.","Application of different spectrophotometric methods for simultaneous determination of elbasvir and grazoprevir in pharmaceutical preparation",2018,"Spectrochimica Acta - Part A: Molecular and Biomolecular Spectroscopy",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027997445&doi=10.1016%2fj.saa.2017.08.026&partnerID=40&md5=8acf6361de2c26eb2483a38773c2d771","The first three UV spectrophotometric methods have been developed of simultaneous determination of two new FDA approved drugs namely; elbasvir and grazoprevir in their combined pharmaceutical dosage form. These methods include simultaneous equation, partial least squares with and without variable selection procedure (genetic algorithm). For simultaneous equation method, the absorbance values at 369 (λmax of elbasvir) and 253 nm (λmax of grazoprevir) have been selected for the formation of two simultaneous equations required for the mathematical processing and quantitative analysis of the studied drugs. Alternatively, the partial least squares with and without variable selection procedure (genetic algorithm) have been applied in the spectra analysis because the synchronous inclusion of many unreal wavelengths rather than by using a single or dual wavelength which greatly increases the precision and predictive ability of the methods. Successfully assay of the drugs in their pharmaceutical formulation has been done by the proposed methods. Statistically comparative analysis for the obtained results with the manufacturing methods has been performed. It is noteworthy to mention that there was no significant difference between the proposed methods and the manufacturing one with respect to the validation parameters. © 2017","Elbasvir; Grazoprevir; Simultaneous analysis; Zepatier","Drug dosage; Drug products; Genetic algorithms; Manufacture; Spectrophotometers; Spectrophotometry; Elbasvir; Grazoprevir; Pharmaceutical dosage forms; Pharmaceutical formulation; Pharmaceutical preparations; Simultaneous analysis; Simultaneous determinations; Zepatier; Least squares approximations",2-s2.0-85027997445
"Franco S.R., Gaspar F.J., Villela Pinto M.A., Rodrigo C.","Multigrid method based on a space-time approach with standard coarsening for parabolic problems",2018,"Applied Mathematics and Computation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029350055&doi=10.1016%2fj.amc.2017.08.043&partnerID=40&md5=ebb1916a0815dfbf8754670adf6b8074","In this work, a space-time multigrid method which uses standard coarsening in both temporal and spatial domains and combines the use of different smoothers is proposed for the solution of the heat equation in one and two space dimensions. In particular, an adaptive smoothing strategy, based on the degree of anisotropy of the discrete operator on each grid-level, is the basis of the proposed multigrid algorithm. Local Fourier analysis is used for the selection of the crucial parameter defining such an adaptive smoothing approach. Central differences are used to discretize the spatial derivatives and both implicit Euler and Crank–Nicolson schemes are considered for approximating the time derivative. For the solution of the second-order scheme, we apply a double discretization approach within the space-time multigrid method. The good performance of the method is illustrated through several numerical experiments. © 2017 Elsevier Inc.","Double discretization; Local Fourier analysis; Parabolic partial differential equations; Space-time multigrid","Fourier analysis; Partial differential equations; Degree of anisotropy; Discretizations; Multi-grid; Multi-grid algorithms; Numerical experiments; Parabolic partial differential equations; Second-order scheme; Temporal and spatial; Numerical methods",2-s2.0-85029350055
"Wang Y., Yan M., Zhu Q., Wang W.Y., Wu Y., Hui X., Otis R., Shang S.-L., Liu Z.-K., Chen L.-Q.","Computation of entropies and phase equilibria in refractory V-Nb-Mo-Ta-W high-entropy alloys",2018,"Acta Materialia",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031736042&doi=10.1016%2fj.actamat.2017.10.017&partnerID=40&md5=72c9a16467dd1307fdf2bcc29548fbf5","We have applied the first-principles phonon method to the refractory V-Nb-Mo-Ta-W high-entropy alloys (HEAs) to predict the major phase separations in the temperature-compositional space and hence the associated entropy changes within the systems, taking into account vibrational, electronic, and configurational contributions to the total entropy. The first-principles calculations covered 178 phases ranging from pure elements, the ordered B2, B32, B23, B22, hR8, hR7, tI6, C15, and D03 binary phases, two ordered MoNbTaW quaternary phases, and the partially disordered and completely disordered bcc phases. By sorting their relative phase stabilities with the Dantzig's simplex minimization algorithm, the possibilities of phase separation for the refractory quaternary and quinary HEAs were thermodynamically found in the temperature range of 500–907 K. © 2017","DFT; Entropy; High entropy alloy; Phase equilibria; Phonon","Calculations; Entropy; Molybdenum alloys; Niobium alloys; Phase separation; Phonons; Refractory alloys; Refractory materials; Stainless steel; Tantalum alloys; Tungsten alloys; Vanadium alloys; Entropy changes; First principles; First-principles calculation; High entropy alloys; Minimization algorithms; Pure elements; Quaternary phasis; Temperature range; Phase equilibria",2-s2.0-85031736042
"Memmolo V., Monaco E., Boffa N.D., Maio L., Ricci F.","Guided wave propagation and scattering for structural health monitoring of stiffened composites",2018,"Composite Structures",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031722083&doi=10.1016%2fj.compstruct.2017.09.067&partnerID=40&md5=ffec967e2b91c551ad333f15991d86a0","Impact induced damages in stiffened composite structures are usually settled with constrained design criteria and recurring maintenance tasks, that affect weight savings potentialities of composite materials as well as operative costs. To overcome those penalties due to hidden damages, this paper deals with detection, localization and size assessment of stringers disbondings with monitoring techniques by permanently attached piezoelectric transducers (PZT) capable to excite and sense guided ultrasonic waves. A composite stiffened plate typically designed for wingbox structures is investigated to test a novel detection technique capable to predict arrival time of guided waves scattered from stringers detecting, as a consequence, any possible change in a specific scattering area. Theoretical aspects are investigated to correctly exploit the technique leading to a geometrical reduction which returns the optimal configuration of sensors. Several measurements are carried out to validate the hypothesis and the approach effectiveness. A promising result in agreement with state-of-the-art ultrasonic nondestructive testing is thus obtained and discussed. Furthermore it is shown that processing Lamb wave reflections signals is possible to improve the localization accuracy respect to a general purpose reconstruction algorithm while making use of fewer number of sensors possible. © 2017 Elsevier Ltd","Aerospace structures; Guided waves scattering; Impact detection; Stiffener disbonding; Structural health monitoring (SHM)","Damage detection; Guided electromagnetic wave propagation; Nondestructive examination; Stringers; Surface waves; Ultrasonic applications; Ultrasonic testing; Ultrasonic waves; Wave propagation; Aerospace structure; Impact detection; Piezoelectric transducers (PZT); Reconstruction algorithms; Stiffened composite structure; Stiffener disbonding; Structural health monitoring (SHM); Ultrasonic non-destructive testing; Structural health monitoring",2-s2.0-85031722083
"He T., Liu L., Makeev A.","Uncertainty analysis in composite material properties characterization using digital image correlation and finite element model updating",2018,"Composite Structures",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030870273&doi=10.1016%2fj.compstruct.2017.10.009&partnerID=40&md5=e5fab5a9b1e48e35604233dd3009bdbf","This work presents an uncertainty analysis on composite material constitutive parameters, which are extracted using digital image correlation (DIC) and finite-element-model-updating (FEMU). The uncertainty is induced by the measurement system noise in the DIC technique and the approximation error in the displacements and strains smoothing algorithm. The covariance matrix of the extracted material constitutive parameters has been given explicitly. Six material constitutive parameters were identified from a customized short-shear experiment simultaneously using an estimated optimal reconstruction mesh size as an illustration. Sensitivity of measurement noise and reconstruction parameter on extracted material properties has been investigated. The effects of region of interest (ROI) and DIC image number on uncertainties of extracted material properties have been addressed. It is suggested that there exist an appropriate ROI and the number of images, from which reliable material parameters can be identified, but much more data used in identification process always lead to smaller standard deviation and COV. It is observed that the material constants used to characterize the in-plane shear stress-strain behavior show strong robustness to the measurement noise. However, the identified longitudinal Young's modulus is more sensitive to the measurement noise. Another key finding is that the reconstruction parameter in the global finite-element based approximation approach is critical for reliable material properties identification. Its value has to stay close to optimum for guaranteeing reliable identification of material properties. © 2017 Elsevier Ltd","Digital image correlation; Finite-element-model-updating; Global finite-element based approximation; Reconstruction parameter; Uncertainty","Approximation algorithms; Characterization; Composite materials; Covariance matrix; Elastic moduli; Extraction; Image analysis; Image processing; Image segmentation; Parameter estimation; Shear stress; Spurious signal noise; Strain; Strain measurement; Uncertainty analysis; Digital image correlations; Finite-element model updating; Global finite-element based approximation; Reconstruction parameters; Uncertainty; Finite element method",2-s2.0-85030870273
"Souli S., Lachiri Z.","Audio sounds classification using scattering features and support vectors machines for medical surveillance",2018,"Applied Acoustics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031769967&doi=10.1016%2fj.apacoust.2017.08.002&partnerID=40&md5=87def892883b6137eb215b76719b0938","This paper proposes a new approach to recognize environmental sounds for audio surveillance and security applications. The sounds are extremely versatile, including sounds generated in domestic, business, and outdoor environments. Since this variability is hard to model, investigations concentrate mostly on specific classes of sounds. Among those, the system that is able to recognize indoor environmental sounds may be of great importance for surveillance and security applications. These functionalities can also be used in portable teleassistive devices to inform disabled and elderly persons affected in their hearing capabilities about specific environmental sounds (door bells, alarm signals, etc.). We propose to apply an environmental sounds classification method, based on scattering transform and the principal component analysis (PCA). Our method integrates ability of PCA to de-correlate the coefficients by extracting a linear relationship with what of scatter transform analysis to derive feature vectors used for environmental sounds classification. The performance evaluation shows the superiority of this novel sound recognition method. The support vector machines method based on Gaussian kernel is used to classify the datasets due to its capability to deal with high-dimensional data. Our SVM−based multiclass classification approach seems well suited for real-world recognition tasks. Experimental results have revealed the good performance of the proposed system and the classification accuracy is up to 92.22%. © 2017 Elsevier Ltd","Audio sounds; Classification; MFCCs; Scattering transform; SVM multiclass","Audio acoustics; Audition; Clustering algorithms; Disabled persons; Mathematical transformations; Monitoring; Principal component analysis; Support vector machines; Classification accuracy; Classification methods; High dimensional data; MFCCs; Multi-class classification; Scattering transforms; Support vectors machine; SVM multiclass; Classification (of information)",2-s2.0-85031769967
"de Souza R.M.V., Pereira T.A.S., Godoy M., de Arruda A.S.","Long-range interactions in magnetic bilayer above the critical temperature",2018,"Physica B: Condensed Matter",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032681249&doi=10.1016%2fj.physb.2017.10.092&partnerID=40&md5=a594fd011aab27c34952215519ea885f","In this paper we have studied the stabilization of the long-range order in (z;x)-plane of two isotropic Heisenberg ferromagnetic monolayers coupled by a short-range exchange interaction (J⊥), by a long range dipole-dipole interactions and a magnetic field. We have applied a magnetic field along of the z-direction to study the thermodynamic properties above the critical temperature. The dispersion relation ω and the magnetization are given as function of dipolar anisotropy parameter defined as Ed=(gμ)2S/a3J∥ and for other Hamiltonian parameters, and they are calculated by the double-time Zubarev-Tyablikov Green's functions in the random-phase approximation (RPA). The results show that the system is unstable for values of Ed≥0.012 with external magnetic field ranging between H/J∥=0 and 10−3. The instability appears for Ed larger then Ed c=0.0158 with H/J∥=10−5, Ed c=0.02885 with H/J∥=10−4, and Ed c=0.115 with H/J∥=10−3, i.e., a small magnetic field is sufficient to maintain the magnetic order in a greater range of the dipolar interaction. © 2017 Elsevier B.V.","Green's functions; Long-range interaction; Magnetic bilayer","Approximation algorithms; Green's function; Magnetic fields; Magnetism; Temperature; Dipole dipole interactions; External magnetic field; Ferromagnetic monolayers; Hamiltonian parameters; Long range interactions; Magnetic bilayer; Random phase approximations; Short-range exchange interaction; Hamiltonians",2-s2.0-85032681249
"Sousa R., Cruzeiro A.B., Guerra M.","Barrier option pricing under the 2-hypergeometric stochastic volatility model",2018,"Journal of Computational and Applied Mathematics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027497676&doi=10.1016%2fj.cam.2017.06.034&partnerID=40&md5=0bb2da32118ad7353892ea2adc161910","We investigate the pricing of financial options under the 2-hypergeometric stochastic volatility model. This is an analytically tractable model that reproduces the volatility smile and skew effects observed in empirical market data. Using a regular perturbation method from asymptotic analysis of partial differential equations, we derive an explicit and easily computable approximate formula for the pricing of barrier options under the 2-hypergeometric stochastic volatility model. The asymptotic convergence of the method is proved under appropriate regularity conditions, and a multi-stage method for improving the quality of the approximation is discussed. Numerical examples are also provided. © 2017 Elsevier B.V.","Asymptotic analysis; Finance; Option pricing theory; Regular perturbation method; Stochastic volatility","Approximation algorithms; Asymptotic analysis; Costs; Economic analysis; Economics; Finance; Financial markets; Perturbation techniques; Stochastic systems; Approximate formulas; Asymptotic convergence; Multi-stage methods; Option Pricing Theory; Regular perturbations; Regularity condition; Stochastic volatility; Stochastic Volatility Model; Stochastic models",2-s2.0-85027497676
"Tan J.P.L.","An algorithm for engineering regime shifts in one-dimensional dynamical systems",2018,"Physica A: Statistical Mechanics and its Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029007912&doi=10.1016%2fj.physa.2017.08.140&partnerID=40&md5=8fdfce592efd870436c9412a744649e4","Regime shifts are discontinuous transitions between stable attractors hosting a system. They can occur as a result of a loss of stability in an attractor as a bifurcation is approached. In this work, we consider one-dimensional dynamical systems where attractors are stable equilibrium points. Relying on critical slowing down signals related to the stability of an equilibrium point, we present an algorithm for engineering regime shifts such that a system may escape an undesirable attractor into a desirable one. We test the algorithm on synthetic data from a one-dimensional dynamical system with a multitude of stable equilibrium points and also on a model of the population dynamics of spruce budworms in a forest. The algorithm and other ideas discussed here contribute to an important part of the literature on exercising greater control over the sometimes unpredictable nature of nonlinear systems. © 2017 Elsevier B.V.","Discontinuous phase transitions; Early warning signals; Regime shifts","Population statistics; Critical slowing down; Discontinuous transition; Early warning; Equilibrium point; Loss of stability; Regime shift; Stable attractors; Stable equilibrium points; Dynamical systems",2-s2.0-85029007912
"Michiels T., Adriaenssens S.","Form-finding algorithm for masonry arches subjected to in-plane earthquake loading",2018,"Computers and Structures",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032389750&doi=10.1016%2fj.compstruc.2017.10.001&partnerID=40&md5=41ab4784966974650e55b67a5cf804b3","This paper presents the first form finding method for masonry arches subjected to self-weight and in-plane horizontal loading due to earthquakes. New material-efficient arch shapes are obtained by considering both horizontal and gravitational acceleration in the form finding process. By interpreting the obtained forms, insights into the influence of form on the earthquake resistance of the arches are presented. The form finding algorithm relies on two simplified, first-order equilibrium methods: thrust line analysis and kinematic limit state analysis, which present respectively a lower- and upper-bound approach to the analytic problem of arch stability under gravity and horizontal loading. Through a methodological application of a series of geometric manipulations of the thrust line, shapes are obtained that can resist the design acceleration by guaranteeing a compression-only load path. Forms are obtained for horizontal accelerations of 0.15, 0.3 and 0.45g, as well as for arches of different rise-to-span ratios (1/2, 1/4 and 1/8). The obtained shapes require up to 65% less material than circular arches with constant thickness that are designed to withstand the same horizontal acceleration and self-weight, regardless of acceleration magnitude. The findings of this research will thus allow more material-efficient design of masonry arches in seismic areas. © 2017 Elsevier Ltd","Earthquake; Form finding; Masonry; Masonry arches; Seismic design","Acceleration; Arch bridges; Arches; Earthquake engineering; Geophysics; Masonry bridges; Masonry construction; Masonry materials; Seismic design; Seismology; Slope stability; Acceleration magnitude; Form finding; Geometric manipulation; Gravitational accelerations; Horizontal acceleration; Lower and upper bounds; Masonry; Masonry arches; Earthquakes",2-s2.0-85032389750
"Wu S.-F., Lin Y.-T., Chang W.-J., Chang C.-W., Lin C.","A computational algorithm for the evaluation on the lifetime performance index of products with Rayleigh distribution under progressive type I interval censoring",2018,"Journal of Computational and Applied Mathematics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028329704&doi=10.1016%2fj.cam.2017.07.004&partnerID=40&md5=51a82e059feea329ad0d1aa244527570","It is a very important topic these days to assessing the lifetime performance of products in manufacturing or service industries. Lifetime performance indices CL is used to measure the larger-the-better type quality characteristics to evaluate the process performance for the improvement of quality and productivity. The lifetimes of products are assumed to have Rayleigh distribution. The maximum likelihood estimator is used to estimate the lifetime performance index based on the progressive type I interval censored sample. The asymptotic distribution of this estimator is also developed. We use this estimator to build the new hypothesis testing algorithmic procedure with respect to a lower specification limit. Finally, two practical examples are given to illustrate the use of this testing algorithmic procedure to determine whether the process is capable. © 2017 Elsevier B.V.","Censored sample; Maximum likelihood estimator; Process capability indices; Rayleigh distribution; Testing algorithmic procedure","Maximum likelihood; Maximum likelihood estimation; Statistical tests; Algorithmic procedure; Censored samples; Maximum likelihood estimator; Process capability indices; Rayleigh distributions; Quality control",2-s2.0-85028329704
"Masselot P., Chebana F., Bélanger D., St-Hilaire A., Abdous B., Gosselin P., Ouarda T.B.M.J.","EMD-regression for modelling multi-scale relationships, and application to weather-related cardiovascular mortality",2018,"Science of the Total Environment",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028774225&doi=10.1016%2fj.scitotenv.2017.08.276&partnerID=40&md5=f616f58b84786d49e7a37b5daf9e8798","In a number of environmental studies, relationships between nat4ural processes are often assessed through regression analyses, using time series data. Such data are often multi-scale and non-stationary, leading to a poor accuracy of the resulting regression models and therefore to results with moderate reliability. To deal with this issue, the present paper introduces the EMD-regression methodology consisting in applying the empirical mode decomposition (EMD) algorithm on data series and then using the resulting components in regression models. The proposed methodology presents a number of advantages. First, it accounts of the issues of non-stationarity associated to the data series. Second, this approach acts as a scan for the relationship between a response variable and the predictors at different time scales, providing new insights about this relationship. To illustrate the proposed methodology it is applied to study the relationship between weather and cardiovascular mortality in Montreal, Canada. The results shed new knowledge concerning the studied relationship. For instance, they show that the humidity can cause excess mortality at the monthly time scale, which is a scale not visible in classical models. A comparison is also conducted with state of the art methods which are the generalized additive models and distributed lag models, both widely used in weather-related health studies. The comparison shows that EMD-regression achieves better prediction performances and provides more details than classical models concerning the relationship. © 2017 Elsevier B.V.","Cardiovascular mortality; Empirical mode decomposition (EMD); Environmental epidemiology; Lasso; Regression; Weather-related health","Signal processing; Time series analysis; Cardiovascular mortality; Empirical Mode Decomposition; Environmental epidemiology; Lasso; Regression; Regression analysis; algorithm; cardiovascular disease; epidemiology; mortality; numerical model; regression analysis; Article; Canada; cardiovascular disease; cardiovascular mortality; climate change; controlled study; empirical mode decomposition algorithm; empirical mode decomposition regression; greenhouse effect; human; humidity; lasso regression; methodology; priority journal; regression analysis; summer; temperature; weather; winter; Canada; Montreal; Quebec [Canada]",2-s2.0-85028774225
"Combettes P.L., Müller C.L.","Perspective functions: Proximal calculus and applications in high-dimensional statistics",2018,"Journal of Mathematical Analysis and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009247820&doi=10.1016%2fj.jmaa.2016.12.021&partnerID=40&md5=4b7ad9493e0df1305e1454a0809df3a2","Perspective functions arise explicitly or implicitly in various forms in applied mathematics and in statistical data analysis. To date, no systematic strategy is available to solve the associated, typically nonsmooth, optimization problems. In this paper, we fill this gap by showing that proximal methods provide an efficient framework to model and solve problems involving perspective functions. We study the construction of the proximity operator of a perspective function under general assumptions and present important instances in which the proximity operator can be computed explicitly or via straightforward numerical operations. These results constitute central building blocks in the design of proximal optimization algorithms. We showcase the versatility of the framework by designing novel proximal algorithms for state-of-the-art regression and variable selection schemes in high-dimensional statistics. © 2016 The Authors","Convex function; Perspective function; Proximal algorithm; Proximity operator; Statistics",,2-s2.0-85009247820
"Jin-xi L., Ding-fu Z., Sheng Y., Yuan-yuan Z., Luo-zhi Z., Dong-ming H., Xin Z.","Modified image fusion technique to remove defocus noise in optical scanning holography",2018,"Optics Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029814552&doi=10.1016%2fj.optcom.2017.08.057&partnerID=40&md5=33a1ba2918cce0f482231b7539d1e9ba","In sectional image reconstruction based on optical scanning holography (OSH) system, tomographic images are always contaminated by defocus noise. Though lots of methods have been proposed to solve this problem, some unsatisfactory results remain. In this article, a modified image fusion method is presented based on wavelet transform and connected component algorithms to deal with the defects in a random-phase OSH system where different sectional images usually have a relative displacement, rotation and loss. The method can fully utilize redundant information and affine transformation to repair the defects, and the defocus noise can be removed well. The final sectional images are more visible. © 2017 Elsevier B.V.","Affine transformation; Defocus noise; Image fusion; Optical scanning holography","Defects; Electron holography; Holography; Image reconstruction; Scanning; Tomography; Wavelet transforms; Affine transformations; Connected component algorithm; Defocus; Image fusion methods; Image fusion techniques; Random-phase; Relative displacement; Tomographic images; Image fusion",2-s2.0-85029814552
"Xu Y., Wang Y., Han H., Liu J., Ji Y., Jin W., Xu X.","Fast phase retrieval with four-quadrant analysis in phase-shifting interferometry with blind phase shifts",2018,"Optics Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029724984&doi=10.1016%2fj.optcom.2017.09.004&partnerID=40&md5=950c7393f828274c2cfc96aed0a83207","Phase-shifting interferometry (PSI) is one of the most effective techniques in optical measurement, in which phase retrieval with high efficiency is an important procedure. In this paper, a simple non-iterative method is proposed to extract the generalized phase shift with the four-quadrant analysis in three-frame PSI. In this method, the possible value of the phase shift is firstly worked out with the inner product algorithm, and then a criterion is put forward to accurately determine its principal value within the range [0,2π], based on the change relationship of the interference wave vector in four quadrants. Thus, this method provides a possible method to solve the uncertainty of phase shift existing in some common algorithms. Subsequently, the phase can be retrieved easily without any other measurements. Both simulation and experimental results have fully proved the feasibility and high accuracy of the method. Moreover, it works well on open- and closed-fringed patterns. © 2017 Elsevier B.V.","Inner product algorithm; Interference wave vector; Phase retrieval; Phase shift extraction; Quadrant analysis","Interferometry; Optical data processing; Inner product; Interference waves; Phase retrieval; Phase shift extraction; Quadrant analysis; Iterative methods",2-s2.0-85029724984
"Sobhani A., Milev M.","A numerical method for pricing discrete double barrier option by Legendre multiwavelet",2018,"Journal of Computational and Applied Mathematics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028338468&doi=10.1016%2fj.cam.2017.07.033&partnerID=40&md5=d9ca872c9a0135637967bc0b7102fb8e","In this Article, a fast numerical algorithm for pricing discrete double barrier option is presented. According to Black–Scholes model, the price of option in each monitoring date can be evaluated by a recursive formula upon the heat equation solution. These recursive solutions are approximated by using Legendre multiwavelets as orthonormal basis functions and expressed in operational matrix form. The most important feature of this method is that its CPU time is nearly invariant when monitoring dates increase. Besides, the rate of convergence of presented algorithm was obtained. The numerical results verify the validity and efficiency of the numerical method. © 2017 Elsevier B.V.","Black–Scholes model; Double and single barrier options; Legendre multiwavelet; Option pricing","Costs; Economics; Electronic trading; Double and single barrier options; Double-barrier options; Fast numerical algorithm; Multiwavelet; Operational matrices; Option pricing; Orthonormal basis functions; Recursive solutions; Numerical methods",2-s2.0-85028338468
"Zhang Q., Yang Y., Zhong K., Liu J., Wu X., Yao Y.","Joint polarization tracking and channel equalization based on radius-directed linear Kalman filter",2018,"Optics Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029598989&doi=10.1016%2fj.optcom.2017.08.036&partnerID=40&md5=df59b41122952946005692e7defae268","We propose a joint polarization tracking and channel equalization scheme based on radius-directed linear Kalman filter (RD-LKF) by introducing the butterfly finite-impulse-response (FIR) filter in our previously proposed RD-LKF method. Along with the fast polarization tracking, it can also simultaneously compensate the inter-symbol interference (ISI) effects including residual chromatic dispersion and polarization mode dispersion. Compared with the conventional radius-directed equalizer (RDE) algorithm, it is demonstrated experimentally that three times faster convergence speed, one order of magnitude better tracking capability, and better BER performance is obtained in polarization division multiplexing 16 quadrature amplitude modulation system. Besides, the influences of the algorithm parameters on the convergence and the tracking performance are investigated by numerical simulation. © 2017 Elsevier B.V.","Channel equalization; Kalman filter; Polarization tracking","Bandpass filters; Chromatic dispersion; Dispersions; FIR filters; Impulse response; Kalman filters; Optical communication; Polarization; Polarization mode dispersion; Algorithm parameters; BER performance; Channel equalization; Faster convergence; Linear Kalman filters; Polarization division multiplexing; Tracking capability; Tracking performance; Equalizers",2-s2.0-85029598989
"Wang T., Yin L., Wang X.","A community detection method based on local similarity and degree clustering information",2018,"Physica A: Statistical Mechanics and its Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029586131&doi=10.1016%2fj.physa.2017.08.090&partnerID=40&md5=e56f1ce8778ba2dd88f084353e4523e9","Community detection is of great importance to understand the structures and functions of networks. In this paper, a novel algorithm is proposed based on local similarity and degree clustering information. Local similarity is employed to measure the similarity between nodes and their neighbors in order to form communities within which nodes are closely connected. Degree clustering information, a hybrid criterion combining local neighborhood ratio with degree ratio, make a large number of nodes with low degree to embrace a small amount of nodes with high degree. Furthermore, each node in small scale communities has the duty to try to connect the nodes with high degree to expand communities, and finally the optimal community structure can be obtained. Simulation results on real and artificial networks show that the proposed algorithm has the excellent performance in terms of accuracy. © 2017 Elsevier B.V.","Community structure; Complex networks; Degree clustering information; Local similarity","Complex networks; Population dynamics; Social sciences; Artificial networks; Clustering information; Community detection; Community structures; Local neighborhoods; Local similarity; Novel algorithm; Optimal community; Structural optimization",2-s2.0-85029586131
"Beretta E., Micheletti S., Perotto S., Santacesaria M.","Reconstruction of a piecewise constant conductivity on a polygonal partition via shape optimization in EIT",2018,"Journal of Computational Physics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032002973&doi=10.1016%2fj.jcp.2017.10.017&partnerID=40&md5=9f688cf5544db386d6a7a30e5fefb2bb","In this paper, we develop a shape optimization-based algorithm for the electrical impedance tomography (EIT) problem of determining a piecewise constant conductivity on a polygonal partition from boundary measurements. The key tool is to use a distributed shape derivative of a suitable cost functional with respect to movements of the partition. Numerical simulations showing the robustness and accuracy of the method are presented for simulated test cases in two dimensions. © 2017 Elsevier Inc.","Electrical impedance tomography; Neumann-to-Dirichlet map; Reconstruction algorithm; Regularization; Shape optimization",,2-s2.0-85032002973
"Menin O.H., Bauch C.T.","Solving the patient zero inverse problem by using generalized simulated annealing",2018,"Physica A: Statistical Mechanics and its Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029721506&doi=10.1016%2fj.physa.2017.08.077&partnerID=40&md5=efcc190d82bc91adbe8ddf6f83fb2b8a","Identifying patient zero – the initially infected source of a given outbreak – is an important step in epidemiological investigations of both existing and emerging infectious diseases. Here, the use of the Generalized Simulated Annealing algorithm (GSA) to solve the inverse problem of finding the source of an outbreak is studied. The classical disease natural histories susceptible–infected (SI), susceptible–infected–susceptible (SIS), susceptible–infected–recovered (SIR) and susceptible–infected–recovered–susceptible (SIRS) in a regular lattice are addressed. Both the position of patient zero and its time of infection are considered unknown. The algorithm performance with respect to the generalization parameter q̃v and the fraction ρ of infected nodes for whom infection was ascertained is assessed. Numerical experiments show the algorithm is able to retrieve the epidemic source with good accuracy, even when ρ is small, but present no evidence to support that GSA performs better than its classical version. Our results suggest that simulated annealing could be a helpful tool for identifying patient zero in an outbreak where not all cases can be ascertained. © 2017 Elsevier B.V.","Epidemic models; Index case; Infection disease; Stochastic optimization","Optimization; Simulated annealing; Stochastic models; Algorithm performance; Emerging infectious disease; Epidemic models; Generalized simulated annealing; Natural history; Numerical experiments; Regular lattice; Stochastic optimizations; Inverse problems",2-s2.0-85029721506
"Wang C., Tao Y.","Interval strong solutions of interval systems of max-plus linear equations",2018,"Linear Algebra and Its Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030769170&doi=10.1016%2fj.laa.2017.10.001&partnerID=40&md5=bda8f36f242f8c7f5e8c5361ee6e1eee","This paper considers the existence and uniqueness of interval strong solutions of interval systems of max-plus linear equations. A necessary and sufficient condition for the existence of interval strong solutions is presented. The proof of the existence of interval strong solutions is constructive and results in a formula for computing such solutions. A necessary and sufficient condition for the uniqueness of interval strong solutions is established by testing the unique solvability of a finite number of subsystems rather than all subsystems. On this basis, a polynomial algorithm is developed to verify the uniqueness of interval strong solutions. © 2017 Elsevier Inc.","Interval strong solution; Interval system; Max-plus linear equations; Polynomial algorithm; Strong solvability",,2-s2.0-85030769170
"Guo C., Zhang Z., Xue D., Li L., Wang R., Zhou X., Zhang F., Zhang X.","High-performance etching of multilevel phase-type Fresnel zone plates with large apertures",2018,"Optics Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029716006&doi=10.1016%2fj.optcom.2017.09.006&partnerID=40&md5=b7b0844d3f9f286f9cfc3ebae6ececa3","To ensure the etching depth uniformity of large-aperture Fresnel zone plates (FZPs) with controllable depths, a combination of a point source ion beam with a dwell-time algorithm has been proposed. According to the obtained distribution of the removal function, the latter can be used to optimize the etching time matrix by minimizing the root-mean-square error between the simulation results and the design value. Owing to the convolution operation in the utilized algorithm, the etching depth error is insensitive to the etching rate fluctuations of the ion beam, thereby reducing the requirement for the etching stability of the ion system. As a result, a 4-level FZP with a circular aperture of 300 mm was fabricated. The obtained results showed that the etching depth uniformity of the full aperture could be reduced to below 1%, which was sufficiently accurate for meeting the use requirements of FZPs. The proposed etching method may serve as an alternative way of etching high-precision diffractive optical elements with large apertures. © 2017 Elsevier B.V.","Diffractive optical elements; Dwell time algorithm; Etching depth uniformity; Fresnel zone plate; Ion beam etching","Density (optical); Diffractive optical elements; Ion beams; Ions; Mean square error; Plates (structural components); Circular aperture; Dwell time; Etching depth; Fresnel zone plate; Ion beam etching; Large aperture; Removal function; Root mean square errors; Etching",2-s2.0-85029716006
"Tarnopolski M.","Correlation between the Hurst exponent and the maximal Lyapunov exponent: Examining some low-dimensional conservative maps",2018,"Physica A: Statistical Mechanics and its Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029331348&doi=10.1016%2fj.physa.2017.08.159&partnerID=40&md5=227fefd76fc423aefa3576dcaad03a3b","The Chirikov standard map and the 2D Froeschlé map are investigated. A few thousand values of the Hurst exponent (HE) and the maximal Lyapunov exponent (mLE) are plotted in a mixed space of the nonlinear parameter versus the initial condition. Both characteristic exponents reveal remarkably similar structures in this space. A tight correlation between the HEs and mLEs is found, with the Spearman rank ρ=0.83 and ρ=0.75 for the Chirikov and 2D Froeschlé maps, respectively. Based on this relation, a machine learning (ML) procedure, using the nearest neighbor algorithm, is performed to reproduce the HE distribution based on the mLE distribution alone. A few thousand HE and mLE values from the mixed spaces were used for training, and then using 2−2.4×105 mLEs, the HEs were retrieved. The ML procedure allowed to reproduce the structure of the mixed spaces in great detail. © 2017 Elsevier B.V.","Chirikov standard map; Conservative systems; Hurst exponent; Machine learning; Maximal Lyapunov exponent","Artificial intelligence; Differential equations; Learning systems; Lyapunov functions; Characteristic exponents; Conservative systems; Hurst exponents; Initial conditions; Maximal Lyapunov exponent; Nearest neighbor algorithm; Non-linear parameters; Standard map; Lyapunov methods",2-s2.0-85029331348
"Ebner M., Chung K.K., Prados F., Cardoso M.J., Chard D.T., Vercauteren T., Ourselin S.","Volumetric reconstruction from printed films: Enabling 30 year longitudinal analysis in MR neuroimaging",2018,"NeuroImage",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032334363&doi=10.1016%2fj.neuroimage.2017.09.056&partnerID=40&md5=3961956fdb50d83c6fdf48540cb3c167","Hospitals often hold historical MR image data printed on films without being able to make it accessible to modern image processing techniques. Having the possibility to recover geometrically consistent, volumetric images from scans acquired decades ago will enable more comprehensive, longitudinal studies to understand disease progressions. In this paper, we propose a consistent framework to reconstruct a volumetric representation from printed films holding thick single-slice brain MR image acquisitions dating back to the 1980's. We introduce a flexible framework based on semi-automatic slice extraction, followed by automated slice-to-volume registration with inter-slice transformation regularisation and slice intensity correction. Our algorithm is robust against numerous detrimental effects being present in archaic films. A subsequent, isotropic total variation deconvolution technique revitalises the visual appearance of the obtained volumes. We assess the accuracy and perform the validation of our reconstruction framework on a uniquely long-term MRI dataset where a ground-truth is available. This method will be used to facilitate a robust longitudinal analysis spanning 30 years of MRI scans. © 2017 The Authors","Brain MRI; Historical MR film data; Longitudinal analysis; Regularized image registration; Total variation reconstruction","Article; automated slice to volume registration; automation; clinical evaluation; controlled study; digital imaging; human; image analysis; image processing; image reconstruction; inter slice transformation regularization; learning algorithm; longitudinal study; mathematical computing; measurement accuracy; neuroimaging; nuclear magnetic resonance imaging; priority journal; qualitative analysis; semi automatic slice extraction; signal noise ratio; slice intensity correction; validation process",2-s2.0-85032334363
"Arieli Y., Epshtein S., Harris A., Yaacubov I., Cohen Y.","Full field tomography using interference fringes casting of a non spatially-coherent extended spectrally modulated broadband light source",2018,"Optics Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029583975&doi=10.1016%2fj.optcom.2017.08.027&partnerID=40&md5=d2e1c1df90480e3590feb93355e71760","A method for full field tomographic measurements using a fully non spatially-coherent extended broadband light source and a common path interferometry is described. A layered object's is being tomographed by acquiring multiple images of the object while modulating the spectrum of the extended broadband light source. In order to overcome the non spatially-coherence of the light source, interference fringes are created by amplitude division interferometry at a focal plane of the illuminating optical system and are casted on the measured object. In addition, due to exploiting one of the object's layers as a reference layer for the interference the need for an auxiliary reference beam is avoided and inherent Full Field “en-face” common path interferometry measurements are obtained. Another advantage is that by using spectrally modulated broadband illumination and obviating the reference beam, the requirement that the object should be used as one of the interferometer arms as in common dual beam interferometry is also avoided. This enables to relay the spectrally modulated light to illuminate the measured object which is just being imaged using a simplified imaging system while modulating the light. However, since there is no reference arm, the tomography of the object is calculated by a complex iterative algorithm where some knowledge on the object's structure is required. © 2017 Elsevier B.V.","Full field tomography; Optical coherence tomography; “en face” tomography","Interferometry; Iterative methods; Light sources; Optical systems; Optical tomography; Broadband illumination; Broadband Light Sources; Interference fringe; Interferometry measurement; Iterative algorithm; Modulated light; Reference beams; Reference layer; Tomography",2-s2.0-85029583975
"Ye D., Sun L., Zou B., Zhang Q., Tan W., Che W.","Non-destructive prediction of protein content in wheat using NIRS",2018,"Spectrochimica Acta - Part A: Molecular and Biomolecular Spectroscopy",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027966973&doi=10.1016%2fj.saa.2017.08.055&partnerID=40&md5=a3bd816bab30a2ec4d84560d9a5d66d8","A steady and accurate model used for quality detection depends on precise data and appropriate analytical methods. In this study, the authors applied partial least square regression (PLSR) to construct a model based on the spectral data measured to predict the protein content in wheat, and proposed a new method, global search method, to select PLSR components. In order to select representative and universal samples for modeling, Monte Carlo cross validation (MCCV) was proposed as a tool to detect outliers, and identified 4 outlier samples. Additionally, improved simulated annealing (ISA) combined with PLSR was employed to select most effective variables from spectral data, the data's dimensionality reduced from 100 to 57, and the standard error of prediction (SEP) decreased from 0.0716 to 0.0565 for prediction set, as well as the correlation coefficients (R2) between the predicted and actual protein content of wheat increased from 0.9989 to 0.9994. In order to reduce the dimensionality of the data further, successive projections algorithm (SPA) was then used, the combination of these two methods was called ISA-SPA. The results indicated that calibration model built using ISA-SPA on 14 effective variables achieved the optimal performance for prediction of protein content in wheat comparing with other developed PLSR models (ISA or SPA) by comprehensively considering the accuracy, robustness, and complexity of models. The coefficient of determination increased to 0.9986 and the SEP decreased to 0.0528, respectively. © 2017 Elsevier B.V.","Improved simulated annealing; Monte Carlo cross validation; Outliers; Partial least square regression; PLSR components; Successive projections algorithm",,2-s2.0-85027966973
"Wang J., Chen Y., Chen F., Shi T., Wu G.","Wavelet-based coupling of leaf and canopy reflectance spectra to improve the estimation accuracy of foliar nitrogen concentration",2018,"Agricultural and Forest Meteorology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031768888&doi=10.1016%2fj.agrformet.2017.10.017&partnerID=40&md5=bddd431708f94057dd35d4d252aa56f3","The leaf or canopy reflectance spectra of vegetation have been widely employed in estimating foliar nitrogen (N) concentration; however, they alone may not actually reflect the spectral and detailed information at a sampling plot. In this study, the potential spectral details of Carex (C. cinerascens) at a plot scale were derived using discrete wavelet transform, in which a simple operation of addition was employed to combine the reconstructed leaf and canopy reflectance at the fourth decomposition level (named “leaf-canopy d4 reflectance”). Partial least squares regression (PLSR), successive projections algorithm-based multiple linear regression (SPA-MLR) and random forest regression (RFR) models with leaf, canopy and leaf-canopy d4 reflectance were established and validated for foliar N estimation, respectively. The results showed that the PLSR (R2 CV = 0.718, determination coefficient of cross-validation; R2 Val = 0.743, determination coefficient of independent validation; RPD = 1.91, residual prediction deviation), SPA-MLR (R2 CV = 0.709, R2 Val = 0.747, RPD = 1.97) and RFR (R2 CV = 0.714, R2 Val = 0.783, RPD = 2.16) models with leaf-canopy d4 reflectance outperformed their corresponding models with leaf or canopy reflectance. We conclude that the wavelet-based coupling of leaf and canopy reflectance spectra has great potential in the accurate estimation of foliar N concentration. This proposed strategy helps to understand the spectral details of vegetation at a plot scale, providing the potential for improving the plot-based estimation of plant nutrients in grassland, precision agriculture or forestry. © 2017","Canopy reflectance; Leaf reflectance; Nitrogen concentration; Random forest regression; Wavelet transform","accuracy assessment; algorithm; canopy reflectance; concentration (composition); fertilizer application; grassland; least squares method; nitrogen; precision agriculture; regression analysis; Carex",2-s2.0-85031768888
"Meng L., Wang C., Yao X.","Non-convex shape effects on the dense random packing properties of assembled rods",2018,"Physica A: Statistical Mechanics and its Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028505938&doi=10.1016%2fj.physa.2017.08.026&partnerID=40&md5=220d064e14091d78ba53338ff1eb6a1d","The packing of rod-like particles, which is common in physical and mathematical studies, has arisen in a variety of industrial applications. Elongation effect on the packing properties of rod-like particle has been well investigated. Besides that, rod-like particles can be easily deformed into a large amount of non-convex shapes by simply bending or assembling several particles, in which effects of non-convex deformations should also be concerned. In this work, the packing behaviors of particulate systems composed of various non-convex deformations of rod-like particles are numerically simulated via the analytical model and the relaxation algorithm. The packing configurations are further optimized using the Monte Carlo method to eliminate the local ordered structures. 8 shapes of non-convex particles including 2-dimensional and 3-dimensional particles are employed in the packing systems. Independent of aspect ratio, the dense random packing densities of identical assembled rods are up to 20% higher than those of spherocylinders and are less dependent from the specific particle shape. However, the coordination numbers of various non-convex particle packings are quite different. With a parameter of convex ratio defined, a packing composed of more non-convex particles will have a higher coordination number. This indicates that for more non-convex particle packings, there are more constraints and entanglements among neighboring particles, resulting in a more stable configuration. The nearest-neighbor contact to a centered particle in 3DX-shaped particle packings is quite different from those of other shapes, which can be identified from the location of the first peak in the radial distribution function. It is also the cause to the distinct disparities of estimated excluded volumes of non-convex particles simulated in this work. © 2017","Non-convex particle; Packing density; Random packing; Shape effect","Aspect ratio; Deformation; Distribution functions; Monte Carlo methods; Coordination number; Packing configuration; Packing density; Radial distribution functions; Random packing; Relaxation algorithm; Shape effect; Stable Configuration; Packing",2-s2.0-85028505938
"Kanat K., Sofyalıoğlu M.","Some approximation results for Stancu type Lupaş–Schurer operators based on (p, q)-integers",2018,"Applied Mathematics and Computation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029630243&doi=10.1016%2fj.amc.2017.08.046&partnerID=40&md5=20bf55f2a6350c88b4b1dd83eec6907c","In the present paper, we introduce the Stancu type generalisation of Lupaş–Schurer operators based on (p, q)-integers. We are concerned with the basic convergence of the constructed operators based on Korovkin's type approximation theorem. Further, we obtain the rate of convergence for the new operators in terms of the modulus of continuity, with the help of functions of Lipschitz class and Peetre's K-functionals. Then, we present three significant numerical mathematical algorithms. Finally, in order to confirm our theoretical results we obtain error estimation and illustrate the convergence of the (p, q)-Lupaş–Schurer–Stancu operators to certain functions by using MATLAB. © 2017 Elsevier Inc.","(p, q)-integers; Functions of Lipschitz class; Korovkin type approximation theorem; Lupaş operators; Modulus of continuity; Peetre's K-functionals","Computational methods; Mathematical techniques; (p, q)-integers; Functionals; Korovkin type approximation theorem; Lipschitz; Modulus of continuity; Approximation theory",2-s2.0-85029630243
"Zhang X., Zhang X., Xu M., Zhang H., Jiang X.","Phase unwrapping in digital holography based on non-subsampled contourlet transform",2018,"Optics Communications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030868275&doi=10.1016%2fj.optcom.2017.09.057&partnerID=40&md5=87c3a786eed6ee07b9a32f81be9f1ac4","In the digital holographic measurement of complex surfaces, phase unwrapping is a critical step for accurate reconstruction. The phases of the complex amplitudes calculated from interferometric holograms are disturbed by speckle noise, thus reliable unwrapping results are difficult to be obtained. Most of existing unwrapping algorithms implement denoising operations first to obtain noise-free phases and then conduct phase unwrapping pixel by pixel. This approach is sensitive to spikes and prone to unreliable results in practice. In this paper, a robust unwrapping algorithm based on the non-subsampled contourlet transform (NSCT) is developed. The multiscale and directional decomposition of NSCT enhances the boundary between adjacent phase levels and henceforth the influence of local noise can be eliminated in the transform domain. The wrapped phase map is segmented into several regions corresponding to different phase levels. Finally, an unwrapped phase map is obtained by elevating the phases of a whole segment instead of individual pixels to avoid unwrapping errors caused by local spikes. This algorithm is suitable for dealing with complex and noisy wavefronts. Its universality and superiority in the digital holographic interferometry have been demonstrated by both numerical analysis and practical experiments. © 2017 Elsevier B.V.","Contourlet; Digital holography; Interferometry; Phase unwrapping; Speckle","Holograms; Holography; Image enhancement; Interferometry; Pixels; Speckle; Contourlets; Digital holographic interferometry; Digital holography; Directional decomposition; Holographic measurement; Non subsampled contourlet transform (NSCT); Non-sub-sampled contourlet transforms; Phase unwrapping; Holographic interferometry",2-s2.0-85030868275
"Kremer G.M., Kunova O.V., Kustova E.V., Oblapenko G.P.","The influence of vibrational state-resolved transport coefficients on the wave propagation in diatomic gases",2018,"Physica A: Statistical Mechanics and its Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028332180&doi=10.1016%2fj.physa.2017.08.019&partnerID=40&md5=44ed58bf71f75728be5b9fa5e2a8d14b","A detailed kinetic-theory model for the vibrationally state-resolved transport coefficients is developed taking into account the dependence of the collision cross section on the size of vibrationally excited molecule. Algorithms for the calculation of shear and bulk viscosity, thermal conductivity, thermal diffusion and diffusion coefficients for vibrational states are proposed. The transport coefficients are evaluated for single-component diatomic gases N2, O2, NO, H2, Cl2 in the wide range of temperature, and the effects of molecular diameters and the number of accounted states are discussed. The developed model is applied to study wave propagation in diatomic gases. For the case of initial Boltzmann distribution, the influence of vibrational excitation on the phase velocity and attenuation coefficient is found to be weak. We expect more significant effect in the case of initial thermal non-equilibrium, for instance in gases with optically pumped selected vibrational states. © 2017 Elsevier B.V.",,"Boltzmann equation; Excited states; Kinetic theory; Viscosity; Wave propagation; Attenuation coefficient; Boltzmann distribution; Collision cross sections; Molecular diameter; Thermal non-equilibrium; Transport coefficient; Vibrational excitation; Vibrationally excited; Thermal conductivity",2-s2.0-85028332180
"He S., Banerjee S.","Multicavity formations and complexity modulation in a hyperchaotic discrete system",2018,"Physica A: Statistical Mechanics and its Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028770095&doi=10.1016%2fj.physa.2017.08.007&partnerID=40&md5=6f3acefbad9a66349918d3f307efe730","This paper introduces a novel and unified approach for controlling the directions and number of cavities of a two dimensional Sine ICMIC modulation map (2D-SIMM). Two controllers are added to the system for arranging the cavity fluctuations and translating the cavities respectively. Both the controllers can effectively redesign the dynamics of reproducing cavities in different directions with grid representations. The dynamics of the proposed controlled model are investigated with bifurcation, Lyapunov and FuzzyEn algorithms under various cavity formations in different directions. A relationship is established for the complexity of the phase space with the directional control and various arrangements of the sinusoidal cavities. The proposed model is overall hyperchaotic with the high complexity in the whole parameter plane. The proposed scheme is effective for a dynamical model to reproduce the self phase structure in various arrangements for the optimization and modulation of complexity. © 2017 Elsevier B.V.","Complexity; Directional control; Hyperchaotic; Multicavity chaotic map","Chaotic systems; Modulation; Phase space methods; Phase structure; Cavity formation; Chaotic map; Complexity; Controlled model; Directional control; Discrete systems; Hyperchaotic; Unified approach; Controllers",2-s2.0-85028770095
"Ben Abdessalem A., Dervilis N., Wagg D., Worden K.","Model selection and parameter estimation in structural dynamics using approximate Bayesian computation",2018,"Mechanical Systems and Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026883296&doi=10.1016%2fj.ymssp.2017.06.017&partnerID=40&md5=7b3674369fb08fea7e78802e5c57d6f7","This paper will introduce the use of the approximate Bayesian computation (ABC) algorithm for model selection and parameter estimation in structural dynamics. ABC is a likelihood-free method typically used when the likelihood function is either intractable or cannot be approached in a closed form. To circumvent the evaluation of the likelihood function, simulation from a forward model is at the core of the ABC algorithm. The algorithm offers the possibility to use different metrics and summary statistics representative of the data to carry out Bayesian inference. The efficacy of the algorithm in structural dynamics is demonstrated through three different illustrative examples of nonlinear system identification: cubic and cubic-quintic models, the Bouc-Wen model and the Duffing oscillator. The obtained results suggest that ABC is a promising alternative to deal with model selection and parameter estimation issues, specifically for systems with complex behaviours. © 2017 The Author(s)","Approximate Bayesian computation; Model selection; Nonlinearity; Parameter estimation; Sequential Monte Carlo","Bayesian networks; Dynamics; Inference engines; Monte Carlo methods; Structural dynamics; Approximate Bayesian; Bayesian inference; Duffing oscillator; Likelihood functions; Model Selection; Nonlinearity; Sequential Monte Carlo; Summary statistic; Parameter estimation",2-s2.0-85026883296
"Zhang Y., Jia Y.","2D automatic body-fitted structured mesh generation using advancing extraction method",2018,"Journal of Computational Physics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032208879&doi=10.1016%2fj.jcp.2017.10.018&partnerID=40&md5=5b0c59da569b2ae62eae029886a3df5b","This paper presents an automatic mesh generation algorithm for body-fitted structured meshes in Computational Fluids Dynamics (CFD) analysis using the Advancing Extraction Method (AEM). The method is applicable to two-dimensional domains with complex geometries, which have the hierarchical tree-like topography with extrusion-like structures (i.e., branches or tributaries) and intrusion-like structures (i.e., peninsula or dikes). With the AEM, the hierarchical levels of sub-domains can be identified, and the block boundary of each sub-domain in convex polygon shape in each level can be extracted in an advancing scheme. In this paper, several examples were used to illustrate the effectiveness and applicability of the proposed algorithm for automatic structured mesh generation, and the implementation of the method. © 2017 Elsevier Inc.","Advancing extraction; Automatic mesh generation; Delaunay triangulation; Structured mesh",,2-s2.0-85032208879
"Barrau A., El Badaoui M.","About the cumulants of periodic signals",2018,"Mechanical Systems and Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026862021&doi=10.1016%2fj.ymssp.2017.06.019&partnerID=40&md5=be8c1923039267b7504eaff16eb23b0a","This note studies cumulants of time series. These functions originating from the probability theory being commonly used as features of deterministic signals, their classical properties are examined in this modified framework. We show additivity of cumulants, ensured in the case of independent random variables, requires here a different hypothesis. Practical applications are proposed, in particular an analysis of the failure of the JADE algorithm to separate some specific periodic signals. © 2017 Elsevier Ltd","Health monitoring; JADE; Kurtosis; Source separation; Statistical independence","Probability; Silicate minerals; Deterministic signals; Health monitoring; Independent random variables; JADE; Kurtosis; Periodic signal; Probability theory; Statistical independence; Source separation",2-s2.0-85026862021
"Cerasa A., Lofaro D., Cavedini P., Martino I., Bruni A., Sarica A., Mauro D., Merante G., Rossomanno I., Rizzuto M., Palmacci A., Aquino B., De Fazio P., Perna G.R., Vanni E., Olivadese G., Conforti D., Arabia G., Quattrone A.","Personality biomarkers of pathological gambling: A machine learning study",2018,"Journal of Neuroscience Methods",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032707333&doi=10.1016%2fj.jneumeth.2017.10.023&partnerID=40&md5=aaac4c1668ae6a45a28b54f2ca11ebca","Background The application of artificial intelligence to extract predictors of Gambling disorder (GD) is a new field of study. A plethora of studies have suggested that maladaptive personality dispositions may serve as risk factors for GD. New method Here, we used Classification and Regression Trees algorithm to identify multivariate predictive patterns of personality profiles that could identify GD patients from healthy controls at an individual level. Forty psychiatric patients, recruited from specialized gambling clinics, without any additional comorbidity and 160 matched healthy controls completed the Five-Factor model of personality as measured by the NEO-PI-R, which were used to build the classification model. Results Classification algorithm was able to discriminate individuals with GD from controls with an AUC of 77.3% (95% CI 0.65–0.88, p < 0.0001). A multidimensional construct of traits including sub-facets of openness, neuroticism and conscientiousness was employed by algorithm for classification detection. Comparison with existing method(s) To the best of our knowledge, this is the first study that combines behavioral data with machine learning approach useful to extract multidimensional features characterizing GD realm. Conclusion Our study provides a proof-of-concept demonstrating the potential of the proposed approach for GD diagnosis. The multivariate combination of personality facets characterizing individuals with GD can potentially be used to assess subjects’ vulnerability in clinical setting. © 2017 Elsevier B.V.","Conscientiousness; Five-factor model; Machine learning; Neuroticism; Openness; Pathological gambling; Personality profile",,2-s2.0-85032707333
"Abdelhamid T.","Simultaneous identification of the spatio-temporal dependent heat transfer coefficient and spatially dependent heat flux using an MCGM in a parabolic system",2018,"Journal of Computational and Applied Mathematics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027502585&doi=10.1016%2fj.cam.2017.06.031&partnerID=40&md5=281dd67d0cf58c0add008a3b6d289572","This paper aims to simultaneously identify the spatio-temporal dependent heat transfer coefficient γ(x,t) and the spatially dependent heat flux q(x) in a parabolic system. The simultaneous identification problem is formulated as a constrained minimization problem using the output least squares method with Tikhonov regularization. The differentiability of the solution and adjoint equations are investigated to obtain the gradient formulae and determine the step lengths, respectively. To illustrate the efficiency, accuracy, and robustness of the proposed algorithm, numerical results are investigated using the modified conjugate gradient method (MCGM). © 2017 Elsevier B.V.","Heat transfer coefficient and heat flux; MCGM; Numerical reconstruction; Simultaneous identification; Tikhonov regularization","Conjugate gradient method; Constrained optimization; Gradient methods; Heat transfer; Heat transfer coefficients; Least squares approximations; Numerical methods; Adjoint equations; Constrained minimization problem; Differentiability; Least squares methods; MCGM; Numerical reconstruction; Simultaneous identification; Tikhonov regularization; Heat flux",2-s2.0-85027502585
"Jiao Y., Wu J., Jiao L.","An image segmentation method based on network clustering model",2018,"Physica A: Statistical Mechanics and its Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029682529&doi=10.1016%2fj.physa.2017.08.118&partnerID=40&md5=e8b47e5940202ebde18f5f37016c146d","Network clustering phenomena are ubiquitous in nature and human society. In this paper, a method involving a network clustering model is proposed for mass segmentation in mammograms. First, the watershed transform is used to divide an image into regions, and features of the image are computed. Then a graph is constructed from the obtained regions and features. The network clustering model is applied to realize clustering of nodes in the graph. Compared with two classic methods, the algorithm based on the network clustering model performs more effectively in experiments. © 2017 Elsevier B.V.","Clustering phenomenon; Graph construction; Image segmentation; Network clustering model","Cluster analysis; Clustering phenomena; Graph construction; Human society; Mass segmentation; Network Clustering; Segmentation methods; Watershed transform; Image segmentation",2-s2.0-85029682529
"Srinivasan A., Muñoz-Estrada J., Bourgeois J.R., Nalwalk J.W., Pumiglia K.M., Sheen V.L., Ferland R.J.","BranchAnalysis2D/3D automates morphometry analyses of branching structures",2018,"Journal of Neuroscience Methods",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032580002&doi=10.1016%2fj.jneumeth.2017.10.017&partnerID=40&md5=4ca1e98e93e664cfa49246735d5d7036","Background Morphometric analyses of biological features have become increasingly common in recent years with such analyses being subject to a large degree of observer bias, variability, and time consumption. While commercial software packages exist to perform these analyses, they are expensive, require extensive user training, and are usually dependent on the observer tracing the morphology. New method To address these issues, we have developed a broadly applicable, no-cost ImageJ plugin we call ‘BranchAnalysis2D/3D’, to perform morphometric analyses of structures with branching morphologies, such as neuronal dendritic spines, vascular morphology, and primary cilia. Results Our BranchAnalysis2D/3D algorithm allows for rapid quantification of the length and thickness of branching morphologies, independent of user tracing, in both 2D and 3D data sets. Comparison with existing methods We validated the performance of BranchAnalysis2D/3D against pre-existing software packages using trained human observers and images from brain and retina. We found that the BranchAnalysis2D/3D algorithm outputs results similar to available software (i.e., Metamorph, AngioTool, Neurolucida), while allowing faster analysis times and unbiased quantification. Conclusions BranchAnalysis2D/3D allows inexperienced observers to output results like a trained observer but more efficiently, thereby increasing the consistency, speed, and reliability of morphometric analyses. © 2017 Elsevier B.V.","Branching morphology; Morphometry; Primary cilia; Spines; Vasculature",,2-s2.0-85032580002
"Uteshev A.Y., Goncharova M.V.","Point-to-ellipse and point-to-ellipsoid distance equation analysis",2018,"Journal of Computational and Applied Mathematics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027838433&doi=10.1016%2fj.cam.2017.07.021&partnerID=40&md5=0458e2d05b17247450a5dce2f5f2cced","For the problem of distance evaluation from a point X0 to an ellipse in R2 and to an ellipsoid in R3 given by algebraic equation G(X)=0, we investigate the properties of the distance equation, i.e. an algebraic equation whose zeros coincide with the critical values of the squared distance function. We detail the structure of this equation and an algorithm for finding the point in the quadric nearest to X0. We also find analytical formulas for distance approximations using the expansion of the zero of distance equation into power series ∑j=1 ∞ℓjGj(X0). Exact values for the approximation error bounds are obtained via construction of an analogue of the distance equations for the curve-to-curve distance problem. © 2017 Elsevier B.V.","Distance approximation; Distance to ellipse; Distance to ellipsoid; Projection of a point; Sampson's distance","Algebra; Error analysis; Distance approximation; Distance to ellipse; Distance to ellipsoid; Projection of a point; Sampson's distance; Geometry",2-s2.0-85027838433
"Azarnavid B., Parand K.","An iterative reproducing kernel method in Hilbert space for the multi-point boundary value problems",2018,"Journal of Computational and Applied Mathematics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027501596&doi=10.1016%2fj.cam.2017.07.015&partnerID=40&md5=afa1e8325f7acbc2b44af14b0a130a41","In this paper, an iterative method is proposed to solve the nonlinear Bitsadze–Samarskii boundary value problems with multi-point boundary conditions. The algorithm is based on the reproducing kernel Hilbert space method. We use an iterative scheme to overcome the nonlinearity of the problem. The convergence and error estimate of the iterative scheme are established. The reproducing kernel Hilbert space method is used to generate an approximation of the linearized problem. In fact, the reproducing kernel Hilbert space method is combined with an iterative scheme to approximate the solution and an error estimate of the approximate solution is derived. In order to show the efficiency and versatility of the proposed method, some numerical results are reported. The comparison of numerical results with the analytical solution and the best results reported in the literature confirms the good accuracy and applicability of the proposed method. © 2017 Elsevier B.V.","Convergence; Error estimate; Iterative reproducing kernel Hilbert space method; Multi-point boundary conditions","Boundary conditions; Boundary value problems; Errors; Hilbert spaces; Numerical methods; Vector spaces; Approximate solution; Convergence; Error estimates; Multi-point boundary conditions; Multipoint boundary value problems; Numerical results; Reproducing Kernel Hilbert spaces; Reproducing kernel methods; Iterative methods",2-s2.0-85027501596
"Luke D.R., Shefi R.","A globally linearly convergent method for pointwise quadratically supportable convex–concave saddle point problems",2018,"Journal of Mathematical Analysis and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019707504&doi=10.1016%2fj.jmaa.2017.02.068&partnerID=40&md5=5e392794be8a33ee875c0743b76f4614","We study the Proximal Alternating Predictor–Corrector (PAPC) algorithm introduced recently by Drori, Sabach and Teboulle [8] to solve nonsmooth structured convex–concave saddle point problems consisting of the sum of a smooth convex function, a finite collection of nonsmooth convex functions and bilinear terms. We introduce the notion of pointwise quadratic supportability, which is a relaxation of a standard strong convexity assumption and allows us to show that the primal sequence is R-linearly convergent to an optimal solution and the primal-dual sequence is globally Q-linearly convergent. We illustrate the proposed method on total variation denoising problems and on locally adaptive estimation in signal/image deconvolution and denoising with multiresolution statistical constraints. © 2017 Elsevier Inc.","Augmented Lagrangian; Linear convergence; Pointwise quadratic supportability; Primal-dual; Saddle point; Statistical multiscale analysis",,2-s2.0-85019707504
"Jacobsen K.A., Tien J.H.","A generalized inverse for graphs with absorption",2018,"Linear Algebra and Its Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030772005&doi=10.1016%2fj.laa.2017.09.029&partnerID=40&md5=dd590bc5a0a04ddfc9a40303123060d1","We consider weighted, directed graphs with a notion of absorption on the vertices, related to absorbing random walks on graphs. We define a generalized inverse of the graph Laplacian, called the absorption inverse, that reflects both the graph structure as well as the absorption rates on the vertices. Properties of this generalized inverse are presented, including a basic relationship between the absorption inverse and the group inverse of a related graph, a forest theorem for interpreting the entries of the absorption inverse, as well as relationships between the absorption inverse and the fundamental matrix of the absorbing random walk. Applications of the absorption inverse for describing the structure of graphs with absorption are given, including a directed distance metric, spectral partitioning algorithm, and centrality measure. © 2017 Elsevier Inc.","Graph Laplacian; Group inverse; Networks; Random walk","Directed graphs; Graphic methods; Inverse problems; Laplace transforms; Networks (circuits); Random processes; Centrality measures; Fundamental matrix; Generalized inverse; Graph Laplacian; Group inverse; Random Walk; Spectral partitioning; Structure of graph; Graph theory",2-s2.0-85030772005
"Lu G., Liu J., Yan P.","Graph-based structural change detection for rotating machinery monitoring",2018,"Mechanical Systems and Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026853815&doi=10.1016%2fj.ymssp.2017.06.003&partnerID=40&md5=1370caa7f23e7c9ac07901c596f0bc9c","Detection of structural changes is critically important in operational monitoring of a rotating machine. This paper presents a novel framework for this purpose, where a graph model for data modeling is adopted to represent/capture statistical dynamics in machine operations. Meanwhile we develop a numerical method for computing temporal anomalies in the constructed graphs. The martingale-test method is employed for the change detection when making decisions on possible structural changes, where excellent performance is demonstrated outperforming exciting results such as the autoregressive-integrated-moving average (ARIMA) model. Comprehensive experimental results indicate good potentials of the proposed algorithm in various engineering applications. This work is an extension of a recent result (Lu et al., 2017). © 2017 Elsevier Ltd","Graph model; Machine monitoring; Martingale test; Structural change detection","Graph theory; Machinery; Numerical methods; Rotating machinery; Autoregressive integrated moving average models; Engineering applications; Graph model; Machine monitoring; Machinery monitoring; Operational monitoring; Statistical dynamics; Structural change detections; Graphic methods",2-s2.0-85026853815
"Xu J.-J., Shi W., Lai M.-C.","A level-set method for two-phase flows with soluble surfactant",2018,"Journal of Computational Physics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032215620&doi=10.1016%2fj.jcp.2017.10.019&partnerID=40&md5=e48f31534cf8274cd92bd0ee5ae6011e","A level-set method is presented for solving two-phase flows with soluble surfactant. The Navier–Stokes equations are solved along with the bulk surfactant and the interfacial surfactant equations. In particular, the convection–diffusion equation for the bulk surfactant on the irregular moving domain is solved by using a level-set based diffusive-domain method. A conservation law for the total surfactant mass is derived, and a re-scaling procedure for the surfactant concentrations is proposed to compensate for the surfactant mass loss due to numerical diffusion. The whole numerical algorithm is easy for implementation. Several numerical simulations in 2D and 3D show the effects of surfactant solubility on drop dynamics under shear flow. © 2017 Elsevier Inc.","Diffusive domain method; Level-set method; Multi-phase flow; Soluble surfactant; Surfactant mass conservation; Topological change",,2-s2.0-85032215620
"Dimarco G., Loubère R., Narski J., Rey T.","An efficient numerical method for solving the Boltzmann equation in multidimensions",2018,"Journal of Computational Physics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031715138&doi=10.1016%2fj.jcp.2017.10.010&partnerID=40&md5=fd6a8b7199bc615ee853841eb90cd9e5","In this paper we deal with the extension of the Fast Kinetic Scheme (FKS) (Dimarco and Loubère, 2013 [26]) originally constructed for solving the BGK equation, to the more challenging case of the Boltzmann equation. The scheme combines a robust and fast method for treating the transport part based on an innovative Lagrangian technique supplemented with conservative fast spectral schemes to treat the collisional operator by means of an operator splitting approach. This approach along with several implementation features related to the parallelization of the algorithm permits to construct an efficient simulation tool which is numerically tested against exact and reference solutions on classical problems arising in rarefied gas dynamic. We present results up to the 3D×3D case for unsteady flows for the Variable Hard Sphere model which may serve as benchmark for future comparisons between different numerical methods for solving the multidimensional Boltzmann equation. For this reason, we also provide for each problem studied details on the computational cost and memory consumption as well as comparisons with the BGK model or the limit model of compressible Euler equations. © 2017 Elsevier Inc.","3D/3D; Boltzmann equation; CUDA; GPU; Kinetic equations; MPI; OpenMP; Semi-Lagrangian schemes; Spectral schemes",,2-s2.0-85031715138
"Ge Z., Loiseau J.-C., Tammisola O., Brandt L.","An efficient mass-preserving interface-correction level set/ghost fluid method for droplet suspensions under depletion forces",2018,"Journal of Computational Physics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032258558&doi=10.1016%2fj.jcp.2017.10.046&partnerID=40&md5=acb289dc58656da167bf6f371bff389e","Aiming for the simulation of colloidal droplets in microfluidic devices, we present here a numerical method for two-fluid systems subject to surface tension and depletion forces among the suspended droplets. The algorithm is based on an efficient solver for the incompressible two-phase Navier–Stokes equations, and uses a mass-conserving level set method to capture the fluid interface. The four novel ingredients proposed here are, firstly, an interface-correction level set (ICLS) method; global mass conservation is achieved by performing an additional advection near the interface, with a correction velocity obtained by locally solving an algebraic equation, which is easy to implement in both 2D and 3D. Secondly, we report a second-order accurate geometric estimation of the curvature at the interface and, thirdly, the combination of the ghost fluid method with the fast pressure-correction approach enabling an accurate and fast computation even for large density contrasts. Finally, we derive a hydrodynamic model for the interaction forces induced by depletion of surfactant micelles and combine it with a multiple level set approach to study short-range interactions among droplets in the presence of attracting forces. © 2017 Elsevier Inc.","Colloidal droplet; Depletion force; Ghost fluid method; Level set method; Multiphase flow",,2-s2.0-85032258558
"Tanaka M., Yanagisawa D., Nishinari K.","Exclusive queueing model including the choice of service windows",2018,"Physica A: Statistical Mechanics and its Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029715652&doi=10.1016%2fj.physa.2017.08.096&partnerID=40&md5=25d7ae5e54845e532f1d5f2824dfc82f","In a queueing system involving multiple service windows, choice behavior is a significant concern. This paper incorporates the choice of service windows into a queueing model with a floor represented by discrete cells. We contrived a logit-based choice algorithm for agents considering the numbers of agents and the distances to all service windows. Simulations were conducted with various parameters of agent choice preference for these two elements and for different floor configurations, including the floor length and the number of service windows. We investigated the model from the viewpoint of transit times and entrance block rates. The influences of the parameters on these factors were surveyed in detail and we determined that there are optimum floor lengths that minimize the transit times. In addition, we observed that the transit times were determined almost entirely by the entrance block rates. The results of the presented model are relevant to understanding queueing systems including the choice of service windows and can be employed to optimize facility design and floor management. © 2017 Elsevier B.V.","Asymmetric simple exclusion process; Choice of service windows; Queueing model","Floors; Information dissemination; Queueing networks; Asymmetric simple exclusion process; Choice behaviors; Different floors; Facility designs; Floor management; Multiple services; Number of services; Queueing model; Queueing theory",2-s2.0-85029715652
"Yazdani S., Rust W.J.H., Wriggers P.","Delamination onset and growth in composite shells",2018,"Computers and Structures",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030454874&doi=10.1016%2fj.compstruc.2017.09.007&partnerID=40&md5=6edf34f48e56e0b2204f8823f949c076","In this paper an efficient numerical tool is proposed to investigate delamination type failure in multi-layered composite shells. In the current contribution the extended finite element method (XFEM), the mixed-mode cohesive zone model, the contact formulation, and the damage criterion are incorporated into a new algorithm to study the interfacial delamination initiation and growth with less computational effort. A flat-shell formulation is developed in the geometrically non-linear regime to study the response of shells in small strains and moderate rotations. In addition, the equivalent single layer theory (ESLT) is applied to simulate the multi-layered laminates. This formulation is enhanced through the XFEM topology to be able to model discontinuous domains and a mixed-mode bilinear cohesive formulation to track the delamination growth. In the current study, the simulation can be initiated in an intact laminate. Thus, unlike formulations in existing finite element models, incorporating cohesive zone model at all available interfaces is not necessary. The interlaminar stresses are calculated during post-processing and they are being used in the delamination onset criterion. As soon as the criterion is satisfied at a specific layer and location, the formulation of that corresponding element is locally changed to XFEM and the cohesive behaviour. Consequently, the possibility to track delamination growth is locally provided; and hence, the computational cost is reduced. © 2017 Elsevier Ltd","Cohesive; Delamination; Shell; XFEM","Computation theory; Delamination; Laminates; Shells (structures); Topology; Cohesive; Equivalent single layer theories; Extended finite element method; Interfacial delamination; Multi-layered composites; Multi-layered laminates; Shell; XFEM; Finite element method",2-s2.0-85030454874
"Chaoqi F., Ying W., Kun Z., Yangjun G.","Complex networks under dynamic repair model",2018,"Physica A: Statistical Mechanics and its Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028709401&doi=10.1016%2fj.physa.2017.08.071&partnerID=40&md5=3fa3c5862b269f7a247441b5fc66ba47","Invulnerability is not the only factor of importance when considering complex networks’ security. It is also critical to have an effective and reasonable repair strategy. Existing research on network repair is confined to the static model. The dynamic model makes better use of the redundant capacity of repaired nodes and repairs the damaged network more efficiently than the static model; however, the dynamic repair model is complex and polytropic. In this paper, we construct a dynamic repair model and systematically describe the energy-transfer relationships between nodes in the repair process of the failure network. Nodes are divided into three types, corresponding to three structures. We find that the strong coupling structure is responsible for secondary failure of the repaired nodes and propose an algorithm that can select the most suitable targets (nodes or links) to repair the failure network with minimal cost. Two types of repair strategies are identified, with different effects under the two energy-transfer rules. The research results enable a more flexible approach to network repair. © 2017 Elsevier B.V.","Coupling structures; Dynamic repair model; Energy transfer; Secondary failure","Energy transfer; Repair; Coupling structures; Different effects; Network repairs; Repair models; Repair process; Repair strategy; Research results; Strong coupling; Complex networks",2-s2.0-85028709401
"Sadri K., Amini A., Cheng C.","A new operational method to solve Abel's and generalized Abel's integral equations",2018,"Applied Mathematics and Computation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029479155&doi=10.1016%2fj.amc.2017.08.060&partnerID=40&md5=bc7455cfe91993d89a143d7d711a6094","Based on Jacobi polynomials, an operational method is proposed to solve the generalized Abel's integral equations (a class of singular integral equations). These equations appear in various fields of science such as physics, astrophysics, solid mechanics, scattering theory, spectroscopy, stereology, elasticity theory, and plasma physics. To solve the Abel's singular integral equations, a fast algorithm is used for simplifying the problem under study. The Laplace transform and Jacobi collocation methods are merged, and thus, a novel approach is presented. Some theorems are given and established to theoretically support the computational simplifications which reduce costs. Also, a new procedure for estimating the absolute error of the proposed method is introduced. In order to show the efficiency and accuracy of the proposed method some numerical results are provided. It is found that the proposed method has lesser computational size compared to other common methods, such as Adomian decomposition, Homotopy perturbation, Block-Pulse function, mid-point, trapezoidal quadrature, and product-integration. It is further found that the absolute errors are almost constant in the studied interval. © 2017 Elsevier Inc.","Abel's integral equation; Collocation method; Error estimation; Shifted Jacobi polynomials","Astrophysics; Computation theory; Error analysis; Errors; Laplace transforms; Numerical methods; Polynomials; Adomian decomposition; Block-pulse function; Collocation method; Elasticity theory; Jacobi polynomials; Operational methods; Product integration; Singular integral equations; Integral equations",2-s2.0-85029479155
"Xu X., Yang H., Neumann I.","A feature extraction method for deformation analysis of large-scale composite structures based on TLS measurement",2018,"Composite Structures",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031764765&doi=10.1016%2fj.compstruct.2017.09.087&partnerID=40&md5=3ab53a9d55a0baf947fffd2a9691eb66","How to obtain a three-dimensional (3D) model efficiently and extract the feature information of larger-scale composite structures, such as tunnels, accurately is a significant issue in the field of health monitoring. Therefore, an effective method based on TLS measurement is proposed and developed using surface-based non-destructive technology. In this paper, terrestrial laser scanning (TLS) technology is adopted to investigate the tunnel structure, focusing on the extraction of the characteristic section and central curve, which could be applied in deformation monitoring. Point cloud data from TLS measurement is processed in four steps: section extraction, section projection, calculation of central points and curve approximation. The innovation of this paper lies in the projection and iterative filtering of the ring data and rasterization of the point clouds for vertical and horizontal lines. The random sample consensus (RANSAC) algorithm is implemented to approximate the vertical and horizontal lines. The central curve, approximated from the central points, agrees with the general design model and the accuracy falls within the millimeter range. © 2017 Elsevier Ltd","Central line; Cross section; Curve approximation; Point cloud; Terrestrial laser scanning; Tunnel structure","Curve fitting; Deformation; Extraction; Iterative methods; Laser applications; Seebeck effect; Steel beams and girders; Structural health monitoring; Structure (composition); Surface analysis; Central line; Cross section; Curve approximation; Point cloud; Terrestrial laser scanning; Tunnel structures; Surveying instruments",2-s2.0-85031764765
"Diaz I.J.L., Branco N.S.","Monte Carlo study of an anisotropic Ising multilayer with antiferromagnetic interlayer couplings",2018,"Physica A: Statistical Mechanics and its Applications",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029393080&doi=10.1016%2fj.physa.2017.09.005&partnerID=40&md5=10d41b27882e20074483e7bbcfebeac6","We present a Monte Carlo study of the magnetic properties of an Ising multilayer ferrimagnet. The system consists of two kinds of non-equivalent planes, one of which is site-diluted. All intralayer couplings are ferromagnetic. The different kinds of planes are stacked alternately and the interlayer couplings are antiferromagnetic. We perform the simulations using the Wolff algorithm and employ multiple histogram reweighting and finite-size scaling methods to analyze the data with special emphasis on the study of compensation phenomena. Compensation and critical temperatures of the system are obtained as functions of the Hamiltonian parameters and we present a detailed discussion about the contribution of each parameter to the presence or absence of the compensation effect. A comparison is presented between our results and those reported in the literature for the same model using the pair approximation. We also compare our results with those obtained through both the pair approximation and Monte Carlo simulations for the bilayer system. © 2017 Elsevier B.V.","Compensation temperature; Critical temperature; Ferrimagnetism; Ising model; Monte Carlo; Multilayer","Antiferromagnetism; Couplings; Ferrimagnetism; Hamiltonians; Intelligent systems; Ising model; Multilayers; Temperature; Antiferromagnetic interlayer couplings; Compensation effects; Compensation temperature; Critical temperatures; Finite-size scaling method; Hamiltonian parameters; Interlayer coupling; Intralayer couplings; Monte Carlo methods",2-s2.0-85029393080
"Liu H., Wang W., Xiang C., Han L., Nie H.","A de-noising method using the improved wavelet threshold function based on noise variance estimation",2018,"Mechanical Systems and Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026871900&doi=10.1016%2fj.ymssp.2017.05.034&partnerID=40&md5=8328bb0155a86d1090632ebe512baba7","The precise and efficient noise variance estimation is very important for the processing of all kinds of signals while using the wavelet transform to analyze signals and extract signal features. In view of the problem that the accuracy of traditional noise variance estimation is greatly affected by the fluctuation of noise values, this study puts forward the strategy of using the two-state Gaussian mixture model to classify the high-frequency wavelet coefficients in the minimum scale, which takes both the efficiency and accuracy into account. According to the noise variance estimation, a novel improved wavelet threshold function is proposed by combining the advantages of hard and soft threshold functions, and on the basis of the noise variance estimation algorithm and the improved wavelet threshold function, the research puts forth a novel wavelet threshold de-noising method. The method is tested and validated using random signals and bench test data of an electro-mechanical transmission system. The test results indicate that the wavelet threshold de-noising method based on the noise variance estimation shows preferable performance in processing the testing signals of the electro-mechanical transmission system: it can effectively eliminate the interference of transient signals including voltage, current, and oil pressure and maintain the dynamic characteristics of the signals favorably. © 2017 Elsevier Ltd","Electro-mechanical transmission; Gaussian mixture model; Noise variance; Wavelet transform","Frequency estimation; Gaussian distribution; Gaussian noise (electronic); Signal processing; Spurious signal noise; Transmissions; Dynamic characteristics; Electro-mechanical; Gaussian Mixture Model; Noise variance; Noise variance estimation; Soft threshold function; Two state gaussian mixture models; Wavelet threshold de-noising; Wavelet transforms",2-s2.0-85026871900
"Clavero C., Vigo-Aguiar J.","Numerical approximation of 2D time dependent singularly perturbed convection–diffusion problems with attractive or repulsive turning points",2018,"Applied Mathematics and Computation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029829861&doi=10.1016%2fj.amc.2017.08.059&partnerID=40&md5=0065bdf007f745554c4107bb8073b3e3","In this work, we are interested in approximating the solution of 2D parabolic singularly perturbed problems of convection–diffusion type. The convective term of the differential equation, associated to the initial and boundary value problem, is such that each one of its components has an interior simple turning point, which can be of attractive or repulsive type. We describe a numerical method to discretize the continuous problem, which combines the fractional implicit Euler method, defined on a uniform mesh, to discretize in time, and the classical upwind finite difference scheme, defined on a nonuniform mesh of Shishkin type, to discretize in space. The fully discrete algorithm has a low computational cost. From a numerical point of view, we see that the method is efficient and uniformly convergent with respect to the diffusion parameter in both cases when the source term is a continuous function or it has a first kind discontinuity at the turning points. Some numerical results for different test problems are showed; from them, we deduce the good properties of the numerical method. © 2017 Elsevier Inc.","2D parabolic convection–diffusion problems; Finite differences scheme; Fractional Euler method; Special meshes; Turning points; Uniform convergence","Boundary value problems; Differential equations; Diffusion; Finite difference method; Mesh generation; Perturbation techniques; Diffusion problems; Euler method; Finite differences scheme; Special meshes; Turning points; Uniform convergence; Numerical methods",2-s2.0-85029829861
"Behrens T., Schmidt K., MacMillan R.A., Viscarra Rossel R.A.","Multiscale contextual spatial modelling with the Gaussian scale space",2018,"Geoderma",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029507084&doi=10.1016%2fj.geoderma.2017.09.015&partnerID=40&md5=9ea97342437166b37605c541a6a6b3e7","We present a contextual spatial modelling (CSM) framework, as a methodology for multiscale, hierarchical mapping and analysis. The aim is to propose and evaluate a practical method that can account for the complex interactions of environmental covariates across multiple scales and their influence on soil formation. Here we derived common terrain attributes from multiscale versions of a DEM based on up-sampled octaves of the Gaussian pyramid. Because the CSM approach is based on a relatively small set of scales and terrain attributes it is efficient, and depending on the regression algorithm and the covariates used in the modelling, the results can be interpreted in terms of soil formation. Cross-validation coefficient of determination modelling (R2), for predictions of clay and silt increased from 0.38 and 0.16 when using the covariates derived at the original DEM resolution to 0.68 and 0.63, respectively, when using CSM. These results are similar to those achieved with the hyperscale covariates of ConMap and ConStat. As with these hyperscale covariates, the multiscale covariates derived from the Gaussian scale space in CSM capture the observed spatial dependencies and interactions of the landscape and soil. However, some advantages of CSM approach compared to ConMap and ConStat are i) a reduced set of scales that still manage to represent the entire extent of the range of scales, ii) a reduced set of attributes at each scale, iii) more efficient computation, and iv) better interpretability of the important covariates used in the modelling and thus of the factors that affect soil formation. © 2017","Contextual spatial modelling; Digital soil mapping; Gaussian pyramids; Geomorphic signature; Multiscale; Spatial dependency","Geomorphology; Image segmentation; Mapping; Soil surveys; Soils; Weathering; Digital soil mappings; Gaussian pyramids; Geomorphic signature; Multiscale; Spatial dependencies; Spatial modelling; Gaussian distribution; complexity; computer simulation; covariance analysis; digital elevation model; digital mapping; Gaussian method; model validation; regression analysis; spatial analysis",2-s2.0-85029507084
"Zhang S., Xu S., Zhang W., Yu D., Chen K.","A hybrid approach combining an extended BBO algorithm with an intuitionistic fuzzy entropy weight method for QoS-aware manufacturing service supply chain optimization",2018,"Neurocomputing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024371418&doi=10.1016%2fj.neucom.2017.07.011&partnerID=40&md5=c1e724650d26af0611e0ea5327c8a7e9","With the increasing complexity of manufacturing tasks, selecting an optimal manufacturing service supply chain has become an important challenge, especially in fuzzy manufacturing environments. In this study, we first propose a new fuzzy quality of service (QoS)-aware multi-objective mathematical model for evaluating the global QoS value of a manufacturing service supply chain including four basic composite structures. Then, we present a hybrid approach that combines the biogeography-based optimization (BBO) algorithm with the intuitionistic fuzzy entropy weight (IFEW) method, to effectively solve the manufacturing service supply chain optimization (MSSCO) problem. Furthermore, the IFEW method is adapted to obtain a more accurate preference weight for each QoS attribute, by further considering the degrees of influence of different decision makers. In addition, the BBO algorithm is extended to effectively obtain a manufacturing service supply chain (MSSC) with an optimal fuzzy QoS value by improving its standard migration and mutation operators, and introducing a new operator called the invasion operator. Finally, we perform three sets of simulation experiments to illustrate the practicality, effectiveness, and efficiency of our proposed method, based on comparisons with the standard BBO algorithm and two other population-based optimization algorithms, namely the genetic algorithm and differential evolution. © 2017","Biogeography-based optimization algorithm; Fuzzy QoS-aware; IFEW method; Manufacturing service supply chain","Ecology; Entropy; Evolutionary algorithms; Fuzzy sets; Genetic algorithms; Heuristic algorithms; Manufacture; Quality of service; Supply chains; Biogeography-based optimization algorithms; Biogeographybased optimizations (BBO); IFEW method; Intuitionistic fuzzy entropies; Manufacturing environments; Manufacturing service; Population-based optimization; QoS-aware; Optimization",2-s2.0-85024371418
"Jothi R., Mohanty S.K., Ojha A.","Fast approximate minimum spanning tree based clustering algorithm",2018,"Neurocomputing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026464964&doi=10.1016%2fj.neucom.2017.07.038&partnerID=40&md5=39cdc020911d33d3700554adc86ac19d","Minimum Spanning Tree (MST) based clustering algorithms have been employed successfully to detect clusters of heterogeneous nature. Given a dataset of n random points, most of the MST-based clustering algorithms first generate a complete graph G of the dataset and then construct MST from G. The first step of the algorithm is the major bottleneck which takes O(n2) time. This paper proposes an algorithm namely MST-based clustering on partition-based nearest neighbor graph for reducing the computational overhead. By using a centroid based nearest neighbor rule, the proposed algorithm first generates a sparse Local Neighborhood Graph (LNG) and then the approximate MST is constructed from LNG. We prove that both size and computational time to construct the graph (LNG) is O(n3/2), which is a O(n) factor improvement over the traditional algorithms. The approximate MST is constructed from LNG in O(n3/2lgn) time, which is asymptotically faster than O(n2). Experimental analysis on both synthetic and real datasets demonstrates that the computational time has been reduced significantly by maintaining the quality of clusters obtained from the approximate MST. © 2017 Elsevier B.V.","Clustering; Local neighborhood graph; Minimum spanning tree","Graph theory; Trees (mathematics); Clustering; Computational overheads; Computational time; Experimental analysis; Local neighborhoods; Minimum spanning trees; Nearest neighbor rule; Nearest neighbors; Clustering algorithms",2-s2.0-85026464964
"Liu Y., Yang D., Zhang C.","Relaxed conditions for convergence analysis of online back-propagation algorithm with L2 regularizer for Sigma-Pi-Sigma neural network",2018,"Neurocomputing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021712233&doi=10.1016%2fj.neucom.2017.06.057&partnerID=40&md5=4bc3ca6747787b60d539ad659c8789a7","The properties of a boundedness estimations are investigated during the training of online back-propagation method with L2 regularizer for Sigma-Pi-Sigma neural network. This brief presents a unified convergence analysis, exploiting theorems of White for the method of stochastic approximation. We apply the method of regularizer to derive estimation bounds for Sigma-Pi-Sigma network, and also give conditions for determinating convergence ensuring that the back-propagation estimator converges almost surely to a parameter value which locally minimizes the expected squared error loss. Besides, some weight boundedness estimations are derived through the squared regularizer, after that the boundedness is exploited to prove the convergence of the algorithm. A simulation is also given to verify the theoretical findings. © 2017 Elsevier B.V.","Boundedness; Convergence; L2 regularizer; Sigma-Pi-Sigma network","Backpropagation; Estimation; Stochastic systems; Boundedness; Convergence; Convergence analysis; Estimation bounds; Expected squared errors; Regularizer; Relaxed conditions; Stochastic approximations; Backpropagation algorithms",2-s2.0-85021712233
"Feng H.-M., Wong C.-C., Horng J.-H., Lai L.-Y.","Evolutional RBFNs image model describing-based segmentation system designs",2018,"Neurocomputing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026674912&doi=10.1016%2fj.neucom.2017.07.006&partnerID=40&md5=dfe5993f06eb7d938c834b4bbed02370","Knowledge discovered-based radial basis function neural networks (RBFNs) model can describe an appropriate behaviors of identified image patterns through the multiple and hybrid learning schemes. The image data extraction learning algorithm (IDELA) with dynamic recognitions to automatically match the appropriate feature with a suitable number of radial basis function (RBFs). This first step approaches their associated centers positions to extract initial prototypes. The approximated image model as a describer is automatically generated by the RBFPSO learning scheme, which is contained hybrid bacterial foraging particle swarm optimization (BFPSO) algorithm and recursive least-squares (RLS) iterations to deeply approach the image feature. Due to the limitations and possible local learning trap, K-means, differential evolution (DE) and particle swarm optimization (PSO) learning algorithms cannot obtain the most smaller Root-Mean-Square Error (RMSE) to achieve an appropriate image segmentation in all experiment cases. The constructed RBFNs image model is generated by the support of multiple image self-extraction feature machine (MISEFM), which combined IDELA and RBFPSO algorithms to develop the universal RBFNs image describers. Simulations compared with other K-means, PSO and DE learning methods, show the average great performance in several real image segmentation applications. The peak signal-to-noise ratio (PSNR) index is selected to evaluate the quality of the reconstructed images. Simulations show that the evolutional hybrid and multi-level RBFNs image model-based system is determined to simultaneously achieve both high performance indexes on accuracy (RMSE) and a high image quality description (PSNR) for matching the desired characters and behaviors of image patterns within a fewer RBFs functions. © 2017 Elsevier Ltd","Bacterial foraging particle swarm optimization; Image segmentation; RBFNs; Recursive least-squares","Evolutionary algorithms; Extraction; Functions; Image processing; Image quality; Learning algorithms; Mean square error; Optimization; Particle swarm optimization (PSO); Radial basis function networks; Signal to noise ratio; Swarm intelligence; Automatically generated; Bacterial foraging; Peak signal to noise ratio; Radial basis function neural networks; Radial basis functions; RBFNs; Recursive least square (RLS); Root mean square errors; Image segmentation",2-s2.0-85026674912
"Wang S.-H., Phillips P., Dong Z.-C., Zhang Y.-D.","Intelligent facial emotion recognition based on stationary wavelet entropy and Jaya algorithm",2018,"Neurocomputing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028296825&doi=10.1016%2fj.neucom.2017.08.015&partnerID=40&md5=a415423fe4cda648de7444154a0fe260","Aim Emotion recognition based on facial expression is an important field in affective computing. Current emotion recognition systems may suffer from two shortcomings: translation in facial image may deteriorate the recognition performance, and the classifier is not robust. Method To solve above two problems, our team proposed a novel intelligent emotion recognition system. Our method used stationary wavelet entropy to extract features, and employed a single hidden layer feedforward neural network as the classifier. To prevent the training of the classifier fall into local optimum points, we introduced the Jaya algorithm. Results The simulation results over a 20-subject 700-image dataset showed our algorithm reached an overall accuracy of 96.80 ± 0.14%. Conclusion This proposed approach performs better than five state-of-the-art approaches in terms of overall accuracy. Besides, the db4 wavelet performs the best among other whole db wavelet family. The 4-level wavelet decomposition is superior to other levels. In the future, we shall test other advanced features and training algorithms. © 2017","Affective computing; Emotion recognition; Facial expression; Feedforward neural network; Jaya algorithm; Optimal decomposition level; Optimal wavelet; Single hidden layer; Stationary wavelet entropy","Entropy; Feedforward neural networks; Network layers; Speech recognition; Wavelet decomposition; Affective Computing; Emotion recognition; Facial Expressions; Hidden layers; Optimal decomposition; Optimal wavelets; Stationary wavelet; Face recognition",2-s2.0-85028296825
"Nath A., Subbiah K.","The role of pertinently diversified and balanced training as well as testing data sets in achieving the true performance of classifiers in predicting the antifreeze proteins",2018,"Neurocomputing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023601684&doi=10.1016%2fj.neucom.2017.07.004&partnerID=40&md5=8966ea55d19a336cbd1cede784bf876f","Antifreeze proteins (AFPs) are those proteins, which inhibit the ice nucleation process and thereby enabling certain organisms to survive under sub-zero temperature habitats. AFPs are supposed to be evolved from different types of protein families to perform the unique function of antifreeze activity and turn out to be the classical example of convergent evolution. The common sequence similarity search methods have failed to predict putative AFPs due to poor sequence and structural similarity that exists among the different sub-types of AFP. The machine learning techniques are the viable alternative approaches to predict putative AFPs. In this paper, we have discussed about the criteria (like apposite feature selection, balanced data sets and complete learning) that are needed to be taken into account for successful application of machine learning methods and implemented these criteria by using a clustering procedure in order to achieve the true performance of the learning algorithms. Diversified and representative training and testing data sets are very crucial for perfect learning as well as true testing of machine learning based prediction methods for two reasons: first is that a training dataset that lacks definable subset of input patterns makes prediction of patterns belonging to this subset either difficult or unfeasible (thus resulting in incomplete learning) and secondly a testing data set that lacks definable subset of input patterns does not tell about whether this subset of patterns can be correctly predicted by the classifier or not (thus resulting in incomplete testing). Moreover, balanced training and testing data sets are equally important for achieving the true (robust) performance of classifiers because a well-balanced training set eliminates bias of the classifier toward particular class/sub-class due to over-representation or under-representation of input patterns belonging to those classes/sub-classes. We have used K-means clustering algorithm for creating the diversified and balanced training as well as testing data sets, to overcome the shortcoming of random splitting, which cannot guarantee representative training and testing sets. The current clustering based optimal splitting criteria proved to be better than random splitting for creating training and testing set in terms of superior generalization and robust evaluation. © 2017 Elsevier Ltd","Antifreeze proteins; Imbalance data set; Incomplete learning; K-means clustering; Physicochemical-n-grams; Representative training set","Artificial intelligence; Biology; Clustering algorithms; Education; Forecasting; Learning algorithms; Learning systems; Proteins; Set theory; Speech recognition; Statistical tests; Antifreeze protein; Imbalance datum; Incomplete learning; K-means clustering; N-grams; Training sets; Classification (of information)",2-s2.0-85023601684
"Li H., Trocan M.","Deep neural network based single pixel prediction for unified video coding",2018,"Neurocomputing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025836584&doi=10.1016%2fj.neucom.2017.07.037&partnerID=40&md5=3aca9a259944f0cfd0eb05cb9aeae2f1","Classical video prediction methods exploit directly and shallowly the intra-frame, inter-frame and multi-view similarities within the video sequences; the proposed video prediction methods indirectly and intensively transform the frame correlations into nonlinear mappings by using a general deep neural network (DNN) with single output node. Traditional DNN based video prediction algorithms wholly and coarsely forecast the next frame, but the proposed video prediction algorithms severally and precisely anticipate single pixel of future frame in order to achieve high prediction accuracy and low computation cost. First of all, general DNN based prediction algorithms for intra-frame coding, inter-frame coding and multi-view coding are presented respectively. Then, general DNN based prediction algorithm for unified video coding is raised, which relies on the preceding three prediction algorithms. It is evaluated by simulation experiments that the proposed methods hold better performance than state of the art High Efficiency Video Coding (HEVC) in peak signal to noise ratio (PSNR) and bit per pixel (BPP) in the situation of low bitrate transmission. It is also verified by experimental results that the proposed general DNN architecture possesses higher prediction accuracy and lower computation load than those of conventional DNN architectures. It is further testified by experimental results that the proposed methods are very suitable for multi-view videos with small correlations and big disparities. © 2017","Deep neural network; Inter-frame coding; Intra-frame coding; Multi-view coding; Unified video coding; Video prediction","Codes (symbols); Forecasting; Image coding; Mathematical transformations; Network architecture; Pixels; Signal to noise ratio; Video signal processing; High-efficiency video coding; Inter-frame coding; Intraframe coding; Multi-view coding; Peak signal to noise ratio; Prediction accuracy; Prediction algorithms; Video prediction; Deep neural networks",2-s2.0-85025836584
"Villarrubia G., De Paz J.F., Chamoso P., la Prieta F.D.","Artificial neural networks used in optimization problems",2018,"Neurocomputing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021401445&doi=10.1016%2fj.neucom.2017.04.075&partnerID=40&md5=b7f857ca7191d6ce0294cfbd41bc039d","Optimization problems often require the use of optimization methods that permit the minimization or maximization of certain objective functions. Occasionally, the problems that must be optimized are not linear or polynomial; they cannot be precisely resolved, and they must be approximated. In these cases, it is necessary to apply heuristics, which are able to resolve these kinds of problems. Some algorithms linearize the restrictions and objective functions at a specific point of the space by applying derivatives and partial derivatives for some cases, while in other cases evolutionary algorithms are used to approximate the solution. This work proposes the use of artificial neural networks to approximate the objective function in optimization problems to make it possible to apply other techniques to resolve the problem. The objective function is approximated by a non-linear regression that can be used to resolve an optimization problem. The derivate of the new objective function should be polynomial so that the solution of the optimization problem can be calculated. © 2017 Elsevier Ltd","Neural networks; Non-linear optimization; Optimization problems","Evolutionary algorithms; Neural networks; Nonlinear programming; Polynomials; Non-linear optimization; Non-linear regression; Objective functions; Optimization method; Optimization problems; Partial derivatives; Optimization",2-s2.0-85021401445
"Peng L., Cao X., Sun C., Cheng Y., Jin S.","Energy efficient jamming attack schedule against remote state estimation in wireless cyber-physical systems",2018,"Neurocomputing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028694288&doi=10.1016%2fj.neucom.2017.07.036&partnerID=40&md5=c4bace63b4e900b515690b6415dbc00c","Recently, there has been a growing volume of literature on the security aspect of wireless cyber-physical systems (CPS). Remote state estimation through wireless channels is a representative application of wireless CPS. However, such a system is exposed to various cyber security threats, such as replay attacks, jamming attacks and bad data injection attacks. In this paper, we focus on the wireless jamming attack and examine, from the standpoint of the attacker, the problem of optimal attack schedule that causes the largest performance degradation of the remote state estimation system, subject to attacker's energy constraint. Unlike some existing studies, we consider estimating multiple systems where sensors transmitting data to the remote estimator through multiple independent wireless channels. Due to the attacker's radio constraint, we assume that it can only launch jamming attack at one of the channels at any time. We start with the two-system case and formulate the energy efficient jamming attack schedule problem as a nonlinear program. The optimal energy efficient schedule is theoretically derived and is shown dependent on the wireless channels’ properties, energy budget of the attacker and dynamics of the systems to be estimated. Then, we extend the results to multi-system cases, and propose both an optimal schedule algorithm and an efficient algorithm of much lower complexity. Finally, we validate the theoretical results by numerical simulations. © 2017","Cyber-physical systems; Energy efficient; Optimal attack schedule; Remote state estimation; Wireless channels","Budget control; Cyber Physical System; Embedded systems; Estimation; Jamming; Network security; Nonlinear programming; Scheduling algorithms; State estimation; Cyber-physical systems (CPS); Energy constraint; Energy efficient; Nonlinear programs; Performance degradation; Remote state estimations; Schedule problems; Wireless channel; Energy efficiency",2-s2.0-85028694288
"Chen B., Li J., Ma B., Wei G.","Discriminative dictionary pair learning based on differentiable support vector function for visual recognition",2018,"Neurocomputing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023647207&doi=10.1016%2fj.neucom.2017.07.003&partnerID=40&md5=b1bc85585d5f480c0fb5809985e5fb5c","Sparse representation and discriminative dictionary learning (DDL) algorithm has become a widely-used model in visual recognition systems, and various discrimination terms are introduced into the DDL models to enhance the discriminative ability and the recognition rate. Recently, an algorithm named dictionary pair learning (DPL) was proposed which jointly learned a synthesis dictionary and an analysis dictionary to promote the recognition performance. In this paper, a novel dictionary learning model is proposed which introduces a differentiable support vector discriminative term into the original DPL model. In the dictionary learning stage, the proposed model can jointly train a synthesis dictionary, an analysis dictionary and a support vector discriminative term. In the classification stage, the class label is decided by the joint effect of the reconstruction residual, the projective discrimination term and the support vector function. Experimental results on various image recognition benchmarks such as face recognition, scene categorization and object classification are presented to demonstrate the effectiveness of the proposed method. © 2017 Elsevier B.V.","Dictionary pair learning; Discriminative dictionary learning; Image recognition; Support vector function","Face recognition; Image recognition; Learning algorithms; Vectors; Dictionary learning; Discriminative ability; Discriminative dictionaries; Object classification; Scene categorization; Sparse representation; Support vector; Visual recognition; Education",2-s2.0-85023647207
"Kobayashi M.","Multistate vector product hopfield neural networks",2018,"Neurocomputing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024391426&doi=10.1016%2fj.neucom.2017.07.013&partnerID=40&md5=5a929ed3a7d033a863fd8eaa9e88fd84","Several high-dimensional models of Hopfield neural networks, such as complex-valued and quaternionic Hopfield neural networks, have been proposed. However, it has been hard to construct three-dimensional models of Hopfield neural networks. A split type of vector product Hopfield neural network (VPHNN) was proposed as a special case of ordinary Hopfield neural networks. It is easier to construct split types of Hopfield neural networks than multistate types of ones, because the split types can be often regarded as special cases of ordinary ones. In the present work, we extend the split VPHNN to the multistate VPHNN. We define its energy and a primitive learning algorithm, the Hebbian learning rule. In addition, we prove the stability of multistate VPHNNs. Furthermore, we investigated the fundamentals of multistate VPHNNs, such as the storage capacity and noise tolerance, by computer simulations. © 2017 Elsevier B.V.","High-dimensional neural networks; Hopfield neural networks; Multistate neuron; Vector product","Complex networks; Education; Learning algorithms; Complex-valued; Hebbian learning; High-dimensional; High-dimensional models; Multi-state; Noise tolerance; Storage capacity; Three-dimensional model; Hopfield neural networks",2-s2.0-85024391426
"Song Y., Hu J., Chen D., Liu Y., Alsaadi F.E., Sun G.","A resilience approach to state estimation for discrete neural networks subject to multiple missing measurements and mixed time-delays",2018,"Neurocomputing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021929048&doi=10.1016%2fj.neucom.2017.06.065&partnerID=40&md5=4278aed4084e3196a67b7421d7c3fc83","In this paper, the resilient state estimation problem is investigated for a class of discrete recurrent neural networks (RNNs) subject to mixed time-delays, missing measurements and stochastic disturbance. The mixed time-delays consist of randomly occurring time-delay and distributed sensor delays, where a random variable obeying the Bernoulli distribution is employed to characterize the phenomenon of randomly occurring time-delay. In addition, the phenomena of the multiple missing measurements are characterized by introducing a set of mutually independent random variables, which reflect that each sensor could have individual missing probability. Meanwhile, the additive variation of the estimator gain is considered to reflect the possible parameter deviations when implementing the state estimation algorithm. Our main purpose is to design a resilient state estimator such that, in the presence of multiple missing measurements, randomly occurring time-delay and distributed sensor delays, the estimation error dynamics is exponentially stable in the mean square. A sufficient condition is established to guarantee the existence of the resilient state estimator and the explicit expression of the desired estimator gain is given based on the solutions to some matrix inequalities. Finally, we use a numerical example to verify the validity of the presented resilient state estimation method. © 2017 Elsevier B.V.","Distributed sensor delays; multiple missing measurements; Neural networks; Randomly occurring time-delay; Resilient state estimation","Estimation; Neural networks; Numerical methods; Random variables; State estimation; Stochastic systems; Time delay; Bernoulli distributions; Discrete neural networks; Distributed sensor; Multiple missing measurements; Recurrent neural network (RNNs); State estimation algorithms; State estimation methods; Stochastic disturbances; Recurrent neural networks",2-s2.0-85021929048
"Gong L., Mu T., Wang M., Liu H., Goulermas J.Y.","Evolutionary nonnegative matrix factorization with adaptive control of cluster quality",2018,"Neurocomputing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023605112&doi=10.1016%2fj.neucom.2017.06.067&partnerID=40&md5=a5780051fa34b6996331d3524eaa3c22","Nonnegative matrix factorization (NMF) approximates a given data matrix using linear combinations of a small number of nonnegative basis vectors, weighted by nonnegative encoding coefficients. This enables the exploration of the cluster structure of the data through the examination of the values of the encoding coefficients and therefore, NMF is often used as a popular tool for clustering analysis. However, its encoding coefficients do not always reveal a satisfactory cluster structure. To improve its effectiveness, a novel evolutionary strategy is proposed here to drive the iterative updating scheme of NMF and generate encoding coefficients of higher quality that are capable of offering more accurate and sharper cluster structures. The proposed hybridization procedure that relies on multiple initializations reinforces the robustness of the solution. Additionally, three evolving rules are designed to simultaneously boost the cluster quality and the reconstruction error during the iterative updates. Any clustering performance measure, such as either an internal one relying on the data itself or an external based on the availability of ground truth information, can be employed to drive the evolving procedure. The effectiveness of the proposed method is demonstrated via careful experimental designs and thorough comparative analyses using multiple benchmark datasets. © 2017","Clustering; Evolutionary computation; Initialization; Nonnegative matrix factorization","Digital storage; Encoding (symbols); Evolutionary algorithms; Factorization; Iterative methods; Quality control; Clustering; Clustering analysis; Comparative analysis; Evolutionary strategies; Initialization; Linear combinations; Nonnegative matrix factorization; Reconstruction error; Matrix algebra",2-s2.0-85023605112
"Alyazidi N.M., Mahmoud M.S., Abouheaf M.I.","Adaptive critics based cooperative control scheme for islanded Microgrids",2018,"Neurocomputing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025700873&doi=10.1016%2fj.neucom.2017.07.027&partnerID=40&md5=46aac77abfa9d2151ca7c443d506119b","This paper introduces novel cooperative control scheme based on adaptive critics for islanded Microgrids in the presence of disturbances. The interactions between the distributed generation sources are governed by a communication graph. Synchronization ideas are used to couple the dynamics of the distributed generation sources. A utility function is selected to reflect the objectives of the optimization problem. An online adaptive learning technique based on particle filtering is developed to estimate the dynamics of the distributed generation sources. Once the separation principle is held, the control input of every generation source and the estimator can be designed independently. The online adaptive learning technique uses incomplete knowledge about the dynamics of the distributed generation sources. Means of adaptive critics are used to implement the solution in real-time. © 2017 Elsevier B.V.","Adaptive critics; Adaptive learning techniques; Cooperative control; Islanded Microgrids; Neural networks","Distributed power generation; Dynamics; E-learning; Education; Learning algorithms; Learning systems; Neural networks; Optimization; Source separation; Adaptive critic; Adaptive learning; Co-operative control; Distributed generation source; Incomplete knowledge; Micro grid; Optimization problems; Separation principle; Adaptive control systems",2-s2.0-85025700873
"Zhang Q., Wang J., Lu A., Wang S., Ma J.","An improved SMO algorithm for financial credit risk assessment – Evidence from China's banking",2018,"Neurocomputing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032680863&doi=10.1016%2fj.neucom.2017.07.002&partnerID=40&md5=b84ef0c82db39a123c87b5976d6ec0ce","With rapid development of financial services and products, credit risk assessment has recently gained considerable attention in the field of financial risk management. In this paper, an improved credit risk assessment approach is presented. Based on the credit data from China Banking Regulatory Commission (CBRC), a multi-dimensional and multi-level credit risk indicator system is constructed. In particular, we present an improved sequential minimal optimization (SMO) learning algorithm, named four-variable SMO (FV-SMO), for credit risk classification model. At each iteration, it jointly selects four variables into the working set and an theorem is proposed to guarantee the analytical solution of sub-problem. The assessment is made on China credit dataset and two benchmark credit datasets from UCI database and CD-ROM database. Experimental results demonstrate FV-SMO is competitive in saving the computational cost and outperforms other five state-of-the-art classification methods in credit risk assessment accuracy. © 2017","Credit risk assessment; Four-variable working set; Sequential minimal optimization (SMO); SVM","Computation theory; Finance; Iterative methods; Optimization; Risk management; Classification methods; Computational costs; Credit risk assessment; Financial risk management; Multi dimensional; Regulatory commission; Sequential minimal optimization; Working set; Risk assessment",2-s2.0-85032680863
"Asghar A.B., Liu X.","Adaptive neuro-fuzzy algorithm to estimate effective wind speed and optimal rotor speed for variable-speed wind turbine",2018,"Neurocomputing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025637392&doi=10.1016%2fj.neucom.2017.07.022&partnerID=40&md5=43706a8ec978d8138216c253d8f3e0a6","The precise measurement of effective wind speed is a crucial task and has huge impact on wind turbine output power, safety and control performance. In this study, a hybrid intelligent learning based adaptive neuro-fuzzy inference system (ANFIS) is proposed for online estimation of effective wind speed from instantaneous values of wind turbine tip speed ratio (TSR), rotor speed and mechanical power. The artificial neural network (ANN) adjusts the parameters of fuzzy membership functions (MFs) using hybrid optimization method. The estimated value of effective wind speed is further utilized to design the optimal rotor speed estimator for maximum power point tracking (MPPT) of variable-speed wind turbine (VSWT). Both estimators are implemented in MATLAB and their performance is investigated for national renewable energy laboratory (NREL) offshore 5 MW baseline wind turbine. The simulation results show the effectiveness of proposed method. The proposed scheme is computationally intelligent, easy to implement and more reliable for fast estimation of effective wind speed and optimal rotor speed. © 2017","ANFIS; Mechanical power; Power coefficient; Rotor speed; Tip speed ratio; Wind turbine","Estimation; Fuzzy neural networks; Fuzzy sets; Fuzzy systems; MATLAB; Maximum power point trackers; Membership functions; Neural networks; Speed; Turbine components; Wind; Wind turbines; ANFIS; Mechanical power; Power coefficients; Rotor speed; Tip speed ratio; Fuzzy inference",2-s2.0-85025637392
"Tran N.-T., Wang Y.-W., Yang W.","Distributed optimization problem for double-integrator systems with the presence of the exogenous disturbance",2018,"Neurocomputing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023625744&doi=10.1016%2fj.neucom.2017.07.005&partnerID=40&md5=b3f8c3679ce41d2cccb24ef4e9011948","The aim of this paper is to study the distributed optimization problem for continuous-time multi-agent systems with the existence and the interference of external disturbance, therein each agent is described as double-integrator dynamic. To reject the exogenous disturbance, the distributed algorithm is proposed for each agent based on the internal model principle. The proposed algorithm only utilizes the position information of each agent from its neighbors subject to the undirected graph, which can reduce communication costs and energy consumptions in applications. Moreover, the algorithm only needs the cost functions of the agent itself, which can greatly protect the privacy of other agents. The optimal solution of the problem is thus obtained with the design of Lyapunov function and the help of convex analysis, LaSallel's Invariance Principle. Finally, two numerical simulation examples and the comparison of proposed algorithm with other previous research are presented to illustrate the persuasive effectiveness of the theoretical result. © 2017 Elsevier B.V.","Distributed optimization; External disturbance; Gradient-based algorithm; Internal model principle; Second-order multi-agent systems","Continuous time systems; Cost functions; Lyapunov functions; Optimization; Software agents; Distributed optimization; External disturbances; Gradient based algorithm; Internal model principle; Second orders; Multi agent systems",2-s2.0-85023625744
"Fang W., Hu H.-M., Hu Z., Liao S., Li B.","Perceptual hash-based feature description for person re-identification",2018,"Neurocomputing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025478825&doi=10.1016%2fj.neucom.2017.07.019&partnerID=40&md5=556c26100be106573416ce710a28fac8","Person re-identification is one of the most important and challenging problems in video surveillance systems. For person re-identification, feature description is a fundamental problem. While many approaches focus on exploiting low-level features to describe person images, most of them are not robust enough to illumination and viewpoint changes. In this paper, we propose a simple yet effective feature description method for person re-identification. Starting from low-level features, the proposed method uses perceptual hashing to binarize low-level feature maps and combines several feature channels for feature encoding. Then, an image pyramid is built, and three regional statistics are computed for hierarchical feature description. To some extent, the perceptual hash algorithm (PHA) can encode invariant macro structures of person images to make the representation robust to both illumination and viewpoint changes. On the other hand, while a rough hashing may be not discriminative enough, the combination of several different feature channels and regional statistics is able to exploit complementary information and enhance the discriminability. The proposed approach is evaluated on seven major person re-identification datasets. The results of comprehensive experiments show the effectiveness of the proposed method and notable improvements over the state-of-the-art approaches. © 2017","Hierarchical feature description; Image pyramid; Person re-identification; Regional statistics; The perceptual hash algorithm (PHA)","Encoding (symbols); Hash functions; Feature description; Hierarchical features; Image pyramids; Low-level features; Perceptual hash; Person re identifications; State-of-the-art approach; Video surveillance systems; Security systems",2-s2.0-85025478825
"Wang X., Zhang W., Yan J., Yuan X., Zha H.","On the flexibility of block coordinate descent for large-scale optimization",2018,"Neurocomputing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026459621&doi=10.1016%2fj.neucom.2017.07.024&partnerID=40&md5=d83975f9cf3c19238a822b79a2f76d9e","We consider a large-scale minimization problem (not necessarily convex) with non-smooth separable convex penalty. Problems in this form widely arise in many modern large-scale machine learning and signal processing applications. In this paper, we present a new perspective towards the parallel Block Coordinate Descent (BCD) methods. Specifically we explicitly give a concept of so-called two-layered block variable updating loop for parallel BCD methods in modern computing environment comprised of multiple distributed computing nodes. The outer loop refers to the block variable updating assigned to distributed nodes, and the inner loop involves the updating step inside each node. Each loop allows to adopt either Jacobi or Gauss–Seidel update rule. In particular, we give detailed theoretical convergence analysis to two practical schemes: Jacobi/Gauss–Seidel and Gauss–Seidel/Jacobi that embodies two algorithms respectively. Our new perspective and behind theoretical results help devise parallel BCD algorithms in a principled fashion, which in turn lend them a flexible implementation for BCD methods suited to the parallel computing environment. The effectiveness of the algorithm framework is verified on the benchmark tasks of large-scale ℓ1 regularized sparse logistic regression and non-negative matrix factorization. © 2017 Elsevier B.V.","Block coordinate descent; Gauss–Seidel; Jacobi; Large-scale optimization","Distributed computer systems; Factorization; Gaussian distribution; Learning systems; Signal processing; Block coordinate descents; Gauss-Seidel; Jacobi; Large-scale minimization problems; Large-scale optimization; Nonnegative matrix factorization; Parallel-computing environment; Signal processing applications; Optimization",2-s2.0-85026459621
"Wang Q.-X., Luo X., Li Y., Shi X.-Y., Gu L., Shang M.-S.","Incremental Slope-one recommenders",2018,"Neurocomputing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025807008&doi=10.1016%2fj.neucom.2017.07.033&partnerID=40&md5=f117435e24ebfe8345abd56a3e60b56a","Collaborative filtering (CF)-based recommenders work by estimating a user's potential preferences on unobserved items referring to the other users’ observed preferences. Slope-one, as a well-known CF recommender, is widely adopted in industrial applications owing to it's (a) competitive prediction accuracy for user's potential preferences, (b) high computational efficiency, and (c) ease of implementation. However, current Slope-one-based algorithms are all designed for static datasets, which are contradictory to real situations where dynamic datasets are mostly involved. This paper focuses on designing incremental Slope-one recommenders able to address dynamic datasets, reflecting their variations instantly without retraining the whole model. To do so, we have carefully analyzed the parameter training processing of Slope-one-based recommenders to design the incremental update rules for involved parameters reflecting data increments in dynamic environments. Three incremental Slope-one recommenders, including the incremental Slope-one, incremental weighted Slope-one, and incremental bi-polar slope one, are proposed. Experimental results on two large real datasets indicate that the proposed incremental slope-one recommenders can correctly reflect the increments of dynamic datasets with high computational efficiency. © 2017 Elsevier B.V.","Collaborative filtering; Dynamic datasets; Incremental recommenders; Recommender system; Slope-one","Computational efficiency; Efficiency; Recommender systems; Dynamic environments; Incremental recommenders; Incremental updates; Parameter training; Prediction accuracy; Real data sets; Real situation; Slope ones; Collaborative filtering",2-s2.0-85025807008
"Manngård M., Kronqvist J., Böling J.M.","Structural learning in artificial neural networks using sparse optimization",2018,"Neurocomputing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025820142&doi=10.1016%2fj.neucom.2017.07.028&partnerID=40&md5=87d135f42e4bb4f721bffd1a853ef4f1","In this paper, the problem of simultaneously estimating the structure and parameters of artificial neural networks with multiple hidden layers is considered. A method based on sparse optimization is proposed. The problem is formulated as an ℓ0-norm minimization problem, so that redundant weights are eliminated from the neural network. Such problems are in general combinatorial, and are often considered intractable. Hence, an iterative reweighting heuristic for relaxing the ℓ0-norm is presented. Experiments have been carried out on simple benchmark problems, both for classification and regression, and on a case study for estimation of waste heat recovery in ships. All experiments demonstrate the effectiveness of the algorithm. © 2017 Elsevier B.V.","Artificial neural networks; Iterative reweighting; Sparse optimization; Structural learning","Education; Iterative methods; Neural networks; Optimization; Waste heat; Waste heat utilization; Bench-mark problems; Hidden layers; Iterative reweighting; Minimization problems; Sparse optimizations; Structural learning; Structural optimization",2-s2.0-85025820142
"Liu D., Yang G.-H.","Neural network-based event-triggered MFAC for nonlinear discrete-time processes",2018,"Neurocomputing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023780912&doi=10.1016%2fj.neucom.2017.07.008&partnerID=40&md5=573bf982a9a9a5fa7de83220f844096d","This paper is concerned with the event-triggered data-driven control problem for nonlinear discrete-time systems. An event-based data-driven model-free adaptive controller design algorithm together with constructing an adaptive event-trigger condition is developed. Different from the existing data-driven model-free adaptive control approach, an aperiodic neural network weight update law is introduced to estimate the controller parameters, and the event-trigger mechanism is activated only if the event-trigger error exceeds the threshold. Furthermore, by combining the equivalent-dynamic-linearization technique with the Lyapunov method, it is proved that both the closed-loop control system and the weight estimation error are ultimately bounded. Finally, two simulation examples are provided to demonstrate the effectiveness of the derived method. © 2017 Elsevier B.V.","Data-driven control (DDC); Event-triggered control (ETC); Model-free adaptive control (MFAC); Radial basis function neural networks (RBFNNs)","Closed loop control systems; Controllers; Digital control systems; Discrete time control systems; Lyapunov methods; Radial basis function networks; Adaptive controller design; Data-driven control; Dynamic linearization; Event-triggered controls; Model-free adaptive control; Nonlinear discrete-time; Nonlinear discrete-time systems; Radial basis function neural networks; Adaptive control systems",2-s2.0-85023780912
"Fan Z., Bi D., Xiong L., Ma S., He L., Ding W.","Dim infrared image enhancement based on convolutional neural network",2018,"Neurocomputing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024107173&doi=10.1016%2fj.neucom.2017.07.017&partnerID=40&md5=7010146fa3f4e4f643200268579e3727","Long-range infrared images are always suffering from dim targets and background clutters. To improve the contrast between target and background, we propose a novel infrared image enhancement approach by highlighting target and suppressing background clutters. Predicting the target and background plays a key role in improving the contrast of dim infrared images that targets are embedded by background clutters. Taking full advantage of machine learning on prediction, we design the convolutional neural network (CNN) architecture in our study. To overcome the lack of large training data, the handwritten images in MNIST dataset are employed to simulate the properties of long-rang infrared images including dim targets, background clutters and low contrast. The target and background sub-images are predicted from the original dim infrared image based on the filters in the first layer of the trained CNN. Finally, the dim infrared image is enhanced by amplifying the targets and subtracting background clutters. The results of subjective and quantitative tests prove the performance of the proposed algorithm in contrast improvement. © 2017 Elsevier B.V.","Image enhancement; Infrared image processing; Neural networks; Pattern recognition; Spatial filtering","Clutter (information theory); Convolution; Image processing; Infrared imaging; Neural networks; Pattern recognition; Background clutter; Contrast improvements; Convolutional neural network; Handwritten images; Quantitative tests; Spatial filterings; Target and background; Training data; Image enhancement",2-s2.0-85024107173
"Ding W., Lin C.-T., Chen S., Zhang X., Hu B.","Multiagent-consensus-MapReduce-based attribute reduction using co-evolutionary quantum PSO for big data applications",2018,"Neurocomputing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023638265&doi=10.1016%2fj.neucom.2017.06.059&partnerID=40&md5=e8978ef7b64c6205fefad605ae289171","The attribute reduction for big data applications has become an urgent challenge in pattern recognition, machine learning and data mining. In this paper, we introduce the multi-agent consensus MapReduce optimization model and co-evolutionary quantum PSO with self-adaptive memeplexes for designing the attribute reduction method, and propose a multiagent-consensus-MapReduce-based attribute reduction algorithm (MCMAR). Firstly, the co-evolutionary quantum PSO with self-adaptive memeplexes is designed for grouping particles into different memeplexes, which aims to explore the search space and locate the global best region during the attribute reduction of big datasets. Secondly, the four layers neighborhood radius framework with compensatory scheme is constructed to partition big attribute sets by exploiting the interdependency among multiple-relevant-attribute sets. Thirdly, a novel multi-agent consensus MapReduce optimization model is adopted to perform the multiple-relevance-attribute reduction, in which five kinds of agents are used to conduct the ensemble co-evolutionary optimization. So the uniform reduction framework of different agents’ co-evolutionary game under the bounded rationality is further refined. Fourthly, the approximation MapReduce parallelism mechanism is permitted to formalize to the multi-agent co-evolutionary consensus structure, interaction and adaptation, which enhances different agents to share their solutions. Finally, extensive experimental studies substantiate the effectiveness and accuracy of MCMAR on some well-known benchmark datasets. Moreover, successful applications in big medical datasets are expected to dramatically scaling up MCMAR for complex infant brain MRI in terms of efficiency and feasibility. © 2017 Elsevier B.V.","Co-evolutionary quantum PSO; Ensemble co-evolutionary optimization of attribute reduction; Multi-agent consensus MapReduce model; Neighborhood radius with compensatory scheme; Self-adaptive memeplexes","Big data; Data mining; Magnetic resonance imaging; Multi agent systems; Optimization; Particle swarm optimization (PSO); Pattern recognition; Rough set theory; Attribute reduction; Co-evolutionary; MapReduce models; Neighborhood radius with compensatory scheme; Self-adaptive memeplexes; Data reduction",2-s2.0-85023638265
"Zhang Y., Xiang M., Yang B.","Hierarchical sparse coding from a Bayesian perspective",2018,"Neurocomputing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025467371&doi=10.1016%2fj.neucom.2017.06.076&partnerID=40&md5=bbb95d141b479040215d219eb8302898","We consider the problem of hierarchical sparse coding, where not only a few groups of atoms are active at a time but also each group enjoys internal sparsity. The current approaches are usually to achieve between-group sparsity using the ℓ1 penalty, such that many groups have small coefficients rather than being accurately zeroed out. The trivial groups may incur the proneness to overfitting of noise and are thereby harmful to interpretability of sparse representation. To this end, we in this paper reformulate the hierarchical sparse model from a Bayesian perspective employing twofold priors: the spike-and-slab prior and the Laplacian prior. The former is utilized to explicitly induce between-group sparsity, while the latter is adopted for both inducing within-group sparsity and obtaining a small reconstruction error. We propose a nest prior by integrating the both priors to result in hierarchical sparsity. The resultant optimization problem can be delivered a convergence solution in a few iterations via the proposed nested algorithm, corresponding to the nested prior. In experiments, we evaluate the performance of our method on signal recovery, image inpainting and sparse representation based classification, with simulated signals and two publicly available image databases. The results manifest that the proposed method, compared with the popular methods for sparse coding, can yield more concise representation and more reliable interpretation of data. © 2017 Elsevier Ltd","Bayesian framework; Hierarchical sparse modeling; Laplacian prior; Sparse representation based classification; Spike-and-slab prior","Classification (of information); Image processing; Laplace transforms; Optimization; Bayesian frameworks; Laplacians; Sparse modeling; Sparse representation based classifications; Spike-and-slab prior; Codes (symbols)",2-s2.0-85025467371
"López-Marín N., Mulet R.","In silico modelling of apoptosis induced by photodynamic therapy",2018,"Journal of Theoretical Biology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030459460&doi=10.1016%2fj.jtbi.2017.09.028&partnerID=40&md5=711ba9b2b9b4ce26928edbedee6e4e32","Photodynamic therapy (PDT) is an emergent technique used for the treatment of several diseases. After PDT, cells die by necrosis, apoptosis or autophagy. Necrosis is produced immediately during photodynamic therapy by high concentration of reactive oxygen species, apoptosis and autophagy are triggered by mild or low doses of light and photosensitizer. In this work we model the cell response to low doses of PDT assuming a bi-dimensional matrix of interacting cells. For each cell of the matrix we simulate in detail, with the help of the Gillespie's algorithm, the two main chemical pathways leading to apoptosis. We unveil the role of both pathways in the cell death rate of the tumor, as well as the relevance of several molecules in the process. Our model suggests values of concentrations for several species of molecules to enhance the effectiveness of PDT. © 2017 Elsevier Ltd","Apoptosis; Mathematical model; Photodynamic therapy","caspase 3; caspase 8; protein Bax; protein bcl 2; apoptosis; cell organelle; disease treatment; numerical model; reactive oxygen species; algorithm; apoptosis; Article; cell damage; cell function; cell interaction; clinical effectiveness; computer model; Gillespie algorithm; mathematical analysis; mathematical model; photodynamic therapy; priority journal; systems biology; upregulation",2-s2.0-85030459460
"Puglia M., Landi C., Gagliardi A., Breslin L., Armini A., Brunetti J., Pini A., Bianchi L., Bini L.","The proteome speciation of an immortalized cystic fibrosis cell line: New perspectives on the pathophysiology of the disease",2018,"Journal of Proteomics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030450027&doi=10.1016%2fj.jprot.2017.09.013&partnerID=40&md5=89b055a66c5be0e4223d4ded5a21b397","Cystic Fibrosis (CF) is a recessively inherited disease caused by mutations in the Cystic Fibrosis Transmembrane Conductance Regulator (CFTR) gene. CFTR has a pivotal role in the onset of CF, and several proteins are involved in its homeostasis. To study CFTR interactors at protein species level, we used a functional proteomics approach combining 2D-DIGE, mass spectrometry and enrichment analysis. A human bronchial epithelial cell line with cystic fibrosis (CFBE41o-) and the control (16HBE14o-) were used for the comparison. 73 differentially abundant spots were identified and some validated by western-blot. Enrichment analysis highlighted molecular pathways in which ezrin, HSP70, endoplasmin and lamin A/C, in addition to CFTR, were considered central hubs in CFTR homeostasis. These proteins acquire different functions through post-translational modifications, emphasizing the importance of studying the CF proteome at protein species level. Moreover, serpin H1, prelamin A/C, protein-SET and cystatin-B were associated to CF, demonstrating the importance of heat shock response, cross-talk between the cytoskeleton and signal transduction, chronic inflammation and alteration of CFTR gating in the pathophysiology of the disease. These results open new perspectives for the understanding of the proteostasis network, characteristic of CF pathology, and could provide a springboard for new therapeutic strategies. Biological significance Homeostasis of CFTR is a dynamic process managed by multiple proteostatic pathways. The used gel-based proteomic approach and enrichment analysis pointed out protein species variations among Human Bronchial (16HBE14o-) and Cystic Fibrosis Bronchial Epithelial cell lines (CFBE41o-) and specific molecular mechanisms involved in CF. In particular, we have highlighted HSP70 (HSP7C), HSP90 (endoplasmin), ERM proteins (ezrin), and lamin-A/C as central hubs of the functional analysis. Moreover, for the first time we consider serpin H1, lamin A/C, protein-SET and cystatin-B important player in CF, affecting acute exacerbation, cytoskeleton reorganization, CFTR gating and chronic inflammation in CF. Due to the presence of different spots corresponding to the same protein, we focalize our attention on the idea that a “protein species discourse” is mandatory to well-define functional roles of proteins. Our approach has permitted to pay attention to the molecular mechanisms which regulate pathways directly or indirectly involved with CFTR defects: heat shock response, cross-talk between cytoskeleton and signal transduction, chronic inflammation and alteration of CFTR gating. Our data could open new perspectives into the understanding of CF, identifying potential targets for drug treatments in order to alleviate Δ508CFTR membrane instability and consequently increase life expectancy for CF patients. © 2017 Elsevier B.V.","Acute exacerbation; CFTR; Cystic fibrosis; Enrichment analysis; Laminopathies; Protein species; Proteomics","collagen type 1; cystatin B; ezrin; glucose regulated protein 94; heat shock protein 70; lamin A; lamin C; proteome; serine proteinase inhibitor; algorithm; Article; chronic inflammation; comparative study; controlled study; cystic fibrosis; cytoskeleton; disease exacerbation; functional proteomics; HBEC cell line (bronchial); heat shock response; human; human cell; mass spectrometry; pathophysiology; priority journal; protein degradation; signal transduction; tandem mass spectrometry; two dimensional difference gel electrophoresis",2-s2.0-85030450027
"Calvo N.L., Maggio R.M., Kaufman T.S.","Characterization of pharmaceutically relevant materials at the solid state employing chemometrics methods",2018,"Journal of Pharmaceutical and Biomedical Analysis",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021770441&doi=10.1016%2fj.jpba.2017.06.017&partnerID=40&md5=11540416f04f2fef58f36a026084a34e","The understanding of materials and processes is a requirement when it comes to build quality into pharmaceutical products. This can be achieved through the development of rapid, efficient and versatile analytical methods able to perform qualification or quantification tasks along the manufacturing and control process. Process monitoring, capable of providing reliable real-time insights into the processes performance during the manufacturing of solid dosage forms, are the key to improve such understanding. In response to these demands, in recent times multivariate chemometrics algorithms have been increasingly associated to different analytical techniques, mainly vibrational spectroscopies [Raman, mid-infrared (MIR), near-infrared (NIR)], but also ultraviolet-visible (UV-vis) spectroscopy, X-ray powder diffraction and other methodologies. The resulting associations have been applied to the characterization and evaluation of different aspects of pharmaceutical materials at the solid state. This review examines the different scenarios where these methodological marriages have been successful. The list of analytical problems and regulatory demands solved by chemometrics analysis of solid-state multivariate data covers the whole manufacturing and control processes of both, active pharmaceutical ingredients in bulk and in their drug products. Hence, these combinations have found use in monitoring the crystallization processes of drugs and supramolecular drug associations (co-crystals, co-amorphous and salts), to access the correct crystal morphology, particle size, solubility and dissolution properties. In addition, they have been applied to identify and quantitate specific compounds, mainly active pharmaceutical ingredients in complex solid state mixtures. This included drug stability against different stimuli, solid-state transformations, or detection of adulterated or fraudulent medicines. The use of chemometrics-assisted analytical methods as part of the modern concept of process analytical technology, where every process step of every product batch from raw materials to final product must take place in a controlled manner is discussed. Finally, but no less important, the application of chemometrics methods to chemical imaging, aiming to extract spatial and compositional information is also revised. © 2017 Elsevier B.V.","Characterization of the solid-state; Chemical imaging; Chemometrics; PAT; Quality control and stability; Vibrational spectroscopies and XRPD",,2-s2.0-85021770441
"Kozelkov A.S., Lashkin S.V., Efremov V.R., Volkov K.N., Tsibereva Y.A., Tarasova N.V.","An implicit algorithm of solving Navier–Stokes equations to simulate flows in anisotropic porous media",2018,"Computers and Fluids",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032833153&doi=10.1016%2fj.compfluid.2017.10.029&partnerID=40&md5=9fd2d0d1d44ad22eaa7ec3ab4514a829","A coupled computational algorithm for modified Navier–Stokes equations to simulate flows in anisotropic porous media is proposed and described. The difference from the classic SIMPLE algorithm is in the completely implicit relationship between velocity and pressure owing to the implicit terms of the pressure and mass flow gradients in the continuity equation and momentum equation. One of the attractive features of this algorithm is the possibility of completely implicit discretization of off-diagonal components of the porous medium resistance tensor in the right-hand side of the momentum equation. Implicit discretization allows reducing the number of linear iterations as compared to the SIMPLE algorithm with explicit discretization of off-diagonal components. The specific features of discretization of modified equations including the discretization of boundary conditions and components of the porous medium resistance tensor are considered. The proposed algorithm is verified in comparison with the SIMPLE algorithm on a series of benchmark problems, such as the problem of a flow through a porous insert, a flow in a divided channel, and a flow through a cylindrical porous filter. The total problem runtimes and the number of iterations required for complete convergence are given to compare the two algorithms. © 2017 Elsevier Ltd","Brinkman equations; Darcy law; Implicit discretization; Multigrid method; Navier–Stokes equations; Porous media; Pressure-based algorithm","Anisotropic media; Anisotropy; Flow of fluids; Porous materials; Tensors; Brinkman equation; Darcy law; Discretizations; Multigrid methods; Pressure-based; Stokes equations; Navier Stokes equations",2-s2.0-85032833153
"Salazar-Ramirez A., Irigoyen E., Martinez R., Zalabarria U.","An enhanced fuzzy algorithm based on advanced signal processing for identification of stress",2018,"Neurocomputing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022004375&doi=10.1016%2fj.neucom.2016.08.153&partnerID=40&md5=9bb639b8b15908425fb31d53ab0fc227","Nowadays, it is crucial to promote and develop the autonomy of people, and specifically of individuals with some disability, in order to improve their life quality and achieve a better inclusion into socio-cultural life. Therefore, the identification of stress situations can be a suitable assistive tool for improving their socio-cultural inclusion. This work presents important enhancements and variations for an existing fuzzy logic stress detection system based on monitoring and processing different physiological signals (heart rate, galvanic skin response and breath). First, it proposes a method based on wavelet processing to improve the detection of R peaks of electrocardiograms. Afterwards, it proposes to decompose the galvanic response signal into two components: the average value and the variations. In addition, it proposes to extract information out the breath signal by analyzing its frequential composition. Finally, an improved response in detecting stress changes is shown in comparison with other previous works. © 2017 Elsevier B.V.","Fuzzy logic; Physiological signal processing; Stress identification; Wavelets","Biomedical signal processing; Computer circuits; Electrophysiology; Fuzzy sets; Physiological models; Physiology; Signal processing; Advanced signal processing; Extract informations; Fuzzy algorithms; Galvanic skin response; Physiological signal processing; Physiological signals; Wavelet processing; Wavelets; Fuzzy logic; Article; breathing pattern; breathing rate; controlled study; electrodermal response; fuzzy system; heart rate; human; limit of detection; priority journal; signal detection; signal processing; stress; wavelet analysis",2-s2.0-85022004375
"Osaba E., Carballedo R., Diaz F., Onieva E., Masegosa A.D., Perallos A.","Good practice proposal for the implementation, presentation, and comparison of metaheuristics for solving routing problems",2018,"Neurocomputing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021963021&doi=10.1016%2fj.neucom.2016.11.098&partnerID=40&md5=c6def4aac026e1d488642f9a561fab7a","Researchers who investigate in any area related to computational algorithms (both defining new algorithms or improving existing ones) usually find large difficulties to test their work. Comparisons among different researches in this field are often a hard task, due to the ambiguity or lack of detail in the presentation of the work and its results. On many occasions, the replication of the work conducted by other researchers is required, which leads to a waste of time and a delay in the research advances. The authors of this study propose a procedure to introduce new techniques and their results in the field of routing problems. In this paper, this procedure is detailed, and a set of good practices to follow are deeply described. It is noteworthy that this procedure can be applied to any combinatorial optimization problem. Anyway, the literature of this study is focused on routing problems. This field has been chosen because of its importance in real world, and its relevance in the actual literature. © 2017 Elsevier B.V.","Combinatorial optimization; Good practice proposal; Metaheuristics; Routing problems; Traveling salesman problem","Combinatorial optimization; Heuristic algorithms; Optimization; Traveling salesman problem; Combinatorial optimization problems; Computational algorithm; Good practices; Hard task; Meta heuristics; Real-world; Research advances; Routing problems; Problem solving",2-s2.0-85021963021
"Bilbao M.N., Del Ser J., Perfecto C., Salcedo-Sanz S., Portilla-Figueras J.A.","Cost-efficient deployment of multi-hop wireless networks over disaster areas using multi-objective meta-heuristics",2018,"Neurocomputing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023625968&doi=10.1016%2fj.neucom.2016.11.097&partnerID=40&md5=c07e427a1a3eeae403d9765381bb6ed0","Nowadays there is a global concern with the growing frequency and magnitude of natural disasters, many of them associated with climate change at a global scale. When tackled during a stringent economic era, the allocation of resources to efficiently deal with such disaster situations (e.g., brigades, vehicles and other support equipment for fire events) undergoes severe budgetary limitations which, in several proven cases, have lead to personal casualties due to a reduced support equipment. As such, the lack of enough communication resources to cover the disaster area at hand may cause a risky radio isolation of the deployed teams and ultimately fatal implications, as occurred in different recent episodes in Spain and USA during the last decade. This issue becomes even more dramatic when understood jointly with the strong budget cuts lately imposed by national authorities. In this context, this article postulates cost-efficient multi-hop communications as a technological solution to provide extended radio coverage to the deployed teams over disaster areas. Specifically, a Harmony Search (HS) based scheme is proposed to determine the optimal number, position and model of a set of wireless relays that must be deployed over a large-scale disaster area. The approach presented in this paper operates under a Pareto-optimal strategy, so a number of different deployments is then produced by balancing between redundant coverage and economical cost of the deployment. This information can assist authorities in their resource provisioning and/or operation duties. The performance of different heuristic operators to enhance the proposed HS algorithm are assessed and discussed by means of extensive simulations over synthetically generated scenarios, as well as over a more realistic, orography-aware setup constructed with LIDAR (Laser Imaging Detection and Ranging) data captured in the city center of Bilbao (Spain). © 2017 Elsevier B.V.","Disaster communications; Genetic algorithm; Harmony search; Multi-hop relaying; Multi-objective optimization","Budget control; Climate change; Costs; Disaster prevention; Genetic algorithms; Multiobjective optimization; Optical radar; Optimization; Pareto principle; Wireless networks; Communication resources; Disaster communications; Harmony search; Multi hop communication; Multi-objective Meta-heuristics; Multihop relaying; Multihop wireless network; Technological solution; Disasters; Article; computer heuristics; computer simulation; cost; disaster; genetic algorithm; priority journal; resource allocation; Spain; wireless communication",2-s2.0-85023625968
"Lopez-Guede J.M., Estevez J., Garmendia A., Graña M.","Making physical proofs of concept of reinforcement learning control in single robot hose transport task complete",2018,"Neurocomputing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023642304&doi=10.1016%2fj.neucom.2017.01.110&partnerID=40&md5=a6bc39bb97bcfa4b22fb2bd0d2fdd0b0","This paper deals with the realization of physical proof of concept experiments in the paradigm of Linked Multi-Component Robotic Systems (LMCRS). The main objective is to demonstrate that the controllers learned through Reinforcement Learning (RL) algorithms with different state space formalizations and different spatial discretizations in a simulator are reliable in a real world configuration of the task of transporting a hose by a single robot. This one is a prototypical example of LMCRS task (extendable to much more complex tasks). We describe how the complete system has been designed and implemented. Two different previously learned RL controllers have been tested solving two different LMCRS control problems, using different state space modeling and discretization step in each case. The physical realizations validate previously published simulation based results, giving a strong argument in favor of the suitability of RL techniques to deal with LMCRS systems. © 2017 Elsevier B.V.","Hose transport; Linked multicomponent robotic systems; LMCRS; Proof of concept; Reinforcement learning","Controllers; Education; Hose; Robotics; Control problems; LMCRS; Physical realization; Proof of concept; Reinforcement learning control; Robotic systems; Spatial discretizations; State - space models; Reinforcement learning; algorithm; Article; learning; Linked Multi Component Robotic System; machine learning; mathematical computing; mathematical model; priority journal; reinforcement; robotics; task performance",2-s2.0-85023642304
"Sierra J.E., Santos M.","Modelling engineering systems using analytical and neural techniques: Hybridization",2018,"Neurocomputing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021901684&doi=10.1016%2fj.neucom.2016.11.099&partnerID=40&md5=c26d8ab06cac679f3fb85cd3b96892c7","From real input/output data, different control-oriented models of a quadrotor unmanned aerial vehicle (UAV) are obtained by applying different identification methods. Parametric techniques, neural networks, neuro-fuzzy inference systems, and the hybridization of some of them are applied. The identified models are analyzed and compared in the time and frequency domains. We conclude that the hybridization of analytical and intelligent techniques is a good choice to model of complex systems while keeping a good balance between accuracy and computational cost. In addition, off-line trained neural networks and adaptive networks with on-line learning are analyzed, and their advantages and disadvantages regarding modelling are presented. The influence of the partition of the training and validation dataset on the model error is also discussed. © 2017 Elsevier B.V.","Adaptive neural networks; Hybridization; Identification; Neuro-fuzzy; Parametric techniques; Unmanned aerial vehicles (UAV)","Complex networks; Fuzzy inference; Fuzzy systems; Identification (control systems); Unmanned aerial vehicles (UAV); Adaptive neural networks; Hybridization; Neuro-Fuzzy; Neuro-fuzzy inference systems; Parametric techniques; Quadrotor unmanned aerial vehicles; Time and frequency domains; Trained neural networks; Fuzzy neural networks; Adaptive Neural Fuzzy Inference System; algorithm; Article; artificial neural network; bioengineering; controlled study; fuzzy logic; hybridization; measurement accuracy; measurement precision; priority journal; validation process",2-s2.0-85021901684
"Trimeche A., Sakly A., Mtibaa A.","Implementation of PSO algorithm for MIMO detection system in FPGA",2018,"International Journal of Electronics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020548521&doi=10.1080%2f00207217.2017.1335801&partnerID=40&md5=5134222aa2e7942f7f0704f5889334ae","This article presents a field programmable gate array design and implementation of particle swarm optimisation (PSO) algorithm for multiple input multiple output (MIMO) detection systems. Although, the simulations results prove that the maximum likelihood (ML) detector presents better performances than the other detectors like zero forcing (ZF) and minimum mean square error (MMSE), but with MIMO systems this algorithm has a high computational complexity. To minimise this effect, we apply a new type of cost function and give an efficient calculation algorithm. We propose a PSO approach based on signal transmitted vector x ∈ ξ = {-1, +1}n T from, y = Hx + w y ∈ Rn R and H ∈ Rn R xnT. The simulation result shows the effectiveness of the proposed algorithm in terms of achieving better bit error rate performance compared to ZF and MMSE with low complexity. This algorithm has been developed to reduce the ML detector complexity. © 2017 Informa UK Limited, trading as Taylor & Francis Group.","BER; FPGA; MIMO; ML; PSO; SNR","Bit error rate; Cost functions; Field programmable gate arrays (FPGA); Maximum likelihood; Mean square error; MIMO systems; Optimization; Particle swarm optimization (PSO); Signal receivers; Bit error rate (BER) performance; Calculation algorithms; Maximum likelihood detectors; MIMO detection; Minimum mean square errors (MMSE); Multiple input multiple output detections; Particle swarm optimisation; PSO algorithms; Computational complexity",2-s2.0-85020548521
"Liu Y., Istook C.L., Liu K., Wang J.","Innovative method for creating fitted brassiere wire prototype based on transformation matrix algorithm",2018,"Journal of the Textile Institute",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019143802&doi=10.1080%2f00405000.2017.1326366&partnerID=40&md5=24e2658d535e1c8344e6a542da2930b1","It has been difficult to obtain the fitted bra wire shape for women’s breasts, since the under breast root shape extracted from 3D bodyscan breast images is three dimensional. A detailed matrix algorithm for the geometric relation is firstly introduced and presented for transferring the 3D bra wire shape to one that is 2D to create a fitted bra underwire shape prototype. In this paper, the under breast root shape was extracted from a medium average avatar, then the curve line was exported as a point format. Points were taken as research subject, then the transformation matrix algorithm was applied to the spatial coordinates of the points to fulfill the transformation. Thereby a detailed program was operated in MATLAB for obtaining the coordinates of points to create the contour for the 2D wire shape. The matrix algorithm method was a useful, simple and straightforward method to implement. In addition, it works well for various kinds of breast shapes. © 2017 The Textile Institute.","Bra wire prototype; fitted; matrix algorithm; transformation","MATLAB; Medical imaging; Wire; Bra wire prototype; fitted; Geometric relations; Matrix algorithms; Spatial coordinates; Straight-forward method; transformation; Transformation matrices; Linear transformations",2-s2.0-85019143802
"Kassarwani N., Ohri J., Singh A.","Design and performance of dynamic voltage restorer using genetic algorithm",2018,"International Journal of Electronics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022057444&doi=10.1080%2f00207217.2017.1347828&partnerID=40&md5=38862ea9c827cbdf89f5544f5da5aa31","In the present scenario, sensitive loads suffer nearly 80% of power quality problems especially due to voltage sag. Dynamic voltage restorer (DVR) finds its perfect application as a compensator to mitigate the voltage sag problem. In this paper, source voltage suffers voltage sag of 30% and load terminal voltage is regulated using proportional and integral (PI) controllers. Synchronous reference frame algorithm is adopted to generate reference load voltage for voltage source converter switching. Optimised values of the gains of PI controllers are achieved using genetic algorithm. Control strategy of the DVR is simulated using MATLAB software and performance of DVR is studied. © 2017 Informa UK Limited, trading as Taylor & Francis Group.","dynamic voltage restorer; genetic algorithm; Power quality; synchronous reference frame; voltage sag","Genetic algorithms; MATLAB; Voltage regulators; Dynamic voltage restorer (DVR); Load terminal voltage; Perfect applications; Power quality problem; Proportional and integral controllers; Synchronous reference frame; Voltage sags; Voltage source converters; Power quality",2-s2.0-85022057444
"Vasquez Padilla R., Soo Too Y.C., Benito R., McNaughton R., Stein W.","Multi-objective thermodynamic optimisation of supercritical CO2 Brayton cycles integrated with solar central receivers",2018,"International Journal of Sustainable Energy",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963545877&doi=10.1080%2f14786451.2016.1166109&partnerID=40&md5=8bf2dd65841be759649060df8c6ca560","In this paper, optimisation of the supercritical CO2 Brayton cycles integrated with a solar receiver, which provides heat input to the cycle, was performed. Four S-COCO2 Brayton cycle configurations were analysed and optimum operating conditions were obtained by using a multi-objective thermodynamic optimisation. Four different sets, each including two objective parameters, were considered individually. The individual multi-objective optimisation was performed by using Non-dominated Sorting Genetic Algorithm. The effect of reheating, solar receiver pressure drop and cycle parameters on the overall exergy and cycle thermal efficiency was analysed. The results showed that, for all configurations, the overall exergy efficiency of the solarised systems achieved at maximum value between 700°C and 750°C and the optimum value is adversely affected by the solar receiver pressure drop. In addition, the optimum cycle high pressure was in the range of 24.2–25.9 MPa, depending on the configurations and reheat condition. © 2016 The Commonwealth Scientific and Industrial Research Organisation.","exergy efficiency; recompression; Solar receiver; thermal efficiency","Brayton cycle; Carbon dioxide; Drops; Efficiency; Exergy; Genetic algorithms; Pressure drop; Reheat cycle; Solar equipment; Central receivers; Exergy efficiencies; Non- dominated sorting genetic algorithms; Objective parameters; Optimum operating conditions; Recompression; Solar receiver; Thermal efficiency; Multiobjective optimization; carbon dioxide; energy efficiency; genetic algorithm; optimization",2-s2.0-84963545877
"Bandeira J.M., Fernandes P., Fontes T., Pereira S.R., Khattak A.J., Coelho M.C.","Exploring multiple eco-routing guidance strategies in a commuting corridor",2018,"International Journal of Sustainable Transportation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020548082&doi=10.1080%2f15568318.2017.1328545&partnerID=40&md5=ed1e6ce48c87aa7d12e42d8edfe11539","The introduction of eco-routing systems has been suggested as a promising strategy to reduce carbon dioxide emissions and criteria pollutants. The objective of this study is to scrutinize the impacts of an eco-routing guidance system on emissions through the use of a case study in a commuting corridor. This research aims at assessing the potential environmental benefits in terms of different pollutant emissions. Simultaneously, it addresses the extent of variations in system travel time (STT) that each eco-routing strategy implies. The methodology consists of three distinct phases. The first phase corresponds to the adjustment of a microsimulation platform of traffic and emissions with empirical data previously collected. Second, to volume-emission-functions (VEF), developed based on the integrated modeling structure. Final, to different scenarios of traffic flow optimization performed at the network level based on a simplified assignment procedure. The results show that if the traffic assignment is performed with the objective to minimize overall impacts, then the total system environmental damage costs can be reduced up to 9% with marginal oscillations in total STT. However, if drivers are advised based on their own emissions minimization, total system emissions may be higher than under the standard user equilibrium flow pattern. Specifically, environmentally friendly navigation algorithms focused on individual goals may tend to divert traffic to roads with less capacity affecting the performance of the remaining traffic. This case study brings new insights about the difficulties and potentials of implementing such systems. © 2018 Taylor & Francis Group, LLC.","Eco-routing; emissions; microscopic modeling; traffic management","Carbon; Carbon dioxide; Flow patterns; Global warming; Particulate emissions; Pollution; Routing algorithms; Travel time; Carbon dioxide emissions; ECO routing; Environmental benefits; Environmental damage; Integrated model structures; Microscopic modeling; Navigation algorithms; Traffic management; Traffic control",2-s2.0-85020548082
"Dunder E., Gumustekin S., Cengiz M.A.","Variable selection in gamma regression models via artificial bee colony algorithm",2018,"Journal of Applied Statistics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994824107&doi=10.1080%2f02664763.2016.1254730&partnerID=40&md5=67817c155d83659b1d4dee351962ce0b","Variable selection is an important task in regression analysis. Performance of the statistical model highly depends on the determination of the subset of predictors. There are several methods to select most relevant variables to construct a good model. However in practice, the dependent variable may have positive continuous values and not normally distributed. In such situations, gamma distribution is more suitable than normal for building a regression model. This paper introduces an heuristic approach to perform variable selection using artificial bee colony optimization for gamma regression models. We evaluated the proposed method against with classical selection methods such as backward and stepwise. Both simulation studies and real data set examples proved the accuracy of our selection procedure. © 2016 Informa UK Limited, trading as Taylor & Francis Group.","artificial bee colony algorithm; gamma regression analysis; heuristic optimization; R-project; Variable selection",,2-s2.0-84994824107
"Xu X., Wang Y., Ji Y., Xu Y., Xie M.","A novel phase retrieval method from three-wavelength in-line phase-shifting interferograms based on positive negative 2π phase shifts",2018,"Journal of Modern Optics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029449964&doi=10.1080%2f09500340.2017.1374480&partnerID=40&md5=acad61d4e0ce0975582f6cf0c986608f","A new method to extract quantitative phases for each wavelength from three-wavelength in-line phase-shifting interferograms is proposed. Firstly, seven interferograms with positive negative 2π phase shifts are sequentially captured by using the phase-shifting technique. Secondly, six dc-term suppressed intensities can be achieved by the use of the algebraic algorithm. Finally, the wrapped phases at the three wavelengths can be acquired simultaneously from these six interferograms add-subtracting by employing the trigonometric function method. The surface morphology with increased ambiguity-free range at synthetic beat wavelength can be obtained, while maintaining the low noise precision of the single wavelength measurement, by combining this method with three-wavelength phase unwrapping method. We illustrate the principle of this algorithm, and the simulated experiments of the spherical cap and the HeLa cell are conducted to prove our proposed method, respectively. © 2017 Informa UK Limited, trading as Taylor & Francis Group.","biological cells; holographic interferometry; Phase retrieval; special phase shift","Holographic interferometry; Algebraic algorithms; Biological cells; Phase retrieval; Phase unwrapping methods; Phase-shifting technique; Simulated experiments; Single wavelength; Trigonometric functions; Interferometry",2-s2.0-85029449964
"Yan S., Lu C.-C., Wang M.-H.","Stochastic fleet deployment models for public bicycle rental systems",2018,"International Journal of Sustainable Transportation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020177969&doi=10.1080%2f15568318.2017.1324586&partnerID=40&md5=bf90fa064244cea356accdff79f5e3e8","This paper presents two stochastic bike deployment (SBD) models that determine the optimal number of bicycles allocated to each station in a leisure-oriented public bicycle rental system with stochastic demands. The SBD models represent the stochastic demands using a set of scenarios with given probabilities. A multilayer bike-flow time-space network is constructed for developing the models, where each layer corresponds to a given demand scenario and effectively describes bicycle flows in the spatial and temporal dimensions. As a result, the models are formulated as the integer multi-commodity network flow problem, which is characterized as NP-hard. We propose a heuristic to efficiently obtain good quality solutions for large-size model instances. Test instances are generated using real data from a bicycle rental system in Taiwan to evaluate the performance of the models and the solution algorithm. The test results show that the models can help the system operator of a public bicycle system make effective fleet deployment decisions. © 2018 Taylor & Francis Group, LLC.","Bicycle rental; fleet allocation; multi-commodity network flows; public bicycles; time-space networks","Bicycles; Sporting goods; Stochastic systems; Fleet allocation; Multi-commodity network flows; Public bicycle systems; Public bicycles; Solution algorithms; Stochastic demand; Temporal dimensions; Time-space networks; Stochastic models",2-s2.0-85020177969
"Wang R.-F., Fu X., Yuan J.-C., Dong Z.-Y.","Economic design of variable-parameter X-Shewhart control chart used to monitor continuous production",2018,"Quality Technology and Quantitative Management",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017472466&doi=10.1080%2f16843703.2017.1304037&partnerID=40&md5=67d6c614ec12f6407c43cb759f289e31","Control charts are a quantitative management tool used in statistical process control to monitor product quality in production processes. This study proposes a new economic design of the variable-parameter (Vp) (Formula presented.) -Shewhart control chart for monitoring a continuous production process. In this design, the mean monitoring quality may exhibit an upward or downward shift due to two types of assignable causes. In certain continuous production settings, product quality directly affects production profit; the mean shift in monitoring quality influences lost cost, unit income and product yield. Thus, for modelling continuous production, using a maximum profit objective function for the optimization algorithm of this economic model is more appropriate than using minimum cost. Therefore, the Vp (Formula presented.) -Shewhart control chart uses an economic criterion for optimum parameter design to maximize the anticipated quality-related profit. The assignable cause occurrence is assumed to be an exponentially distributed random variable; Markov chain theory with a 9 × 9 transition probability matrix is used to subdivide the process operation into three actual states and three necessary actions. A numerical investigation is used to demonstrate the superiority of the proposed profit model compared to existing models. The proposed Vp (Formula presented.) -Shewhart control chart is applied to an example case to show its feasibility and practical application. © 2017 International Chinese Association of Quantitative Management.","Markov chain; profit maximization; Shewhart scheme; variable parameter control chart","Chains; Control charts; Flowcharting; Markov processes; Optimization; Probability; Process control; Profitability; Statistical process control; Distributed random variables; Numerical investigations; Optimization algorithms; Profit maximization; Shewhart; Shewhart control charts; Transition probability matrix; Variable parameter control charts; Quality control",2-s2.0-85017472466
"Duan Y., Li M., Niu Z., Jing P., Chen Z.","A star pattern recognition algorithm for cameras with large FOV",2018,"Journal of Modern Optics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029719990&doi=10.1080%2f09500340.2017.1377304&partnerID=40&md5=ddb02abf8c50f557c6de5bf808212a0a","In most large field of view (FOV) observations, the distortion problem is inevitably and significantly more serious than in small FOV ones. In the circumstances, many traditional star identification approaches are not able to efficiently identify stars any more. In order to deal with this problem, we put forward a star identification method that is less sensitive to distortion. The method first processes stars in the central area of the image, using traditional identification logic, and then applies the region growing strategy to enlarge the identified regions iteratively until the entire image is covered. The performance of the new scheme is analysed in the presence of both simulated data and real data. The results show that the proposed algorithm has the advantage of speed, and the strategy of regional extension can efficiently identify stars in large FOV images compared with other existing algorithms. © 2017 Informa UK Limited, trading as Taylor & Francis Group.","distortion; large FOV; pattern recognition; region growing; Star identification","Distortion (waves); Iterative methods; Stars; Large field of views; large FOV; Region growing; Star identification; Star pattern recognition; Pattern recognition",2-s2.0-85029719990
"Li F., Hitchens C., Stoddart D.","A performance evaluation method to compare the multi-view point cloud data registration based on ICP algorithm and reference marker",2018,"Journal of Modern Optics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029530513&doi=10.1080%2f09500340.2017.1375566&partnerID=40&md5=7faf2b79e65499fd5acc402bd36e969d","Registration of range images of surfaces is a fundamental problem in three-dimensional modelling. This process is performed by finding a rotation matrix and translation vector between two sets of data points requiring registration. Many techniques have been developed to solve the registration problem. Therefore, it is important to understand the accuracy of various registration techniques when we decide which technique will be selected to perform registration task. This paper presents a new approach to test and compare registration techniques in terms of accuracy. Among various registration methods, iterative closest point-based algorithms and reference marker methods are two types of commonly applied methods which are used to accomplish this task because they are easy to implement and relatively low cost. These two methods have been selected to perform a comprehensively quantitative evaluation by using the proposed method and the registration results are verified using the calibrated NPL freeform standard. © 2017 Informa UK Limited, trading as Taylor & Francis Group.","iterative closest point; Optical metrology; point clouds; reference markers; registration","Image registration; Iterative Closest Points; Optical Metrology; Point cloud; reference markers; registration; Iterative methods",2-s2.0-85029530513
"Wei Z., Wei G.","The inverse discrete transmission eigenvalue problem for absorbing media",2018,"Inverse Problems in Science and Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017131809&doi=10.1080%2f17415977.2017.1309397&partnerID=40&md5=9a7ee138ceff21c5620bd01bc297fbd7","The inverse problem for the discrete analogue of the transmission eigenvalue problem for absorbing media with a spherically symmetric index of refraction ϱ is considered. Some uniqueness results are provided which imply that ϱ can be recovered uniquely if only the all transmission eigenvalues (counting with their multiples) are given together with partial information on the entries of ϱ. © 2017 Informa UK Limited, trading as Taylor & Francis Group.","Absorbing media; discrete version; inverse spectral problem; the extended Euclidean algorithm; transmission eigenvalue","Eigenvalues and eigenfunctions; Refractive index; Absorbing media; discrete version; Extended Euclidean algorithm; Inverse spectral problems; Transmission eigenvalue; Inverse problems",2-s2.0-85017131809
"Kronenfeld B.J.","Manual construction of continuous cartograms through mesh transformation",2018,"Cartography and Geographic Information Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009288486&doi=10.1080%2f15230406.2016.1270775&partnerID=40&md5=60621884fbd3798b3a545cefed6bf9a3","A computer-assisted framework is proposed to support the manual construction of cartograms. The framework employs a joint triangulation, similar to that used in rubber-sheeting, to define a piecewise affine transformation between map space and cartogram space. This guarantees preservation of all topological relations within and among transformed datasets with insertion of a finite number of points. To support intuitive user control of cartogram appearance, methods are developed to translate generically defined user adjustments of the cartogram into mesh vertex positions on either the source map mesh or cartogram mesh. The framework is implemented in a working prototype application and used to create sample cartograms of the USA and China. Results are compared with cartograms produced using diffusion and carto3f algorithms in terms of accuracy, aesthetic appearance, and approximate construction time. Qualitative aspects of the manual construction process are also discussed. © 2017 Cartography and Geographic Information Society.","Cartogram; China; the USA; value-by-area map","Civil engineering; Innovation; Cartogram; China; Computer assisted; Construction process; Mesh transformations; nocv1; Qualitative aspects; the USA; Topological relations; Mesh generation; accuracy assessment; algorithm; cartogram; data set; map; China; United States",2-s2.0-85009288486
"McClain N.","The horizons of technological control: automated surveillance in the New York subway",2018,"Information Communication and Society",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84999751947&doi=10.1080%2f1369118X.2016.1260624&partnerID=40&md5=7dfc6ec99ff3f173f653419e60101c41","Surveillance technologies may be capable of monitoring a domain, but they need a sufficiently orderly domain to monitor. This article examines the secretive effort to institute artificial-intelligence-based ‘smart surveillance’ in the New York subway, using object- and pattern-recognition algorithms to identify dangerous activities in video feeds, such as a person abandoning a package. By considering the necessary preconditions for computer vision systems to recognize patterns and objects, I show how smart surveillance was challenged by the lack of visual and social uniformities necessary for smart surveillance systems to make its fine-toothed distinctions. In spite of vast resources and involvement of a major military contractor, the project was eventually deemed a failure. Although problems in computer vision are being incrementally solved, those improvements do not yet add up to a holistic technology capable of parsing the real-world ambiguity of open-ended settings which do not meet the assumptions of the detection algorithms. In the absence of technologies that can handle the actual mess, the world itself must cooperate, but it often does not. The article demonstrates the importance of looking beyond the claims of technical efficacy in the study of security and surveillance to discover how technologies of inspection and control actually work, as a means to cut through the heavy rhetorical packaging in which they are sold to their publics. © 2016 Informa UK Limited, trading as Taylor & Francis Group.","artificial intelligence; security; sociology; subway; Surveillance/privacy; urban studies",,2-s2.0-84999751947
[No author name available],"Corrigendum to: An alternative update formula for non-linear model-based iterative learning control (Inverse Problems in Science and Engineering, (2016), 24, 5, (860-888), 10.1080/17415977.2015.1088536)",2018,"Inverse Problems in Science and Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031779083&doi=10.1080%2f17415977.2017.1312362&partnerID=40&md5=aaa0eebcb9e98b504c1d4f6703304d5c","In the original, online version of the above article, please note that Equation (79), line 2 should read: +θ5u(k−5)y(k−4)+θ6u(k−5)u(k−6)y(k−2) Equation (85) should read: y(k) = 0.24389u(t−4)−0.10626u(t−6)+0.048292u(t−10)+2.3557y(t−1)−2.6323y (t −2)+1.6364y(t −3)−0.45734y(t −4)−0.28732u(5t −5)u(t −10). Table 4, rowA2: cSI should be 0.05 instead of 0.03. Example 1 to Example 4: The results presented for the alternative algorithm instead apply to the modified alternative algorithm. The correct results for the alternative algorithm are generally inferior to the modified alternative algorithm and are not presented. The alternative algorithm is nonetheless useful as a stepping stone in deriving the modified alternative algorithm. Full data for all examples are available from the author. Section 10: Ignore the first item in the list. Section 11: The statements made regarding the alternative algorithm instead apply to the modified alternative algorithm. Replace Figure 8 and Figure 9 with Figure 1 shown below. (Figure presented.). © 2017 Informa UK Limited, trading as Taylor & Francis Group.",,,2-s2.0-85031779083
"Chen H., Cheng T., Shawe-Taylor J.","A Balanced Route Design for Min-Max Multiple-Depot Rural Postman Problem (MMMDRPP): a police patrolling case",2018,"International Journal of Geographical Information Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031106333&doi=10.1080%2f13658816.2017.1380201&partnerID=40&md5=2f8716903bc732d0f1344871031a3da8","Providing distributed services on road networks is an essential concern for many applications, such as mail delivery, logistics and police patrolling. Designing effective and balanced routes for these applications is challenging, especially when involving multiple postmen from distinct depots. In this research, we formulate this routing problem as a Min-Max Multiple-Depot Rural Postman Problem (MMMDRPP). To solve this routing problem, we develop an efficient tabu-search-based algorithm and propose three novel lower bounds to evaluate the routes. To demonstrate its practical usefulness, we show how to formulate the route design for police patrolling in London as an MMMDRPP and generate balanced routes using the proposed algorithm. Furthermore, the algorithm is tested on multiple adapted benchmark problems. The results demonstrate the efficiency of the algorithm in generating balanced routes. © 2017 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.","Arc routing; police patrol; rural postman problem; tabu search",,2-s2.0-85031106333
"Ben Ameur H., Chavent G., Cheikh F., Clément F., Martin V., Roberts J.E.","First-order indicators for the estimation of discrete fractures in porous media",2018,"Inverse Problems in Science and Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014535003&doi=10.1080%2f17415977.2017.1290087&partnerID=40&md5=a9fb4f266e55ff1a1aa26c092b7d8c39","Faults and geological barriers can drastically affect the flow patterns in porous media. Such fractures can be modelled as interfaces that interact with the surrounding matrix. We propose a new technique for the estimation of the location and hydrogeological properties of a small number of large fractures in a porous medium from given distributed pressure or flow data. At each iteration, the algorithm builds a short list of candidates by comparing fracture indicators. These indicators quantify at the first order the decrease of a data misfit function; they are cheap to compute. Then, the best candidate is picked up by minimization of the objective function for each candidate. Optimally driven by the fit to the data, the approach has the great advantage of not requiring remeshing, nor shape derivation. The stability of the algorithm is shown on a series of numerical examples representative of typical situations. © 2017 Informa UK Limited, trading as Taylor & Francis Group.","Adaptive parameterization; fault and barrier; flow in porous media; fractured porous media; inverse problem","Fracture; Inverse problems; Iterative methods; Adaptive parameterization; Discrete fractures; Flow in porous media; Fractured porous media; Geological barriers; Hydrogeological properties; Objective functions; Surrounding matrix; Porous materials",2-s2.0-85014535003
"Rostamian M., Shahrezaee A.","A meshless method for solving 1D time-dependent heat source problem",2018,"Inverse Problems in Science and Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018162104&doi=10.1080%2f17415977.2017.1309396&partnerID=40&md5=159c6e214ecd507d462919280b203ce9","A novel meshless numerical procedure based on the method of fundamental solutions (MFS) and the heat polynomials is proposed for recovering a time-dependent heat source and the boundary data simultaneously in an inverse heat conduction problem (IHCP). We will transform the problem into a homogeneous IHCP and initial value problems for the first-order ordinary differential equation. An improved method of MFS is used to solve the IHCP and a finite difference method is applied for solving the initial value problems. The advantage of applying the proposed meshless numerical scheme is producing the shape functions which provide the important delta function property to ensure that the essential conditions are fulfilled. Numerical experiments for some examples are provided to show the effectiveness of the proposed algorithm. © 2017 Informa UK Limited, trading as Taylor & Francis Group.","boundary data; finite difference method; fundamental solutions; heat polynomial; heat source; Inverse heat conduction problem; method of fundamental solutions; ordinary differential equation; shape functions; Theta method","Delta functions; Differential equations; Finite difference method; Heat conduction; Initial value problems; Numerical methods; Ordinary differential equations; Polynomials; Boundary data; Fundamental solutions; Heat sources; Inverse heat conduction problem; Method of fundamental solutions; Shape functions; Theta method; Inverse problems",2-s2.0-85018162104
"Khaloo A., Lattanzi D., Cunningham K., Dell’Andrea R., Riley M.","Unmanned aerial vehicle inspection of the Placer River Trail Bridge through image-based 3D modelling",2018,"Structure and Infrastructure Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019736693&doi=10.1080%2f15732479.2017.1330891&partnerID=40&md5=d2c980eddbcb1d2a6a1996a1d0d36c75","Unmanned aerial vehicles (UAV) are now a viable option for augmenting bridge inspections. Utilising an integrated combination of a UAV and computer vision can decrease costs, expedite inspections and facilitate bridge access. Any such inspection must consider the design of the UAV, the choice of cameras, data acquisition, geometrical resolution, safety regulations and pilot protocols. The Placer River Trail Bridge in Alaska recently served as a test bed for a UAV inspection methodology that integrates these considerations. The end goal was to produce a three-dimensional (3D) model of the bridge using UAV-captured images and a hierarchical Dense Structure-from-Motion algorithm. To maximise the quality of the model and its benefits to inspectors, this goal guided UAV design and mission planning. The resulting inspection methodology integrates UAV design, data capture and data analysis together to provide an optimised 3D model. This model provides inspection documentation while enabling the monitoring of defects. The developed methodology is presented herein, as well as analyses of the 3D models. The results are compared against models generated through laser scanning. The findings demonstrate that the UAV inspection methodology provided superior 3D models with the accuracy to resolve defects and support the needs of infrastructure managers. © 2017 Informa UK Limited, trading as Taylor & Francis Group.","3D modelling; Bridge inspection; computer vision; light detection and ranging; photogrammetry; point clouds; robotics; unmanned aerial vehicle","Aircraft detection; Computer vision; Data acquisition; Defects; Inspection; Optical radar; Photogrammetry; Robotics; Unmanned aerial vehicles (UAV); Vehicles; 3D modelling; Bridge inspection; Geometrical resolution; Infrastructure managers; Light detection and ranging; Point cloud; Safety regulations; Three dimensional (3-D) modeling; Three dimensional computer graphics",2-s2.0-85019736693
"Azazi H.Z., Ahmed S.M., Lashine A.E.","Single-stage three-phase boost power factor correction circuit for AC–DC converter",2018,"International Journal of Electronics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020744761&doi=10.1080%2f00207217.2017.1335800&partnerID=40&md5=b650ce51f335688ddd435d7fb0f0281c","This article presents a single-stage three-phase power factor correction (PFC) circuit for AC-to-DC converter using a single-switch boost regulator, leading to improve the input power factor (PF), reducing the input current harmonics and decreasing the number of required active switches. A novel PFC control strategy which is characterised as a simple and low-cost control circuit was adopted, for achieving a good dynamic performance, unity input PF, and minimising the harmonic contents of the input current, at which it can be applied to low/medium power converters. A detailed analytical, simulation and experimental studies were therefore conducted. The effectiveness of the proposed controller algorithm is validated by the simulation results, which were carried out using MATLAB/SIMULINK environment. The proposed system is built and tested in the laboratory using DSP-DS1104 digital control board for an inductive load. The results revealed that the total harmonic distortion in the supply current was very low. Finally, a good agreement between simulation and experimental results was achieved. © 2017 Informa UK Limited, trading as Taylor & Francis Group.","AC–DC converter; boost regulator; power factor correction; single-stage","Digital control systems; Electric power factor correction; Harmonic analysis; MATLAB; Rectifying circuits; Timing circuits; Boost regulators; DC converter; MATLAB/Simulink environment; Power factor correction circuits; Power factor corrections; Single stage; Three phase power factor correction; Total harmonic distortion (THD); Power converters",2-s2.0-85020744761
"Cox T.F., Arnold D.S.","Simple components",2018,"Journal of Applied Statistics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006163511&doi=10.1080%2f02664763.2016.1268104&partnerID=40&md5=fffaf1932630f8d7ee299fe8f8b3476d","Interpretation of principal components is difficult due to their weights (loadings, coefficients) being of various sizes. Whereas very small weights or very large weights can give clear indication of the importance of particular variables, weights that are neither large nor small (‘grey area’ weights) are problematical. This is a particular problem in the fast moving goods industries where a lot of multivariate panel data are collected on products. These panel data are subjected to univariate analyses and multivariate analyses where principal components (PCs) are key to the interpretation of the data. Several authors have suggested alternatives to PCs, seeking simplified components such as sparse PCs. Here components, termed simple components (SCs), are sought in conjunction with Thurstonian criteria that a component should have only a few variables highly weighted on it and each variable should be weighted heavily on just a few components. An algorithm is presented that finds SCs efficiently. Simple components are found for panel data consisting of the responses to a questionnaire on efficacy and other features of deodorants. It is shown that five SCs can explain an amount of variation within the data comparable to that explained by the PCs, but with easier interpretation. © 2016 Informa UK Limited, trading as Taylor & Francis Group.","Factor analysis; fast moving goods industry; Hausmann weights; principal components; sensory data",,2-s2.0-85006163511
"Pravilovic S., Appice A., Malerba D.","Leveraging correlation across space and time to interpolate geophysical data via CoKriging",2018,"International Journal of Geographical Information Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029903021&doi=10.1080%2f13658816.2017.1381338&partnerID=40&md5=65fb6d22e0f24ca0bcde3c9ecabcc7ad","Managing geophysical data generated by emerging spatiotemporal data sources (e.g. geosensor networks) presents a growing challenge to Geographic Information System science. The presence of correlation poses difficulties with respect to traditional spatial data analysis. This paper describes a novel spatiotemporal analytical scheme that allows us to yield a characterization of correlation in geophysical data along the spatial and temporal dimensions. We resort to a multivariate statistical model, namely CoKriging, in order to derive accurate spatiotemporal interpolation models. These predict unknown data by utilizing not only their own geosensor values at the same time, but also information from near past data. We use a window-based computation methodology that leverages the power of temporal correlation in a spatial modeling phase. This is done by also fitting the computed interpolation model to data which may change over time. In an assessment, using various geophysical data sets, we show that the presented algorithm is often able to deal with both spatial and temporal correlations. This helps to gain accuracy during the interpolation phase, compared to spatial and spatiotemporal competitors. Specifically, we evaluate the efficacy of the interpolation phase by using established machine-learning metrics (i.e. root mean squared error, Akaike information criterion and computation time). © 2017 Informa UK Limited, trading as Taylor & Francis Group.","CoKriging; interpolation; multivariate analysis; Spatiotemporal data",,2-s2.0-85029903021
"Erchiqui F.","Application of genetic and simulated annealing algorithms for optimization of infrared heating stage in thermoforming process",2018,"Applied Thermal Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029912457&doi=10.1016%2fj.applthermaleng.2017.09.102&partnerID=40&md5=a9c37aaec58f458bca68e598d0e05134","In thermoforming, the shaping of the thermoplastics takes place essentially in two principals steps: infrared heating (IR) in an oven and then shaping the desired product using a mold of given geometry. The quality of the molded product depends directly on the temperature distribution in the material during infrared heating and indirectly on the temperature and optical properties of the radiant zones. To ensure that the energy flux intercepted by the thermoplastic sheet is uniform, we propose the application of two meta-heuristic algorithms MA (Simulated annealing algorithm) and GA (Genetic algorithms) to detect, from a fixed and random set of temperatures of the radiant zones of oven, the best temperatures that must be assigned to the heating zones. For numerical heating analysis, the nonlinear heat conduction problem is solved by a specific 3D volumetric enthalpy-based finite element method. The view factor is estimated by a semi-analytical method. An example of optimization of the heating stage of the high-density polyethylene (HDPE) grade sheet is presented. © 2017 Elsevier Ltd","Finite element; Genetic algorithm; Infrared heating; Optimization; Simulated annealing; Thermoforming","Finite element method; Genetic algorithms; Heat conduction; Heating; Heuristic algorithms; High density polyethylenes; Infrared heating; Numerical methods; Optical properties; Ovens; Reinforced plastics; Simulated annealing; Thermoforming; Genetic and simulated annealing algorithms; Heating analysis; High density polyethylene(HDPE); Meta heuristic algorithm; Nonlinear heat conduction problem; Semi-analytical methods; Simulated annealing algorithms; Volumetric enthalpy; Optimization",2-s2.0-85029912457
"Rabbani M., Heidari R., Farrokhi-Asl H., Rahimi N.","Using metaheuristic algorithms to solve a multi-objective industrial hazardous waste location-routing problem considering incompatible waste types",2018,"Journal of Cleaner Production",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031939585&doi=10.1016%2fj.jclepro.2017.09.029&partnerID=40&md5=a9b88e9241f2a2501af8a69a01e5aeb7","Rapid progress in technology is a primary cause of acceleration in the rate of the industrial hazardous waste generation all over the world. Management of hazardous waste has magnetized researcher's attention because of its considerable impacts on the economy, ecology, and the environment. In this regard, this paper addresses a new industrial hazardous waste location-routing problem by putting emphasis on some new aspects in its formulation such as considering restriction about the incompatibility between some kinds of wastes and incorporating routing decisions into the model. Simultaneously minimization of three significant criteria, including total cost, total transportation risk of hazardous waste related to population exposure, and site risk persuades authors to implement two multi-objective evolutionary algorithms, Nondominated Sorting Genetic Algorithm (NSGA-II) and Multi-Objective Particle Swarm Optimization (MOPSO) for tackling the problem. The results obtained from experiments on several problem instances confirm the superiority of NSGA-II over MOPSO in terms of most of the evaluation metrics. Therefore, the significance of the paper is firstly the novelty of the model, and secondly, the comparison of two solution methods allows for the identification of the method resulting in the best results. © 2017 Elsevier Ltd","Hazardous materials; Industrial hazardous waste; Location-routing problem; Multiobjective optimization","Genetic algorithms; Hazardous materials; Hazards; Location; Multiobjective optimization; Optimization; Particle swarm optimization (PSO); Routing algorithms; Screening; Waste management; Industrial hazardous waste; Location routing problem; Meta heuristic algorithm; Multi objective evolutionary algorithms; Multi objective particle swarm optimization; Non dominated sorting genetic algorithm (NSGA II); Population exposure; Transportation risks; Evolutionary algorithms",2-s2.0-85031939585
"Mobin M., Mousavi S.M., Komaki M., Tavana M.","A hybrid desirability function approach for tuning parameters in evolutionary optimization algorithms",2018,"Measurement: Journal of the International Measurement Confederation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030866702&doi=10.1016%2fj.measurement.2017.10.009&partnerID=40&md5=046f895a64bbbe4cb9b3c02e60d1a4cf","Evolutionary algorithms are optimization methods commonly used to solve engineering and business optimization problems. The parameters in evolutionary algorithm must be perfectly tuned in a way that the optimization algorithm solves the optimization problems efficiently and effectively. Several parameter tuning approaches with a single performance metric have been proposed in the literature. However, simultaneous consideration of multiple performance metrics could provide the optimal setting for the parameters in the evolutionary algorithm. In this research, a new hybrid parameter tuning approach is proposed to simultaneously optimize the performance metrics of the evolutionary optimization algorithm while it is used in solving an optimization problem. The proposed hybrid approach provides the optimal value of parameters of the evolutionary optimization algorithm. The proposed approach is the first parameter tuning approach in the evolutionary optimization algorithm which simultaneously optimizes all performance metrics of the evolutionary optimization algorithm. To do this, a full factorial design of experiment is used to find the significant parameters of the evolutionary optimization algorithm, as well as an approximate equation for each performance metric. The individual and composite desirability function approaches are then proposed to provide the optimal setting for the parameters of the evolutionary optimization algorithm. For the first time, we use the desirability function approach to find an optimal level for the parameters in the evolutionary optimization algorithm. To show the real application of the proposed parameter tuning approach, we consider two multi-objective evolutionary algorithms, i.e., a multi-objective particle swarm optimization algorithm (MOPSO) and a fast non-dominated sorting genetic algorithm (NSGA-III) and solve a single machine scheduling problem. We demonstrate the applicability and efficiency of the proposed hybrid approach in providing the optimal values of all parameters of the evolutionary optimization algorithms to optimize their performance in solving an optimization problem. © 2017","Desirability function; Evolutionary algorithms; Fast non-dominated sorting genetic algorithm; Multi-objective particle swarm optimization; Multi-objective single machine scheduling; Parameter tuning","Design of experiments; Genetic algorithms; Machinery; Multiobjective optimization; Optimal systems; Optimization; Parameter estimation; Particle swarm optimization (PSO); Problem solving; Scheduling; Scheduling algorithms; Screening; Desirability function; Multi objective particle swarm optimization; Non- dominated sorting genetic algorithms; Parameter-tuning; Single-machine scheduling; Evolutionary algorithms",2-s2.0-85030866702
"Singh K., Jain A., Mittal A., Yadav V., Singh A.A., Jain A.K., Gupta M.","Optimum transistor sizing of CMOS logic circuits using logical effort theory and evolutionary algorithms",2018,"Integration, the VLSI Journal",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028919642&doi=10.1016%2fj.vlsi.2017.08.003&partnerID=40&md5=01fb5bc0826573c3fa0d3805e9760ddf","Most existing methodologies use either Logical Effort (LE) theory or stand-alone optimization algorithms for automated transistor sizing of CMOS logic circuits. LE theory optimizes a logic circuit only with respect to speed while it completely ignores power and area. Whereas heuristic algorithms when used as a stand-alone approach for optimization lead to huge computational effort since there is no predefined technique to apply constraints on transistor sizes in order to limit the design space for target specifications. The problem has been resolved in this paper by utilizing delay sensitivity factor based on LE theory proposed by Alioto et. al. [1] for estimating the highest operating speed of a logic circuit and determining the upper bound on the size of transistors. Recently proposed heuristic algorithms viz. Interior Search Algorithm (ISA) [2] and Gravitational Search Algorithm (GSA) [3] have been utilized further to converge towards minimum power-delay-area product (PDAP). Simulation results for various test circuits indicate upto 35.1% and 63.8% improvement in power-delay product (PDP) and PDAP respectively in 130 nm/1.2 V TSMC CMOS technology. PVT analysis and Monte Carlo simulations have been used to further validate the effectiveness of the proposed methodology. © 2017 Elsevier B.V.","CMOS logic circuits; Digital VLSI; Heuristic algorithms; Logical effort theory; Optimization; Power-delay-area product","CMOS integrated circuits; Computation theory; Delay circuits; Evolutionary algorithms; Heuristic algorithms; Intelligent systems; Learning algorithms; Logic circuits; Monte Carlo methods; Optimization; Timing circuits; Transistors; CMOS logic circuits; Computational effort; Digital VLSI; Gravitational search algorithm (GSA); Logical effort theory; Optimization algorithms; Power delays; Target specifications; Computer circuits",2-s2.0-85028919642
"Jain A., Chinta S., Tripathy B.K.","Stabilizing rough sets based clustering algorithms using firefly algorithm over image datasets",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028391514&doi=10.1007%2f978-3-319-63645-0_36&partnerID=40&md5=1e145c49eccbfbd5d04e811f412e4b3c","Rough Intuitionistic Fuzzy C-Means Algorithm is a combination of Fuzzy Sets, Rough Sets and Intuitionistic Fuzzy Sets. This algorithm provides high quality clustering over numeric datasets. However, RIFCM is highly inconsistent over Image datasets. In this paper, we combine RIFCM with Firefly Algorithm. Firefly algorithm is a meta-heuristic bio-inspired algorithm which mimics the behavior of fireflies. Our experimental results prove that using Firefly algorithm before RIFCM lends stability to the clustering output and considerably reduces the number of iterations required for convergence. © Springer International Publishing AG 2018.","D-index; Data clustering; DB-index; Firefly algorithm; Rough set","Bioluminescence; Copying; Fire protection; Fuzzy clustering; Fuzzy sets; Intelligent systems; Optimization; Rough set theory; Bio-inspired algorithms; Data clustering; DB-index; Firefly algorithms; Image datasets; Intuitionistic fuzzy C- means algorithms; Intuitionistic fuzzy sets; Number of iterations; Clustering algorithms",2-s2.0-85028391514
"Fahimnia B., Davarzani H., Eshragh A.","Planning of complex supply chains: A performance comparison of three meta-heuristic algorithms",2018,"Computers and Operations Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964958172&doi=10.1016%2fj.cor.2015.10.008&partnerID=40&md5=f4b914e0ab3d97a13241e316cea2ed10","Businesses have more complex supply chains than ever before. Many supply chain planning efforts result in sizable and often nonlinear optimization problems that are difficult to solve using standard solution methods. Meta-heuristic and heuristic solution methods have been developed and applied to tackle such modeling complexities. This paper aims to compare and analyze the performance of three meta-heuristic algorithms in solving a nonlinear green supply chain planning problem. A tactical planning model is presented that aims to balance the economic and emissions performance of the supply chain. Utilizing data from an Australian clothing manufacturer, three meta-heuristic algorithms including Genetic Algorithm, Simulated Annealing and Cross-Entropy are adopted to find solutions to this problem. Discussions on the key characteristics of these algorithms and comparative analysis of the numerical results provide some modeling insights and practical implications. In particular, we find that (1) a Cross-Entropy method outperforms the two popular meta-heuristic algorithms in both computation time and solution quality, and (2) Simulated Annealing may produce better results in a time-restricted comparison due to its rapid initial convergence speed. © 2015 Elsevier Ltd","Case study; Cross-Entropy; Genetic Algorithm; Green supply chain management; Meta-heuristics; Optimization; Simulated Annealing; Supply chain planning","Algorithms; Genetic algorithms; Heuristic methods; Nonlinear programming; Optimization; Simulated annealing; Supply chain management; Cross entropy; Emissions performance; Green supply chain management; Meta heuristic algorithm; Meta heuristics; Non-linear optimization problems; Performance comparison; Supply chain planning; Heuristic algorithms",2-s2.0-84964958172
"Fernández Anta A., Georgiou C., Kowalski D.R., Zavou E.","Competitive analysis of fundamental scheduling algorithms on a fault-prone machine and the impact of resource augmentation",2018,"Future Generation Computer Systems",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84977480329&doi=10.1016%2fj.future.2016.05.042&partnerID=40&md5=fed36eff1b004d3757e12e7e14143d8b","Reliable task execution in machines that are prone to unpredictable crashes and restarts is both challenging and of high importance, but not much work exists on the analysis of such systems. We consider the online version of the problem, with tasks arriving over time at a single machine under worst-case assumptions. We analyze the fault-tolerant properties of four popular scheduling algorithms: Longest In System (LIS), Shortest In System (SIS), Largest Processing Time (LPT) and Shortest Processing Time (SPT). We use three metrics for the evaluation and comparison of their competitive performance, namely, completed load, pending load and latency. We also investigate the effect of resource augmentation in their performance, by increasing the speed of the machine. Hence, we compare the behavior of the algorithms for different speed intervals and show that there is no clear winner with respect to all the three considered metrics. While SPT is the only algorithm that achieves competitiveness on completed load for small speed, LIS is the only one that achieves competitiveness on latency (for large enough speed). © 2016 Elsevier B.V.","Competitive analysis; Different task processing times; Failures; Online algorithms; Resource augmentation; Scheduling","Algorithms; Competition; Failure (mechanical); Scheduling; Competitive analysis; Competitive performance; Crashes and restarts; Largest processing time; On-line algorithms; Resource augmentation; Shortest Processing Time; Task-processing; Scheduling algorithms",2-s2.0-84977480329
"Fong S., Deb S., Yang X.-S.","How meta-heuristic algorithms contribute to deep learning in the hype of big data analytics",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026775964&doi=10.1007%2f978-981-10-3373-5_1&partnerID=40&md5=ad6fcb2e35de3e2aa77873ed8dc3d955","Deep learning (DL) is one of the most emerging types of contemporary machine learning techniques that mimic the cognitive patterns of animal visual cortex to learn the new abstract features automatically by deep and hierarchical layers. DL is believed to be a suitable tool so far for extracting insights from very huge volume of so-called big data. Nevertheless, one of the three “V” or big data is velocity that implies the learning has to be incremental as data are accumulating up rapidly. DL must be fast and accurate. By the technical design of DL, it is extended from feed-forward artificial neural network with many multi-hidden layers of neurons called deep neural network (DNN). In the training process of DNN, it has certain inefficiency due to very long training time required. Obtaining the most accurate DNN within a reasonable run-time is a challenge, given there are potentially many parameters in the DNN model configuration and high dimensionality of the feature space in the training dataset. Meta-heuristic has a history of optimizing machine learning models successfully. How well meta-heuristic could be used to optimize DL in the context of big data analytics is a thematic topic which we pondered on in this paper. As a position paper, we review the recent advances of applying meta-heuristics on DL, discuss about their pros and cons and point out some feasible research directions for bridging the gaps between meta-heuristics and DL. © Springer Nature Singapore Pte Ltd. 2018.","Algorithm design; Deep learning; Meta-heuristic algorithm; Nature-inspired computing algorithms; Neural network training","Artificial intelligence; Computation theory; Data mining; Deep learning; Deep neural networks; Heuristic algorithms; Intelligent computing; Learning algorithms; Learning systems; Neural networks; Optimization; Algorithm design; Feed-forward artificial neural networks; High dimensionality; Machine learning models; Machine learning techniques; Meta heuristic algorithm; Nature inspired computing; Neural network training; Big data",2-s2.0-85026775964
"He C., Liang T., Wei S., Meng W.","Performance analysis of routing algorithms based on intelligent optimization algorithms in cluster Ad Hoc network",2018,"Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031287860&doi=10.1007%2f978-3-319-66625-9_13&partnerID=40&md5=f8c7040b4b0d39993e9d66467350d4ab","In this paper, a mobile cluster Ad Hoc network model is presented for scenarios with large nodes number and high mobility. Intelligent optimization algorithms perform better than traditional routing algorithms in such scenarios but papers about performance comparison of these algorithms are rare. So we pick the most widely used intelligent optimization algorithms ACO, PSO and GA and describe the routing search process of these three algorithms in detail. Then we analyze performance of them together with AODV for comparison. Simulation results show that ACO, PSO and GA algorithms perform better than AODV in average throughput, packet loss rate, success link rate and average link hop. © 2018, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.","Ad Hoc network; Cluster; Intelligent optimization; Performance analysis","Ad hoc networks; Ant colony optimization; Artificial intelligence; Genetic algorithms; Mobile ad hoc networks; Optimization; Particle swarm optimization (PSO); Routing algorithms; Ad hoc network models; Average throughput; Cluster; Intelligent optimization; Intelligent optimization algorithm; Packet loss rates; Performance analysis; Performance comparison; Clustering algorithms",2-s2.0-85031287860
"Jannu S., Dara S., Kumar K.K., Bandari S.","Efficient algorithms for hotspot problem in wireless sensor networks: Gravitational search algorithm",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032668841&doi=10.1007%2f978-3-319-68385-0_4&partnerID=40&md5=71915ff7a7e3a93c2f628343c8d245d9","Energy conservation of sensor nodes (SNs) is the major concern of wireless sensor networks (WSNs) as those are operated by small batteries with a limited power. In a clustered WSN, cluster heads (CHs) collects local information such as temperature, humidity, pressure etc. from the member SNs aggregate it and send to the sink through few intermediate CHs. Here, the CHs that are closer to the sink are over burdened as they are responsible for forwarding more number of packets than the farther CHs that tends to exhaust their energy quickly. This results in network partitioning and this problem well known hot spot or energy hole problem. In this paper, a Gravitational Search Algorithm (GSA) approach based clustering and routing algorithms are proposed to address the hot spot problem. In clustering, we select few efficient SNs as CHs from the normal SNs with respect to certain cost function. We design an algorithm for CH selection based on GSA and assign the remaining SNs to the CHs based on another derived cost function. Then, a GSA based routing algorithm is presented with respect to the routing cost function. These algorithms are intended to develop to enhance the lifetime of network with efficient encoding schemes of GSA. The proposed algorithms are simulated on various scenarios of WSNs by varying number of SNs. The results of the proposed algorithms are compared with few well known algorithms to show the supremacy in terms network lifetime, residual energy and number of alive SNs. © Springer International Publishing AG 2018.",,"Cost functions; Costs; Intelligent systems; Learning algorithms; Sensor nodes; Wireless sensor networks; Efficient encoding; Energy-hole problems; Gravitational search algorithm (GSA); Gravitational search algorithms; Lifetime of networks; Local information; Network lifetime; Wireless sensor network (WSNs); Clustering algorithms",2-s2.0-85032668841
"Pudaruth S., Soyjaudah K.M.S., Gunputh R.P.","Markov Chain monte carlo methods and evolutionary algorithms for automatic feature selection from legal documents",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032705319&doi=10.1007%2f978-3-319-68385-0_12&partnerID=40&md5=023f8dfa60faf8bbec4c6dad9cdfc584","In this paper, we present three different approaches for feature selection, starting from a naïve Markov Chain Monte Carlo random walk algorithm to more refined methods like simulated annealing and genetic algorithms. It is typical for textual data to have thousands of dimensions in their feature space which makes feature selection a crucial phase before the final classification. Classification of legal documents into eight categories was performed via a simple document similarity measure based on term frequency and the nearest neighbour concept. With an average success rate of 76.4%, the random walk algorithm not only performed better than the simulated annealing and genetic algorithms but also matched the accuracy of support vector machines. Although these methods have commonly been used for selecting appropriate features in other fields, their use in text categorisation have not been satisfactorily investigated. And, to our knowledge, this is the first work which investigates their use in the legal domain. This generic text classification framework can further be enhanced by using an active learning methodology for the selection of training samples rather than following a passive learning approach. © Springer International Publishing AG 2018.","Court judgements; Genetic algorithm; Legal text categorisation; Monte carlo; Random walk; Simulated annealing","Authentication; Chains; Classification (of information); Evolutionary algorithms; Feature extraction; Genetic algorithms; Information retrieval systems; Intelligent systems; Markov processes; Random processes; Simulated annealing; Text processing; Automatic feature selection; Court judgement; Legal texts; Markov chain Monte Carlo method; Markov Chain Monte-Carlo; Random Walk; Random walk algorithms; Text classification; Monte Carlo methods",2-s2.0-85032705319
"Gomes W.J.S., Beck A.T., Lopez R.H., Miguel L.F.F.","A probabilistic metric for comparing metaheuristic optimization algorithms",2018,"Structural Safety",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032033855&doi=10.1016%2fj.strusafe.2017.10.006&partnerID=40&md5=9fb8db250fb1fc45b17eb76f7ee0fcd5","The evolution of metaheuristic optimization algorithms towards identification of a global minimum is based on random numbers, making each run unique. Comparing the performance of different algorithms hence requires several runs, and some statistical metric of the results. Mean, standard deviation, best and worst values metrics have been used with this purpose. In this paper, a single probabilistic metric is proposed for comparing metaheuristic optimization algorithms. It is based on the idea of population interference, and yields the probability that a given algorithm produces a smaller (global?) minimum than an alternative algorithm, in a single run. Three benchmark example problems and four optimization algorithms are employed to demonstrate that the proposed metric is better than usual statistics such as mean, standard deviation, best and worst values obtained over several runs. The proposed metric actually quantifies how much better a given algorithm is, in comparison to an alternative algorithm. Statements about the superiority of an algorithm can also be made in consideration of the number of algorithm runs and the number of objective function evaluations allowed in each run. © 2017 Elsevier Ltd","Evolutionary algorithms; Metaheuristic; Optimization algorithms; Performance metric; Population interference","Evolutionary algorithms; Global optimization; Statistics; Alternative algorithms; Global minima; Meta-heuristic optimizations; Metaheuristic; Optimization algorithms; Performance metrices; Random Numbers; Standard deviation; Optimization",2-s2.0-85032033855
"Tchapet Njafa J.-P., Nana Engo S.G.","Quantum associative memory with linear and non-linear algorithms for the diagnosis of some tropical diseases",2018,"Neural Networks",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030863640&doi=10.1016%2fj.neunet.2017.09.002&partnerID=40&md5=26c523926082719558e4926d61215bf1","This paper presents the QAMDiagnos, a model of Quantum Associative Memory (QAM) that can be a helpful tool for medical staff without experience or laboratory facilities, for the diagnosis of four tropical diseases (malaria, typhoid fever, yellow fever and dengue) which have several similar signs and symptoms. The memory can distinguish a single infection from a polyinfection. Our model is a combination of the improved versions of the original linear quantum retrieving algorithm proposed by Ventura and the non-linear quantum search algorithm of Abrams and Lloyd. From the given simulation results, it appears that the efficiency of recognition is good when particular signs and symptoms of a disease are inserted given that the linear algorithm is the main algorithm. The non-linear algorithm helps confirm or correct the diagnosis or give some advice to the medical staff for the treatment. So, our QAMDiagnos that has a friendly graphical user interface for desktop and smart-phone is a sensitive and a low-cost diagnostic tool that enables rapid and accurate diagnosis of four tropical diseases. © 2017 Elsevier Ltd","Linear search algorithm; Non-linear search algorithm; Quantum associative memory; Quantum search algorithm; Tropical diseases","Associative processing; Associative storage; Graphical user interfaces; Learning algorithms; Memory architecture; mHealth; Smartphones; Tropics; User interfaces; Associative memory; Linear search algorithms; Non linear; Quantum search algorithm; Tropical disease; Diagnosis",2-s2.0-85030863640
"Rasel M.K., Lee Y.-K.","An Efficient Subgraph Compression-Based Technique for Reducing the I/O Cost of Join-Based Graph Mining Algorithms",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032469875&doi=10.1007%2f978-981-10-6520-0_9&partnerID=40&md5=5b579ed8f235c40220c5e844ecdd4da6","Many join-based graph mining algorithms such as triangle listing and clique enumeration output a large size of intermediate or final data that sometimes dominates the mining cost. A few researches highlighted on the size of output data. However, those techniques have limitation that they are highly specific to their corresponding graph mining algorithms. In this paper, through the careful observations of the output patterns, we propose a general compression solution that can be applied to any join-based graph algorithm. It first categorizes the overlapping and non-overlapping vertices in a resultant subgraph set of a join-based graph mining algorithm. Then it compresses the output data by removing the redundancy from the overlapping vertices and by encoding the non-overlapping vertices using a non-aligned hybrid bit vector compression technique. Our proposed technique performs the compression on-the-fly and can easily be adopted by the join-based graph mining algorithms. Experiments on the real datasets show that our proposed technique, which is adopted in a triangle listing algorithm, reduces the size of the output data and the running time by three times and more than two times, respectively. The proposed technique also reduces the I/O cost for a maximal clique listing algorithm. © 2018, Springer Nature Singapore Pte Ltd.","Bitmap compression; Graph I/O compression; Graph mining algorithms","Cost reduction; Costs; Compression solutions; Compression techniques; Graph algorithms; Graph mining; Listing algorithms; Maximal clique; Real data sets; Running time; Data mining",2-s2.0-85032469875
"El-Ghandour H.A., Elbeltagi E.","Comparison of Five Evolutionary Algorithms for Optimization of Water Distribution Networks",2018,"Journal of Computing in Civil Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030482384&doi=10.1061%2f%28ASCE%29CP.1943-5487.0000717&partnerID=40&md5=7990d5b3c30288a386db55fc55da8fd8","In this paper, five models based on evolutionary algorithms (EAs) are introduced and compared for the optimization of the design and rehabilitation of water distribution networks. These EAs include the genetic algorithm (GA), the particle swarm optimization (PSO), the ant colony optimization (ACO), the memetic algorithm (MA), and the modified shuffled frog leaping algorithm (SFLA). A brief description of each algorithm is introduced to explain its application. A methodology is applied for the rigorous comparison of the models in terms of the optimum solution obtained, the number of objective function evaluations corresponding to the optimum solution, the effect of starting seeds on the optimum solution, and the quality of the results. A statistical analysis is carried out and then an efficiency-rate metric is determined to assess the performance of each model. The five EAs are applied to two popular benchmark networks, the two-loop network and the New York tunnels. In addition, the models are applied to a real water distribution network of El-Mostakbal City, Egypt. The results show that the PSO outperformed the other evolutionary algorithms in terms of the efficiency-rate metric and the rapid convergence to the best solution. © 2017 American Society of Civil Engineers.","Ant colony; Evolutionary algorithms; Genetic algorithms; Memetic algorithms; Optimal design and rehabilitation; Optimization; Particle swarm; Shuffled frog leaping; Water distribution networks","Ant colony optimization; Artificial intelligence; Efficiency; Electric power distribution; Genetic algorithms; Optimization; Particle swarm optimization (PSO); Quality control; Water distribution systems; Water supply systems; Ant colonies; Memetic algorithms; Optimal design; Particle swarm; Shuffled frog leaping; Water distribution networks; Evolutionary algorithms",2-s2.0-85030482384
"Yang L., Li B., Zhou X., Kang Y.","Micro-blog friend recommendation algorithms based on content and social relationship",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031400799&doi=10.1007%2f978-981-10-3187-8_12&partnerID=40&md5=85d1a02bf08550e8528b240d5914c6dc","First, this paper researches the micro-blog information push, which leads to the concept of user’s friends, expounds the reason and meaning of friends recommendation algorithm, and introduces its current research situation, the paper has made the detailed introduction and analysis of existing algorithms and made a comprehensive comparison of the advantages and disadvantages of them. Then we make a recommendation of the micro-blog friend recommendation algorithms, which has two broad categories and three types: the recommendation algorithm based on content, the topology recommendation algorithm based on social relations and the filtering recommendation algorithm. Through the analysis of existing micro-blog friends recommendation algorithm, we represent the process of the algorithm and emphatically elaborated the implementation process, and finally we work out the Reasonable weighting of the three recommendation algorithm, get a sequence of recommended as a result, improved the algorithms, and reached a more comprehensive recommendation method. The improved algorithm could be a more effective way of potentially friends recommended for users. © Springer Nature Singapore Pte Ltd. 2018.","Algorithm; Friend recommendation; Information push; Micro-blog; Social relationship","Algorithms; Computation theory; Social aspects; Comprehensive comparisons; Current research situation; Friend recommendations; Implementation process; Information push; Micro-blog; Recommendation algorithms; Social relationships; Blogs",2-s2.0-85031400799
"Montiel O., Sepúlveda R., Rubio Y.","Speeding up quantum genetic algorithms in matlab through the quack_GPU V1",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030709881&doi=10.1007%2f978-3-319-67137-6_17&partnerID=40&md5=e8c542a9e8ec4d52652be30d1b0a06aa","Quantum computing is inspired in quantum mechanical phenomena and uses superposition and entanglement to process data at very high speeds outperforming conventional computers on some tasks. At present, the access for testing algorithms in commercial quantum computers is too expensive for most institutions; hence, it is very important to have alternatives for testing quantum algorithms. In this paper, we present the results obtained when optimizing a two variables multimodal function when it was optimized through the Quack_GPU v1, which is a modification of the original software Quack! We show that it is possible to obtain speedups up to 8.4× using a Graphic Processing Unit (GPU) computer card with thousands of cores, saving hours of processing time. Performance comparative results of the Quack! vs. the Quack_GPU are presented. © Springer International Publishing AG 2018.","High-performance; QGA; Quantum genetic algorithm","Genetic algorithms; Graphics processing unit; MATLAB; Quantum computers; Quantum theory; Conventional computers; Graphic processing unit(GPU); High-performance; Multi modal function; Quantum algorithms; Quantum Computing; Quantum genetic algorithm; Quantum mechanical; Quantum entanglement",2-s2.0-85030709881
"Popescu D.A., Bold N., Popescu A.I.","The generation of tests of knowledge check using genetic algorithms",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031397290&doi=10.1007%2f978-3-319-62524-9_3&partnerID=40&md5=7f6406c267100bd28fa6e0e92c8a9b57","In this paper, we will present a modality for generating knowledge-check tests using questions characterized by keywords. The obtained tests have certain restrictions regarding the keywords labeling the questions. These restrictions will be defined in the paper. The test generation will be made using genetic algorithms, whose chromosomes will be considered the tests and genes will be considered questions. At the end of the paper some results obtained with the algorithm implemented in Java programming language will be presented. © Springer International Publishing AG 2018.","Algorithm; Assessment; Chromosomes; Genetic; Learning","Algorithms; Chromosomes; Computer programming; Genetic algorithms; Soft computing; Assessment; Genetic; Learning; Test generations; Testing",2-s2.0-85031397290
"Stolfi D.H., Alba E.","Epigenetic algorithms: A New way of building GAs based on epigenetics",2018,"Information Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030842751&doi=10.1016%2fj.ins.2017.10.005&partnerID=40&md5=49cf01ad0ed98fd6ca69a74b8f48182d","This article presents a new set of ideas on how to build bio-inspired algorithms based on the new field of epigenetics. By analyzing this domain and extracting working computational ideas we want to offer a set of tools for the future creation of representations, operators, and search techniques that can competitively solve complex problems. To illustrate this, we describe an epiGenetic Algorithm, analyze its behavior and solve a set of instances of the multidimensional knapsack problem. Since we are in some measure opening a new line of research, we include a description of epigenetics and computational search, show their working principles and show an example algorithm solving a real problem. Our aim is to offer ideas as well as put them to work, to show that they are actually competitive, not just a nice new inspiration. © 2017 Elsevier Inc.","Bio-inspiration; Epigenetics; Evolutionary algorithm; MKP","Combinatorial optimization; Evolutionary algorithms; Bio-inspiration; Bio-inspired algorithms; Complex problems; Epigenetics; Multidimensional knapsack problems; Real problems; Search technique; Problem solving",2-s2.0-85030842751
"Popa C.-A.","Enhanced gradient descent algorithms for quaternion-valued neural networks",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031419018&doi=10.1007%2f978-3-319-62524-9_5&partnerID=40&md5=5401759ac0a6619d850e28db67b813fe","This paper proposes enhanced gradient descent learning algorithms for quaternion-valued feedforward neural networks. The quickprop, resilient backpropagation, delta-bar-delta, and SuperSAB algorithms are the most known such enhanced algorithms for the real- and complex-valued neural networks. They gave superior performances than the gradient descent algorithm, so it is natural to extend these learning methods to quaternion-valued neural networks, also. The quaternion variants of these four algorithms are presented, which are then used to learn various time series prediction applications. Experimental results show an important improvement in performance over the quaternion gradient descent. © Springer International Publishing AG 2018.","Delta-bar-delta; Quaternion-valued neural networks; Quickprop; Resilient backpropagation; SuperSAB; Time series prediction","Backpropagation; Backpropagation algorithms; Learning algorithms; Soft computing; Time series; Delta-bar-delta; Quickprop; Resilient backpropagation; SuperSAB; Time series prediction; Feedforward neural networks",2-s2.0-85031419018
"Saemi B., Hosseinabadi A.A.R., Kardgar M., Balas V.E., Ebadi H.","Nature inspired partitioning clustering algorithms: A review and analysis",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031420026&doi=10.1007%2f978-3-319-62524-9_9&partnerID=40&md5=a31e1d93a61baf65daf0e8971f013b35","Clustering algorithms are developed as a powerful tool to analyze the massive amount of data which are produced by modern applications. The main goal of these algorithms is to classify the data in clusters of objects, so that data in each cluster is similar based on specific criteria and data from two different clusters be different as much as possible. One of the most commonly used clustering methods is partitioning clustering method. So far various partitioning clustering algorithms are provided by researchers, among them inspiring the nature algorithms are the most popular used algorithms. In this paper some partitioning clustering algorithms inspiring by nature are described, and then these algorithms are compared and evaluated based on several standards such as time complexity, stability and also in terms of clustering accuracy on real and synthetic data sets. Simulation results have shown that combinational methods have good influence to increase the efficiency of algorithms and also the use of different operators can maintain population diversity and cause to reach a good answer in a reasonable time. © Springer International Publishing AG 2018.","Hybrid; Inspiring by the nature algorithms; Partitioning clustering; Stability","Cluster analysis; Convergence of numerical methods; Soft computing; Clustering accuracy; Clustering methods; Combinational methods; Hybrid; Modern applications; Partitioning clustering; Population diversity; Synthetic datasets; Clustering algorithms",2-s2.0-85031420026
"Vadamodula P., Rao M.P., Hemanth Kumar V., Radhika S., Vahini K., Vineela C., Sravani C., Tamada S.R.","Scrutiny of data sets through procedural algorithms for categorization",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021232518&doi=10.1007%2f978-981-10-3223-3_42&partnerID=40&md5=de7718e152fa85512e9fe0f673ce8b9a","This paper evaluates the selected classification algorithms for classifying thyroid datasets. The classification algorithms considered here are principle component analysis method and partial least square regression method of machine learning algorithms. After successful prediction of disease levels, these algorithms resultant output levels are compared. The analysis suggests the best classifiers for predicting the exact levels of thyroid disease. This work is a comparative study of above said algorithms on thyroid dataset firmly collected from UCI Machine Learning Repository. © Springer Nature Singapore Pte Ltd. 2018.","Machine learning algorithm; PCA; PLS; Ridge regression; Thyroid disease","Artificial intelligence; Classification (of information); Drug products; Education; Intelligent computing; Learning systems; Least squares approximations; Principal component analysis; Regression analysis; Classification algorithm; Comparative studies; Output levels; Partial least square regression; Principle component analysis; Ridge regression; Thyroid disease; UCI machine learning repository; Learning algorithms",2-s2.0-85021232518
"Krawczyk A., Polanska J.","Comparative analysis of MicroRNA-target gene interaction prediction algorithms based on integrated p-value calculation",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030749342&doi=10.1007%2f978-3-319-67792-7_14&partnerID=40&md5=17c747c8508f5004ba06087096e5f936","In the paper we continue our previous research on microRNA- target gene prediction algorithms that has been already published in Krawczyk and Polańska [5] Comparative analysis of microRNA-target gene interaction prediction algorithms—the attempt to compare the results of three algorithms, Bioinformatics and Biomedical Engineering, Lecture Notes in Computer Science. MicroRNAs are non-coding molecules that consist approximately of 21–25 nucleotides. The crucial functions of miRNAs are: translational repression of the target genes and downregulation of the target genes. According to the modern knowledge about microRNAs, they bind to the gene in a specific place in the genome: 3’-UTR, 5’-UTR, CDS and Promoter. Moreover, they play an essential role in cancer growth. In these days we can observe a development of target prediction algorithms. A large number of prediction algorithms implicates many complications connected with the choice of the algorithm that will met the requirements of our experiment and that also predict the possible binding site of the microRNA to the target gene. Our goal is to create the method that can be useful for comparison of the microRNA-target gene interaction prediction algorithms that are based on different approaches of predicting the microRNA-target gene interactions. In order to achieve that, we decided to define one probability space for the mentioned algorithms. We performed the Fisher’s exact test to ensure that we can juxtapose the results from three different algorithms that take into consideration different aspects of binding microRNA to the target gene. Our research has strongly devel-oped from then and according to this, in this paper we would like to introduce our thorough study for not only the single microRNA molecule but for the microRNA family, as well. © 2018, Springer International Publishing AG.","MicroRNA; MicroRNA-target prediction algorithms; P-value integration; Poisson distribution; Target gene","Bins; Bioinformatics; Biomedical engineering; Engineering education; Forecasting; Genes; Molecules; Poisson distribution; Comparative analysis; Crucial functions; Microrna target predictions; MicroRNAs; P-values; Prediction algorithms; Probability spaces; Target genes; RNA",2-s2.0-85030749342
"Hu C., Liu X., Yang W., Lu W., Yu N., Chang S.","Improved zero-order fringe positioning algorithms in white light interference based atomic force microscopy",2018,"Optics and Lasers in Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026381907&doi=10.1016%2fj.optlaseng.2017.07.010&partnerID=40&md5=5e48ce5d203fc34f756f7c0e184a9118","In white light interference based atomic force microscopy (WLIAFM), the vertical displacement of the probe is obtained by zero-order fringe positioning on the probe cantilever, so the accuracy of zero-order fringe positioning will affect directly that of the WLIAFM. However, due to non-uniform distribution of light intensity and photoelectric noises, accurate zero-order fringe positioning becomes a problem. In this paper, two algorithms are proposed to improve the zero-order fringe positioning accuracy. In the first algorithm which is called improved maximum algorithm, multi-row maximum positions of the interference fringes are obtained and error theory is applied to eliminate erroneous maximum positions, then the average of remaining maximum positions is used as the zero-order fringe position. Another is called phase evaluation algorithm, in which wavelet transform is applied to eliminate effects from disturbances mentioned above and Hilbert transform is used for phase evaluation to obtain the zero-order fringe position. The practicability and accuracy of the two algorithms have been verified by series of experiments. The experiment results indicate that both two algorithms are suitable in this condition and the phase evaluation algorithm has higher accuracy while the improved maximum algorithm has higher processing speed. © 2017 Elsevier Ltd","Atomic force microscopy; Hilbert transform; White light interference; Zero-order fringe positioning","Atomic force microscopy; Fiber optic sensors; Light interference; Probes; Wavelet transforms; Hilbert transform; Non-uniform distribution; Phase evaluation algorithms; Positioning accuracy; Positioning algorithms; Vertical displacements; White light interference; Zero order; Mathematical transformations",2-s2.0-85026381907
"Janardhanan M.N., Li Z., Nielsen P., Tang Q.","Artificial bee colony algorithms for two-sided assembly line worker assignment and balancing problem",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022190420&doi=10.1007%2f978-3-319-62410-5_2&partnerID=40&md5=ca23ad2f1f7c1df3f6e68d7e30db6747","Worker assignment is a new type of problem in assembly line balancing problems, which typically occurs in sheltered work centers for the disabled. However, only a few contributions consider worker assignment in a two-sided assembly line. This research presents three variants of artificial bee colony algorithm to solve worker assignment and line balancing in two-sided assembly lines. The utilization of meta-heuristics is motivated by the NP-hard nature of the problem and the chosen methods utilize different operators for onlooker phase and scout phase. The proposed algorithms are tested on 156 cases generated from benchmark problems. A comparative study is conducted on the results obtained from the three proposed variants and other well-known metaheuristic algorithms, such as simulated annealing, particle swarm optimization and genetic algorithm. The computational study demonstrates that the proposed variants produce more promising results and are able to solve this new problem effectively in an acceptable computational time. © Springer International Publishing AG 2018.","Artificial bee colony; Assembly line balancing; Metaheuristics; Two-sided assembly line; Worker assignment","Artificial intelligence; Assembly; Assembly machines; Distributed computer systems; Evolutionary algorithms; Genetic algorithms; Heuristic methods; Optimization; Particle swarm optimization (PSO); Simulated annealing; Artificial bee colonies; Assembly line balancing; Meta heuristics; Two-sided assembly lines; Worker assignments; Problem solving",2-s2.0-85022190420
"Sharifian M., Sharifian M., Krysl P., Sharifian M.","Stress-update algorithms for Bigoni-Piccolroaz yield criterion coupled with a generalized function of kinematic hardening laws",2018,"European Journal of Mechanics, A/Solids",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028499789&doi=10.1016%2fj.euromechsol.2017.08.011&partnerID=40&md5=a3272419060edf043ee2f210a330a17b","A broad-ranging plasticity model is constructed by combining Bigoni-Piccolroaz yield function with a sweeping expression of kinematic hardening. Subsequently, two explicit and implicit update algorithms are developed to compute the stress from the rate equations of the plasticity in an incremental elastoplastic finite element analysis. The integrations are based on Forward and Backward Euler schemes. Considering a number of varying materials and the associated plasticity models, the proposed formulations are examined by means of a comprehensive set of numerical investigations. These include investigations to verify the suggested strategies along with two numerical simulations carried out by implementing the algorithms in a nonlinear finite element code. The versatility of the formulae allows for an expansive choice of elastoplastic constitutive models with a simple adjustment of a few parameters. © 2017 Elsevier Masson SAS","Constitutive equations; Elastic-plastic behavior; Nonlinear finite elements; Stress-update algorithms; Yield criterion","Constitutive equations; Elastoplasticity; Hardening; Kinematics; Nonlinear equations; Plasticity; Yield stress; Elastic-plastic behavior; Elasto-plastic finite element analysis; Elastoplastic constitutive model; Generalized functions; Non-linear finite elements; Numerical investigations; Stress update algorithms; Yield criteria; Finite element method",2-s2.0-85028499789
"Vamshi Krishna M., Raju G.S.N., Mishra S.","Design of linear and circular arrays using natural search algorithms for generation of low side lobe patterns",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029812662&doi=10.1007%2f978-981-10-4280-5_52&partnerID=40&md5=c719fc0cb2133e501b8720ad206e7a76","Arrays are designed conventionally using standard distribution functions and also using age old techniques like Woodward, Taylor, etc. It is well known that beam width and side lobe are conflicting and is involved in generating a compromise between these two for deserved radiation characteristics. In this paper, design of linear and circular arrays with such optimization is considered. The optimization is carried using the state-of-the-art natural search algorithms like Cuckoo Search Algorithm. Simulation is carried out with the objective of side lobe level (SLL) suppression considering beam width (BW) constraint. These results are compared with that of Accelerated particle swarm optimization. © Springer Nature Singapore Pte Ltd. 2018.","APSO; Circular arrays; CSA; Linear array; Optimization","Distribution functions; Learning algorithms; Particle swarm optimization (PSO); Accelerated particles; APSO; Circular arrays; Cuckoo search algorithms; Linear arrays; Radiation characteristics; Side lobe level (SLL); Standard distributions; Optimization",2-s2.0-85029812662
"Klinkowski M., Lechowicz P., Walkowiak K.","Survey of resource allocation schemes and algorithms in spectrally-spatially flexible optical networking",2018,"Optical Switching and Networking",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029954480&doi=10.1016%2fj.osn.2017.08.003&partnerID=40&md5=a441dbbc4131ba9c907f3ed6277e112b","Space division multiplexing (SDM) is a promising optical network solution with the scaling potential to overcome the possible capacity crunch problem in backbone networks. In SDM optical networks, optical signals are transmitted in parallel through spatial modes co-propagating in suitably designed optical fibers. The combination of SDM with wavelength division multiplexing technologies, based on either fixed or flexible frequency grids, allows for a significant increase in the transmission system capacity and improves network flexibility through the joint management of spectral and spatial resources. The goal of this tutorial paper is to survey the resource allocation schemes and algorithms that aim at efficient and optimized use of transmission resources in spectrally and spatially flexible optical networks. There are several flavors of SDM, which results from available optical fiber and switching technologies; hence, we begin from classifying SDM optical network scenarios. As some SDM solutions have specific limitations, for instance, due to coupling of spatial modes, we discuss related constraints and their impact on resource allocation schemes. Along with defining possible SDM scenarios, we survey the proposed in the literature resource allocation algorithms and classify them according to diverse criteria. This study allows us to overview the state-of-the-art solutions in the scope of planning and operating SDM optical networks in a systematic way as well as to identify some open issues that lack solutions and need to be addressed. © 2017 Elsevier B.V.","Algorithms; Network optimization; Optical networks; Routing, space and spectrum allocation; Space division multiplexing; Survey","Algorithms; Fiber optic networks; Optical fibers; Optimization; Resource allocation; Surveying; Surveys; Flexible optical networks; Network optimization; Optical network scenario; Resource allocation algorithms; Resource allocation schemes; Space division multiplexing; Spectrum allocation; Wavelength division multiplexing technology; Space division multiple access",2-s2.0-85029954480
"Guan J., Wang X., Feng P., Dong J., Chambers J., Jiang Z.L., Wang W.","Polynomial dictionary learning algorithms in sparse representations",2018,"Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027492676&doi=10.1016%2fj.sigpro.2017.08.011&partnerID=40&md5=5b9ff44b1a5168e4affffdab0edb2df9","Dictionary learning has been extensively studied in sparse representations. However, existing dictionary learning algorithms are developed mainly for standard matrices (i.e. matrices with scalar elements), and little attention has been paid to polynomial matrices, despite their wide use for describing convolutive signals or for modeling acoustic channels in room and underwater acoustics. In this paper, we propose a polynomial dictionary learning technique to deal with signals with time delays. We present two types of polynomial dictionary learning methods based on the fact that a polynomial matrix can be represented either as a polynomial of matrices (i.e. the coefficient in the polynomial corresponding to each time lag is a scalar matrix) or equally as a matrix of polynomial elements (i.e. each element of the matrix is a polynomial). The first method allows one to extend any state-of-the-art dictionary learning method to the polynomial case; and the second method allows one to directly process the polynomial matrix without having to access its coefficient matrices. A sparse coding method is also presented for reconstructing convolutive signals based on a polynomial dictionary. Simulations are provided to demonstrate the performance of the proposed algorithms, e.g. for polynomial signal reconstruction from noisy measurements. © 2017","Dictionary learning; Impulse responses; Polynomial matrix; Sparse representation","Impulse response; Learning systems; Polynomials; Time delay; Underwater acoustics; Acoustic channels; Coefficient matrix; Dictionary learning; Dictionary learning algorithms; Noisy measurements; Polynomial matrices; Polynomial signal; Sparse representation; Learning algorithms",2-s2.0-85027492676
"Caradonna G., Lionetti S., Tarantino E., Verdoscia C.","A comparison of low-poly algorithms for sharing 3D models on the web",2018,"Lecture Notes in Geoinformation and Cartography",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028633251&doi=10.1007%2f978-3-319-56218-6_19&partnerID=40&md5=c049054d1bba646ff3666928c1d89934","In recent years, the rising popularity of 3D models in the field of Cultural Heritage has brought additional geo-spatial formats for its documentation, making necessary to test new approaches in managing, publishing and studying heterogeneous data in an integrated way. Nowadays several computer applications and IT instruments are available for the management of cultural, archaeological and environmental heritages. The large size and complex nature of data makes it difficult for heritage experts to manage them for run more complex spatial analyses. Furthermore, it is also more difficult for citizens to access 3D models aimed at tourism and education. In this paper, we analyze recent low-poly methods aimed at reducing the size and complexity of 3D models applied to the case study of an historical building of Bari (Italy). The main idea is to create simple geometries (through low-poly algorithms) to significantly reduce the number of polygons in the reality-based environment and publish the model on the web. After the comparative evaluation of different low-poly algorithms and the generation of a test model, a PostgreSQL DBMS and a front-end PHP interface were developed to allow users to analyze and query the model. © Springer International Publishing AG 2018.","3D models; Architectural heritages; Low-poly algorithms","Environmental engineering; Geophysics; 3D models; Architectural heritage; Comparative evaluations; Cultural heritages; Environmental heritage; Heterogeneous data; Historical buildings; Poly-algorithms; Three dimensional computer graphics",2-s2.0-85028633251
"Roeva O., Atanassova V.","Universal generalized net model for description of metaheuristic algorithms: verification with the bat algorithm",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029407508&doi=10.1007%2f978-3-319-66827-7_22&partnerID=40&md5=140f4b31f89e72beff328a0415bdf857","In the present paper, the apparatus of generalized nets is used to describe the metaheuristic technique Bat algorithm. Generalized nets are considered an effective and appropriate tool for description of the logics of different optimization techniques. As a result, the developed generalized net model executes the Bat algorithm procedures, conducting basic steps and performing optimal search. The paper elaborates on the already proposed Universal generalized net model for description of the population-based metaheuristic algorithms, which was used so far to model the Cuckoo search, Firefly algorithm and Artificial bee colony optimization, and is used here for modelling of Bat algorithm. It is shown that the Bat algorithm can be described in terms of Universal generalized net model by only varying the characteristic functions of the tokens. Thus, verification of the Universal generalized net model is performed. © 2018, Springer International Publishing AG.","Bat algorithm; Generalized nets; Metaheuristic; Modelling","Fuzzy logic; Fuzzy sets; Models; Pattern matching; Artificial bee colony optimizations; Bat algorithms; Characteristic functions; Generalized net; Meta heuristic algorithm; Meta-heuristic techniques; Metaheuristic; Optimization techniques; Optimization",2-s2.0-85029407508
"Mezera F., Krupka J.","Classification of clients on the basis of modifying case-based reasoning algorithms",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030762079&doi=10.1007%2f978-3-319-67792-7_31&partnerID=40&md5=660a821fd168a5c7abaeb48191ef6caa","This article deals with client’s classification possibilities for trade companies. One of the options for dealing with classification is to use Case-based Reasoning method. The proposed modified algorithm clears cases base, it eliminates invalid data and out-dated data from the time point of view. Hill-climbing algorithm is used for this. Classification results achieved by means of modified algorithm are compared with other classification methods such as Neuron Networks, Top Down Induction Decision Trees and Logistic Regression. © 2018, Springer International Publishing AG.","Aging of cases; Base clearing; Case-based reasoning; Clients’ classification; Customer relationship management","Decision trees; Public relations; Trees (mathematics); Base clearing; Classification methods; Classification results; Customer relationship management; Hill climbing algorithms; Logistic regressions; Modified algorithms; Neuron networks; Case based reasoning",2-s2.0-85030762079
"Janota B., Paszyńska A.","Automatic algorithms for the construction of element partition trees for isogeometric finite element method",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030790167&doi=10.1007%2f978-3-319-67792-7_28&partnerID=40&md5=22efe614460e82904a9f9ea9875dd1b9","The IGA-FEM is a modern method for simulation of different engineering and biomedical problems by using B-spline basis functions. To allow for real time interaction between human and computer while performing numerical simulations, there is a need for extremely fast solvers solving systems of linear equations generated while performing simulations. In this paper, an algorithm for construction of the ordering that controls the execution of the multi-frontal direct solver algorithm is presented. The ordering prescribes the permutation of the computational matrix in order to minimize the computational cost of the direct solver. We show that execution of our algorithm generating the recursive partitions of the h-adaptive grids with B-spline basis functions allows reducing the computational cost of the IGA-FEM simulations. © 2018, Springer International Publishing AG.","Graph algorithms; Isogeometric finite element method; Simulations on biomedicine; Topology of computational meshes","Bioinformatics; Functions; Human computer interaction; Interpolation; Real time systems; Regression analysis; Splines; Topology; Automatic algorithms; B-spline basis function; Computational costs; Computational mesh; Graph algorithms; Real time interactions; Simulations on biomedicine; Systems of linear equations; Finite element method",2-s2.0-85030790167
"Corbellini A., Godoy D., Mateos C., Schiaffino S., Zunino A.","DPM: A novel distributed large-scale social graph processing framework for link prediction algorithms",2018,"Future Generation Computer Systems",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013197040&doi=10.1016%2fj.future.2017.02.025&partnerID=40&md5=8e9bab9e51e39d0f6e469341cb46e107","Large-scale graphs have become ubiquitous in social media. Computer-based recommendations in these huge graphs pose challenges in terms of algorithm design and resource usage efficiency when processing recommendations in distributed computing environments. Moreover, recommendation algorithms for graphs, particularly link prediction algorithms, have different requirements depending of the way the underlying graph is traversed. Path-based algorithms usually perform traversals in different directions to build a large ranking of vertices to recommend, whereas random walk-based algorithms build an initial subgraph and perform several iterations on those vertices to compute the final ranking. In this work, we propose a distributed graph processing framework called Distributed Partitioned Merge (DPM), which supports both types of algorithms and we compare its performance and resource usage w.r.t. two relevant frameworks, namely Fork-Join and Pregel. In our experiments, we show that in most tests DPM outperforms both Pregel and Fork-Join in terms of recommendation time, with a minor penalization in network usage in some scenarios. © 2017 Elsevier B.V.","Distributed graph processing; Online Social Networks; Recommendation algorithms","Social networking (online); Algorithm design; Distributed computing environment; Graph processing; Link prediction; On-line social networks; Recommendation algorithms; Resource usage; Underlying graphs; Distributed computer systems",2-s2.0-85013197040
"Gilbert A.D., Kuo F.Y., Sloan I.H.","Hiding the weights—CBC black box algorithms with a guaranteed error bound",2018,"Mathematics and Computers in Simulation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85002339091&doi=10.1016%2fj.matcom.2016.06.005&partnerID=40&md5=49453ee91fe6f7f8a61928bd46f8d183","The component-by-component (CBC) algorithm is a method for constructing good generating vectors for lattice rules for the efficient computation of high-dimensional integrals in the “weighted” function space setting introduced by Sloan and Woźniakowski. The “weights” that define such spaces are needed as inputs into the CBC algorithm, and so a natural question is, for a given problem how does one choose the weights? This paper introduces two new CBC algorithms which, given bounds on the mixed first derivatives of the integrand, produce a randomly shifted lattice rule with a guaranteed bound on the root-mean-square error. This alleviates the need for the user to specify the weights. We deal with “product weights” and “product and order dependent (POD) weights”. Numerical tables compare the two algorithms under various assumed bounds on the mixed first derivatives, and provide rigorous upper bounds on the root-mean-square integration error. © 2016 International Association for Mathematics and Computers in Simulation (IMACS)","Component-by-component algorithm; Lattice rules; Quasi-Monte Carlo methods","Errors; Mean square error; Monte Carlo methods; Vector spaces; Black box algorithms; Efficient computation; Guaranteed bounds; Guaranteed error bounds; High-dimensional integrals; Lattice rules; Quasi Monte Carlo methods; Root mean square errors; Computational efficiency",2-s2.0-85002339091
"Issa M.","Digital image watermarking performance improvement using bio-inspired algorithms",2018,"Studies in Computational Intelligence",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032014325&doi=10.1007%2f978-3-319-63754-9_30&partnerID=40&md5=6b01a1b3612fddfd05f31dae9e0c22aa","Copyrights protection and ownership of multimedia is a vital task nowadays used in a lot of fields such as broadcasting media. Hence digital media watermarking techniques were developed to embed a watermark image into the original media (image or videos). The watermarking techniques aim to improve the robustness of watermarked image against attacks and increase the impeccability of significant regions of the media. This chapter focuses on explaining the rule of using metaheuristic algorithms for optimizing the robustness and impeccability of image watermarking techniques. This will be discussed through two watermarking techniques one used genetic algorithm optimization and the other use cuckoo search optimization approach. © Springer International Publishing AG 2018.","Bio-inspired algorithms; Digital watermarking; Genetic algorithm and cuckoo search optimization",,2-s2.0-85032014325
"Liu X., Argente E., Valero S., Sastre G.","Applying genetic algorithms in chemical engineering for determining zeolite structures",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028645523&doi=10.1007%2f978-3-319-67180-2_4&partnerID=40&md5=8df9cf709716b2506307c17945c837fe","Zeolites are crystalline materials widely used in many catalytic process in industry. Specifically, they have a major impact at petrochemicals, fine chemicals or gas separation. Thus, discovering new zeolites with specific properties is a high-impact target for the industry, due to their huge economical repercussions. New tools and techniques are needed to help in this task, because trial and error approaches prevail until now. In this work, we propose a new application of genetic algorithms for helping chemical engineers in the process of determining zeolite structures with specific properties. Our proposal takes advantage of some symmetry operation properties to improve the performance of the genetic algorithm. Furthermore, a suitable fitness function has been designed which evaluates all main features required for efficient zeolites. © 2018, Springer International Publishing AG.","Catalysis; Computer-aided model-building method; Genetic algorithm; Zeolite structure determination","Catalysis; Crystalline materials; Genetic algorithms; Soft computing; Catalytic process; Computer aided modeling; Fitness functions; Specific properties; Symmetry operations; Tools and techniques; Trial-and-error approach; Zeolite structure; Zeolites",2-s2.0-85028645523
"Yan J., Li Z., Huang X.","Applications of genetic algorithms in bgp-based interdomain traffic engineering",2018,"Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031280038&doi=10.1007%2f978-3-319-66625-9_11&partnerID=40&md5=d8a9663c5d30bc1fbfe311e958d3876b","With the rapid development of the Internet, widely deployed new services such as high definition videos and voice over IP (VoIP) require higher performance guarantees. Traffic engineering can improve end to end service quality, help large autonomous systems (AS) operators improve network resource utilization and meet the challenge. At the interdomain level, traffic engineering is more challenging. Most network operators still rely on changing routing policies and BGP attributes manually. In this paper, we discuss the existing systematic techniques in BGP-based interdomain traffic engineering and propose an improved algorithm based on a multi-objective genetic algorithm. Our algorithm is scalable and efficient. We apply our solution to a provincial network of China Mobile and discuss the influence of different parameters on the performance and validity of the algorithm. © 2018, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.","BGP; Genetic algorithms; Interdomain traffic engineering","Internet telephony; Mobile telecommunication systems; Quality of service; Video cameras; Voice/data communication systems; Autonomous systems; End-to-end service; High definition video; Interdomain traffic engineering; Multi-objective genetic algorithm; Network resource utilization; Performance guarantees; Traffic Engineering; Genetic algorithms",2-s2.0-85031280038
"de Oliveira L.L., Freitas A.A., Tinós R.","Multi-objective genetic algorithms in the study of the genetic code's adaptability",2018,"Information Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031296427&doi=10.1016%2fj.ins.2017.10.022&partnerID=40&md5=d64d84b896d638afc5e5e0c82d95625b","Using a robustness measure based on values of the polar requirement of amino acids, Freeland and Hurst (1998) showed that less than one in one million random hypothetical codes are better than the standard genetic code. In this paper, instead of comparing the standard code with randomly generated codes, we use an optimisation algorithm to find the best hypothetical codes. This approach has been used before, but considering only one objective to be optimised. The robustness measure based on the polar requirement is considered the most effective objective to be optimised by the algorithm. We propose here that the polar requirement is not the only property to be considered when computing the robustness of the genetic code. We include the hydropathy index and molecular volume in the evaluation of the amino acids using three multi-objective approaches: the weighted formula, lexicographic and Pareto approaches. To our knowledge, this is the first work proposing multi-objective optimisation approaches with a non-restrictive encoding for studying the evolution of the genetic code. Our results indicate that multi-objective approaches considering the three amino acid properties obtain better results than those obtained by single objective approaches reported in the literature. The codes obtained by the multi-objective approach are more robust and structurally more similar to the standard code. © 2017 Elsevier Inc.","Genetic algorithms; Genetic code; Lexicographic approach; Multi-objective genetic algorithm","Amino acids; Genetic algorithms; Multiobjective optimization; Optimization; Amino acid properties; Genetic code; Hydropathy index; Lexicographic approach; Multi-objective genetic algorithm; Robustness measures; Single objective; Weighted formulas; Codes (symbols)",2-s2.0-85031296427
"Chan Y.-T., Wang S.-J., Tsai C.-H.","Real-time foreground detection approach based on adaptive ensemble learning with arbitrary algorithms for changing environments",2018,"Information Fusion",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019469784&doi=10.1016%2fj.inffus.2017.05.001&partnerID=40&md5=0698cbd6b4e377528cb002779a32d56d","Foreground detection technologies have emerged as an important research area with increasing popularity of computer vision and camera devices. Even though several foreground detection approaches have been proposed, they cannot address various challenges in actual complex scenes owing to their applicability and restrictions. This study proposes a method that can integrate arbitrary detection technologies to detect foregrounds in real time, thereby improving overall detection performance of video-based systems. Moreover, the proposed approach can be fully initialized with initial foreground results, requires no training, and performs dynamic adjustments online, for every new frame. In this approach, critical weighted values are automatically calculated over time based on observed scenes for optimal flexibility and parameterization. Thus, the proposed method has the flexibility to accommodate any new technology to overcome the challenging problems of foreground detection in changing environments. Experimental results demonstrate that the performance of the proposed method is comparable to that of state-of-the-art methods and satisfies the requirements of real-time practical applications. © 2017 Elsevier B.V.","Arbitrary algorithm; Change detection; Ensemble learning; Foreground segmentation; Real-time applications; Stopped object detection","Learning algorithms; Object recognition; Change detection; Detection performance; Ensemble learning; Foreground detection; Foreground segmentation; Real-time application; Real-time foreground detection; State-of-the-art methods; Real time systems",2-s2.0-85019469784
"Autran S., Formenti E.","More decision algorithms for global properties of 1D cellular automata",2018,"Journal of Cellular Automata",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028535058&partnerID=40&md5=64252f4a165e9bfc94e496cb54f5e60b","This paper proposes some new decision algorithms for basic properties of one-dimensional cellular automata (CA). In particular, it provides an algorithm for deciding surjectivity on finite configurations. Moreover, by using the classical decision algorithm for surjectivity and injectivity of Sutner, we provide a simple decision algorithm for openess (although its complexity is unchanged). Finally, a complete implication diagram between global properties of one-dimensional CA is provided. When possible the corresponding algorithms for one-sided CA are also given. © 2017 Old City Publishing, Inc.","Closingness; Computational complexity; Decision algorithms; Finite configurations; Openess; Surjectivity","Cellular automata; One dimensional; Closingness; Decision algorithms; Finite configurations; Openess; Surjectivity; Computational complexity",2-s2.0-85028535058
"Liu W., Gong M., Wang S., Ma L.","A two-level learning strategy based memetic algorithm for enhancing community robustness of networks",2018,"Information Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029279091&doi=10.1016%2fj.ins.2017.09.021&partnerID=40&md5=3a519da6e4eba7e7c610835a1a9ce662","Community structure is a natural and inherent property of complex networks which can reflect their potential functionality. When the robustness of a network is improved, its community structure should be preserved as much as possible. However, most earlier studies only considered enhancing the network robustness and ignored the analysis of the community structure, which may alter the original topological structure and functionality of networks. In this paper, we propose a new memetic algorithm (MA-CR) with a two-level learning strategy to enhance the community robustness of networks, while maintaining the degree distribution and community structure. The proposed MA-CR is a hybrid global-local heuristic search methodology which adopts genetic algorithm as the global search and the proposed two-level learning strategy as the local search. The two-level learning strategy is designed based on the potential characteristics of the node structure and community structure of networks, which aims at mitigating two-level targeted attacks. Experiments on synthetic scale-free networks as well as real-world networks demonstrate the effectiveness and stability of the proposed algorithm as compared with several state-of-the-art algorithms. © 2017","Community structure; Complex network; Memetic algorithm; Robustness","Complex networks; Genetic algorithms; Heuristic algorithms; Heuristic methods; Learning algorithms; Learning systems; Robustness (control systems); Social sciences; Community structures; Degree distributions; Memetic algorithms; Network robustness; Potential functionality; Real-world networks; State-of-the-art algorithms; Topological structure; Computer networks",2-s2.0-85029279091
"Gozzard A., Ward M., Datta A.","Converting a network into a small-world network: Fast algorithms for minimizing average path length through link addition",2018,"Information Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029288427&doi=10.1016%2fj.ins.2017.09.020&partnerID=40&md5=dd8972997022a489ec0f4ba88d3ebfe4","The average path length in a network is an important parameter for measuring the end-to-end delay for message delivery. The delay between an arbitrary pair of nodes is smaller if the average path length is low. It is possible to reduce the average path length of a network by adding one or more additional links between pairs of nodes. However, a naïve algorithm is often very expensive for determining which additional link can reduce the average path length in a network the most. In this paper, we present two efficient algorithms to minimize the average network path length by link addition. Our algorithms can process significantly larger networks compared to the naïve algorithm. We present simple implementations of our algorithms, as well as performance studies. © 2017 Elsevier Inc.",,"Small-world networks; Average path length; End to end delay; Fast algorithms; Larger networks; Message delivery; Network paths; Performance study; Distributed computer systems",2-s2.0-85029288427
"Indri M., Trapani S.","Using virtual sensors in industrial manipulators for service algorithms like payload checking",2018,"Mechanisms and Machine Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028353925&doi=10.1007%2f978-3-319-61276-8_16&partnerID=40&md5=129a382693129a979f29a3c4b78f78f1","Industrial manipulators are usually equipped with a set of basic sensors (encoders and current sensors) that could not be sufficient to implement more advanced service and control algorithms, like the Payload Check, the Impedance Control or the Cartesian Soft Servo. A software layer between the real sensors and the algorithms is developed in order to provide a new set of “measures”. Such a layer, called Virtual Sensor, exploits the information provided by the real sensors to compute new virtual measures, to be used in the algorithms layer to implement new services. The Virtual Sensor is introduced in a standard COMAU controller and its effectiveness is tested in a service algorithm, called Payload Check, able to detect a wrong declaration of the robot payload. Good performances have been obtained for a wide range of COMAU manipulators. © 2018, Springer International Publishing AG.","Payload check; Service algorithms for robots; Virtual Sensors","Manipulators; Robotics; Cartesians; Current sensors; Impedance control; New services; Payload check; Virtual sensor; Industrial manipulators",2-s2.0-85028353925
"Sharma D., Chandra P.","Applicability of soft computing and optimization algorithms in software testing and metrics – A brief review",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028585588&doi=10.1007%2f978-3-319-60618-7_53&partnerID=40&md5=77a9e9ae51245dd4d738eb650c21c7f4","In spite of many years of work by scientists and specialists on various software qualities, testing stays one of the most broadly honed and concentrated on methodologies for evaluating and improving software quality. Our objective, in this paper, is to present how optimization techniques provide solutions to different and difficult issues in different areas of software engineering. Optimization algorithms are mathematical procedures, which intends to best optimal results for the defect, fault, failure to accomplish tractability, strength, and low arrangement cost. In this paper, a comprehensive overview of software testing and metrics based on soft computing and optimization techniques is presented. In this survey, we try to explain some major problems like defect prediction, software fault prediction and their solutions by soft computing and optimization algorithms. The paper presents an overview of the usage of Mathematical optimization Algorithms and soft computing approaches. © Springer International Publishing AG 2018.","Metrics; Optimization algorithms; Soft computing; Software fault prediction; Software testing","Computer software; Computer software selection and evaluation; Defects; Forecasting; Pattern recognition; Soft computing; Software engineering; Software testing; Defect prediction; Mathematical optimizations; Mathematical procedures; Metrics; Optimization algorithms; Optimization techniques; Soft computing approaches; Software fault prediction; Optimization",2-s2.0-85028585588
"Boehnke M., Patel N., McKinney K., Clark T.","Diagnostic Performance of SRU and ATA Thyroid Nodule Classification Algorithms as Tested With a 1 Million Virtual Thyroid Nodule Model",2018,"Current Problems in Diagnostic Radiology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019957086&doi=10.1067%2fj.cpradiol.2017.04.005&partnerID=40&md5=d8edb17f41bd3475301e136cf02fae1e","Purpose The Society of Radiologists in Ultrasound (SRU 2005) and American Thyroid Association (ATA 2009 and ATA 2015) have published algorithms regarding thyroid nodule management. Kwak et al. and other groups have described models that estimate thyroid nodules’ malignancy risk. The aim of our study is to use Kwak's model to evaluate the tradeoffs of both sensitivity and specificity of SRU 2005, ATA 2009 and ATA 2015 management algorithms. Materials and Methods 1,000,000 thyroid nodules were modeled in MATLAB. Ultrasound characteristics were modeled after published data. Malignancy risk was estimated per Kwak's model and assigned as a binary variable. All nodules were then assessed using the published management algorithms. With the malignancy variable as condition positivity and algorithms’ recommendation for FNA as test positivity, diagnostic performance was calculated. Results Modeled nodule characteristics mimic those of Kwak et al. 12.8% nodules were assigned as malignant (malignancy risk range of 2.0-98%). FNA was recommended for 41% of nodules by SRU 2005, 66% by ATA 2009, and 82% by ATA 2015. Sensitivity and specificity is significantly different (< 0.0001): 49% and 60% for SRU; 81% and 36% for ATA 2009; and 95% and 20% for ATA 2015. Conclusion SRU 2005, ATA 2009 and ATA 2015 algorithms are used routinely in clinical practice to determine whether thyroid nodule biopsy is indicated. We demonstrate significant differences in these algorithms’ diagnostic performance, which result in a compromise between sensitivity and specificity. © 2017 Elsevier Inc.",,"Article; ATA 2009 management algorithm; ATA 2015 management algorithm; cancer classification; cancer model; cancer risk; classification algorithm; comparative study; controlled study; disease assessment; fine needle aspiration biopsy; human; malignant neoplasm; predictive value; sensitivity and specificity; SRU 2005 management algorithm; thyroid nodule; thyroid weight; virtual thyroid nodule model",2-s2.0-85019957086
"Karthika R., Kumar V.S.","Artificial Bee Colony Algorithm-Based Shunt Active Filter for Sinusoidal Supply and Trapezoidal Supply",2018,"Journal of Circuits, Systems and Computers",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021827332&doi=10.1142%2fS0218126618500160&partnerID=40&md5=69180e2b7483c60d7803f4a09105cc74","In this paper, a DC-link voltage tuning algorithm is introduced to control the shunt active filter (SAF) with sinusoidal and trapezoidal power supplies. The purpose of the proposed optimization algorithm is for tuning the PI controller and reducing the harmonics level. Artificial bee colony (ABC) algorithm is introduced for tuning the gain of the controller and the voltage variation of power converter by using PWM pulses. It regulates the DC-link voltage as per the signal harmonics and the active power loss of the system is reduced. Therefore, the accurate compensation current is injected by the SAF devices. The proposed ABC-PI controller-based harmonic compensation method is implemented in MATLAB/Simulink platform. Then, the Total Harmonic Distortion (THD) and the power factor are evaluated. The results of the proposed method are compared with PI controller and PSO-PI controller. The proposed method has fast DC-link voltage response, low THD and good power factor. © 2018 World Scientific Publishing Company.","ABC algorithm; current harmonics; DC-link voltage; SAF; THD","Active filters; Bandpass filters; Controllers; Electric power factor; Evolutionary algorithms; Harmonic analysis; Particle swarm optimization (PSO); Passive filters; Tuning; Abc algorithms; Accurate compensation; Artificial bee colony algorithms; Artificial bee colony algorithms (ABC); Current harmonics; DC-link voltages; Optimization algorithms; Total harmonic distortion (THD); Optimization",2-s2.0-85021827332
"Naumoski A., Mirceva G., Lameski P.","Influence of fuzzy tolerance metrics on classification and regression tasks for fuzzy-rough nearest neighbour algorithms",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031719928&doi=10.1007%2f978-3-319-68855-8_11&partnerID=40&md5=da385a411ab7c657a507fe1b4ab4fa90","In this paper, we investigate the influence of the fuzzy tolerance relationship (fuzzy similarity metrics) on two fuzzy and two fuzzy-rough nearest neighbour algorithms for both classification and regression tasks. The fuzzy similarity metric plays a major role in construction of the lower and upper approximations of decision classes, and therefore has high influence on the accuracy of the algorithm. The experimental results evaluated on the four approaches show the difficulty to estimate a single metric that will be good in all cases. Moreover, the choice of similarity metric on some datasets has not influence at all. This require further investigation, not only with similarity metrics, but also for evaluating the algorithms with different T-norms and implicators. © Springer International Publishing AG 2018.","Classification; Fuzzy rough sets; Fuzzy tolerance relationship; k-nearest neighbour; Regression","Classification (of information); Cognitive systems; Fuzzy logic; Nearest neighbor search; Regression analysis; Rough set theory; Fuzzy similarity; Fuzzy tolerance relationship; Fuzzy-rough sets; K-nearest neighbours; Lower and upper approximations; Nearest neighbour; Regression; Similarity metrics; Approximation algorithms",2-s2.0-85031719928
"Vannucci M., Colla V.","Genetic algorithms based resampling for the classification of unbalanced datasets",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020442349&doi=10.1007%2f978-3-319-59424-8_3&partnerID=40&md5=a32b0aa0f1dcc3d828600030a2915931","In the paper a resampling approach for unbalanced datasets classification is proposed. The method suitably combines undersampling and oversampling by means of genetic algorithms according to a set of criteria and determines the optimal unbalance rate. The method has been tested on industrial and literature datasets. The achieved results put into evidence a sensible increase of the rare patterns detection rate and an improvement of the classification performance. © Springer International Publishing AG 2018.",,"Genetic algorithms; Pattern recognition; Classification performance; Detection rates; Over sampling; Re-sampling approach; Resampling; Unbalanced datasets; Under-sampling; Classification (of information)",2-s2.0-85020442349
"Sreekara Reddy M.B.S., Ratnam C., Rajyalakshmi G., Manupati V.K.","An effective hybrid multi objective evolutionary algorithm for solving real time event in flexible job shop scheduling problem",2018,"Measurement: Journal of the International Measurement Confederation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029506357&doi=10.1016%2fj.measurement.2017.09.022&partnerID=40&md5=621c700b45a4fe84a6c2735b59216916","This paper addresses the multi-objective model for a flexible job shop scheduling problem (FJSSP) to improve the system performance under the condition of machines break down as a real time event. It is important to identify the relevant performance measures to the mentioned problem for examining the system performance. Therefore, minimization of make span and minimization of total machine load variation is considered as two performance measures. Generally, it is very difficult to develop a mathematical model for the real-time situations in FJSSP. Hence, in this paper we divided the research work into two folds: Primarily, a mixed-integer non-linear programming (MINLP) model has been developed to represent the above-mentioned multi-objectives that subjected to constraints without considering machines break down. Secondarily, by incorporating the machines break down as the real-time event the performance of the system is examined. Solving conflicting objectives simultaneously for finding the optimal/near optimal solutions in a reasonable time is a challenge. In this paper, we proposed a new evolutionary based multi-objective teacher learning-based optimization algorithm (MOTLBO) to solve the above-mentioned complex problem. Moreover, to improve the obtained solutions a local search technique has been incorporated in the MOTLBO and comparisons has been made with existing multi-objective particle swarm optimization (MOPSO) and conventional non-dominated sorting genetic algorithm (CNSGA-II). Results found that the proposed multi-objective-based hybrid meta-heuristic algorithm produced high-quality solutions as proved by the tests we performed over a number of randomly generated test problems. Finally, comparisons also made with how the machines break down can affect the proposed systems performance. © 2017 Elsevier Ltd","Flexible job shop; Multi-objective evolutionary algorithm; NP-hard; Optimization","Education; Evolutionary algorithms; Genetic algorithms; Heuristic algorithms; Integer programming; Multiobjective optimization; Nonlinear programming; Optimization; Particle swarm optimization (PSO); Scheduling; Screening; Teaching; Flexible job shops; Flexible job-shop scheduling problem; Mixed-integer nonlinear programming; Multi objective evolutionary algorithms; Multi objective particle swarm optimization; Multi-objective modeling; Non- dominated sorting genetic algorithms; NP-hard; Job shop scheduling",2-s2.0-85029506357
"Zhang Q., Yang L.T., Chen Z., Li P.","High-order possibilistic c-means algorithms based on tensor decompositions for big data in IoT",2018,"Information Fusion",5,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017458048&doi=10.1016%2fj.inffus.2017.04.002&partnerID=40&md5=569110bcdcbdd58580addf105afe097a","Internet of Things (IoT) connects the physical world and the cyber world to offer intelligent services by data mining for big data. Each big data sample typically involves a large number of attributes, posing a remarkable challenge on the high-order possibilistic c-means algorithm (HOPCM). Specially, HOPCM requires high-performance servers with a large-scale memory and a powerful computing unit, to cluster big samples, limiting its applicability in IoT systems with low-end devices such as portable computing units and embedded devises which have only limited memory space and computing power. In this paper, we propose two high-order possibilistic c-means algorithms based on the canonical polyadic decomposition (CP-HOPCM) and the tensor-train network (TT-HOPCM) for clustering big data. In detail, we use the canonical polyadic decomposition and the tensor-train network to compress the attributes of each big data sample. To evaluate the performance of our algorithms, we conduct the experiments on two representative big data datasets, i.e., NUS-WIDE-14 and SNAE2, by comparison with the conventional high-order possibilistic c-means algorithm in terms of attributes reduction, execution time, memory usage and clustering accuracy. Results imply that CP-HOPCM and TT-HOPCM are potential for big data clustering in IoT systems with low-end devices since they can achieve a high compression rate for heterogeneous samples to save the memory space significantly without a significant clustering accuracy drop. © 2017","Big data; Canonical polyadic decomposition; IoT; Possibilistic c-means clustering; Tensor-train network","Cluster computing; Clustering algorithms; Data mining; Embedded systems; Internet of things; Tensors; Attributes reduction; Canonical polyadic decompositions; Intelligent Services; Internet of Things (IOT); Possibilistic C-means; Possibilistic c-means clustering; Tensor decomposition; Tensor trains; Big data",2-s2.0-85017458048
"Radhika D., Aruna Kumari D.","Adding big value to big businesses: A present state of the art of big data, frameworks and algorithms",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031410362&doi=10.1007%2f978-981-10-6602-3_17&partnerID=40&md5=b75f49c5784441f308740b814b8f8962","Data plays a pivotal role in business growth. In fact, data is considered to be an asset to organizations. This is more evident in the enterprises where the data is preserved and mined for discovering knowledge. The data with exponential growth and characterized by volume, velocity, and variety is termed as big data. Mining such voluminous data can give comprehensive business intelligence for making strategic decisions. The emergence of cloud computing technology, parallel processing power of servers, and the distributed programming frameworks like Hadoop with new programming paradigm “MapReduce” pave way for mining massive-scale data. Data mining domain is rich in algorithms that are used to mine data for discovering trends. The era of big data has arrived and mining such data is beyond the capability of conventional data mining techniques. The unprecedented exponential growth of data needs a platform for effective data analysis in real time with fast response. In this paper, we present an overview of big data, mechanisms or algorithms and environment or tools needed to execute them. The rationale behind this paper is that big data mining is the need of the hour in all sectors like finance, biology, healthcare, banking, insurance, and environmental research to name few. Review of various aspects of big data mining can help readers to gain know-how in the context of globalization, business collaborations where mining cross-organization data is essential. This paper also throws light into the relationship among big data, cloud computing technology, Hadoop, and Big data storage systems. In future, we intend to propose and implement algorithms for big data mining. © 2018, Springer Nature Singapore Pte Ltd.","Algorithms; Big data; Big data mining; Distributed programming frameworks; Hadoop","Algorithms; Cloud computing; Data mining; Data storage equipment; Digital storage; Distributed computer systems; Information analysis; Technology transfer; Business collaboration; Cloud computing technologies; Conventional data mining; Data storage systems; Distributed programming; Environmental researches; Hadoop; Programming paradigms; Big data",2-s2.0-85031410362
"Butakova M.A., Chernov A.V., Guda A.N.","Algorithms of sequential pattern generation with noise using stochastic and fuzzy models",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031421084&doi=10.1007%2f978-3-319-68321-8_21&partnerID=40&md5=ca9aa469fa3b8ffdde67d8914f36cbb3","A task of sequential pattern generation can be considered as a problem which is inverse to sequential pattern mining. This paper presents two novel approaches to the sequential pattern generation with noise, namely the approach based on stochastic automata and context-free grammars and the approach based on Hidden Markov model. The distinctive feature of these methods is the suitability to produce an output in the noisy and fuzzy input data. Also, we present the detailed calculation algorithms to the proposed approaches. © Springer International Publishing AG 2018.","Fuzzy pattern; Hidden markov model; Sequential pattern; Stochastic automata model","Automata theory; Context free grammars; Hidden Markov models; Inverse problems; Markov processes; Stochastic systems; Calculation algorithms; Fuzzy input; Fuzzy models; Fuzzy pattern; Sequential patterns; Sequential-pattern mining; Stochastic Automata; Stochastic models",2-s2.0-85031421084
"Gola A., Kłosowski G.","Application of fuzzy logic and genetic algorithms in automated works transport organization",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022209752&doi=10.1007%2f978-3-319-62410-5_4&partnerID=40&md5=7edc4952f1233845b4bcfbf046e730d0","The paper deals with the problem of works transport organization and control by artificial intelligence with respect to path routing for an automated guided vehicle (AGV). The presented approach is based on non-changeable path during travel along a given loop. The ordered set of stations requesting transport service was determined by fuzzy logic, while the sequence of stations in a loop was optimized by genetic algorithms. A solution for both AGV’s and semi-autonomous transport vehicles wherein the control system informs the driver about optimal route was presented. The obtained solution was verified by a computer simulation. © Springer International Publishing AG 2018.","AGV; Artificial intelligence; Control; Fuzzy logic; Genetic algorithms; Path optimization; Tandem loop; Works transport","Artificial intelligence; Automatic guided vehicles; Computation theory; Computer circuits; Control; Distributed computer systems; Genetic algorithms; Optimization; Remotely operated vehicles; Transportation; Automated guided vehicles; Autonomous transport vehicles; Optimal routes; Path optimizations; Tandem loop; Transport organization; Transport services; Works transport; Fuzzy logic",2-s2.0-85022209752
"Girish G.N., Anima V.A., Kothari A.R., Sudeep P.V., Roychowdhury S., Rajan J.","A benchmark study of automated intra-retinal cyst segmentation algorithms using optical coherence tomography B-scans",2018,"Computer Methods and Programs in Biomedicine",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031760704&doi=10.1016%2fj.cmpb.2017.10.010&partnerID=40&md5=a6219ef0ef4d859dd5426272ea6cebda","(Background and objectives) Retinal cysts are formed by accumulation of fluid in the retina caused by leakages from inflammation or vitreous fractures. Analysis of the retinal cystic spaces holds significance in detection and treatment of several ocular diseases like age-related macular degeneration, diabetic macular edema etc. Thus, segmentation of intra-retinal cysts and quantification of cystic spaces are vital for retinal pathology and severity detection. In the recent years, automated segmentation of intra-retinal cysts using optical coherence tomography B-scans has gained significant importance in the field of retinal image analysis. The objective of this paper is to compare different intra-retinal cyst segmentation algorithms for comparative analysis and benchmarking purposes. (Methods) In this work, we employ a modular approach for standardizing the different segmentation algorithms. Further, we analyze the variations in automated cyst segmentation performances and method scalability across image acquisition systems by using the publicly available cyst segmentation challenge dataset (OPTIMA cyst segmentation challenge). (Results) Several key automated methods are comparatively analyzed using quantitative and qualitative experiments. Our analysis demonstrates the significance of variations in signal-to-noise ratio (SNR), retinal layer morphology and post-processing steps on the automated cyst segmentation processes. (Conclusion) This benchmarking study provides insights towards the scalability of automated processes across vendor-specific imaging modalities to provide guidance for retinal pathology diagnostics and treatment processes. © 2017 Elsevier B.V.","Computer-aided diagnostics; Cyst; Macular edema; Optical coherence tomography; Retinal image; Segmentation","Automation; Benchmarking; Diagnosis; Image analysis; Ophthalmology; Optical tomography; Pathology; Scalability; Signal to noise ratio; Tomography; Age-related macular degeneration; Computer aided diagnostics; Cyst; Image acquisition systems; Macular edema; Qualitative experiments; Retinal image; Segmentation algorithms; Image segmentation; Article; B scan; benchmarking; controlled study; cyst; human; image segmentation; optical coherence tomography; qualitative analysis; quantitative analysis; retina disease; retina image; retinal cyst; retinal pigment epithelium; signal noise ratio",2-s2.0-85031760704
"Devarapalli D.D., Srikanth P.","A novel cluster algorithms of analysis and predict for brain derived neurotrophic factor (BDNF) using diabetes patients",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021208356&doi=10.1007%2f978-981-10-3223-3_11&partnerID=40&md5=ce1d9661527545ebb0210e4d053df323","Brain Derived Neurotrophic Factor (BDNF) is involved Diabetes disease is associated with metabolic syndrome. Disease is mainly Type-2 Diabetes Mellitus (T2DM) parameters related to BDNF also. Today’s most people suffered Diabetes Disease. Diabetes Mellitus is a metabolic disorder. Current research is Cluster analyses of T2DM of BDNF data based on predicting the diabetes and identify patients. In this paper, Evaluated as a clustering method for the cluster regarding T2DM of BDNF dataset classifies several clusters. Data Mining is one of the primary methods in clustering. This method examines measurements based on compute minimum, maximum and average values based predict of patients. These algorithms and mathematical problems applied into dataset, evaluate Normalize data and similarity measures based on identifying accurate results. Identification of the BDNF Korley et al. (J Neurotrauma, 33(2):215–225, 2015, [1]) gene these factors help the neurological affected, Change Behavior thing and Mind Depression. © Springer Nature Singapore Pte Ltd. 2018.","Clustering algorithms; Euclidean distance measure; Manhattan distance measure; T2DM of BDNF data","Cluster analysis; Forecasting; Intelligent computing; Metabolism; Brain-derived neurotrophic factors; Euclidean distance measure; Manhattan distance; Mathematical problems; Metabolic disorders; Metabolic syndromes; Similarity measure; T2DM of BDNF data; Clustering algorithms",2-s2.0-85021208356
"Ma H., Wang Y., Wang K.","Automatic detection of false positive RFID readings using machine learning algorithms",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029489992&doi=10.1016%2fj.eswa.2017.09.021&partnerID=40&md5=330aa10e4b9a268753a2f7a356018754","Radio frequency identification (RFID) has been widely used for the automatic identification, tracking and tracing of goods throughout the supply chain from the manufacturer to the customer. However, one technological problem that impedes the productive and reliable use of RFID is the constraint of false positive readings, which refers to tags that are detected accidentally by the reader but not the ones of interest. This paper focuses on the use of machine learning algorithms to identify such RFID readings. A total of 11 statistical features are extracted from received signal strength (RSS) and phase rotations derived from the raw RFID data. Each of the features is highly statistically different to distinguish the false positive readings, but satisfactory classification cannot be achieved when these features are considered individually. Classifiers based on logistic regression (LR), support vector machine (SVM) and decision tree (DT) are constructed, which combine all of the extracted features to classify the RFID readings more effectively. The performance of the classifiers is evaluated in a real-world factory. Results show that SVM provides the highest accuracy of up to 95.3%. DT shows slightly better accuracy (92.85%) than LR (92.75%), while LR has the larger area under the curve (0.976) than DT (0.949). Overall, machine learning algorithms could achieve accuracy of 93% on average. The proposed methodology provides a much more reliable RFID application as false-positive readings are detected immediately without human intervention, which enables a significant potential of fully automatic identification and tracking of goods throughout the supply chain. © 2017 Elsevier Ltd","Classification; False positive readings; Machine learning; RFID","Artificial intelligence; Automation; Classification (of information); Data mining; Decision trees; Learning systems; Radio frequency identification (RFID); Supply chains; Support vector machines; Area under the curves; Automatic Detection; Automatic identification; False positive; Logistic regressions; Received signal strength; Statistical features; Tracking and tracing; Learning algorithms",2-s2.0-85029489992
"Janerio F.M., Vo Tan P., Ton That L., Nguyen Thai C.","Genetic algorithms for parameter estimation in circadian model",2018,"IFMBE Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030860851&doi=10.1007%2f978-981-10-4361-1_107&partnerID=40&md5=ee3d6ed1c6b2bacb0d700dfffe269899","This paper proposes an algorithm to estimate two parameter values vs, transcription of frq gene, and vd, maximum rate of FRQ protein degradation for an existing 3rd order Neurospora model in literature. Details of the algorithm with simulation results are shown in this paper. © Springer Nature Singapore Pte Ltd. 2018.","Biological system; Circadian clock; Circadian system; Genetic algorithms; Parameter estimation","Bioinformatics; Biological systems; Biomedical engineering; Genetic algorithms; Transcription; Circadian clock; Circadian model; Circadian system; Neurospora; Protein degradation; Two parameter; Parameter estimation",2-s2.0-85030860851
"Zielinski K., Nielek R., Wierzbicki A., Jatowt A.","Computing controversy: Formal model and algorithms for detecting controversy on Wikipedia and in search queries",2018,"Information Processing and Management",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029710534&doi=10.1016%2fj.ipm.2017.08.005&partnerID=40&md5=50f6b1080f11b84a4ed658cee2b464bd","Controversy is a complex concept that has been attracting attention of scholars from diverse fields. In the era of Internet and social media, detecting controversy and controversial concepts by the means of automatic methods is especially important. Web searchers could be alerted when the contents they consume are controversial or when they attempt to acquire information on disputed topics. Presenting users with the indications and explanations of the controversy should offer them chance to see the “wider picture” rather than letting them obtain one-sided views. In this work we first introduce a formal model of controversy as the basis of computational approaches to detecting controversial concepts. Then we propose a classification based method for automatic detection of controversial articles and categories in Wikipedia. Next, we demonstrate how to use the obtained results for the estimation of the controversy level of search queries. The proposed method can be incorporated into search engines as a component responsible for detection of queries related to controversial topics. The method is independent of the search engine's retrieval and search results recommendation algorithms, and is therefore unaffected by a possible filter bubble. Our approach can be also applied in Wikipedia or other knowledge bases for supporting the detection of controversy and content maintenance. Finally, we believe that our results could be useful for social science researchers for understanding the complex nature of controversy and in fostering their studies. © 2017 The Authors","Controversy; Web search; Wikipedia","Data processing; Information management; Automatic Detection; Classification based methods; Computational approach; Controversial topics; Controversy; Recommendation algorithms; Web searches; Wikipedia; Search engines",2-s2.0-85029710534
"Corus D., Lehre P.K.","Theory driven design of efficient genetic algorithms for a classical graph problem",2018,"Operations Research/ Computer Science Interfaces Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032629726&doi=10.1007%2f978-3-319-58253-5_8&partnerID=40&md5=88c9cc029ebdce469091789346a802f7","This paper presents a principled way of designing a genetic algorithm which can guarantee a rigorously proven upper bound on its optimization time. The shortest path problem is selected to demonstrate how level-based analysis, a general purpose analytical tool, can be used as a design guide. We show that level-based analysis can also ease the experimental burden of finding appropriate parameter settings. Apart from providing an example of theory-driven algorithmic design, we also provide the first runtime analysis of a non-elitist population-based evolutionary algorithm for both the single-source and all-pairs shortest path problems. © Springer International Publishing AG 2018.","Genetic algorithms; Level-based analysis; Runtime analysis; Shortest path problems",,2-s2.0-85032629726
"Alves T., Coelho J., Nogueira L.","Content Generation for Massively Multiplayer Online Games with Genetic Algorithms",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029579539&doi=10.1007%2f978-3-319-67621-0_4&partnerID=40&md5=b66d200fd9121e0b247e66b0dc28ddc4","Procedural content generation can be defined as the algorithmical creation of game content with limited or indirect user input. In this paper we present a procedural content generation genetic algorithm for massively multiplayer online games. The incremental generation of content by choosing the most appropriate selection of added blocks allows an efficient progress in the game with a small impact on performance and the consequent ability to deploy such type of game in low performance mobile devices. © 2018, Springer International Publishing AG.",,"Computational methods; Genetic algorithms; Interactive computer graphics; Social networking (online); Game contents; Massively multi-player online games; Procedural content generations; User input; Distributed computer systems",2-s2.0-85029579539
"Agdas D., Warne D.J., Osio-Norgaard J., Masters F.J.","Utility of Genetic Algorithms for Solving Large-Scale Construction Time-Cost Trade-Off Problems",2018,"Journal of Computing in Civil Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032626784&doi=10.1061%2f%28ASCE%29CP.1943-5487.0000718&partnerID=40&md5=aea18047af72af70f992c739edf55adf","The time-cost trade-off (TCT) problem has long been a popular optimization question for construction engineering and management researchers. The problem manifests itself as the optimization of total costs of construction projects that consist of indirect project costs and individual activity costs. The trade-off occurs as project duration and, as a result, indirect project costs decrease with reduced individual activity duration. This reduction in individual activity duration is achieved by increasing resource allocation to individual activities, which increases their costs to completion. Historically, metaheuristic solutions have been applied to small-scale problems due to computational complexities and requirements of larger networks. Findings in this article demonstrate that the metaheuristic approach is highly effective for solving large-scale construction TCT problems. A custom genetic algorithm (GA) is developed and used to solve large benchmark networks of up to 630 variables with high levels of accuracy (<3% deviation) consistently using computational power of a personal computer in less than 10 min. The same method can also be used to solve larger networks of up to 6,300 variables with reasonable accuracy (∼7% deviation) at the expense of longer processing times. A number of simple, yet effective, techniques that improve GA performance for TCT problems are demonstrated, the most effective of which is a novel problem encoding, based on weighted graphs, that enables the critical path problem to be partially solved for all candidate solutions a priori, thus significantly increasing fitness evaluation. Other improvements include parallel fitness evaluations, optimal algorithm parameters, and the addition of a stagnation criteria. This article also presents some guidelines of optimal algorithm parameter selection through a comprehensive parameter sweep and a computational demand profile analysis. Moreover, the methods proposed in this article are based on open source development projects that enable scalable solutions without significant development efforts. This information will be beneficial for other researchers in improving computational efficiency of their solution in addressing TCT problems. © 2017 American Society of Civil Engineers.",,"Computational efficiency; Cost engineering; Cost reduction; Costs; Economic and social effects; Genetic algorithms; Parameter estimation; Personal computers; Comprehensive parameters; Computational demands; Computational power; Construction engineering; Construction projects; Meta-heuristic approach; Open source development; Time-cost trade-offs; Optimization",2-s2.0-85032626784
"Zehetner M., Gutjahr W.J.","Sampling-Based Genetic Algorithms for the Bi-Objective Stochastic Covering Tour Problem",2018,"Operations Research/ Computer Science Interfaces Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032615981&doi=10.1007%2f978-3-319-58253-5_15&partnerID=40&md5=a4123f79adc1fb3b02f9de0aa65de922","The paper investigates a sampling-based extension of the NSGA-II algorithm, applied to the solution of a bi-objective stochastic covering tour problem. The proposed extension uses variable samples for gradually improving approximations to the Pareto front. The approach is evaluated on a test benchmark for a humanitarian logistics application with data from Senegal. Comparisons to alternative solution techniques, in particular also to the exact solution of the deterministic counterpart problem based on a fixed sample, show the superiority of our approach. © Springer International Publishing AG 2018.","Covering tour problem; Genetic algorithms; Humanitarian logistics; Multi-objective optimization; Stochastic optimization",,2-s2.0-85032615981
"Pan J.-S., Meng Z., Chu S.-C., Roddick J.F.","QUATRE Algorithm with Sort Strategy for Global Optimization in Comparison with DE and PSO Variants",2018,"Advances in Intelligent Systems and Computing",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030865122&doi=10.1007%2f978-3-319-68527-4_34&partnerID=40&md5=64dc9326096ec9dc692adcb6781698c3","Optimization algorithm in swarm intelligence is getting more and more prevalent both in theoretical field and in real-world applications. Many nature-inspired algorithms in this domain have been proposed and employed in different applications. In this paper, a new QUATRE algorithm with sort strategy is proposed for global optimization. QUATRE algorithm is a simple but powerful stochastic optimization algorithm proposed in 2016 and it tackles the representational/positional bias existing in DE structure. Here a sort strategy is used for the enhancement of the canonical QUATRE algorithm. This advancement is verified on CEC2013 test suite for real-parameter optimization and also is contrasted with several state-of-the-art algorithms including Particle Swarm Optimization (PSO) variants, Differential Evolution (DE) variants on COCO framework under BBOB2009 benchmarks. Experiment results show that the proposed QUATRE algorithm with sort strategy is competitive with the contrasted algorithms. © 2018, Springer International Publishing AG.","Differential evolution; Particle swarm optimization; QUATRE; Real parameter optimization; Swarm intelligence","Artificial intelligence; Data handling; Evolutionary algorithms; Global optimization; Information analysis; Particle swarm optimization (PSO); Swarm intelligence; Differential Evolution; Nature inspired algorithms; Optimization algorithms; QUATRE; Real-parameter optimization; Real-world; State-of-the-art algorithms; Stochastic optimization algorithm; Optimization",2-s2.0-85030865122
"Abraham K.T., Ashwin M., Sundar D., Ashoor T., Jeyakumar G.","Empirical comparison of different key frame extraction approaches with differential evolution based algorithms",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032677091&doi=10.1007%2f978-3-319-68385-0_27&partnerID=40&md5=9c25d22350dc7b37f0aed4299b369af8","Key frame extraction is an integral part of video analytics. The extracted key frames are used for video summarization and information retrieval. There exist many approaches for solving key frame extraction problem in video analytics. The focus of this paper is to extend the strategy of integrating Evolutionary Computing technique with a conventional key frame extraction approach, which is proposed by the authors in their previous work, with two other conventional approaches. The conventional approaches considered in this study are SSIM (Structural Similarity Index Method) Method, Entropy Method and Euclidean Distance method. This paper also proposes a new approach for key frame extraction by integrating the Euclidean Distance method with Differential Evolution algorithm. The proposed approach is compared with all the existing approaches by its speed and accuracy. It is found from the comparison that the proposed approach outperforms other approaches. The results and discussion related to this experiment study are presented in this paper. © Springer International Publishing AG 2018.","ASSIM values; Differential evolution; Entropy difference; Euclidean distance; Key frame extraction; Video analytics","Evolutionary algorithms; Intelligent systems; Optimization; ASSIM values; Differential Evolution; Entropy differences; Euclidean distance; Key-frame extraction; Video analytics; Extraction",2-s2.0-85032677091
"Wang Z., Mak C.M.","Optimization of geometrical parameters for periodical structures applied to floating raft systems by genetic algorithms",2018,"Applied Acoustics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026201888&doi=10.1016%2fj.apacoust.2017.07.018&partnerID=40&md5=5be56450f7236628363d3a2468cedb7b","This paper presented a theoretical study of the vibration control of a floating raft system using periodic structures. The band gap properties of the periodic structures, the power flow and the power transmissibility of the floating raft system were investigated by using the transfer matrix method. To minimize the power flow through periodic structures in a floating raft system, the geometrical parameters of the periodic structures were optimized by using a genetic algorithm. The numerical results demonstrated that the optimum periodic structure can provide broader stop band regions. The stop band regions of the optimum periodic structure contained all the harmonic frequencies of the force excitation in the floating raft system. The numerical results validated that the proposed optimization approach is sufficiently capable for the design of periodic structures. The proposed optimization approach has potential use for the development of vibration and shock isolation systems such as floating raft systems. © 2017 Elsevier Ltd","Floating raft; Genetic algorithms; Geometric optimization; Periodic structure; Vibration isolation","Electric load flow; Genetic algorithms; Geometry; Optimization; Parameter estimation; Shape optimization; Structural optimization; Transfer matrix method; Bandgap properties; Floating rafts; Geometric optimization; Harmonic frequency; Optimization approach; Periodical structure; Shock isolation system; Vibration isolations; Periodic structures",2-s2.0-85026201888
"Goyal A., Khandelwal I., Anand R., Srivastava A., Swarnalatha P.","A comparative analysis of the different data mining tools by using supervised learning algorithms",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028581672&doi=10.1007%2f978-3-319-60618-7_11&partnerID=40&md5=296529e57676b3a9114fad421f03ea18","These days a lot of raw data is generated from various common sources. This large amount of data, which would appear useless at first glance, is very important for companies and researchers as could provide a lot of helpful information. The data could be mined to get useful knowledge that could be used to make fruitful decisions. A lot of online tools and proprietary toolkits are available to the users and it becomes all the more cumbersome for them to know which is the best tool among these for the supervised learning algorithm and datasets they are applying. In order to aid this process, the paper progresses in this direction by doing a comparison of various data mining tools on the basis of their classification finesse. The various tools used in the paper are weka, knime and tanagra. Rigorous work on this has given the result that the performance of the tools is affected by the kind of datasets used and the way in which the supervised learning is done. © Springer International Publishing AG 2018.","Knime; Mining tools; Supervised learning; Tanagra; Weka","Data mining; Pattern recognition; Soft computing; Supervised learning; Common source; Comparative analysis; Data-mining tools; Knime; Large amounts; On-line tools; Tanagra; Weka; Learning algorithms",2-s2.0-85028581672
"Uppal R.S.","Hybrid intelligent algorithm for energy-efficient routing in WSN",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031432009&doi=10.1007%2f978-981-10-6614-6_19&partnerID=40&md5=60cca322a4a8abaee76ad827981e0e32","Sensing data by sensor nodes in wireless sensor network (WSN) is random both in space and time. Routing of sensed data to base station in energy constrained WSN become more challenging as batteries of sensor nodes got consumed with every round of routing. Data packets are routed in multihop wireless communication in Time Division Multiple Access mode to base station. In this paper, soft computing techniques are used to propose an intelligent algorithm which enhances network lifetime by providing energy efficient routing. This is a hybrid approach in which genetic algorithm with partially mapped crossover is applied to find optimal routes while fuzzy logic is used to determine link cost. In order to make routing optimal, the link cost between adjacent nodes is calculated that consider residual energy of node, distance from base station, and density of nodes in a cluster. Fuzzy logic mechanism is used to calculate this link cost of all adjacent nodes, and these costs are represented in a link cost matrix which is updated after every round. This algorithm is based on hierarchal routing concept, and K-Mean numerical approach is used for clustering of sensor nodes. The approach is successfully implemented in MATLAB, and the simulation results of the various scenario show that the number of rounds before which the first node dies is more than LEEACH, thereby it enhances network lifetime as compared to LEEACH. © 2018, Springer Nature Singapore Pte Ltd.","K-Mean; Routing; Soft computing; WSN","Base stations; Clustering algorithms; Computation theory; Computer circuits; Costs; Energy efficiency; Fuzzy logic; Genetic algorithms; Image processing; MATLAB; Mobile telecommunication systems; Routing algorithms; Soft computing; Time division multiple access; Wireless sensor networks; Wireless telecommunication systems; Energy efficient routing; Energy-constrained; Hybrid intelligent algorithms; Intelligent Algorithms; K-means; Numerical approaches; Routing; Softcomputing techniques; Sensor nodes",2-s2.0-85031432009
"Pal H., Rohilla B., Singh T.","A deadline-aware modified genetic algorithm for scheduling jobs with burst time and priorities",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031395999&doi=10.1007%2f978-981-10-6747-1_7&partnerID=40&md5=142449198441f6d20c0367daf7371d5d","Scheduling plays a vital role in our real life, same as CPU scheduling majorly affects the performance of computer system. For better performance, scheduling depends upon the parameters of jobs (arrival time, burst time, priority, etc.). Different algorithms have been used to find the above factors. Many algorithms such as FCFS, SJF, round-robin, priority are applied, but all these techniques provide a sequence of jobs relevant to their properties. Developing an appropriate sequence using previously known algorithms takes exponential time. This paper proposes an efficient method for process scheduling using a deadline-aware approximation algorithm, where required schedule has a certain weightage of priority and burst time of job. Here, GA and modified GA are compared in terms of number of iterations, number of test cases, requirement percentage and tardiness (fitness value). The results demonstrate that modified GA approach produces solutions very close to the optimal one in comparison with GA. © 2018, Springer Nature Singapore Pte Ltd.","CPU scheduling; Crossover; Genetic algorithm; Optimization","Approximation algorithms; Genetic algorithms; Optimization; Routers; Scheduling; CPU scheduling; Crossover; Exponential time; Modified genetic algorithms; Number of iterations; Performance of computer system; Process scheduling; Scheduling jobs; Scheduling algorithms",2-s2.0-85031395999
"Kahankova R., Martinek R., Bilik P.","Non-invasive fetal ECG extraction from maternal abdominal ECG using LMS and RLS adaptive algorithms",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028675716&doi=10.1007%2f978-3-319-60834-1_27&partnerID=40&md5=a91830f095ab403426aa69d4a6dd4fa8","This paper focuses on the fetal electrocardiogram (fECG) recorded transabdominally. This method could become very efficient and essential tool in monitoring and diagnosing endangered fetuses during the pregnancy and the delivery. The greatest challenge connected with this kind of monitoring is the amount of noise that is recorded within the desired signal. Thus, the extraction of the fECG from the composite abdominal signal is discussed. The authors’ aim is to introduce the most suitable representatives from the Least Mean Squares (LMS) and Recursive Least Square (RLS) based Finite Impulse Response (FIR) Adaptive Filters. Experimental results suggest the ideal combination of the chosen filters’ settings (Step size, filter length, forgetting factor etc.). Results of fECG extraction are evaluated by the objective parameters, namely Percentage Root-Mean-Square Difference (PRD), input and output Signal to Noise Ratios (SNRs), and Root Mean Square Error (RMSE). © 2018, Springer International Publishing AG.","Adaptive filtering; fECG; LMS; mECG; RLS","Adaptive algorithms; Adaptive filtering; Adaptive filters; Electrocardiography; Extraction; Impulse response; Mean square error; Signal to noise ratio; fECG; Fetal electrocardiograms; Finite-impulse response; Least mean square (LMS); mECG; Percentage root-mean-square differences; Recursive least square (RLS); Root mean square errors; Biomedical signal processing",2-s2.0-85028675716
"Alswaitti M., Albughdadi M., Isa N.A.M.","Density-based particle swarm optimization algorithm for data clustering",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028849459&doi=10.1016%2fj.eswa.2017.08.050&partnerID=40&md5=ece85faa884d69ee929e1f99b492b1d4","Particle swarm optimization (PSO) algorithm is widely used in cluster analysis. However, it is a stochastic technique that is vulnerable to premature convergence to sub-optimal clustering solutions. PSO-based clustering algorithms also require tuning of the learning coefficient values to find better solutions. The latter drawbacks can be evaded by setting a proper balance between the exploitation and exploration behaviors of particles while searching the feature space. Moreover, particles must take into account the magnitude of movement in each dimension and search for the optimal solution in the most populated regions in the feature space. This study presents a novel approach for data clustering based on particle swarms. In this proposal, the balance between exploitation and exploration processes is considered using a combination of (i) kernel density estimation technique associated with new bandwidth estimation method to address the premature convergence and (ii) estimated multidimensional gravitational learning coefficients. The proposed algorithm is compared with other state-of-the-art algorithms using 11 benchmark datasets from the UCI Machine Learning Repository in terms of classification accuracy, repeatability represented by the standard deviation of the classification accuracy over different runs, and cluster compactness represented by the average Dunn index values over different runs. The results of Friedman Aligned-Ranks test with Holm's test over the average classification accuracy and Dunn index values indicate that the proposed algorithm achieves better accuracy and compactness when compared with other algorithms. The significance of the proposed algorithm is represented in addressing the limitations of the PSO-based clustering algorithms to push forward clustering as an important technique in the field of expert systems and machine learning. Such application, in turn, enhances the classification accuracy and cluster compactness. In this context, the proposed algorithm achieves better results compared with other state-of-the-art algorithms when applied to high-dimensional datasets (e.g., Landsat and Dermatology). This finding confirms the importance of estimating multidimensional learning coefficients that consider particle movements in all the dimensions of the feature space. The proposed algorithm can likewise be applied in repeatability matters for better decision making, as in medical diagnosis, as proved by the low standard deviation obtained using the proposed algorithm in conducted experiments. © 2017 Elsevier Ltd","Data clustering; Exploitation and exploration balance; Kernel density estimation; Particle swarm optimization; Swarm intelligence; Universal gravity rule","Artificial intelligence; Classification (of information); Cluster analysis; Decision making; Diagnosis; Estimation; Evolutionary algorithms; Expert systems; Learning algorithms; Learning systems; Optimization; Particle swarm optimization (PSO); Statistics; Stochastic systems; Swarm intelligence; Data clustering; Exploitation and explorations; High dimensional datasets; Kernel Density Estimation; Particle swarm optimization algorithm; State-of-the-art algorithms; UCI machine learning repository; Universal gravity rule; Clustering algorithms",2-s2.0-85028849459
"Agarwal M., Srivastava G.M.S.","A cuckoo search algorithm-based task scheduling in cloud computing",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031407915&doi=10.1007%2f978-981-10-3773-3_29&partnerID=40&md5=0e59ccf0cafd61e1446ac6d6cbdc8ba7","Recently, Cloud computing emerges out as a latest technology which enables an organization to use the computing resources like hardware, applications, and software, etc., to perform the computation over the internet. Cloud computing gain so much attention because of advance technology, availability, and cost reduction. Task scheduling in cloud computing emerges out as new area of research which attracts the attention of lots researchers. An effective task scheduling is always required for optimum or efficient utilization of the computing resources to avoid the situation of over or under-utilization of such resources. Through this paper, we are going to proposed the cuckoo search-based task scheduling approach which helps in distributing the tasks efficiently among the available virtual machines (VM’s) and also keeps the overall response time (QoS) minimum. This algorithm assigns the tasks among the virtual machines on the basis of their processing power, i.e., million instructions per seconds (MIPS) and length of the tasks. A comparison of cuckoo search algorithm is done with the first—in first—out (FIFO) and greedy-based scheduling algorithm which is performed using the CloudSim simulator, the results clearly shows that cuckoo search outperforms the other algorithms. © Springer Nature Singapore Pte Ltd. 2018.","Cloud computing; Cuckoo search; Genetic algorithm; Makespan; QoS; Task scheduling; Virtual machines","Application programs; Cloud computing; Cost reduction; Genetic algorithms; Learning algorithms; Multitasking; Network function virtualization; Network security; Optimization; Quality of service; Virtual machine; Computing resource; Cuckoo search algorithms; Cuckoo searches; Latest technology; Makespan; Million instructions per seconds; Processing power; Task-scheduling; Scheduling algorithms",2-s2.0-85031407915
"Mohd Zain M.Z.B., Kanesan J., Kendall G., Chuah J.H.","Optimization of fed-batch fermentation processes using the Backtracking Search Algorithm",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029363592&doi=10.1016%2fj.eswa.2017.07.034&partnerID=40&md5=1b15659e9388a4475ca63f0b73382e0b","Fed-batch fermentation has gained attention in recent years due to its beneficial impact in the economy and productivity of bioprocesses. However, the complexity of these processes requires an expert system that involves swarm intelligence-based metaheuristics such as Artificial Algae Algorithm (AAA), Artificial Bee Colony (ABC), Covariance Matrix Adaptation Evolution Strategy (CMAES) and Differential Evolution (DE) for simulation and optimization of the feeding trajectories. DE traditionally performs better than other evolutionary algorithms and swarm intelligence techniques in optimization of fed-batch fermentation. In this work, an improved version of DE namely Backtracking Search Algorithm (BSA) has edged DE and other recent metaheuristics to emerge as superior optimization method. This is shown by the results obtained by comparing the performance of BSA, DE, CMAES, AAA and ABC in solving six fed batch fermentation case studies. BSA gave the best overall performance by showing improved solutions and more robust convergence in comparison with various metaheuristics used in this work. Also, there is a gap in the study of fed-batch application of wastewater and sewage sludge treatment. Thus, the fed batch fermentation problems in winery wastewater treatment and biogas generation from sewage sludge are investigated and reformulated for optimization. © 2017 Elsevier Ltd","Backtracking Search Algorithm; Evolutionary algorithms; Fed-batch fermentation; Feeding trajectory optimization; Sewage sludge; Wastewater treatment","Artificial intelligence; Covariance matrix; Evolutionary algorithms; Expert systems; Fermentation; Heuristic algorithms; Learning algorithms; Sewage sludge; Swarm intelligence; Wastewater treatment; Wine; Artificial bee colonies (ABC); Backtracking search algorithms; Covariance matrix adaptation evolution strategies; Fed-batch fermentation; Sewage sludge treatment; Simulation and optimization; Swarm intelligence techniques; Trajectory optimization; Optimization",2-s2.0-85029363592
"Boon K.H., Khalil-Hani M., Malarvili M.B.","Paroxysmal atrial fibrillation prediction based on HRV analysis and non-dominated sorting genetic algorithm III",2018,"Computer Methods and Programs in Biomedicine",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032011695&doi=10.1016%2fj.cmpb.2017.10.012&partnerID=40&md5=920924391d560ddb5e770815138b5025","This paper presents a method that able to predict the paroxysmal atrial fibrillation (PAF). The method uses shorter heart rate variability (HRV) signals when compared to existing methods, and achieves good prediction accuracy. PAF is a common cardiac arrhythmia that increases the health risk of a patient, and the development of an accurate predictor of the onset of PAF is clinical important because it increases the possibility to electrically stabilize and prevent the onset of atrial arrhythmias with different pacing techniques. We propose a multi-objective optimization algorithm based on the non-dominated sorting genetic algorithm III for optimizing the baseline PAF prediction system, that consists of the stages of pre-processing, HRV feature extraction, and support vector machine (SVM) model. The pre-processing stage comprises of heart rate correction, interpolation, and signal detrending. After that, time-domain, frequency-domain, non-linear HRV features are extracted from the pre-processed data in feature extraction stage. Then, these features are used as input to the SVM for predicting the PAF event. The proposed optimization algorithm is used to optimize the parameters and settings of various HRV feature extraction algorithms, select the best feature subsets, and tune the SVM parameters simultaneously for maximum prediction performance. The proposed method achieves an accuracy rate of 87.7%, which significantly outperforms most of the previous works. This accuracy rate is achieved even with the HRV signal length being reduced from the typical 30 min to just 5 min (a reduction of 83%). Furthermore, another significant result is the sensitivity rate, which is considered more important that other performance metrics in this paper, can be improved with the trade-off of lower specificity. © 2017 Elsevier B.V.","Arrhythmia prediction; Feature selection; Heart rate variability; Multi-objective optimization; Non-dominated Sorting genetic algorithm III; Paroxysmal atrial fibrillation","Biomedical signal processing; Cardiology; Diseases; Economic and social effects; Extraction; Feature extraction; Forecasting; Frequency domain analysis; Genetic algorithms; Health risks; Heart; Multiobjective optimization; Sorting; Support vector machines; Time domain analysis; Feature extraction algorithms; Heart rate variability; Non- dominated sorting genetic algorithms; Optimization algorithms; Paroxysmal atrial fibrillations; Performance metrics; Prediction accuracy; Prediction performance; Optimization",2-s2.0-85032011695
"Ahmad R., Choubey N.S.","Review on image enhancement techniques using biologically inspired artificial bee colony algorithms and its variants",2018,"Lecture Notes in Computational Vision and Biomechanics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028061713&doi=10.1007%2f978-3-319-61316-1_11&partnerID=40&md5=779f4bc5e08f6d01df94885d0cc17e17","When medical images are processed by morphological operations, they provide substantial amount of utilizable information. The technological advancement in the field of image analysis and medical imaging domain acquiesces the understating of detection and diagnosis of disease to enhance the quality of medical treatment. Application of image processing in medical imaging field administers the development of processing nebulous, skeptical, reciprocal, superfluous information, and data for a vigorous structural attribute. To understand any image, the human and artificial astuteness system matches the features extracted from an image. Image enhancement is a decisive stage in image processing system. It intents at convalescencing the ocular data and the informational trait of wry images. After the acquisition of an image, if it is of poor quality, it requires enhancement. Various available techniques can be applied for enhancement; some are providing good results with limitation of computing time. A new intelligent algorithmic approach, based upon biologically inspired approaches, is suggested for image enhancement. In this ambience, this article describes about one of the most commonly used algorithms known as artificial bee colony algorithm, and its various types, used for image enhancement in different subdomains of medical imaging, are covered here. © 2018, Springer International Publishing AG.","ABC with ASF; ABC with BPNN; ABC with FCM; ABC with FCONN; ABC with LS-SVM; ABC with Otsu method; ABC with radial basis function NN; ABC with SOM-based k-means clustering; Algorithmic structures of swarm intelligence ABC with neural network; Artificial bee colony algorithm; Basic ABC; CABC with forward NN; EABCO; HABC with KELM; Modified ABC algorithm; Multiscale retinex (MSR) using the artificial bee colony (ABC) algorithm; Swarm intelligence",,2-s2.0-85028061713
"Singh K., Sundar S.","Artifical bee colony algorithm using problem-specific neighborhood strategies for the tree t-spanner problem",2018,"Applied Soft Computing Journal",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032455393&doi=10.1016%2fj.asoc.2017.10.022&partnerID=40&md5=20b63b16f6d327f07a8c8a0a7fac462b","A tree t-spanner is a spanning tree T in which the ratio of distance between every pair of vertices is at most t times their shortest distance in a connected graph, where t is a value called stretch factor of T. On a given connected, undirected, and weighted graph, this paper studies the tree t-spanner problem (Tree_t-SP) that aims to find a spanning tree whose stretch factor is minimum amongst all spanning trees of the graph. Being a NP-Hard for any fixed t > 1, this problem is under-studied in the domain of metaheuristic techniques. In literature, only genetic algorithm has been proposed for this problem. This paper presents an artificial bee colony (ABC) algorithm for this problem, where ABC algorithm is a swarm intelligence technique inspired by intelligent foraging behavior of honey bees. Neighborhood strategies of ABC algorithm particularly employ problem-specific knowledge that makes ABC algorithm highly effective in searching high quality solutions in less computational time. Computational experiments on a large set of randomly generated graph instances exhibit superior performance of ABC algorithm over the existing genetic algorithm for the Tree_t-SP. © 2017 Elsevier B.V.","Artificial bee colony algorithm; Problem-specific knowledge; Swarm intelligence; Tree spanner; Weighted graph","Artificial intelligence; Evolutionary algorithms; Genetic algorithms; Graph theory; Graphic methods; Optimization; Swarm intelligence; Artificial bee colony algorithms; Artificial bee colony algorithms (ABC); Computational experiment; Meta-heuristic techniques; Problem-specific knowledge; Swarm intelligence techniques; Tree spanner; Weighted graph; Trees (mathematics)",2-s2.0-85032455393
"Arora S., Kaur P.","Grayscale image enhancement using improved cuckoo search algorithm",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026767030&doi=10.1007%2f978-981-10-3373-5_13&partnerID=40&md5=a8ec9ce3a0c1ce66d4e07c5a6218a4ef","Meta-heuristic algorithms have been proved to play a significant role in the automatic image enhancement domain which can be regarded as an optimization question. Cuckoo search algorithm is one such algorithm which uses Levy flight distribution to find out the optimized parameters affecting the enhanced image. In this paper, improved cuckoo search algorithm is proposed which is used to achieve the better optimized results. The proposed method is implemented on some test images, and results are compared with original cuckoo search algorithm. © Springer Nature Singapore Pte Ltd. 2018.","Cuckoo search; Gauss distribution; Image enhancement; Improved cuckoo search algorithm; Meta-heuristics","Computation theory; Heuristic algorithms; Image enhancement; Intelligent computing; Learning algorithms; Cuckoo search algorithms; Cuckoo searches; Gauss distribution; Levy flights; Meta heuristic algorithm; Meta heuristics; Optimized parameter; Test images; Optimization",2-s2.0-85026767030
"Mousavi S., Mosavi A., Varkonyi-Koczy A.R.","A load balancing algorithm for resource allocation in cloud computing",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029796640&doi=10.1007%2f978-3-319-67459-9_36&partnerID=40&md5=eda892f2535e5e681eadf03dcfaeced6","Utilizing dynamic resource allocation for load balancing is considered as an important optimization process of task scheduling in cloud computing. A poor scheduling policy may overload certain virtual machines while remaining virtual machines are idle. Accordingly, this paper proposes a hybrid load balancing algorithm with combination of Teaching-Learning-Based Optimization (TLBO) and Grey Wolves Optimization algorithms (GWO), which can well contribute in maximizing the throughput using well balanced load across virtual machines and overcome the problem of trap into local optimum. The hybrid algorithm is benchmarked on eleven test functions and a comparative study is conducted to verify the results with particle swarm optimization (PSO), Biogeography-based optimization (BBO), and GWO. To evaluate the performance of the proposed algorithm for load balancing, the hybrid algorithm is simulated and the experimental results are presented. © Springer International Publishing AG 2018.","Cloud computing; Optimization; Resource allocation","Cloud computing; Education; Heuristic algorithms; Network security; Particle swarm optimization (PSO); Resource allocation; Virtual machine; Biogeographybased optimizations (BBO); Comparative studies; Dynamic resource allocations; Hybrid algorithms; Load balancing algorithms; Optimization algorithms; Scheduling policies; Teaching-learning-based optimizations; Optimization",2-s2.0-85029796640
"Inclan E., Geohegan D., Yoon M.","A hybrid optimization algorithm to explore atomic configurations of TiO2 nanoparticles",2018,"Computational Materials Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029498711&doi=10.1016%2fj.commatsci.2017.08.046&partnerID=40&md5=8a3b7d41136773ae94b5f5e3d0dcd3a6","In this paper we present a hybrid algorithm comprised of differential evolution, coupled with the Broyden–Fletcher–Goldfarb–Shanno quasi-Newton optimization algorithm, for the purpose of identifying a broad range of (meta)stable TinO2 n nanoparticles, as an example system, described by Buckingham interatomic potential. The potential and its gradient are modified to be piece-wise continuous to enable use of these continuous-domain, unconstrained algorithms, thereby improving compatibility. To measure computational effectiveness a regression on known structures is used. This approach defines effectiveness as the ability of an algorithm to produce a set of structures whose energy distribution follows the regression as the number of TinO2 n increases such that the shape of the distribution is consistent with the algorithm's stated goals. Our calculation demonstrates that the hybrid algorithm finds global minimum configurations more effectively than the differential evolution algorithms, widely employed in the field of materials science. Specifically, the hybrid algorithm is shown to reproduce the global minimum energy structures reported in the literature up to n = 5, and retains good agreement with the regression up to n = 25. For 25 &lt; n &lt; 100, where literature structures are unavailable, the hybrid effectively obtains structures that are in lower energies per TiO2 unit as the system size increases. © 2017 Elsevier B.V.","Atomistic simulations; Differential evolution; Global structure search algorithm; Hybrid algorithm; Titanium dioxide (TiO2)","Evolutionary algorithms; Global optimization; Hybrid materials; Nanoparticles; Regression analysis; Atomistic simulations; Differential Evolution; Hybrid algorithms; Search Algorithms; Titanium dioxides (TiO2); Optimization",2-s2.0-85029498711
"Ahmad N., Bibi R., Khan S.A.","Cost effective provisioning of electricity in smart nano-grid using GA and optimized heuristic algorithm",2018,"Mechanisms and Machine Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031276808&doi=10.1007%2f978-3-319-67567-1_33&partnerID=40&md5=0936b6687305189853e754442198ed6f","In the last few decades, developing countries power demand has increased which lead to several critical issues like frequent power outages and peak pricing hours. Utilization of distributed energy sources along with utility grid has helped to cope with these issues to certain level but still there are some loopholes. Novel intelligent algorithms are needed to handle such hybrid systems. In this paper, an algorithm is proposed for consistent and cost effective power supply for Grid-connected photovoltaic system which considers a set of constraints i.e. load-shedding hours, tariff hours and weather conditions. This paper proposes genetic algorithm for making optimal decision for the cost, considering all the above mentioned constraints. The research has also presented another heuristic algorithm which takes much less computation time then Genetic Algorithm and provides comparable results. © 2018, Springer International Publishing AG.","Best fitness value; Genetic algorithm; Heuristic algorithm; Smart nano-grid","Cost effectiveness; Costs; Developing countries; Electric load shedding; Electric power systems; Genetic algorithms; Heuristic algorithms; Hybrid systems; Optimization; Outages; Photovoltaic cells; Computation time; Critical issues; Distributed energy sources; Fitness values; Grid-connected photovoltaic system; Intelligent Algorithms; Optimal decisions; Smart nano-grid; Electric power transmission networks",2-s2.0-85031276808
"Agrawal A.P., Kaur A.","A comprehensive comparison of ant colony and hybrid particle swarm optimization algorithms through test case selection",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021226331&doi=10.1007%2f978-981-10-3223-3_38&partnerID=40&md5=57363d8ec0e7c45589fbf22b0a993e82","The focus of this paper is towards comparing the performance of two metaheuristic algorithms, namely Ant Colony and Hybrid Particle Swarm Optimization. The domain of enquiry in this paper is Test Case Selection, which has a great relevance in software engineering and requires a good treatment for the effective utilization of the software. Extensive experiments are performed using the standard flex object from SIR repository. Experiments are conducted using Matlab, where Execution time and Fault Coverage are considered as quality measure, is reported in this paper which is utilized for the analysis. The underlying motivation of this paper is to create awareness in two aspects: Comparing the performance of metaheuristic algorithms and demonstrating the significance of test case selection in software engineering. © Springer Nature Singapore Pte Ltd. 2018.","Ant colony optimization; Meta-heuristics; Optimization; Particle swarm optimization; Regression testing","Ant colony optimization; Intelligent computing; MATLAB; Particle swarm optimization (PSO); Software engineering; Software testing; Comprehensive comparisons; Hybrid Particle Swarm Optimization; Hybrid particle swarm optimization algorithm; Meta heuristic algorithm; Meta heuristics; Quality measures; Regression testing; Test case selection; Optimization",2-s2.0-85021226331
"Xiao Q., Li J., Xiao C.","Research on performance optimization of several frequently-used genetic algorithm selection operators",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032665554&doi=10.1007%2f978-3-319-67071-3_14&partnerID=40&md5=1092fa5967c5cac27381878e32fc9276","Genetic Algorithm is an intelligent algorithm for simulation of biological evolution, is widely applied to solve all kinds of problems. In this paper, several Frequently-used selection operators of Genetic Algorithm are programmed by C language, and are tested in an optimization problem. © 2018, Springer International Publishing AG.","Genetic algorithm; Hausdorff measure; Selection operator; Sierpinski carpet","Bioinformatics; Biology; C (programming language); Evolutionary algorithms; Genetic algorithms; Algorithm selection; Biological evolution; Hausdorff measures; Intelligent Algorithms; Optimization problems; Performance optimizations; Selection operators; Sierpinski carpet; Optimization",2-s2.0-85032665554
"Zidane I.M., Ibrahim K.","Wavefront and a-star algorithms for mobile robot path planning",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029547358&doi=10.1007%2f978-3-319-64861-3_7&partnerID=40&md5=614838cbb00a14bc7eed3523c99399fa","In the last years, many strategies of route planning have been invented. But some problems still be there, such as dead end, U-shape, shortest path, and the required time which is the main element if the environment is dynamic. The main idea of this paper is how we can reduce the required time when we deal with a picture with any size which represents the map to explore the main elements (Obstacles, Target, Robot position) from it and finding the shortest path for the robot to move. Instructions of movement depend basically on WAVEFRONT Algorithm (WFA) and A_STAR (A*) algorithm. By using MATLAB software we can make a simulation for algorithms that applied on the map that figured out from image processing to find the shortest path between target and robot position without collision with obstacles and calculate the processing time. © 2018, Springer International Publishing AG.","A_star algorithm; Image processing; Matlab software; Path planning; Wavefront algorithm",,2-s2.0-85029547358
"Wang S., Gao F.","Improvements of wireless network routing clustering algorithm",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028399688&doi=10.1007%2f978-3-319-60744-3_54&partnerID=40&md5=f536b5160b19a664d4174be91fc9f5a7","According to the agreement of wireless network base layer, and for the issues of energy consumption in the network search and node inequality, this paper introduced routing clustering algorithm, which is improved by the acoustic search algorithm, to make parameter optimization settings with nodes, node distance and cluster distance and decrease routing nodes allocation time so as to reduce the network search time, saves the transmission energy consumption and increase operational efficiency. Experiments proved the feasibility of optimization algorithm proposed in this paper, which has realized the practical application effect on the rational optimization of routing clustering. According to the LEACH protocol cluster random, the cluster head distribution is uniform, resulting in the network life cycle is too short, put forward a hierarchical clustering routing algorithm based on wireless sensor (Multi-Energy balance clustering hierarchy, MEBC). In the algorithm, the sensor nodes are divided into different levels, in order to hop and energy as the transmission path the establishment of standards, through the autonomy of base station and the multi hop transmission to route choice, rather than direct transmission of multi cluster head sensor node and the base station node, it can effectively prolong the network life cycle. © 2018, Springer International Publishing AG.","Acoustic algorithm; Clustering algorithm; Wireless network","Base stations; Energy utilization; Intelligent systems; Life cycle; Network layers; Network routing; Optimization; Power management (telecommunication); Real time systems; Routing algorithms; Sensor nodes; Wireless networks; Wireless sensor networks; Hier-archical clustering; Multihop transmission; Network life cycle; Operational efficiencies; Optimization algorithms; Parameter optimization; Rational optimization; Transmission energy consumption; Clustering algorithms",2-s2.0-85028399688
"Peraza C., Valdez F., Castillo O.","Comparative study of type-1 and interval type-2 fuzzy systems in the fuzzy harmony search algorithm applied to benchmark functions",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029455345&doi=10.1007%2f978-3-319-66827-7_15&partnerID=40&md5=f7508d81344aa705ea74d7ddbd728d76","At present the use of fuzzy systems applied to problem solving is very common, since the use of linguistic variables is less complex when solving a problem. This article presents a study of the use of type-1 and interval type-2 fuzzy system applied to the solution of problems of optimization using metaheuristic algorithms. There are many types of algorithms that mimic social, biological, etc. behaviors. In this case the work focuses on the metaheuristic algorithms in specific the fuzzy harmony search algorithm (FHS), the metaheuristic algorithms use a technique to obtain a suitable exploration in a definite space to finish with an exploitation around the best position found, with this it is possible to obtain a good solution of the problem. In particular, it was applied to 11 mathematical reference functions using different numbers of dimensions. © 2018, Springer International Publishing AG.","Dynamic parameter adaptation; Harmony search; Metaheuristic algorithms; Type-1 fuzzy logic; Type-2 fuzzy logic","Bioinformatics; Computer circuits; Functions; Fuzzy sets; Fuzzy systems; Learning algorithms; Optimization; Pattern matching; Problem solving; Benchmark functions; Dynamic parameter adaptation; Harmony search; Harmony search algorithms; Interval type-2 fuzzy; Meta heuristic algorithm; Reference functions; Type-2 fuzzy logic; Fuzzy logic",2-s2.0-85029455345
"Peraza C., Valdez F., Castillo O.","Study on the use of type-1 and interval type-2 fuzzy systems applied to benchmark functions using the fuzzy harmony search algorithm",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030671986&doi=10.1007%2f978-3-319-67137-6_10&partnerID=40&md5=3803608a3ae74ae6e623ba1f1f2b67bf","At present the use of fuzzy systems applied to problem solving is very common, since the use of linguistic variables is less complex when solving a problem. This article presents a study of the use of Type-1 and interval Type-2 fuzzy system applied to the solution of problems of optimization using metaheuristic algorithms. There are many types of algorithms that mimic social, biological, etc. behaviors. In this case the work focuses on the metaheuristic algorithms in specific the fuzzy harmony search algorithm (FHS), the metaheuristic algorithms use a technique to obtain a suitable exploration in a definite space to finish with exploitation around the best position found; with this it is possible to obtain a good solution of the problem. In particular, it was applied to 11 mathematical reference functions using different numbers of dimensions. © Springer International Publishing AG 2018.","Dynamic parameter adaptation; Harmony search; Metaheuristic algorithms; Type-1 fuzzy logic; Type-2 fuzzy logic","Bioinformatics; Functions; Fuzzy logic; Fuzzy systems; Learning algorithms; Optimization; Benchmark functions; Dynamic parameter adaptation; Harmony search; Harmony search algorithms; Interval type-2 fuzzy; Linguistic variable; Meta heuristic algorithm; Type-2 fuzzy logic; Problem solving",2-s2.0-85030671986
"Na-Udom A., Rungrattanaubol J.","Applying stochastic evolutionary algorithm for correlation control in monte carlo simulation",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022215214&doi=10.1007%2f978-3-319-60663-7_1&partnerID=40&md5=20d25deccc029dd8f30e27cb8696c30e","This paper presents an application of stochastic evolutionary algorithm (SE) in generating correlated multivariate random samples for Monte Carlo simulation. The algorithm is applied to impose the correlation structure when the marginal distribution and correlation matrix are pre-specified. The performance of a proposed method is compared with the existing methods namely simulated annealing algorithm (SA). The results show that SE performs well and is comparable to SA for all case studies under consideration. Further, SE is capable to impose the correlation structure in a hard case such that the correlation structure is nearly positive definite. Hence, SE seems to be a good approach to use in any Monte Carlo simulations such as risk analysis model and computer simulations. © Springer International Publishing AG 2018.","Correlated multivariate random samples; Monte carlo simulation; Simulated annealing algorithm; Stochastic evolutionary algorithm","Evolutionary algorithms; Risk analysis; Risk assessment; Simulated annealing; Stochastic systems; Correlation control; Correlation matrix; Correlation structure; Marginal distribution; Positive definite; Random sample; Simulated annealing algorithms; Stochastic evolutionary algorithms; Monte Carlo methods",2-s2.0-85022215214
"Oskorbin N., Khvalynskiy D.","Decomposition Algorithms for Mathematical Programming and Generalization of the Dantzig-Wolfe Method",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029590864&doi=10.1007%2f978-3-319-67618-0_4&partnerID=40&md5=eb513718f8336bd58fa3d3bd789326d6","The main result of the paper is the applicability of Dantzig-Wolfe method for Large-Scale Nonlinear Programming with composite (block) structure of the function and constraints. Equivalent transformation of this problem is a task decomposition and coordination. This result allows to propose a new class of decomposition methods, which differ in approximating a feasible solution set of the coordination problem. The authors propose the modification of the Dantzig-Wolfe algorithm for solving mathematical programming problems, where coordinating solutions is a convex set. It was applied as a decomposition algorithm for a quadratic programming problem. The algorithm was implemented in MS Excel environment and its efficiency was studied and tested. The rate of convergence in the number of global iterations was defined in tests, and it is shown that the proposed algorithm is not significantly different from the Dantzig-Wolfe algorithm in linear block programming. © 2018, Springer International Publishing AG.","Coordination problems; Dantzig-Wolfe decomposition; Decomposition algorithm for quadratic programming; Nonlinear Large-Scale optimization","Computational methods; Intelligent systems; Mathematical programming; Nonlinear programming; Optimization; Quadratic programming; Set theory; Coordination problems; Dantzig-wolfe decomposition; Decomposition algorithm; Equivalent transformations; Large-scale nonlinear programming; Large-scale optimization; Mathematical programming problem; Quadratic programming problems; Problem solving",2-s2.0-85029590864
"Li J.-B., Liu H., Pan J.-S., Yao H.","Training samples-optimizing based dictionary learning algorithm for MR sparse superresolution reconstruction",2018,"Biomedical Signal Processing and Control",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026914630&doi=10.1016%2fj.bspc.2017.08.007&partnerID=40&md5=7a2925f927fccdfdbdd1360535595085","Magnetic Resonance (MR) imaging is widely used in diseases diagnosis. The hardware imaging arrives the limitation of resolution, and the high radiation intensity and time of magnetic hurts the human body. The software-based image super-resolution technology is prospective to solve the problem, especially with good excellent performance by sparse reconstruction-based image super-resolution. Dictionary generating is crucial issue of effecting the performance of the super-resolution algorithm, because of without considering the potential discriminative information during dictionary generating. For this problem, we propose the training samples-optimized dictionary learning algorithm for MR sparse super-resolution reconstruction. The gray-consistency & gradient joined diversity-based dictionary representation method is proposed to select the optimal images for the dictionary training. The dictionary training method is evaluated with the framework of sparse reconstruction-based MR imaging. Results show that the proposed dictionary selection framework is feasible and effective to improve the quality of sparse reconstruction-based MR super-resolution. © 2017 Elsevier Ltd","Dictionary diversity; Magnetic resonance imaging; Sparse reconstruction; Super-resolution imaging","Diagnosis; Image processing; Learning algorithms; Magnetic levitation vehicles; Magnetic resonance imaging; Magnetism; Optical resolving power; Sampling; Dictionary learning algorithms; Dictionary trainings; Image super resolutions; Representation method; Sparse reconstruction; Super resolution algorithms; Super resolution imaging; Super resolution reconstruction; Image reconstruction; Article; feasibility study; human; image quality; image reconstruction; learning algorithm; magnetic resonance imaging sparse super resolution reconstruction; nuclear magnetic resonance imaging; priority journal; training samples optimized dictionary learning algorithm",2-s2.0-85026914630
"Clark P.G., Gao C., Grzymala-Busse J.W.","MLEM2 rule induction algorithm with multiple scanning discretization",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020411921&doi=10.1007%2f978-3-319-59421-7_20&partnerID=40&md5=2446a3c50f9cd379906225d688dc548b","In this paper we show experimental results on the MLEM2 rule induction algorithm and the Multiple Scanning discretization algorithm. The MLEM2 algorithm of rule induction has its own mechanisms to handle missing attribute values and numerical data. We compare, in terms of an error rate, two setups: MLEM2 used for rule induction directly from incomplete and numerical data and MLEM2 inducing rule sets from data sets previously discretized by Multiple Scanning and then converted to be incomplete. In both setups certain and possible rule sets were induced. For certain rule sets, the former setup was more successful for two data sets, while the latter setup was more successful for four data sets, for eight data sets the difference was not significant (Wilcoxon test, 5% significance level). Similarly, for possible rule sets the former setup was more successful for two data sets, while the latter setup was more successful for three data sets. Thus we may conclude that there is not significant difference between both setups and that we may use MLEM2 for rule induction directly from incomplete and numerical data. © Springer International Publishing AG 2018.","Concept lower and upper approximations; Incomplete data; MLEM2 rule induction algorithm; Multiple discretization algorithm","Rough set theory; Scanning; Attribute values; Discretization algorithms; Discretizations; Incomplete data; Lower and upper approximations; Multiple scanning; Rule induction algorithms; Significance levels; Approximation algorithms",2-s2.0-85020411921
"Bhesdadiya R.H., Trivedi I.N., Jangir P., Kumar A., Jangir N., Totlani R.","Training multilayer perceptrons in neural network using interior search algorithm",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031408821&doi=10.1007%2f978-981-10-3773-3_8&partnerID=40&md5=a1b78ee5332887fb29be964c995e4090","Multilayer perceptron (MLP) is the most popular neural network method and it has been widely used for many practical applications. In this paper, recently developed interior search algorithm (ISA) is proposed for training MLP. Five of most important standard classification datasets (balloon, XOR, Iris, heart, and breast cancer) are employed to evaluate the proposed algorithm performance. The obtained results from ISA-based are compared with five well-known algorithms including ant colony optimization (ACO), genetic algorithm (GA), particle swarm optimization (PSO), population-based incremental learning (PBIL), and evolution strategy (ES). The statistical results reflect that the performance of the proposed algorithm can train MLPs with a very high degree of accuracy and it is capable of outperforming the well-known algorithms. The results also show that the high convergence rate of the ISA and it is potential to avoid local minima. © Springer Nature Singapore Pte Ltd. 2018.","Feedforward neural network; ISA; Learning neural network; Multilayer perceptron","Ant colony optimization; Artificial intelligence; Classification (of information); Evolutionary algorithms; Feedforward neural networks; Genetic algorithms; Learning algorithms; Multilayer neural networks; Multilayers; Particle swarm optimization (PSO); Algorithm performance; Ant Colony Optimization (ACO); Classification datasets; High degree of accuracy; Learning neural networks; Multi layer perceptron; Neural network method; Population based incremental learning; Optimization",2-s2.0-85031408821
"Huang C.","Research and analysis on the search algorithm based on artificial intelligence about chess game",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032710364&doi=10.1007%2f978-3-319-67071-3_60&partnerID=40&md5=64638f80b909f09dfdce390691505a71","Artificial intelligence is the simulation of the information process of human consciousness and thinking. The search algorithm based on artificial intelligence has a good application prospect. In this paper, the shortcomings of traditional search algorithms are analyzed, and the disadvantages can be made up by artificial intelligence. We first analyze the application directions of artificial intelligence in the search algorithm, and then point out the system requirements and the overall design of the search algorithm based on artificial intelligence. It includes the game module, game board module, player module and displayer module. At the same time, we analyze the functions in the above four modules and construct a search algorithm based on artificial intelligence. Finally, the part codes of the search algorithm are given to provide some reference for the relative researchers. © 2018, Springer International Publishing AG.","Algorithm; Artificial intelligence; Search","Algorithms; Learning algorithms; Application prospect; Human consciousness; Information process; Overall design; Research and analysis; Search; Search Algorithms; System requirements; Artificial intelligence",2-s2.0-85032710364
"Sugier J.","Improving FPGA implementations of BLAKE and BLAKE2 algorithms with memory resources",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020786729&doi=10.1007%2f978-3-319-59415-6_38&partnerID=40&md5=dc354a07fd0ce771a997a17765a4a735","BLAKE is a cryptographic hash function which was one of the 5 finalists in the SHA-3 competition and although it ultimately lost to KECCAK the algorithm was very well received for its both cryptographic strength and performance. In this paper we propose particular modifications in hardware implementation of the cipher which employ built-in FPGA block RAM modules in order to eliminate involved distribution of message bits among cipher rounds. The idea is tested on 4 different architectures: the standard iterative one and three loop-unrolled organizations with 2, 4 and 5 rounds instantiated in hardware. Parameters of the architectures implemented with two popular FPGA families – Spartan-3 and Spartan-6 – indicate that substantial reductions in design size can be achieved also with some (albeit not so spectacular) improvements in speed. © Springer International Publishing AG 2018.","BLAKE hash algorithm; Block RAM; Implementation efficiency; Resource utilization","Cryptography; Field programmable gate arrays (FPGA); Hardware; Hash functions; Iterative methods; Memory architecture; Random access storage; Block rams; Cryptographic hash functions; FPGA implementations; Hardware implementations; Hash algorithm; Resource utilizations; Strength and performance; Substantial reduction; Computational complexity",2-s2.0-85020786729
"Yuan W., Wang J., Li J., Yan B., Wu J.","Two-Stage Heuristic Algorithm for a New Model of Hazardous Material Multi-depot Vehicle Routing Problem",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029595293&doi=10.1007%2f978-3-319-66939-7_32&partnerID=40&md5=c500d646dd20c0864b5b82f1953207ff","Vehicle routing problem (VRP) plays a vital role in logistics management. Among which, the transportation of hazardous material attracts much attention especially in China. The hazardous material multi-depot vehicle routing problem (HMDVRP) considers the transportation of hazardous material and multiple depots based on VRP. This paper develops a new HMDVRP bi-objective optimization model. Some new decision variables are introduced to the model to describe the sequence of customers and simplify the model expression. Moreover, the risk measurement of the model considers the change of the loading, which reflects the nature of hazardous material transportation. HMDVRP is NP-hard, and the heuristic algorithms are the main method used for solving it. This paper proposes a two-stage heuristic algorithm to solve the new HMDVRP model. Numerical experiments show that the two-stage heuristic algorithm can solve the HMDVRP model effectively and efficiently. © 2018, Springer International Publishing AG.","Bi-objective optimization; Hazardous material transportation; Heuristic algorithm; Multi-depot vehicle routing problem","Artificial intelligence; Hazardous materials; Hazards; Heuristic methods; Materials handling; Optimization; Risk assessment; Routing algorithms; Vehicle routing; Vehicles; Bi-objective optimization; Decision variables; Hazardous material transportation; Logistics management; Multi-depot vehicle routing problems; Numerical experiments; Two-stage heuristic algorithms; Vehicle routing problem; Heuristic algorithms",2-s2.0-85029595293
"Bahrami M., Bozorg-Haddad O., Chu X.","Application of cat swarm optimization algorithm for optimal reservoir operation",2018,"Journal of Irrigation and Drainage Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032739701&doi=10.1061%2f%28ASCE%29IR.1943-4774.0001256&partnerID=40&md5=fc37f9cb8ead4d3e1fa4e50708b1505c","The scarcity of water resources throughout the world has caused many complexities in meeting water demands, which in turn has created a tendency toward developing more efficient and effective methods for optimum operation of reservoirs. In this study, the cat swarm optimization (CSO) algorithm is applied to determine optimal operation of reservoir systems (a single-reservoir system and a hypothetical four-reservoir system). Comparison with the commonly used genetic algorithm (GA) demonstrates the superiority of this metaheuristic algorithm. For the single-reservoir system, the global optimum of 1.213 was computed using the nonlinear programming method, whereas the average objective-function values for 10 runs of the CSO algorithm and GA were 1.222 and 1.635, respectively. The CSO algorithm scored a convergence rate of 99.58% compared with 78.76% by GA, and a coefficient of variation that was 1/31 that of the GA in 10 runs. In the four-reservoir system, the convergence rate of the CSO algorithm was 99.97% compared with 98.47% by GA, with average objectivefunction values of 307.76 and 303.59, respectively. The results for the mathematical test functions and operations of the reservoir systems demonstrated the superior performance and high efficiency of the CSO algorithm in finding the global optimization solutions. © 2017 American Society of Civil Engineers.","Cat swarm algorithm; Karun4 Reservoir; Operation; Optimization; Reservoir system","Functions; Genetic algorithms; Global optimization; Nonlinear programming; Reservoirs (water); Water resources; Nonlinear programming methods; Objective function values; Operation; Optimal operation of reservoir; Optimal reservoir operations; Reservoir systems; Swarm algorithms; Swarm optimization algorithms; Optimization",2-s2.0-85032739701
"Villarino G., Gómez D., Rodríguez J.T.","Improving supervised classification algorithms by a bipolar knowledge representation",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029418833&doi=10.1007%2f978-3-319-66827-7_48&partnerID=40&md5=52a2f7c106375bc6a406b8eb7e1aa992","The aim of supervised classification algorithms is to assign objects/items to known classes. Before carrying out the final assignment, many classification algorithms obtain a soft score (probability, fuzzy, possibility, cost..) between each item and each class. In order to improve this final decision, we build a bipolar probabilistic model that considers some extra information about the dissimilarity structure between the classes. We present here some improvements for several supervised classification algorithms such as random forest, decision trees and neural networks for binary classification problems. © 2018, Springer International Publishing AG.","Bipolar models; Soft information; Supervised classification models","Binary trees; Classification (of information); Decision trees; Fuzzy sets; Knowledge representation; Pattern matching; Supervised learning; Binary classification problems; Bipolar model; Classification algorithm; Final decision; Probabilistic modeling; Random forests; Soft information; Supervised classification; Fuzzy logic",2-s2.0-85029418833
"Pleshkova S., Bekiarski A.","Development of fast parallel algorithms based on visual and audio information in motion control systems of mobile robots",2018,"Intelligent Systems Reference Library",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032591050&doi=10.1007%2f978-3-319-67994-5_5&partnerID=40&md5=ab0f120ef9cb562046a4209f790a7108","Decision making for movement is one of the essential activities in motion control systems of mobile robots. It is based on methods and algorithms of data processing obtained from the mobile robot sensors, usually video and audio sensors, like video cameras and microphone arrays. After image processing, information about the objects and persons including their current positions in area of mobile robot observation can be obtained. The aim of methods and algorithms is to achieve the appropriate precision and effectiveness of mobile robot’s visual perception, as well as the detection and tracking of objects and persons applying the mobile robot motion path planning. The precision in special cases of visual speaking person’s detection and tracking can be augmented adding the information of sound arrival in order to receive and execute the voice commands. There exist algorithms using only visual perception and attention or also the joined audio perception and attention. These algorithms are usually tested in the most cases as simulations and cannot provide a real time tracking objects and people. Therefore, the goal in this chapter is to develop and test the fast parallel algorithms for decision making in the motion control systems of mobile robots. The depth analysis of the existing methods and algorithms was conducted, which provided the main ways to increase the speed of an algorithm, such as the optimization, simplification of calculations, applying high level programming languages, special libraries for image and audio signal processing based on the hybrid hardware and software implementations, using processors like Digital Signal Processor (DSP) and Field-Programmable Gate Array (FPGA). The high speed proposed algorithms were implemented in the parallel computing multiprocessor hardware structure and software platform using the well known NVIDIA GPU processor and GUDA platform, respectively. The experimental results with different parallel structures confirm the real time execution of algorithms for the objects and speaking person’s detection and tracking using the given mobile robot construction. © 2018, Springer International Publishing AG.","CUDA; GPU; Mobile robot; Motion control system; Parallel algorithm; Visual and audio decision making; Visual and audio perception and attention",,2-s2.0-85032591050
"Zhang Q., Ma Y., Yang Z., Chen Z.","The civil aviation crew recovery time-space network model based on a tabu search algorithm",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031405107&doi=10.1007%2f978-981-10-6499-9_36&partnerID=40&md5=2a2c780efdd7027ade742a978c987447","In order to reduce cost of airlines when disruption of crew scheduling happens, a mathematical programming model of crew scheduling recovery is constructed under the usage of airline crew. In the proposed model, the objective is to minimize the usage of airline crew,moreover, the estimated delay costs are considered as chance constraints. To solve the model, a tabu search algorithm ia adopted. Finally, a numerical example is carried out to illustrate the efficiency of the model and algorithm. The computed results show that the tabu search algorithm designed in this paper to solve the crew scheduling recovery problem not only achieves good optimization results, but also has a higher computational efficiency, a faster convergence rate and a more stable computing result. By this, the airlines cost waste can be better avoided. © 2018, Springer Nature Singapore Pte Ltd.","Airline delay; Crew scheduling recovery problem; Optimization; Tabu search algorithm","Air transportation; Civil aviation; Costs; Efficiency; Intelligent systems; Learning algorithms; Mathematical programming; Optimization; Recovery; Scheduling; Tabu search; Chance constraint; Crew recoveries; Crew scheduling; Faster convergence; Mathematical programming models; Model and algorithms; Reduce costs; Tabu search algorithms; Computational efficiency",2-s2.0-85031405107
"Cárdenas E.H., Camargo H.A.","A multi-objective evolutionary algorithm for tuning type-2 fuzzy sets with rule and condition selection on fuzzy rule-based classification system",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029408506&doi=10.1007%2f978-3-319-66830-7_35&partnerID=40&md5=132aaac3b2639ebf6760427f3e52c3c7","This paper presents a Multi-Objective Evolutionary Algorithm (MOEA) for tuning type-2 fuzzy sets and selecting rules and conditions on Fuzzy Rule-Based Classification Systems (FRBCS). Before the tuning and selection process, the Rule Base is learned by means of a modified Wang-Mendel algorithm that considers type-2 fuzzy sets in the rules antecedents and in the inference mechanism. The Multi-Objective Evolutionary Algorithm used in the tuning process has three objectives. The first objective reflects the accuracy where the correct classification rate of the FRBCS is optimized. The second objective reflects the interpretability of the system regarding complexity, by means of the quantity of rules and is to be minimized through selecting rules from the initial rule base. The third objective also reflects the interpretability as a matter of complexity and models the quantity of conditions in the Rule Base. Finally, we show how the FRBCS tuned by our proposed algorithm can achieve a considerably better classification accuracy and complexity, expressed by the quantity of fuzzy rules and conditions in the RB compared with the FRBCS before the tuning process. © 2018, Springer International Publishing AG.","Fuzzy rule-based classification system; Multi-objective evolutionary algorithm; Type-2 fuzzy sets","Computer circuits; Fuzzy inference; Fuzzy logic; Fuzzy rules; Fuzzy sets; Inference engines; Classification accuracy; Classification rates; Fuzzy rule based classification systems; Inference mechanism; Interpretability; Multi objective evolutionary algorithms; Type-2 fuzzy set; Wang-mendel algorithms; Evolutionary algorithms",2-s2.0-85029408506
"Jing M., Kong J.","Developing green construction evaluation system based on deep neural network algorithm",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028425514&doi=10.1007%2f978-3-319-60744-3_35&partnerID=40&md5=492153d92b0cbe6945e2d495b63e19f7","The green construction evaluation model is a multi objective and multi qualified model, and the solution has a certain degree of complexity. Often a single algorithm cannot be a good solution to the accuracy of the evaluation system and fault tolerance capabilities and other issues. This paper, through empirical analysis and application of the actual construction of the data depth network model is constructed, in complex models in the abstract condition as factors and as neural network input and output node information and the network optimize. By introducing the ant colony algorithm to train the neural network’s cost function, the paper obtains the high precision model of the green construction evaluation system and the new optimization method for solving the traditional problem. Through the algorithm of organic fusion, the existing algorithms are improved, and the reliability and accuracy of the algorithm are improved. It provides a new theoretical basis and practical model for the green construction evaluation system. © 2018, Springer International Publishing AG.","Ant colony algorithm; Fusion algorithm; Green construction; Neural network","Ant colony optimization; Complex networks; Cost functions; Deep neural networks; Fault tolerance; Intelligent systems; Neural networks; Real time systems; Ant colony algorithms; Degree of complexity; Evaluation modeling; Fault-tolerance capability; Fusion algorithms; Green constructions; High-precision models; Neural network algorithm; Optimization",2-s2.0-85028425514
"Li G., Jin Y., Akram M.W., Chen X., Ji J.","Application of bio-inspired algorithms in maximum power point tracking for PV systems under partial shading conditions – A review",2018,"Renewable and Sustainable Energy Reviews",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027847237&doi=10.1016%2fj.rser.2017.08.034&partnerID=40&md5=97385d6933b6640eafd8a41fc7103361","Solar energy is one of the most promising renewable energy resource due to its variety of advantages. The photovoltaic systems have a remarkable development over the past few decades. As the maximum power point of the photovoltaic system varies with the change in environmental conditions, the maximum power point tracking technology is necessary to harvest maximum power from the photovoltaic systems. However, multiple peaks occur in the power-voltage (P-V) curve during partial shading conditions. In such condition, many traditional maximum power point tracking methods like perturbation and observation, and incremental conductance may become invalid due to involvement in the local maximum power point. Many advanced methods based on the artificial intelligence like artificial neural network, and fuzzy logic control can track the global maximum power point. However, they are not feasible in real complex environment because they need massive training and broader experience. Alternatively, bio-inspired maximum power point tracking algorithms deal properly with such situations. In recent years, researchers have widely applied bio-inspired algorithms to track the global maximum power point of photovoltaic system during partial shading situations. This paper presents a comprehensive review of the bio-inspired algorithms used for global maximum power point tracking. Various tracking methods are discussed and compared in terms of their characteristics and corresponding improved methods. It also presents the advantages and disadvantages of each method. The modified and combined forms of these methods found to have better performance than original algorithms. Overall, the performance of swarm intelligence based algorithms is found better than evolutionary algorithms. This review may help the researchers to acquire comprehensive information about the application of bio-inspired algorithms to gain maximum power from the photovoltaic systems, and furthermore, help them to choose an efficient way of global maximum power point tracking in photovoltaic systems during partial shading conditions. © 2017 Elsevier Ltd","Bio-inspired algorithm; Global maximum power point tracking; Maximum power point tracking; Partial shading situations; Photovoltaic (PV) system",,2-s2.0-85027847237
"Abdelaziz A., Elhoseny M., Salama A.S., Riad A.M., Hassanien A.E.","Intelligent algorithms for optimal selection of virtual machine in cloud environment, towards enhance healthcare services",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029525665&doi=10.1007%2f978-3-319-64861-3_27&partnerID=40&md5=503d65e9c5055f87472a334d207ef75c","Cloud computing plays a very important role in healthcare services (HCS). Cloud computing for HCS can restore patients’ records, diseases diagnosis and other medical domains in less time and less of cost. In cloud computing, optimally chosen of virtual machines (VMs) is very significant to interest in healthcare services (IHS) (patients, doctors, etc.) in HCS to implementation time and speed of response to medical requests. This paper proposes a new intelligent architecture for HCS. also, this paper proposes three intelligent algorithms are a genetic algorithm (GA), particle swarm optimization (PSO) and parallel particle swarm optimization (PPSO) to find optimal chosen of VMs in a cloud environment. For that, this paper uses MATLAB tool to find optimal intelligent algorithm and CloudSim to find optimal chosen of VMs in a cloud environment. The results proved that PPSO algorithm is better than GA and PSO algorithms. © 2018, Springer International Publishing AG.","Cloud computing; Genetic algorithm; Healthcare services; Parallel particle swarm optimization",,2-s2.0-85029525665
"Guo L., Ge Y., Hou W., Guo P., Cai Q., Wu J.","A novel IP-core mapping algorithm in reliable 3D optical network-on-chips",2018,"Optical Switching and Networking",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029154037&doi=10.1016%2fj.osn.2017.08.001&partnerID=40&md5=3e079c4697ff3e32379e3e0168ffab71","The Optical Network-on-Chip (ONoC) is considered as a promising way to achieve high performance of multiprocessor systems, and it will be a 3-Dimensional (3D) architecture organized by a certain topology where optical routers are optically interconnected with each other. For the design of 3D ONoCs, the highly reliable IP-core mapping is a key problem of properly assigning IP cores onto optical routers for a given communication task, and it has two main challenges: reliability estimation and mapping scheme. As for reliability estimation, crosstalk noise and thermal sensitivity which severely influence Signal-Noise-Ratio (SNR) should be measured. In addition, although standard genetic algorithms have been widely utilized to solve the optimal mapping solution due to the superiority of simple process, there are some deficiencies such as premature convergence and inferior local searching. In this paper, the impact factors of ONoC reliability are measured by SNR and thermal models, and we also design a novel IP-core mapping algorithm called as CGSA (Cataclysm Genetic-based Simulated Annealing) based on proposed models. In CGSA, we integrate genetic with an improved simulated annealing algorithm assorted with cataclysm strategies, in order to speed up the searching process. Furthermore, to enhance the network reliability, CGSA is bound with the topology selection, i.e., CGSA generates the optimal mapping solution with the best matched 3D ONoC topology. Simulation results show that CGSA is effective on achieving the higher reliability than benchmarks. © 2017 Elsevier B.V.","3D ONoC; Genetic and simulated annealing algorithm; IP-core mapping; Reliability","Conformal mapping; Distributed computer systems; Fault tolerant computer systems; Fiber optic networks; Genetic algorithms; Integrated circuit design; Intellectual property core; Mapping; Network-on-chip; Optical communication; Reliability; Routers; Signal to noise ratio; Simulated annealing; Topology; 3D ONoC; Core mappings; Genetic and simulated annealing algorithms; Improved simulated annealing algorithm; Multi processor systems; Optical network on chip (ONoC); Pre-mature convergences; Standard genetic algorithm; Internet protocols",2-s2.0-85029154037
"Hans K., Ahuja L., Muttoo S.K.","Performance evaluation of neural network training algorithms in redirection spam detection",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031420981&doi=10.1007%2f978-981-10-6747-1_20&partnerID=40&md5=836713d6f06100191c72b3380fe4bb1f","Redirection spam is a technique whereby a genuine search user is forced to pass through a series of redirections and finally land on a compromised Web site that may present an unwanted content or download malware on his machine. Such malicious redirections are a threat to Web security and must be detected. In this paper, we explore the Artificial Neural Network algorithms for modeling redirection spam detection by conducting the performance evaluation of the three most used training algorithms, namely scaled conjugate gradient (trainscg), Bayesian regularization (trainbr), and Levenberg–Marquardt (trainlm). Our results indicate that the network trained using Bayesian regularization outperformed the other two algorithms. To establish the success of our results, we have used two datasets comprising of 2200 URLs and 2000 URLs, respectively. © 2018, Springer Nature Singapore Pte Ltd.","Information retrieval; Malicious redirection; Neural network; Redirection spam; Spam detection; Web security","Information retrieval; Malware; Neural networks; Artificial neural network algorithm; Bayesian regularization; Malicious redirection; Neural network training; Redirection spam; Scaled conjugate gradients; Spam detection; WEB security; Knowledge based systems",2-s2.0-85031420981
"Chen D., Zhou N., Ting C., Li C., Guo H., Zhang L., Wang X.","Control strategy of energy storage for frequency coordination dispatch based on improved niche genetic algorithm",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028677739&doi=10.1007%2f978-3-319-67349-3_7&partnerID=40&md5=4cb4a1e2dfe0ab549d969cb9f8523d75","In order to reduce the operating cost of power frequency control, a control strategy based on energy storage optimization is presented. The aim of the control strategy is maximizes the use of power provided by new energy power supply and reduces the electric energy from real-time power grid; the operation cost is effectively reduced without influences on the power life by reasonable charge and discharge strategy of energy storage, by the improved niche genetic algorithm based on fuzzy clustering, a hour level of scheduling plan is given by this case. Based on the uncertainty on the energy demand and supply, the optimal value of the direct purchase of the frequency control is determined. The computation results show that under the same condition of system framework, load and operating environment, through reasonable and effective operation of the frequency control strategy, effectively reduce the operating costs of the system, has a high practical value. © 2018, Springer International Publishing AG.","Energy storage; Freqnecy contrl; Improved niche genetic algorithm; Operating cost","Biomedical engineering; Cost reduction; Costs; Electric power system control; Electric power systems; Electric power transmission networks; Energy storage; Genetic algorithms; Operating costs; Optimization; Purchasing; Charge and discharge; Control strategies; Electric energies; Freqnecy contrl; Improved niche genetic algorithms; Operating environment; Storage optimization; System framework; Clustering algorithms",2-s2.0-85028677739
"Soto R., Crawford B., Olivares R., Escárate F.","A Harmony Search Algorithm to Solve the Manufacturing Cell Design Problem",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029592852&doi=10.1007%2f978-3-319-67618-0_3&partnerID=40&md5=5aa9a8ef98d657d823f8cb0f224486e1","This paper focuses on modeling and solving the Manufacturing Cell Design Problem (MCDP) by using the Harmony Search (HS) metaheuristic. The MDCP consists on grouping machines and parts that they process, into groups called cells. So, the idea is to identify an organization of cells such that the number of times that a piece is transported between these cells is minimized. To this end, we use the HS optimization algorithm, which is based on the process of improvisation performed by musicians to find a perfect musical harmony. The experimental results demonstrate the efficiency of the proposed approach which is able to reach all global optimums for a set of 90 well-known MDCP instances. © 2018, Springer International Publishing AG.","Harmony search algorithm; Manufacturing cell design problem; Metaheuristics","Cells; Computational methods; Cytology; Flexible manufacturing systems; Intelligent systems; Learning algorithms; Manufacture; Cell design; Global optimum; Harmony search; Harmony search algorithms; Meta heuristics; Metaheuristic; Optimization algorithms; Optimization",2-s2.0-85029592852
"Soomro M.H., Giunta G., Laghi A., Caruso D., Ciolina M., De Marchis C., Conforto S., Schmid M.","Segmenting MR images by level-set algorithms for perspective colorectal cancer diagnosis",2018,"Lecture Notes in Computational Vision and Biomechanics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032391817&doi=10.1007%2f978-3-319-68195-5_44&partnerID=40&md5=b7203f514bc77851b5d2ec35f5ffeb4d","Segmentation is an essential and crucial step in interpreting medical images for possible treatment. Medical image segmentation is very chaotic procedure as medical image may have different structures of same organ in different image modalities and may also have different features in different image slices of same modality. In this work, we present a comparison of segmentation algorithms based on level set methods, viz. Caselles, Chan & Vese, Li, Lankton, Bernard, and Shi algorithms. We assessed these algorithms with our T2-weighted colorectal MR images using Dice coefficient that measures the similarity between the reference sketched by specialist and the segmentation result produced by each algorithm. In addition, computational time taken by each algorithm to perform the segmentation is also computed. Our results on average Dice coefficient and average time computation demonstrate that Bernard has the lowest average Dice coefficient and the highest computational complexity followed by Li which has second lowest Dice coefficient and highest computational complexity. Lankton has achieved satisfactory results on average Dice coefficient and computational complexity followed by Chan & Vese and Shi. Whereas, Caselles algorithm outperforms than all with respect to average Dice coefficient and computational time. © 2018, Springer International Publishing AG.","Level set segmentation algorithm; Magnetic Resonance Imaging (MRI); Medical image segmentation; T2-weighted colorectal MRI",,2-s2.0-85032391817
"Selamoğlu B.İ., Salhi A., Sulaiman M.","Strip algorithms as an efficient way to initialise population-based metaheuristics",2018,"Operations Research/ Computer Science Interfaces Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032630734&doi=10.1007%2f978-3-319-58253-5_18&partnerID=40&md5=defae1abe3a25fead77a8986f53c40fe","The Strip Algorithm (SA) is a constructive heuristic which has been tried on the Euclidean Travelling Salesman Problem (TSP) and other planar network problems with some success. Its attraction is its efficiency. In its simplest form, it can find tours of length Ω(n) in (Formula presented) operations where n is the number of nodes. Here, we set out to investigate new variants such as the 2-Part Strip Algorithm (2-PSA), the Spiral Strip Algorithm (SSA) and the Adaptive Strip Algorithm (ASA). The latter is particularly suited for Euclidean TSPs with non-uniform distribution of cities across the grid; i.e problems with clustered cities. These cases present an overall low density, but high localised densities. ASA takes this into account in that smaller strips are generated where the density is high. All three algorithms are analysed, implemented and computationally tested against each other and the Classical Strip Algorithm. Computational results are included. © Springer International Publishing AG 2018.","Heuristics; Optimisation; Strip algorithm; Travelling Salesman",,2-s2.0-85032630734
"He Y., Xie H., Wong T.-L., Wang X.","A novel binary artificial bee colony algorithm for the set-union knapsack problem",2018,"Future Generation Computer Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028083529&doi=10.1016%2fj.future.2017.05.044&partnerID=40&md5=a2ed9d2a73452ed25abcdb211c639b10","This article investigates how to employ artificial bee colony algorithm to solve Set-Union Knapsack Problem (SUKP). A mathematical model of SUKP, which is to be easily solved by evolutionary algorithms, is developed. A novel binary artificial bee colony algorithm (BABC) is also proposed by adopting a mapping function. Furthermore, a greedy repairing and optimization algorithm (S-GROA) for handling infeasible solutions by employing evolutionary technique to solve SUKP is proposed. The consolidation of S-GROA and BABC brings about a new approach to solving SUKP. Extensive experiments are conducted upon benchmark datasets for evaluating the performance of our proposed models. The results verify that the proposed approach is significantly superior to the baseline evolutionary algorithms for solving SUKP such as A-SUKP, ABCbin and binDE in terms of both time complexity and solution performance. © 2017","Artificial bee colony; Infeasible solution; Repairing and optimization; Set-union knapsack problem","Benchmarking; Bins; Combinatorial optimization; Optimization; Repair; Artificial bee colonies; Artificial bee colony algorithms; Benchmark datasets; Evolutionary techniques; Infeasible solutions; Knapsack problems; Mapping functions; Optimization algorithms; Evolutionary algorithms",2-s2.0-85028083529
"Gong D., Han Y., Sun J.","A hybrid discrete artificial bee colony algorithm for multi-objective blocking lot-streaming flow shop scheduling problem",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031421254&doi=10.1007%2f978-981-10-6499-9_57&partnerID=40&md5=9856bf5f90aeddb498732875b2ec84ac","A blocking lot-streaming flow shop (BLSFS) scheduling problem involves in splitting a job into several sublots and no capacity buffers with blocking between adjacent machines. It is of popularity in real-world applications but hard to be effectively solved in light of many constrains and complexities. Thus, the research on optimization algorithms for the BLSFS scheduling problem is relatively scarce. In view of this, we proposed a hybrid discrete artificial bee colony (HDABC) algorithm to tackle the BLSFS scheduling problem with two commonly used and conflicting criteria, i.e., makespan and earliness time. We first presented three initialization strategies to enhance the quality of the initial population, and then developed two novel crossover operators by taking full of valuable information of non-dominated solutions to enhance the capabilities of HDABC in exploration. We applied the proposed algorithm to 16 instances and compared with three previous algorithms. The experimental results show that the proposed algorithm clearly outperforms these comparative algorithms. © 2018, Springer Nature Singapore Pte Ltd.","Blocking; Lot-streaming flow shop; Multi-objective optimization Artificial bee colony; Pareto local search","Evolutionary algorithms; Intelligent systems; Machine shop practice; Multiobjective optimization; Scheduling; Stream flow; Artificial bee colonies; Artificial bee colony algorithms; Blocking; Local search; Lot-streaming flow shop scheduling; Lot-streaming flow shops; Nondominated solutions; Optimization algorithms; Optimization",2-s2.0-85031421254
"Shang R., Yuan Y., Jiao L., Meng Y., Ghalamzan A.M.","A self-paced learning algorithm for change detection in synthetic aperture radar images",2018,"Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026768629&doi=10.1016%2fj.sigpro.2017.07.023&partnerID=40&md5=5bc1746a2600b72e519b463038c5c308","Detecting changed regions between two given synthetic aperture radar images is very important to monitor change of landscapes, change of ecosystem and so on. This can be formulated as a classification problem and addressed by learning a classifier, traditional machine learning classification methods very easily stick to local optima which can be caused by noises of data. Hence, we propose an unsupervised algorithm aiming at constructing a classifier based on self-paced learning. Self-paced learning is a recently developed supervised learning approach and has been proven to be capable to overcome effectively this shortcoming. After applying a pre-classification to the difference image, we uniformly select samples using the initial result. Then, self-paced learning is utilized to train a classifier. Finally, a filter is used based on spatial contextual information to further smooth the classification result. In order to demonstrate the efficiency of the proposed algorithm, we apply our proposed algorithm on five real synthetic aperture radar images datasets. The results obtained by our algorithm are compared with five other state-of–the-art algorithms, which demonstrates that our algorithm outperforms those state-of-the-art algorithms in terms of accuracy and robustness. © 2017 Elsevier B.V.","Change detection; Self-paced learning; Synthetic aperture radar (SAR)","Classification (of information); Learning systems; Radar; Radar imaging; Radar signal processing; Synthetic aperture radar; Tracking radar; Change detection; Classification results; Contextual information; Machine learning classification; Self-paced learning; State-of-the-art algorithms; Supervised learning approaches; Unsupervised algorithms; Learning algorithms",2-s2.0-85026768629
"Żywica P., Basiukajc K., Couso I.","Practical notes on applying generalised stochastic orderings to the study of performance of classification algorithms for low quality data",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029449042&doi=10.1007%2f978-3-319-66827-7_54&partnerID=40&md5=1c3a6ba30fe6d027106a6c97607fafeb","This paper presents an approach to applying stochastic orderings to evaluate classification algorithms for low quality data. It discusses some known stochastic orderings along with practical notes about their application to classifier evaluation. Finally, a new approach based on fuzzy cost function is presented. The new method allows comparing any two classifiers, but does not require a precise definition of the cost function. All proposed methods were evaluated on real life medical data. The obtained results are very similar to those previously reported but comparatively much weaker assumptions about costs values are adopted. © 2018, Springer International Publishing AG.","Classification; Fuzzy random variable; Loss function; Low quality data; Stochastic ordering","Classification (of information); Cost functions; Costs; Function evaluation; Fuzzy sets; Pattern matching; Quality control; Stochastic systems; Classification algorithm; Classifier evaluation; Fuzzy random variable; Loss functions; Low quality datum; Precise definition; Stochastic order; Stochastic orderings; Fuzzy logic",2-s2.0-85029449042
"Liu Y., Liang J., Li J., Zhao Z.","Robot path planning based on Dijkstra’s algorithm and Genetic algorithm",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031411159&doi=10.1007%2f978-981-10-3187-8_38&partnerID=40&md5=1c98a20afc97dbcc74623baa2898e612","In this paper, a robot path planning method based on Dijkstra’s Algorithm and Genetic Algorithms is proposed. This method works for any appointed start point and end point in an arbitrary rectangular workspace with arbitrary rectangular obstacles whose edges are perpendicular or parallel to the walls of the workspace. Firstly, use Dijkstra’s Algorithm to find a path among all the midpoints of obstacles’ vertices and the walls of the workspace. Then use Genetic Algorithm to optimize the path gotten from Dijkstra’s Algorithm and finally generate an optimal path for the robot from the start point to the end point. © Springer Nature Singapore Pte Ltd. 2018.","Dijkstra’s algorithm; Genetic algorithm; Robot path planning","Computation theory; Genetic algorithms; Point contacts; Robot programming; Robots; Dijkstra; End points; Optimal paths; Rectangular obstacles; Robot path-planning; S-algorithms; Start point; Motion planning",2-s2.0-85031411159
"Rabbani M., Rezaei H., Lashgari M., Farrokhi-Asl H.","Vendor managed inventory control system for deteriorating items using metaheuristic algorithms",2018,"Decision Science Letters",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019020579&doi=10.5267%2fj.dsl.2017.4.006&partnerID=40&md5=a5302d7943508d109032a1da55d646cb","Inventory control of deteriorating items constitutes a large part of the world’s economy and covers various goods including any commodity, which loses its worth over time because of deterioration and/or obsolescence. Vendor managed inventory (VMI), which is a win-win strategy for both suppliers and buyers gains better results than traditional supply chain. In this research, we study an economic order quantity (EOQ) with shortage in form of partial backorder under VMI policy. The model is concerned with multi-item subject to multi-constraint including storage space, time period and budget constraints. Two metaheuristic algorithms, namely Simulated Annealing and Tabu Search, are used to find a near optimal solution for the proposed fuzzy nonlinear integer-programming problem with the objective of minimizing the total cost of the supply chain. Furthermore, the sensitivity analysis of the metaheuristic parameters is performed and five numerical examples containing different numbers of items are conducted in order to evaluate the performance of the algorithms. © 2018 Growing Science Ltd. All rights reserved.","Deteriorating items; Economic order quantity; Fuzzy; Metaheuristic algorithm; Vendor managed inventory",,2-s2.0-85019020579
"Phankokkruad M.","Efficient similarity measurement by the combination of distance algorithms to identify the duplication relativity",2018,"Studies in Computational Intelligence",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020379286&doi=10.1007%2f978-3-319-60170-0_17&partnerID=40&md5=bb1d402a7816d44963b4fc6b281386fc","This paper studied the efficient similarity measurement in order to improve the duplication detection techniques in a programming class. This work used the combination of the three proficient algorithms that include Smith-Waterman, longest common subsequence, and Damalau-Levenshtein distance to measure the distance between each pair of the code files. In order to identify the proximity of the person who duplicates each other, this work applied the frequency of occurrence technique to score the accumulated similarity of duplication, the number of times or the regularity of the duplication happens, and the relationship between incidence and time period. Moreover, this work proposed the technique to identify a group of people positioned closely together. The result shows that the proposed of the combination of algorithms could measure the similarity of files efficiently. This work could identify the relativity of a person who frequently duplicates together, and the people positioned closely together. Finally, this work suggested the number of time that student duplicated the code files. © Springer International Publishing AG 2018.",,"Artificial intelligence; Computational methods; Distance algorithm; Duplication detection; Levenshtein distance; Longest common subsequences; Programming class; Similarity measurements; Smith-Waterman; Time-periods; Relativity",2-s2.0-85020379286
"Topçu Ş., Etaner-Uyar A.Ş.","A Multiobjective Evolutionary Algorithm Approach for Map Sketch Generation",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029573661&doi=10.1007%2f978-3-319-66939-7_11&partnerID=40&md5=82e7cc19325e2adc557e0b8303f4d9f0","In this paper, we present a method to generate map sketches for strategy games using a state of the art many-objective evolutionary algorithm, namely NSGAIII. The map sketch generator proposed in this study outputs a three objective Pareto-front in which all the points are fair and strong in different aspects. The generated map sketch can be used by level designers to create real time strategy maps effectively and/or help them see multiple aspects of a game map simultaneously. The algorithm can also be utilised as a benchmark generator to be used in tests for various cases such as shortest path algorithms and strategy game bots. The results reported in this paper are very promising and promote further study. © 2018, Springer International Publishing AG.","Computational intelligence; Evolutionary multiobjective optimization; Games; Map sketch generation; NSGAIII; Procedural content generation","Artificial intelligence; Multiobjective optimization; Optimization; Evolutionary multiobjective optimization; Games; Multi objective evolutionary algorithms; NSGAIII; Procedural content generations; Real time strategies; Shortest path algorithms; State of the art; Evolutionary algorithms",2-s2.0-85029573661
"Batra M., Agrawal R.","Comparative analysis of decision tree algorithms",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031416085&doi=10.1007%2f978-981-10-6747-1_4&partnerID=40&md5=42fc5ba2eb82e0846a0f70fcb4fb7af6","Decision trees are outstanding tools to help anyone to select the best course of action. They generate a highly valuable arrangement in which one can place options and study possible outcomes of those options. They also facilitate users to make a fair idea of the pros and cons related to each possible action. A decision tree is used to represent graphically the decisions, the events, and the outcomes related to decisions and events. Events are probabilistic and determined for each outcome. The aim of this paper is to do detailed analysis of decision tree and its variants for determining the best appropriate decision. For this, we will analyze and compare various decision tree algorithms such as ID3, C4.5, CART, and CHAID. © 2018, Springer Nature Singapore Pte Ltd.","C4.5; CART; CHAID; Ensemble; ID3","Decision trees; C4.5; CART; CHAID; Comparative analysis; Course of action; Decision-tree algorithm; Ensemble; Data mining",2-s2.0-85031416085
"Pathan S., Prabhu K.G., Siddalingaswamy P.C.","Techniques and algorithms for computer aided diagnosis of pigmented skin lesions—A review",2018,"Biomedical Signal Processing and Control",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028007005&doi=10.1016%2fj.bspc.2017.07.010&partnerID=40&md5=1fba65d626dded213dca014b692cb763","Computerized image analysis methods for dermoscopy are primarily of great interest and benefit, as it provides significant information about the lesion, which can be of pertinence for the clinicians and a stand-alone warning implement. Computer-based diagnostic systems require dedicated image processing algorithms to provide mathematical descriptions of the suspected regions, such systems hold a great potential in oncology. In this paper, we have performed a review of the state of art techniques used in computer-aided diagnostic systems, by giving the domain aspects of melanoma followed by the prominent techniques used in each of the steps. The steps include dermoscopic image pre-processing, segmentation, extraction and selection of peculiar features, and relegation of skin lesions. The paper also presents cognizance to judge the consequentiality of every methodology utilized in the literature, in addition to the corresponding results obtained in this perspective. The inadequacies and the future research directions are accentuated. © 2017 Elsevier Ltd","Acquisition; Classification; Dermoscopy; Melanoma; Pigmented skin lesions (PSLs); Segmentation","Classification (of information); Dermatology; Diagnosis; Image processing; Image segmentation; Oncology; Acquisition; Computer aided diagnostics; Dermoscopy; Future research directions; Image processing algorithm; Mathematical descriptions; Melanoma; Pigmented skin lesions; Computer aided diagnosis",2-s2.0-85028007005
"Chang Y.","A parallel algorithm of mining frequent pattern on uncertain data streams",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032653230&doi=10.1007%2f978-3-319-67071-3_47&partnerID=40&md5=fb62f7969527f890c2c956473ef45864","At present, more and more data are generated every day and the actual application requirements for the mining algorithm efficiency have become higher. In such a situation, one of the hot research topics on the frequent pattern mining over uncertain data is the spatiotemporal efficiency improvement of mining algorithms. Aiming at solving the frequent pattern mining problems over dynamic uncertain data streams, based on the existing algorithm researches, the paper proposes a parallel mining approximation algorithm based on the MapReduce framework by combining a highly efficient algorithm for static data. If this algorithm is used to mine frequent patterns, all the frequent patterns can be mined from a sliding window by using MapReduce at most twice. In the experiments conducted for this paper, in most cases the frequent item set was accurately discovered after MapReduce is used once. The experiments have shown that the spatiotemporal efficiency of the algorithm proposed in this paper is much better than those of the other algorithms. © 2018, Springer International Publishing AG.","Data mining; Frequent pattern; Parallel algorithm; Uncertain data","Approximation algorithms; Efficiency; Parallel algorithms; Algorithm researches; Application requirements; Efficiency improvement; Frequent pattern; Frequent pattern mining; Mapreduce frameworks; Uncertain data streams; Uncertain datas; Data mining",2-s2.0-85032653230
"Sanabria-Borbón A.C., Tlelo-Cuautle E., de la Fraga L.G.","Optimal sizing of amplifiers by evolutionary algorithms with integer encoding and gm/ID design method",2018,"Studies in Computational Intelligence",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030105210&doi=10.1007%2f978-3-319-64063-1_11&partnerID=40&md5=c3fb53629a499f833662552b85f4e837","The optimal sizing of analog integrated circuits (ICs) by evolutionary algorithms (EAs) has the challenge of reducing the search spaces of the design variables, guaranteeing the proper bias conditions and providing manufacturable feasible solutions. In this manner, this chapter applies two EAs, namely the non-dominated sorting genetic algorithm (NSGA-II) and differential evolution (DE) to optimize operational amplifiers designed with complementary metal-oxide-semiconductor (CMOS) IC fabrication technology. Those EAs link the simulation program with IC emphasis (SPICE) to evaluate performances characteristics, and apply the gm/ID design method to guarantee bias conditions and to reduce the search spaces for the design variables of the MOS transistors, which are associated to the width (W) and length (L) of their channels. The W/L design variables are encoded with integer values that are converted to multiples of the IC fabrication technology within SPICE. That way, integer encoding of the design variables provides manufacturable transistor sizes, while the EAs are accelerated by using chromosomes with reduced search spaces provided by the gm/ID design method. As examples, two CMOS operational transconductance amplifiers (OTAs) are sized with this optimization approach to highlight the EA’s advantages when applying gm/ID design method and integer encoding. © Springer International Publishing AG 2018.","Circuit sizing; Differential evolution algorithm; gm/ID design method; MOS transistor; Multi-objective optimization; NSGA-II; Operational transconductance amplifier; SPICE",,2-s2.0-85030105210
"Lin Y., Li L.","An improved particle filter algorithm based on swarm intelligence optimization",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031395596&doi=10.1007%2f978-981-10-6499-9_23&partnerID=40&md5=e8e7afe40f0b14567184edf56bda608e","Due to the problem of particle degeneracy and loss of particle diversity in particle filter algorithm, this paper proposes an improved particle filter algorithm referring to some ideas of optimized algorithm like particle swarm and firefly group. The proposed algorithm utilizes the firefly algorithm to optimize particle filter and avoid re-sampling process; makes the particles move towards the location of better weight particles and prevents the small weight particles from disappearing after several iterations. Meanwhile, this algorithm sets a transition threshold and iteration times in order to improve the real-time property of the algorithm. Experimental results show that the improved algorithm possesses higher estimation accuracy and keeps good diversity of particle. © 2018, Springer Nature Singapore Pte Ltd.","Particle filter; Particle impoverishment; State estimation; Swarm intelligence optimization","Artificial intelligence; Bandpass filters; Bioluminescence; Intelligent systems; Iterative methods; Monte Carlo methods; State estimation; Swarm intelligence; Firefly algorithms; Improved particle filter; Optimized algorithms; Particle degeneracy; Particle filter; Particle filter algorithms; Real-time properties; Swarm intelligence optimization; Optimization",2-s2.0-85031395596
"Dalmeijer K., Spliet R.","A branch-and-cut algorithm for the Time Window Assignment Vehicle Routing Problem",2018,"Computers and Operations Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028767241&doi=10.1016%2fj.cor.2017.08.015&partnerID=40&md5=77c0caa3f2fdb7f919736b177432a21e","This paper presents a branch-and-cut algorithm for the Time Window Assignment Vehicle Routing Problem (TWAVRP), the problem of assigning time windows for delivery before demand volume becomes known. A novel set of valid inequalities, the precedence inequalities, is introduced and multiple separation heuristics are presented. In our numerical experiments the branch-and-cut algorithm is 3.8 times faster when separating precedence inequalities. Furthermore, in our experiments, the branch-and-cut algorithm is 193.9 times faster than the best known algorithm in the literature. Finally, using our algorithm, instances of the TWAVRP are solved which are larger than the instances previously presented in the literature. © 2017 Elsevier Ltd","Precedence inequalities; Time window assignment; Vehicle Routing","Routing algorithms; Vehicle routing; Vehicles; Best-known algorithms; Branch-and-cut algorithms; Numerical experiments; Precedence inequalities; Time windows; Valid inequality; Vehicle Routing Problems; Integer programming",2-s2.0-85028767241
"Gupta A., Gusain K., Goyal L.M.","Improved FP-linked list algorithm for association rule mining",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031415725&doi=10.1007%2f978-981-10-3773-3_54&partnerID=40&md5=913d9dd8a8ad6f475ba8dfb9662a0138","One of the more important techniques used in Data Mining is, Association Rule Mining and it involves the finding of frequent item sets from the database. A linked list version of one of the most widely used association mining algorithms that are the FP-Growth algorithm was proposed, called the FPBitLink Algorithm. It uses a bit matrix along with linked lists to find the desired item sets. In this paper, we propose two things, first is a variant of the FPBitLink Algorithm, in which instead of treating the items in the datasets as individual nodes, we take a single transaction to be the node in the linked list, and finally use UNION set operation to obtain the frequent pattern set. Since this transactional version is a highly efficient alternative when the number of transactions are greater than the number of items, as it saves valuable space and time, whereas the original FPBitLink algorithm is more efficient when the number of items is greater than the transactions, we further propose the installation of a checkpoint in the beginning, such that depending upon the data either of the two algorithms can be chosen. This way we arrive at a frequent pattern set finding procedure, which is both, highly efficient and extremely efficacious. © Springer Nature Singapore Pte Ltd. 2018.","Algorithm; Association rules; Data mining; FP-growth algorithm; Frequent itemset; Linked list","Algorithms; Association rules; Association mining; FP-growth algorithm; Frequent item sets; Frequent itemset; Linked list; List algorithms; Set operation; Space and time; Data mining",2-s2.0-85031415725
"Álvarez Fernández R., Corbera Caraballo S., Beltrán Cilleruelo F., Lozano J.A.","Fuel optimization strategy for hydrogen fuel cell range extender vehicles applying genetic algorithms",2018,"Renewable and Sustainable Energy Reviews",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027570575&doi=10.1016%2fj.rser.2017.08.047&partnerID=40&md5=ecc0cd93e10b972e21b1706b4979ef1a","Whether or not alternative fuel vehicles (AFVs) will finally find a place in the global mass-market or even will dominate the vehicle segment will depend on several success factors: reduction of customer anxiety, fast recharging, better charging infrastructure, environmental justice policies and some others. Current technological advances in battery electric vehicles and hydrogen fuelled electric vehicles could represent a hopefully option in the near future. Nevertheless, and until electric/hydrogen technological barriers are not torn down, both power architecture do not have an opportunity to be fully introduced in the vehicle market. In this paper, the authors present a powertrain architecture concept based in current fossil fuel extender range, but changing it to a hydrogen fuel cell stack system that works as range extender. The objective is to probe how optimization techniques, by the inclusion of genetic algorithms, could be a crucial help when planning the fuel consumption/selection. The paper ambition is to highlight the possibilities of this powertrain and its appropriated management to allow hydrogen become an energy carrier feasible today in the automotive world. © 2017","Electric vehicle; Extended range; Fuel cell; Genetic algorithm; Optimization; Simulation",,2-s2.0-85027570575
"García J., Crawford B., Soto R., Astorga G.","A Percentile Transition Ranking Algorithm Applied to Knapsack Problem",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029573970&doi=10.1007%2f978-3-319-67621-0_11&partnerID=40&md5=1fd04c299a17aa4c4851657af435983b","The binarization of Swarm Intelligence continuous metaheuristics is an area of great interest in operational research. This interest is mainly due to the application of binarized metaheuristics to combinatorial problems. In this article we propose a general binarization algorithm called Percentile Transition Ranking Algorithm (PTRA). PTRA uses the percentile concept as a binarization mechanism. In particular we will apply this mechanism to the Cuckoo Search metaheuristic to solve the set multidimensional Knapsack problem (MKP). We provide necessary experiments to investigate the role of key ingredients of the algorithm. Finally to demonstrate the efficiency of our proposal, we solve Knapsack benchmark instances of the literature. These instances show PTRA competes with the state-of-the-art algorithms. © 2018, Springer International Publishing AG.","Combinatorial optimization; Metaheuristics; Multidimensional knapsack problem","Artificial intelligence; Benchmarking; Bins; Combinatorial optimization; Computational methods; Heuristic algorithms; Binarization algorithm; Combinatorial problem; Knapsack problems; Meta heuristics; Multidimensional knapsack problems; Operational research; Ranking algorithm; State-of-the-art algorithms; Optimization",2-s2.0-85029573970
"Wang B., Wang X., Lan F., Pan Q.","A hybrid local-search algorithm for robust job-shop scheduling under scenarios",2018,"Applied Soft Computing Journal",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032785279&doi=10.1016%2fj.asoc.2017.10.020&partnerID=40&md5=20aefcffb55bca9e2ad48737c8650927","This paper discusses an uncertain job-shop scheduling problem with the makespan as the performance criterion. Uncertain processing times are described by discrete scenarios. A robust optimization model is established for the job-shop scheduling problem based on a set of bad scenarios to hedge against the risk of achieving substandard performances among these bad scenarios. To solve the established problem, a problem-specific neighborhood structure is constructed by uniting multiple single-scenario neighborhoods. The constructed neighborhood structure is applied in a hybrid local-search algorithm of combining the simulated-annealing search and the tabu technique. An extensive computational experiment was conducted. The developed algorithm was compared with two possible alternative algorithms. The computational results show the efficiency of the defined neighborhood structure and the competitiveness of the developed hybrid local-search algorithm for the established model. © 2017 Elsevier B.V.","Hybrid local-search algorithm; Robust job-shop scheduling; Scenario; Simulated annealing; Tabu search","Computational efficiency; Learning algorithms; Local search (optimization); Optimization; Problem solving; Risk perception; Scheduling; Simulated annealing; Tabu search; Alternative algorithms; Computational experiment; Job shop scheduling problems; Local search algorithm; Neighborhood structure; Robust optimization models; Scenario; Uncertain processing time; Job shop scheduling",2-s2.0-85032785279
"Ezugwu A.E., Olusanya M.O., Adewumi A.O.","A Hybrid Method Based on Intelligent Water Drop Algorithm and Simulated Annealing for Solving Multi-depot Vehicle Routing Problem",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029581513&doi=10.1007%2f978-3-319-67621-0_19&partnerID=40&md5=12c49d4be6d91f87893142b66e4d411c","The vehicle routing problem and its variants such as the multi-depot vehicle routing problem are well-known NP-hard combinatorial optimization problems with wide engineering and theoretical background. In this paper a new hybrid technique based on intelligent water drop algorithm and simulated annealing is proposed to solve the multi-depot vehicle routing problem. The intelligent water drop algorithm is a stochastic population based metaheuristic optimization algorithm that uses a constructive approach to find optimal solutions of a given problem. Simulated annealing is a popular local search meta-heuristic approach with the key features of being able to provide a means to escape local optima by allowing hill-climbing moves with the hope of finding a global optimum. The performance of the hybrid algorithm is evaluated on a set of 23 benchmark instances and the results obtained compared with the best known solutions. The computational results show that the proposed method can produce good solutions, indicating that it is a good alternative algorithm for solving the multi-depot vehicle routing problem. © 2018, Springer International Publishing AG.","Intelligent water drops; Metaheuristics; Multi-depot vehicle routing problem; Simulated annealing","Benchmarking; Combinatorial optimization; Computational methods; Drops; Heuristic algorithms; Heuristic methods; Hybrid vehicles; Routing algorithms; Simulated annealing; Stochastic systems; Vehicle routing; Vehicles; Alternative algorithms; Combinatorial optimization problems; Meta heuristics; Meta-heuristic approach; Meta-heuristic optimizations; Multi-depot vehicle routing problems; Vehicle Routing Problems; Water drop; Optimization",2-s2.0-85029581513
"Liu J.-S., Chang W.-L.","A distributed gossip optimization algorithm for wireless multi-hop networks",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022227887&doi=10.1007%2f978-981-10-5281-1_5&partnerID=40&md5=731c3ea2eb49c5f6a8af41935727da5f","In this paper, we study a constrained network lifetime maximization problem in wireless sensor networks, and introduce a cross-layer formulation with general NUM (network utility maximization) that accommodates routing, scheduling and stream control from different layers of network. Specifically, for this problem, we derive a gossip-based formulation for the consensus agreement on the variables involved, and develop an asynchronous decentralized algorithm specific to the optimization problem. Our numerical experiments exhibit its results, showing that the gossip-based consensus algorithm can actually achieve the optimization objective by means of the simple and robust asynchronous operations developed. © Springer Science+Business Media Singapore 2018.",,"Network layers; Optimization; Wireless telecommunication systems; Asynchronous operation; Consensus algorithms; Decentralized algorithms; Network utility maximization; Numerical experiments; Optimization algorithms; Optimization problems; Wireless multi-hop network; Wireless sensor networks",2-s2.0-85022227887
"Kaur R., Ghumman N.S.","A load balancing algorithm based on processing capacities of VMS in cloud computing",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031430446&doi=10.1007%2f978-981-10-6620-7_8&partnerID=40&md5=cc12ad463b862fdc2cf0ddcf65fc5270","Cloud Computing is a computing paradigm which has made high-performance computing accessible even to SMEs (small and medium enterprises). It provides various types of services to the users in the form of hardware, software, application platforms. The cloud computing environment is elastic and heterogeneous in nature. Any number of users may join/leave the system at any point of time; it means the workload of the system increases/decreases randomly. Therefore, there is a requirement for a load balancing system which must ensure that the load of the system is fairly distributed among the nodes of the system and aims to achieve minimum completion time and maximum resource utilization. The paper presents a load balancing algorithm based on processing capacities of virtual machines (VMs) in cloud computing. It analyses the algorithm and finds the research gap. It also proposes the future work overcoming the research gap in this field. The simulation of the algorithm is carried out in the CloudSim simulation toolkit. © 2018, Springer Nature Singapore Pte Ltd.","Challenges; Cloud computing; Existing algorithms; Heuristic approach; Load balancing; Processing capacities; Round-robin","Application programs; Cloud computing; Heuristic algorithms; Heuristic methods; Network function virtualization; Resource allocation; Routers; Challenges; Cloud computing environments; Heuristic approach; High performance computing; Load balancing algorithms; Processing capacities; Round Robin; Small and medium enterprise; Big data",2-s2.0-85031430446
"Joshi A., Shah T.","Parallelization of string matching algorithm with compaction of DFA",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026789660&doi=10.1007%2f978-981-10-3373-5_33&partnerID=40&md5=c7b22bbd8e8f413d6246dd36c40647cc","String matching algorithms are widely acknowledged due to its use in many areas such as digital forensics, intrusion detection system, plagiarism checking, bioinformatics. For improving the efficiency of the string matching, speed of matching the strings must be elevated. Hence, an approach has been proposed which would significantly reduce the time for matching the strings. Ternary content addressable memory (TCAM) has been used by many for reducing the time requirement. But TCAM has many disadvantages such as high cost, very high power dissipation, problem due to pipelining. Small-scale applications may not be able to bear all the disadvantages associated with TCAM. Hence, an approach has been proposed which would overcome all the disadvantages associated with TCAM. Modern CPUs have multicore facility. These multiple cores have been exploited to provide parallelism. Parallelism greatly helps to increase the speed of matching the string. Apart from this, reducing the memory requirement for string matching algorithm is also necessary. When reduction in memory requirement and parallelization are applied simultaneously, it provides improved results. High response time would be obtained by using this approach. © Springer Nature Singapore Pte Ltd. 2018.","Aho - Corasick algorithm (AC algorithm); Finite automaton (FA); Parallelization; String matching","Computation theory; Digital forensics; Intelligent computing; Intrusion detection; Logic gates; Pattern matching; Program processors; String searching algorithms; Aho-Corasick algorithms; Intrusion Detection Systems; Memory requirements; Parallelizations; Small-scale applications; String matching; Ternary content addressable memory; Time requirements; Ternary content adressable memory",2-s2.0-85026789660
"Yang J., Li L.","Improved biogeography-based optimization algorithm for mobile robot path planning",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031411746&doi=10.1007%2f978-981-10-6499-9_22&partnerID=40&md5=69534f61834308be5adc129cce89a0a6","In view of biogeography-based optimization algorithm has the disadvantages of application limitations and slow convergence speed when in solving the problem of mobile robot path planning. This paper proposes an improved biogeography-based optimization algorithm, which is used to solve the global path planning of mobile robot in static environment. In the proposed algorithm, the navigation point model is selected as the working area model of mobile robot, and the nonlinear migration model and mutation mechanism with the elite retention mechanism are introduced to the biogeography-based optimization algorithm to improve its performance. Simulation proves the feasibility and the effectiveness of the proposed path planning algorithm. © 2018, Springer Nature Singapore Pte Ltd.","Biogeography-based optimization algorithm; Mobile robot; Path planning; The navigation point model","Ecology; Heuristic algorithms; Intelligent systems; Mobile robots; Motion planning; Robot programming; Robots; Biogeography-based optimization algorithms; Global path planning; Mutation mechanism; Path-planning algorithm; Point modeling; Retention mechanism; Robot path-planning; Static environment; Optimization",2-s2.0-85031411746
"Bershad N.J., Eweda E., Bermudez J.C.M.","Stochastic analysis of soft limiters in the LMS algorithm for stationary white Gaussian inputs—A unified theory",2018,"Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024376272&doi=10.1016%2fj.sigpro.2017.06.005&partnerID=40&md5=009a6a1151497a8f598ea5131c1387f4","The effects of saturation-type nonlinearities on the input and the error in the weight update equation for LMS adaptation are investigated for a stationary white Gaussian data model for system identification. Nonlinear recursions are derived for the transient and steady-state weight first and second moments that include the effect of soft limiters on both the input and the error driving the algorithm. By varying a single parameter of the soft limiter, a general theory is presented that is applicable to LMS, soft limiting of the input, error or both and sign–sign LMS. © 2017 Elsevier B.V.","Adaptive filters; Analysis; LMS type algorithms; Stochastic algorithms","Adaptive filtering; Errors; Stochastic systems; Analysis; Gaussian inputs; General theory; LMS algorithms; Second moments; Single parameter; Stochastic algorithms; Stochastic analysis; Adaptive filters",2-s2.0-85024376272
"Ye S., Wei C.","Hierarchical consensus algorithm of multi-agent system based on node-contribution-based community decomposition",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031412201&doi=10.1007%2f978-981-10-6499-9_40&partnerID=40&md5=672a03811d046ffbec0e6c081a0e4d8a","To improve the convergence speed of multi-agent system, a hierarchical consensus algorithm based on community decomposition is proposed. Considering converting the single-layer consensus problem to multi-layers consensus problem, the topology graph is divided into several sub-graphs by utilizing community decomposition algorithm based on node contribution firstly, and the sub-graphs achieve consensus respectively. And then apply the hierarchical decomposition consistency algorithm to the system. The convergence speed of the multi-agent system is improved significantly by optimizing the topology on the premise of maintaining the original topology constraints. For the first-order linear system, the effectiveness of this algorithm is demonstrated by simulations compared with the standard model. © 2018, Springer Nature Singapore Pte Ltd.","Community decomposition; Convergence speed; Hierarchical decomposition consensus algorithm; Multi-agent system","Intelligent agents; Intelligent systems; Linear systems; Software agents; Topology; Consensus algorithms; Consensus problems; Consistency algorithms; Convergence speed; Decomposition algorithm; Hierarchical decompositions; The standard model; Topology constraint; Multi agent systems",2-s2.0-85031412201
"Meng Z., Pan J.-S., Li X.","The QUasi-Affine TRansformation Evolution (QUATRE) Algorithm: An Overview",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030837188&doi=10.1007%2f978-3-319-68527-4_35&partnerID=40&md5=b8c261ee24edca5c7a163ac03e2ce0a8","QUasi-Affine TRansformation Evolution (QUATRE) algorithm is a new simple but powerful stochastic optimization algorithm proposed recently. The QUATRE algorithm aims to tackle the representational/positional bias inborn with DE algorithm and secures an overall better performance on commonly used Conference of Evolutionary Computation (CEC) benchmark functions. Recently, several QUATRE variants have been already proposed since its inception in 2016 and performed very well on many benchmark functions. In this paper, we mainly have a brief overview of all these proposed QUATRE variants first and then make simple contrasts between these QUATRE variants and several state-of-the-art DE variants under CEC2013 test suites for real-parameter single objective optimization benchmark functions. Experiment results show that the movement trajectory of individuals in the QUATRE structure is much more efficient than DE structure on most of the tested benchmark functions. © 2018, Springer International Publishing AG.","Benchmark function; Differential evolution; Global optimization; QUATRE algorithm","Benchmarking; Data handling; Global optimization; Information analysis; Optimization; Benchmark functions; DE algorithms; Differential Evolution; Movement trajectories; Quasi-affine; Single objective optimization; State of the art; Stochastic optimization algorithm; Evolutionary algorithms",2-s2.0-85030837188
"Gu J., Wu Z., Wang X.","Research and practice of genetic algorithm theory",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031428523&doi=10.1007%2f978-981-10-3187-8_11&partnerID=40&md5=4d42b239e5b7f6853eb9cb3e963ba402","Genetic Algorithm is a class of high collateral, stochastic self-reliance search algorithms which based on mechanism of nature select and nature genetic. The paper introduces the principles of genetic algorithm and its methodology. The algorithm is practiced on the solution to find the maximum value of function in a given interval and the result is satisfied. © Springer Nature Singapore Pte Ltd. 2018.","Extrema problem; Genetic algorithm; Nature select","Genetic algorithms; Stochastic systems; Extrema problem; Nature select; Search Algorithms; Computation theory",2-s2.0-85031428523
"Wang J., Liu J., Pan J.-S., Xue X., Huang L.","A Hybrid BPSO-GA Algorithm for 0-1 Knapsack Problems",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030847110&doi=10.1007%2f978-3-319-68527-4_37&partnerID=40&md5=c6c61eec0f99917456f0f01eae62b9c6","0-1 knapsack problems (KPs) is a typical NP-hard problem in combinatorial optimization problem. For the sake of efficiency, it becomes increasingly popular for researchers to apply heuristic techniques to solve the 0-1 KPs. Due to its simplicity and convergence speed, an increasing number of techniques based on binary particle swarm optimization (BPSO) has been presented. However, BPSO-based techniques suffered from a major shortcoming which is the premature convergence of a swam. To address the problem, this paper proposed a hybrid BPSO-GA algorithm which combines the strengths of BPSO and genetic algorithm (GA). Experimental results show that our proposal is able to find more optimal solutions than BPSO-based algorithm. © 2018, Springer International Publishing AG.","Binary particle swarm optimization (BPSO); Genetic algorithm; Hybrid algorithm; Knapsack problems","Bins; Combinatorial optimization; Computational complexity; Data handling; Genetic algorithms; Heuristic methods; Information analysis; Particle swarm optimization (PSO); 0-1 knapsack problem; Binary particle swarm optimization; Combinatorial optimization problems; Convergence speed; Heuristic techniques; Hybrid algorithms; Knapsack problems; Pre-mature convergences; Optimization",2-s2.0-85030847110
"Rathore A., Bhandari M.","Parameter estimation for PID controller using modified gravitational search algorithm",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031417325&doi=10.1007%2f978-981-10-3773-3_4&partnerID=40&md5=176cbedbf15c937846fecc364fa0abdb","This paper focuses on the Gravitational Search Algorithm (GSA) which depends on the law of gravity and law of motion. GSA lacks the exploitation property. To improve the exploitation skill, efficiency, and accuracy of GSA, a modified GSA (MGSA) is proposed. The proposed algorithm keeps up a suitable stability between the exploitation and exploration skills of GSA by using an intelligence factor (IF). The MGSA is applied to speed control problem of an induction motor system. Simulations results showed that the modified GSA performs better than GSA and Adaptive Tabu Search (ATS) in terms of computational time and closed-loop response. © Springer Nature Singapore Pte Ltd. 2018.","Gravitational search algorithm; Induction motor; Integral square error; Modified GSA","Induction motors; Learning algorithms; Tabu search; Three term control systems; Adaptive tabu search; Closed loop response; Exploitation and explorations; Gravitational search algorithm (GSA); Gravitational search algorithms; Integral square errors; Modified GSA; Speed control problem; Proportional control systems",2-s2.0-85031417325
"de Moura Oliveira P.B., Oliveira J., Cunha J.B.","Trends in gravitational search algorithm",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022204276&doi=10.1007%2f978-3-319-62410-5_33&partnerID=40&md5=32a220f784a0e17f81b19189a05526d5","The gravitational search algorithm (GSA) is reviewed, by presenting a tutorial analysis of its key issues. As any other metaheuristic, GSA requires the selection of some heuristic parameters. One parameter which is crucial in regulating the exploratory capabilities of this algorithm is the gravitational constant. An analysis regarding this parameter selection is presented and a heuristic rule proposed for this purpose. The GSA performance is compared both with a hybridization with particle swarm optimization (PSO) and standard PSO. Preliminary simulation results are presented considering simple continuous functions optimization examples. © Springer International Publishing AG 2018.","Gravitational search algorithm; Particle swarm optimization","Artificial intelligence; Distributed computer systems; Learning algorithms; Particle swarm optimization (PSO); Continuous functions; Gravitational constant; Gravitational search algorithm (GSA); Gravitational search algorithms; Heuristic parameters; Heuristic rules; Metaheuristic; Parameter selection; Optimization",2-s2.0-85022204276
"Obara S., Ito Y., Okada M.","Optimization algorithm for power-source arrangement that levels the fluctuations in wide-area networks of renewable energy",2018,"Energy",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031936242&doi=10.1016%2fj.energy.2017.10.038&partnerID=40&md5=afb15c1272413b8bb3b6883b57a7edc9","Fluctuations in individual renewable-energy supplies are largely reduced by distributing the renewable energy over a wide-area transmission network. Therefore, a new analysis algorithm for determining the amount of renewable energy in a wide-area transmission network was developed in this study. Accounting for the power interchange in the transmission network and the energy storage in electric heat pumps and heat storage tanks, the objective function plans the arrangement of the electric power sources that maximizes the economic efficiency of the system. The developed algorithm was applied to Hokkaido, Japan. The areas and capacities of the introduced renewable energies, and the amount of electric power interchanged through the transmission line, were determined. The installed capacity and economic efficiency of the backup power supply and energy storage equipment (heat storage) were also investigated. In this area, the introductory rate of renewable energy was 39.5% of the total electricity production. Moreover, the cost of a distributed power-supply network was 9.99 × 1010 USD. The proposed system is equivalent to 1.88 years of Hokkaido's energy consumption. © 2017 Elsevier Ltd","Distributed power source; Genetic algorithm; Power interchange; Power-source arrangement; Renewable energy; Wide-area network","Electric energy storage; Electric lines; Electric power supplies to apparatus; Electric power system economics; Electric power system planning; Electric power systems; Energy efficiency; Energy storage; Energy utilization; Genetic algorithms; Heat storage; Optimization; Wide area networks; Backup power supplies; Distributed power sources; Distributed power supplies; Electricity production; Optimization algorithms; Power interchanges; Power sources; Renewable energies; Electric power transmission networks; algorithm; economic analysis; electricity generation; electricity supply; energy flux; equipment; genetic algorithm; network analysis; optimization; power generation; renewable resource; Hokkaido; Japan",2-s2.0-85031936242
"Boschetti G., Passarini C., Trevisani A., Zanotto D.","A fast algorithm for Wrench Exertion Capability computation",2018,"Mechanisms and Machine Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025835621&doi=10.1007%2f978-3-319-61431-1_25&partnerID=40&md5=27548cb19921764b15df1e5d8f75eefc","Computational efficiency is a critical issue in most real time applications. In general, non-iterative computational algorithms are less demanding than iterative ones. This paper proposes a new geometry-based algorithm to determine the maximum force or moment a cable driven parallel manipulator can exert in a given direction. A method to find a feasible set of cable tensions corresponding to the desired maximum wrench is also presented, and the proposed approach is validated using three illustrative examples. These algorithms show promise for applications requiring real-time planning. © Springer International Publishing AG 2018.",,"Cables; Computational efficiency; Manipulators; Robots; Tools; Cable-driven parallel manipulators; Computational algorithm; Critical issues; Fast algorithms; Geometry-based algorithms; Maximum forces; Real-time application; Real-time planning; Iterative methods",2-s2.0-85025835621
"Apinantanakon W., Sunat K.","OMFO: A new opposition-based moth-flame optimization algorithm for solving unconstrained optimization problems",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022197647&doi=10.1007%2f978-3-319-60663-7_3&partnerID=40&md5=becf44358fd14f965d74f79c05c72d8b","The Moth-Flame Optimization (MFO) algorithm is a nature-inspired search algorithm that has delivered good performance and efficiency in solving various optimization problems. In order to avoid local optimum and increase global exploration, each moth of MFO updates its position with respect to a specific MFO operation. However, MFO tends to suffer from a slow convergence speed and produces a low quality solution. This paper presents a new opposition-based scheme and embeds it into the MFO algorithm. The proposed algorithm is called OMFO. The experiments were conducted on a set of commonly used benchmark functions for performance evaluation. The proposed OMFO was compared with the original MFO and four other well-known algorithms, namely, PSO, DE, GSA and GWO. The results clearly showed that OMFO outperformed MFO and the four other algorithms used. © Springer International Publishing AG 2018.","Moth-flame optimization; Nature-inspired algorithm; Opposition-based learning; Unconstrained optimization problems","Benchmarking; Particle swarm optimization (PSO); Problem solving; Benchmark functions; Global exploration; Nature inspired algorithms; Opposition-based learning; Optimization algorithms; Optimization problems; Slow convergences; Unconstrained optimization problems; Optimization",2-s2.0-85022197647
"Pandey H.M., Rajput M., Mishra V.","Performance comparison of pattern search, simulated annealing, genetic algorithm and jaya algorithm",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021204430&doi=10.1007%2f978-981-10-3223-3_36&partnerID=40&md5=fc6dc7f94f548f9bb6d1b2ff6f096151","In this paper, we have shown the performance comparison of four powerful global optimization algorithms, namely Pattern Search, Simulated Annealing, Genetic Algorithm and Jaya Algorithm. All of these algorithms are used to find an optimum solution. The standard benchmark functions are utilized for the implementation. The results are collected and analyzed that helps to classify the algorithms according to their computational capability to solve the optimization problems. © Springer Nature Singapore Pte Ltd. 2018.","Genetic algorithm; Jaya algorithm; Pattern search; Simulated annealing","Genetic algorithms; Global optimization; Intelligent computing; Simulated annealing; Benchmark functions; Computational capability; Global optimization algorithm; Optimization problems; Optimum solution; Pattern search; Performance comparison; Optimization",2-s2.0-85021204430
"Yelghi A., Köse C.","A modified firefly algorithm for global minimum optimization",2018,"Applied Soft Computing Journal",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032292802&doi=10.1016%2fj.asoc.2017.10.032&partnerID=40&md5=0929e630ace96b57c15ba6d024d383d4","The Firefly algorithm is a population-based optimization algorithm. It has become popular in the field of optimization and has been applied to engineering practices. Recent works have failed to address how to find the global minimum because their algorithm was trapped in the local minimum. Also, they were not able to provide a balance between exploration and exploitation. In this paper, the Tidal Force formula has been applied to modify the Firefly algorithm, which describes the effect of a massive body that gravitationally affects another massive body. The proposed algorithm brings a new strategy into the optimization field. It is applied by using exploitation (Tidal Force) and keeping a balance between the exploration and exploitation on function suitability. Plate shaped, Steep Ridges, Unimodal and Multimodal benchmark functions were used to compare experimental results. The study findings indicate that the Tidal Force Firefly algorithm outperforms the other existing modified Firefly algorithms. © 2017 Elsevier B.V.","Firefly algorithm; Global minimum; Optimization; Swarm intelligence; Tidal force","Bioluminescence; Global optimization; Gravitation; Swarm intelligence; Engineering practices; Exploration and exploitation; Firefly algorithms; Global minima; Modified firefly algorithms; Multimodal benchmark; Population-based optimization; Tidal forces; Optimization",2-s2.0-85032292802
"Maghawry A.M., Omar Y., Badr A.","Initial Centroid Selection Optimization for K-Means with Genetic Algorithm to Enhance Clustering of Transcribed Arabic Broadcast News Documents",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029587401&doi=10.1007%2f978-3-319-67621-0_8&partnerID=40&md5=55b745a1cd29a55333e4a8c2ba16d9c2","In this research a collection of artificial intelligence techniques are combined together to optimize the process of clustering textual transcripts obtained from audio sources. Since clustering techniques have drawbacks that if not taken care of will produce sub optimal clustering solutions, it’s essential to attempt to optimize the clustering algorithms to avoid sub optimal solutions. As an attempt to overcome this problem, different artificial intelligence techniques are applied to avoid clustering problems. The main objectives of this research is to optimize automatic topic clustering of transcribed speech documents, and investigate the impact of applying genetic algorithm optimization and initial centroid selection optimization (ICSO) in combination with K-means clustering algorithm using Chi-Square similarity measure on the accuracy and the sum of square distances (SSD) of the selected clustering algorithm. The evaluation showed that using ICSO with genetic algorithm and K-means clustering algorithm with Chi-square similarity measure achieved the highest accuracy with the least SSD. © 2018, Springer International Publishing AG.","Centroid selection; Clustering; Genetic algorithm; K-means; Optimization; Speech transcripts; Text clustering; Topic identification","Artificial intelligence; Cluster analysis; Computational methods; Genetic algorithms; Optimization; Transcription; Centroid selection; Clustering; K-means; Speech transcripts; Text Clustering; Topic identification; Clustering algorithms",2-s2.0-85029587401
"Blocho M., Nalepa J.","Complexity analysis of the parallel memetic algorithm for the pickup and delivery problem with time windows",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030792671&doi=10.1007%2f978-3-319-67792-7_46&partnerID=40&md5=fd8082eac374f700b87d79e85904538d","Estimating the theoretical complexity of a parallel algorithm can give an impression on how it will perform in practice. However, this complexity analysis is very often omitted in the works from the parallel computation field. In this paper, we theoretically analyze the time complexity of our parallel algorithm for the pickup and delivery problem with time windows (PDPTW), which is an NP-hard discrete optimization task. The PDPTW is a hierarchical objective problem—the main objective is to minimize the number of trucks serving the transportation requests, whereas the second objective is to optimize the travel distance. In our approach, the fleet size is optimized using the parallel ejection search, and the distance is minimized using the parallel memetic algorithm. Finally, we report example experimental results showing that our parallel algorithms work very fast in practice. © 2018, Springer International Publishing AG.","Complexity analysis; Parallel memetic algorithm; PDPTW","Parallel algorithms; Pickups; Complexity analysis; Discrete optimization; Memetic algorithms; Parallel Computation; PDPTW; Pickup and delivery problem with time windows; Theoretical complexity; Travel distance; Optimization",2-s2.0-85030792671
"Zhao W., Han S., Meng W., Gong Z.","RSSI based positioning fusion algorithm in wireless sensor network using factor graph",2018,"Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031284575&doi=10.1007%2f978-3-319-66628-0_55&partnerID=40&md5=b2e076b2b9d43aa620c194cbe1dabaa7","Various positioning techniques have been widely developed based on received signal strength indicator (RSSI) in Wireless Sensor Network (WSN) positioning systems. Multilateration-based positioning technique is simple and easy to realize, but it can not provide very high positioning accuracy caused by fluctuation of range measurement. Fingerprinting technique is a promising method benefitting from its high precision. However, the process of building radio map cost too much time and labor. In this paper, a fusion algorithm based on both multilateration and fingerprinting is proposed to reduce cost and maintain high accuracy at the same time. An adaptive radio propagation mode is presented in this algorithm as well as a multilateration approaches based on sparse fingerprint. Factor graph is adopted to fuse the results of these two positioning techniques. Simulation experiments demonstrate that the proposed positioning fusion algorithm performs much better than any of the original algorithms participated in the fusion process. © 2018, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.","Factor graph; Fingerprinting; Fusion algorithm; Multilateration; Received Signal Strength Indicator (RSSI); Wireless Sensor Network (WSN)","Mobile computing; Radio waves; Time difference of arrival; Factor graphs; Fingerprinting; Fingerprinting techniques; Fusion algorithms; Original algorithms; Positioning accuracy; Positioning techniques; Received signal strength indicators; Wireless sensor networks",2-s2.0-85031284575
"Su Q., Huang Y., Jiang Y., Fang H.","Quasi-consistent fusion navigation algorithm for DSS",2018,"Science China Information Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028743651&doi=10.1007%2fs11432-016-9054-x&partnerID=40&md5=db0ab1cdc34ad47df760697c3c548338","A fusion navigation algorithm for the distributed satellites system (DSS) utilizing relative range measurements is proposed in this paper. Based on the quasi-consistent extended Kalman filter (QCEKF), an on-line evaluation of the navigation precision can be provided by the fusion navigation algorithm. In addition, the upper bound for the estimation error obtained from the fusion navigation algorithm is lower than those with any groups of measurements, which indicates that the fusion navigation algorithm can automatically choose the suitable redundant measurements to improve the navigation precision. The simulations show the feasibility and effectiveness of the proposed fusion navigation algorithm. © 2017, Science China Press and Springer-Verlag GmbH Germany.","distributed satellites system (DSS); extended Kalman filter (EKF); fusion algorithm; navigation; quasi-consistent extended Kalman filter (QCEKF)","Kalman filters; Navigation; Distributed satellites; Estimation errors; Fusion algorithms; Navigation algorithms; Navigation precision; On-line evaluation; quasi-consistent extended Kalman filter (QCEKF); Range measurements; Extended Kalman filters",2-s2.0-85028743651
"Rashidi H., Khorshidi J.","Exergoeconomic analysis and optimization of a solar based multigeneration system using multiobjective differential evolution algorithm",2018,"Journal of Cleaner Production",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031931533&doi=10.1016%2fj.jclepro.2017.09.201&partnerID=40&md5=03bd967ee5d7f5b189991352de142b66","This paper presents and analyzes a multigeneration energy system that consists of a reverse osmosis desalination unit, water heater, organic Rankine cycle, photovoltaic solar collectors, and a single effect absorption chiller. In doing so, energy and exergy analysis are first performed to evaluate the performance of the system and determine the irreversibility of each component. Next, considering minimizing total cost rate and maximizing exergy efficiency as two objective functions, a multiobjective optimization approach based on differential evolution algorithm is proposed to determine the best design parameters. A self-adaptive technique is utilized to deal with the search capability, population diversity, and convergence speed of the proposed optimization algorithm. An external archive list is used to save all nondominated optimal solutions during the optimization. Dynamic crowding distance approach is employed to decrease archiving size without losing its characteristics. Furthermore, a fuzzy clustering approach is used to select the desired solution among the Pareto-optimal solutions. Simulation results are compared with two other multiobjective optimization algorithms and effectiveness of the proposed optimization method is verified using various indices. Finally, a sensitivity analysis is employed to evaluate effects of design parameters on exergy efficiency and total cost rate of the system. © 2017 Elsevier Ltd","Differential evolution algorithm; Exergy analysis; Multigeneration energy; Multiobjective optimization; Pareto frontier; Photovoltaic solar system; Sensitivity analysis","Cost benefit analysis; Desalination; Evolutionary algorithms; Exergy; Multiobjective optimization; Optimal systems; Pareto principle; Photovoltaic effects; Rankine cycle; Sensitivity analysis; Solar power generation; Water absorption; Differential evolution algorithms; Exergy Analysis; Multi generations; Pareto frontiers; Photovoltaic solar systems; Optimization",2-s2.0-85031931533
"Nalepa J., Cwiek M., Zak L.","Behind the scenes of deadline24: A memetic algorithm for the modified job shop scheduling problem",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030779149&doi=10.1007%2f978-3-319-67792-7_49&partnerID=40&md5=9b1fde8cad37119e85c1a033048c8ad5","Job shop scheduling problem (JSSP) is an NP-hard optimization problem which has been widely studied in the literature due to its practical applicability. In this paper, we show how to model a workflow using a modified version of JSSP, in which a given operation may be executed on a number of different machines. Solving the instances of this modified JSSP, elaborated using our benchmark generation routine, constituted a qualifying task of the Deadline24 programming marathon. In the experimental study, we confront the results submitted by the participants with the solutions obtained using our memetic algorithms and other solvers. This analysis is backed up with the statistical tests. © 2018, Springer International Publishing AG.","Benchmark generation; Job shop sheduling problem; Memetic algorithm; Workflow modeling","Evolutionary algorithms; Optimization; Scheduling; Job shop scheduling problems; Memetic algorithms; NP-hard; Optimization problems; Qualifying tasks; Sheduling; Workflow modeling; Job shop scheduling",2-s2.0-85030779149
"Wu Z., Yu D.","Application of improved bat algorithm for solar PV maximum power point tracking under partially shaded condition",2018,"Applied Soft Computing Journal",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032458826&doi=10.1016%2fj.asoc.2017.10.039&partnerID=40&md5=04fb0365a2161c2ea128945e66aa70b2","The power output curves of solar photovoltaic (PV) system have multiple peaks under partially shaded condition. As the same as traditional MPPT (Maximum Power Point Tracking) search methods, bat algorithm often makes optimized results fall into local extremum. So an improved bat algorithm is proposed. Chaos search strategy is introduced in initial arrangement to improve the uniformity and ergodicity of population. Adapting weight is introduced to balance the global searching ability and the local searching ability. Dynamic contraction regain decreases the search range more effectively. Compared with the original algorithm, the rapidity and accuracy of algorithm have been improved. The simulation shows that improved bat algorithm can find the globally optimal point fast, with high precision, under the partially shaded condition. © 2017 Elsevier B.V.","Bat algorithm; Chaos search strategy; Local extremum; Maximum power point tracking; Solar battery","Solar cells; Solar power generation; Thermoelectricity; Bat algorithms; Chaos search; Global searching ability; Local extremum; Local searching; Maximum Power Point Tracking; Original algorithms; Solar photovoltaic system; Maximum power point trackers",2-s2.0-85032458826
"Cheng Q., Wang C.","A method of trajectory prediction based on kalman filtering algorithm and support vector machine algorithm",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030835274&doi=10.1007%2f978-981-10-6496-8_46&partnerID=40&md5=c88a97f4fa0e123c38c2e3269eab97c5","A trajectory prediction method based on kalman filter algorithm (KF) and support vector machine algorithm (SVM) is proposed to predict the trajectory prediction of fast flight ping-pong in the research of ping-pong robot. This method combines the real-time performance of KF and the stability of SVM. By comparing the correlation coefficient between the predicted value and the measured value, the method intelligently selects an appropriate algorithm for the trajectory prediction of ping-pong. Finally, the result of simulation experiment of fast flight ping-pong shows that the method has good stability to the trajectory prediction of ping-pong, and the prediction accuracy is obviously improved compared with the single algorithm. © 2018, Springer Nature Singapore Pte Ltd.","Correlation coefficient; Kalman filter; Support vector machine; Trajectory prediction","Flight simulators; Forecasting; Intelligent systems; Potassium compounds; Signal filtering and prediction; Support vector machines; Trajectories; Correlation coefficient; Kalman filter algorithms; Kalman filtering algorithms; Measured values; Prediction accuracy; Real time performance; Support vector machine algorithm; Trajectory prediction; Kalman filters",2-s2.0-85030835274
"Tang J., Pan J.-S., Tseng Y.-M., Tsai P.-W., Meng Z.","Optimal economic dispatch of fuel cost based on intelligent monkey king evolutionary algorithm",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026636730&doi=10.1007%2f978-3-319-63859-1_30&partnerID=40&md5=1df88e3953be9cd69ae5e6d9290a1cca","Monkey King evolutionary algorithm (MKEA) is a new type and innovation of gene method that can be more effective evolution of the algorithm to reach goal or objective function. In this study and research is applied the monkey king evolutionary algorithm is used to apply the evolutionary particle to find the optimal power flow of system and calculate the complex power of each line, bus and to minimize power generation cost of the power plant. In order to study the practicability of the algorithm, it is applied to the standard IEEE 5bus load flow test system, and its convergence characteristic curve is observed and compared with the genetic algorithm (GA). The experimental results show that the MKEA can effectively solve the power system optimal power flow problem and this method is find the global solution not local solution that be confirmed in minimum fuel cost of generator of power plants. The minimum fuel cost obtained by MKE and GA is 5369.55 and 5422.0 US Dollars, respectively, when the number of population particles is 100 and the number of iterations is 300 that compared with GA which is 7.6% lower than GA. The results show that MKE has the obvious superiority to find the global solution. © Springer International Publishing AG 2018.","Convergence characteristic; IEEE 5bus; Minimum fuel cost; Monkey king evolutionary algorithm; Optimal power flow","Acoustic generators; Costs; Electric load dispatching; Electric load flow; Fuels; Genetic algorithms; Multimedia signal processing; Scheduling; Signal processing; Convergence characteristics; Economic Dispatch; Fuel cost; Global solutions; IEEE 5bus; Number of iterations; Objective functions; Optimal power flows; Evolutionary algorithms",2-s2.0-85026636730
"Guo M., Zhou J., Tang X., Qiao Y.","4×25-Gb/s duo-binary system over 20-km SSMF transmission with LMS algorithm",2018,"Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031285502&doi=10.1007%2f978-3-319-66625-9_40&partnerID=40&md5=4b47bb8733173542dacf6b405b5390aa","We propose a 4×25-Gb/s intensity-modulated direct detection (IM/DD) duo-binary system with 50-GHz channel spacing. Both of the modulator and photodetector (PD) have 10-GHz 3-dB electrical bandwidth. At receiver, least mean square (LMS) algorithm is used to compensate the signal distortion after transmission. After 20-km standard single mode fiber (SSMF) transmission, LMS algorithm improves about 2-dB receive sensitivity at forward error correction (FEC) limit (BER = 10-3) in duo-binary system. With LMS algorithm, duo-binary system has about 5-dB receive sensitivity improvement at FEC limit compared to on-off keying (OOK) system over 20-km SSMF transmission. This paper proposes a feasible scheme for future high-speed passive optical network (PON). © 2018, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.","Duo-binary system; Intensity-modulated direct detection (IM/DD); Least mean square (LMS) algorithm; Passive optical network (PON)","Bins; Error correction; Optical communication; Passive networks; Signal receivers; Single mode fibers; Systems (metallurgical); Channel spacings; Duo-binary; Electrical bandwidth; Intensity modulated direct detections; Least mean square algorithms; LMS algorithms; Sensitivity improvements; Standard single mode fibers; Passive optical networks",2-s2.0-85031285502
"Janardhanan M.N., Nielsen P., Li Z., Ponnambalam S.G.","Minimizing energy consumption in a straight robotic assembly line using differential evolution algorithm",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022231232&doi=10.1007%2f978-3-319-62410-5_6&partnerID=40&md5=821788717081600c166c50c4e84a820f","This paper focuses on implementing differential evolution (DE) to optimize the robotic assembly line balancing (RALB) problems with an objective of minimizing energy consumption in a straight robotic assembly line and thereby help to reduce energy costs. Few contributions are reported in literature addressing this problem. Assembly line balancing problems are classified as NP-hard, implying the need of using metaheuristics to solve realistic sized problems. In this paper, a well-known metaheuristic algorithm differential evolution is utilized to solve the problem. The proposed algorithm is tested on benchmark problems and the obtained results are compared with current state. It can be seen that the proposed DE algorithm is able to find a better solution for the considered objective function. Comparison of the computational time along with the cycle time is presented in detail. © Springer International Publishing AG 2018.","Assembly line layout; Cycle time; Differential evolution; Energy consumption","Artificial intelligence; Assembly; Assembly machines; Distributed computer systems; Energy utilization; Evolutionary algorithms; Optimization; Problem solving; Robotics; Assembly line; Assembly line balancing problems; Cycle time; Differential Evolution; Differential evolution algorithms; Meta heuristic algorithm; Robotic assembly line balancing; Robotic assembly lines; Robotic assembly",2-s2.0-85022231232
"Bucciarelli E., Mattoscio N., Erasmo V.","Understanding bruno de finetti’s decision theory: A basic algorithm to support decision-making behaviour",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021747855&doi=10.1007%2f978-3-319-60882-2_8&partnerID=40&md5=fcfd9807c089dac934ddba17bb28e8c0","The aim of this work is to present an algorithm inspired to Bruno de Finetti’s decision theory, limited to the version proposed by him in the essay “La probabilità: guida nel pensare e nell’agire” released in 1965. This work is focused on decision theory within the subjective theory of probability conceived by de Finetti. It opens with a brief overview of his theory of probability, followed by a methodological analysis functional to introduce the renowned de Finetti’s example model given for the solution of decision problems. Starting from this example, this work presents a mathematical generalization of the decision algorithm. Afterwards, a real decisional algorithm written in mathematical-style pseudo code is developed. Finally, some conclusive remarks are discussed along with possible future developments. © Springer International Publishing AG 2018.","Decision theory; Earnings; Information; Mathematical algorithm; Mathematical expectation; Probabilities; Uncertainty","Artificial intelligence; Computation theory; Decision making; Distributed computer systems; Earnings; Probability; Decision algorithms; Decision problems; Information; Mathematical algorithms; Mathematical expectation; Possible futures; Pseudo codes; Uncertainty; Decision theory",2-s2.0-85021747855
"Hamdi H., Arfaoui N., Al Mashhour Y., Akaichi J.","Ambulance fastest path using ant colony optimization algorithm",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020482985&doi=10.1007%2f978-3-319-59480-4_40&partnerID=40&md5=9e4409747fb046d2c68f2ca0efe29f24","The number of the accidents in Tunisia is terrifying and it is considered as the highest in the world while basing on accurate statistics. Such situation requires a very fast intervention. Therefore, it is necessary to promote the study in ambulance management, so as to optimize the strategy of response to a given accident. Based on the defect of the ambulance root choosing, this paper puts forward a new algorithm based on ant colony optimization algorithm to find the best way that minimizes the time while taking into consideration the cases of problems that can appear each time such as traffics, catastrophes natural, etc. © Springer International Publishing AG 2018.","ACO algorithm; Ambulance root choosing; Faster path; Shortest path","Accidents; Ambulances; Artificial intelligence; Interactive computer systems; Multimedia services; Multimedia systems; Optimization; ACO algorithms; Ant Colony Optimization algorithms; Faster path; Fastest paths; Shortest path; Tunisia; Ant colony optimization",2-s2.0-85020482985
"Ran Y., Chen Z., Tang S., Zhang Z.","Primal dual based algorithm for degree-balanced spanning tree problem",2018,"Applied Mathematics and Computation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028564927&doi=10.1016%2fj.amc.2017.08.016&partnerID=40&md5=e6ba90feb6ae457799ba8b0654e02b40","This paper studies approximation algorithm for the degree-balanced spanning tree (DBST) problem. Given a graph G=(V,E), the goal is to find a spanning tree T such that ∑v ∈ VdegT(v)2 is minimized, where degT(v) denotes the degree of node v in tree T. The idea of taking squares on node degrees is to manifest the role of nodes with large degree, and thus minimizing the sum will result in a comparatively balanced degree distribution. This is a non-linear objective function. We prove that DBST is NP-hard, and then develop a primal–dual based algorithm with a guaranteed performance ratio. © 2017 Elsevier Inc.","Degree-balanced spanning tree; Nonlinear objective function; Primal dual algorithm","Approximation algorithms; Graph theory; Degree distributions; Degree of nodes; Guaranteed performance; Node degree; Nonlinear objective functions; Primal dual algorithms; Spanning tree; Spanning tree problems; Trees (mathematics)",2-s2.0-85028564927
"Yao L., Wang F.Z., Han S.M.","Fault diagnosis of hoist braking system based on improved particle swarm optimization algorithm",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030863631&doi=10.1007%2f978-981-10-6496-8_4&partnerID=40&md5=27ea859d48abc080fac0e7d1f89eeb1f","Reliability of the mine hoist braking system is directly related to the safety of staff in the pit. For the sake of improving the accuracy of the fault diagnosis of the hoist braking system, aradial basis function (RBF) neural network diagnostic method based on improved particle swarm optimization (PSO) algorithm is proposed. Then, the hoist braking system fault diagnosis model is established, which uses some kinds of braking system fault characteristic parameters as input variables and adopts several kinds of main fault types as output ones. In view of the strong global convergence of the genetic algorithm (GA), the idea of crossover and mutation is introduced into PSO and the paper employs to optimize the parameters of hidden layer of RBF neural network. The simulation results show that the improved diagnosis strategy improves fault diagnostic speed and precision of the hoist braking system. © 2018, Springer Nature Singapore Pte Ltd.","Fault diagnosis; GA; Mine hoist braking system; PSO; RBF","Failure analysis; Gallium; Genetic algorithms; Hoists; Intelligent systems; Mine hoists; Optimization; Particle swarm optimization (PSO); Radial basis function networks; Reactive power; Braking system; Crossover and mutation; Diagnosis strategies; Global conver-gence; Improved particle swarm optimization algorithms; Network diagnostics; Particle swarm optimization algorithm; RBF Neural Network; Fault detection",2-s2.0-85030863631
"Ramadas M., Abraham A., Kumar S.","RDE - Reconstructed mutation strategy for differential evolution algorithm",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028617716&doi=10.1007%2f978-3-319-60618-7_8&partnerID=40&md5=1b66fd4b23fa6d45bbf35e376d1e32e9","Several researchers’ innovative work during past years has led to development of numerous optimization techniques. Complex task that were once difficult to be compute using traditional methods now can use the optimization techniques for computation. Differential Evolution (DE) is a powerful, population based, stochastic optimization algorithm. The mutation strategy of DE algorithm is an important operator as it aids in generating a new solution vector. In this paper, we are introducing a variant of DE mutation strategy named RDE (Reconstructed Differential Evolution). This strategy use three different control parameters. The results computed here are then compared with the results of an existing mutation strategy where in the comparison show a better performance for the new revised strategy. © Springer International Publishing AG 2018.","Control parameters; Differential evolution; Mutation; Optimization","Evolutionary algorithms; Pattern recognition; Soft computing; Control parameters; Differential Evolution; Differential evolution algorithms; Mutation; Mutation strategy; Optimization techniques; Solution vectors; Stochastic optimization algorithm; Optimization",2-s2.0-85028617716
"Jiang L., Yang Y., Zhang Y., Feng X., Ji J.","Vehicle routing model and algorithm study for the network of container transportation with dumping trailers under hard time window constraint",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026763976&doi=10.1007%2f978-981-10-3551-7_46&partnerID=40&md5=ff9eee5c85d2316989212161a57c7525","The network of container transportation with dumping trailers is a typical NP-hard problem and has strict requirement on time. Therefore, vehicle routing becomes the core problem of the network. In this paper, the vehicle routing optimization model is built for the network of container transportation with dumping trailers to analyze the vehicle routing optimization problem under hard time constraint. In addition, via simulated annealing algorithm, the model is solved and finally verified via sample calculation. © Springer Science+Business Media Singapore 2018.","Hard time window; Network of container transportation with dumping trailers; Simulated annealing algorithm; Vehicle routing problem","Computational complexity; Containers; Intelligent systems; Intelligent vehicle highway systems; Optimization; Routing algorithms; Simulated annealing; Transfer cases (vehicles); Transportation; Vehicle routing; Vehicles; Container transportation; Routing model; Simulated annealing algorithms; Time constraints; Time window constraint; Time windows; Vehicle routing optimization; Vehicle Routing Problems; Network routing",2-s2.0-85026763976
"Islam M.Z., Estivill-Castro V., Rahman M.A., Bossomaier T.","Combining K-MEANS and a genetic algorithm through a novel arrangement of genetic operators for high quality clustering",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029490496&doi=10.1016%2fj.eswa.2017.09.005&partnerID=40&md5=5c4d8c6906f85879015ff37dea613a78","Knowledge discovery from data can be broadly categorized into two types: supervised and unsupervised. A supervised knowledge discovery process such as classification by decision trees typically requires class labels which are sometimes unavailable in datasets. Unsupervised knowledge discovery techniques such as an unsupervised clustering technique can handle datasets without class labels. They aim to let data reveal the groups (i.e. the data elements in each group) and the number of groups. For the ubiquitous task of clustering, K-MEANS is the most used algorithm applied in a broad range of areas to identify groups where intra-group distances are much smaller than inter-group distances. As a representative-based clustering approach, K-MEANS offers an extremely efficient gradient descent approach to the total squared error of representation; however, it not only demands the parameter k, but it also makes assumptions about the similarity of density among the clusters. Therefore, it is profoundly affected by noise. Perhaps more seriously, it can often be attracted to local optima despite its immersion in a multi-start scheme. We present an effective genetic algorithm that combines the capacity of genetic operators to conglomerate different solutions of the search space with the exploitation of the hill-climber. We advance a previous genetic-searching approach called GENCLUST, with the intervention of fast hill-climbing cycles of K-MEANS and obtain an algorithm that is faster than its predecessor and achieves clustering results of higher quality. We demonstrate this across a series of 18 commonly researched datasets. © 2017 Elsevier Ltd","Cluster evaluation; Clustering; Data mining; Genetic algorithm; K-MEANS","Classification (of information); Data mining; Decision trees; Distributed computer systems; Genetic algorithms; Cluster evaluations; Clustering; Clustering results; K-means; Knowledge discovery process; Knowledge discovery techniques; Total squared errors; Unsupervised clustering technique; Clustering algorithms",2-s2.0-85029490496
"Ochoa P., Castillo O., Soria J.","A new approach for dynamic mutation parameter in the differential evolution algorithm using fuzzy logic",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030695355&doi=10.1007%2f978-3-319-67137-6_9&partnerID=40&md5=0c1d5697142172f811a9afabda879f38","We have been working previously with the Differential Evolution algorithm by dynamically adapting the mutation parameter using a simple fuzzy system where we have one input as the generations and one output as the mutation, and we have obtained good results with this modification for simple problems. However, our new goal is to include diversity as another the input to the fuzzy system, this is an Euclidean distance, which will help us to know if the individuals of the population are separated or near in the search space in other words is the exploration and the exploitation in the search space. This work is the beginning of an investigation to be able to adapt the diversity variable in the best form in the Differential Evolution algorithm just as our previous work the output of the new fuzzy system will be the mutation variable of the Differential evolution algorithm. For this article we work with a set of simple benchmark functions in order to observe the behavior of this new fuzzy system. © Springer International Publishing AG 2018.","Differential evolution algorithm; Diversity and mutation; Fuzzy differential evolution","Fuzzy logic; Fuzzy systems; Optimization; Parameter estimation; Benchmark functions; Differential Evolution; Differential evolution algorithms; Diversity and mutation; Dynamic mutation; Euclidean distance; New approaches; Search spaces; Evolutionary algorithms",2-s2.0-85030695355
"Lagunes M.L., Castillo O., Soria J.","Methodology for the optimization of a fuzzy controller using a bio-inspired algorithm",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030673374&doi=10.1007%2f978-3-319-67137-6_14&partnerID=40&md5=0129cd9cdb835c887986d8ae72ec8e48","This paper describes the work done on the methodology for the optimization of a fuzzy controller using a bio-inspired optimizationalgorithm. The fuzzy controlller which uses a fuzzy inference system that has angular velocity error, linear velocity error as inputs respectively and as outputs torque 1 and torque 2, to evaluate the tracking performance of the robot in simulation to the desired reference trajectory. For the optimization of the fuzzy system the algorithm of the fireflies was used, which is based on the behavior on the blinking fireflies. © Springer International Publishing AG 2018.","Firefly algorithm; Fuzzy systems; Methodology; Optimization","Bioluminescence; Fire protection; Fuzzy inference; Fuzzy systems; Bio-inspired algorithms; Firefly algorithms; Fuzzy controllers; Fuzzy inference systems; Linear velocity; Methodology; Reference trajectories; Tracking performance; Optimization",2-s2.0-85030673374
"Menon V.K., Soman K.P.","A new evolutionary parsing algorithm for LTAG",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026779991&doi=10.1007%2f978-981-10-3373-5_45&partnerID=40&md5=6548eedb1835c60381d5070371b5ca1a","Tree adjoining grammars (TAGs) are mildly context-sensitive psycholinguistic formalisms that are hard to parse. All standard TAG parsers have a worst-case complexity of O(n6), despite being one of the most linguistically relevant grammars. For comprehensive syntax analysis, especially of ambiguous natural language constructs, most TAG parsers will have to run exhaustively, bringing them close to worst-case runtimes, in order to derive all possible parse trees. In this paper, we present a new and intuitive genetic algorithm, a few fitness functions and an implementation strategy for lexicalised-TAG parsing, so that we might get multiple ambiguous derivations efficiently. © Springer Nature Singapore Pte Ltd. 2018.","Crossover; Derivation; Evolutionary parsing; Genetic algorithm; Genetic operators; Lexicalisation; Mutation; NLP; Parse tree; Syntax analysis; Tree adjoining grammar","Computational grammars; Computational linguistics; Context sensitive grammars; Evolutionary algorithms; Forestry; Formal languages; Genetic algorithms; Intelligent computing; Linguistics; Trees (mathematics); Crossover; Derivation; Evolutionary parsing; Genetic operators; Lexicalisation; Mutation; Parse trees; Syntax analysis; Tree adjoining grammars; Syntactics",2-s2.0-85026779991
"Sowmiya N., Valarmathi B., Srinivasa Gupta N.","Solving machine part cell formation problem using genetic algorithm based evolutionary computing",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028602205&doi=10.1007%2f978-3-319-60618-7_20&partnerID=40&md5=ad9398bd1a18355e3f5ef63e21e6fa79","Machine part cell formation is the group technology problem, in which the parts with near similar machining requirements are grouped into part families and the corresponding machines into machine cells. In this paper, a genetic algorithm with a fine tuning procedure is proposed to solve the group technology problem considering only one process plan for each part. The grouping efficacy achieved by the proposed method is comparable to the existing methods in general and better for 11.42% of the datasets. © Springer International Publishing AG 2018.","Cell formation; Cellular manufacturing; Clustering; Genetic algorithm; Grouping efficacy","Cells; Clustering algorithms; Cytology; Genetic algorithms; Group technology; Machinery; Pattern recognition; Soft computing; Cell formation; Cell formation problem; Clustering; Evolutionary computing; Grouping efficacy; Machine cell; Process plan; Technology problems; Cellular manufacturing",2-s2.0-85028602205
"Xiao Y., Konak A.","A genetic algorithm with exact dynamic programming for the green vehicle routing & scheduling problem",2018,"Journal of Cleaner Production",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007454331&doi=10.1016%2fj.jclepro.2016.11.115&partnerID=40&md5=83a3ac48ef7af4dff44f2db935d32145","Traffic congestion significantly increases CO2 (a well-known greenhouse gas) emissions of vehicles in road transportation and causes other environmental costs as well. A road-based delivery company can reduce its CO2 emissions through operational decisions such as efficient vehicle routes and delivery schedules by considering time-varying traffic congestion in its service area. In this paper, we study the time-dependent vehicle routing &amp; scheduling problem with CO2 emissions optimization (TD-VRSP-CO2) and develop an exact dynamic programming algorithm to determine the optimal vehicle schedules for given vehicle routes. A hybrid solution approach that combines a genetic algorithm with the exact dynamic programming procedure (GA-DP) is proposed as an efficient solution approach for the TD-VRSP-CO2. Computational experiments on 30 small-sized instances and 14 large-sized instances are used to study the efficiency and effectiveness of the proposed hybrid optimization approach with promising results. Contributions of this study can help road-based delivery companies be ready for a low-carbon economy and also help individual vehicle drivers make better vehicle scheduling plans with lower CO2 emissions and fuel consumption. © 2016 Elsevier Ltd","CO2 emissions; Dynamic programming; Green logistics; Hybrid optimization; Sustainability","Carbon; Carbon dioxide; Fuel economy; Gas emissions; Genetic algorithms; Greenhouse gases; Logistics; Optimization; Renewable energy resources; Roads and streets; Routing algorithms; Scheduling; Sustainable development; Traffic congestion; Transportation; Vehicle routing; Vehicles; Computational experiment; Dynamic programming algorithm; Green logistics; Hybrid optimization; Hybrid optimization approaches; Hybrid solution approaches; Operational decisions; Road transportation; Dynamic programming",2-s2.0-85007454331
"Kabalci Y., Kockanat S., Kabalci E.","A modified ABC algorithm approach for power system harmonic estimation problems",2018,"Electric Power Systems Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028512636&doi=10.1016%2fj.epsr.2017.08.019&partnerID=40&md5=8923af710c21bcbf65ad50bab25f3812","Electrical harmonic is an important issue on power quality of electrical systems. Therefore, estimation of power harmonics are essential to design filters to be utilized in electrical power systems for reducing harmonics and their effects on the electrical power systems. In this study, a power system harmonic estimation solution based on modified artificial bee colony (MABC) algorithm have been proposed. The proposed method in this study is different from other hybrid techniques previously reported ones since estimation processes are mainly focused on decreasing computational complexity and time. In order to provide more accurate and comprehensive estimation results for the proposed method, two different experiments are investigated. Obtained results by the performed experiments showed that the proposed harmonic estimator provides several advantages such as offering very low computational time, more accurate estimation of amplitude and phase values for all conditions and low complexity. © 2017 Elsevier B.V.","Estimation; Harmonics; Modified artificial bee colony algorithm","Electric power systems; Estimation; Evolutionary algorithms; Optimization; Accurate estimation; Artificial bee colonies; Artificial bee colony algorithms; Electrical harmonics; Electrical power system; Estimation process; Harmonics; Power system harmonics; Harmonic analysis",2-s2.0-85028512636
"Gu S., Luo L., Zhao Z., Li X.","The multi-objective routing optimization algorithm for hybrid SDN",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028335718&doi=10.1007%2f978-981-10-4837-1_39&partnerID=40&md5=a744b5e6ab7573d640128e811b88cfd0","In order to make full use of advantages of SDN nodes to optimize network performance, traffic engineering of hybrid SDN becomes a current research focus, and routing optimization is one of the key strategies to realize the goal of traffic engineering. However, current traffic engineering of hybrid SDN fails to take overall load balancing of the network and processing capacity of SDN nodes into consideration. To solve the above problem, a multi-objective routing optimization algorithm, i.e. MCS, is proposed to optimize link utilization and transmission delay of SONet under the actual restriction of SDN-FE. Experiments show that in light network load, MCS is similar to SOTE in performance, but the former could reduce 9% of network compared with the latter in heavy load. Therefore, MCS is able to provide better optimization. © Tsinghua University Press, Beijing and Springer Nature Singapore Pte Ltd. 2018.","Genetic algorithm; Hybrid SDN; Minimum cost sum; Routing optimization; Traffic engineering","Cost engineering; Genetic algorithms; Multiobjective optimization; Optimization; Hybrid SDN; Link utilization; Minimum cost; Multi objective; Processing capacities; Routing optimization; Traffic Engineering; Transmission delays; Routing algorithms",2-s2.0-85028335718
"Zhang Z., Wang X., Lu J.","Multi-objective immune genetic algorithm solving nonlinear interval-valued programming",2018,"Engineering Applications of Artificial Intelligence",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032827886&doi=10.1016%2fj.engappai.2017.10.004&partnerID=40&md5=00af82ca3017e7fd9d1dce92dfcd59a9","This work studies one multi-objective immune genetic algorithm with small population to solve a general kind of unconstrained multi-objective interval-valued programming. In this optimization approach, those competitive individuals are discriminated based on interval arithmetic rules and a possibility model; a crowding degree model in interval-valued environments is developed to eliminate redundant individuals; the current population promotes different individuals to evolve towards specific directions by population sorting and immune evolution, while those elitist individuals found accelerate to explore the desired regions through genetic evolution. The theoretical analysis has showed that the computational complexity of the proposed approach depends mainly on the elitist population size. Comparative experiments have illustrated that the approach can take a rational tradeoff between effect and efficiency. It can perform well over the compared approaches as a whole, and has the potential to solving multi-modal and hard multi-objective interval-valued programming problems. © 2017 Elsevier Ltd","Crowding degree model; Immune genetic algorithm; Interval analysis; Multi-objective interval-valued programming; Pareto optimality","Genetic algorithms; Pareto principle; Population statistics; Comparative experiments; Immune genetic algorithms; Interval analysis; Interval arithmetic; Interval-valued Programming; Optimization approach; Pareto-optimality; Population sorting; Optimization",2-s2.0-85032827886
"Liu J., Fan C., Tian X., Ding Q.","Optimization of AES and RSA algorithm and its mixed encryption system",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026650336&doi=10.1007%2f978-3-319-63859-1_48&partnerID=40&md5=5c3171ce48bdecafd77a30e9cb47d944","An improved key expansion method is proposed to improve the security performance in AES key expansion. There is large difference of operation time between Mixcolumns and Inverse Mixcolumns, we propose the simplest form of MixColumn and InvMixColumn operation on finite field GF (2N) which consumes same computing resources in the process of encryption and decryption. In terms of the defection of RSA operation efficiency, traditional double prime number is replaced by four prime number, Chinese remainder theorem combined with Montgomery modular multiplication is also presented to optimize modular exponentiation. On this basis, we adopt message digest, digital signature, digital envelope and other technologies to build a mixed encryption system which encompasses convenient key management and high-efficiency encryption and decryption, combined with the advantages of AES and RSA. The experimental results show that optimized algorithm has high speed and feasibility. © Springer International Publishing AG 2018.","AES; Algorithm; Algorithm; Chinese remainder theorem; Digital signature; RSA","Algorithms; Authentication; Computation theory; Efficiency; Electronic document identification systems; Multimedia signal processing; Optimization; Signal processing; Chinese remainder theorem; Computing resource; Encryption and decryption; Modular Exponentiation; Montgomery modular multiplication; Operation efficiencies; Optimized algorithms; Security performance; Cryptography",2-s2.0-85026650336
"Manzke L., Keller B., Buscher U.","An artificial bee colony algorithm to solve the single row layout problem with clearances",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029541062&doi=10.1007%2f978-3-319-67223-6_27&partnerID=40&md5=a01a4e9324662ee67f603ddfd98db219","The single row layout problem (SRLP) is defined as the optimal arrangement of n machines with varying length along a straight line in order to minimize the weighted sum of distances between all machine pairs. In this paper, an artificial bee colony (ABC) metaheuristic is proposed to solve the SRLP considering sequence-dependent, asymmetric clearances for the first time. The algorithm is evaluated on several benchmark instances selected from literature as well as random generated ones involving up to n = 60 machines. By comparing the computational results, either to optimal or best known solutions, it is revealed that our ABC performs efficiently, especially for instances with sequence-dependent asymmetric clearances. © 2018, Springer International Publishing AG.","Artificial bee colony algorithm; Asymmetric clearances; Combinatorial optimization; Machine layout problem; Single row layout","Benchmarking; Combinatorial optimization; Evolutionary algorithms; Information systems; Artificial bee colonies (ABC); Artificial bee colony algorithms; Computational results; Machine layout problems; Metaheuristic; Optimal arrangement; Sequence-dependent; Single-row layout; Optimization",2-s2.0-85029541062
"Priya Esther B., Sathish Kumar K., Venkatesh S., Gokulakrishnan G., Asha Rani M.S.","Genetic algorithm based peak load management for low voltage consumers in smart grid – A case study",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028418874&doi=10.1007%2f978-3-319-63645-0_51&partnerID=40&md5=1d5f856a475e9547fba9f1cb19810cfe","To withstand the quick development with the demand for energy and the overall demand cost, enhanced effectiveness, dependability and adaptability, smart strategies should be carried forth in energy sector for our earth and vitality protection. In the electrical domain DSM can be a part of smart grid where the consumers can participate themselves to decrease the peak load and eventually the load profile can be reshaped. A portion of the DSM method is peak clipping, load shifting, valley filling and energy conservation. The paper involves the concept of load shifting to low voltage consumers using several types of appliances and in large numbers. Load shifting with respect to day ahead forecast is formulated as a minimization problem and are solved using learning based evolutionary algorithm. Simulations were carried out with a specific test case using Mat Lab and the results show a substantial peak reduction and cost savings for the future smart grid. © Springer International Publishing AG 2018.","Day ahead load shifting; Demand side management (DSM); Heuristic algorithm; Load forecasting; Load scheduling; Peak load management (PLM); Time of day (ToD)","Electric load management; Electric power plant loads; Electric power transmission networks; Electric utilities; Genetic algorithms; Heuristic algorithms; Intelligent systems; Scheduling; Load forecasting; Load scheduling; Load shifting; Peak load management (PLM); Time of day; Smart power grids",2-s2.0-85028418874
"Lee C.-T., Peng S.-L.","A pairwise alignment algorithm for long sequences of high similarity",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031761447&doi=10.1007%2f978-981-10-5508-9_27&partnerID=40&md5=a190e2a5107ce40648612b10642b28df","Alignment algorithms are important in bioinformatics for comparing the similarity among sequences. The algorithm of Needleman–Wunsch is well known for globally aligning two sequences. However, this algorithm is unsuitable for sequences of long length. Many heuristic algorithms are proposed, such as BLAST and FASTA. However, they are still unsuitable for long sequences. In this paper, we study the alignment problem on highly similar sequences. By taking SARS viruses as an example, our result shows that our algorithm runs faster than Clustalx for aligning two SARS viruses. It implies that our algorithm is suitable for viruses of high similarity. © Springer Nature Singapore Pte Ltd. 2018.","Pairwise alignment; SARS virus; Whole-genome alignment","Diseases; Heuristic algorithms; Alignment algorithms; Alignment Problems; Long lengths; Long sequences; Pairwise alignment; SARS virus; Whole genome alignment; Viruses",2-s2.0-85031761447
"Yu T., Wang S., Yu X.","A preamble mining algorithm oriented to binary protocol using random probes",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026636405&doi=10.1007%2f978-3-319-63859-1_39&partnerID=40&md5=c6bdbc7c684bffff6786c23c5632eea7","At present, most of the researches on the protocol reverse are on the basis of segmented frames and lack of effective methods to analyze the raw data stream. Several existing frame segmentation algorithms based on AC have the problem of large space overhead and low time efficiency. In this paper, we study on frames segmentation algorithms based on preamble mining and propose a preamble mining algorithm based on random probes oriented to binary protocol. We extract the correct preamble by randomly inserting some probes into the data stream, from which to find continuous short mode strings, after which extracting the most frequently repeated strings as the candidate units, and then filtering them with the help of structural characteristics of the preamble. Experiment shows that the algorithm has higher time efficiency compared with the preamble mining algorithm based on AC algorithm. © Springer International Publishing AG 2018.","Frames segmentation; Preamble mining; Protocol reverse; Random probes","Bins; Data communication systems; Data mining; Efficiency; Probes; Signal processing; Binary protocols; Large spaces; Mining algorithms; Random probes; Repeated strings; Segmentation algorithms; Structural characteristics; Time efficiencies; Multimedia signal processing",2-s2.0-85026636405
"Luchter-Boba M., Łukasik P., Piórkowski A.","Efficient parallelization methods of labeling algorithm",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031432601&doi=10.1007%2f978-3-319-68720-9_13&partnerID=40&md5=c6e176ee683056eedc9a0ede632018e8","Digital image processing is a field with broad applications. The development of technology has made it possible to introduce intelligent systems in distinctive areas such as medicine, robotics and astronomy. In this paper, the authors focus on indexing algorithms (also called labeling). Numerous studies have considered the various ways of implementing parallelization and the associated benefits. The indexing process involves assigning the same label to pixels of the same object. For the purpose of this study, a few algorithms proposed by Suzuki et al., Soh et al. and the method described by Tadeusiewicz and Korohoda were implemented. In order to parallelize the algorithms, the indexing algorithm of Niknam et al. was used and a method of partial parallelization was proposed. © 2018, Springer International Publishing AG.","Connected component labeling; Image processing; Indexation; Labeling; Parallel processing; Parallelization","Aluminum; Coding errors; Indexing (of information); Intelligent systems; Labeling; Broad application; Connected component labeling; Indexation; Indexing algorithms; Indexing process; Labeling algorithms; Parallel processing; Parallelizations; Image processing",2-s2.0-85031432601
"Anuradha M.G., Basavaraj L.","Design and implementation of high speed VLSI architecture of online clustering algorithm for image analysis",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021240740&doi=10.1007%2f978-981-10-3223-3_18&partnerID=40&md5=2914c0661927e38ca5c3cfbe663500b9","A novel architecture for computing On-line clustering using moving average method for handling varied dimension data up to eight is proposed. The architecture proposed can perform clustering operation in a single clock cycle for any given dimension. A new method for division is proposed using parallel multiplier architecture and power of two which computes the division operation in single clock cycle. The architecture is tested for its working using Xilinx/ISim tool and the design is implemented using FPGA Spartan 3A. © Springer Nature Singapore Pte Ltd. 2018.","Clustering; FPGA; Fuzzy C-Means algorithm; K-Means","Clocks; Copying; Data handling; Field programmable gate arrays (FPGA); Fuzzy clustering; Integrated circuit design; Intelligent computing; VLSI circuits; Clustering; Clustering operation; Design and implementations; Fuzzy C-means algorithms; K-means; Moving average method; Parallel multiplier architecture; VLSI architectures; Clustering algorithms",2-s2.0-85021240740
"Raj B., Ranjan P., Rizvi N., Pranav P., Paul S.","Improvised bat algorithm for load balancing-based task scheduling",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026731311&doi=10.1007%2f978-981-10-3373-5_52&partnerID=40&md5=b221ef4a6ff2d5cdea6837973e50bbfd","The development of computing system has always focused on performance improvements driven by the demand of applications by customers, scientific and business domain. Cloud computing has emanated as a new trend as well as required domain for the efficient usage of computing systems. As the applications operating in cloud environments are becoming popular, the load is also rising on the servers and the traffic is increasing rapidly. In this paper, a new metaheuristic algorithm has been discussed known as improvised Bat algorithm and the case study of it is explained with proper example. The improvised Bat algorithm works on Min-Min, Max-Min and Alpha-Beta pruning algorithm for population generation and then uses the Bat algorithm for determining the sequence of execution of tasks to keep it minimum. © Springer Nature Singapore Pte Ltd. 2018.","Algorithm; Cloud; Computing; Load; Task","Algorithms; Clouds; Computation theory; Intelligent computing; Loading; Alpha-beta pruning algorithm; Business domain; Cloud environments; Computing; Computing system; Meta heuristic algorithm; Task; Task-scheduling; Distributed computer systems",2-s2.0-85026731311
"Zhao Y., Chen Z., Xu Y., Wei H.","Energy-efficient resource allocation in energy harvesting communication systems: A heuristic algorithm",2018,"Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031295214&doi=10.1007%2f978-3-319-66628-0_1&partnerID=40&md5=513c206ff07592b762b223abb91874f0","Harvesting energy from the environment is a method to improve the energy utilization efficiency. However, most renewable energy has a poor stability due to the weather and the climate. The reliability of the communication systems will be influenced to a large extent. In this paper, an energy-efficient downlink resource allocation problem is investigated in the energy harvesting communication systems by exploiting wireless power transfer technology. The resource allocation problem is formulated as a mixed-integer nonlinear programming problem. The objective is to maximize the energy efficiency while satisfying the energy causality and the data rate requirement of each user. In order to reduce the computational complexity, a suboptimal solution to the optimization problem is obtained by employing a quantum-behaved particle swarm optimization (QPSO) algorithm. Simulation results show that the QPSO algorithm has a higher energy efficiency than the traditional particle swarm optimization (PSO) algorithm. © 2018, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.","Energy harvesting communication; Heuristic algorithm; Resource allocation","Energy harvesting; Energy transfer; Energy utilization; Heuristic algorithms; Integer programming; Nonlinear programming; Optimization; Particle swarm optimization (PSO); Resource allocation; Downlink resource allocation; Energy utilization efficiency; Energy-efficient resource allocation; Mixed integer non-linear programming problems; Particle swarm optimization algorithm; Quantum-behaved particle swarm optimization(QPSO) algorithm; Resource allocation problem; Wireless power transfer; Energy efficiency",2-s2.0-85031295214
"Zhao Y., Zhang F., Qi C.","A novel algorithm enumerating bent functions based on value distribution and run length",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028374118&doi=10.1007%2f978-3-319-60744-3_27&partnerID=40&md5=58097a2ba6ff04f17b9e556d4e5c3422","Bent function is an important nonlinear function in design of stream cipher and S-box. With more than eight variables Bent functions can only be generated by construction, where, most of these functions are still not found. In this paper, the Bent function search algorithm based on truth table is presented via analyzing the value distribution and run the length of the Bent function. Compared with other searching algorithms, the algorithm proposed in this paper has weak storage complexity and is easy to be implemented by parallel computing. © 2018, Springer International Publishing AG.","Bent functions; Boolean functions; Cryptography; Parallel computing algorithms; Run length; Walsh transformation","Cryptography; Intelligent systems; Mathematical transformations; Real time systems; Walsh transforms; Bent function; Nonlinear functions; Parallel computing algorithms; Run length; Searching algorithms; Storage complexity; Value distribution; Walsh transformation; Boolean functions",2-s2.0-85028374118
"Tefrie K.G., Sohn K.-A.","Autonomous text summarization using collective intelligence based on nature-inspired algorithm",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022175933&doi=10.1007%2f978-981-10-5281-1_50&partnerID=40&md5=7a0b135efee118e43757f5104fdb6775","Thousands of years ago written language was introduced as a way of enhancing and facilitating communication. Fast forward to the twenty first century much has changed, especially the flow of data incrementing at fast rate and we should use the power of algorithms and hardware technology to understand text more clearly. With the Information age rising we are being cluttered with humongous data each day with no sign of it slowing. Humans have been trying to create ways on how to handle this continuous flow of text, image and video. And one of the categories of subjects regarding text is text summarization, given a document coming up with a reasonable summarized version of the original document. People have tried different aspects of summarizing to get a shorter yet an informative definition of document. This paper tries to utilize using nature inspired algorithms to implement an auto summarizer of text using pseudo-selected features. The main objective of this research is to use of cooperative nature-inspired algorithm specifically ant colony algorithm in text mining problems, in our case, text summarization. And throughout the paper we will try to show how this system can be achieved as well as show the performance and effectiveness of the measurement. We have used the standard data used to test summarization techniques, DUC data and at last comparing it to two algorithms for further analysis. © Springer Science+Business Media Singapore 2018.","Ant colony system; Automated text summarization; Natural language processing","Ant colony optimization; Data mining; Text processing; Wireless telecommunication systems; Ant colony algorithms; Ant colony systems; Collective intelligences; Continuous flows; Hardware technology; Nature inspired algorithms; Test summarization; Text summarization; Natural language processing systems",2-s2.0-85022175933
"Umang, Hoda M.N., Geetanjali Singh","EEA-LEACH—Trustworthy-enhanced algorithm for energy optimization in wireless sensor networks",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031433003&doi=10.1007%2f978-981-10-6614-6_15&partnerID=40&md5=16479036029ee0c982f3af8c7acb2342","Due to multifunctional nature of sensor nodes, the energy consumption among nodes increases gradually. Based on this issue, in this attempt, a new enhanced algorithm EEA-LEACH is proposed which includes basic concepts of energy-efficient LEACH algorithm and trustworthy cluster-based routing algorithms for large and small in network scenario. Proposed algorithm is an optimal solution and satisfies the encountered constraints related to energy conservation and security. It also balances the overload on a cluster head in the network. Analytical and simulation results show that suggested protocol can minimize the energy consumption among sensor nodes and increase the performance of network during data. In this attempt, MATLAB simulator is used here to judge the performance of the proposed algorithm EEA-LEACH and its comparative simulation result analysis with existing LEACH protocol. © 2018, Springer Nature Singapore Pte Ltd.","Energy consumption; LEACH protocol; MATLAB simulator; Routing protocols; Security","Energy efficiency; Energy utilization; Image processing; Leaching; MATLAB; Optimization; Power management (telecommunication); Routing protocols; Sensor nodes; Wireless sensor networks; Cluster-based routing; Comparative simulation; Energy optimization; Leach algorithms; Leach protocols; Matlab simulators; Optimal solutions; Security; Clustering algorithms",2-s2.0-85031433003
"Tanaka S., Tierney K.","Solving real-world sized container pre-marshalling problems with an iterative deepening branch-and-bound algorithm",2018,"European Journal of Operational Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020478076&doi=10.1016%2fj.ejor.2017.05.046&partnerID=40&md5=1130d0767d199a9365e98d98200b1488","Container terminals around the world regularly re-sort the containers they store according to their retrieval times in a process called pre-marshalling, thus ensuring containers are efficiently transferred through the terminal. State-of-the-art algorithms struggle to find optimal solutions for real-world sized pre-marshalling problems. To this end, we introduce an improved exact algorithm using an iterative deepening branch and bound search, including a novel lower bound computation, a new branching heuristic, new dominance rule and a new greedy partial solution completion heuristic. Our approach finds optimal solutions for 161 more instances than the state-of-the-art algorithm on two well known, difficult pre-marshalling datasets, and solves all instances in three other datasets in just several seconds. Furthermore, we find optimal solutions for a majority of real-world sized instances, and feasible solutions with very low relaxation gaps on those instances where no optimal could be found. © 2017 Elsevier B.V.","Container pre-marshalling; OR in maritime industry; Terminal operations","Branch and bound method; Containers; Optimal systems; Optimization; Branch and bound search; Branch-and-bound algorithms; Container terminal; Feasible solution; Iterative deepening; Maritime industry; State-of-the-art algorithms; Terminal operation; Iterative methods",2-s2.0-85020478076
"Watanabe R., Duolikun D., Enokido T., Takizawa M.","An energy-efficient migration algorithm of virtual machines in server clusters",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026289423&doi=10.1007%2f978-3-319-61566-0_9&partnerID=40&md5=a71abf5384cd8631342f040948ec08ae","Virtual machines are now widely used to support applications with virtual service on computation resources. Furthermore, a virtual machine can migrate from a host server to a guest server while processes are being performed. In this paper, we propose a Simple Energy-aware Migration (SEAM) algorithm to migrate a virtual machine to another energy-efficient server in order to reduce the electric energy consumption. Here, the amount of computation to be performed by processes on a virtual machine is simply estimated only by using the number of the processes. We show the total electric energy consumption of the servers can be reduced in the SEAM algorithm compared with non-migration algorithms in the evaluation. © Springer International Publishing AG 2018.",,"Clustering algorithms; Energy efficiency; Energy utilization; Network security; Computation resources; Electric energy consumption; Energy aware; Energy efficient; Energy-efficient servers; Migration algorithms; Server cluster; Virtual service; Virtual machine",2-s2.0-85026289423
"Li C., Zhai R., Liu H., Yang Y., Wu H.","Optimization of a heliostat field layout using hybrid PSO-GA algorithm",2018,"Applied Thermal Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028801826&doi=10.1016%2fj.applthermaleng.2017.08.164&partnerID=40&md5=9ce4abf2e4e42ea509d921b192095f63","A mathematical model of the heliostat field and the PSO-GA algorithm are developed in Matlab to optimize a heliostat field and determine the highest potential daily energy collection (DEC). The heliostat field in Lhasa, China is analyzed as an example. The energy collected per unit cost (ECUC) is then calculated to evaluate the economic performance of the heliostat field. Furthermore, the effects of several important factors on the heliostat field are also explored. Results indicate that, after optimization, the DEC during the spring equinox, summer solstice, autumnal equinox, and winter solstice increase by approximately 1.1 × 105, 1.8 × 105, 1.2 × 105, and 0.9 × 105 MJ, respectively. Studies on the key parameters show that as the number of heliostats in the first row of the field (Nhel1) increases, the ECUC first increases to its maximum value and then decreases. Additionally, ECUC increases with tower height but decreases as the cost of the heliostat mirror collector increases. © 2017 Elsevier Ltd","Genetic algorithm; Heliostat field optimization; Particle swarm optimization algorithm; Solar tower power system","Genetic algorithms; Particle swarm optimization (PSO); Economic performance; Energy collection; GA algorithm; Heliostat field; Hybrid PSO; Particle swarm optimization algorithm; Solar towers; Summer solstice; Optimization",2-s2.0-85028801826
"Min S.N., Lee K.-S., Park S.J., Subramaniyam M., Kim D.J.","Development of stroke diagnosis algorithm through logistic regression analysis with national health insurance database",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023168858&doi=10.1007%2f978-3-319-60483-1_37&partnerID=40&md5=90164361db460b53a632277378fa1e06","This study purpose is to derive a model equation for developing a stroke pre-diagnosis algorithm with the potentially modifiable risk factors. In this study, logistic regression analysis technique was used for model derivation. It is one of the methods employed in the machine-learning field of statistics. Korea’s National Health Insurance Service (NHIS), one of the largest administrative health care databases around the world, has been used widely in academic studies. From the NHIS Corporation, 500,000 enrollees’ databases were collected. For the regression analysis, 367 stroke patients’ data were selected from the NHIS database. The control group consisted of 500 patients who were followed up for two consecutive years and who had no history of stroke. As a result, the separation accuracy with the modifiable risk factors was 64.7%. The results of this study are expected to be useful for the development of stroke pre-diagnosis algorithms. © Springer International Publishing AG 2018.","Logistic regression analysis; Modifiable risk factors; Stroke diagnosis","Biomedical equipment; Database systems; Diagnosis; Ergonomics; Health care; Health insurance; Human engineering; Insurance; Learning algorithms; Risk assessment; Control groups; Diagnosis algorithms; Logistic regression analysis; Model derivations; Model equations; Risk factors; Stroke patients; Regression analysis",2-s2.0-85023168858
"Wei F., Li S., Gao L.","A new evolutionary algorithm with deleting and jumping strategies for global optimization",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026778861&doi=10.1007%2f978-3-319-63856-0_32&partnerID=40&md5=c5df84b3276653f7167edd48dbd46ea0","For global optimization problems with a large number of local optimal solutions, evolutionary algorithms are efficient parallel algorithms, but they drops into local optimum easily, therefore their efficiency and effectiveness will be much reduced. In this paper, first, a new deleting strategy is proposed that can eliminate all local optimal solutions no better than this obtained local optimal solution. Second, when algorithm drops into a local optimal solution, a new jumping strategy is proposed that can jump out of the current local optimal solution and then find a better local optimal solution. Based on the above, a new algorithm called evolutionary algorithm with deleting and jumping strategies (briefly, EADJ) is proposed, and the algorithm convergence is proved theoretically. The simulations are made on 25 standard benchmark problems, and the results indicate the proposed deleting strategy and jumping strategy are effective; further, the proposed algorithm is compared with some well performed existing algorithms, and the results indicate the proposed algorithm EADJ is more effective and efficient. © Springer International Publishing AG 2018.","Deleting strategy; Evolutionary algorithm; Global optimization; Jumping strategy","Drops; Global optimization; Multimedia signal processing; Optimal systems; Optimization; Signal processing; Algorithm convergence; Bench-mark problems; Deleting strategy; Global optimization problems; Jumping strategy; Local optima; Local optimal solution; Evolutionary algorithms",2-s2.0-85026778861
"Fu X., Sun J., Zhang Q.","A Reference-Inspired Evolutionary Algorithm with Subregion Decomposition for Many-Objective Optimization",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029591912&doi=10.1007%2f978-3-319-66939-7_12&partnerID=40&md5=8b51bc5cd2eec93717b04cc6c83bda80","In this paper, we propose a reference-inspired multiobjective evolutionary algorithm for many-objective optimisation. The main idea is (1) to summarise information inspired by a set of randomly generated reference points in the objective space to strengthen the selection pressure towards the Pareto front; and (2) to decompose the objective space into subregions for diversity management and offspring recombination. We showed that the mutual relationship between the objective vectors and the reference points provides not only a fine selection pressure, but also a balanced convergence-diversity information. The decomposition of the objective space into subregions is able to preserve the Pareto front’s diversity. A restricted stable match strategy is proposed to choose appropriate parent solutions from solution sets constructed at the subregions for high-quality offspring generation. Controlled experiments conducted on a commonly-used benchmark test suite have shown the effectiveness and competitiveness of the proposed algorithm in comparison with several state-of-the-art many-objective evolutionary algorithms. © 2018, Springer International Publishing AG.","Domain decomposition; Many-objective optimization; Reference-inspired","Artificial intelligence; Benchmarking; Domain decomposition methods; Optimization; Controlled experiment; Diversity managements; Many-objective optimizations; Match strategies; Multi objective evolutionary algorithms; Objective optimisation; Reference-inspired; Selection pressures; Evolutionary algorithms",2-s2.0-85029591912
"Zhao Z., Liu Y., Li J., Wang J., Wang X.","A study of fuzzy clustering ensemble algorithm focusing on medical data analysis",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031414305&doi=10.1007%2f978-981-10-3187-8_37&partnerID=40&md5=80dc10bdbc9cbb0f201a903b6b80461d","Unitary clustering algorithm, not well adapted for fuzzy medical data sets, may result in low clustering accuracy and other problems. This paper investigates and compares the effects of various clustering methods to achieve improvements. First, unitary clustering algorithms such as k-means, FANNY, FCM, and etc. are achieved, then FCM algorithm was improved into CFCM algorithm, which increases the accuracy to a certain extent. Second, on this basis, in order to better adapt to the diversity of characteristics of fuzzy medical data, weighted co-association matrix is adopted to achieve integration, and consistency function is designed to present a fuzzy clustering ensemble algorithm. Finally, experiments shows that the Fuzzy Clustering Ensemble Algorithm can solve the problem of low accuracy in unitary clustering algorithm with higher stability, accuracy and robustness. © Springer Nature Singapore Pte Ltd. 2018.","Clustering ensemble; Fuzzy clustering; Fuzzy clustering ensemble algorithm; Medical data","Cluster analysis; Computation theory; Fuzzy clustering; Medical problems; Clustering accuracy; Clustering Ensemble; Clustering methods; Co-association matrix; FCM algorithm; Medical data; Medical data analysis; Medical data sets; Clustering algorithms",2-s2.0-85031414305
"Kaur R., Ghumman N.S.","Task-based load balancing algorithm by efficient utilization of VMS in cloud computing",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031416757&doi=10.1007%2f978-981-10-6620-7_7&partnerID=40&md5=7023065c8d6d6e594923fa76115f92f3","Although a lot of fundamental research is being carried out in a field of cloud computing, but still it is in infancy stage. In today’s era of computing, it is trending Internet technology, which suffers from various issues and challenges. This research addresses load balancing as one of the major challenges in cloud computing. The paper proposes a dynamic load balancing algorithm for cloud computing environment and compares with the existing algorithm. The results show that proposed algorithm outperforms existing algorithm in terms of average response time, turnaround time, and total cost. © 2018, Springer Nature Singapore Pte Ltd.","Challenges; Cloud computing; Datacenter broker (DCB); Load balancer; Load balancing; Utilized power","Cloud computing; Network function virtualization; Resource allocation; Challenges; Cloud computing environments; Datacenter; Dynamic load balancing algorithms; Issues and challenges; Load balancer; Load balancing algorithms; Utilized power; Big data",2-s2.0-85031416757
"Zhao Q., Wei C., Qi L., Yuan W.","Adaptive double-resampling particle filter algorithm for target tracking",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031405022&doi=10.1007%2f978-981-10-3187-8_73&partnerID=40&md5=4d58f4ecfd8cd271e5e345ced6de0e33","Based on the traditional particle degradation and depleted of particle filter and the number of particle set, which cannot be adaptive to change brought by the filtering accuracy and convergence rate of decline. A new methods of Innovation and resampling particle filter was applied to the, paper. This approach, can solve, the problems mentioned, above. The, algorithm first uses the observation information to establish the particle distribution program of the resampling. Then, to conduct a, resampling, on the basis of the initial resampling. The second resampling used the particle cross aggregation algorithm. This can improve, efficiency of, the, particles,, and avoid, the increase of the calculation when using too many particles. The simulation result, based on the DR/GPS shows that, compared, with the traditional, PF algorithm,, the algorithm can improve the accuracy and stability of the filter. © Springer Nature Singapore Pte Ltd. 2018.","Adaptive; Double-resampling; Innovation; Particle filter; Target tracking","Adaptive filtering; Bandpass filters; Clutter (information theory); Computation theory; Innovation; Monte Carlo methods; Adaptive; Aggregation algorithms; Filtering accuracies; Observation information; Particle distributions; Particle filter; Particle filter algorithms; Resampling; Target tracking",2-s2.0-85031405022
"Inenaga S., Hyyrö H.","A hardness result and new algorithm for the longest common palindromic subsequence problem",2018,"Information Processing Letters",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029384363&doi=10.1016%2fj.ipl.2017.08.006&partnerID=40&md5=3380cca24f9e9ee5386a56a3f4516d61","The 2-LCPS problem, first introduced by Chowdhury et al. (2014) [17], asks one to compute (the length of) a longest common palindromic subsequence between two given strings A and B. We show that the 2-LCPS problem is at least as hard as the well-studied longest common subsequence problem for four strings. Then, we present a new algorithm which solves the 2-LCPS problem in O(σM2+n) time, where n denotes the length of A and B, M denotes the number of matching positions between A and B, and σ denotes the number of distinct characters occurring in both A and B. Our new algorithm is faster than Chowdhury et al.'s sparse algorithm when σ=o(log2⁡nlog⁡log⁡n). © 2017 Elsevier B.V.","Algorithms; Longest common subsequences; Nesting rectangles; Palindromic subsequences; String processing","Algorithms; Data transfer; Hardness result; Longest common subsequence problem; Longest common subsequences; Nesting rectangles; Palindromic; Sparse algorithms; String processing; Object recognition",2-s2.0-85029384363
"Liu W., Liu Y.","Fault diagnosis algorithm for wireless sensor-based on fault tolerant topology",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028426022&doi=10.1007%2f978-3-319-60744-3_53&partnerID=40&md5=ff302be037efba1f3c5dbbaec6db727d","Based on the principle that the wireless sensors in a wireless network can relocate its loads to adjacent nodes when there are single node failures, this thesis proposed a load redistribution model in fault and analyses chain fault diagnosis algorithm of adjacent nodes in order to study the relationships between the scale of parameters and the cascading failure in the sensor network load. By the simulation test, it showed that this algorithm can effectively reduce the chain load effect caused by overload which works well in the wireless network. The problem of cascading failures caused by the random node failure, in order to reduce cascading failures caused by the wireless sensor network as much as possible damage to the chain fault diagnosis algorithm is proposed for wireless sensor network scale-free fault-tolerant topology. The algorithm is based on a single node failure load is redistributed to adjacent nodes, a cascading failure under the load redistribution model, cascading failure scale arising from analysis of the single node failures. The relationship between the parameters of load chain fault diagnosis algorithm using the neighboring nodes to the sensor network research and cascading failure scale, node loss as much as possible to reduce cascading failures caused. The simulation results show that the algorithm is effective inhibited by over load chain loading effect caused by the great, played a good effect in reducing network losses. It is a sharp increase in recent years, the number of users and applications, some of the nodes in the Internet in the high load working condition. If these nodes attack, such as virus attacks will lead to the overload even cannot work normally, forcing data packets to the other routers routing, which can cause overload successively, produce cascading failure (cascading failures), large-scale cascading failure occurs, often with strong destruction. © 2018, Springer International Publishing AG.","Cascading failure; Fault tolerant topology; Wireless network sensors","Chains; Failure analysis; Fault detection; Fault tolerance; Intelligent systems; Learning algorithms; Parameter estimation; Real time systems; Topology; Viruses; Wireless networks; Wireless sensor networks; Cascading failures; Diagnosis algorithms; Fault-tolerant; Load redistribution; Neighboring nodes; Simulation tests; Single node failure; Wireless network sensors; Sensor nodes",2-s2.0-85028426022
"Krzeszowski T., Wiktorowicz K., Przednowek K.","Comparison of selected fuzzy PSO algorithms",2018,"Studies in Computational Intelligence",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022334294&doi=10.1007%2f978-3-319-59861-1_7&partnerID=40&md5=fe3b7fceca3336cd7ca6c451036e402c","This paper presents a comparison of selected fuzzy particle swarm optimization algorithms. Two non-fuzzy and four fuzzy algorithms are considered. The Takagi-Sugeno fuzzy system is used to change the parameters of these algorithms. A modified fuzzy particle swarm optimization method is proposed in which each of the particles has its own inertia weight and coefficients of the cognitive and social components. The evaluation is based on the common nonlinear benchmark functions frequently used for testing optimization methods. The ratings of the algorithms are assigned on the basis of the mean of the objective function final value. © Springer International Publishing AG 2018.",,,2-s2.0-85022334294
"Bustince H., Minárová M., Fernandez J., Sesma-Sara M., Marco-Detchart C., Ruiz-Aranguren J.","A generalization of the gravitational search algorithm",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020000644&doi=10.1007%2f978-3-319-59306-7_17&partnerID=40&md5=b8b59d14adafb2a0867b1a13b1439e97","In this work we propose a generalization of the gravitational search algorithm where the product in the expression of the gravitational attraction force is replaced by more general functions. We study some conditions which ensure convergence of our proposal and we show that we recover a wide class of aggregation functions to replace the product. © Springer International Publishing AG 2018.",,"Mathematical operators; Aggregation functions; General functions; Gravitational attraction; Gravitational search algorithms; Learning algorithms",2-s2.0-85020000644
"Xi D., Liu M., Teng Y., Song M.","Radial velocity based CoMP handover algorithm in LTE-A system",2018,"Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031276726&doi=10.1007%2f978-3-319-66628-0_38&partnerID=40&md5=ec85774c2312a8a76ecfbbad0f933217","In the Long Term Evolution-Advanced (LTE-A) systems, coordinated Multi-Point (CoMP) transmission/reception technology is widely used to improve cell-edge throughput and system throughput. With the introduction of CoMP technology, handover scenes have changed and traditional handover algorithms are no longer able to meet the requirements of current handover scenes. Different from traditional CoMP handover trigger mechanism, we adopt the event based handover trigger mechanism to update the CoMP coordinating set (CCS) and transmission points (CTP). Furthermore, under the constraints of the reference signal received power (RSRP) and the load of the base stations (BSs), we propose the cycle selection algorithm to choose CCS and CTP based on the radial velocity and SINR. Simulation results show that the proposed handover algorithm can effectively reduce the total number of handover, system delay and signaling overhead in the practical CoMP system. © 2018, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.","CoMP; Cycle selection; Event trigger mechanism; Handover algorithm","Spurious signal noise; Standards; Cell-edge throughputs; CoMP; Coordinated multi point (CoMP); Cycle selection; Event trigger; Handover algorithms; Selection algorithm; Transmission points; Long Term Evolution (LTE)",2-s2.0-85031276726
"Li S., Fang H., Liu X.","Parameter optimization of support vector regression based on sine cosine algorithm",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028537052&doi=10.1016%2fj.eswa.2017.08.038&partnerID=40&md5=bdf26e05374ec3d94c230bd7f1b5262a","Time series prediction is an important part of data-driven based prognostics which are mainly based on the massive sensory data with less requirement of knowing inherent system failure mechanisms. Support Vector Regression (SVR) has achieved good performance in forecasting problems of small samples and high dimensions. However, the SVR parameters have a significant influence on forecasting performance of SVR. In our current work, a novel SCA-SVR model has been presented where sine cosine algorithm (SCA) is used to select the penalty and kernel parameters in SVR, so that the generalization performance on unknown data can be improved. To validate the proposed model, the results of the SCA-SVR algorithm were compared with those of grid search and some other meta-heuristics optimization algorithms on common used benchmark datasets. The experimental results proved that the proposed model is capable to find the optimal values of the SVR parameters and can yield promising results. © 2017 Elsevier Ltd","Parameter optimization; Sine cosine algorithm; Support vector regression; Time series prediction","Forecasting; Parameter estimation; Regression analysis; Systems engineering; Time series; Forecasting performance; Forecasting problems; Generalization performance; Optimization algorithms; Parameter optimization; Sine-cosine algorithm; Support vector regression (SVR); Time series prediction; Optimization",2-s2.0-85028537052
"Yoomak S., Pothisarn C., Jettanasen C., Ngaopitakkul A.","Discrete wavelet transform and fuzzy logic algorithm for classification of fault type in underground cable",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029426208&doi=10.1007%2f978-3-319-66827-7_52&partnerID=40&md5=79951bfba00c20befe7555509177cec6","This paper proposes the combination of discrete wavelet transform (DWT) and fuzzy logic to classify the fault type in underground distribution cable. The DWT is employed to decompose high frequency component from fault signal with the mother wavelet daubechies4 (db4). The maximum coefficients detail of DWT from phase A, B, C and zero sequence for post-fault current waveforms are considered as an input pattern of decision algorithm. Triangle-shaped S-shaped and Z-shaped membership function with maximum, medium, minimum, and zero are used to create a function for the input variable. Output variable of fuzzy are designated as values range 1 to 10 which corresponding with type of fault. The obtained average accuracy results shown that the proposed decision algorithm is able to classify the fault type with satisfactory accuracy. © 2018, Springer International Publishing AG.","Fault type; Fuzzy logic; Underground distribution system","Cables; Computer circuits; Discrete wavelet transforms; Fuzzy sets; Membership functions; Pattern matching; Underground electric power distribution; Wavelet transforms; Decision algorithms; Fault current waveforms; Fault types; Fuzzy logic algorithms; High frequency components; Output variables; Underground distribution; Underground distribution system; Fuzzy logic",2-s2.0-85029426208
"Guo P., Xue Z.","Real-time fault-tolerant scheduling algorithm in virtualized clouds",2018,"Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031288036&doi=10.1007%2f978-3-319-66628-0_42&partnerID=40&md5=b03b1ac8f4896a8dfee286a89a10d3fd","The past decade has witnessed the rapid development of cloud computing. Virtualization, which is the fundamental technique in providing Infrastructure as a Service (IaaS), has led to an explosive growth of the cloud computing industry. Fault-tolerance is a significant requirement of cloud computing due to the Service Level Agreements (SLA). In order to achieve high reliability and resilience of real-time systems in virtualized clouds, a Virtualization-based Fault-Tolerant Scheduling (VFTS) algorithm is proposed. In this paper, fault tolerance is implemented by using primary-backup approach. VFTS is designed for periodic and preemptive tasks in homogeneous environment. Simulation results demonstrate an impressing saving of processing resources compared with those needed by the dual-system hot backup approach, which proves the feasibility and effectiveness of the proposed VFTS algorithm. © 2018, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.","Fault tolerance; Real-time system; Scheduling; Virtualized cloud","Cloud computing; Fault tolerance; Infrastructure as a service (IaaS); Interactive computer systems; Scheduling; Scheduling algorithms; Virtual reality; Virtualization; Dual system; Explosive growth; Fault tolerant scheduling; Fault-tolerant scheduling algorithms; High reliability; Primary-backup; Processing resources; Service Level Agreements; Real time systems",2-s2.0-85031288036
"Scitovski S.","A density-based clustering algorithm for earthquake zoning",2018,"Computers and Geosciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028773451&doi=10.1016%2fj.cageo.2017.08.014&partnerID=40&md5=54b29c78cb184b012b385258d980f5cb","A possibility of applying the density-based clustering algorithm Rough-DBSCAN for earthquake zoning is considered in the paper. By using density-based clustering for earthquake zoning it is possible to recognize nonconvex shapes, what gives much more realistic results. Special attention is thereby paid to the problem of determining the corresponding value of the parameter ɛ in the algorithm. The size of the parameter ɛ significantly influences the recognizing number and configuration of earthquake zones. A method for selecting the parameter ɛ in the case of big data is also proposed. The method is applied to the problem of earthquake data zoning in a wider area of the Republic of Croatia. © 2017 Elsevier Ltd","Big data; Density-based clustering; Earthquake zoning; Rough-DBSCAN","Big data; Earthquakes; Geophysics; Zoning; Croatia; Density-based Clustering; Density-based clustering algorithms; Earthquake data; Earthquake zones; Earthquake zoning; Non-convex shapes; Rough-DBSCAN; Clustering algorithms",2-s2.0-85028773451
"Górnicka D., Markowski M., Burduk A.","Optimization of production organization in a packaging company by ant colony algorithm",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028597046&doi=10.1007%2f978-3-319-64465-3_33&partnerID=40&md5=77ac3550deb3daef1719eb788c10cd79","The paper deals with the production scheduling optimization problem. Real production environment have been considered - a company that produces different types of products; and an optimization method based on the intelligent ant-colony optimization (ACO) algorithm have been proposed. In the paper the original problem formulation for the considered production scheme is shown, also the details of ACO meta-heuristic are proposed and presented. © Springer International Publishing AG 2018.","Ant Colony Optimization (ACO); Intelligent optimization methods; Material flow; Meta-heuristics; Organization of production","Artificial intelligence; Heuristic methods; Intelligent systems; Maintenance; Optimization; Production; Production control; Ant colony algorithms; Ant Colony Optimization (ACO); Ant Colony Optimization algorithms; Intelligent optimization method; Material Flow; Meta heuristics; Production environments; Production organizations; Ant colony optimization",2-s2.0-85028597046
"Mostafa A., Houssein E.H., Houseni M., Hassanien A.E., Hefny H.","Evaluating swarm optimization algorithms for segmentation of liver images",2018,"Studies in Computational Intelligence",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032005839&doi=10.1007%2f978-3-319-63754-9_3&partnerID=40&md5=bcf6c529d0feb05c88c865c743b187d5","There is a remarkable increase in the popularity of swarms inspired algorithms in the last decade. It offers a kind of flexibility and efficiency in their applications in different fields. These algorithms are inspired by the behaviour of various swarms as birds, fish and animals. This chapter presents an overview of some algorithms as grey wolf optimization (GWO), artificial bee colony (ABC) and antlion optimization (ALO). It proposed swarm optimization approaches for liver segmentation based on these algorithms in CT and MRI images. The experimental results of these algorithms show that they are powerful and can get remarkable results when applied to segment liver medical images. It is evidently proved from the experimental results that ALO, GWO and ABC have obtained 94.49%, 94.08% and 93.73%, respectively, in terms of overall accuracy using similarity index measure. © Springer International Publishing AG 2018.","Antlion and segmentation; Artificial bee colony; Grey wolf",,2-s2.0-85032005839
"Nalepa J., Blocho M.","Verification of correctness of parallel algorithms in practice",2018,"Studies in Computational Intelligence",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022334358&doi=10.1007%2f978-3-319-59861-1_9&partnerID=40&md5=3d9b697ac695d1101aa91b70758a58da","Verification of the correctness of parallel algorithms is often omitted in the works from the parallel computation field. In this paper, we discuss in detail how to show that a parallel algorithm is correct. This process involves proving its safety and liveness. In our case study, we prove the correctness of our two parallel algorithms for the NP-hard pickup and delivery problem with time windows. Both algorithms (for minimizing the number of routes and the travel distance) were already shown to be extremely efficient in practice—the implementations were thoroughly examined using the famous Li and Lim’s benchmark dataset. © Springer International Publishing AG 2018.",,,2-s2.0-85022334358
"Muneeswaran V., Pallikonda Rajasekaran M.","Beltrami-regularized denoising filter based on tree seed optimization algorithm: An ultrasound image application",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028380601&doi=10.1007%2f978-3-319-63673-3_54&partnerID=40&md5=154cc1ce1e48c71c55218298ab145207","The dominant degrading factor of quality in ultrasound images is mainly due to the occurrence of speckle noise that in turn leads to false ameliorative decisions, restricts auto diagnosis and telemedicine practices. In medical image analysis speckle reduction is contemplated to be the pre-processing task that sustains decisive information and exclude speckle noise. Meta-heuristics optimization algorithm were used now a days for speckle reduction problems. Our contribution in this paper analyses the use of optimization technique in determining the best noise removing filter coefficients that removes the speckle content contributively. The proposed method comprises the use of Finite Impulse Response filter receiving the filter coefficients from Tree Seed optimization algorithm. Evaluation of noise removal with standard metrics such as Peak Signal to Noise Ratio, Correlation coefficient and Structural Similarity Index shows that the proposed method gives optimal speckle reduction score when compared with conventional filters and its superiority in despeckling medical ultrasound images. Assessment of the proposed methodology with advanced evaluation metrics ensures the ability of it in terms of preserving edges and textural features. © 2018, Springer International Publishing AG.","Finite impulse response filter; Mean square error; Speckle noise; Structural similarity index; Tree seed optimization; Ultrasound image","Bandpass filters; Diagnosis; Digital signal processors; FIR filters; Forestry; Image denoising; Impulse response; Intelligent systems; Mean square error; Medical imaging; Signal to noise ratio; Speckle; Telemedicine; Trees (mathematics); Ultrasonic applications; Medical ultrasound images; Optimization algorithms; Optimization techniques; Peak signal to noise ratio; Seed optimization algorithms; Speckle noise; Structural similarity indices; Ultrasound images; Optimization",2-s2.0-85028380601
"Claypo N., Hanskunatai A., Jaiyen S.","A new streaming learning for stream chunk data classification based on incremental learning and adaptive boosting algorithm",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022179182&doi=10.1007%2f978-3-319-60663-7_15&partnerID=40&md5=5287ad2927f6f65a2bb1c1684b64b284","Currently, stream data classification is a challenge task to discover new useful knowledge from massive and dynamic data in big data era. This paper proposes a streaming learning method based on the incremental learning using a new adaptive boosting algorithm for stream data. The proposed adaptive boosting consists of a new method for updating distribution weight and the new weight voting. This learning method concentrates on learning from sequential chunks of data stream. The distribution weight updating method uses error of previous hypothesis to update the weight. The learning method uses only one data chunk to create a new hypothesis at a time and after learning, the learned data chunk can be thrown away and can learn the new data chunk without using the previous learned data. The experimental results show that the accuracy of the proposed method is higher than other methods in all datasets. © Springer International Publishing AG 2018.","Adaptive boosting; Classification; Incremental learning; Stream data","Adaptive boosting; Big data; Classification (of information); Data mining; Learning algorithms; Learning systems; Adaptive boosting algorithms; Data classification; Dynamic data; Incremental learning; Learning methods; Stream data; Stream data classifications; Updating methods; Education",2-s2.0-85022179182
"Alam T., Raza Z.","Quantum genetic algorithm based scheduler for batch of precedence constrained jobs on heterogeneous computing systems",2018,"Journal of Systems and Software",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032223281&doi=10.1016%2fj.jss.2017.10.001&partnerID=40&md5=d60b8730a906bec55660124367e26d3f","Distributed systems are efficient means of realizing High-Performance Computing (HPC). They are used in meeting the demand of executing large-scale high-performance computational jobs. Scheduling the tasks on such computational resources is one of the prime concerns in the heterogeneous distributed systems. Scheduling requires optimizing either single objective or multiple objectives. Load Imbalance (LIB) and Load balancing Cost Ratio (LCR) are two such objectives. LIB and LCR are used in deciding the distribution of load over available resources for utilization and the computational cost respectively. Scheduling jobs with precedence constraints are NP-complete in nature. Scheduling requires either heuristic or metaheuristic approach for sub-optimal but acceptable solutions. Quantum computing is one such metaheuristic approach. It has proven to be promising in addressing the multi-objective scheduling problems with an effective exploration of the search space. This work proposes a dual-objective Quantum-inspired Genetic Algorithm based Load Balancing Strategy (QGLBS) for workflow application with the objective of optimizing both LIB and LCR. The DAG representation of the batch of jobs helps in effective exploitation of the parallelism available at the job level as well as the sub-job level with the modules at the same level of the batch executing at the same time. The strategy ensures that the communication cost and the critical path are considered in making scheduling decisions. QGLBS exploits the features of Quantum Computing and Genetic Algorithm to establish the Pareto fronts using non-dominated sorting based on NSGA-II. Hypervolume measures are used to compare the results of the quality assessment of Pareto fronts. Simulation study on Gridsim ensures that the QGLBS approach works effectively for real life scenario with various workflow applications. © 2017 Elsevier Inc.","Batch scheduling; Heterogeneous distributed systems; Load Balancing; Load balancing cost ratio; Load Imbalance; Workflow application","Costs; Distributed computer systems; Fading (radio); Genetic algorithms; Optimization; Quantum computers; Resource allocation; Scheduling; Scheduling algorithms; Batch-scheduling; Cost ratio; Heterogeneous distributed systems; Load imbalance; Workflow applications; Job shop scheduling",2-s2.0-85032223281
"Yin J., Zhang Y., Gao L.","Accelerating distributed Expectation–Maximization algorithms with frequent updates",2018,"Journal of Parallel and Distributed Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027418885&doi=10.1016%2fj.jpdc.2017.07.005&partnerID=40&md5=45328eea307f8889785ff60f6b0e4b14","Expectation–Maximization (EM) is a popular approach for parameter estimation in many applications, such as image understanding, document classification, and genome data analysis. Despite the popularity of EM algorithms, it is challenging to efficiently implement these algorithms in a distributed environment for handling massive data sets. In particular, many EM algorithms that frequently update the parameters have been shown to be much more efficient than their concurrent counterparts. Accordingly, we propose two approaches to parallelize such EM algorithms in a distributed environment so as to scale to massive data sets. We prove that both approaches maintain the convergence properties of the EM algorithms. Based on the approaches, we design and implement a distributed framework, FreEM, to support the implementation of frequent updates for the EM algorithms. We show its efficiency through two categories of EM applications, clustering and topic modeling. These applications include k-means clustering, fuzzy c-means clustering, parameter estimation for the Gaussian Mixture Model, and variational inference for Latent Dirichlet Allocation. We extensively evaluate our framework on both a cluster of local machines and the Amazon EC2 cloud. Our evaluation shows that the EM algorithms with frequent updates implemented on FreEM can converge much faster than those implementations with traditional concurrent updates. © 2017 Elsevier Inc.","Clustering; Concurrent updates; Distributed framework; Expectation–Maximization; Frequent updates; Topic modeling","Data handling; Gaussian distribution; Information retrieval systems; Metadata; Statistics; Clustering; Concurrent update; Distributed framework; Frequent updates; Topic Modeling; Parameter estimation",2-s2.0-85027418885
"Chinna Babu J., Chinnapu Reddy C., Giri Prasad M.N.","Generation and decoding of non-binary LDPC codes using MSA decoding algorithm",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029792850&doi=10.1007%2f978-981-10-4280-5_61&partnerID=40&md5=079c257b3215ab8e95e5ad37179542f0","The latest advancements in low density parity check (LDPC) codes have resulted in reducing the decoding complexity. Hence these codes have excelled over BCH and turbo codes in terms of performance in the higher code rate, hence these codes are the trending topic in coding theory. Construction of LDPC codes is being elaborated in this proposed paper which further helps to study encoding and decoding of these NB-low density parity check codes. In the proposed design architecture, we have considered the Min-Sum Decoding Algorithm (MSA) employed here utilizes reliability estimation to improve error performance and it has advantages over bit flipping (BF) algorithms This algorithm can be improved with still more security level by having a trade-off between performance and data transmission. It can also enhanced by implementing it in real-time applications for data decoding and correction, for smaller size datum and these codes are used for medical and signal processing applications. These proposed LDPC codes are also used in the generation of bar codes, which are used in real time applications. © Springer Nature Singapore Pte Ltd. 2018.","BCH codes; Decoding algorithm; LDPC codes; Shannon limit; Turbo codes","Bar codes; Computer programming; Decoding; Economic and social effects; Forward error correction; Information theory; Satellite communication systems; Signal encoding; Signal processing; Turbo codes; BCH code; Bit flipping algorithms; Decoding algorithm; LDPC codes; Low-density parity-check (LDPC) codes; Min-sum decoding algorithm; Shannon limit; Signal processing applications; Codes (symbols)",2-s2.0-85029792850
"Su Y., Zhang Q., Xu X., Gao Z., Wu S.","Interpolation bias for the inverse compositional Gauss–Newton algorithm in digital image correlation",2018,"Optics and Lasers in Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029489905&doi=10.1016%2fj.optlaseng.2017.09.013&partnerID=40&md5=12f0d06d6485c9371a6aea546ac1ce5c","It is believed that the classic forward additive Newton–Raphson (FA-NR) algorithm and the recently introduced inverse compositional Gauss–Newton (IC-GN) algorithm give rise to roughly equal interpolation bias. Questioning the correctness of this statement, this paper presents a thorough analysis of interpolation bias for the IC-GN algorithm. A theoretical model is built to analytically characterize the dependence of interpolation bias upon speckle image, target image interpolation, and reference image gradient estimation. The interpolation biases of the FA-NR algorithm and the IC-GN algorithm can be significantly different, whose relative difference can exceed 80%. For the IC-GN algorithm, the gradient estimator can strongly affect the interpolation bias; the relative difference can reach 178%. Since the mean bias errors are insensitive to image noise, the theoretical model proposed remains valid in the presence of noise. To provide more implementation details, source codes are uploaded as a supplement. © 2017 Elsevier Ltd","Digital image correlation; Fourier analysis; Gradient estimator; Interpolation bias; Inverse compositional Gauss–Newton algorithm","Fourier analysis; Gaussian distribution; Image analysis; Strain measurement; Digital image correlations; Gn algorithms; Gradient estimator; Mean bias errors; Newton algorithm; Reference image; Speckle images; Theoretical modeling; Interpolation",2-s2.0-85029489905
"Xing B., Marwala T.","Introduction to intelligent search algorithms",2018,"Studies in Systems, Decision and Control",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029227672&doi=10.1007%2f978-3-319-67480-3_3&partnerID=40&md5=eedc0e12967a0d4a51421a0936e835a6","This chapter introduces some general knowledge relative to the broad area of intelligent search algorithms. The desirable merits of these clever algorithms and their remarkable achievements in many fields have inspired researchers (from a variety of disciplines) to continuously develop their ameliorated versions. Some historical information regarding search and artificial intelligence are briefed in Sect. 3.1. Then, the relevant developed-, developing-, and emerging-intelligent search algorithms are presented in Sect. 3.2. Section 3.3 summarises this chapter. © Springer International Publishing AG 2018.",,,2-s2.0-85029227672
"Khan R., Amjad M., Srivastava A.K.","Optimization of automatic test case generation with cuckoo search and genetic algorithm approaches",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031426943&doi=10.1007%2f978-981-10-3773-3_40&partnerID=40&md5=0dd54299b0c9f6328f937e57ca37e0ad","Automatic test case generation is an optimization problem in software testing process. With the use of genetic algorithm we can generate the test cases automatically. Genetic algorithm alone does not give 100% accurate optimized test cases. Hence merging of genetic algorithm with Cuckoo search optimization technique produces better optimized test cases. The main aim of this paper is to customize the cost and time for the Testing process after the generation of test cases automatically. The two optimization techniques namely Cuckoo Search and genetic algorithm produce better result as compared to single one. © Springer Nature Singapore Pte Ltd. 2018.","Cuckoo search optimization (CSO); Genetic algorithm; Software testing; Test cases","Genetic algorithms; Software testing; Automatic test-case generations; Cuckoo searches; Genetic algorithm approach; Optimization problems; Optimization techniques; Test case; Testing process; Optimization",2-s2.0-85031426943
"Boccia M., Crainic T.G., Sforza A., Sterle C.","Multi-commodity location-routing: Flow intercepting formulation and branch-and-cut algorithm",2018,"Computers and Operations Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028466180&doi=10.1016%2fj.cor.2017.08.013&partnerID=40&md5=41f27c001117d8f82cf5f53fd692d36f","Research on the location-routing problem (LRP) is very active, producing a good number of effective exact and approximated solution approaches. It is noteworthy that most of the contributions present in the literature address the single-commodity LRP, whereas the multi-commodity case has been scarcely investigated. Yet, this issue assumes an important role in many LRP applications, particularly in the context of designing single-tier freight distribution City Logistics systems. To fill this gap, we define a new multi-commodity LRP, proposing an original integer linear programming model for it. The proposed formulation takes into account the multi-commodity feature of the problem, modeling the strategic location and the tactical routing decisions using the flow intercepting approach. We therefore name this problem the flow intercepting facility location-routing problem. It is solved by a branch-and-cut algorithm which exploits cuts derived and adapted from literature. The proposed method is successfully experienced and validated on test instances reproducing different network topologies and problem settings. © 2017 Elsevier Ltd","Branch-and-cut; City logistics; Flow intercepting facility location; Multi-commodity location-routing","Location; Logistics; Routing algorithms; Approximated solutions; Branch and cut; Branch-and-cut algorithms; City logistics; Facility locations; Integer linear programming models; Location routing problem; Location-routing; Integer programming",2-s2.0-85028466180
"Awal G.K., Bharadwaj K.K.","Mining set of influencers in signed social networks with maximal collective influential power: A genetic algorithm approach",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028389867&doi=10.1007%2f978-3-319-63645-0_29&partnerID=40&md5=78f02c2585b81a1b4c89f55ae974753b","The ubiquitous growth of social networks opens a new line of research for developing algorithms and models for influence mining. Determining influential people in the network which consists of both positive and negative links between users is a challenging task. It becomes critical for businesses with fixed budget constraints to identify a group of influential people whose views will influence others’ behaviors the most. In this paper, we propose a model that aims to discover a set of influencers in signed social networks with maximal Collective Influential Power (CIP). We first construct an “influence network” between users and compute the influence strength between each pair of users by utilizing both the explicit trust-distrust information provided by users and the information derived from interactions between them. We then employ an elitist genetic algorithm that discovers a set of influencers with high influence spread as well as maximal enhanced joint influential power over the other users in the network. Experiments are performed on Epinions, a real-world dataset, and the results obtained are quite promising and clearly demonstrate the effectiveness of our proposed model. © Springer International Publishing AG 2018.","Collective intelligence; Genetic algorithm; Influence mining; Signed social networks; Trust-distrust","Budget control; Genetic algorithms; Intelligent systems; Collective intelligences; Explicit trusts; Fixed budget; Genetic algorithm approach; Influence networks; Real-world; Trust-distrust; Economic and social effects",2-s2.0-85028389867
"Tyagi N., Gupta S.K.","Web structure mining algorithms: A survey",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031415327&doi=10.1007%2f978-981-10-6620-7_30&partnerID=40&md5=90c0106983c548fa7c46806bf0909001","World Wide Web (WWW) is a massive collection of information and due to its rapid growing size, information retrieval becomes more challenging task to the user. Web mining techniques such as web content mining, web usage mining, and web structure mining are used to make the information retrieval more efficient. In this paper, study is focused on the web structure mining and different link analysis algorithms. Further, a comparative review of these algorithms is given. © 2018, Springer Nature Singapore Pte Ltd.","Information retrieval; Link analysis; Web content mining; Web mining; Web structure mining; Web usage mining","Big data; Information retrieval; Websites; Link analysis; Web content mining; Web Mining; Web structure mining; Web usage mining; Data mining",2-s2.0-85031415327
"Mozo A., López-Presa J.L., Fernández Anta A.","A distributed and quiescent max-min fair algorithm for network congestion control",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029845189&doi=10.1016%2fj.eswa.2017.09.015&partnerID=40&md5=dddff5b5201c0451b2c70fd9a54b4cfd","Given the higher demands in network bandwidth and speed that the Internet will have to meet in the near future, it is crucial to research and design intelligent and proactive congestion control and avoidance mechanisms able to anticipate decisions before the congestion problems appear. Nowadays, congestion control mechanisms in the Internet are based on TCP, a transport protocol that is totally reactive and cannot adapt to network variability because its convergence speed to the optimal values is slow. In this context, we propose to investigate new congestion control mechanisms that (a) explicitly compute the optimal sessions’ sending rates independently of congestion signals (i.e., proactive mechanisms) and (b) take anticipatory decisions (e.g., using forecasting or prediction techniques) in order to avoid the appearance of congestion problems. In this paper we present B-Neck, a distributed optimization algorithm that can be used as the basic building block for the new generation of proactive and anticipatory congestion control protocols. B-Neck computes proactively the optimal sessions’ sending rates independently of congestion signals. B-Neck applies max-min fairness as optimization criterion, since it is very often used in traffic engineering as a way of fairly distributing a network capacity among a set of sessions. B-Neck iterates rapidly until converging to the optimal solution and is also quiescent. The fact that B-Neck is quiescent means that it stops creating traffic when it has converged to the max-min rates, as long as there are no changes in the sessions. B-Neck reacts to variations in the environment, and so, changes in the sessions (e.g., arrivals and departures) reactivate the algorithm, and eventually the new sending rates are found and notified. To the best of our knowledge, B-Neck is the first distributed algorithm that maintains the computed max-min fair rates without the need of continuous traffic injection, which can be advantageous, e.g., in energy efficiency scenarios. This paper proposes as novelty two theoretical contributions jointly with an in-depth experimental evaluation of the B-Neck optimization algorithm. First, it is formally proven that B-Neck is correct, and second, an upper bound for its convergence time is obtained. In addition, extensive simulations were conducted to validate the theoretical results and compare B-Neck with the most representative competitors. These experiments show that B-Neck behaves nicely in the presence of sessions arriving and departing, and its convergence time is in the same range as that of the fastest (non-quiescent) distributed max-min fair algorithms. These properties encourage to utilize B-Neck as the basic building block of proactive and anticipatory congestion control protocols. © 2017 Elsevier Ltd","Distributed optimization; Max-min fair; Network congestion control; Proactive algorithm; Quiescent algorithm","Energy efficiency; Optimal systems; Telecommunication traffic; Traffic congestion; Congestion control mechanism; Congestion control protocols; Distributed optimization; Experimental evaluation; Extensive simulations; Max-min; Network congestion control; Optimization algorithms; Optimization",2-s2.0-85029845189
"Mao W., Zhao Y., Mao Y.","Optimization of the water supply system based on an adaptive particle swarm algorithm",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030836194&doi=10.1007%2f978-981-10-6496-8_44&partnerID=40&md5=45e758919ff53c63b5dcb40847282323","The optimization of water supply pipe networks based on traditional particle swarm algorithm is easy to trap into local optimum and slow to converge the optimum. In this paper, an adaptive particle swarm optimization algorithm with variation (VAPSO) is proposed. The inertia weight is dynamically adjusted by particle swarm complexity, and the variation threshold is dynamically adjusted by single particle complexity. The experiment of water supply system with VAPSO shows that the proposed algorithm has faster convergence speed and a significant advantage in optimizing performance. It can reduce the network diameter cost effectively. © 2018, Springer Nature Singapore Pte Ltd.","Particle swarm complexity; Single particle complexity; VAPSO; Water supply pipe networks","Complex networks; Intelligent systems; Optimization; Particle swarm optimization (PSO); Water supply systems; Adaptive particle swarm algorithms; Adaptive particle swarm optimization algorithm; Optimizing performance; Particle swarm; Particle swarm algorithm; Pipe networks; Single particle; VAPSO; Water supply",2-s2.0-85030836194
"Romero-Zaliz R., Reinoso-Gordo J.F.","An updated review on watershed algorithms",2018,"Studies in Fuzziness and Soft Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024495584&doi=10.1007%2f978-3-319-62359-7_12&partnerID=40&md5=3494228ff544da4e6fc977fa558c2eb5","Watershed identification is one of the main areas of study in the field of topography. It is critical in countless applications including sustainability and flood risk evaluation. Beyond its original conception, the watershed algorithm has proved to be a very useful and powerful tool in many different applications beside topography, such as image segmentation. Although there are a few publications reviewing the state-of-the-art of watershed algorithms, they are now outdated. In this chapter we review the most important works done on watershed algorithms, including the problem over-segmentation and parallel approaches. Open problems and future work are also investigated. © 2018, Springer International Publishing AG.",,,2-s2.0-85024495584
"Velampalli S., Jonnalagedda V.R.M.","Frequent subgraph mining algorithms: Framework, classification, analysis, comparisons",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021236825&doi=10.1007%2f978-981-10-3223-3_31&partnerID=40&md5=0cfb820909b98e9f32607c872bec4949","Graphs and Trees are non-linear data structures used to organise, model and solve many real world problems and becoming more popular both in scientific as well as commercial domains. They have wide number of applications ranging from Telephone networks, Internet, Social Networks, Program flow, Chemical Compounds, BioInformatics, XML data, Terrorist networks etc. Graph Mining is used for finding useful and significant patterns. Frequent subgraph Mining mines for frequent patterns and subgraphs and they form the basis for Graph clustering, Graph classification, Graph Based Anomaly Detection. In this paper, classification of FSM algorithms is done and popular frequent subgraph mining algorithms are discussed. Comparative study of algorithms is done by taking chemical compounds dataset. Further, this paper provides a framework which acts as strong foundation in understanding any frequent subgraph mining algorithm. © Springer Nature Singapore Pte Ltd. 2018.","Apriori; Chemical compounds; Frequent subgraph mining; Graph mining; Graphs; Pattern growth; Trees","Application programs; Chemical compounds; Flow graphs; Intelligent computing; Trees (mathematics); Apriori; Frequent subgraph mining; Graph mining; Graphs; Pattern growth; Trees; Data mining",2-s2.0-85021236825
"Kumar S., Mishra S., Asthana P., Pragya","Automated detection of acute leukemia using K-mean clustering algorithm",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031401525&doi=10.1007%2f978-981-10-3773-3_64&partnerID=40&md5=e0448ea36ac868d0449d3fe0c4d2a822","Leukemia is a hematologic cancer which develops in blood tissue and triggers rapid production of immature and abnormal-shaped White Blood Cells. Based on statistics it is found that the leukemia is one of the leading causes of death in men and women alike. Microscopic examination of blood sample or bone marrow smear is the most effective technique for diagnosis of leukemia. Pathologists analyze microscopic samples to make diagnostic assessments on the basis of characteristic cell features. Recently, computerized methods for cancer detection have been explored towards minimizing human intervention and providing accurate clinical information. This paper presents an algorithm for automated image based acute leukemia detection systems. The method implemented uses basic enhancement, morphology, filtering and segmenting technique to extract region of interest using k-means clustering algorithm. The proposed algorithm achieved an accuracy of 92.8% and is tested with Nearest Neighbor (kNN) and Naïve Bayes Classifier on the dataset of 60 samples. © Springer Nature Singapore Pte Ltd. 2018.","Clustering; Image processing; Leukemia; White blood cells","Blood; Cells; Classification (of information); Diseases; Image processing; Image segmentation; Nearest neighbor search; Automated detection; Clinical information; Clustering; Computerized methods; K-mean clustering algorithm; K-Means clustering algorithm; Leukemia; White blood cells; Clustering algorithms",2-s2.0-85031401525
"Kakulapati V., Pentapati V.K., Kattamuri S.R.","Implementation of K-mean algorithm using big data in health informatics",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028431690&doi=10.1007%2f978-3-319-63673-3_29&partnerID=40&md5=607c16a5b1eabf4214b79115e1e62cf2","Big information could be a new technology to spot the dataset’s giant in size and complication. The tremendous growth-rate of huge information with appearance contemporary scientific techniques for informative assortment, large amount of medic’s specialty and Health scientific discipline. Giant amounts of heterogeneous medic’s information became on the market in varied aid organizations. This Medical information may be associate sanctionative resource for account insights for up concern delivery and reducing misuse. The immenseness and complication of that dataset’s yield challenges in analyses and succeeding applications to sensible medical surrounding. There is a sensible problem to judge and infer the info victimization inevitable ways. For extracting helpful data in effective and economical information investigation ways are necessary. Data processing bunch methodology is one that helps in characteristic attention-grabbing patterns from huge information. Several smart applications wide used formula is k-mean. This k-means formula is computationally valuable and conjointly the following cluster quality is heavily depending upon the selection of the initial centurions. This paper proposes a k-means formula is with refined initial centurions. To figure out the initial centurions associated with nursing improved methodology to various clusters the data points is also an assignment. The final results show that the projected formula produces clusters with higher precision in less than working out time. © 2018, Springer International Publishing AG.","Algorithms; Big information; Datasets; Health; K-mean","Algorithms; Data handling; Health; Intelligent systems; Big information; Datasets; Health informatics; K-mean algorithms; K-means; Medical information; Scientific discipline; Smart applications; Big data",2-s2.0-85028431690
"Garau E.M., Vázquez R.","Algorithms for the implementation of adaptive isogeometric methods using hierarchical B-splines",2018,"Applied Numerical Mathematics",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029445965&doi=10.1016%2fj.apnum.2017.08.006&partnerID=40&md5=191083d81e2d931e0b63d7daeee422e3","In this article we introduce all the ingredients to develop adaptive isogeometric methods based on hierarchical B-splines. In particular, we give precise definitions of local refinement and coarsening that, unlike previously existing methods, can be understood as the inverse of each other. We also define simple and intuitive data structures for the implementation of hierarchical B-splines, and algorithms for refinement and coarsening that take advantage of local information. We complete the paper with some simple numerical tests to show the performance of the data structures and algorithms, that have been implemented in the open-source Octave/Matlab code GeoPDEs. © 2017 IMACS","Adaptive methods; Coarsening; Hierarchical splines; Isogeometric analysis; Local refinement","Coarsening; Data structures; Interpolation; Open systems; Adaptive methods; Hierarchical splines; Isogeometric analysis; Local information; Local refinement; Numerical tests; Open sources; Precise definition; Inverse problems",2-s2.0-85029445965
"Mohammad Zubir W.M.A., Abdul Aziz I., Jaafar J., Hasan M.H.","Inference Algorithms in Latent Dirichlet Allocation for Semantic Classification",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029592113&doi=10.1007%2f978-3-319-67621-0_16&partnerID=40&md5=fcaad5d0774e2882d0438b21c3ada74a","There are existing implementations of Latent Dirichlet Allocation (LDA) algorithm as a semantic classifier to arrange the data for efficient retrieval. However, the problem of learning or inferencing the posterior distribution of the algorithm is trivial. Inferencing directly the prior distribution could lead to time taken to increase exponentially. It is due to the coupling of the hyperparameters. Several inference algorithms have been implemented together with LDA to solve this issue. The inference algorithm used in this research work is Gibbs sampling. Research using Gibbs sampling shows promising results in comparison to other inference algorithms, especially in the performance of the algorithm. It still takes a long time to compute the topic distribution of the data. There are still room for improvement in the time taken for the algorithm to complete the topic distribution. Using two datasets, an evaluation of the performance of the algorithm has been conducted. Results show that Gibbs sampling as the inference algorithm provides a better prediction on the optimal number of topic of the data in comparison to Variational Expectation Maximization (VEM). © 2018, Springer International Publishing AG.","Inference engine; Information retrieval; Latent Dirichlet Allocation; Semantic; Text classification; Topic models","Classification (of information); Computational methods; Information retrieval; Maximum principle; Sampling; Search engines; Semantics; Statistics; Text processing; Expectation - maximizations; Latent Dirichlet allocation; Latent dirichlet allocations; Posterior distributions; Semantic classification; Text classification; Topic distributions; Topic model; Inference engines",2-s2.0-85029592113
"Yu M., Wang G.","Algorithm design on filtering signals in cable defect magnetic flux leakage non-destructive testing system",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028392095&doi=10.1007%2f978-3-319-60744-3_43&partnerID=40&md5=eda957b090ea79998998758b04121dc5","Cable defect magnetic flux leakage non-destructive testing system is designed according to the characteristics of cable-stayed bridge cable nondestructive testing. The measured results show that the defects of the magnetic flux leakage signals are often accompanied by a lot of noise signals, which leads to signal characteristics no significant. In filtering signal algorithm, first to do the smoothing and filtering processes, then to obtain the signal by characteristic differential of limitation after quantization process characteristic, at least to acquire the object internal defects by the BP neural network. Simulation results show that after dealing with the filtering algorithm of magnetic flux leakage signal characteristics significantly, which provides a reliable basis for the nondestructive testing and analysis of the bridge cable wire brake defect. © 2018, Springer International Publishing AG.","Filtering algorithm; Magnetic flux leakage non-destructive testing; Neural networks; Signal algorithm; Smoothing; Smoothing processing","Bridge cables; Bridge decks; Cable stayed bridges; Cables; Defects; Intelligent systems; Leakage (fluid); Magnetic flux; Magnetism; Neural networks; Nondestructive examination; Quantization (signal); Real time systems; Signal filtering and prediction; Signal processing; Filtering algorithm; Non destructive testing; Signal algorithms; Smoothing; Smoothing processing; Magnetic leakage",2-s2.0-85028392095
"Duong H., Truong T., Le B.","Efficient algorithms for simultaneously mining concise representations of sequential patterns based on extended pruning conditions",2018,"Engineering Applications of Artificial Intelligence",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032285989&doi=10.1016%2fj.engappai.2017.09.024&partnerID=40&md5=a5f129669d1c36148a13db457081c6d2","The concise representations of sequential patterns, including maximal sequential patterns, closed sequential patterns and sequential generator patterns, play an important role in data mining since they provide several benefits when compared to sequential patterns. One of the most important benefits is that their cardinalities are generally much less than the cardinality of the set of sequential patterns. Therefore, they can be mined more efficiently, use less storage space, and it is easier for users to analyze the information provided by the concise representations. In addition, the set of all maximal sequential patterns can be utilized to recover the complete set of sequential patterns, while closed sequential patterns and sequential generators can be used together to generate non-redundant sequential rules and to quickly recover all sequential patterns and their frequencies. Several algorithms have been proposed to mine the concise representations separately, i.e., each of them has been designed to discover only a type of the concise representation. However, they remain time-consuming and memory intensive tasks. To address this problem, we propose three novel efficient algorithms named FMaxSM, FGenCloSM and MaxGenCloSM to exploit only maximal sequential patterns, to simultaneously mine both the sets of closed sequential patterns and generators, and to discover all three concise representations during the same process. To our knowledge, MaxGenCloSM is the first algorithm for concurrently mining the three concise representations of sequential patterns. The proposed algorithms are based on two novel local pruning strategies called LPMAX and LPMaxGenClo that are designed to prune non-maximal, non-closed and non-generator patterns earlier and more efficiently at two and three successive levels of the prefix tree without subsequence relation checking. Extensive experiments on real-life and synthetic databases show that FMaxSM, FGenCloSM and MaxGenCloSM are up to two orders of magnitude faster than the state-of-the-art algorithms and that the proposed algorithms consume much less memory, especially for low minimum support thresholds and for dense databases. © 2017 Elsevier Ltd","Frequent closed sequence; Frequent generator sequences; Frequent sequence; Maximal frequent sequence; Sequential pattern mining; Vertical data format","Digital storage; Closed sequences; Frequent generator sequences; Frequent sequences; Maximal frequent sequences; Sequential-pattern mining; Vertical data formats; Data mining",2-s2.0-85032285989
"Kosheleva O., Villaverde K.","How to enhance student motivations by borrowing from modern practices: Can we learn algorithms from people who compute fast",2018,"Studies in Computational Intelligence",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032370468&doi=10.1007%2f978-3-662-55993-2_11&partnerID=40&md5=46654b4a5f93b8cec4f155e2c6b9f606","In the previous chapter, we showed how to use usual modern practices when teaching math. In this chapter, we focus on unusual modern practices, namely, on the ability of some people to perform calculations unusually fast. In the past, mathematicians actively used this ability. With the advent of computers, there is no longer need for human calculators – even fast ones. However, recently, it was discovered that there exist, e.g., multiplication algorithms which are much faster than standard multiplication. Because of this discovery, it is possible than even faster algorithms will be discovered. It is therefore natural to ask: did fast human calculators of the past use faster algorithms – in which case we can learn from their experience – or they simply performed all operations within a standard algorithm much faster? This question is difficult to answer directly, because the fast human calculators’ self-description of their algorithm is very fuzzy. In this chapter, we use an indirect analysis to argue that fast human calculators most probably used the standard algorithm. © Springer-Verlag GmbH Germany 2018.",,,2-s2.0-85032370468
"Ratajczak-Ropel E., Skakovski A.","Performance evaluation of the proposed algorithms",2018,"Studies in Systems, Decision and Control",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028605302&doi=10.1007%2f978-3-319-62893-6_11&partnerID=40&md5=ef6ec28cc25b920f487dd36d06623cce","In this section, a research on the performance evaluation and ways of the performance improvement for some of the proposed algorithms are discussed. Some useful properties of the DEA, used in the PLA3 and the IBDEA, and a policy for its performance improvement are also presented. © 2018, Springer International Publishing AG.",,,2-s2.0-85028605302
"Duraj A., Chomatek L.","Supporting breast cancer diagnosis with multi-objective genetic algorithm for outlier detection",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028343874&doi=10.1007%2f978-3-319-64474-5_25&partnerID=40&md5=b9734627c2d9a87d0823324f85297d3f","Outlier detection in medical data covers a broad spectrum of medical research. In this paper, the authors propose a new approach to outlier detection based on the multi-objective genetic algorithm. In medical data, an outlier may be considered as a deviation which indicates the existence of cancerous cells in the breast. The paper presents the results of tests which were conducted on the set of medical data from the repository. The results of the study indicate that our method can be successfully applied to the medical problem in question. © Springer International Publishing AG 2018.","Genetic algorithm; Medical diagnosis; Outlier detection","Data handling; Fault tolerance; Genetic algorithms; Statistics; Breast cancer diagnosis; Broad spectrum; Cancerous cells; Medical data; Medical research; Multi-objective genetic algorithm; New approaches; Outlier Detection; Diagnosis",2-s2.0-85028343874
"Pilloni A., Pisano A., Usai E.","Robustification of cooperative consensus algorithms in perturbed multi-agents systems",2018,"Studies in Systems, Decision and Control",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029101192&doi=10.1007%2f978-3-319-62896-7_10&partnerID=40&md5=5a41101fbb659a0a5641ef369010fa1f","In this chapter we show how the Integral Sliding-Mode Control design paradigm can be usefully applied in the framework of Multi-Agent Systems to allow the agents dynamics to be affected by unknown disturbances. Existing consensus-based algorithms for the distributed estimation of pre-specified quantities such as, e.g., the average or the median value of the agents initial conditions fail to converge when disturbances affect the agents dynamics. In the present chapter, is discussed how to redesign the original “non-robust” algorithms from an integral sliding mode perspective, such that restoration on the ideal unperturbed scenario (e.g., convergence to the average or median value) is guaranteed in spite of the unknown perturbations. The theoretical results are fully derived within a Lyapunov analysis approach. Finally, to corroborate the developed approaches, simulative results are also presented and discussed. © Springer International Publishing AG 2018.",,,2-s2.0-85029101192
"Krzywaniak A., Czarnul P.","Parallelization of selected algorithms on multi-core CPUs, a cluster and in a hybrid CPU+Xeon Phi environment",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029505866&doi=10.1007%2f978-3-319-67220-5_27&partnerID=40&md5=714167531995fcf15690b91f8bcae54a","In the paper we present parallel implementations as well as execution times and speed-ups of three different algorithms run in various environments such as on a workstation with multi-core CPUs and a cluster. The parallel codes, implementing the master-slave model in C+MPI, differ in computation to communication ratios. The considered problems include: a genetic algorithm with various ratios of master processing time to communication and fitness evaluation times, matrix multiplication and numerical integration. We present how the codes scale in the aforementioned systems. For the numerical integration code that scales very well we also show performance in a hybrid CPU+Xeon Phi environment. © 2018, Springer International Publishing AG.","Cluster; Intel Xeon Phi; Multi-core CPU; Parallel programming; Parallelization",,2-s2.0-85029505866
"Ooms K., Van de Weghe N.","Finding the right match: Human cognition via indoor route descriptions versus existing indoor networks and algorithms to support navigation",2018,"Lecture Notes in Geoinformation and Cartography",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031297702&doi=10.1007%2f978-3-319-63946-8_32&partnerID=40&md5=ba026462865258dd10e9d4106192e827","This working paper aims to compare existing approaches in indoor navigation. In this we focus on networks and algorithms to respectively model the indoor space and to calculate routes. This is compared with crowdsourced and text-based route instructions. As such the goal is to develop and evaluate an indoor solution that can generate indoor networks and route descriptions which are in line with human intuition, which is a consequence of cognition. © Springer International Publishing AG 2018.","Cognition; Crowdsourced; Indoor navigation","Information theory; Navigation; Cognition; Crowdsourced; Human cognition; In-door navigations; Indoor networks; Indoor solutions; Route descriptions; Working papers; Indoor positioning systems",2-s2.0-85031297702
"Jeevakala S., A. B.T., Rangasami R.","A novel segmentation of cochlear nerve using region growing algorithm",2018,"Biomedical Signal Processing and Control",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026825493&doi=10.1016%2fj.bspc.2017.07.014&partnerID=40&md5=be367527facc9b3358943a2df153420f","Sensorineural hearing loss is a hearing impairment which occurs when there is damage to the inner ear, or to the nerve pathways from the inner ear to the brain. Cochlear implants have been developed to benefit children with bilateral or unilateral Sensorineural hearing loss. A very small or absence of cochlear nerve precludes successful outcome of cochlear implant surgery. Hence, segmentation and measurement of the cochlear nerve support the surgeon's decision to predict a normal or poor outcome of the cochlear implant. For this purpose, a modified region growing segmentation algorithm is proposed that segments the cochlear nerve region accurately. The segmentation accuracy is evaluated using parameters like Jaccard, Dice, False Positive Dice, and False Negative Dice. The segmented region is measured and evaluated using long diameter, short diameter, and cross-sectional area. The statistical analyses of intra/inter-observer correlation and limits of agreement are performed on a cross-sectional area of the cochlear nerve to investigate the reproducibility of the automated measurement. © 2017 Elsevier Ltd","Automatic measurement; Cochlear implant; Cochlear nerve; Internal auditory canal; Magnetic resonance(MR) image; Region growing; Sensorineural hearing loss","Audition; Image segmentation; Magnetic resonance; Automated measurement; Automatic measurements; Cochlear nerve; Region growing; Region growing algorithm; Segmentation accuracy; Segmentation algorithms; Sensorineural hearing loss; Cochlear implants; algorithm; Article; clinical article; cochlea prosthesis; cochlear nerve; diagnostic accuracy; facial nerve; human; image quality; image segmentation; measurement accuracy; nuclear magnetic resonance imaging; nuclear magnetic resonance scanner; outcome assessment; perception deafness; priority journal; region growing algorithm; unilateral hearing loss; vestibular nerve; vestibulocochlear nerve",2-s2.0-85026825493
"Li J.-Z., Liu W.-X., Han Y., Xing H.-W., Yang A.-M., Pan Y.-H.","TSP problem based on artificial ant colony algorithm",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028392661&doi=10.1007%2f978-3-319-60744-3_22&partnerID=40&md5=121277922eb1606b700d1d6e796118e2","An Artificial ant colony algorithm is a swarm intelligence optimization algorithm is advanced and it is widely used in many fields. In this paper, the algorithm applied to the TSP problem solving, to construct the model of an artificial ant colony system, was designed to solve the model algorithm. With 31 capital cities of the latitude and longitude data as a sample, using MATLAB software empirical the application effect of artificial ant colony algorithm in solving the traveling salesman problem (TSP), and verified the superiority of the algorithm through way of seven kinds of algorithms are compared. The results show that the application of an artificial ant colony algorithm in solving TSP is feasible, and obtains the traversal of 31 provincial capital cities of the shortest distance 38884 km and the shortest path; in the operation time and optimal solution quality, artificial ant colony algorithm than the others algorithms perform a certain superiority. © 2018, Springer International Publishing AG.","Artificial ant colony; Optimal solution; Pheromone update; Shortest path; Traveling salesman problem","Ant colony optimization; Application programs; Graph theory; Intelligent systems; MATLAB; Optimal systems; Optimization; Real time systems; Traveling salesman problem; Application effect; Artificial ant colonies; Matlab- software; Model algorithms; Optimal solutions; Pheromone update; Shortest path; Swarm intelligence optimization algorithm; Problem solving",2-s2.0-85028392661
"Chen W.-H., Wu P.-H., Lin Y.-L.","Performance optimization of thermoelectric generators designed by multi-objective genetic algorithm",2018,"Applied Energy",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032686581&doi=10.1016%2fj.apenergy.2017.10.094&partnerID=40&md5=a5be7287b519f7ef9ba5ba70008b0bdb","The purpose of this study is to investigate the output power and efficiency of a TEG system using waste heat from heat pipes, and then optimize its performance. The TEG material is Bi0.4Sb1.6Te3 and its figure-of-merit (ZT) is 1.18 at room temperature. The predictions indicate that a longer length of the elements has greater power output and efficiency based on a fixed heat flux on the hot side surface, whereas a shorter length has greater output power based on a fixed temperature difference. The geometry of the TEG is designed through a multi-objective genetic algorithm (MOGA) to maximize its efficiency. When the temperature difference is fixed at 40 °C, the output power and efficiency of the TEG with optimization is increased by about 51.9% and 5.4%, compared to the TEG without optimization. Once the impedance matching, namely, the internal resistance is equal to the external load resistance, is used, the output power can be further enhanced by about 3.85–4.40%. When the heat flux is fixed at 20,000 Wm−2 along with the temperature difference of 40 °C, the output power and efficiency of a pair of elements can be increased to 7.99 mW and 9.52%, respectively. These results are much higher than those reported in other studies. Accordingly, it is concluded that the MOGA is a powerful tool to design the geometry of a TEG for maximizing its performance and real applications in industry. © 2017 Elsevier Ltd","Heat pipes; Impedance matching; Multi-objective genetic algorithm (MOGA); Optimization; Output power and efficiency; Thermoelectric generator","Antimony compounds; Bismuth compounds; Efficiency; Electronic equipment; Genetic algorithms; Heat flux; Heat pipes; Impedance matching (electric); Multiobjective optimization; Optimization; Tellurium compounds; Waste heat; Fixed temperature; Internal resistance; Multi-objective genetic algorithm; Output power and efficiencies; Performance optimizations; Real applications; Temperature differences; Thermoelectric generators; Thermoelectric equipment",2-s2.0-85032686581
"Cunha T., Soares C., de Carvalho A.C.P.L.F.","Metalearning and Recommender Systems: A literature review and empirical study on the algorithm selection problem for Collaborative Filtering",2018,"Information Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029679350&doi=10.1016%2fj.ins.2017.09.050&partnerID=40&md5=f595c534d933c3cfd14ad54fcfb12008","The problem of information overload motivated the appearance of Recommender Systems. From the several open problems in this area, the decision of which is the best recommendation algorithm for a specific problem is one of the most important and less studied. The current trend to solve this problem is the experimental evaluation of several recommendation algorithms in a handful of datasets. However, these studies require an extensive amount of computational resources, particularly processing time. To avoid these drawbacks, researchers have investigated the use of Metalearning to select the best recommendation algorithms in different scopes. Such studies allow to understand the relationships between data characteristics and the relative performance of recommendation algorithms, which can be used to select the best algorithm(s) for a new problem. The contributions of this study are two-fold: 1) to identify and discuss the key concepts of algorithm selection for recommendation algorithms via a systematic literature review and 2) to perform an experimental study on the Metalearning approaches reviewed in order to identify the most promising concepts for automatic selection of recommendation algorithms. © 2017 Elsevier Inc.","Algorithm selection; Collaborative Filtering; Metalearning; Recommendation system","Collaborative filtering; Intelligent agents; Metals; Recommender systems; Algorithm selection; Computational resources; Experimental evaluation; Information overloads; Meta-learning approach; Metalearning; Recommendation algorithms; Systematic literature review; Problem solving",2-s2.0-85029679350
"Vergani A.A., Martinelli S., Binaghi E.","Cluster analysis of functional neuroimages using data reduction and competitive learning algorithms",2018,"Lecture Notes in Computational Vision and Biomechanics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032335961&doi=10.1007%2f978-3-319-68195-5_7&partnerID=40&md5=89a0649ad2e9a500cd7c79ed8ec5b96a","In the present work we use pattern vectors derived from Statistical Parametric Map, generated from a group of artificial and in-house collected fMRI data, to conduct cluster analysis. Two clustering algorithms, self-organizing map (SOM) and growing neural gas (GNG), are selected to explore inherent properties in the brain functional data. As seen in our experimental context, SOM and GNG show comparable behavior, however GNG prevails in the management of large data sets. An exploratory, descriptive analysis is conducted on in-house collected data clustered by GNG and results are detailed in the paper. © 2018, Springer International Publishing AG.","Data reduction; fMRI; Growing neural gas; Self organizing map; Statistical parametric mapping",,2-s2.0-85032335961
"Wu S.-C., Chen K.-Y., Lin T.-H., Chou H.-P.","Multivariate algorithms for initiating event detection and identification in nuclear power plants",2018,"Annals of Nuclear Energy",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028962250&doi=10.1016%2fj.anucene.2017.08.066&partnerID=40&md5=c9e7a800e73142d046f30a37388afa45","To prevent escalation of an initiating event into a severe accident, promptly detecting its occurrence and precisely identifying its type are essential. In this study, several multivariate algorithms for initiating event detection and identification are proposed to help maintain safe operations of nuclear power plants (NPPs). By monitoring changes in the NPP sensing variables, an event is detected when the preset thresholds are exceeded. Unlike existing approaches, recordings from sensors of the same type are simultaneously considered for detection, and no subjective reasoning is involved in setting these thresholds. To facilitate efficient event identification, a spatiotemporal feature extractor is proposed. The extracted features consist of the temporal traits used by existing techniques and the spatial signature of an event. Through an F-score-based feature ranking, only those that are most discriminant in classifying the events under consideration will be retained for identification. Moreover, an untrained event isolation scheme is introduced to avoid relating an untrained event to those in the event dataset so that improper recovery actions can be prevented. Results from experiments containing data of 12 event classes and a total of 125 events generated using a Taiwan's Maanshan NPP simulator are provided to illustrate the efficacy of the proposed algorithms. © 2017 Elsevier Ltd",,"Nuclear energy; Nuclear fuels; Nuclear reactor accidents; Event identification; Feature ranking; Initiating events; Monitoring change; Recovery actions; Severe accident; Spatial signature; Spatio temporal features; Nuclear power plants",2-s2.0-85028962250
"Vekkot S., Tripathi S.","Significance of glottal closure instants detection algorithms in vocal emotion conversion",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029510870&doi=10.1007%2f978-3-319-62521-8_40&partnerID=40&md5=af2a4f2966419030e9e0c0571845e11c","The objective of this work is to explore the significance of efficient glottal activity detection for inter-emotion conversion. Performance of popular glottal epoch detection algorithms like Dynamic Projected Phase-Slope Algorithm (DYPSA), Speech Event Detection using Residual Excitation And a Mean-based Signal (SEDREAMS) and Zero Frequency Filtering (ZFF) are compared in the context of vocal emotion conversion. Existing conversion approaches deal with synthesis/conversion from neutral to different emotions. In this work, we have demonstrated the efficacy of determining the conversion parameters based on statistical values derived from multiple emotions and using them for inter-emotion conversion in Indian context. Pitch modification is effected by using transformation scales derived from both male and female speakers in IIT Kharagpur-Simulated Emotion Speech Corpus. Three archetypal emotions viz. anger, fear and happiness were generated using pitch and amplitude modification algorithm. Analysis of statistical parameters for pitch after conversion revealed that anger gives good subjective and objective similarity while characteristics of fear and happiness are most challenging to synthesise. Also, use of male voice for synthesis gave better intelligibility. Glottal activity detection by ZFF gave results with least error for median pitch. The results from this study indicated that for emotions with overlapping characteristics like surprise and happiness, inter-emotion conversion can be a better choice than conversion from neutral. © 2018, Springer International Publishing AG.","DYPSA; Glottal Closure Instants; Inter-emotion conversion; SEDREAMS; ZFF",,2-s2.0-85029510870
"Jain L.C., Favorskaya M.N.","Innovative algorithms in computer vision",2018,"Intelligent Systems Reference Library",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032591343&doi=10.1007%2f978-3-319-67994-5_1&partnerID=40&md5=00a69f32ec946c8dc1c38d9c8eb55153","This chapter contains a brief description of the methods, algorithms, and implementations applied in many fields of computer vision. The graphological analysis and identification of handwritten manuscripts are discussed using the examples of Great Russian writers. A perceptually tuned watermarking using non-subsampled shearlet transform is a contribution in the development of the watermarking techniques. The mobile robot simultaneous localization and mapping, as well as the joined processing of visual and audio information in the motion control systems of the mobile robots, are directed on the robotics’ development. The ambient audiovisual monitoring based on a wide set of methods for digital processing of video sequences is another useful real life application. Processing of medical images becomes more and more complicated due to the enforced current requirements of medical practitioners. © 2018, Springer International Publishing AG.","Clinical decision support system; Digital watermarking; Eye detection and tracking; Face image quality assessment; Gait monitoring; Graphological analysis; Indoor human activity; Medical image processing; Simultaneous localization and mapping; Visual and audio decision making",,2-s2.0-85032591343
"Assija V., Baliyan A., Jain V.","Effective and efficient digital advertisement algorithms",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031433418&doi=10.1007%2f978-981-10-6602-3_9&partnerID=40&md5=9072a755f34f96c3b036ff90275958f0","In today’s world when everyone wants the best deal when it comes to online shopping, it becomes tedious job for companies to target their audience with appropriate content and advertising media. This paper talks about such issues faced by various companies nowadays and tries to resolve those issues by implementing some algorithms or by introducing a new platform to showcase advertisements online. In this we also talk about efficient way of tracking users online and analyze their data to showcase content based on their preferences. Our focus is also on the usage of “AdBlock” plug-in, that is, how to stop it or prevent it to block advertisements online. At last we try to deliver advertisements in such a way that they should take as less as bandwidth they can and increase the page load time. © 2018, Springer Nature Singapore Pte Ltd.","ASCII; Bots; CPA; CPC; CPL; CPM; DMP; DSP; ISP; PPC; PPV; ROI; RTB","Computer programming; ASCII; Bots; Content-based; Digital advertisement; Online shopping; Plug-ins; Computer science",2-s2.0-85031433418
"Khawaja S.G., Khan A.M., Akram M.U., Khan S.A.","A novel architecture for k-means clustering algorithm",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028652714&doi=10.1007%2f978-3-319-60834-1_31&partnerID=40&md5=119624485bc57603b0d9a9d76a0b4749","Technological advancements in today information age has helped the researchers to capture digital footprints of humans with regards to their daily activities. These logs of information posses valuable information for the data analytics who process it to find hidden pattern and unique behavior. Among the many algorithms k-means clustering is one of the very popular and widely used algorithm in the field of data mining and machine learning. k-means provides natural segments of dataset provided for clustering. It uses proximity to assign data points to a specific cluster, here the criteria of allocation is the minimum distance from the cluster center. Unfortunately, the rate of data growth has not been met by the speed of the algorithms. A number of hardware based solutions have been proposed to increase the processing power of different algorithms. In this paper, we present a novel algorithm for k-mean clustering which exploits the data redundancy occurring in the dataset. The proposed algorithm performs computations for the available unique items in the dataset and uses its frequency to finalize the results. Furthermore, FPGA based hardware architecture for the proposed algorithm is also presented in the paper. The performance of the proposed algorithm and its hardware implementation is evaluated using execution time, speedup and throughput. The proposed architecture provides speedup of 23 times and 2600 times against sequential hardware architecture and software implementation with a very small area requirement. © 2018, Springer International Publishing AG.",,"Data mining; Hardware; Learning systems; Hardware architecture; Hardware implementations; K-means clustering; K-Means clustering algorithm; Novel architecture; Proposed architectures; Software implementation; Technological advancement; Clustering algorithms",2-s2.0-85028652714
"Zouache D., Moussaoui A., Ben Abdelaziz F.","A cooperative swarm intelligence algorithm for multi-objective discrete optimization with application to the knapsack problem",2018,"European Journal of Operational Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025169784&doi=10.1016%2fj.ejor.2017.06.058&partnerID=40&md5=3555e85cc7eb45b92ffadc229554e882","We propose a novel cooperative swarm intelligence algorithm to solve multi-objective discrete optimization problems (MODP). Our algorithm combines a firefly algorithm (FA) and a particle swarm optimization (PSO). Basically, we address three main points: the effect of FA and PSO cooperation on the exploration of the search space, the discretization of the two algorithms using a transfer function, and finally, the use of the epsilon dominance relation to manage the size of the external archive and to guarantee the convergence and the diversity of Pareto optimal solutions. We compared the results of our algorithm with the results of five well-known meta-heuristics on nine multi-objective knapsack problem benchmarks. The experiments show clearly the ability of our algorithm to provide a better spread of solutions with a better convergence behavior. © 2017 Elsevier B.V.","Firefly algorithm; Knapsack problem; Multi-objective discrete optimization; Particle swarm optimization; Transfer function","Artificial intelligence; Bioluminescence; Combinatorial optimization; Multiobjective optimization; Pareto principle; Particle swarm optimization (PSO); Swarm intelligence; Transfer functions; Convergence behaviors; Cooperative swarm; Discrete optimization; Discrete optimization problems; Dominance relation; Firefly algorithms; Knapsack problems; Meta heuristics; Optimization",2-s2.0-85025169784
"Xing D., Gong Q.","A fast algorithm for the measurement of stimulus frequency otoacoustic emission suppression tuning curves",2018,"Applied Acoustics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026888548&doi=10.1016%2fj.apacoust.2017.06.017&partnerID=40&md5=d0aff1c08532b4ed98b8b1c056e75616","Frequency selectivity is an important indicator of auditory function in the human ear. Stimulus frequency otoacoustic emission (SFOAE) suppression tuning curves (STCs) have great potential in the objective analysis of human auditory frequency selectivity but are costly to measure by the traditional algorithm using pure-tone adaptive method. To improve the measurement efficiency of the SFOAE STCs, a faster algorithm based on a suppressor with gradiently changing intensity and interpolation is proposed in this paper. Twelve subjects participated in this study by measuring their SFOAE STCs through the traditional and fast algorithm. The results shows that the average correlation coefficients of the SFOAE STCs measured using the fast and the traditional algorithms at different probe frequencies is 0.94. And the measurement speed of the fast algorithm was approximately 2.10 times higher than the traditional one. Also, the fast algorithm is more efficient than the algorithms of Keefe et al. (2008) and Charaziak et al. (2013). Experimental evidence is provided that the proposed fast algorithm greatly improves the measurement speed and reduces the processing time, exhibiting good accuracy and reliability. © 2017 Elsevier Ltd","Fast algorithm; Stimulus frequency otoacoustic emission; Suppression tuning curves","Acoustic emissions; Average correlation coefficients; Experimental evidence; Fast algorithms; Frequency selectivity; Measurement efficiency; Objective analysis; Stimulus-frequency otoacoustic emissions; Suppression tuning curves; Otoacoustic emissions",2-s2.0-85026888548
"Ayeh M.D.N., Gao H., Chen D.","An approximation algorithm for shortest path based on the hierarchical networks",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028443870&doi=10.1007%2f978-3-319-63645-0_53&partnerID=40&md5=bc0beb06f1f5c59d718dcec3cfa695a8","Social networks have become a “household name” for internet users. Identifying shortest paths between nodes in such networks is intrinsically important in reaching out to users on such networks. In this paper we propose an efficient algorithm that can scale up to large social networks. The algorithm iteratively constructs higher levels of hierarchical networks by condensing the central nodes and their neighbors into super nodes until a smaller network is realized. Shortest paths are approximated by corresponding super nodes of the newly constructed hierarchical network. Experimental results show an appreciable improvement over existing algorithms. © Springer International Publishing AG 2018.","Approximation algorithm; Complex network; Hierarchical networks; Shortest path","Complex networks; Graph theory; Intelligent systems; Iterative methods; Social networking (online); Central nodes; Hierarchical network; Internet users; Scale-up; Shortest path; Supernodes; Approximation algorithms",2-s2.0-85028443870
"Vatamaniuk I.V., Budkov V.Y., Kipyatkova I.S., Karpov A.A.","Methods and algorithms of audio-video signal processing for analysis of indoor human activity",2018,"Intelligent Systems Reference Library",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032573772&doi=10.1007%2f978-3-319-67994-5_6&partnerID=40&md5=bf4350f3340879d87ae8d3d5c3f2a851","In this chapter, the methods and algorithms of audio and video signal processing for analysis of indoor human activity are presented. The concept of ambient intelligent space and several implementations are discussed. The main idea is the development of proactive information services based on the analysis of user behavior and environment. The methods of image processing, such as illumination normalization and blur estimation based on focus estimation methods and image quality assessment, are described afterwards. A short overview of face recognition methods including the principal component analysis, Fisher linear discriminate analysis, and local binary patterns is presented. Their efficiency was subjected to comparative analysis both in terms of the processing speed and precision under several variants of the area selected for image analysis, including the procedure seeking face in the image and limitation of the size of the zone of interest. Several approaches to audiovisual monitoring of meeting room participants are discussed. The main goal of the described system is to identify events in the smart conference room, such as the time, when a new user enters the room, a speech begins, or an audience member is given the floor. The participant registration system including face recognition accuracy assessment and recording system involving assessment results of the pointing of the camera, when photographing participants are presented. © 2018, Springer International Publishing AG.","Audio-video signal processing; Audiovisual monitoring; Face recognition; Image blur; Indoor human activity; Speech recognition",,2-s2.0-85032573772
"Trivedi I.N., Jangir P., Kumar A., Jangir N., Totlani R.","A novel hybrid PSO–WOA algorithm for global numerical functions optimization",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031411102&doi=10.1007%2f978-981-10-3773-3_6&partnerID=40&md5=34d3c7a381977b49ec311a31e233710f","Recent trend of research is to hybridize two and more algorithms to obtain superior solution in the field of optimization problems. In this context, a new technique hybrid particle swarm optimization (PSO)–whale optimizer (WOA) is exercised on some unconstraint benchmark test functions. Hybrid PSO–WOA is a combination of PSO used for exploitation phase and WOA for exploration phase in uncertain environment. Analysis of competitive results obtained from PSO–WOA validates its effectiveness compared to standard PSO and WOA algorithm. © Springer Nature Singapore Pte Ltd. 2018.","HPSO–WOA; Particle swarm optimization; Whale optimization algorithm","Benchmarking; Optimization; Benchmark tests; Exploration phase; Hybrid Particle Swarm Optimization; Numerical functions; Optimization algorithms; Optimization problems; Recent trends; Uncertain environments; Particle swarm optimization (PSO)",2-s2.0-85031411102
"Zhang Y., Guo B.","An improved ViBe algorithm based on salient region detection",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026784057&doi=10.1007%2f978-3-319-63856-0_41&partnerID=40&md5=5063acbec614a73e5586ff6417339a4e","The ViBe algorithm is a powerful technique for the background detection and subtraction in video sequences. Compared to the state-of-the-art algorithms, ViBe algorithm is better in fast speed and less memory consumption. However, when applying ViBe algorithm to the moving objects appeared in the first frame of videos, all pixels in first frame will be used to build the background model that will result in the foreground pixels in sample set. This problem causes the ghost areas emerge. And it will remain for a long time. In this paper, a salient region detection based ViBe algorithm is proposed to eliminate the ghost areas fast. First, the foreground region is extracted from the first frame of videos using the salient region detection algorithm. According to the result of salient region detection, the background area of image is separated from the foreground area. The foreground pixels are dislodged from the sample set. Then, only background pixels are used for background model initialization. The experimental result shows that the improved algorithm can eliminate ghost in few frames quickly. © Springer International Publishing AG 2018.","Background model; Ghost area; Object detection; ViBe algorithm","Object detection; Pixels; Signal processing; Background detection; Background model; Background pixels; Foreground regions; Ghost area; Memory consumption; Salient region detections; State-of-the-art algorithms; Multimedia signal processing",2-s2.0-85026784057
"Raghu G., Sharma N.K., Domanal S.G., Ram Mohana Reddy G.","Memory-based load balancing algorithm in structured peer-to-peer system",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026755814&doi=10.1007%2f978-981-10-3373-5_43&partnerID=40&md5=ee9708de156ef02bb119d878647ef30d","There are several load balancing techniques which are popular used in Structured Peer-to-Peer (SPTP) systems to distribute the load among the systems. Most of the protocols are concentrating on load sharing in SPTP Systems that lead to the performance degeneration in terms of processing delay and processing time due to the lack of resources utilization. The proposed work is related to the sender-initiated load balancing algorithms which are based on the memory. Further to check the performance of the proposed load balancing algorithm, the experimental results carried out in the real-time environment with different type of network topologies in distributed environment. The proposed work performed better over existing load balancing algorithm such as Earliest Completion Load Balancing (ECLB) and First Come First Serve (FCFS) in terms of processing delay and execution time. © Springer Nature Singapore Pte Ltd. 2018.","Distributed environment; Load balancing; Network topologies; Sender-initiated algorithm; Structured peer-to-peer (SPTP) systems","Computation theory; Distributed computer systems; Intelligent computing; Resource allocation; Time sharing systems; Topology; Distributed environments; First come first serves; Load balancing algorithms; Load balancing technique; Network topology; Resources utilizations; Structured peer-to-peer; Structured peer-to-peer system; Peer to peer networks",2-s2.0-85026755814
"Lis R., Vanin A., Kotelnikova A.","Performance Comparison of Neural Network Training Algorithms for Load Forecasting in Smart Grids",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029496557&doi=10.1007%2f978-3-319-67229-8_9&partnerID=40&md5=896323dd077f35df9ff98d6405c0d397","Voltage control of distribution systems need load forecast. For improvement of efficiency and sustainability of the automated control of Smart Power Grids (SPG) the control system of the process should contain a subsystem of forecasting time series - load forecasting, as a parameter directly associated with voltage. The highest requirements applicate for the accuracy of short-term (day-week-month) and operational (within the current day) forecasts, as they determine the management of the current mode of operation of the SPG. The paper describes forecasting methods and concludes that using of artificial neural networks for this problem is preferable. It shows that for the complex real networks particle swarm method is faster and more accurate than traditional back propagation method. Finally the used model of short-term load forecasting (STLF) is described and tuning of all presented models is done. The paper concentrates of training methods of neural networks and uses “back propagation” algorithm and “particle swarm” algorithm for this purpose. © 2018, Springer International Publishing AG.","Artificial neural network; Load forecasting; Voltage control",,2-s2.0-85029496557
"Salcedo-Sanz S., Deo R.C., Cornejo-Bueno L., Camacho-Gómez C., Ghimire S.","An efficient neuro-evolutionary hybrid modelling mechanism for the estimation of daily global solar radiation in the Sunshine State of Australia",2018,"Applied Energy",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032435325&doi=10.1016%2fj.apenergy.2017.10.076&partnerID=40&md5=fa2ab6d4d04feec558c67b3333a802da","This research paper aims to develop a hybrid neuro-evolutionary wrapper-based model for daily global solar radiation estimation in the solar-rich Sunshine State of Queensland, Australia. To design a robust hybrid modelling mechanism, the Interim-ERA European Centre for Medium Range Weather Forecasting (ECMWF) Reanalysis data are employed to train and cross-validate the estimation model that is formulated by an evolutionary-type algorithm: the Coral Reefs Optimization (CRO) integrated with an Extreme Learning Machine (ELM) model. The hybrid CRO-(ELM) algorithm is applied in two stages: first for the feature selection process guided by an ELM algorithm (a class of fast training neural network tool) as the model's fitness function to screen an optimal set of predictor variables and second, for the estimation of the solar radiation using the optimally screened variables by the final hybrid CRO-(ELM)-ELM system. To benchmark the performance of the hybrid CRO-ELM algorithm for this estimation problem we apply an alternative, yet a similar feature screening approach: the Grouping Genetic Algorithm encoded into the ELM-based model (GGA-(ELM) used as the predictor mechanism). After the feature selection process is performed by the CRO algorithm that extracts the data patterns for accurate estimation the alternative objective algorithm is applied (in this case the ELM again) to formulate the hybrid CRO-(ELM)-ELM modelling system. To provide a rigorous evaluation of the CRO-(ELM)-ELM hybrid system, alternative estimation approaches are considered: the Multivariate Adaptive Regression Splines (MARS), Multiple Linear Regression (MLR) and the Support Vector Regression (SVR). The hybrid CRO-(ELM)-ELM system is tested in a real problem where the results are evaluated by means of several statistical score metrics and diagnostic plots of the observed and the estimated daily global solar radiation in the testing phase. We show that the hybrid CRO-(ELM)-ELM model is able to yield promising results; thus improving those attained by the 7 alternative models (i.e., hybrid CRO-(ELM)-MARS, CRO-(ELM)-MLR and CRO-(ELM)-SVR and the GGA equivalent models). The study ascertains that the CRO-based hybrid system where a large pool of predictor data are carefully screened through a wrapper-based modelling system and the ELM model is applied as a objective estimation tool can be adopted as a qualified stratagem in solar radiation estimation problems. The proposed hybrid CRO-(ELM)-ELM system exhibits clear advantages over the alternative machine learning approaches tested and also over the other machine learning algorithms used without the feature selection tool; thus advocating its scientific utility in renewable energy applications. © 2017 Elsevier Ltd","Coral Reefs Optimization; Extreme Learning Machines; Grouping Genetic Algorithms; Hybrid modelling system; Solar radiation estimation","Artificial intelligence; Benchmarking; Feature extraction; Genetic algorithms; Hybrid systems; Knowledge acquisition; Learning algorithms; Learning systems; Linear regression; Optimization; Radiation; Reefs; Regression analysis; Solar radiation; Weather forecasting; Coral reef; Extreme learning machine; Grouping genetic algorithms; Hybrid modelling; Solar radiation estimation; Evolutionary algorithms; estimation method; genetic algorithm; machine learning; model validation; numerical model; optimization; solar power; solar radiation; Australia; Queensland; Anthozoa",2-s2.0-85032435325
"Rizun N., Ossowska K., Taranenko Y.","Modeling the Customer’s Contextual Expectations Based on Latent Semantic Analysis Algorithms",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029506019&doi=10.1007%2f978-3-319-67229-8_33&partnerID=40&md5=d231999e0b4ee55081866d9f058ba92e","This paper presents the approach of modeling the system of customer’s contextual expectations. The novelty consists in systematic usage of the different technic. The first technic – the theory of Benefits Language as an instrument of forming Concept of Benefits for studied product. The second one – the combination of advantages the probabilistic Latent Dirichlet Allocation (LDA) and Linear Algebra based Latent Semantic Analysis (LSA) methods as an instrument of textual data retrieval. The verification of the proposed approach for specifies type of product – films – was conducted. The main research plan was realized: Contextual Summary using the LDA-based algorithm was formed; the Contextual Frameworks using LSA-based approach were performed; the Manually Created Contextual Expectations Dictionary was built. The results of case study, based on the Polish-language film reviews corpora analysis, allowed to make the conclusions about the possibility to use proposed approach for building the system of Customer’s Contextual Expectations. © 2018, Springer International Publishing AG.","Benefits Language; Contextual expectations; Customer; Latent Dirichlet Allocation; Latent Semantic Analysis",,2-s2.0-85029506019
"Ji W., Guo Q., Lei Y.","HM-AprioriAll algorithm improvement based on Hadoop environment",2018,"Studies in Computational Intelligence",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020409236&doi=10.1007%2f978-3-319-60170-0_12&partnerID=40&md5=87faeda161f9a9e4ce338123ea1a8c4e","In order to improve the efficiency of the mining frequent item-sets of AprioriAll algorithm, the Hadoop environment and MapReduce model are introduced to improve AprioriAll algorithm, a new algorithm of mining frequent item-sets under the environment of big data HM-AprioriAll algorithm is designed. Compared with the original algorithm, the new algorithm introduces user attributes and pruning technology, which reduces the number of the elements in the candidate sets and reduces the number of the scanning times on the data sets, greatly reduces the time complexity and space complexity of computing, gives rules model in large scale. After testing HM-AprioriAll algorithm on Hadoop platform, the results prove that the insertion of this technology makes HM-AprioriAll algorithm have higher efficiency of expanding. © Springer International Publishing AG 2018.","AprioriAll algorithm; Big data; Hadoop; Map Reduce; Recommendation systems","Data mining; Efficiency; Recommender systems; AprioriAll algorithm; Frequent item sets; Hadoop; Hadoop platforms; Higher efficiency; Map-reduce; Original algorithms; Space complexity; Big data",2-s2.0-85020409236
"Merk A., Cal P., Woźniak M.","Distributed DBSCAN algorithm – Concept and experimental evaluation",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019178009&doi=10.1007%2f978-3-319-59162-9_49&partnerID=40&md5=a347c2fd2b14a480334077bde92f3fda","One of the most popular clustering algorithm is DBSCAN, which is known to be efficient and highly resistant to noise. In this paper we propose its distributed implementation. Distributed computing is a very fast growing way of solving problems in big datasets using a multinode cluster, rather than parallelization in one computer. Using its features in proper way, can lead to higher performance and, what is probably more important, higher scalability. In order to show added value of this way of designing and implementing algorithms we compare our results with GPU parallelization. On the basis of the obtained results We formulate the propositions how to improve our solution. © Springer International Publishing AG 2018.","Big data; Clustering; Distributed computing; Unsupervised learning","Big data; Cluster computing; Distributed computer systems; Unsupervised learning; Added values; Clustering; DBSCAN algorithm; Distributed implementation; Experimental evaluation; Gpu parallelization; Parallelizations; Clustering algorithms",2-s2.0-85019178009
"Abdul A.M., Cherukuvada S., Soujanya A., Srikanth R., Umar S.","Analysis of genetic algorithm for effective power delivery and with best upsurge",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021201697&doi=10.1007%2f978-981-10-3223-3_1&partnerID=40&md5=90ce4d7bda46ea1b5605a632db13358c","Wireless network is ready for hundreds or thousands of nodes, where each node is connected to one or sometimes more sensors. WSN sensor integrated circuits, embedded systems, networks, modems, wireless communication and dissemination of information. The sensor may be an obligation to technology and science. Recent developments underway to miniaturization and low power consumption. They act as a gateway, and prospective clients, I usually have the data on the server WSN. Other components separate routing network routers, called calculating and distributing routing tables. Discussed the routing of wireless energy balance. Optimization solutions, we have created a genetic algorithm. Before selecting an algorithm proposed for the construction of the center console. In this study, the algorithms proposed model simulated results based on parameters depending dead nodes, the number of bits transmitted to a base station, where the number of units sent to the heads of fuel consumption compared to replay and show that the proposed algorithm has a network of a relative. © Springer Nature Singapore Pte Ltd. 2018.","Dead nodes; Genetic algorithm; LEACH-GSA; Upsurge","Electric power transmission; Embedded systems; Genetic algorithms; Intelligent computing; Optimization; Routers; Wireless sensor networks; Wireless telecommunication systems; Dead nodes; Low-power consumption; Optimization solution; Routing networks; Simulated results; Upsurge; Wireless communications; Wireless energy; Gateways (computer networks)",2-s2.0-85021201697
"Gupta A.K., Yadav N.S., Goyal D.","Implementation of smart job first dynamic round robin (SJFDRR) scheduling algorithm with smart time quantum in multi-core processing system",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031729745&doi=10.1007%2f978-981-10-5508-9_3&partnerID=40&md5=055c803e4eb4a25f39820ec621377f01","Modern computer system is organized with multi-core processing system. The scheduling of processes in multiprocessing may turn into more complex task. In multi-core processing system, there are two or more cores embedded into a single chip. This architecture provides more efficiency in terms of throughput than single processor architecture. Previously, most of the work has been done in creating new scheduling algorithms for multi-core processing system, but small consideration has been given to merge user priority and system priority. In this paper, researcher has proposed Smart Job First Dynamic Round Robin Algorithm with smart Time Quantum (SJFDRR) in multi-core processing system in which a smart priority factor (SPF) is calculated for each process. The process which has lowest value of SPF is scheduled first. The time quantum is calculated dynamically for each processor. By this algorithm the average waiting time and average turnaround time and context switch is significantly decreases which lead to increase in performance of the system. © Springer Nature Singapore Pte Ltd. 2018.","Asynchronous multi-core processor; Multi-core processing system; Operating systems; Round robin; Scheduling algorithm; Synchronous multi-core processor; Time quantum","Computer operating systems; Memory architecture; Program processors; Routers; Average waiting-time; Dynamic round robin; Modern computer systems; Multi-core processing; Multi-core processor; Round Robin; Single processor architecture; Time quantum; Scheduling algorithms",2-s2.0-85031729745
"Lach E.","New adaptations for evolutionary algorithm applied to dynamic difficulty adjustment system for serious game",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030760914&doi=10.1007%2f978-3-319-67792-7_48&partnerID=40&md5=e243c9a05debf68fb5b6915f1614560d","The aim of the Dynamic Difficulty Adjustment is to dynamically balance the difficulty level of the games in order to keep the user interested in playing. Generally, a game in which the challenge level matches the skill of the human player has a greater entertainment value than a game that is either too easy (boring) or too hard (frustrating). An entertainment has an important role to play in serious games (educational games), contributing to their motivational and engaging qualities leading to players voluntarily playing serious games for extended periods of time. In this paper, we present new adaptations for reducing the number of training data for the evolutionary algorithms used to find game settings suitable for the player of a serious game. The training process for a human player should be as short as possible. Various experiments are performed. The obtained results show that the proposed adaptation causes a substantial decrease in training data for different players. © 2018, Springer International Publishing AG.","Dynamic Difficulty Adjustment (DDA); Evolutionary algorithm; Game AI; Serious game","Evolutionary algorithms; Challenge levels; Educational game; Game AI; Human players; Training data; Training process; Serious games",2-s2.0-85030760914
"Atashpaz-Gargari E., Reis M.S., Braga-Neto U.M., Barrera J., Dougherty E.R.","A fast Branch-and-Bound algorithm for U-curve feature selection",2018,"Pattern Recognition",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028714985&doi=10.1016%2fj.patcog.2017.08.013&partnerID=40&md5=1e3c9953ebb3de822b88ef188c1361c7","We introduce a fast Branch-and-Bound algorithm for optimal feature selection based on a U-curve assumption for the cost function. The U-curve assumption, which is based on the peaking phenomenon of the classification error, postulates that the cost over the chains of the Boolean lattice that represents the search space describes a U-shaped curve. The proposed algorithm is an improvement over the original algorithm for U-curve feature selection introduced recently. Extensive simulation experiments are carried out to assess the performance of the proposed algorithm (IUBB), comparing it to the original algorithm (UBB), as well as exhaustive search and Generalized Sequential Forward Search. The results show that the IUBB algorithm makes fewer evaluations and achieves better solutions under a fixed computational budget. We also show that the IUBB algorithm is robust with respect to violations of the U-curve assumption. We investigate the application of the IUBB algorithm in the design of imaging W-operators and in classification feature selection, using the average mean conditional entropy (MCE) as the cost function for the search. © 2017 Elsevier Ltd","Branch-and-bound algorithm; Feature selection; U-curve assumption; W-operator design","Branch and bound method; Budget control; Cost functions; Costs; Branch-and-bound algorithms; Classification errors; Classification features; Extensive simulations; Mean conditional entropies; Optimal feature selections; Sequential forward search; W-operators; Feature extraction",2-s2.0-85028714985
"Bagheri A., Bollen M.H.J., Gu I.Y.H.","Improved characterization of multi-stage voltage dips based on the space phasor model",2018,"Electric Power Systems Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029393979&doi=10.1016%2fj.epsr.2017.09.004&partnerID=40&md5=f2e2e443ea056f47f5426f8c41d9bda4","This paper proposes a method for characterizing voltage dips based on the space phasor model of the three phase-to-neutral voltages, instead of the individual voltages. This has several advantages. Using a K-means clustering algorithm, a multi-stage dip is separated into its individual event segments directly instead of first detecting the transition segments. The logistic regression algorithm fits the best single-segment characteristics to every individual segment, instead of extreme values being used for this, as in earlier methods. The method is validated by applying it to synthetic and measured dips. It can be generalized for application to both single- and multi-stage dips. © 2017 Elsevier B.V.","Clustering algorithms; Electric power distribution; Electric power transmission; Logistic regression; Machine learning algorithms; Power quality; Voltage dips","Electric power distribution; Electric power transmission; Learning algorithms; Learning systems; Power quality; Regression analysis; Transients; Extreme value; K-Means clustering algorithm; Logistic regression algorithms; Logistic regressions; Neutral voltage; Phasor model; Single segments; Voltage dip; Clustering algorithms",2-s2.0-85029393979
"Chakravarthy V.V.S.S.S., Terlapu S.K., Chowdary P.S.R., Venkateswara Rao T., Satapathy S.C.","On the convergence of synthesis of desired nulls from circular arrays using flower pollination algorithm",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029821136&doi=10.1007%2f978-981-10-4280-5_50&partnerID=40&md5=8311a0ba139efa89bf7b7172cc2bab64","In this paper, Synthesis of sum patterns from circular arrays to generate desired nulls with reduced sidelobes using flower pollination algorithm is presented. The array design is first formulated as an optimization problem with the goal of reducing peak sidelobe level with a deep null. The objective of the FPA algorithm is to determine the optimized set of amplitude excitation coefficients to obtain the desired pattern. The patterns are numerically computed for different constraints and the results obtained are compared with those of genetic algorithm in the present paper. © Springer Nature Singapore Pte Ltd. 2018.","Circular array; Fitness function and radiation pattern; Flower Pollination Algorithm; Side lobe level","Genetic algorithms; Amplitude excitation; Array design; Circular arrays; Fitness functions; Optimization problems; Peak sidelobe level; Side lobes; Sidelobe levels; Optimization",2-s2.0-85029821136
"Lin M.","Application of optimized genetic algorithm in building energy-saving optimization control",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028384225&doi=10.1007%2f978-3-319-60744-3_20&partnerID=40&md5=56ddcb0a899f6a4e37b0b5c489589d86","As the concept of low carbon and green enjoys popular support, how to construct an energy-saving building system in the modern building project has gradually become a research hotspot in the industry. Based on the above background, this paper proposed an adaptive loop optimized genetic algorithm. On the basis of fully expounding the principles and advantages of this algorithm, this paper took residential housing in Xiangyang for example, introduced such optimized genetic algorithm and constructed a full set of building energy-saving optimization control system. The calculation and application results indicate that this optimized genetic algorithm can achieve bi-directional optimal control of building energy consumption and construction cost, and has good Adaptivity and portability. © 2018, Springer International Publishing AG.","Construction cost; Energy consumption; Energy-saving optimization control; Optimized genetic algorithm","Buildings; Carbon; Energy utilization; Genetic algorithms; Housing; Intelligent buildings; Intelligent systems; Optimization; Real time systems; Building energy consumption; Building energy saving; Calculation and applications; Construction costs; Energy-saving buildings; Modern buildings; Optimization control; Residential housings; Energy conservation",2-s2.0-85028384225
"Lee D., Kim J.","Autonomous algorithm for safety systems of the nuclear power plant by using the deep learning",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025811868&doi=10.1007%2f978-3-319-60204-2_8&partnerID=40&md5=0129ffc27ca852a916bfca087bee9583","This study aims to develop an autonomous algorithm to control the safety systems of nuclear power plant (NPP) by using the deep learning that is one of machine learning methods. The autonomous algorithm has two main goals. First, it achieves a high level of automation for nine safety functions of NPP. Second, the algorithm controls the nine safety functions in an integrated way. The function-based hierarchical framework is suggested to represent the multi-level structure that models NPP safety systems with the levels of goal, function and system. The function-based hierarchical framework is used to model the NPP for the application of the multi-system deep learning network. Multi-system deep learning network is applied to develop the algorithm for autonomous control. This approach enables the systematic analysis of power plant system and development of the database for the deep learning network. © Springer International Publishing AG 2018.","Autonomous algorithm; Deep-learning; Systems engineering","Education; Electric industry; Hierarchical systems; Human engineering; Learning algorithms; Learning systems; Nuclear energy; Nuclear fuels; Nuclear power plants; Safety engineering; Security systems; Systems engineering; Autonomous control; Learning network; Level of automations; Machine learning methods; Multi-level structures; Power plant system; Safety functions; Systematic analysis; Deep learning",2-s2.0-85025811868
"Moghram B.A., Nabil E., Badr A.","Ab-initio conformational epitope structure prediction using genetic algorithm and SVM for vaccine design",2018,"Computer Methods and Programs in Biomedicine",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032877099&doi=10.1016%2fj.cmpb.2017.10.011&partnerID=40&md5=a01b74524bff0e6414e704fc1e15aca3","Background and objective T-cell epitope structure identification is a significant challenging immunoinformatic problem within epitope-based vaccine design. Epitopes or antigenic peptides are a set of amino acids that bind with the Major Histocompatibility Complex (MHC) molecules. The aim of this process is presented by Antigen Presenting Cells to be inspected by T-cells. MHC-molecule-binding epitopes are responsible for triggering the immune response to antigens. The epitope's three-dimensional (3D) molecular structure (i.e., tertiary structure) reflects its proper function. Therefore, the identification of MHC class-II epitopes structure is a significant step towards epitope-based vaccine design and understanding of the immune system. Methods In this paper, we propose a new technique using a Genetic Algorithm for Predicting the Epitope Structure (GAPES), to predict the structure of MHC class-II epitopes based on their sequence. The proposed Elitist-based genetic algorithm for predicting the epitope's tertiary structure is based on Ab-Initio Empirical Conformational Energy Program for Peptides (ECEPP) Force Field Model. The developed secondary structure prediction technique relies on Ramachandran Plot. We used two alignment algorithms: the ROSS alignment and TM-Score alignment. We applied four different alignment approaches to calculate the similarity scores of the dataset under test. We utilized the support vector machine (SVM) classifier as an evaluation of the prediction performance. Results The prediction accuracy and the Area Under Receiver Operating Characteristic (ROC) Curve (AUC) were calculated as measures of performance. The calculations are performed on twelve similarity-reduced datasets of the Immune Epitope Data Base (IEDB) and a large dataset of peptide-binding affinities to HLA-DRB1*0101. The results showed that GAPES was reliable and very accurate. We achieved an average prediction accuracy of 93.50% and an average AUC of 0.974 in the IEDB dataset. Also, we achieved an accuracy of 95.125% and an AUC of 0.987 on the HLA-DRB1*0101 allele of the Wang benchmark dataset. Conclusions The results indicate that the proposed prediction technique “GAPES” is a promising technique that will help researchers and scientists to predict the protein structure and it will assist them in the intelligent design of new epitope-based vaccines. © 2017 Elsevier B.V.","ECEPP force field; Epitope tertiary structure prediction; GAPES; Genetic algorithm; Major histocompatibility complex (MHC) class-II; Vaccine design","Antigens; Binding energy; Bins; Bioinformatics; Calculations; Conformations; Forecasting; Genetic algorithms; Immune system; Molecules; Peptides; Statistical tests; Support vector machines; T-cells; Vaccines; Force fields; GAPES; Major histocompatibility complex; Major histocompatibility complex class; Receiver operating characteristic curves; Secondary structure prediction; Tertiary structures; Three-dimensional (3D) molecular structure; Epitopes; epitope; HLA DRB1 antigen; vaccine; ab initio calculation; antigen presenting cell; Article; binding affinity; comparative study; drug design; genetic algorithm; IC50; immune response; major histocompatibility complex; prediction; protein secondary structure; protein structure; support vector machine",2-s2.0-85032877099
"Hurtik P., Vajgl M.","Edge detection competition – Algorithms based on image represented by a fuzzy function",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029454710&doi=10.1007%2f978-3-319-66824-6_23&partnerID=40&md5=d1be9475928a327eb80986063f05bfdf","The contribution serves as a supporting report for outputs posted for EUSFLAT Competition on Edge Detection 2017. We present three different types of methods used for edge detection in an image. The methods differ in their interpretation of the term edge. The first one considers edges as thresholded gradient magnitudes. The second one reduces edges thickness in order to obtain 1px thin edges. The last one focuses on obtaining 1 pixel thin and continuous edges. The contribution describes the three methods, demonstrates their visual outputs and points their advantages and disadvantages. © 2018, Springer International Publishing AG.","Edge detection; Fuzzy image; Gradient detection","Fuzzy logic; Fuzzy sets; Pattern matching; Fuzzy function; Fuzzy image; Gradient detection; Gradient magnitude; Thin edge; Visual outputs; Edge detection",2-s2.0-85029454710
"Florin S., Sorin N., Romeo N., Anca P., Sergiu F.","Data acquisition and processing with fusion sensors, used in algorithms for increasing accuracy of position measurement of mobile robots",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031430512&doi=10.1007%2f978-3-319-62524-9_42&partnerID=40&md5=868c7c2a5ec05489017514c28ce80c32","For a mobile robot movement, the position measurement using internal reference sensors are of low accuracy. Encoder measurements are affected by skid, accelerometer results are affected by noise and final calculation by additive errors. In this paper is presented a method for acquiring and processing data in order to be used for the correction to be performed in order to determine the position of a mobile robot with increased accuracy. The used sensors in the proposed system are accelerometer and encoders, while the perturbation filtering is made with Kalman method. The data obtained from sensors are processed and analyzed, in order to reduce the measurement error. © Springer International Publishing AG 2018.","Accelerometer; Data processing; Encoder; Fusion sensors; Kalman filter; Mobile robot","Accelerometers; Data acquisition; Data processing; Kalman filters; Mobile robots; Position measurement; Robots; Signal encoding; Soft computing; Additive errors; Encoder; Encoder measurements; Fusion sensor; Reference sensors; Robot movements; Data handling",2-s2.0-85031430512
"Kanrar S., Chaki N., Chattopadhyay S.","Voting-based mutual exclusion algorithms",2018,"Studies in Systems, Decision and Control",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028967552&doi=10.1007%2f978-981-10-5559-1_5&partnerID=40&md5=365abfcef8b56b9bb5f722b910ae3d05","Concurrency control (Thomas in ACM Transactions on Database Systems 4(2):180–209, 1979; Stoica et al. in Proceedings of ACM SIGCOMM, 2001) for a distributed system is always quite challenging and is getting even more complex with the increasing sophistication of such systems. Voting is one of the relatively simpler techniques and does not bear high overhead. © Springer Nature Singapore Pte Ltd. 2018.",,,2-s2.0-85028967552
"Yu H., Wan Q., Lu X., Zhao C., Du Y.","A robust sub-pixel subdivision algorithm for image-type angular displacement measurement",2018,"Optics and Lasers in Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029366437&doi=10.1016%2fj.optlaseng.2017.09.006&partnerID=40&md5=43824ccc1a6d2c6c07c77c14600cd832","The use of an image detector to receive grating images and measure angle displacement via image processing is a relatively new technique, which yields higher resolution and better precision than the traditional moiré fringe method. To improve the robustness of image-type angle measurement, this paper proposes a robust sub-pixel subdivision algorithm based on the least square method. Firstly, by analyzing the characteristic of grating image, a new subdivision algorithm is established based on the least square method. Secondly, the simulations of robustness are completed to prove the performance in theoretically. Lastly, the proposed algorithm is used in a typical image-type angle sensor to test the performance in real case. By test, the proposed method is shown to be more accurate and with better robust than the traditional algorithm (centroid algorithm). In a typical image-type angle sensor, it successfully achieves a resolution of 0.62″ (21-bit), 213-fold subdivision resolution, and precision of 12.85″. The results presented here may provide a theoretical and technological foundation for further research on small-size, high-resolution photographic rotary encoders. © 2017","120.0280 130.6010 120.3930","Image processing; Pixels; 120.0280 130.6010 120.3930; Angular displacement measurement; Centroid algorithm; High resolution; Higher resolution; Least square methods; Sub-pixel subdivisions; Subdivision algorithms; Least squares approximations",2-s2.0-85029366437
"Anand A., Kar A., Swamy M.N.S.","An improved CLMS algorithm for feedback cancellation in hearing aids",2018,"Applied Acoustics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029309760&doi=10.1016%2fj.apacoust.2017.09.002&partnerID=40&md5=e3db57cfe467625192e0f8b53047b83d","In LMS algorithm-based feedback estimation, the value of the adaptation step size chosen imposes establishes a compromise between the speed at which the algorithm converges to the feedback-path estimate and the misadjustment between the true and estimated feedback paths at steady state. The combined LMS (CLMS) scheme overcomes this issue, but itself suffers from a sluggish adaptation of the mixture parameter during periods of a rapidly-varying or a stationary feedback path, leading to a degradation in the performance of the feedback canceller. In this work, we propose an acoustic feedback canceller with an improved affine combination of two different-step-size LMS filters, for a bias-less estimation of the acoustic feedback. The new filter-combiner parameter controls the filter combination and ensures at least a minimum adaptation of the mixture parameter for a stationary as well as a varying acoustic environment. We analyse the proposed algorithm for feedback reduction and prove that it performs as well as the element filters or even better in some situations, as compared to the CLMS algorithm. A detailed behaviour analysis of the proposed algorithm is also presented for scenarios of a stationary as well as a time-varying acoustic environment of the user. Simulation results verify the validity of the derived expressions. © 2017 Elsevier Ltd","Adaptive filters; Convex combination; Feedback cancellation; LMS; Stochastic algorithm","Adaptive filtering; Adaptive filters; Audition; Hearing aids; Mixtures; Stochastic systems; Acoustic environment; Acoustic feedback; Behaviour analysis; Convex combinations; Feedback cancellation; Feedback cancellers; Parameter control; Stochastic algorithms; Feedback",2-s2.0-85029309760
"Charkhgard H., Savelsbergh M., Talebian M.","A linear programming based algorithm to solve a class of optimization problems with a multi-linear objective function and affine constraints",2018,"Computers and Operations Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026749768&doi=10.1016%2fj.cor.2017.07.015&partnerID=40&md5=76b5c5b7bd36cd012f0f8aa3afa81bd4","We present a linear programming based algorithm for a class of optimization problems with a multi-linear objective function and affine constraints. This class of optimization problems has only one objective function, but it can also be viewed as a class of multi-objective optimization problems by decomposing its objective function. The proposed algorithm exploits this idea and solves this class of optimization problems from the viewpoint of multi-objective optimization. The algorithm computes an optimal solution when the number of variables in the multi-linear objective function is two, and an approximate solution when the number of variables is greater than two. A computational study demonstrates that when available computing time is limited the algorithm significantly outperforms well-known convex programming solvers IPOPT and CVXOPT, in terms of both efficiency and solution quality. The optimization problems in this class can be reformulated as second-order cone programs, and, therefore, also be solved by second-order cone programming solvers. This is highly effective for small and medium size instances, but we demonstrate that for large size instances with two variables in the multi-linear objective function the proposed algorithm outperforms a (commercial) second-order cone programming solver. © 2017 Elsevier Ltd","Convex programming; Linear programming; Multi-linear objective function; Pareto optimal solutions; Polynomial-time algorithm","Computational efficiency; Convex optimization; Linear programming; Multiobjective optimization; Optimal systems; Pareto principle; Polynomial approximation; Polynomials; Computational studies; Linear objective functions; Multi-objective optimization problem; Optimization problems; Pareto optimal solutions; Polynomial-time algorithms; Second order cone programs; Second-order cone programming; Optimization",2-s2.0-85026749768
"Tan Z., Du L., Feng D., Zhou W.","EML: An I/O scheduling algorithm in large-scale-application environments",2018,"Future Generation Computer Systems",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020168148&doi=10.1016%2fj.future.2017.04.019&partnerID=40&md5=80511fed80ab23264bef380ca614f603","Distributed file systems have been widely used in many applications to provide high performance. However, large amounts of data-intensive applications often access the data server concurrently, the average completion time is enlarged due to the long request queue on data servers, especially when requests of applications cause a series of synchronous I/O requests. This paper proposes an I/O scheduling algorithm, called EML (equal-length multi-level algorithm) to solve this problem, it can reduce the average response time significantly. We demonstrate the performance improvement versus multi-level queue through both theoretical and experimental analysis. The experiments show that EML algorithm can effectively reduce the average completion time by 30% in 64 concurrent write applications and 50% in 64 concurrent read applications. © 2017 Elsevier B.V.","EML; I/O scheduling algorithm; Multi-level queue","File organization; Queueing theory; Completion time; Data server; Distributed file systems; Experimental analysis; Large amounts of data; Large-scale applications; Multilevels; Synchronous I/O; Scheduling algorithms",2-s2.0-85020168148
"Perez J., Melin P., Castillo O., Valdez F., Gonzalez C., Martinez G.","Trajectory optimization for an autonomous mobile robot using the bat algorithm",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030691804&doi=10.1007%2f978-3-319-67137-6_25&partnerID=40&md5=6d3192196004f7d31b5607544194bb2b","This work uses the metaheuristic Bat Algorithm, and the main reason for its use is its speed of convergence, giving us the advantage of solving problems of optimization in a short time in comparison with other metaheuristic. We apply the Bat Algorithm in optimizing the trajectory of a unicycle mobile robot, which is the model considered in this work based on two wheels mounted on the same axis and a front wheel and the algorithm is responsible for building the best Type-1 fuzzy system once selected the best applied to the mobile robot model with the objective of following an established path with the least margin of error. © Springer International Publishing AG 2018.","Bat algorithm (BA); Mobile robot; Optimization; Type-1 fuzzy logic","Fuzzy logic; Mobile robots; Robots; Wheels; Autonomous Mobile Robot; Bat algorithms; Front wheels; Margin of error; Metaheuristic; Speed of convergence; Trajectory optimization; Optimization",2-s2.0-85030691804
"Dang T.T., Le H.M., Huynh C., Dinh A.","Lossy compression for medical images by using ideal cross-point regions and Lloyd’s algorithm",2018,"IFMBE Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030873769&doi=10.1007%2f978-981-10-4361-1_24&partnerID=40&md5=05354b868c1c677d0adf790feebcacb9","This paper presents a lossy compression scheme for images by using the theory of cross-point regions and Lloyd’s algorithm with non-uniform quantization. The main idea of the method is that the application of the non-uniform quantization of Lloyd’s algorithm over Ideal Cross-point Regions (ICR). This quantization is very effective because the process of coding to make the code word uses the probability of data bits being optimized by the theory of cross-point regions. This means it can increase the compression ratio with better image quality—higher Peak Signal to Noise Ratio (PSNR) and less Mean Square Error (MSE). The algorithm can be implemented in storing patients’ medical imaging from Magnetic Resonant Imaging (MRI), Computed Tomography (CT) scanner, and for real time processing such as telemedicine. ICR can be also applied in connection with other quantization methods to improve compression scheme. © Springer Nature Singapore Pte Ltd. 2018.","Cross-point regions; Gray code transformation; Lloyd’s algorithm","Biomedical engineering; Codes (symbols); Computerized tomography; Cosine transforms; Image coding; Image quality; Magnetic resonance imaging; Mean square error; Medical image processing; Medical imaging; Signal to noise ratio; Compression scheme; Computed tomography scanners; Cross point region; Gray code transformation; Non-uniform quantization; Peak signal to noise ratio; Realtime processing; S-algorithms; Image compression",2-s2.0-85030873769
"Buciakowski M., Pazera M., Witczak M.","Robust guaranteed cost control for nonlinear system using product reduction algorithm",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028359033&doi=10.1007%2f978-3-319-64474-5_7&partnerID=40&md5=d97cde5b761d675cd64d9af35ab576d3","The paper presents a robust Guaranteed Cost Control (GCC) for nonlinear system using Product Reduction Algorithm (PRA). The proposed approach starts with a general description of the nonlinear system with nonlinear term in the state equation and assumptions regarding to a nonlinear function. The subsequent part of the paper is concerned with the design of the robust controller using Linear Matrix Inequalities (LMIs). Next, an algorithm to solve linear optimization problem base on PRA is proposed. The final part presents results obtained for the two–tank system. © Springer International Publishing AG 2018.","Linear matrix inequality; Nonlinear system; Product reduction algorithm; Robust control","Cost effectiveness; Cost reduction; Equations of state; Fault tolerance; Linear programming; Matrix algebra; Nonlinear equations; Nonlinear systems; Optimization; Robust control; Robustness (control systems); General description; Linear optimization problems; Nonlinear functions; Nonlinear terms; Reduction algorithms; Robust controllers; Robust guaranteed cost control; State equations; Linear matrix inequalities",2-s2.0-85028359033
"El Alami H., Najid A.","A new fuzzy clustering algorithm to enhance lifetime of wireless sensor networks",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028669804&doi=10.1007%2f978-3-319-60834-1_8&partnerID=40&md5=884c12ef7893963f0987045557320365","Due to limitations of resource in wireless sensor networks (WSNs) enhancing the network lifetime has been of great concern. An efficient routing algorithm is known as clustering algorithm based routing protocol. In which getting optimal cluster heads (CHs) and a number of them has been defiance. In this paper, a new fuzzy clustering algorithm is proposed to maximize the lifetime of WSNs. Network field in this approach, contains two types of sensors: free sensors that communicate directly with sink, and clustered sensors that send the sensed data to the sink through CHs which are preselected. This approach uses fuzzy logic to select free sensor nodes and CHs with four fuzzy parameters. These parameters are energy level of sink and sensor proximity to the sink in terms of free sensors selection, and energy level of sensor node and centrality of sensors in terms of CHs selection. The main goal of our algorithm is to extend the lifetime of WSNs by minimizing distributing the workload on CHs. The simulation results show that our proposed is more efficient than SET protocol. © 2018, Springer International Publishing AG.","Cluster Heads; Clustering algorithm; Fuzzy logic; Wireless Sensor Networks","Computer circuits; Fuzzy clustering; Fuzzy logic; Sensor nodes; Wireless sensor networks; Cluster head; Efficient routing; Fuzzy parameter; Network lifetime; Set protocols; Sink-in; Wireless sensor network (WSNs); Clustering algorithms",2-s2.0-85028669804
"Shehu A., Hulaj A., Bajrami X.","An algorithm for edge detection of the image for application in WSN",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026775975&doi=10.1007%2f978-3-319-53934-8_25&partnerID=40&md5=a247cf8e0a5cf3640f4501f3ee3955f8","The conversion of the image in black and white image is a very important factor in the case of WSNs. This conversion affects the image size reduction. In other words, it affects energy saving and bandwidth transmission of sensor nodes. However, in this case, we can have a loss of details of image characteristics. With purpose of preserving the image characteristics, the edge detection as accurately as possible is a key factor. So, in this paper, we will present a new algorithm which enables the efficient realization of pixels detection that corresponds to the edges of the image captured by the sensor nodes. The results obtained with the application of this algorithm will be compared with results obtained from the application of traditional Filters. © Springer International Publishing AG 2018.","Algorithm; Edge detection; Filter; Image; Sensor","Algorithms; Energy conservation; Sensor nodes; Sensors; Black and white images; Filter; Image; Image characteristics; Key factors; Size reductions; Traditional filter; Edge detection",2-s2.0-85026775975
"Zhang Y., Gong D., Yao X., Lu Q.","Generating test data covering multiple paths using genetic algorithm incorporating with reducing input domain",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031426724&doi=10.1007%2f978-981-10-6499-9_70&partnerID=40&md5=a77b195069cdca6b1f062c20356543fe","The problem of efficiently generating test data covering multiple paths was focused on this study, and a method of generating test data covering multiple paths using a genetic algorithm incorporating with reducing the input domain of a program was presented. In this method, all target paths are first divided into several groups based on the same independent sub-path, and the input variables corresponding to the independent sub-path are determined. Then, a multi-population genetic algorithm is used to generate test data to cover these target paths, each sub-population generating test data covering target paths belonging to the same group. During the evolution, the input variables corresponding to the traversed independent sub-path are remained fixed, and the ranges of crossover and mutation operations are reduced, leading to these sub-populations’ search in a reduced input domain so that the efficiency of generating test data is improved. © 2018, Springer Nature Singapore Pte Ltd.","Genetic algorithms; Input domain; Software testing; Test data","Genetic algorithms; Intelligent systems; Population statistics; Testing; Crossover and mutation; Input domain; Input variables; Multi-population genetic algorithm; Multiple-path; Reduced inputs; Sub-populations; Test data; Software testing",2-s2.0-85031426724
"Selvi Ö., Yavuz S.","Design and dimensional optimization of a novel walking mechanism with firefly algorithm",2018,"Mechanisms and Machine Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025805223&doi=10.1007%2f978-3-319-60702-3_8&partnerID=40&md5=5c06b152fd922a70e506456d6ff788f7","In this paper, a walking mechanism named Atlas is proposed which is a Watt-I type 6 link mechanism. First, the geometry is proposed and then kinematic analysis is done that will be used for the synthesis problem. Furthermore, constraints and an objective function are obtained from kinematic analysis. Then, these constraints are implemented to the Firefly Algorithm and dimensional parameters are obtained for a desired step profile. Finally, these dimensional parameters are tested. © Springer International Publishing AG 2018.","Dimensional optimization; Firefly algorithm; Kinematic synthesis; Walking mechanisms","Bioluminescence; Kinematics; Dimensional parameters; Firefly algorithms; Kinematic Analysis; Kinematic synthesis; Link mechanisms; Objective functions; Synthesis problems; Walking mechanism; Optimization",2-s2.0-85025805223
"Wang L., Tang X.","Network time balance management based on TFRR optimization algorithm",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028436321&doi=10.1007%2f978-3-319-60744-3_19&partnerID=40&md5=8c88234f1a6286658a8a33b8a0e0a4fb","Network coordination work based on IEEE802.11 protocol will form a network blocking phenomenon when it was accessed into channels at a same site and the same site and with the same rate. According to the analysis of network throughput and fairness theories, this paper presents an optimization algorithm based on the accessibility of TFRR algorithm to network balance, so as to improve the network working performance and avoid the occurrence of channel blocking phenomenon through the round robin queue of adjustable time for. And the tests show that the theoretical basis of the algorithm is feasible in practice with a pure quadratic function, the minimum is reached within N iterations (excepting round-off error), but a non-quadratic function likely to makes slower progress. The subsequent search directions lose noncompliance requiring the search direction to be reset to the steepest descent direction at minimum for every N iterations, or earlier if the progress is contained. If every iteration is reset, then it turns it to the steepest. The algorithm will not work if it gets the minimum, determined when there is no progress after a direction reset (i.e. in the steepest descent direction), or if any tolerance criterion is reached. Within a linear approximation, the parameter α {\displaystyle \displaystyle \alpha} and the parameter β {\displaystyle \displaystyle \beta} are equal in the linear conjugate gradient method and they get the line searches. The conjugate gradient method will follow the narrow or ill-conditioned valleys and the steepest descent method slows down which follows a criss-cross pattern. © 2018, Springer International Publishing AG.","Network time balance; TFRR algorithm; WLAN network","Conjugate gradient method; Intelligent systems; Iterative methods; Real time systems; Routers; Steepest descent method; Descent directions; Linear approximations; Network coordinations; Network throughput; Optimization algorithms; Quadratic function; WLAN networks; Working performance; Optimization",2-s2.0-85028436321
"Sangdani M.H., Tavakolpour-Saleh A.R., Lotfavar A.","Genetic algorithm-based optimal computed torque control of a vision-based tracker robot: Simulation and experiment",2018,"Engineering Applications of Artificial Intelligence",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030685070&doi=10.1016%2fj.engappai.2017.09.014&partnerID=40&md5=1354c209bb68cd3e05177bcfc21487a6","In this paper, an optimal control scheme based on the application of genetic algorithm (GA) is applied to a tracker robot with machine vision capability. First, dynamic equations governing the robot system are extracted and then, kinematic relationships are acquired according to camera specifications. Then, the obtained open-loop model of the robot is simulated and its validity is evaluated through an experimental work. The computed torque control algorithm with conventional tuning technique is initially used to control the robotic system. However, it is found that tuning the mentioned robot controller via the conventional technique is not so effective due to the unseen hard non-linearity presented in the robot controller such as saturation of the actuators. Consequently, a more advanced GA-based optimal control scheme is proposed in this investigation. Thus, GA is used to obtain the optimum values of control constants based on a suitable cost function. Accordingly, a simulation study is conducted to highlight the superiority of the GA-based controller compared to the former algorithm. Besides, the linking approach of the vision subsystem to the robot controller is further described from both mathematical and experimental standpoints. Finally, the proposed visual tracker robot is developed and its performance to track a moving object on a circular as well as a butterfly-shape trajectory in the camera coordinates is investigated. The experimental results clearly reveal the effectiveness of the visual robot incorporating the optimal controller to follow the target trajectories and confirm the stability of the control system. © 2017 Elsevier Ltd","Genetic algorithm; Optimal control; Visual tracker robot","Cameras; Controllers; Cost functions; Genetic algorithms; Robots; Torque control; Computed torque control; Conventional techniques; Dynamic equations; Optimal control scheme; Optimal controller; Optimal controls; Simulation studies; Vision based trackers; Computer vision",2-s2.0-85030685070
"Bai J., Gao H., Gu X., Yang H.","A multi-dimensional genetic algorithm for spacecraft TT&C resources unified scheduling",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028352069&doi=10.1007%2f978-981-10-4837-1_13&partnerID=40&md5=645daf2f130315e4c38286958ca92943","Many researches at home and abroad applied genetic algorithm (GA) on the problem of space tracking, telemetry and command (TT&C) resource scheduling, which is a kind of time window limited constraint satisfaction problem, and many good effects are achieved. But these works mainly focused on the low earth orbit (LEO) spacecraft which has a short visible pass and the total pass is tracked usually, without considering the high earth orbit (HEO) which has long visible pass and usually only part of it is tracked. In this paper aiming at the characteristic of spacecraft TT&C resources unified allocation for HEO and LEO spacecraft, a multi-dimensional genetic encoding method is promoted to describe this problem. The corresponding elements of the algorithm including crossover operator and mutation operator are defined as well so that a multi-dimensional GA is built to solve this resources allocation problem. The simulation results show that this algorithm could solve the problem of TT&C resources management and unified allocation for LEO and HEO spacecraft effectively, as is confronted with the current domestic managing mode of “one net for multi-spacecraft”. © Tsinghua University Press, Beijing and Springer Nature Singapore Pte Ltd. 2018.","Genetic algorithm (GA); Multi-dimension encoding; Resource scheduling; Spacecraft TT&C","Constraint satisfaction problems; Encoding (symbols); Genetic algorithms; Problem solving; Scheduling; Signal encoding; Spacecraft; Telemetering; Crossover operator; Low earth orbit(LEO); Multi dimensions; Mutation operators; Resource-scheduling; Resources allocation; Resources management; Telemetry and command; Orbits",2-s2.0-85028352069
"Hu Y., Zhu X., Ma G.","Location prediction model based on K-means algorithm",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031420412&doi=10.1007%2f978-981-10-3773-3_66&partnerID=40&md5=9bfad12df5d6ff310940640a7de2b2fa","Location prediction is critical to mobile service because various kinds of applications tightly combined with object’s location. However, location prediction is a challenging work because the location captured is always not continuous and object’s behavior is uncertain and irregular. The prediction accuracy of many models is less than 30%. But the prediction accuracy is important to location prediction. It will directly affect the mobile services. So this paper is to improve prediction accuracy to provide more efficient mobile service. This paper proposes a location prediction model based on k-means algorithm and time matching. For the mobile service always region oriented, we first cluster history location using k-means algorithm to define several regions. Then we divide every day time into several segments and calculate the maximum probability location in every time segment. A trajectory of an object in one day is formed with trajectory model and trajectory updating model which is proposed in this paper. We can predict object’s location with time-matching method. At last, we do experiments with real location data which captured by APs. The prediction result with k-means is compared to the result without model based on k-means algorithm. The experiment result shows that prediction accuracy of our model is higher than the prediction without new model. So more location services can be provided to objects with this new model. © Springer Nature Singapore Pte Ltd. 2018.","Cluster; K-means; Location prediction; Prediction accuracy","Clustering algorithms; Location; Mobile telecommunication systems; Trajectories; Cluster; K-means; k-Means algorithm; Location prediction; Location services; Maximum probability; Prediction accuracy; Trajectory modeling; Forecasting",2-s2.0-85031420412
"Moussaoui M., Zaghdoud M., Akaichi J.","Clustering social network profiles using possibilistic C-means algorithm",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020444461&doi=10.1007%2f978-3-319-59480-4_42&partnerID=40&md5=c4757e7875b5fd4cdb035fc966b39211","Social networking has become one of the most useful tools in modern society. Unfortunately, terrorists are taking advantage of the easiness of accessing social networks and they have set up profiles to recruit, radicalize and raise funds. Most of these profiles have pages that existing as well as new recruits to join the terrorist groups see and share information. Therefore, there is a potential need of detecting terrorist communities in social network in order to search for key hints in posts that appear to promote the militants cause. Community detection has recently drawn intense research interest in diverse ways. However, it represents a big challenge of practical interest that has received a great deal of attention. Social network clustering allows the labeling of social network profiles that is considered as an important step in community detection process. In this paper, we used possibilistic c-means algorithm for clustering a set of profiles that share some criteria. The use of possibility theory version of k-means algorithm allows more flexibility when assigning a social network profile to clusters. We experimentally showed the efficiency of the use of possibilistic c-means algorithm through a detailed tweet extract, semantic processing and classification of the community detection process. © Springer International Publishing AG 2018.","Clustering; Community detection; Possibility theory; Social network analysis","Interactive computer systems; Multimedia services; Multimedia systems; Population dynamics; Semantics; Social networking (online); Terrorism; Clustering; Community detection; k-Means algorithm; Network Clustering; Possibilistic C-means; Possibility theory; Research interests; Semantic processing; Clustering algorithms",2-s2.0-85020444461
"Liu Z.-S.","Design and Performance Simulation of Direct Drive Hub Motor Based on Improved Genetic Algorithm",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030870313&doi=10.1007%2f978-3-319-68527-4_33&partnerID=40&md5=2bc46acf6486f1b5a42224538425d87e","By using improved genetic algorithm (IGA), a direct drive hub motor with high efficiency and low-cost was designed. According to the characteristics of the hub motor, a mathematical model for optimize of direct drive hub motor was established, and optimized calculation was extended, and finally a prototype was developed. The simulation results show that the novel direct-drive hub motor can meet the requirements of great torque when low speed and high speed when constant power, so it is very suitable for the vehicle. © 2018, Springer International Publishing AG.","Direct drive; Genetic algorithm; Hub motor; Improve; Simulation","Data handling; Genetic algorithms; Information analysis; Constant power; Direct drive; High Speed; High-efficiency; Hub motors; Improve; Performance simulation; Simulation; Digital storage",2-s2.0-85030870313
"Sun C., Li L., Liu Y.","An encryption algorithm for ROI images",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026736662&doi=10.1007%2f978-3-319-63856-0_53&partnerID=40&md5=b72162b7cdb0e320d6b66e41a5d0b994","According to JPEG2000 image encryption algorithm based on confusion of the wavelet coefficients cannot support region-of-interest(ROI) image coding, an encryption method for ROI images is proposed. The proposed method Generates the confusion table using Chaotic sequences, confuses the Wavelet coefficients inside each code blocks, and encrypts the sign bits using Chaotic sequences. The experimental results show that the proposed method has lower affection to the compression ratio, and has the ability to provide adequate key space to resist the brute attack. The proposed method is important to support ROI image coding. © Springer International Publishing AG 2018.","Chaotic sequences; Image encryption; JPEG2000; ROI","Codes (symbols); Image coding; Image processing; Image segmentation; Multimedia signal processing; Signal processing; Wavelet transforms; Chaotic sequence; Encryption algorithms; Encryption methods; Image encryption algorithm; Image encryptions; JPEG 2000; Support regions; Wavelet coefficients; Cryptography",2-s2.0-85026736662
"Dong Y., Pan Z., Ernawan M.E., Liu J., Shimamoto S., Wicaksono R.P., Kunishige S., Chang K.","Novel UE RF condition estimation algorithm by integrating machine learning",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022181162&doi=10.1007%2f978-981-10-5281-1_12&partnerID=40&md5=3da5ccda9c9aa2c5620a099019b08c82","By 2020, 5G era will be commercially available. The smart city construction will also make great progress. Compared to current situation, more than thousand times of devices will connect to the cellular networks. For the operators, in order to analyze overall network performance, it is a key factor to estimate the user equipment (UE) radio frequency (RF) condition. However, practical RF estimation scheme is based on UE data log which can only observe UE that is at the top-serving cell with good RF condition. However, according to the comparison of actual UE data log and the scanner data log, potential RF problems may still exist since the UE will not always be served by the top-1 cell. In this paper, we propose a novel estimation scheme by integrating machine learning (ML) algorithm to analyze the scanner data logs from the target estimation zones where the mobility problems may occur. A hypothesis is obtained from learning step by various kinds of RF condition as input features. The numerical results show that the proposed estimation algorithm integrated ML can estimate probability of the potential mobility problems accurately. © Springer Science+Business Media Singapore 2018.","Estimation; Machine learning; Mobility problem; RF condition","Artificial intelligence; Estimation; Information retrieval; Learning algorithms; Learning systems; Scanning; Smart city; Wireless telecommunication systems; Condition estimation; Estimation algorithm; Estimation schemes; Integrating machines; Potential mobility; Radio frequencies; RF condition; Target estimations; Education",2-s2.0-85022181162
"Sepúlveda C., Montiel O., Cornejo J.M., Sepúlveda R.","Estimation of population pharmacokinetic model parameters using a genetic algorithm",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030714417&doi=10.1007%2f978-3-319-67137-6_23&partnerID=40&md5=0bbd2d88379e6ac69ef99441bc1e8663","Nowadays, there is need to analyze data in such a way as to consider the interrelationships between variables that describe the behavior of such data. The analysis of multivariate data refers precisely to a wide variety of methods of description or inference for the analysis of these data so that the inter-relationships between the variables can be quantified and evaluated. One of the most useful methods is the nonlinear mixed effects modeling. Nonlinear mixed effects models have been implemented in a wide variety of disciplines such as social sciences, physics, and life sciences where complex data structures such as multivariate observations or longitudinal data are present. Implementing a nonlinear mixed effects model is an arduous and complicated task. This is because the estimation of the parameters is performed solving maximum likelihood functions that usually have no analytical solution. In this work, we presented an example of an implementation of nonlinear mixed effect modeling for the development of a population pharmacokinetic model using a genetic algorithm to improve the estimation of the population pharmacokinetic parameters. At the end of this work, we conducted the comparison between a classical estimation method and an estimation method using a genetic algorithm. © Springer International Publishing AG 2018.","Genetic algorithm; Longitudinal data; Maximum likelihood functions; Multivariate data; Nonlinear mixed effects models; Population pharmacokinetic model","Genetic algorithms; Graphical user interfaces; Maximum likelihood; Maximum likelihood estimation; Multivariant analysis; Nonlinear analysis; Pharmacokinetics; Population statistics; Longitudinal data; Maximum likelihood function; Multivariate data; Nonlinear mixed effects; Population pharmacokinetic models; Parameter estimation",2-s2.0-85030714417
"Saidala R.K., Devarakonda N.","Improved whale optimization algorithm case study: Clinical data of anaemic pregnant woman",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021224614&doi=10.1007%2f978-981-10-3223-3_25&partnerID=40&md5=9cb7f8511ce155d417d7120f32c6f2e6","WOA is a meta-heuristic algorithm possessing the proper potentiality in solving complex numerical function optimization problems. It works well, but poor in the convergence at exploration and exploitation phases. In order to enhance the convergence enforcement of WOA, a novel constitutional appraising strategy based WOA has been set forth in this paper. In this scenario, constituent states are fully utilized in each of the iterations to supervise the subsequent gazing process, and to counterbalance the local exploration with global exploitation. We fix up with the mechanism together with the convergence straight stuff of the enhanced algorithm. Comparable investigations are supervised on various mathematical benchmark function optimization problems. Simulation results confirm, with statistical significance, that the proposed scenario is more efficient in the convergence performance of WOA. In addition to this, we applied the same technique to a clinical dataset of an anaemic pregnant woman and obtained optimized clusters and cluster heads to secure a clear comprehension and meaningful insights in the clinical decision-making process. © Springer Nature Singapore Pte Ltd. 2018.","Clinical data analysis; Clinical decision-making process; Meta-heuristic optimization techniques; Outlier detection; WOA","Data handling; Decision making; Functions; Heuristic algorithms; Intelligent computing; Clinical data analysis; Clinical decision making; Exploration and exploitation; Meta heuristic algorithm; Meta-heuristic optimization techniques; Numerical function optimization; Outlier Detection; Statistical significance; Optimization",2-s2.0-85021224614
"Gozali A.A., Fujimura S.","Localization strategy for island model genetic algorithm to preserve population diversity",2018,"Studies in Computational Intelligence",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020457539&doi=10.1007%2f978-3-319-60170-0_11&partnerID=40&md5=345c2b5b25bb3f8c7eadb120fcc256c5","Years after being firstly introduced by Fraser and remodeled for modern application by Bremermann, genetic algorithm (GA) has a significant progression to solve many kinds of optimization problems. GA also thrives into many variations of models and approaches. Multi-population or island model GA (IMGA) is one of the commonly used GA models. IMGA is a multi-population GA model objected to getting a better result (aimed to get global optimum) by intrinsically preserve its diversity. Localization strategy of IMGA is a new approach which sees an island as a single living environment for its individuals. An island’s characteristic must be different compared to other islands. Operator parameter configuration or even its core engine (algorithm) represents the nature of an island. These differences will incline into different evolution tracks which can be its speed or pattern. Localization strategy for IMGA uses three kinds of single GA core: standard GA, pseudo GA, and informed GA. Localization strategy implements migration protocol and the bias value to control the movement. The experiment results showed that localization strategy for IMGA succeeds to solve 3-SAT with an excellent performance. This brand new approach is also proven to have a high consistency and durability. © Springer International Publishing AG 2018.","3-SAT; Genetic algorithms; Island model genetic algorithm; Localization strategy","Optimization; 3-SAT; Different evolutions; Island model genetic algorithm; Localization strategy; Migration protocols; Modern applications; Optimization problems; Population diversity; Genetic algorithms",2-s2.0-85020457539
"Dong Z., Cheng H.","Highly noise-tolerant hybrid algorithm for phase retrieval from a single-shot spatial carrier fringe pattern",2018,"Optics and Lasers in Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027573622&doi=10.1016%2fj.optlaseng.2017.08.011&partnerID=40&md5=a6ebbdd9d40bdc9d8048e61a3056cf26","A highly noise-tolerant hybrid algorithm (NTHA) is proposed in this study for phase retrieval from a single-shot spatial carrier fringe pattern (SCFP), which effectively combines the merits of spatial carrier phase shift method and two dimensional continuous wavelet transform (2D-CWT). NTHA firstly extracts three phase-shifted fringe patterns from the SCFP with one pixel malposition; then calculates phase gradients by subtracting the reference phase from the other two target phases, which are retrieved respectively from three phase-shifted fringe patterns by 2D-CWT; finally, reconstructs the phase map by a least square gradient integration method. Its typical characters include but not limited to: (1) doesn't require the spatial carrier to be constant; (2) the subtraction mitigates edge errors of 2D-CWT; (3) highly noise-tolerant, because not only 2D-CWT is noise-insensitive, but also the noise in the fringe pattern doesn't directly take part in the phase reconstruction as in previous hybrid algorithm. Its feasibility and performances are validated extensively by simulations and contrastive experiments to temporal phase shift method, Fourier transform and 2D-CWT methods. © 2017","Hybrid algorithm; Phase retrieval; Single-shot fringe pattern; Wavelet transform","Interferometry; Least squares approximations; Carrier phase shift; Fringe pattern; Hybrid algorithms; Integration method; Phase reconstruction; Phase retrieval; Spatial-carrier fringe patterns; Two-dimensional continuous wavelet transforms; Wavelet transforms",2-s2.0-85027573622
"Xiao Y., Cui G., Sun T., Chen J.","An integrated random walk algorithm with compulsive evolution and fine-search strategy for heat exchanger network synthesis",2018,"Applied Thermal Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029653881&doi=10.1016%2fj.applthermaleng.2017.09.075&partnerID=40&md5=9879afa6ad40582ad0b9cf3905369a6d","Heat exchanger network synthesis has been extensively studied in process system engineering for its complexity and difficulty resulting from stream matches and the nonlinearity of continuous variables. Stochastic methods have difficulties in finding the precise optimum solution on the near optimal regions and expanding the integer variables optimization in the late evolution. Therefore, a novel fine-search strategy was established on the basis of the evolutionary mechanism of random walk algorithm with compulsive evolution. The fine-search strategy was efficient in achieving the accuracy of solutions for a certain heat exchanger network structure. Then, the fine-search strategy and Random Walk algorithm with Compulsive Evolution were integrated to enhance and refine the optimization for continuous and integer variables in heat exchanger networks synthesis simultaneously. The integrated method could satisfy the needs of global and local search abilities for heat exchanger network synthesis. Finally, the proposed method was applied in three different-sized cases and more economical in contrast to the best results with no splits published thus far were obtained. © 2017 Elsevier Ltd","Fine-search strategy; Heat exchanger network synthesis; Integer variables optimization; Random Walk algorithm with Compulsive Evolution","Heat exchangers; Integer programming; Random processes; Stochastic systems; Continuous variables; Evolutionary mechanisms; Heat exchanger network; Heat exchanger network synthesis; Integer variables; Random walk algorithms; Search strategies; Stochastic methods; Optimization",2-s2.0-85029653881
"Ben Abdallah M.A., Khemili I., Laribi M.A., Aifaoui N.","Dynamic synthesis of a multibody system: A comparative study between genetic algorithm and particle swarm optimization techniques",2018,"Mechanisms and Machine Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026304739&doi=10.1007%2f978-3-319-60867-9_26&partnerID=40&md5=953b3eda2042fbf556316a2f7ccea05d","This paper proposes a dynamic synthesis of a flexible multibody systems, mainly, a slider crank mechanism incorporating a flexible connecting rod. Differently to classical synthesis, the mechanism design variables are identified by means of the mechanism dynamic responses such as, the velocity and the acceleration of the slider, and the flexible connecting rod transversal deflection. A comparative study between two optimization techniques, the genetic algorithm (GA) and the Particle Swarm Optimization (PSO), has been established. The two approaches employ different strategies and computational effort to find a solution to a given objective function. Thus, we are interested in the comparison of their implementation. The comparative study asserts that the PSO technique is more suitable for the dynamic synthesis. © Springer International Publishing AG 2018.","Dynamic synthesis; Flexible slider crank mechanism; GA; PSO","Connecting rods; Dynamics; Gallium; Genetic algorithms; Kinematics; Machine design; Optimization; Comparative studies; Computational effort; Dynamic synthesis; Flexible multibody systems; Genetic algorithm and particle swarm optimizations; Objective functions; Optimization techniques; Slider-crank mechanism; Particle swarm optimization (PSO)",2-s2.0-85026304739
"Soto R., Crawford B., Olivares R., Ortega H., Almonacid B.","An Imperialist Competitive Algorithm to Solve the Manufacturing Cell Design Problem",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029588839&doi=10.1007%2f978-3-319-67621-0_9&partnerID=40&md5=36ebe91df695d20b46dcb917a6b5da3a","The manufacturing cell design problem is part of the cellular manufacturing system and it has been widely studied as an optimization problem. It consists of grouping machines in parts into manufacturing cells in order to minimize the inter-cell movements. In recent years, different approximate methods have been used to solve this problem. In this paper, we propose a new approximate method inspired on the phenomenon of the colonial age, called imperialist competitive algorithm. In the colonial age, the most powerful countries competed to conquer colonies for increasing their power, where the country with highest power was considered the imperialist one. We performed several experiments on a set of 90 instances, where the proposed approach is able to produce optimal values for the whole set of tested instances. © 2018, Springer International Publishing AG.","Imperialist competitive algorithm; Manufacturing cell design problem; Metaheuristics","Approximation theory; Cells; Cellular manufacturing; Computational methods; Cytology; Flexible manufacturing systems; Manufacture; Optimization; Approximate methods; Cell design; Cell movement; Imperialist competitive algorithms; Meta heuristics; Optimal values; Optimization problems; Problem solving",2-s2.0-85029588839
"Sato H., Hirabayashi S., Takagi M.","Approximate algorithm for multi-source skyline queries on decentralized remote spatial databases",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020425967&doi=10.1007%2f978-3-319-59480-4_50&partnerID=40&md5=ab9989a147810ab38961c840553e8d7c","A multi-source skyline query about spatial data considers several query reference points at the same time, while a single-source skyline query refers to only one query point. Nowadays, supporting multisource skyline queries on decentralized remote spatial databases is much important, since (1) multi-source skyline queries about spatial data are effective for supporting spatial decision making in various tasks and (2) various kinds of spatial datasets are available on the Internet and are accessible via Web services provided. This paper proposes Approximate Algorithm for Multi-Source Skyline Queries on Decentralized Remote Spatial Databases (AMUSE). AMUSE finds the MIN-SUM data point regarding a set of query points first. Then, it makes a series of k-NN queries move on a half line connecting both a MIN-SUM data point and each query point. According to the experimental evaluation, AMUSE is excellent in Precision. Additionally, it is also excellent in Recall, except cases that the search area is large and/or k of k-NN queries to search for data points is small. © Springer International Publishing AG 2018.","Aggregate query; AMUSE; Approximate algorithm; Decentralized remote spatial database; Multi-source skyline query; Web service","Database systems; Decision making; Indexing (of information); Interactive computer systems; Multimedia services; Multimedia systems; Nearest neighbor search; Query languages; Web services; Websites; Aggregate queries; AMUSE; Approximate algorithms; Skyline query; Spatial database; Query processing",2-s2.0-85020425967
"Kwon K., Shin J.W., Kim N.S.","Incremental basis estimation adopting global k-means algorithm for NMF-based noise reduction",2018,"Applied Acoustics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030837889&doi=10.1016%2fj.apacoust.2017.08.008&partnerID=40&md5=f64980135bc61d73ef9aab3cbbcdce26","Nonnegative matrix factorization (NMF) is a data decomposition technique enabling to discover meaningful latent nonnegative components. Since, however, the objective function of NMF is non-convex, the performance of the source separation can degrade when the iterative update of the basis matrix in the training procedure is stuck to a poor local minimum. In most of the previous studies, the whole basis matrix for a specific source is iteratively updated to minimize a certain objective function with random initialization although a few approaches have been proposed for the systematic initialization of the basis matrix such as the singular value decomposition and k-means clustering. In this paper, we propose an approach to robust bases estimation in which an incremental strategy is adopted. Based on an analogy between clustering and NMF analysis, we estimate the NMF bases in a similar way to the global k-means algorithm popular in the data clustering area. Experiments on audio separation from noise showed that the proposed methods outperformed the conventional NMF technique using random initialization by about 2.04 dB and 2.34 dB in signal-to-distortion ratio when the target source was speech and violin, respectively. © 2017 Elsevier Ltd","Basis training; Global k-means; Incremental approach; Nonnegative matrix factorization; Source separation","Audio acoustics; Cluster analysis; Clustering algorithms; Factorization; Iterative methods; Separation; Singular value decomposition; Source separation; Global K-means algorithm; Incremental approach; Incremental Strategy; K-means; Nonnegative components; Nonnegative matrix factorization; Signal-to-distortion ratios; Training procedures; Matrix algebra",2-s2.0-85030837889
"Chowdhary C.L., Acharjya D.P.","Segmentation of mammograms using a novel intuitionistic possibilistic fuzzy c-mean clustering algorithm",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031405894&doi=10.1007%2f978-981-10-6747-1_9&partnerID=40&md5=18da04d0e367486c4d3159768a33b03d","There is a partitioning of a data set X into c-clusters in clustering analysis. In 1984, fuzzy c-mean clustering was proposed. Later, fuzzy c-mean was used for the segmentation of medical images. Many researchers work to improve the fuzzy c-mean models. In our paper, we proposed a novel intuitionistic possibilistic fuzzy c-mean algorithm. Possibilistic fuzzy c-mean and intuitionistic fuzzy c-mean are hybridized to overcome the problems of fuzzy c-mean. This proposed clustering approach holds the positive points of possibilistic fuzzy c-mean that will overcome the coincident cluster problem, reduces the noise and brings less sensitivity to an outlier. Another approach of intuitionistic fuzzy c-mean improves the basics of fuzzy c-mean by using intuitionistic fuzzy sets. Our proposed intuitionistic possibilistic fuzzy c-mean technique has been applied to the clustering of the mammogram images for breast cancer detector of abnormal images. The experiments result in high accuracy with clustering and breast cancer detection. © 2018, Springer Nature Singapore Pte Ltd.","Hesitation degree; Intuitionistic fuzzy c-mean; Membership degree; Non-membership degree; Possibilistic c-mean","Diseases; Fuzzy clustering; Fuzzy sets; Image segmentation; Mammography; Medical imaging; X ray screens; Fuzzy C mean clustering; Fuzzy c-mean clustering algorithm; Hesitation degrees; Intuitionistic Fuzzy C-Means; Intuitionistic fuzzy sets; Membership degrees; Possibilistic C-means; Segmentation of medical images; Clustering algorithms",2-s2.0-85031405894
"Rasheed T., Long P., Marquez-Gamez D., Caro S.","Tension distribution algorithm for planar mobile cable-driven parallel robots",2018,"Mechanisms and Machine Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025807521&doi=10.1007%2f978-3-319-61431-1_23&partnerID=40&md5=7a1f2d1368b61229ff0f62e61ca84f77","Cable-Driven Parallel Robots (CDPRs) contain numerous advantages over conventional manipulators mainly due to their large workspace. Reconfigurable Cable-Driven Parallel Robots (RCDPRs) can increase the workspace of classical CDPRs by modifying the geometric architecture based on the task feasibility. This paper introduces a novel concept of RCDPR, which is a Mobile CDPR (MCDPR) mounted on multiple mobile bases allowing the system to autonomously reconfigure the CDPR. A MCDPR composed of two mobile bases and a planar CDPR with four cables and a point mass is studied as an illustrative example. As the mobile bases containing the exit points of the CDPR are not fixed to the ground, the static and dynamic equilibrium of the mobile bases and the moving-platform of the MCDPR are firstly studied. Then, a real time Tentensions onto the mobilesion Distribution Algorithm (TDA) that computes feasible and continuous cable tension distribution while guaranteeing the static stability of mobile bases and the equilibrium of the moving-platform of a n = 2 Degree of Freedom (DoF) CDPR driven by n+2 cables is presented. © Springer International Publishing AG 2018.","Cable-driven parallel robot; Equilibrium; Mobile robot; Reconfigurability; Tension distribution algorithm","Cables; Degrees of freedom (mechanics); Fixed platforms; Manipulators; Mobile robots; Phase equilibria; Reconfigurable architectures; 2 degree of freedoms; Architecture-based; Distribution algorithms; Dynamic equilibria; Parallel robots; Reconfigurability; Static stability; Tension distribution; Robots",2-s2.0-85025807521
"Rajani P.K., Khaparde A., Ghuge A.D.","Implementation of video error concealment using block matching algorithm",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028402015&doi=10.1007%2f978-3-319-63673-3_44&partnerID=40&md5=ff0c2190bb7374fe18861aa3787ef6f9","Video Error Concealment is the error hiding technique in videos. In recent years, there is huge requirement of error concealment in video applications such as in video streaming, entertainment, advertisement, media, security, etc. The simulation on MATLAB for the error videos using Block matching algorithm (BMA) has been performed to achieve the concealed videos. From an error video, error frame is detected using Histogram and correlation. This frame is corrected using BMA. First step of BMA is to divide the current, frame, of a video into macroblock. Second step is to compare each of the macroblocks with a corresponding block and its adjacent neighbors in the frame or previous frame. Third step is to models the movement in a macroblock from one location to another. Last step is to calculate this movement for all the macro blocks that is comprising a frame. This error block is replaced by correct reference block. The quality of the error video and concealed video is measured using PSNR (Peak Signal to Noise Ratio) and SSIM (Structural Similarity Index Method). An improvement in quality is observed in concealed video. © 2018, Springer International Publishing AG.","Block matching algorithm; Error concealment; PSNR; SSIM","Error correction; Image coding; Image quality; Intelligent systems; MATLAB; Media streaming; Motion compensation; Signal to noise ratio; Video streaming; Block matching algorithms; Error concealment; PSNR; PSNR (peak signal to noise ratio); SSIM; Structural similarity indices; Video applications; Video error concealment; Errors",2-s2.0-85028402015
"Goyal V., Kant C.","An effective hybrid encryption algorithm for ensuring cloud data security",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031404804&doi=10.1007%2f978-981-10-6620-7_20&partnerID=40&md5=c0cece774617a9baa94df982043a3ab4","Cloud computing is one of the most research hot topics in IT industry nowadays. A lot of startup organizations are adopting cloud eagerly due to massive cloud facilities available with minimal investment; but as every coin has two sides, so with cloud. In the cloud, the user data is stored at some off-site location. So cloud data security is one of the main concerns of any organizations, before shifting to the cloud. The data owners can ensure the data security at its premises using firewalls, VPN (Virtual Private Network) like most used security options. But as data owner stores their sensitive data to remote servers and users access required data from these remote cloud servers, which is not under their control. So storing data outside client premises, raises the issue of data security. Thus, one of the primary research areas in cloud computing is cloud data protection. In this research paper, strategies followed include categorization of the data on the basis of their sensitivity and importance, followed by the various cryptography techniques such as the AES (a Symmetric Cryptography technique), SHA-1 (a Hashing technique), and ECC (Elliptic curve Cryptography (an Asymmetric Cryptography technique). Till date, most of the authors were using a single key for both encryption and decryption which is a weak target of various identified malicious attacks. Hence, in the designed hybrid algorithm, two separate keys are used for each encryption and decryption. The cloud user who wants to access cloud data, need to first register with CSP and cloud owner. After registration, user login id, password and OTP (One Time Password) sent to the user registered mobile number, are required to access the encrypted cloud data. © 2018, Springer Nature Singapore Pte Ltd.","AES; Cloud; Data security; ECC; Hybrid algorithm for cloud data security; SHA-1","Authentication; Big data; Cloud computing; Clouds; Computer system firewalls; Computer viruses; Network security; Public key cryptography; Security of data; Virtual private networks; Asymmetric cryptography; Elliptic curve cryptography; Encryption and decryption; Hashing techniques; Hybrid algorithms; One time passwords; SHA-1; Symmetric cryptography; Cryptography",2-s2.0-85031404804
"Mahata S., Saha S.K., Kar R., Mandal D.","Optimal design of fractional order low pass Butterworth filter with accurate magnitude response",2018,"Digital Signal Processing: A Review Journal",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032178938&doi=10.1016%2fj.dsp.2017.10.001&partnerID=40&md5=4aafdc72c354e4bbba0b8105d9f6e5f9","The design of (1+α) order, 0&lt;α&lt;1, low pass Butterworth filter approximated in terms of an integer order continuous-time transfer function using a nature-inspired optimization technique called Gravitational Search Algorithm (GSA) is presented in this paper. While approximations of the non-integer order Laplacian operator sα in terms of second order rational function using the continued fraction expansion method for the design of fractional order low pass Butterworth filters (FOLBFs) is recently reported in literature, however, such a design technique is non-optimal. In this work, the metaheuristic global search process of GSA efficiently explores and intensely exploits the nonlinear, non-uniform, multidimensional, and multimodal FOLBF design problem error landscape. At the end of the iterative search routine of GSA, the optimal values of the coefficients in terms of the third order rational approximations are achieved which accurately approximate the magnitude response of the ideal FOLBF. The proposed GSA based FOLBFs consistently achieve the best solution quality with the fastest convergence rate as compared with the designs based on Real coded Genetic Algorithm (RGA) and Particle Swarm Optimization (PSO). Comparison with the recent literature also demonstrates the superiority of the proposed designs. SPICE simulations justify the design feasibility of the proposed FOLBF models. © 2017 Elsevier Inc.","Butterworth filter; Fractional order; Gravitational Search Algorithm; Mann–Whitney U test; Metaheuristic optimization; Signal processing","Bandpass filters; Continuous time systems; Design; Genetic algorithms; Integer programming; Iterative methods; Learning algorithms; Low pass filters; Mathematical operators; Optimal systems; Optimization; Particle swarm optimization (PSO); Rational functions; Signal processing; Continued fraction expansion method; Fractional order; Gravitational search algorithm (GSA); Gravitational search algorithms; Meta-heuristic optimizations; Rational approximations; Real-coded genetic algorithm; Whitney; Butterworth filters",2-s2.0-85032178938
"Deo R.C., Ghorbani M.A., Samadianfard S., Maraseni T., Bilgili M., Biazar M.","Multi-layer perceptron hybrid model integrated with the firefly optimizer algorithm for windspeed prediction of target site using a limited set of neighboring reference station data",2018,"Renewable Energy",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030656566&doi=10.1016%2fj.renene.2017.09.078&partnerID=40&md5=06bcd99a8b0963cefdf2158d1f917fda","Long-term windspeed prediction is crucial for establishing the viability of wind as a clean energy option, including the selection of wind farm locations, feasibility studies on energy potential and the operation of wind energy conversion systems with minimal investment risk. To deliver this vital societal need, data-inexpensive artificial intelligence models relying on historical inputs can be a useful scientific contrivance by energy analysts, engineers and climate-policy advocates. In this paper, a novel approach is adopted to construct a multilayer perceptron (MLP) hybrid model integrated with the Firefly Optimizer algorithm (MLP-FFA) trained with a limited set of historical (monthly) data (2004–2014) for a group of neighboring stations to predict windspeed at target sites in north-west Iran. Subsequently, the MLP-FFA model is developed to minimize the error rate of the resulting hybrid model and applied at each of the eight target sites one-by-one (namely: Tabriz, Jolfa, Sarab, Marand, Sahand, Kaleybar, Maraghe and Mianeh) such that the seven neighboring (reference) sites are used for training and the remainder eighth site for testing purposes. To ascertain conclusive results, the hybrid model's ability to predict windspeed at each target site is cross-validated with the MLP model without the FFA optimizer and the statistical performance is benchmarked with root mean square error (RMSE), mean absolute error (MAE), Nash-Sutcliffe efficiency (ENS), Willmott's Index (d) and the Legates and McCabes Index (E1), including relative errors. For all eight target sites, the testing performance of the MLP-FFA model is found to be significantly superior than the classical MLP, resulting in lower values of the RMSE (0.202–0.50 ms−1 relative to 0.236–0.664 ms−1) and larger values of ENS, d and E1 (0.686–0.953 vs. 0.529–0.936, 0.874–0.976 vs. 0.783–0.966, 0.417–0.800 vs. 0.303–0.748). Despite a more accurate performance of hybrid models tested at each target site, the preciseness registered a distinct geographic signature with the least accurate result (for Kaleybar) and the most accurate result (for Jolfa). To accord with this result, we conclude that the utilization of the FFA as an add-in optimizer in a hybrid data-intelligent model leads to a significant improvement in the predictive accuracy, presumably due to the optimal weights attained in the hidden layer that allows a more robust feature extraction process. Accordingly, we establish that the hybrid MLP-FFA model can be explored further in a problem of long-term windspeed prediction with reference station input data, and feasibility studies on wind energy investments in data-scarce regions where a limited set of neighboring reference site data can be employed to forecast the target site windspeed. © 2017 Elsevier Ltd","Firefly algorithm (FFA); Hybrid predictive model; Multilayer perceptron; Prediction; Windspeed","Bioluminescence; Energy conversion; Errors; Flood control; Forecasting; Investments; Mean square error; Multilayer neural networks; Multilayers; Optimization; Planning; Wind power; Firefly algorithms; Multi layer perceptron; Predictive modeling; Robust feature extractions; Root mean square errors; Statistical performance; Wind energy conversion system; Windspeed; Climate models; accuracy assessment; artificial intelligence; model validation; performance assessment; wind farm; wind velocity; East Azerbaijan; Iran; Kaleybar; Mianeh; Sahand; Sarab; Tabriz",2-s2.0-85030656566
"Solanki P., Gopal G.","Image categorization using improved data mining technique",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031405458&doi=10.1007%2f978-981-10-6620-7_19&partnerID=40&md5=884aad2d0dd8c6dbd78481b324203d8b","Image categorization is one of the important branches of artificial intelligence. Categorization of images is a way of grouping images according to their similarity. Image categorization uses various features of images like texture, color component, shape, edge, etc. Categorization process has various steps like image preprocessing, object detection, object segmentation, feature extraction, and object classification. For the past few years, researchers have been contributing different algorithms in the two most common machine learning categories to either cluster or classify images. The goal of this paper is to discuss two of the most popular machine learning algorithms: Nearest Neighbor (k-NN) for image classification and Means clustering algorithm. After that, a Hybrid model of both the above algorithms is proposed. These algorithms are implemented in MATLAB; finally, the experimental results of each algorithm are presented and discussed. © 2018, Springer Nature Singapore Pte Ltd.","Image categorization; Means algorithm; Nearest neighbor (NN) algorithm","Artificial intelligence; Big data; Data mining; Feature extraction; Image classification; Image enhancement; Image segmentation; Imaging systems; Learning algorithms; Learning systems; Nearest neighbor search; Object detection; Color component; Image Categorization; Image preprocessing; Means clustering algorithm; Nearest neighbor algorithm; Nearest neighbors; Object classification; Object segmentation; Clustering algorithms",2-s2.0-85031405458
"Shen N., Lu X., Miao D.","Research and application of extracting data sampling point from time series database",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030863673&doi=10.1007%2f978-981-10-6496-8_70&partnerID=40&md5=338727fd287da4737b8610f438b98b8c","In order to solve the problem of extracting data points and displaying time curve of industrial process, the linear difference algorithm, median algorithm, maximum algorithm and minimum algorithm are proposed. The result shows that proposed algorithms can solve those problems and meet requirements of real-time data extraction in industry process. As a result, it has played a catalytic role for the application of time series database and the development of industrial process. © 2018, Springer Nature Singapore Pte Ltd.","Linear difference algorithm; Maximum algorithm minimum algorithm; Median algorithm; Time series database","Intelligent systems; Time series; Catalytic role; Difference algorithms; Industrial processs; Industry process; Median algorithms; Real-time data; Research and application; Time Series Database; Database systems",2-s2.0-85030863673
"Shah P., Oza R.","Improved parallel Rabin-Karp algorithm using compute unified device architecture",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028402583&doi=10.1007%2f978-3-319-63645-0_26&partnerID=40&md5=5f1d0df4196aee555a1e6a8db3a328be","String matching algorithms are among one of the most widely used algorithms in computer science. Traditional string matching algorithms are not enough for processing recent growth of data. Increasing efficiency of underlaying string matching algorithm will greatly increase the efficiency of any application. In recent years, Graphics processing units are emerged as highly parallel processor. They out perform best of the central processing units in scientific computation power. By combining recent advancement in graphics processing units with string matching algorithms will allows to speed up process of string matching. In this paper we proposed modified parallel version of Rabin-Karp algorithm using graphics processing unit. Based on that, result of CPU as well as parallel GPU implementations are compared for evaluating effect of varying number of threads, cores, file size as well as pattern size. © Springer International Publishing AG 2018.","Big data; CUDA; GPU; Parallel processing; Pattern matching; Rabin-Karp; String matching","Big data; Computer graphics; Computer graphics equipment; Efficiency; Image coding; Intelligent systems; Parallel architectures; Pattern matching; Program processors; String searching algorithms; Compute unified device architectures; CUDA; GPU implementation; Number of threads; Parallel processing; Rabin-Karp; Scientific computation; String matching; Graphics processing unit",2-s2.0-85028402583
"Chen J., Chen D.Q., Meng S.H.","A Novel Region Selection Algorithm for Auto-focusing Method Based on Depth from Focus",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030873573&doi=10.1007%2f978-3-319-68527-4_11&partnerID=40&md5=f361e9ab66d74b8a3b2f694372f85030","Region selection algorithm for auto-focusing method based on depth from focus plays an important role in obtaining a high-quality image. A novel algorithm is proposed after analyzing different region selection algorithms. Firstly, the gradient image is obtained through Scharr operator with improved templates. Then the region with maximum accumulation value is selected as the final auto-focusing region based on global searching with fixed step. The experiments show that the proposed algorithm is more accurate compared with other algorithms. © 2018, Springer International Publishing AG.","Auto-focusing; Depth from focus; Region selection; Scharr operator","Data handling; Image enhancement; Information analysis; Auto-focusing; Depth from focus; Global searching; Gradient images; High quality images; Region selection algorithms; Region selections; Scharr operator; Focusing",2-s2.0-85030873573
"Paliwal P., Kumar D.","ABC based neural network approach for churn prediction in telecommunication sector",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028406323&doi=10.1007%2f978-3-319-63645-0_38&partnerID=40&md5=41086c39e2985b9d83ed4a2dcb7c5b9b","Customer churn prediction has always been an important aspect of every business. Most of the companies have dedicated churn management teams which work for both churn prevention and churn avoidance. In both of the scenarios it is highly required to identify customers who may change their service providers. In this paper we have tried to propose a neural network based model to predict customer churn in telecommunication industry. We have than used Artificial Bee Colony (ABC) algorithm for neural network training and observed a substantial improvement in accuracy. To prove the efficacy of our model we have compared it against Genetic Algorithm (GA), Particle Swarm Optimization (PSO) and Ant Colony Optimization algorithm (ACO). Simulation result shows that ABC trained neural network is more accurate than others in predicting customer churn in telecommunication sector. © Springer International Publishing AG 2018.","Artificial bee colony; Customer churn; Evolutionary algorithms; Neural network; Swarm intelligence","Ant colony optimization; Artificial intelligence; Forecasting; Genetic algorithms; Human resource management; Intelligent systems; Neural networks; Optimization; Particle swarm optimization (PSO); Sales; Swarm intelligence; Telecommunication industry; Ant Colony Optimization algorithms; Artificial bee colonies; Artificial bee colony algorithms (ABC); Customer churn prediction; Customer churns; Neural network training; Telecommunication sector; Trained neural networks; Evolutionary algorithms",2-s2.0-85028406323
"Tan Z., Wang J., Peng Y., Ma F.","The admissions big data mining research based on real data from a normal university",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030844854&doi=10.1007%2f978-981-10-6496-8_49&partnerID=40&md5=997b886e4b37cb1edf8a3a1db4e8ad06","In this paper, a Normal University’s 2011–2016 real admissions data are analyzed by the Apriori, K-MEANS and KNN algorithm. The result shows that the university’s normal students are more likely to choose other normal majors than to choose other non-normal majors related the normal majors and the overall situation of the Normal University’s student enrollment is relatively stable. Liberal arts college is the most popular college. Chinese language and Literature (normal) and English (normal) are more popular in the Normal University. The result reveals the internal connection between the various majors and has a guiding role for specialties setup in the university. © 2018, Springer Nature Singapore Pte Ltd.","Admissions data; Apriori algorithm; K-MEANS algorithm; KNN algorithm","Big data; Intelligent systems; Learning algorithms; Admissions data; Apriori algorithms; Chinese language; Internal connections; k-Means algorithm; k-NN algorithm; Normal students; Student enrollments; Data mining",2-s2.0-85030844854
"Drabowski M.","Adaptation of ant colony algorithm for CAD of complex systems with higher degree of dependability",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020787352&doi=10.1007%2f978-3-319-59415-6_14&partnerID=40&md5=070e1bd31e75d0eab301c6afb299b036","The paper includes a proposal of a new algorithm for Computer Aided Design (CAD) of complex system with higher degree of dependability. Optimization: in scheduling of tasks, partitioning of resources, the allocation of task and resources are basic goals this algorithm. These optimization problems are NP-hard, but can be it solved efficiently e.g. by meta-heuristic algorithms. Presented the CAD algorithm based on Ant Colony Optimization may have a practical application in developing tools for rapid prototyping of such systems. The Ant Colony Optimization algorithm is a probabilistic technique for solving computational problems which can be reduced to finding good paths through graphs. © Springer International Publishing AG 2018.","Allocation; Ant Colony; CAD tools; Complex system; Dependable; Evaporation; Optimization; Partition; Pheromone; Scheduling","Ant colony optimization; Artificial intelligence; Computer aided design; Evaporation; Heuristic algorithms; Large scale systems; Partitions (building); Scheduling; Software prototyping; Allocation; Ant colonies; CAD tool; Dependable; Pheromone; Optimization",2-s2.0-85020787352
"Visheratin A.A., Melnik M., Nasonov D.","Dynamic resources configuration for coevolutionary scheduling of scientific workflows in cloud environment",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028669090&doi=10.1007%2f978-3-319-67180-2_2&partnerID=40&md5=c5839f63d3c861dc88c618889f77c0a6","Modern composite scientific applications, also called scientific workflows, require large processing capacities. Cloud environments provide high performance and flexible infrastructure, which can be easily employed for workflows execution. Since cloud resources are paid in the most cases, there is a need to utilize these resources with maximal efficiency. In this paper we propose dynamic resources coevolutionary genetic algorithm, which extends previously developed coevolutionary genetic algorithm for dynamic cloud environment by changing computational capacities of execution nodes on runtime. This method along with using two types of chromosomes – mapping of tasks on resources and resources configuration – allows to greatly extend the search space of the algorithm. Experimental results demonstrate that developed algorithm is able to generate solutions better than other scheduling algorithms for a variety of scientific workflows. © 2018, Springer International Publishing AG.","Coevolutionary algorithm; Dynamic coevolution; Genetic algorithm; Virtualization; Workflow scheduling","Genetic algorithms; Scheduling; Scheduling algorithms; Soft computing; Virtualization; Co-evolution; Co-evolutionary algorithm; Coevolutionary Genetic Algorithm; Computational capacity; Processing capacities; Scientific applications; Scientific workflows; Workflow scheduling; Computational complexity",2-s2.0-85028669090
"Agarwal R., Singh S., Vats S.","Review of parallel apriori algorithm on mapreduce framework for performance enhancement",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031410450&doi=10.1007%2f978-981-10-6620-7_38&partnerID=40&md5=71785ff38c80ffff5e91b3fffe84e638","Finding frequent itemsets in the large transactional database is considered as one of the most and significant issues in data mining. Apriori is one of the popular algorithms that widely used as a solution of addressing the same issue. However, it has computing power shortage to deal with large data sets. Various modified Apriori-like algorithms have been proposed to enhance the performance of traditional Apriori algorithm that works on distributed platform. Developing efficient and fast computing algorithm to handle large data sets becomes a challenging task due to load balancing, synchronisation and fault-tolerance issue. In order to overcome these problems, MapReduce model comes into existence, originally introduced by Google. MapReduce model-based parallel Apriori algorithm finds the frequent itemsets from large data sets using a large number of computers in distributed computational environment. In this paper, we mainly focused on parallel Apriori algorithm and its different versions based on approaches used to implement them. We also explored on current major open issues and extensions of MapReduce framework along with future research directions. © 2018, Springer Nature Singapore Pte Ltd.","Big data; Frequent itemsets; Hadoop; MapReduce; Parallel Apriori","Computer supported cooperative work; Data mining; Fault tolerance; Learning algorithms; Apriori; Computational environments; Future research directions; Hadoop; Item sets; Map-reduce; Performance enhancements; Transactional database; Big data",2-s2.0-85031410450
"Xiaofang G.","A new decomposition many-objective evolutionary algorithm based on - Efficiency order dominance",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026731196&doi=10.1007%2f978-3-319-63856-0_30&partnerID=40&md5=6d31d8c8cf4bdf816d4d2037d817f15b","Decomposition-based evolutionary algorithms are promising for handling many objective optimization problems with more than three objectives in the past decade. In the proposed algorithm, we develop a new dominance relation based on - efficiency order dominance (MOEA/D-εEOD) in each sub-problem to realize the selection and update of the individuals. Besides, a dynamic adaptive weight vector generation method is proposed, which is able to dynamically adjust the weight vector setting according to the current distribution of the non-dominated solution set. The proposed algorithm has been tested extensively on six widely used benchmark problems, and an extensive comparison indicates that the proposed algorithm offers competitive advantages in convergence and diversity. © Springer International Publishing AG 2018.","Decomposition; Many-objective; ε-dominance efficiency order rank","Competition; Decomposition; Efficiency; Multimedia signal processing; Optimization; Signal processing; Bench-mark problems; Competitive advantage; Current distribution; Dominance relation; Dynamic-adaptive; Many-objective; Many-objective optimizations; Nondominated solutions; Evolutionary algorithms",2-s2.0-85026731196
"Kanimozhi K.V., Venkatesan M.","A novel map-reduce based augmented clustering algorithm for big text datasets",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021221326&doi=10.1007%2f978-981-10-3223-3_41&partnerID=40&md5=cd4a538c9de839ce8eecb61d47e2f5d1","Text clustering is a well known technique for improving quality in information retrieval, In Today’s real world data is not organized in the essential manner for a precise mining, given a large unstructured text document collection it is essential to organize into clusters of related documents. It is a contemporary challenge to explore compact and meaning insights from large collections of the unstructured text documents. Although many frequent item mining algorithms have been discovered yet most do not scale for “Big Data” and also takes more processing time. This paper presents a high scalable speedy and efficient map reduce based augmented clustering algorithm based on bivariate n-gram frequent item to reduce high dimensionality and derive high quality clusters for Big Text documents and also the comparative analysis is shown for the sample text datasets with stop word removal the proposed algorithm performs better than without stop word removal. © Springer Nature Singapore Pte Ltd. 2018.","Clustering; Frequent item; Similarity; Text documents","Big data; Data mining; Intelligent computing; Clustering; Comparative analysis; Frequent item; Frequent item minings; High dimensionality; Similarity; Text document; Unstructured texts; Clustering algorithms",2-s2.0-85021221326
"Venkatesh V., Raj P., Balakrishnan P.","An energy-efficient fuzzy based data fusion and tree based clustering algorithm for wireless sensor networks",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032677032&doi=10.1007%2f978-3-319-68385-0_2&partnerID=40&md5=443ee8120eb337d89b794a7992988c5a","The realization of any wireless sensor network (WSNs) clearly determined on how the key quality of service (QoS) attributes/non-functional requirements (NFRs) gets accomplished. The well-known issues to be taken into account while designing WSNs for setting up smarter environments are information precision (timeliness and accuracy), data accretion, network latency, and energy efficiency. A wisely employed clustering algorithm for interconnecting sensor nodes can significantly enhance the energy efficiency of WSNs. However, the aspect of clustering involves additional overheads due to cluster head selection and cluster construction. This research work proposes a workaround that utilizes Type-II fuzzy for fusing the data and tree driven clustering algorithm that employs Type-2 fuzzy logic to improve the QoS parameters as well as preserving the power/energy of sensor networks. The primary objectives of the proposed cluster algorithm are two folded. Firstly, it constructs the clusters and chooses the cluster head (CH) by considering the remaining energy in the nodes and its distance from the base station (BS). Secondly, it performs the data fusion which contains meaningful information that has been sensed and captured. An extensive experimental analysis has been done on the proposed FBDF-TBC method by comparing it against its counterparts. The simulation results conclude that the proposed fuzzy-based technique for data fusion and tree-based clustering routing algorithm (FBDF-TBC) outperforms other clustering algorithms and improves the overall network lifetime of WSN from a minimum of 16% to maximum of 76%. © Springer International Publishing AG 2018.","Data fusion; Delay; Fuzzy based clustering; Mobile sensor networks; Network lifetime; Routing protocol","Data fusion; Energy efficiency; Fuzzy logic; Intelligent systems; Network routing; Power management (telecommunication); Quality of service; Routing protocols; Sensor data fusion; Sensor nodes; Trees (mathematics); Wireless sensor networks; Based clustering; Cluster construction; Cluster-head selections; Delay; Experimental analysis; Mobile sensor networks; Network lifetime; Wireless sensor network (WSNs); Clustering algorithms",2-s2.0-85032677032
"Lalwani A., Banerjee S., Kindo M.M., Ali S.Z.","An obscure method for clustering in android using k-medoid and apriori algorithm",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028382894&doi=10.1007%2f978-3-319-63673-3_9&partnerID=40&md5=fd90b19bb12863efc85a086bfbde810f","In today’s scenario, there is quick evolution in each field which contains majority and distinctive sorts of information. In order to differentiate sample data from the other, the amalgamation of data mining techniques with other useful algorithms is done. Android development is one of the major arena where there is tremendous need to execute these calculations. Combining frequent pattern calculation with clustering is extremely efficacious for android. In this paper the work is done in two levels, initial stage concentrates on generation of clusters and final stage deals with finding the frequent patterns. © 2018, Springer International Publishing AG.","Android; Clustering; Itemsets","Data mining; Intelligent systems; Metals; Android; Apriori algorithms; Clustering; Item sets; K-medoid; Sample data; Android (operating system)",2-s2.0-85028382894
"Sioud A., Gagné C.","Enhanced migrating birds optimization algorithm for the permutation flow shop problem with sequence dependent setup times",2018,"European Journal of Operational Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021738804&doi=10.1016%2fj.ejor.2017.06.027&partnerID=40&md5=287749ca4f69eab71ac8b04fdca76f5a","This paper presents an enhanced migrating bird optimization (MBO) algorithm and a new heuristic for solving a scheduling problem. The proposed approaches are applied to a permutation flowshop with sequence dependent setup times and the objective of minimizing the makespan. In order to augment the MBOs intensification capacity, an original problem specific heuristic is introduced. An adapted neighborhood, a tabu list, a restart mechanism and an original process for selecting a new leader also improved the MBO's behavior. Using benchmarks from the literature, the resulting enhanced MBO (EMBO) gives state-of-the-art results when compared with other algorithms reference. A statistical analysis of the numerical experiments confirms the relative efficiency and effectiveness of both EMBO and the new heuristic. © 2017 Elsevier B.V.","Makespan; Migrating birds optimization; Permutation flowshop; Scheduling; Sequence dependent setup times","Birds; Problem solving; Scheduling; Tabu search; Makespan; Migrating birds; Numerical experiments; Optimization algorithms; Permutation flow shops; Relative efficiency; Scheduling problem; Sequence-dependent setup time; Optimization",2-s2.0-85021738804
"Mohanapriya N., Kousalya G.","Optimized cost-based biomedical workflow scheduling algorithm in cloud",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030166868&doi=10.1007%2f978-3-319-67934-1_40&partnerID=40&md5=1f951df1ea781c3d04a3d07b79dad292","Owing to the data deluge of biomedical workflow applications, researchers consider cloud as a promising environment for deploying biomedical workflow applications. As the Workflow applications consist of precedence-constrained tasks, it requires high computing resources for its execution. Scheduling of pertinent resource to biomedical workflow applications is an appealing research area. The key concern is that the workflow applications should be scheduled with the appropriate resource such that the overall execution time and cost would be minimized and correspondingly resource utilization is maximized. The proposed Optimized Cost Scheduling Algorithm (OCSA) addresses this issue by scheduling the workflows to a resource in such a way that it efficiently reduces the time and cost. The proposed OCSA algorithm is simulated rigorously in WorkflowSim on real biomedical workflow application and the results are compared with the existing workflow scheduling approaches in terms of cost and time. The simulation result shows that the proposed scheduling algorithm appreciably reduces the execution time and cost than the existing scheduling algorithms. © Springer International Publishing AG 2018.","Biomedical workflow scheduling; Cloud scheduling; Cost based scheduling; Workflows in the cloud","Bioinformatics; Cost reduction; Costs; Scheduling; Signal processing; Cloud scheduling; Computing resource; Constrained tasks; Cost-based scheduling; Resource utilizations; Work-flows; Workflow applications; Workflow scheduling; Scheduling algorithms",2-s2.0-85030166868
"Gu X., Angelov P., Kangin D., Principe J.","Self-Organised direction aware data partitioning algorithm",2018,"Information Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029700275&doi=10.1016%2fj.ins.2017.09.025&partnerID=40&md5=bdcf57965a650b9c8087e6b3d2b888d7","In this paper, a novel fully data-driven algorithm, named Self-Organised Direction Aware (SODA) data partitioning and forming data clouds is proposed. The proposed SODA algorithm employs an extra cosine similarity-based directional component to work together with a traditional distance metric, thus, takes the advantages of both the spatial and angular divergences. Using the nonparametric Empirical Data Analytics (EDA) operators, the proposed algorithm automatically identifies the main modes of the data pattern from the empirically observed data samples and uses them as focal points to form data clouds. A streaming data processing extension of the SODA algorithm is also proposed. This extension of the SODA algorithm is able to self-adjust the data clouds structure and parameters to follow the possibly changing data patterns and processes. Numerical examples provided as a proof of the concept illustrate the proposed algorithm as an autonomous algorithm and demonstrate its high clustering performance and computational efficiency. © 2017 Elsevier Inc.","Autonomous learning; Clustering; Cosine similarity; Empirical Data Analytics (EDA); Nonparametric; Traditional distance metric","Clustering algorithms; Computational efficiency; Autonomous learning; Clustering; Cosine similarity; Distance metrics; Empirical data; Non-parametric; Data handling",2-s2.0-85029700275
"Yang X., Liao A., Xie J.","A remark on joint sparse recovery with OMP algorithm under restricted isometry property",2018,"Applied Mathematics and Computation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028317365&doi=10.1016%2fj.amc.2017.07.081&partnerID=40&md5=08d5243676f896b54d0ba0c793cf753a","The theory and algorithms for recovering a sparse representation of multiple measurement vector (MMV) are studied in compressed sensing community. The sparse representation of MMV aims to find the K-row sparse matrix X such that Y=AX, where A is a known measurement matrix. In this paper, we show that, if the restricted isometry property (RIP) constant δK+1 of the measurement matrix A satisfies δK+1&lt;1K+1, then all K-row sparse matrices can be recovered exactly via the Orthogonal Matching Pursuit (OMP) algorithm in K iterations based on Y=AX. Moreover, a matrix with RIP constant δK+1=1K+0.086 is constructed such that the OMP algorithm fails to recover some K-row sparse matrix X in K iterations. Similar results also hold for K-sparse signals recovery. In addition, our main result further improves the proposed bound δK+1=1K by Mo and Shen [12] which can not guarantee OMP to exactly recover some K-sparse signals. © 2017 Elsevier Inc.","Compressed sensing; Greedy algorithms; Joint sparse recovery; Orthogonal Matching Pursuit; Restricted isometry property","Compressed sensing; Matrix algebra; Signal reconstruction; Greedy algorithms; Measurement matrix; Multiple measurement vector (MMV); Orthogonal matching pursuit; Restricted isometry properties; Restricted isometry properties (RIP); Sparse recovery; Sparse representation; Recovery",2-s2.0-85028317365
"Kotowska J., Markowski M., Burduk A.","Optimization of the supply of components for mass production with the use of the ant colony algorithm",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028624143&doi=10.1007%2f978-3-319-64465-3_34&partnerID=40&md5=9422a9e35c33a6eddc36762d759d434c","The paper raises the issue of adapting the logistics processes to the changes in the manufacturing area. The continuous improvement of production processes enforces searching for better solutions for the milk run to achieve shorter time of the milk run loop. In the paper we propose integer linear programming (ILP) model ant the intelligent ant-colony based meta-heuristic algorithm for the milkman problem. The tuning process of algorithm and the verification of algorithm performance are reported in the paper. Proposed algorithm is then utilized for solving real-life production line provisioning problem. © Springer International Publishing AG 2018.","Ant colony optimization (ACO); Intelligent optimization methods of production systems; Logistics processes; Meta-heuristics; Milk run","Artificial intelligence; Heuristic algorithms; Heuristic methods; Integer programming; Intelligent systems; Maintenance; Optimization; Production; Ant Colony Optimization (ACO); Logistics process; Meta heuristics; Milk run; Production system; Ant colony optimization",2-s2.0-85028624143
"Mo D., Duarte M.F.","Compressive parameter estimation via K-median clustering",2018,"Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025120234&doi=10.1016%2fj.sigpro.2017.07.003&partnerID=40&md5=070d52d46854b0bc6bf3462301c283c5","Compressive sensing (CS) has attracted significant attention in parameter estimation tasks, where parametric dictionaries (PDs) collect signal observations for a sampling of the parameter space and yield sparse representations for signals of interest when the sampling is dense. While this sampling also leads to high dictionary coherence, one can leverage structured sparsity models to prevent highly coherent dictionary elements from appearing simultaneously in the recovered signal. However, the resulting approaches depend heavily on the careful setting of the maximum allowable coherence; furthermore, their guarantees are not concerned with general parameter estimation performance. We propose the use of earth mover's distance (EMD), as applied to a pair of true and estimated PD coefficient vectors, to measure the parameter estimation error. We formally analyze the connection between the EMD and the parameter estimation error and show that the EMD provides a better-suited metric for parameter estimation performance than the Euclidean distance. Additionally, we analyze the previously described relationship between K-median clustering and EMD-optimal sparse approximation and leverage it to develop improved PD-based parameter estimation algorithms. Numerical experiments verify our theoretical results, showing that the proposed compressive parameter estimation algorithms have performance similar to state-of-the-art algorithms while featuring simpler implementation and broader applicability. © 2017 Elsevier B.V.","Compressive sensing; Earth mover's distance; K-median clustering; Parameter estimation; Parametric dictionary","Approximation algorithms; Clustering algorithms; Compressed sensing; Signal reconstruction; Signal sampling; Compressive sensing; Earth Mover's distance; Estimation performance; K-median clustering; Parameter estimation algorithm; Parameter estimation errors; Sparse approximations; State-of-the-art algorithms; Parameter estimation",2-s2.0-85025120234
"Tang Z., Zhang X., Li K., Li K.","An intermediate data placement algorithm for load balancing in Spark computing environment",2018,"Future Generation Computer Systems",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85001967889&doi=10.1016%2fj.future.2016.06.027&partnerID=40&md5=cfd984d6a2b028469c5f5ccc7a3934e6","Since MapReduce became an effective and popular programming framework for parallel data processing, key skew in intermediate data has become one of the important system performance bottlenecks. For solving the load imbalance of bucket containers in the shuffle process of the Spark computing framework, this paper proposes a splitting and combination algorithm for skew intermediate data blocks (SCID), which can improve the load balancing for various reduce tasks. Because the number of keys cannot be counted out until the input data are processed by map tasks, this paper provides a sampling algorithm based on reservoir sampling to detect the distribution of the keys in intermediate data. Contrasting with the original mechanism for bucket data loading, SCID sorts the data clusters of key/value tuples from each map task according to their sizes, and fills them into the relevant buckets orderly. A data cluster will be split once it exceeds the residual volume of the current bucket. After filling this bucket, the remainder cluster will be entered into the next iteration. Through this processing, the total size of data in each bucket is roughly scheduled equally. For each map task, each reduce task should fetch the intermediate results from a specific bucket, the quantity in all buckets for a map task will balance the load of the reduce tasks. We implement SCID in Spark 1.1.0 and evaluate its performance through three widely used benchmarks: Sort, Text Search, and Word Count. Experimental results show that our algorithms can not only achieve higher overall average balancing performance, but also reduce the execution time of a job with varying degrees of data skew. © 2016 Elsevier B.V.","Data sampling; Data skew; Load balancing; MapReduce; Spark","Benchmarking; Electric sparks; Iterative methods; Resource allocation; Computing environments; Data placement algorithms; Data sampling; Data skew; Map-reduce; Parallel data processing; Performance bottlenecks; Programming framework; Data handling",2-s2.0-85001967889
"Łapa K.","Population-based algorithm with selectable evolutionary operators for nonlinear modeling",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029483442&doi=10.1007%2f978-3-319-67220-5_2&partnerID=40&md5=07056e550ff3bfb88300f93090f2b7b7","In this paper a new population-based algorithm for nonlinear modeling is proposed. Its advantage is the automatic selection of evolutionary operators and their parameters for individuals in population. In this approach evolutionary operators are selected from a large set of operators, however only the solutions that use low number of operators are promoted in population. Moreover, assigned operators can be changed during evolution of population. Such approach: (a)Â eliminates the need for determining detailed mechanism of the population-based algorithm, and (b)Â reduces the complexity of the algorithm. For the simulations typical nonlinear modeling benchmarks are used. © 2018, Springer International Publishing AG.","Fuzzy systems; Nonlinear modeling; Population-based algorithms; Selection of evolutionary operators",,2-s2.0-85029483442
"de la O D., Castillo O., Astudillo L., Soria J.","Fuzzy chemical reaction algorithm with dynamic adaptation of parameters",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030703799&doi=10.1007%2f978-3-319-67137-6_13&partnerID=40&md5=4970b2b1ac0a1b3237c673e5c6abc450","In this research work, we used the Chemical Reaction Algorithm (CRA) for solving optimization problems. The used optimization algorithm is based on an abstraction of chemical reactions. The main goal of the method is to dynamically adjust the parameters of the reactions in the range from 0.1 to 1. The impact of using fixed parameters in the CRA is discussed and then a strategy for efficiently tuning these parameters using fuzzy logic is presented. The Fuzzy CRA algorithm was successfully applied on different benchmarking optimization problems. The results of simulations and comparison studies demonstrate the effectiveness and efficiency of the proposed approach. © Springer International Publishing AG 2018.",,"Chemical reactions; Fuzzy logic; Comparison study; Dynamic adaptations; Effectiveness and efficiencies; Optimization algorithms; Optimization problems; Optimization",2-s2.0-85030703799
"Prathusha P., Jyothi S.","A novel edge detection algorithm for fast and efficient image segmentation",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021231670&doi=10.1007%2f978-981-10-3223-3_26&partnerID=40&md5=f9342ba83cf7f989b841e4c9f2210c32","Edge detection determines the boundaries of objects in an Image. Edge detection is a vital concept in object recognition and Image analysis. This paper evaluates the existing edge detection methods and proposes a new edge detection algorithm which uses the morphological operations, sobel operator, Gaussian Smoothing and masking. The novelty of the proposed algorithm is extracting continuous edges in the Image and removing spurious edges using m-connectivity. The paper introduces performance parameters for edge detection to determine which method gives good results. A parameter named Human Perception Clarity (HPC) is mathematically modeled and experimentally proves the efficacy of proposed algorithm. © Springer Nature Singapore Pte Ltd. 2018.","Canny edge detection; Edge detection operators; Human perception clarity; Image segmentation methods; Otsu segmentation","Image segmentation; Intelligent computing; Mathematical morphology; Object recognition; Signal detection; Canny edge detection; Edge detection algorithms; Edge detection methods; Edge-detection operators; Human perception; Morphological operations; Performance parameters; Segmentation methods; Edge detection",2-s2.0-85021231670
"Wang Y., Chen J., Ren C., Chang H.","Green distributed power control algorithm for multi-user cognitive radio networks",2018,"Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031301952&doi=10.1007%2f978-3-319-66628-0_10&partnerID=40&md5=0e67940f5afcad7f9a99488b39d78040","Considering both system energy efficiency (EE) and the implementation of distributed power control algorithm in multi-user cognitive radio networks (CRNs), a multi-leader Stackelberg power control game algorithm is proposed to achieve continuous Pareto improvements in non-cooperative power control game (NPG) in this paper. By combining the advantages of cooperative and non-cooperative games with consideration of secondary users’ quality of service (QoS) requirements, the problems of low system EE of non-cooperative game and limited Pareto improvement of single leader Stackelberg game are solved. Simple utility function and time back-off are utilized to facilitate the implementation of distributed algorithm. Simulations show that the proposed algorithm improves the system EE as Pareto improvement is reached. Meanwhile, primary user’s QoS is guaranteed as secondary users transmit with lower power. © 2018, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.","Cognitive radio networks; Energy efficiency; Pareto improvement; Stackelberg game theory","Energy efficiency; Game theory; Power control; Quality of service; Radio; Radio systems; Cognitive radio network; Cognitive radio networks (CRNs); Distributed power control algorithms; Noncooperative game; Pareto improvements; Power control game; Qualityof-service requirement (QoS); Stackelberg Games; Cognitive radio",2-s2.0-85031301952
"Slotkienė A.","Algorithm of contextual information formation for smart learning object",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020424671&doi=10.1007%2f978-3-319-59451-4_11&partnerID=40&md5=31b543dcd1d204084f8fc4e452686d07","This paper presents a contextual information formation algorithm for smart learning object, which enables to comprise learning content, process of active learning activities and the essential aspects of the problematic learning situations. It presents how to get the specification of a smart learning object by using context of learning content and learning activities. This paper also analyzes the characteristic of proposed algorithm by comparing two smart learning objects. © Springer International Publishing AG 2018.","Active learning; Contextual information; Contextual modeling; Learning situation; Object; Smart learning","Artificial intelligence; E-learning; Active Learning; Contextual information; Contextual modeling; Learning situation; Object; Smart learning; Learning algorithms",2-s2.0-85020424671
"Li X., Xiao D., Wang Q.-H.","Error-free holographic frames encryption with CA pixel-permutation encoding algorithm",2018,"Optics and Lasers in Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028518382&doi=10.1016%2fj.optlaseng.2017.08.018&partnerID=40&md5=17a95fdf9f729c6517dc3ee6f808fcbf","The security of video data is necessary in network security transmission hence cryptography is technique to make video data secure and unreadable to unauthorized users. In this paper, we propose a holographic frames encryption technique based on the cellular automata (CA) pixel-permutation encoding algorithm. The concise pixel-permutation algorithm is used to address the drawbacks of the traditional CA encoding methods. The effectiveness of the proposed video encoding method is demonstrated by simulation examples. © 2017 Elsevier Ltd","CA; Holographic frames encryption; Pixel permutation","Calcium; Encoding (symbols); Holography; Network security; Pixels; Signal encoding; Video recording; Encoding algorithms; Encoding methods; Encryption technique; In networks; Security transmission; Simulation example; Unauthorized users; Video encodings; Cryptography",2-s2.0-85028518382
"Khanzad I., Seyedabrishami S., Nazemi M., Zarrinmehr A.","Transit network design problem: An expansion of the route generation algorithm",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022229796&doi=10.1007%2f978-3-319-57105-8_8&partnerID=40&md5=34d186cc646d781c62c089a867fd3ad5","The problem of public transportation routes network design deals with establishing the configuration of transit routes in a transportation network. This problem is recognized as one of the most complicated problems in transportation planning. An appropriate design of transit network will help increasing transit share of urban trips and reducing traffic congestion in urban networks. Previous research proposed the Route Generation Algorithm (RGA) in which shortest paths with the highest demands are selected and then expanded by insertion of new nodes in order to increase transit demand coverage. This paper extends RGA by introducing a new algorithm namely Extended Route Generation Algorithm (ERGA) with further details in node insertion scheme. A heuristic algorithm is proposed, tested in a medium-size network, and applied on a real-size network. In contrast to the conventional RGA in which all nodes are examined to be inserted between nodes of Origin-Destination (O-D) pairs, the algorithm inserts only adjacent nodes to the shortest paths between selected (O-D) pairs. Moreover, the proposed algorithm restricts the distance between each pair of nodes, not to be greater than two times of the shortest path length between the two nodes and the travel time of each generated route in the problem. Also, the number of common links between proposed routes of ERGA has been restricted due to the specifications of case study network. © Springer International Publishing AG 2018.","Node insertion; Route generation; Transit routes network design","Graph theory; Heuristic algorithms; Mass transportation; Traffic congestion; Traffic control; Transportation; Network design; Node insertion; Origin-destination pairs; Public transportation; Route generation; Transit network design; Transportation network; Transportation planning; Transportation routes",2-s2.0-85022229796
"Elalouf A., Tsadikovich D., Hovav S.","Optimization of blood sample collection with timing and quality constraints",2018,"International Transactions in Operational Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84996542619&doi=10.1111%2fitor.12354&partnerID=40&md5=d39a44f67169996d7ff373aeafa7e2f1","We focus on planning transportation operations within a blood sample supply chain, which comprises clinics and a laboratory. Specifically, the main goal of this study is to obtain the optimal number of vehicles to be deployed and the scheduling of the pickup process. First, we formulate a mixed-integer programming (MIP) problem. Next, we develop a heuristic scheme composed of two heuristic algorithms and numerical search, and a new genetic algorithm. In an extensive numerical study, based on the data from a real-life blood sample collection process, we illustrate the potential of the new heuristic scheme. © 2016 The Authors. International Transactions in Operational Research © 2016 International Federation of Operational Research Societies","blood samples collection; genetic algorithm; MIP; optimization; tabu search","Blood; Genetic algorithms; Heuristic algorithms; Integer programming; Supply chains; Tabu search; Timing circuits; Blood samples; Heuristic schemes; Mixed integer programming (MIP); New genetic algorithms; Numerical search; Pick-up process; Quality constraints; Transportation operations; Optimization",2-s2.0-84996542619
"Varughese J.C., Thenius R., Wotawa F., Schmickl T.","FSTT algorithm: Can tides assist bio-inspired gradient taxis?",2018,"Mechanisms and Machine Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028057219&doi=10.1007%2f978-3-319-59972-4_23&partnerID=40&md5=820e127b81f8497f26059eb127e8d5a0","In this article we introduce a variation of the Firefly-Slime mold-Taxis (FSTaxis) algorithm, which is an emergent gradient ascent solution using external environmental influences such as tides, wind among others. Such external environmental influences are useful sources of energy for movement. If utilized, this results in substantial energy saving compared to robots relying solely on propulsion. Assistance using external factors can be adopted by various types of service robots depending on their environment of operation (for example, rescue robots, robotic underwater exploration). The variant of the FSTaxis algorithm we present in this paper combines bio-inspired communication strategies to achieve gradient taxis purely based on neighbor-to-neighbor interaction and tidal movements for mobility. In this article, we discuss the modified algorithm in detail and further introduce first simulation results obtained using a multiagent simulation environment. © Springer International Publishing AG 2018.","Bio-inspiration; Gradient taxis; Self organization; Swarm robotics; Tides","Energy conservation; Machine design; Mobile robots; Robotics; Robots; Tides; Bio-inspiration; Bio-inspired communications; Environmental influences; Modified algorithms; Multi agent simulation; Self organizations; Swarm robotics; Underwater exploration; Swarm intelligence",2-s2.0-85028057219
"Agrawal R.","Integrated effect of nearest neighbors and distance measures in k-nn algorithm",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031411767&doi=10.1007%2f978-981-10-6620-7_74&partnerID=40&md5=fe57f0cb618373fa54fc7213dd12953f","Supervised learning or classification is the cornerstone of Data Mining. A well-known, simple, and effective algorithm for supervised classification is k-Nearest Neighbor (k-NN). A distance measure provides significant support in the process of classification and the correct choice of distance measure is the most influential process in the classification technique. Also, the choice of k in k-Nearest Neighbor algorithm plays an effective role in the accuracy of the classifier. The aim of this paper is to analyze the integrated effect of various distance measures on different values of k in k-Nearest Neighbor algorithm on different data sets taken from UCI machine learning repository. © 2018, Springer Nature Singapore Pte Ltd.","Cityblock; Classification; Cosine; Data sets; Distance measure; Euclidean; K-Nearest neighbor; Mahalanobis","Big data; Data mining; Learning algorithms; Learning systems; Motion compensation; Nearest neighbor search; Pattern recognition; Supervised learning; Cityblock; Cosine; Data sets; Distance measure; Euclidean; K-nearest neighbors; Mahalanobis; Classification (of information)",2-s2.0-85031411767
"Guo X., Lu Z., Cui H., Liu B., Jiang Q., Wang S.","Modelling and solving the position tracking problem of remote-controlled gastrointestinal drug-delivery capsules",2018,"Biomedical Signal Processing and Control",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026921847&doi=10.1016%2fj.bspc.2017.05.014&partnerID=40&md5=7c9e748ca795b020d57f29c512485641","A theoretical basis is presented to develop a real-time position tracking system for a remote-controlled drug-delivery capsule that would enable the targeted delivery of drugs to specific locations in the gastrointestinal tract. Tracking is accomplished by dual magnetic vector detection over time, using two separate sets of magnetic field sensing devices. One is used to detect the alternating magnetic field excited externally with certain frequencies, while the other is used to detect the geomagnetic field. A mathematical model of the magnetic flux density in space and time is constructed using the Biot–Savart law. Additionally, the earth's magnetic field and quaternion rotation theory are also used in the model to compensate for the constantly changing spatial orientation of the capsule as it travels through the gastrointestinal tract. Based on the model, an improved artificial bee colony algorithm is used to solve the inverse magnetic field problem. Firstly, chaotic sequencing improves the initial solution diversity, and a ranked selection strategy is applied. At later stages, the Levenberg-Marquardt algorithm is introduced in order to accelerate convergence. To verify the theoretical basis presented above, a prototype of the tracking system is developed. Calculations verification results in a convergence rate of 100% with an average of 179 iterations. The prototype testing shows that the dual magnetic vector detection method simplifies the solution of the inverse magnetic field problem, shortens the tracking time for each round of data, and increases the solution accuracy. © 2017 Elsevier Ltd","Artificial bee colony algorithm; Drug-delivery capsule; Dual magnetic vector detection; Quaternion; Tracking solution","Controlled drug delivery; Evolutionary algorithms; Geomagnetism; Inverse problems; Magnetic fields; Magnetism; Optimization; Remote control; Tracking (position); Alternating magnetic field; Artificial bee colony algorithms; Levenberg-Marquardt algorithm; Magnetic field sensing devices; Magnetic vectors; Position tracking system; Quaternion; Tracking solutions; Targeted drug delivery; gastrointestinal agent; accuracy; algorithm; Article; artificial bee colony algorithm; drug delivery capsule; drug delivery device; drug delivery system; gastrointestinal tract; Levenberg Marquardt algorithm; magnetic field; mathematical analysis; mathematical model; priority journal; sensor; simulation; spatial orientation",2-s2.0-85026921847
"Wang X.-T., Chang Y.-L., Zhang P.","Traffic signal optimization based on system equilibrium and bi-level multi-objective programming model",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026779644&doi=10.1007%2f978-981-10-3551-7_34&partnerID=40&md5=0193b0dc6d206fbbe13c6e7941a867f4","Based on the design principle of minimizing the automotive exhaust emissions and the total impedance of the road network, an urban road traffic signal control method of bi-level multi-objective programming model is established by designing the heuristic particle swarm optimization (PSO) algorithm. First of all, the upper-level model which combined the vehicle emissions model and system optimum assignment model is built, and the lower-level model is built based on minimizing the sum of the link travel time function integral. Then, the heuristic PSO algorithm is designed and transformed to solve upper-level and lower-levels model iteratively by two PSO algorithms. Ultimately, by altering the weight parameters of the upper model, the model is dealt with separately in case of single target and multi-target, the optimization results of which is compared with the VISSIM simulation results and the optimization results by means of heuristic genetic algorithm. The simulation results show that bi-level multi-objective control method, which could improve the operating quality of road network, is of great optimization ability and can effectively reduce the automotive exhaust emissions and the total impedance of the road network. © Springer Science+Business Media Singapore 2018.","Bi-level multi-objective programming model; PSO algorithm; Signal control; System equilibrium; Traffic engineering","Genetic algorithms; Heuristic algorithms; Heuristic methods; Intelligent systems; Intelligent vehicle highway systems; Iterative methods; Multiobjective optimization; Particle swarm optimization (PSO); Quality control; Roads and streets; Safety engineering; Street traffic control; Traffic control; Traffic signals; Transportation; Travel time; Bi-level multi-objective programming; PSO algorithms; Signal control; System equilibrium; Traffic Engineering; Optimization",2-s2.0-85026779644
"Singh T., Shukla A., Mishra K.K.","Improved environmental adaption method with real parameter encoding for solving optimization problems",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031407084&doi=10.1007%2f978-981-10-3773-3_2&partnerID=40&md5=6e8b4bc6ead8476b9360f95289e05b97","Environmental Adaption Method (EAM) was proposed by K.K. Mishra et al. in 2011. Further an improved version of EAM with binary encoding was proposed in 2012, known as Improved Environmental Adaption Method (IEAM) with some changes in adaption operator. IEAM uses adaption, alteration, and selection operators to generate new population. In this paper, we have implemented a real parameter version of IEAM. In IEAM, adaption window of variable bandwidth was used for evolution of solutions, due to this particles could not evolve properly in entire search space. Here, we have used adaption window of fixed bandwidth for proper evolution of solutions. Performance of Improved Environmental Adaption Method with real parameter encoding (IEAM-RP) is compared with other nature-inspired optimization algorithms on Black Box Optimization Test-bed at dimensions 2D, 3D, 5D, and 10D on a set of 24 benchmark functions. It is found that IEAM-RP performs better than other state-of-the-art algorithms. © Springer Nature Singapore Pte Ltd. 2018.","Adaption factor; EAM; IEAM; Mobility factor; Randomized algorithm","Bandwidth; Benchmarking; Encoding (symbols); Signal encoding; Adaption factor; Black-box optimization; IEAM; Mobility factors; Optimization algorithms; Optimization problems; Randomized Algorithms; State-of-the-art algorithms; Optimization",2-s2.0-85031407084
"Wan X., Feng X., Wang Z., Fan Z.","Power allocation algorithm for heterogeneous cellular networks based on energy harvesting",2018,"Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031279951&doi=10.1007%2f978-3-319-66628-0_4&partnerID=40&md5=3f152723965a59c723f28197d8528ce6","Cellular network can use renewable energy through energy harvesting technology in green communication. In this paper, power allocation for heterogeneous cellular networks (HetNets) with energy harvesting is proposed to maximize the system energy efficiency. Considering the minimal transmit rate of the users and the battery capacity of the system, a low complexity power allocation algorithm based on fractional programming is proposed to maximize the energy efficiency of the system. Simulation results demonstrate the effectiveness of the proposed algorithm. © 2018, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.","Battery capacity; Energy efficiency; Energy harvesting; Power allocation","Computational complexity; Energy harvesting; Heterogeneous networks; Mathematical programming; Mobile telecommunication systems; Wireless networks; Battery capacity; Cellular network; Fractional programming; Green communications; Heterogeneous cellular networks; Power allocation algorithms; Power allocations; Renewable energies; Energy efficiency",2-s2.0-85031279951
"Petkov T., Sotirov S., Popov S.","Generalized net model of optimization of the self-organizing map learning algorithm",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031425765&doi=10.1007%2f978-3-319-65545-1_29&partnerID=40&md5=3bcf0050497cead647ab9dec5afaa3c4","This paper describes an optimization of the algorithm of self-organizing map neural network. The proposed algorithm takes place during the learning trial. We take into consideration the number of the epochs so their number needs to be decreased. In order to do that, for each epoch the distance from each cluster unit to all training vectors is measured. If the total distance is the same as the distance estimated from the previous epoch, it is assumed that the network is trained and the learning trial stops. The process of optimization is described with the generalized net. © Springer International Publishing AG 2018.","Generalized net; Neural networks; Self-organizing map","Conformal mapping; Decision making; Decision support systems; Fuzzy sets; Neural networks; Optimization; Self organizing maps; Cluster units; Generalized net; Organizing map; Self-organizing map neural network; Total distances; Learning algorithms",2-s2.0-85031425765
"Li X.-Y., Lin Z.-X.","Face Recognition Based on HOG and Fast PCA Algorithm",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030840620&doi=10.1007%2f978-3-319-68527-4_2&partnerID=40&md5=ead829927562cf5990c8a84077ca332f","A new method of face recognition based on gradient direction histogram (HOG) features extraction and fast principal component analysis (PCA) algorithm is proposed to solve the problem of low accuracy of face recognition under non-restrictive conditions. In this method, the Haar feature classifier is used to extract and extract the original data, and then the HOG features are extracted from the image data and the PCA dimension reduction is processed, and the Support Vector Machines (SVM) algorithm is used to recognize the face. The experimental results of the classification recognition on the LFW face database verify the effectiveness of the method. © 2018, Springer International Publishing AG.","Fast PCA; Haar feature classifier; HOG; SVM","Classification (of information); Data handling; Information analysis; Principal component analysis; Support vector machines; Dimension reduction; Face database; Fast PCA; Features extraction; Gradient direction histograms; Haar features; Restrictive conditions; Support vector machines algorithms; Face recognition",2-s2.0-85030840620
"Paternain D., Jurio A., Ruiz-Aranguren J., Minárová M., Takáč Z., Bustince H.","Optimized fuzzy transform for image compression",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029453520&doi=10.1007%2f978-3-319-66827-7_11&partnerID=40&md5=261e7558784189122ccefd8a24928844","In this work we propose an image compression algorithm based on the fuzzy transform. The algorithm tries to find the best fuzzy partition of the functions domain in order to obtain the best compressed image (in terms of quality). To solve the optimization problem we based ourselves in the Gravitational Search Algorithm, in which each agent represents a possible fuzzy partition of a fixed size. © 2018, Springer International Publishing AG.","Fuzzy transform; Gravitational Search Algorithm; Image compression","Fuzzy logic; Fuzzy sets; Fuzzy systems; Learning algorithms; Optimization; Pattern matching; Compressed images; Fixed size; Fuzzy partition; Fuzzy transforms; Gravitational search algorithms; Image compression algorithms; Optimization problems; Image compression",2-s2.0-85029453520
"Jurio A., Paternain D., Pagola M., Marco-Detchart C., Bustince H.","Two-step algorithm for image inpainting",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029447251&doi=10.1007%2f978-3-319-66824-6_27&partnerID=40&md5=aabda8e4d4c338e3dd73d2c273bc1043","In this work we propose a new algorithm for image inpainting. The proposal is patch-based, so we look for similar small regions (windows) through the whole image to inpaint the unknown area. The final goal is to obtain a complete image with no visual differences between the original part and the reconstructed one. The main novelty is the use of color and gradient properties to look for similar windows of the image. We combine these two properties in two stages. In the first one we cluster all the available windows taking into account only the gradient feature. With this step we preselect some windows from the set of all available ones. From all the preselected ones, we finally select the most similar in color intensity. The results show that our algorithm gets final images with better textures than the ones obtained just considering color features. © 2018, Springer International Publishing AG.","Clustering; Color; Gradient; Image inpainting","Color; Fuzzy logic; Fuzzy sets; Gradient methods; Pattern matching; Clustering; Color features; Color intensity; Gradient feature; Image Inpainting; Small region; Two-step algorithms; Visual differences; Image processing",2-s2.0-85029447251
"Zhao Z., Zhang L., Cui J.","A 3D printing task packing algorithm based on rectangle packing in cloud manufacturing",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031401497&doi=10.1007%2f978-981-10-6499-9_3&partnerID=40&md5=03218e0063d620cf52f032629924871c","In Cloud Manufacturing environment, massive 3D Printing services in various types provide users with the ability of mass customization. The large number of 3D printing tasks bring more challenges on printing task scheduling to improve 3D printers’ utilization and thus saving time and materials. This paper establishes the model of 3D printing process in different types and figures out the existence of auxiliary processes. Aiming at decreasing the ratio of auxiliary process time consumption, this paper develops an algorithm derived from the rectangle packing problem to pack printing tasks whose model size are relatively small into one task and print them all in one 3D printing process. Experiments show that the ratio of auxiliary process time consumption significantly reduced by this algorithm. © 2018, Springer Nature Singapore Pte Ltd.","3D printing; Cloud manufacturing; Rectangle packing","Computer aided manufacturing; Geometry; Intelligent systems; Manufacture; Printing; Printing presses; Three dimensional computer graphics; 3-D printing; 3D printing process; Auxiliary process; Cloud Manufacturing; Mass customization; Packing algorithms; Rectangle packing; Rectangle packing problem; 3D printers",2-s2.0-85031401497
"Du H., Xu Z., Ding Y.","The fast lane detection of road using RANSAC algorithm",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032696518&doi=10.1007%2f978-3-319-67071-3_1&partnerID=40&md5=2f355ade205f775d866c7371d5753f8a","In order to ensure driving safety and advanced driver assistance systems (ADAS) attracted more and more attention. Lane departure warning system is an important part of the system. Fast and stable lane detection is a prerequisite for Lane detection under complex background. In this paper, we propose a new lane detection method through a bird’s eye view maps and modified RANSAC (random sampling) based on inspiration from the road feature extraction algorithm for remote sensing images. According to the image of a bird’s eye view, we can identify the tag line through progressive probabilistic Hough transform in the opposite lane detection. Then the group rows are detected by a new weighting scheme based on distance, we can get a candidate lane field. Each field, Lane the RANSAC algorithm is improved and the dual-model fitting. Therefore, the curvature of the road direction can be predicted and the slope of the line. Finally, our results show that lane detection algorithm is robust and real-time performance in a variety of road conditions. © 2018, Springer International Publishing AG.","Bird’s eye view; Lane detection; RANSAC","Advanced driver assistance systems; Automobile drivers; Birds; Hough transforms; Remote sensing; Roads and streets; Transportation; Complex background; Feature extraction algorithms; Lane detection; Lane-departure-warning systems; RANSAC; Real time performance; Remote sensing images; Weighting scheme; Feature extraction",2-s2.0-85032696518
"Zhao Y., Shao J., Li D., Mei L.","A vehicle model data classification algorithm based on hierarchy clustering",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032662325&doi=10.1007%2f978-3-319-67071-3_24&partnerID=40&md5=b1e47fd879617d8336c207e57dcd9f8d","With wide application of deep learning in security field, using it on vehicle brand, style and years recognition product has become an active research. Due to the variety of vehicle brand, the total quantity of training samples needed by deep learning is so huge that the difficulty of sample collection and corresponding cost on time and labor are both unacceptable. In addition, new vehicle types come out continuously which require database augmentation and product update in time. To solve this problem, this article proposes a vehicle model data classification algorithm based on hierarchy clustering. Firstly, train the classification model with vehicle data collected by the index of vehicle model information. Secondly, get mean feature of each class and use hierarchical clustering according to the distance between the classes. Then on the basis of distance sorting and model test result to merge the vehicle models. Finally, the feasibility of this algorithm is verified through the experiment. Experimental results show the scheme is feasible. The algorithm realizes the automatic clustering of vehicle model data whose car face or tail has the same structure which can’t be distinguish in image or video. This article provides a new way for the development of vehicle brand, style and year recognition products. © 2018, Springer International Publishing AG.","Deep learning; Hierarchy clustering; Vehicle data classification; Vehicle model","Classification (of information); Deep learning; Vehicles; Automatic clustering; Classification models; Data classification; Hier-archical clustering; Hierarchy clustering; Sample collection; Training sample; Vehicle model; Clustering algorithms",2-s2.0-85032662325
"Sarraf S., Lopez E., Battaglia L., Rios Rodriguez G., D'Elia J.","An improved assembling algorithm in boundary elements with galerkin weighting applied to three-dimensional stokes flows",2018,"Journal of Fluids Engineering, Transactions of the ASME",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030757738&doi=10.1115%2f1.4037690&partnerID=40&md5=c4ffbbac95d06bbd8a048f6fd959ec94","In the boundary element method (BEM), the Galerkin weighting technique allows to obtain numerical solutions of a boundary integral equation (BIE), giving the Galerkin boundary element method (GBEM). In three-dimensional (3D) spatial domains, the nested double surface integration of GBEM leads to a significantly larger computational time for assembling the linear system than with the standard collocation method. In practice, the computational time is roughly an order of magnitude larger, thus limiting the use of GBEM in 3D engineering problems. The standard approach for reducing the computational time of the linear system assembling is to skip integrations whenever possible. In this work, a modified assembling algorithm for the element matrices in GBEM is proposed for solving integral kernels that depend on the exterior unit normal. This algorithm is based on kernels symmetries at the element level and not on the flow nor in the mesh. It is applied to a BIE that models external creeping flows around 3D closed bodies using second-order kernels, and it is implemented using OpenMP. For these BIEs, the modified algorithm is on average 32% faster than the original one. Copyright © 2018 by ASME.","complex flows; computational fluid dynamics; microfluidics; Newtonian flows","Application programming interfaces (API); Boundary integral equations; Computational fluid dynamics; Galerkin methods; Integral equations; Linear systems; Microfluidics; Newtonian flow; Numerical methods; Sailing vessels; Boundary integral equations (BIE); Complex flow; Engineering problems; Galerkin boundary element method; Modified algorithms; Surface integration; Threedimensional (3-d); Weighting techniques; Boundary element method",2-s2.0-85030757738
"Fu Q., Wu Z., Wang X., Zhou M., Zheng J.","An algorithm for finding intersection between ball B-spline curves",2018,"Journal of Computational and Applied Mathematics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022177127&doi=10.1016%2fj.cam.2017.06.015&partnerID=40&md5=bc57fc68b011adb6175f548488b5e0d7","A ball B-spline curve (BBSC) is a skeleton based solid model representation, which consists of a B-spline curve and a B-spline function serving as the (varying) radius of a ball moving along the B-spline curve. The surface shape specified by the BBSC is the envelope of the moving ball and thus the BBSC is very suitable for representing vascular shapes. To apply this good representation in various fields as CSG-to-boundary conversion, Boolean operations, geometric design, pattern recognition, scientific visualization, this paper proposes an efficient algorithm to solve their common fundamental intersection problem. The surface of each BBSC is decomposed into a starting spherical patch, a set of lateral surfaces defined by ball Bézier curves (BBC), and an ending spherical patch. The intersection algorithm proceeds in four steps: (1) tessellating both BBSCs into triangular meshes and computing the intersection curves between the triangular meshes, which serve as the initial intersections for later refinement; (2) parameterizing the surfaces/patches of one BBSC and implicitizing the surfaces/patches of the other BBSC; (3) calculating the intersection curves between a parametric surface and an implicit surface numerically by using the Newton's method; and (4) tracing the intersection curves for the construction of intersection solid regions. In particular, we present simple methods for parameterization and implicitization of BBSCs, which are the core of the proposed algorithm. And BBSC is a solid model, therefore the intersection of BBSCs is the intersection of solid models, and the final intersection result is also a solid object. Experimental results show that our method is able to efficiently find the intersections of BBSCs with high accuracy. © 2017 Elsevier B.V.","Ball B-spline curve; Ball Bézier curve; Implicitization; Intersection; Newton's method; Parameterization","Curve fitting; Interpolation; Intersections; Newton-Raphson method; Parameterization; Pattern recognition; Ball B-spline; Boolean operations; Implicitization; Intersection algorithms; Intersection curves; Intersection problem; Newton's methods; Parametric surfaces; Parameter estimation",2-s2.0-85022177127
"Potuzak T., Lipka R.","Analysis and optimization of fitness function of genetic algorithm for road traffic network division",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028603848&doi=10.1007%2f978-3-319-62120-3_8&partnerID=40&md5=add4c452ae764a946a0b8f4f0cd93e2c","In this paper, the analysis and the optimization of a fitness function of a genetic algorithm for the road traffic network division are discussed. We explain why an original flawed fitness function gave better results than a new fitness function with the flaws removed. We also describe the new penalizing fitness function, which gives better results than the former two, and its optimization, which leads to a substantial reduction of the computation time. The comparison of the results of the particular fitness functions and their performance is also part of this paper. © Springer International Publishing AG 2018.",,"Genetic algorithms; Optimization; Roads and streets; Transportation; Computation time; Fitness functions; Road traffic network; Substantial reduction; Health",2-s2.0-85028603848
"Potuzak T.","Sparsely synchronized distributed/parallel genetic algorithm for road traffic network division",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028596873&doi=10.1007%2f978-3-319-62120-3_9&partnerID=40&md5=161e1a766d9cfac4bdcd5f95176fecce","This work describes the sparse synchronization of a distributed/parallel genetic algorithm, which is the main component of the method for the road traffic network division. This division is necessary for a distributed road traffic simulation. The synchronization is used among multi-threaded processes communicating via messages. Within each process, the threads interact via shared memory. The meaning of the sparse synchronization is that the access to the shared memory is synchronized and the processes communicate only once per several generations. © Springer International Publishing AG 2018.",,"Genetic algorithms; Memory architecture; Roads and streets; Synchronization; Multithreaded; Road traffic network; Road traffic simulation; Shared memory; Transportation",2-s2.0-85028596873
"Javeed Ahammed M., Swathi A., Sanku D., Chakravarthy V.V.S.S.S., Ramesh H.","Performance of firefly algorithm for null positioning in linear arrays",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029811942&doi=10.1007%2f978-981-10-4280-5_40&partnerID=40&md5=120d9f399942738ee75e33015dbc378d","In this paper, linear array (LA) synthesis for desired nulls is performed using firefly algorithm (FFA). The undesired signals are often termed as interference approaching the radiating system in certain directions. It is possible to reject these signals thereby avoiding potential interference by simply placing nulls in the direction of arrival of interference in the respective radiation pattern of the antenna array. In order to demonstrate this, single and multiple nulls are obtained using FFA in linear arrays. The radiation patterns are obtained for both single and multiple nulls when the beam is positioned from 0° to 30° which typically refers to scanned and unscanned beams. © Springer Nature Singapore Pte Ltd. 2018.","FFA; Linear array; Null positioning; Optimization","Antenna arrays; Bioluminescence; Directional patterns (antenna); Firefly algorithms; Linear arrays; Null positioning; Potential interferences; Radiating systems; Optimization",2-s2.0-85029811942
"He Y., Deng G., Wang Y., Wei L., Yang J., Li X., Zhang Y.","Optimization of SIFT algorithm for fast-image feature extraction in line-scanning ophthalmoscope",2018,"Optik",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030479714&doi=10.1016%2fj.ijleo.2017.09.075&partnerID=40&md5=91e3b08531d838bd908383b84b5d6496","The Scale Invariant Feature Transform (SIFT) algorithm is utilized broadly in image registration to improve image qualities. However, the algorithm's complexity reduces its efficiency in biology study and usually requires real-time. In this article, we present an improved SIFT technique in software architecture for matching sequences of images taken from a line-scanning ophthalmoscope (LSO). The method generates the Gaussian Scale-space pyramid in frequency domain to complete the SIFT feature detector more quickly. A novel SIFT descriptor invariable with rotation and illumination is then created to reduce calculation time, implementing the original SIFT method, our improved SIFT method, and the graphic processing unit (GPU) version of our improved SIFT method. The experiments have shown that the improved SIFT is almost 2–3 times faster than the original while maintaining more robust performance, and the GPU implementation of the improved SIFT is 20 times faster than central processing unit (CPU) implementation and achieves acceleration at real-time as expected. Although tested on an LSO system, the improved SIFT method does not rely on the acquisition setup. As a result, this method can be applied to other imaging instruments, e.g., adaptive optics to increase their resolution in agreement. © 2017 Elsevier GmbH","Confocal microscopy; Feature extraction; Image matching; Medical and biological imaging; Retina scanning; SIFT","Adaptive optics; Computational complexity; Confocal microscopy; Extraction; Feature extraction; Frequency domain analysis; Graphics processing unit; Image matching; Image processing; Medical imaging; Optimization; Program processors; Scanning; Gaussian scale space; GPU implementation; Graphic processing unit(GPU); Image feature extractions; Imaging instruments; Medical and biological imaging; Scale invariant feature transform algorithms (SIFT); SIFT; Image enhancement",2-s2.0-85030479714
"Chen M., Gao Y., Chai R., Chen Q.","An optimal joint user association and power allocation algorithm for secrecy information transmission in heterogeneous integrated networks",2018,"Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031291235&doi=10.1007%2f978-3-319-66628-0_22&partnerID=40&md5=2507bc5c1467243c28c735f6e5e04e8c","In recent years, radio access technologies have experienced rapid development and gradually achieved effective coordination and integration, resulting in heterogeneous networks (HetNets). User equipments (UEs) located in the overlapping area of various networks of HetNets are capable of selecting the base station (BS) of one network for association and conduct information interaction. In this paper, we study user association and power allocation problem for HetNets with eavesdroppers. To achieve secrecy data transmission in a secret and energy-efficient manner, the concept of joint secrecy energy efficiency of the network is introduced and is defined as the ratio of secrecy transmission rate and the power consumption of the BSs. An optimization problem is formulated which maximizes the joint secrecy energy efficiency under the constraints of maximum power of the BSs and the minimum data rate requirement of the UEs, and the optimal user association and transmit power strategy is obtained through applying iterative algorithm and Lagrange dual method. Numerical results demonstrate the efficiency of the proposed algorithm. © 2018, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.","HetNets; Power allocation; Secrecy energy efficiency; Secrecy information transmission; User association","Association reactions; Data communication systems; Heterogeneous networks; Iterative methods; Optimization; Heterogeneous network (HetNets); Hetnets; Information interaction; Information transmission; Power allocation algorithms; Power allocations; Radio access technologies; User associations; Energy efficiency",2-s2.0-85031291235
"Cui L., Li G., Zhu Z., Lin Q., Wong K.-C., Chen J., Lu N., Lu J.","Adaptive multiple-elites-guided composite differential evolution algorithm with a shift mechanism",2018,"Information Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029153377&doi=10.1016%2fj.ins.2017.09.002&partnerID=40&md5=a0b23bea8bc0105fef2b26ac9b1c82f0","The performance of differential evolution (DE) has been significantly influenced by trial vector generation strategies and control parameters. Various powerful trial vector generation strategies with adaptive parameter adjustment methods such that the population generation is guided by the elites have been proposed. This paper aims to strengthen the performance of DE by compositing these powerful trial vector generation strategies, making it possible to obtain the guidance of each individual from multiple elites concurrently and independently. In this manner, the deleterious behavior in which an individual is misguided by various local optimal solutions into unpromising areas could be restrained to a certain extent. An adaptive multiple-elites-guided composite differential evolution algorithm with a shift mechanism (abbreviated as AMECoDEs) has been proposed in this paper. This algorithm concurrently employs two elites-guided trial vector generation strategies for each individual to generate two candidate solutions accordingly, and the best one is adopted to participate in the selection. Moreover, a novel shift mechanism is established to handle stagnation and premature convergence issues. AMECoDEs has been tested on the CEC2014 benchmark functions. Experimental results show that AMECoDEs outperforms various classic state-of-the-art DE variants and is better than or at least comparable to various recently proposed DE methods. © 2017 Elsevier Inc.","Adaptive control parameters; Composite differential evolution; Global numerical optimization; Multiple-elites-guided; Shift mechanism","Optimization; Vectors; Adaptive Control; Composite differential evolutions; Global numerical optimizations; Multiple-elites-guided; Shift mechanism; Evolutionary algorithms",2-s2.0-85029153377
"Luo Z., Wei S., Chai Y., Liu Y., Sun X.","Simulation of wind farm scheduling algorithm based on predictive model control",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031433557&doi=10.1007%2f978-981-10-6499-9_56&partnerID=40&md5=813bed3e79197b2687bf182d2ff929fc","In this paper, a simulation study is carried out on the coordinated active and reactive dispatch of wind farm based on Model Predictive Control (MPC). Compared with the traditional scheduling algorithm, this method combines the active and reactive scheduling, and balances the active and reactive target by changing the weight coefficients of the cost functions. The proposed control method can not only track the scheduling instructions accurately and smoothly, but also can make fluctuations of bus’ voltage in the wind farm stable. Therefore the anti-perturbation capability of wind farm system is improve. A simulation model is built in MATLAB/SIMULINK environment, and the results show that the MPC is effective for wind power dispatch. © 2018, Springer Nature Singapore Pte Ltd.","Coordinated active; MPC; Power dispatch; Reactive; Wind farm","Cost functions; Electric load dispatching; Electric utilities; Intelligent systems; MATLAB; Model predictive control; Predictive control systems; Wind power; Coordinated active; MATLAB/Simulink environment; Power dispatch; Predictive modeling; Reactive; Reactive scheduling; Wind farm; Wind power dispatches; Scheduling algorithms",2-s2.0-85031433557
"Álvarez A., Reyes D., Rincón E.J., Valderrama J., Noradino P., Méndez G.M.","PID implemented by a type-1 fuzzy logic system with back-propagation algorithm for online tuning of its gains",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030725044&doi=10.1007%2f978-3-319-67137-6_28&partnerID=40&md5=a71776d13c02991d6ad5b1ab24c06191","Two different types of benchmarking proportional-integral-derivative PID controllers are used to compare the proposed methodology. In the first controller the proportional gain KP, the integral gain KI, and the derivative gain KD, are offline calculated based on the dynamics of the process under control using the Ziegler Nichols method. The second controller uses three type-1 fuzzy logic systems to estimate each one of the gains every control cycle. This paper proposes a fuzzy self-tuning PID controller: it has three singleton type-1 fuzzy logic systems to calculate each gain of the controller every control cycle, with the novel characteristics that each fuzzy rule base is updated and tuned each feedback cycle using the back-propagation (BP) algorithm. This proposal is named T1 SFLS PID-BP. The results show that the proposed controller presents better performance than the two benchmarking controllers: the PID and the T1 SFLS PID. © Springer International Publishing AG 2018.",,"Backpropagation; Backpropagation algorithms; Benchmarking; Computer circuits; Controllers; Electric control equipment; Fuzzy inference; Fuzzy logic; Fuzzy rules; Potassium compounds; Three term control systems; Two term control systems; Control cycles; Feedback cycle; Fuzzy logic system; Fuzzy rule base; Fuzzy self-tuning pid; PID controllers; Proportional integral derivatives; Ziegler-Nichols method; Proportional control systems",2-s2.0-85030725044
"Jackowski K.","A novel simulated annealing based training algorithm for data stream processing ensemble classifier",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019244990&doi=10.1007%2f978-3-319-59162-9_46&partnerID=40&md5=23b60e67f3d2dbc6fa6e4d9b0b931f57","Training of compound ensemble classifier systems might be computationally complex and hence time consuming task. Not only elementary classifiers are to be trained, but also model of the ensemble has to be updated. Therefore, an efficiency of the training shall be considered as a compound quality which consists of not only a classification accuracy but also a running time. This gains a special importance while dealing with data streams where data arrive at high pace and the system update shall be done promptly. In this paper we present an application of Simulated Annealing based algorithm for training of data stream processing ensemble. The evaluation of our method is performed in series of experiments which show that our ensemble perform very effectively in term of accuracy and processing time. © Springer International Publishing AG 2018.",,"Data communication systems; Simulated annealing; Classification accuracy; Data stream; Data stream processing; Ensemble classifiers; Processing time; Running time; Time-consuming tasks; Training algorithms; Data handling",2-s2.0-85019244990
"Myszkowski P.B., Olech Ł.P., Laszczyk M., Skowroński M.E.","Hybrid Differential Evolution and Greedy Algorithm (DEGR) for solving Multi-Skill Resource-Constrained Project Scheduling Problem",2018,"Applied Soft Computing Journal",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032299359&doi=10.1016%2fj.asoc.2017.10.014&partnerID=40&md5=938ff57cc4db04e0d7f3ac646c6b225d","Paper presents a hybrid Differential Evolution and Greedy Algorithm (DEGR) applied to solve Multi-Skill Resource-Constrained Project Scheduling Problem. The specialized indirect representation and transformation of solution space from discrete (typical for this problem), to continuous (typical for DE-approaches) are proposed and examined. Furthermore, Taguchi Design of Experiments method has been used to adjust parameters for investigated method to reduce the procedure of experiments. Finally, various initialisation, clone elimination, mutation and crossover operators have been applied there. The results have been compared with the results from other reference methods (HantCO, GRASP and multiStart Greedy) using the benchmark iMOPSE dataset. This comparison shows that DEGR effort is very robust and effective. For 28 instances of iMOPSE dataset DEGR has achieved the best-known solutions. © 2017 Elsevier B.V.","Differential Evolution; Hybrid; Metaheuristics; MS-RCPSP; Scheduling","Design of experiments; Evolutionary algorithms; Optimization; Crossover operator; Differential Evolution; Hybrid; Hybrid differential evolution; Meta heuristics; MS-RCPSP; Resource-constrained project scheduling problem; Taguchi design of experiment; Scheduling",2-s2.0-85032299359
"Zhang Y., Zhang M., Zhang Z., Yang H., Niu K.","Video steganographic algorithm based on intra prediction modification for H.264/AVC",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028406888&doi=10.1007%2f978-3-319-60744-3_16&partnerID=40&md5=bbbf492d11410b4393420f2ea70caedd","To analyze the technique of video steganography, which provides security guarantees for national security and confidential information of government agencies and enterprises, videos may be used to transform secret information and then achieve the goal of covert communication. Aim to use the specific features of the H.264–intra prediction mode, and decrease the modification rate, we present a video steganography method based on logistic mapping and the intra prediction mode in H.264/AVC. First of all, we process, the secret information from logistic sequence. Then we use the parity of intra prediction mode of 4, ×, 4 blocks group. Further, embed secret information by modifying the parity. Experimental results indicate that our algorithm has good invisibility, little influence on the bit rate of the video carrier, and the modification rate is low. © 2018, Springer International Publishing AG.","Intra prediction; Logistic map; Steganography; Video","Forecasting; Image coding; Intelligent systems; National security; Real time systems; Confidential information; Covert communications; Government agencies; Intra Prediction; Intra prediction modes; Logistic maps; Steganographic algorithms; Video; Steganography",2-s2.0-85028406888
"Wang R., Wu Y., Wang Y., Feng X.","An industrial area layout design methodology considering piping and safety using genetic algorithm",2018,"Journal of Cleaner Production",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029685059&doi=10.1016%2fj.jclepro.2017.08.147&partnerID=40&md5=3c442d5d9f41c9af3a901e16325ae8b0","The industrial area layout can influence the economic benefit, safety and surrounding environment of an industrial area to a large extent, especially the length of piping and safety. Every year, the construction of new industrial areas requires thousands of tons of steel pipes, resulting in a high consumption of natural resource of iron and high emission of carbon dioxide. Additionally, the long pipeline will increase the energy consumption for material transportation. Meanwhile, accidents in industrial areas can usually result in serious damage to the local environment. So the optimization of industrial area layout holds great significance for natural resource, energy saving, and environment protection. But up to now, very few papers have been reported to consider the use of pipes and safety simultaneously to optimize the layout in industrial area level. Most works only focus on safety aspects, and the impact of connection is ignored. Accordingly, this paper proposes a methodology to optimize the relative position of each plant, whose objective function consists of piping cost and safety cost. In this paper, despite conventional consideration of material piping, steam piping, which features multiple-branches connected pipeline network, is also considered. For safety issues, it is firstly analyzed by qualitative principles to limit position for some specified plants. Then quantitative analysis, including explosion and toxic release, are optimized simultaneously with connection cost. A genetic algorithm is used to solve the proposed model. Kruskal algorithm and Arrangement & Combination are used to calculate the length of steam piping. Finally, a case study illustrates the effectiveness and applicability of the proposed methodology. © 2017 Elsevier Ltd","Area layout; Explosion; Mathematical programing; Piping; Toxic gas dispersion","Carbon; Carbon dioxide; Cost benefit analysis; Costs; Dispersions; Economic and social effects; Energy conservation; Energy utilization; Explosions; Genetic algorithms; Industrial emissions; Materials handling; Natural resources; Optimization; Pipelines; Area layout; Environment protection; Material transportation; Mathematical programing; Objective functions; Piping; Surrounding environment; Toxic gas; Accident prevention",2-s2.0-85029685059
"Juneja S., Kochar S., Dhiman S.","Intelligent algorithm for automatic multistoried parking system using image processing with vehicle tracking and monitoring from different locations in the building",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031404973&doi=10.1007%2f978-981-10-6614-6_8&partnerID=40&md5=af2b539e6c46389c447130160366a697","This paper presents an intelligent algorithm implemented to design an intelligent parking system in an existing multistoried parking facility. The system will automatically guide the user (driver) to vacant parking slot; the system will keep the track of vehicles by remembering the vehicle number and will allow user to locate the exact parking slot of his vehicle in the multistory parking, from any location in the building. All this is done with the help of image processing using image binarization and segmentation techniques and with very minimal use of hardware to ensure that the cost of the system is very small. Parking is a very big problem today, especially in the big cities, and we are well aware of it. We have built multistoried parking facilities in malls, multiplexes, large crowded market places, but these parking facilities are manually operated; as a result, users face problems such as difficulty in ticketing, locating a free parking slot for parking, locating where their vehicle is parked among 1000s of vehicles. In our system, we have used two cameras and MATLAB for image processing. We have created a pseudoparking space with parking slots and obtained our results. As you will find out from the snapshots in the description below, it is shown that our system successfully (1) identifies the vehicle with its registration number, (2) identifies the available parking slots, and (3) ties the parking slot to vehicle number and stores it in the memory so that users can locate their vehicle. © 2018, Springer Nature Singapore Pte Ltd.","Automatic car parking; Image processing; MATLAB; Number Plate Recognition; OCR","Image segmentation; Location; MATLAB; Optical character recognition; Parking; Vehicle locating systems; Vehicles; Car parking; Image binarization; Intelligent Algorithms; Number plate recognition; Parking facilities; Parking systems; Registration number; Segmentation techniques; Image processing",2-s2.0-85031404973
"Artime Ríos E.M., Seguí Crespo M.M., Suarez Sánchez A., Suárez Gómez S.L., Sánchez Lasheras F.","Genetic algorithm based on support vector machines for computer vision syndrome classification",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028641731&doi=10.1007%2f978-3-319-67180-2_37&partnerID=40&md5=3d58bfc7147a95b54d27fe3be8b8e247","The inclusion in workplaces of video display terminals has introduced multiple benefits in the organization of the work. Nevertheless, it also implies a series of risks for the health of the workers, since it can cause ocular and visual disorders, among others. In this work, a group of eye and vision-related problems associated to prolonged computer use (known as computer vision syndrome) are studied. The aim is to select the characteristics of the subject most relevant for the occurrence of this syndrome, and then, to develop a classification model for its prediction. The estimation of this problem is made by means of support vector machines for classification. This machine learning technique will be trained with the support of a genetic algorithm. This provides different patterns of parameters to the training of the support vector machine, improving its performance. The model performance is verified in terms of the area under the ROC curve, which leads to a model with high accuracy in the classification of the syndrome. © 2018, Springer International Publishing AG.","Computer vision syndrome; Genetic Algorithms; Support vector machines","Artificial intelligence; Computer terminals; Education; Genetic algorithms; Health risks; Learning systems; Soft computing; Support vector machines; Vectors; Area under the ROC curve; Classification models; Computer use; Computer vision syndromes; High-accuracy; Machine learning techniques; Model performance; Video display terminals; Computer vision",2-s2.0-85028641731
"RajithKumar B.K., Mohana H.S., Uday J., Uma B.V.","Edge detection of degraded stone inscription Kannada characters using fuzzy logic algorithm",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021225131&doi=10.1007%2f978-981-10-3223-3_2&partnerID=40&md5=84df31ba479832db21c48b49d1d9c308","Digital India is an initiative by the Government of India. This initiative encourages digitization and analysis in all walks of life. Digitization will preserve any historical document and that information can access by any individuals by his finger tip from any place. Stone inscriptions are one of the key historical evidences of literature and culture of that region in the passage of time. Recognition and analysis of stone inscriptions play a pivotal role in deciding the era/age it belongs ad to understand the content. A proper digitization and recognition technique is prerequisite and desired. Here, in this work digitization of characters has been done by using ordinary digital camera. Further, the captured images are pre-processed in order to extract features. In this proposed algorithm, gradient analysis is carried out at every pixel in the x and y directions, based on the result it defines an edge using Fuzzy Inference System. The experiment was conducted on twenty set of analogous degraded stone inscriptions Kannada characters and result obtained was magnificent with better time efficiency compared to prior methods. © Springer Nature Singapore Pte Ltd. 2018.","Digitalization; Edge detection; Fuzzy inference system","Computation theory; Edge detection; Fuzzy inference; Fuzzy systems; Inference engines; Intelligent computing; Digitalization; Fuzzy inference systems; Fuzzy logic algorithms; Government of India; Gradient analysis; Historical documents; Stone inscription; Time efficiencies; Fuzzy logic",2-s2.0-85021225131
"Watanabe M., Takahashi R., Matsuda K., Seto T.","A Cooperative Control Algorithm for Multiple SVRs Using Correlation of Measurement Data of Distribution Line",2018,"Electrical Engineering in Japan (English translation of Denki Gakkai Ronbunshi)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029447636&doi=10.1002%2feej.22964&partnerID=40&md5=27bed34d28d08876c37dabf798956365","In this paper, a cooperative control algorithm for multiple step voltage regulator (SVR) using correlation of measurement data of distribution line is proposed. Conventionally, the control time constant of a SVR placed on the feeder end side was set slower than a SVR placed on the substation side. The unnecessary tap movement of SVR was reduced by this setting. In this case, on the condition that “the photovoltaic power generation output of the feeder end fluctuates” and “only SVR of the end side works”, it is a problem that control of SVR becomes slow. By the proposed method, the SVR settled in end side of a feeder can change its tap rapidly only if the SVR settled in sending side of a feeder will not change its tap by using proposed method. The features of the method are followings: (1) to estimate tap change possibility of the sending side SVR using correlation model of both of the SVR, (2) only use local measurement data of the SVRs for tap change control. By the proposed method, unnecessary tap change operation and lag of tap control are reduced without communication networks. © 2017 Wiley Periodicals, Inc.","cooperate control; distribution network; LRT; power system; SVR; voltage control","Electric power distribution; Grounding electrodes; Photovoltaic cells; Solar energy; Voltage control; Voltage regulators; Cooperative control algorithms; Correlation modeling; Distribution lines; Local measurement; Photovoltaic power generation; power system; Step voltage regulators; Tap change controls; Feeding",2-s2.0-85029447636
"Zhou K., Martin A., Pan Q., Liu Z.","SELP: Semi-supervised evidential label propagation algorithm for graph data clustering",2018,"International Journal of Approximate Reasoning",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031817149&doi=10.1016%2fj.ijar.2017.09.008&partnerID=40&md5=5a8df83cf4f2344815b5a8b6150090e8","With the increasing size of social networks in the real world, community detection approaches should be fast and accurate. The label propagation algorithm is known to be one of the near-linear solutions which is easy to implement. However, it is not stable and it cannot take advantage of the prior information about the network structure which is very common in real applications. In this paper, a new Semi-supervised clustering approach based on an Evidential Label Propagation strategy (SELP) is proposed to incorporate limited domain knowledge into the community detection model. The main advantage of SELP is that it can effectively use limited supervised information to guide the detection process. The prior information about the labels of nodes in the graph, including the labeled nodes and the unlabeled ones, is initially expressed in the form of mass functions. Then the evidential label propagation rule is designed to propagate the labels from the labeled nodes to the unlabeled ones. The communities of each node can be identified after the propagation process becomes stable. The outliers can be identified to be in a special class. Experimental results demonstrate the effectiveness of SELP on both graphs and classical data sets. © 2017 Elsevier Inc.","Community detection; Label propagation; Semi-supervised learning; Theory of belief functions; Uncertainty","Population dynamics; Supervised learning; Uncertainty analysis; Community detection; Label propagation; Semi- supervised learning; Theory of belief functions; Uncertainty; Clustering algorithms",2-s2.0-85031817149
"Kovački N.V., Vidović P.M., Sarić A.T.","Scalable algorithm for the dynamic reconfiguration of the distribution network using the Lagrange relaxation approach",2018,"International Journal of Electrical Power and Energy Systems",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025164313&doi=10.1016%2fj.ijepes.2017.07.005&partnerID=40&md5=37376f0dd9ff395464d4070a8f5ea1ff","This paper proposes a new methodology for the dynamic reconfiguration of the distribution network (DRDN) which is based on the Lagrange relaxation approach. The aim of DRDN is to determine the optimal topologies (configurations) of the distribution network over the specified time interval. The objective is to minimize the active power losses, subject to the following constraints: branch power flow capacities, allowed ranges of bus voltages, radial network configuration, and limited number of switching (open/close) operations for all switching devices. The paper first introduces the “path-switch-to-switch” approach for the modelling of distribution networks, which is used to formulate DRDN as the mixed integer linear programming (MILP) problem. Then, the specified MILP problem is solved using the Lagrange relaxation approach in two-step procedure. In the first step, the associated Lagrange dual problem is solved, which is created by relaxing the switching operation constraints. The Lagrange dual problem is decoupled and much easier to solve than the original problem. In the second step, the solution of the Lagrange dual problem is used to perform the heuristic search, providing the suboptimal, though feasible solution of the original problem. Finally, the presented DRDN model is extended to multi-objective formulation, which also includes the impact of the network reliability and the switching costs to the DRDN process. The robustness and scalability of the developed algorithm (for application in large-scale distribution networks) are demonstrated with two test examples: 15-bus test benchmark and 1021-bus real-world test system. © 2017","Distribution network; Dynamic reconfiguration; Lagrange relaxation; Loss reduction; Mixed integer linear programming; Multi-objective optimization","Benchmarking; Buses; Dynamic models; Electric power distribution; Heuristic algorithms; Lagrange multipliers; Multiobjective optimization; Optimization; Switching; Dynamic re-configuration; Lagrange relaxation; Large-scale distribution; Loss reduction; Mixed integer linear programming; Multi-objective formulation; Power-flow capacity; Switching operations; Integer programming",2-s2.0-85025164313
"Rodríguez Ramos A., Bernal de Lázaro J.M., da Silva Neto A.J., Cruz Corona C., Verdegay J.L., Llanes-Santiago O.","An approach to fault diagnosis using fuzzy clustering techniques",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029405371&doi=10.1007%2f978-3-319-66827-7_21&partnerID=40&md5=b758f3a5d9cb004fe691464840a80772","In this paper a novel approach to design data driven based fault diagnosis systems using fuzzy clustering techniques is presented. In the proposal, the data was first pre-processed using the Noise Clustering algorithm. This permits to eliminate outliers and reduce the confusion as a first part of the classification process. Secondly, the Kernel Fuzzy C-means algorithm was used to achieve greater separability among the classes, and reduce the classification errors. Finally, it can be implemented a step for optimizing the parameters of the NC and KFCM algorithms. The proposed approach was validated using the iris benchmark data sets. The obtained results indicate the feasibility of the proposal. © 2018, Springer International Publishing AG.","Fault diagnosis; FCM algorithm; Fuzzy clustering; KFCM algorithm; Metaheuristics; NC algorithm","Cluster analysis; Copying; Failure analysis; Fault detection; Fuzzy clustering; Fuzzy logic; Fuzzy sets; Pattern matching; Benchmark data; Classification errors; Classification process; Fault diagnosis systems; FCM algorithm; Fuzzy C-means algorithms; Fuzzy clustering techniques; Meta heuristics; Clustering algorithms",2-s2.0-85029405371
"Sethi K.K., Dharavath R., Nyakotey S.","PPS: Parallel pincer search for mining frequent itemsets based on spark",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028590336&doi=10.1007%2f978-3-319-60618-7_35&partnerID=40&md5=0529ac535409e366921e642f1f300398","Association rule mining is one of prominent techniques to discover the relation between data items of a transactional data. The process of mining has been simplified by considering only the frequent itemsets. Pincer search is one of the frequent itemset mining method which combines top-down and bottom-up search techniques to get the benefits of both. Top-down approach in Pincer search reduces the number of candidates in pass of iterations and saves a lot of computing resources. In this work, we present a Parallel Pincer Search (PPS) which is based on distributed implementation on Spark framework. We have converted the search algorithm according to the Spark framework to make it run in parallel. Spark provides a lot of features for the iterative algorithm such as in-memory execution, efficient data structure, better fault tolerant method, etc. We implemented the PPS on a Spark cluster with multiple datasets and analysed the performance. © Springer International Publishing AG 2018.","Apriori algorithm; Frequent itemset mining; Maximal itemset; Pincer search; Spark","Clustering algorithms; Data mining; Electric sparks; Learning algorithms; Mining; Pattern recognition; Soft computing; Apriori algorithms; Distributed implementation; Efficient data structures; Fault-tolerant method; Frequent itemset mining; Itemset; Mining frequent itemsets; Pincer search; Iterative methods",2-s2.0-85028590336
"Solanki N., Panchal G.","A novel machine learning based approach for rainfall prediction",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028368663&doi=10.1007%2f978-3-319-63673-3_38&partnerID=40&md5=145253f9acf270c1f88722c04ff2d651","The climate changes effortlessly nowadays, prediction of climate is very hard. However, the forecasting mechanism is the vital process. It is also a valuable thing as it is the important part of the human life. Accordingly to the research, the weather forecast of rainfall intensity conducted. The remarkable commitment of this proposal is in the implementation of a hybrid intelligent system data mining technique for solving novel practical problems, Hybrid Intelligent system data mining consists of the combination of Artificial Neural Network and the proper usage of Genetic Algorithm. In this research, Genetic algorithm is utilized the type of inputs, the connection structure between the inputs and the output layers and make the training of neural network more efficient. In ANN, Multi-layer Perceptron (MLP) serves as the center data mining (DM) engine in performing forecast tasks. Back Propagation algorithm used for the trained the neural network. During the training phase of the proposed approach, it gains the optimal values of the connection weights which, in fact, utilized as the part of the testing phase of the MLP. Here, the testing phase is used to bring about the rainfall prediction accuracy. It may be noted that the information/data is used to cover the information from the variables namely temperature, cloud fraction, wind, humidity, and rainfall. © 2018, Springer International Publishing AG.","Artificial neural network; Genetic algorithm; Rainfall prediction","Backpropagation; Backpropagation algorithms; Climate change; Data mining; Forecasting; Genetic algorithms; Intelligent systems; Learning algorithms; Learning systems; Neural networks; Rain; Connection structures; Connection weights; Hybrid intelligent system; Multi layer perceptron; Practical problems; Rainfall intensity; Rainfall prediction; Training phase; Weather forecasting",2-s2.0-85028368663
"Crawford B., Soto R., Caballero H.","Solving the Set Covering Problem Using Cat Swarm Optimization Algorithm with a Variable Mixture Rate and Population Restart",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029598277&doi=10.1007%2f978-3-319-67621-0_14&partnerID=40&md5=108592bcb456a760e482cafdcc101ea3","Cat swarm optimization (CSO) is a novel metaheuristic based on swarm intelligence, presented in 2006 has demonstrated great potential generating good results and excellent performances simulating the behavior of domestic cats using two behavior: seeking and tracing mode, this mode are classified using a mixture rate (MR), this parameter finally defines the number of individuals who work by exploring and exploiting. This work presents an improvement structure of a binary cat swarm optimization using a total reboot of the population when loss diversity it is detected. © 2018, Springer International Publishing AG.","Combinatorial Optimization; Diversity loss; Metaheuristics","Artificial intelligence; Combinatorial optimization; Computational methods; Mixtures; Diversity loss; Meta heuristics; Metaheuristic; Set covering problem; Swarm optimization; Swarm optimization algorithms; Optimization",2-s2.0-85029598277
"Sharma N., Rajput S.S., Dwivedi A.K., Shrimali M.","P-RED: Probability based random early detection algorithm for queue management in MANET",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031413460&doi=10.1007%2f978-981-10-3773-3_62&partnerID=40&md5=0f2e7401d883ab2b1f338eafac314b83","Thousands of flows could traverse an Internet gateway at each given time. Ideally, every single of these flows should dispatch at precisely its fair allocate, and the gateway should not demand to make each decisions. In exercise, the burden inclines to fluctuate and the traffic origins incline to be greedy. Therefore, a gateway queuing strategy has to permit buffering of provisional excess burden but furnish negative feedback if the excess burden persists. Such a strategy has to stop elevated stay by manipulating the queue size, it has to circumvent compelling queues to be too short, that can cause low utilization; and it have to furnish negative feedback fairly. As RED queues precisely present larger than drop_tail queues, it is tough to parameterize RED queues to give good presentation below disparate Congn scenarios. One of the aims of RED is to stabilize the queue lengths in routers, but that does not prosper because the equilibrium queue length powerfully depends on the number of TCP connections. We present Probability based Random Early Detection (P-RED), a modification to RED that enhances fairness after disparate traffic kinds allocate a gateway. P-RED is extra competent in isolating ill-behaved flows that turns out to protect the bursty and low speed flows in a larger amount. © Springer Nature Singapore Pte Ltd. 2018.","Congestion control; MANET; Queue management; Random early detection (RED)","Congestion control (communication); Feedback; Queueing theory; Signal detection; Internet gateway; Low-speed flow; MANET; Queue management; Queuing strategy; Random early detection algorithms; Random Early Detections; TCP connections; Gateways (computer networks)",2-s2.0-85031413460
"Pei L., Dong K., Tang Y., Zhang B., Yu C.","An improved clone selection algorithm for set optimization",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028734221&doi=10.1007%2f978-981-10-6232-2_34&partnerID=40&md5=eea3e407ef5b3d6db0ec0a51244ef727","An improved CSA is put forward based on the shortcomings of traditional CSA which cannot meliorate set well. First, antibody cleaning is added, and antibody selection is improved. This step is very important for the process of set optimization, and antibody cleaning’s aim is to delete the similar antibody. Antibody selection is to perform the local search to cleaned antibody set, and the process of total optimal solution searching is deleted. Then, the objective function of the antibody set is made to judge set’s quality which does not exist in the traditional method. Each time the local search is completed, the affinity of antibody set needs to be calculated, and the several times iterative calculations need to be compared. In addition, the process of best individual selection is cut out, and the quality of analysis is increased. At last, the experiment and simulation prove that the improved CSA is effective. © Springer Nature Singapore Pte Ltd. 2018.","Antibody cleaning; Objective function; The optimal set","Cleaning; Iterative methods; Local search (optimization); Optimization; Systems engineering; Clone selection algorithms; Cut-out; Iterative calculation; Local search; Objective functions; Optimal sets; Optimal solutions; Set optimizations; Antibodies",2-s2.0-85028734221
"Nikolaev N., Yordanov S., Vasilev R.","An optimization algorithm for simulating smart-grid means for distribution grid balancing",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031408290&doi=10.1007%2f978-3-319-68321-8_37&partnerID=40&md5=8620f83769c755fa7d23c0bc5728d542","In the near future, Smart-Grid technologies will have an incredible impact on the economics of power systems and on environment. This will be possible thanks to the intelligent communication and computer systems, which would allow the system to accommodate much more energy from renewables by combining different technologies for energy storage, electric vehicles and demand response. The main contribution of this paper is the development of models for the different components of the Smart-Grid, which can be easily generalized for many different studies. The modelling framework includes energy storage, renewable energy sources, electric vehicles and demand response. We use the problem of distribution grid power balancing to illustrate the application of the models for improving the economic performance of a balancing group. The problem is formulated as a mixed-integer linear program and can help energy companies and custumers to make investment decisions for smart-grid. © Springer International Publishing AG 2018.","Demand response; Electric vehicle; Energy storage; Optimization; Renewable energy; Smart-grid","Economic analysis; Economics; Electric power system economics; Electric power transmission networks; Electric vehicles; Energy storage; Integer programming; Investments; Optimization; Renewable energy resources; Vehicle to vehicle communications; Vehicles; Demand response; Intelligent communication; Mixed integer linear program; Optimization algorithms; Renewable energies; Renewable energy source; Smart grid; Smart Grid technologies; Smart power grids",2-s2.0-85031408290
"Huang Y., Gao L., Yi Z., Tai K., Kalita P., Prapainainar P., Garg A.","An application of evolutionary system identification algorithm in modelling of energy production system",2018,"Measurement: Journal of the International Measurement Confederation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029579957&doi=10.1016%2fj.measurement.2017.09.009&partnerID=40&md5=3ad9e7525435a53c926c8179094e9783","The present work introduces the literature review on System Identification (SI) by classifying it into several fields. The review summarizes the need of evolutionary SI method that automates the model structure selection and its parameter evaluation based on only the system data. In this context, the evolutionary SI approach of genetic programming (GP) is applied in modeling and optimization of cleaner energy system such as direct methanol fuel cell. The functional response of the power density of the fuel cell with respect to input conditions is selected based on the minimum training error. Further, an experimental data is used to validate the robustness of the formulated GP model. The analysis based on 2-D and 3-D parametric procedure is further conducted to reveals insights into functioning of the fuel cell. The pareto front obtained from optimization of model reveals that the operating temperature of 64.5 °C, methanol flow rate of 28.04 mL/min and methanol concentration of 0.29 M are the optimum settings for achieving the maximum power density of 7.36 mW/cm2 for DMFC. © 2017 Elsevier Ltd","Energy system; Fuel cell; Genetic programming; Modelling methods; System identification","Fuel cells; Genetic algorithms; Genetic programming; Identification (control systems); Methanol; Methanol fuels; Religious buildings; Energy production systems; Energy systems; Maximum power density; Methanol concentration; Model structure selection; Modeling and optimization; Modelling method; Operating temperature; Direct methanol fuel cells (DMFC)",2-s2.0-85029579957
"Pawar M.M., Talbar S.N.","Wavelet statistical feature selection using genetic algorithm with fuzzy classifier for breast cancer diagnosis",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026778943&doi=10.1007%2f978-981-10-3373-5_8&partnerID=40&md5=883fd3078a23fe4d03315f6218a83a27","Breast cancer diagnosis at its early stage is achieved through mammogram analysis. This paper presents a genetic fuzzy system (GFS) for feature selection and mammogram classification. Mammogram image is decomposed into sub-bands using wavelet transform. Wavelet statistical features are obtained from 100 biggest wavelet coefficients from each sub-band. From each level of decomposition, 20 WSFs are extracted. Therefore, total 80 WSFs are extracted from four levels of decomposition. At first level, 20 WSFs are given to GFS, which selects five features with classification accuracy of 60.94%. For second level, 18 features are selected from 40 features and classification accuracy of 80.66% is obtained. Further, at third level, 18 features are selected from 60 features with classification accuracy of 85.25%. At last, for fourth level, 21 features are selected from 80 features and classification accuracy improved to 93.77%. © Springer Nature Singapore Pte Ltd. 2018.","Breast cancer diagnosis; Feature selection; Wavelet statistical feature","Computation theory; Diseases; Feature extraction; Fuzzy sets; Fuzzy systems; Genetic algorithms; Intelligent computing; Mammography; Wavelet transforms; X ray screens; Breast cancer diagnosis; Classification accuracy; Fuzzy classifiers; Genetic fuzzy systems; Mammogram analysis; Mammogram classifications; Statistical features; Wavelet coefficients; Classification (of information)",2-s2.0-85026778943
"Tian X., Fan C., Liu J., Ding Q.","Design and implementation of network video encryption system based on STM32 and AES algorithm",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026627142&doi=10.1007%2f978-3-319-63859-1_7&partnerID=40&md5=ac3207aebcfdcb5836e32e58bac63790","Due to the rapid development of the Internet, the network video surveillance technology has been widely implemented to overcome the geographical constraints in the network by monitoring the target in any place. There may be some problems when the Internet providing convenience because it’s available to global users. For example, video reveal may happen in some situations, which is a threaten to government and national security. So encryption network video surveillance research is imperative. The purpose of this paper is to protect the security of network video surveillance information, and to prevent the useful information from being intercepted and stolen by criminals. © Springer International Publishing AG 2018.","CRYP; Hardware encryption; STM32","Monitoring; Multimedia signal processing; National security; Network security; Security systems; Signal processing; AES algorithms; CRYP; Design and implementations; Network video; STM32; Cryptography",2-s2.0-85026627142
"Cimbálník J., Hewitt A., Worrell G., Stead M.","The CS algorithm: A novel method for high frequency oscillation detection in EEG",2018,"Journal of Neuroscience Methods",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029704167&doi=10.1016%2fj.jneumeth.2017.08.023&partnerID=40&md5=d10252ba81f99f7258256dcc993bff14","Background High frequency oscillations (HFOs) are emerging as potentially clinically important biomarkers for localizing seizure generating regions in epileptic brain. These events, however, are too frequent, and occur on too small a time scale to be identified quickly or reliably by human reviewers. Many of the deficiencies of the HFO detection algorithms published to date are addressed by the CS algorithm presented here. New Method The algorithm employs novel methods for: 1) normalization; 2) storage of parameters to model human expertise; 3) differentiating highly localized oscillations from filtering phenomena; and 4) defining temporal extents of detected events. Results Receiver-operator characteristic curves demonstrate very low false positive rates with concomitantly high true positive rates over a large range of detector thresholds. The temporal resolution is shown to be +/−∼5 ms for event boundaries. Computational efficiency is sufficient for use in a clinical setting. Comparison with existing methods The algorithm performance is directly compared to two established algorithms by Staba (2002) and Gardner (2007). Comparison with all published algorithms is beyond the scope of this work, but the features of all are discussed. All code and example data sets are freely available. Conclusions The algorithm is shown to have high sensitivity and specificity for HFOs, be robust to common forms of artifact in EEG, and have performance adequate for use in a clinical setting. © 2017 Elsevier B.V.","Detection algorithm; Frequency dominance; HFO; High frequency oscillations; Ripples","algorithm; Article; artifact; Cimbalnik Stead algorithm; clinical article; electrode implantation; electroencephalogram; focal epilepsy; high frequency oscillation; human; microelectrode; priority journal; sensitivity and specificity",2-s2.0-85029704167
"Cai L., Qu S., Cheng G.","Two-archive method for aggregation-based many-objective optimization",2018,"Information Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029363884&doi=10.1016%2fj.ins.2017.08.078&partnerID=40&md5=849e1af697516a69415b78668bc465ea","In this paper, a novel two-archive method is proposed for solving many-objective optimization problems. Our aim is to exploit the advantages of using two separate archives to balance the convergence and diversity. To this end, two updating strategies based on the aggregation-based framework are presented and incorporated into the two-archive method. In addition, we further extend this method by eliminating the restricted neighbourhood models. The proposed algorithms have been tested extensively on a number of well-known benchmark problems with 3–20 objectives. Experimental results reveal that the proposed algorithms work well on the many-objective optimization problems with different characteristics. © 2017 Elsevier Inc.","Aggregation-based method; Evolutionary computation; Many-objective optimization; Multi-objective evolutionary algorithms; Two archives","Optimization; Bench-mark problems; Many-objective optimizations; Multi objective evolutionary algorithms; Neighbourhood models; Two archives; Updating strategy; Evolutionary algorithms",2-s2.0-85029363884
"Shankar A., Jaisankar N.","Security enabled cluster head selection for wireless sensor network using improved firefly optimization",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028603812&doi=10.1007%2f978-3-319-60618-7_18&partnerID=40&md5=19804b0e57213fd514a802d62cdb2a9b","An energy efficient algorithm with security is necessary to extend the existence of the Wireless Sensor Network (WSN). Since sensing, data processing and data transmission by sensor nodes requires more energy, the sensor node become dead due to the presence of rechargeable batteries. In this paper, a security constraint cluster head selection methodology is implemented using Firefly with Dual Update Process (FFDUP) algorithm to reach the objectives such as minimization of energy, delay and distance and maximization of security. Then the analysis based on the network sustainability, manner of cluster head distribution, security awareness and trade-off occurred from the proposed FFDUP algorithm is determined and validated by comparing with conventional algorithms such as Artificial Bee Colony (ABC), FABC, Firefly (FF) and Artificial Bee Colony- Dynamic Scout Bee (ABC-DS). The analytical results proved that the proposed algorithm for the cluster head selection provides superior performance when compared with existing algorithm. © Springer International Publishing AG 2018.","Cluster head selection; Energy awareness; FFDUP; Risk awareness; WSN","Bioluminescence; Clustering algorithms; Data handling; Economic and social effects; Energy efficiency; Network security; Optimization; Pattern recognition; Risk perception; Sensor nodes; Soft computing; Artificial bee colonies; Artificial bee colonies (ABC); Cluster-head selections; Conventional algorithms; Energy awareness; Energy efficient algorithms; FFDUP; Risk awareness; Wireless sensor networks",2-s2.0-85028603812
"Cerroni D., Giommi D., Manservisi S., Mengini F.","Preliminary monolithic fluid structure interaction model for ventricle contraction",2018,"Lecture Notes in Applied and Computational Mechanics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028922876&doi=10.1007%2f978-3-319-59548-1_12&partnerID=40&md5=280d79baf40ea8456154f38f301ceaee","In this work we test the performance of different algorithms for the solution of a monolithic Fluid Structure Interaction (FSI) problem with a simplified ventricle model with the purpose to reduce the computational time. We study this challenging FSI problem by solving the fully coupled and the projection algorithm with a different number of penalty correction steps. The proposed FSI penalty projection algorithm is a modification of the Chorin method for fluids based on a predictor and a corrector step. The performance of the modified algorithm is tested by comparing the results obtained with the standard coupled algorithm with the ones obtained with the modified penalty projection scheme. © Springer International Publishing AG 2018.",,"Computational mechanics; Computational time; Coupled algorithms; Fully-coupled; Modified algorithms; Projection algorithms; Projection schemes; Fluid structure interaction",2-s2.0-85028922876
"Zaporozhets D., Zaruba D.","Bacterial foraging optimization for VLSI fragments placement",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031422864&doi=10.1007%2f978-3-319-68321-8_35&partnerID=40&md5=2fda6715446d29f2cb35d2161227a63c","The paper deals with one of the most significant problem of computer design – a VLSI placement problem. The authors prove a relevance of new heuristic methods for the given problem. The VLSI placement problem is formulated and an optimization criterion is suggested. As an optimization method there is suggested an algorithm based on bacterial colony behavior in nature according with environment conditions. On the basis of these observations it is developed a new bioinspired algorithm for the VLSI placement problem. There are conducted series of computational experiments for comparison of the developed algorithm with known VLSI placement algorithms on the basis of IBM benchmarks. Obtained results are represented in a table. Conducted researches shown the efficiency of the suggested approach better then 8–10% on average. © Springer International Publishing AG 2018.","Bacterial foraging optimization; Bioinspired algorithms; IBM benchmarks; Optimization; VLSI","Heuristic methods; VLSI circuits; Bacterial foraging optimization; Bio-inspired algorithms; Computational experiment; Efficiency of the suggested approaches; Environment conditions; VLSI; VLSI placement algorithms; VLSI placement problems; Optimization",2-s2.0-85031422864
"Pratiwi L., Choo Y.-H., Muda A.K.","A review on hierarchical clustering-based covariance model to ncRNA identification",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028595458&doi=10.1007%2f978-3-319-60618-7_56&partnerID=40&md5=1050011a72e7b011751b3eef91f80fd5","Recent discoveries have revealed that functional discovery of noncoding RNAs (ncRNAs) has gradually acquired attention among researchers in bioinformatics domain. ncRNA families are believed to be responsible for a variety of biological functionalities, ranging from gene expression regulation to catalytic activities, when the others are still to be unveiled. These new recoveries have opened many aspects in ncRNA research, for example in functional subgroups discovery. Hence, cross fertilization solutions originated from computational intelligence concepts and algorithms has started to achieve promising results. For instance, data clustering is one of the popular techniques in many different domains for the purpose of Covariance Model (CM) in ncRNA identification. Hierarchical clustering is the most frequently used mathematical technique to group a set of ncRNAs in human into different families based on sequence similarity. However, conventional algorithms have some shortcomings such as the sequence structures of each family will be significantly diluted when the number of sequence features for known family dataset increases. This study presents a literature review on the hierarchical clustering algorithm and its variants for ncRNA family identification using the sequence structure. © Springer International Publishing AG 2018.","Covariance model; Hierarchical clustering; ncRNA identification; Noncoding RNA","Catalyst activity; Gene expression; Gene expression regulation; Nucleic acids; Pattern recognition; Soft computing; Conventional algorithms; Covariance modeling; Cross fertilization; Hier-archical clustering; Hierarchical clustering algorithms; Non-coding RNAs; Sequence similarity; Sequence structure; Clustering algorithms",2-s2.0-85028595458
"Kazmi S., Hussain H.M., Khan A., Ahmad M., Qasim U., Khan Z.A., Javaid N.","Balancing demand and supply of energy for smart homes",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026305717&doi=10.1007%2f978-3-319-61566-0_94&partnerID=40&md5=ac4059278157484fa71444fdbe1266b4","Smart grid (SG) is one of the most advanced technologies, which plays a key role in maintaining balance between demand and supply by implementing demand response (DR). In SG the main focus of the researchers is on home energy management (HEM) system, that is also called demand side management (DSM). DSM includes all responses, which adjust the consumer’s electricity consumption pattern, and make it match with the supply. If the main grid cannot provide the users with sufficient energy, then the smart scheduler (SS) integrates renewable energy source (RES) with the HEM system. This alters the peak formation as well as minimizes the cost. Residential users basically effect the overall performance of traditional grid due to maximum requirement of their energy demand. HEM benefits the end users by monitoring, managing and controlling their energy consumption. Appliance scheduling is integral part of HEM system as it manages energy demand according to supply, by automatically controlling the appliances or shifting the load from peak to off peak hours. Recently different techniques based on artificial intelligence (AI) are being used to meet aforementioned objectives. In this paper, three different types of heuristic algorithms are evaluated on the basis of their performance against cost saving, user comfort and peak to average ratio (PAR) reduction. Two techniques are already existing heuristic techniques i.e. harmony search (HS) algorithm and enhanced differential evolution (EDE) algorithm. On the basis of aforementioned two algorithms a hybrid approach is developed i.e. harmony search differential evolution (HSDE). We have done our problem formulation through multiple knapsack problem (MKP), that the maximum consumption of electricity of consumer must be in the range which is bearable for utility and also for consumer in sense of electricity bill. Finally simulation of the proposed techniques will be conducted in MATLAB to validate the performance of proposed scheduling algorithms in terms of minimum cost, reduced peak to average ratio (PAR), waiting time and equally distributed energy consumption pattern in each hour of a day to benefit both utility and end users. © Springer International Publishing AG 2018.",,"Automation; Combinatorial optimization; Cost reduction; Costs; Energy management; Energy management systems; Energy utilization; Evolutionary algorithms; Heuristic algorithms; Heuristic methods; Intelligent buildings; MATLAB; Optimization; Renewable energy resources; Scheduling; Scheduling algorithms; Differential Evolution; Distributed energies; Electricity consumption patterns; Heuristic techniques; Home energy managements; Multiple knapsack problem; Peak to average ratios; Renewable energy source; Smart power grids",2-s2.0-85026305717
"Bečirović V., Pavić I., Filipović-Grčić B.","Sensitivity analysis of method for harmonic state estimation in the power system",2018,"Electric Power Systems Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030706350&doi=10.1016%2fj.epsr.2017.07.029&partnerID=40&md5=879ec6965308779e0eeb001639afe717","In this paper, a new algorithm for harmonic state estimation in power systems is represented. The algorithm is based on node voltage method, Kron reduction matrix, modeling of power system in frequency domain using phase values and optimization genetic algorithm. The algorithm uses measured voltage and current harmonics as an input data, with partially known data about transmission network. Algorithm estimates RMS and angle values of voltage harmonics in the unmonitored part of power system. Sensitivity analysis of proposed algorithm was conducted on a case study of 110 kV transmission network. Admittance matrix of power system is identified by using genetic algorithm with an accuracy of 0.5%, while an error of harmonic voltage estimation is lower than 1.129%. © 2017 Elsevier B.V.","Harmonic estimation; Kron reduction matrix; Optimization evaluation genetic algorithms; Power quality; Power systems; Sensitivity analysis","Frequency domain analysis; Genetic algorithms; Harmonic analysis; Matrix algebra; Optimization; Power quality; Quality control; Standby power systems; State estimation; Admittance matrices; Harmonic estimation; Harmonic state estimation; Harmonic voltages; Kron reduction; Modeling of power systems; Optimization genetic algorithms; Voltage harmonics; Sensitivity analysis",2-s2.0-85030706350
"Radomskyi O.","Principles of mobile walking robot control in scope of technical monitoring tasks",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020827971&doi=10.1007%2f978-3-319-59415-6_36&partnerID=40&md5=00be60509078dfef430a95017d552bf1","The article describes control synthesis for mobile walking robot, which has an interval mathematical model. We proposed proof of concept for mobile walking robot, carrying load up to sixty percents of robot’s mass. Control system includes a computing unit, seven servos, a three-axis accelerometer and a moving camera operating in a visible optical range. Results of interval algorithms synthesis are shown for robot as an object of automatic control (OAC), with interval mathematical model. We defined the operational mode range of the system, its structure and interval parameters of mathematical model. It is shown that setting of interval values allows adequate modeling and description of processes in dynamic systems such as mobile walking robots. Main goal of this paper is to show possibility of classical Bode Diagram modification and application for the synthesis of interval control. © Springer International Publishing AG 2018.","Bode diagram; Control algorithms; Four legged robot; Interval model; Mobile walking robot","Algorithms; Automation; Bode diagrams; Mobile robots; Walking aids; Control synthesis; Four-legged robot; Interval algorithms; Interval models; Interval parameter; Operational modes; Three axis accelerometers; Walking robots; Robots",2-s2.0-85020827971
"Djenouri Y., Belhadi A., Fournier-Viger P., Lin J.C.-W.","An hybrid multi-core/GPU-based mimetic algorithm for big association rule mining",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032622722&doi=10.1007%2f978-981-10-6487-6_8&partnerID=40&md5=dfddf0a164fade7e1e9c555b7a0a07d2","This paper addresses the problem of big association rule mining using an evolutionary approach. The mimetic method has been successfully applied to small and medium size databases. However, when applied on larger databases, the performance of this method becomes an important issue and current algorithms have very long execution times. Modern CPU/GPU architectures are composed of many cores, which are massively threaded and provide a large amount of computing power, suitable for improving the performance of optimization techniques. The parallelization of such method on GPU architecture is thus promising to deal with very large datasets in real time. In this paper, an approach is proposed where the rule evaluation process is parallelized on GPU, while the generation of rules is performed on a multi-core CPU. Furthermore, an intelligent strategy is proposed to partition the search space of rules in several independent sub-spaces to allow multiple CPU cores to explore the search space efficiently and without performing redundant work. Experimental results reveal that the suggested approach outperforms the sequential version by upto at 600 times for large datasets. Moreover, it outperforms the-state-of-the-art high performance computing based approaches when dealing with the big WebDocs dataset. © Springer Nature Singapore Pte Ltd. 2018.","Association rule mining; Big data; GPU algorithm; Mimetic algorithm; Multi-core algorithm",,2-s2.0-85032622722
"Fujino S., Hatanaka T., Mori N., Matsumoto K.","The evolutionary deep learning based on deep convolutional neural network for the anime storyboard recognition",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022198178&doi=10.1007%2f978-3-319-62410-5_34&partnerID=40&md5=0c523004673c4ee0d5e4c94305962bb6","Recently, the researches of image recognition have been developed remarkably by means of the deep learning. In this study, we focused on the anime storyboards and applied deep convolutional neural networks (DCNNs) to those data. There exists one problem that it takes a lot of effort to tune DCNN hyperparameters. To solve this problem, we propose a novel method called evolutionary the deep learning (evoDL) by means of genetic algorithms (GAs). The effectiveness of evoDL is confirmed by computer simulations taking a real anime storyboard recognition problem as an example. © Springer International Publishing AG 2018.","Anime storyboard; Deep convolutional network; Genetic algorithm; Hyperparameter","Artificial intelligence; Convolution; Deep neural networks; Distributed computer systems; Education; Evolutionary algorithms; Genetic algorithms; Image recognition; Neural networks; Problem solving; Anime storyboard; Convolutional networks; Convolutional neural network; Genetic algorithm (GAs); Hyper-parameter; Hyperparameters; Deep learning",2-s2.0-85022198178
"Cammarata G., di Stefano A., Morana G., Zito D.","Energy-aware routing in A4SDN",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026324608&doi=10.1007%2f978-3-319-61566-0_53&partnerID=40&md5=be2e41802a49b1f7923e2b2f20d9d652","The concept of Green Computing and, more specifically, energy-aware solutions have gained attention in the last years in many fields of ICT: network management is one of those. Today, power consumption is considered a fundamental parameter, as well as latency, bandwidth or error rate, to take into account when a new routing strategy is designed. In this paper the authors introduce an energy-aware extension of the A4SDN, an algorithm for traffic engineering on SDN based on the Alienated Ant Algorithm, a heuristic solution inspired by a non-natural behaviour of ants colonies. In order to evaluate its performance, the proposed energy-aware approach is compared with the standard A4SDN and with two deterministic solution based on Dijkstra’s Algorithm. © Springer International Publishing AG 2018.",,"Complex networks; Green computing; Power management; Power management (telecommunication); Ant algorithms; Energy aware; Energy aware approaches; Energy-aware routing; Heuristic solutions; Routing strategies; S-algorithms; Traffic Engineering; Routing algorithms",2-s2.0-85026324608
"Nama S., Saha A.K.","An ensemble symbiosis organisms search algorithm and its application to real world problems",2018,"Decision Science Letters",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025167735&doi=10.5267%2fj.dsl.2017.6.006&partnerID=40&md5=068dff5484e240df3d7d00f6825d4b61","In this study, an ensemble algorithm has been proposed, called Quasi-Oppositional Symbiosis Organisms Search (QOSOS) algorithms, by incorporating the quasi-oppositional based learning (QOBL) strategy into the newly proposed Symbiosis Organisms Search (SOS) algorithm for solving unconstrained global optimization problems. The QOBL is incorporated into the basic SOS algorithm due to the balance of the exploration capability of QOBL and the exploitation potential of SOS algorithm. To validate the efficiency and robustness of the proposed Quasi-Oppositional Symbiosis Organisms Search (QOSOS) algorithms, it is applied to solve unconstrained global optimization problems. Also, the proposed QOSOS algorithm is applied to solve two real world global optimization problems. One is gas transmission compressor design optimization problem and another is optimal capacity of the gas production facilities optimization problem. The performance of the QOSOS algorithm is extensively evaluated and compares favorably with many progressive algorithms. © 2018 Growing Science Ltd. All rights reserved.","Ensemble algorithm; Quasi-opposition based learning (QOBL); Symbiosis organisms search (SOS) algorithm; Unconstrained global optimization problem",,2-s2.0-85025167735
"Nagula Meera S., Srinivasa Kumar D., Rao S.","Ad Hoc networks: Route discovery channel for mobile network with low power consumption",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029812248&doi=10.1007%2f978-981-10-4280-5_70&partnerID=40&md5=27b169786bf492ad7ef025cbab2c4e87","The mobile networks are the independent node networks with limited power sources and mobility. The source node acts as an intermediate node for communication with the target nodes with direct transmission range of source node. For the clear network establishment between the source and the target nodes, the selected node must have the sufficient power and minimal power consumption. Hence, establishing the stable path between the source and destination nodes is crucial for multicast routing network paths. For multicasting networks, a special route discovery channel is proposed for mobile ad hoc networks. This approach is based on the evolutionary strategy. The topology discriminates other tree-based multicast routing topologies by adopting evolutionary computation strategy called genetic algorithm to select the multicast tree with optimal intermediate nodes that have the maximal residual energy and minimal energy usage. © Springer Nature Singapore Pte Ltd. 2018.","Ad hoc; Mobile networks; Multicasting","Electric power utilization; Evolutionary algorithms; Genetic algorithms; Low power electronics; Mobile telecommunication systems; Multicasting; Network routing; Routing algorithms; Topology; Trees (mathematics); Wireless networks; Ad hoc; Destination nodes; Evolutionary strategies; Intermediate node; Low-power consumption; Multicast routing; Multicasting networks; Transmission ranges; Mobile ad hoc networks",2-s2.0-85029812248
"Satyanarayana S., Sravan Kumar P., Sridevi G.","Improved process scheduling in real-time operating systems using support vector machines",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029794449&doi=10.1007%2f978-981-10-4280-5_63&partnerID=40&md5=99af09e1597817c35ac59779d7c56aa5","In the field operating systems, most advanced scheduling method is Multilevel Feedback Scheduling. There are multiple queues with different level priorities (high to low). Selection of each process from a queue is based on the priority of the queue. Support Vector Machine (SVM) method is learning linear predictions in high-dimensional feature spaces. SVM approach can handle the sample complexity challenges by searching large margin separators. In this paper, we are proposing an innovative machine learning Support Vector Machines to predict priorities of multiple queues based on the knowledge of past processes in real-time Operating Systems. This approach can train each queue with linear predictions. So that real-time operating systems like Embedded Systems/Firmware can handle nonhomogenous tasks also. The problem of predicting large volume of processes can be solved with high performance. This algorithm is tested with onelakh processes and these processes are scheduled in 1 min 5.377 s. © Springer Nature Singapore Pte Ltd. 2018.","Dynamic allocations; Priority; Process scheduling; Process type; Queue; Real-time operating systems; Self-learning algorithms; Tasks; Vector","Computer operating systems; Embedded systems; Forecasting; Learning algorithms; Learning systems; Queueing theory; Scheduling; Support vector machines; Vector spaces; Vectors; Dynamic allocations; Priority; Process scheduling; Queue; Real time operating system; Self learning algorithms; Tasks; Real time systems",2-s2.0-85029794449
"Quiñonez Y., Barrera F., Bugueño I., Bekios-Calfa J.","Simulation and path planning for quadcopter obstacle avoidance in indoor environments using the ROS framework",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032684349&doi=10.1007%2f978-3-319-69341-5_27&partnerID=40&md5=f0ba189a104f55fadc7911237d1ba332","This work focuses on the analysis of different algorithms dedicated to the planning of trajectories in a quadcopter. The times and distances of the paths from one point to another have been evaluated autonomously, and the evaluation of the reactive algorithms Bug1, Bug2 and DistBug have been considered to carry out the planning of the quadcopter paths. From the experiments and metrics defined, the efficiency and robustness of the algorithms have been determined. To carry out the implementation of the experiments, we have chosen and evaluated an environment based on the Robot Operating System (ROS) and Gazebo development platform. © Springer International Publishing AG 2018.","Bug algorithm; Robotic software framework; ROS; Unmanned aerial vehicle","Application programs; Computer programming; Process engineering; Software engineering; Unmanned aerial vehicles (UAV); Bug algorithms; Development platform; Indoor environment; Reactive algorithms; Robot operating systems (ROS); Robotic software frameworks; Motion planning",2-s2.0-85032684349
"Eremeev A.P., Kozhukhov A.A.","Methods and program tools based on prediction and reinforcement learning for the intelligent decision support systems of real-time",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031405246&doi=10.1007%2f978-3-319-68321-8_8&partnerID=40&md5=2eaf57d2b8a2bb43a2c3c9de0eea4374","The paper considers integrated tools based on multi-agent temporal differences reinforcement learning and statistical modules. Implemented algorithms of reinforcement learning methods are described. The possibilities of including anytime algorithms into the forecasting subsystem type of intelligent decision support system of real-time for improving performance and reducing response and execution time were proposed. The work is supported by RFBR and BRFBR. © Springer International Publishing AG 2018.","Anytime algorithm; Artificial intelligence; Decision support; Forecasting; Intelligent system; Real time; Reinforcement learning","Artificial intelligence; Decision support systems; Forecasting; Intelligent systems; Learning algorithms; Multi agent systems; Real time systems; Any-time algorithms; Decision supports; Improving performance; Integrated tools; Intelligent decision support systems; Real time; Reinforcement learning method; Temporal differences; Reinforcement learning",2-s2.0-85031405246
"Kowalczuk Z., Bia̷laszewski T.","Approximate quality criteria for difficult multi-objective optimization problems",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028307544&doi=10.1007%2f978-3-319-64474-5_17&partnerID=40&md5=985f32e8e5e2363a136133b1cc1396b8","This paper introduces approximate analytic quality criteria useful in assessing the efficiency of evolutionary multi-objective optimization (EMO) procedures. We present a summary of extensive research into computing. In the performed comparative study we take into account the various approaches of the state-of-the-art, in order to objectively assess the EMO performance in highly dimensional spaces; where some executive criteria, such as those based on the true Pareto front, are difficult to calculate. Whereas, on the other hand, the proposed approximated quality criteria are easy to implement, computationally inexpensive, and sufficiently effective. © Springer International Publishing AG 2018.","Approximation; Evolutionary computations; Genetic algorithms; Multi-objective optimization; Pareto-optimality; Quality criteria","Approximation algorithms; Evolutionary algorithms; Fault tolerance; Genetic algorithms; Optimization; Pareto principle; Approximation; Comparative studies; Dimensional spaces; Evolutionary multiobjective optimization; Multi-objective optimization problem; Pareto-optimality; Quality criteria; State of the art; Multiobjective optimization",2-s2.0-85028307544
"Wang Y., Ding F., Xu L.","Some new results of designing an IIR filter with colored noise for signal processing",2018,"Digital Signal Processing: A Review Journal",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031722498&doi=10.1016%2fj.dsp.2017.09.006&partnerID=40&md5=8de95a31b965b459b703fc50d79e3a65","The design of adaptive finite impulse response filters is a linear optimization problem and the design of adaptive infinite impulse response (IIR) filters in the presence of observation noise is a nonlinear optimization problem. This paper considers the parameter estimation issues of an infinite impulse response (IIR) filter with colored noise which is treated as an autoregressive process. The key is to investigate novel estimation methods of an IIR filter with an autoregressive disturbance noise from the viewpoint of the observation data filtering. Firstly, we simply give the least mean square (LMS) algorithm for an IIR filter with autoregressive noise and derive a multi-innovation LMS (MI-LMS) algorithm for improving the parameter estimation accuracy. Secondly, we present a data filtering based LMS algorithm and a data filtering based MI-LMS algorithm for further improving the parameter estimation accuracy. The theoretical analyses show that the proposed algorithms are convergent and the simulation results indicate that the MI-LMS algorithm and the data filtering based MI-LMS algorithm are superior to the LMS algorithm and the data filtering based LMS algorithm in accuracy, respectively. The proposed methods in this paper have been extended to an IIR filter with autoregressive moving average noise. Finally, two simulation examples test the performances of the proposed algorithms. © 2017 Elsevier Inc.","Convergence analysis; Filtering technique; IIR filter; LMS algorithm; Parameter estimation","Bandpass filters; Impulse response; Linear programming; Nonlinear programming; Optimization; Parameter estimation; Signal processing; White noise; Autoregressive moving average; Convergence analysis; Filtering technique; Infinite impulse response; Least mean square algorithms; Linear optimization problems; LMS algorithms; Non-linear optimization problems; IIR filters",2-s2.0-85031722498
"Zhong Y.-B., Lyu Z.-F., Kuang X.-T.","Application research of improved classification recognition algorithm based on causality analysis",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030769039&doi=10.1007%2f978-3-319-66514-6_26&partnerID=40&md5=9d9a96f52f68576504761655a7a8cdc3","When the causality-relationship is incomplete, it’s easy to have problem on sample classification. For the sake of solving this problem, this paper proposes an improved classification recognition algorithm based on causality analysis. This algorithm has improved the process of classification and recognition which is proposed in Causality Analysis in Factor Spaces [1], and it’s based on the nearest-neighbor rule and maximum subordination principle. In addition, aiming at the case that can be only applied in the discrete groups in Pei-Zhuang Wang’s paper, this article has transformed the continuous data into discrete data by segmentation method. Therefore, this algorithm expands on its original application into the case involving continuous data. Experimental results indicate that this improved classification recognition algorithm can successfully identify all the samples, and it also significantly improves the overall recognition rate. Simultaneously, when continuous data is centralizing, this algorithm is better than most common classification algorithms, and it can be effectively applied to image classification areas. © Springer International Publishing AG 2018.","Causality analysis; Factor space; Improved classification recognition algorithm; Maximum subordination principle; Nearest-neighbor rule","Computer programming; Computer science; Causality analysis; Factor space; Maximum subordination principle; Nearest neighbor rule; Recognition algorithm; Factor analysis",2-s2.0-85030769039
"de la Cal E., Villar J.R., Vergara P., Sedano J., Herrero Á.","A SMOTE extension for balancing multivariate epilepsy-related time series datasets",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028683204&doi=10.1007%2f978-3-319-67180-2_43&partnerID=40&md5=a6cfdb8a06d0be026dd4c526b05747ae","In some cases, big data bunches are in the form of Time Series (TS), where the occurrence of complex TS events are rarely presented. In this scenario, learning algorithms need to cope with the TS data balancing problem, which has been barely studied for TS datasets. This research addresses this issue, describing a very simple TS extension of the well-known SMOTE algorithm for balancing datasets. To validate the proposal, it is applied to a realistic dataset publicly available containing epilepsy-related TS. A study on the characteristics of the dataset before and after the performance of this TS balancing algorithm is performed, showing evidence on the requirements for the research on this topic, the energy efficiency of the algorithm and the TS generation process among them. © 2018, Springer International Publishing AG.","Dataset balancing algorithms; SMOTE; Time series","Education; Energy efficiency; Neurology; Soft computing; Time series; Balancing algorithms; Balancing problems; Generation process; SMOTE; SMOTE algorithm; Big data",2-s2.0-85028683204
"Balaji Ramachandran S., Gillis K.D.","A matched-filter algorithm to detect amperometric spikes resulting from quantal secretion",2018,"Journal of Neuroscience Methods",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032267289&doi=10.1016%2fj.jneumeth.2017.10.019&partnerID=40&md5=1309af207baf81807872b8f61e83f8bf","Background Electrochemical microelectrodes located immediately adjacent to the cell surface can detect spikes of amperometric current during exocytosis as the transmitter released from a single vesicle is oxidized on the electrode surface. Automated techniques to detect spikes are needed in order to quantify the spike rate as a measure of the rate of exocytosis. New method We have developed a Matched Filter (MF) detection algorithm that scans the data set with a library of prototype spike templates while performing a least-squares fit to determine the amplitude and standard error. The ratio of the fit amplitude to the standard error constitutes a criterion score that is assigned for each time point and for each template. A spike is detected when the criterion score exceeds a threshold and the highest-scoring template and the time of peak score is identified. The search for the next spike commences only after the score falls below a second, lower threshold to reduce false positives. The approach was extended to detect spikes with double-exponential decays with the sum of two templates. Results Receiver Operating Characteristic plots (ROCs) demonstrate that the algorithm detects >95% of manually identified spikes with a false-positive rate of ∼2%. Comparison with existing methods ROCs demonstrate that the MF algorithm performs better than algorithms that detect spikes based on a derivative-threshold approach. Conclusions The MF approach performs well and leads into approaches to identify spike parameters. © 2017","Carbon-fiber amperometry; Quantal exocytosis; Signal processing; Spike detection","action potential; algorithm; amperometry; animal cell; animal tissue; Article; cell surface; chromaffin cell; comparative study; exocytosis; false positive result; matched filter algorithm; nonhuman; priority journal; quantal secretion; signal noise ratio; signal processing; spike",2-s2.0-85032267289
"Idrus A., Mahmoud M.A., Ahmad M.S., Yahya A., Husen H.","A negotiation algorithm for decision-making in the construction domain",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022193803&doi=10.1007%2f978-3-319-62410-5_14&partnerID=40&md5=ca62862aaa8d5aaf2cf1ade451152381","In this paper, we propose a negotiation algorithm for automated decision-making in the construction domain. The algorithm enables software agents to conduct negotiations and autonomously make decisions. The algorithm consists of eight steps which are submit solutions, review solutions’ weights, solutions pair ranking, set a plan, select the plan, form coalition, review coalitions’ strength, and re-evaluate coalition. We first present the algorithm architecture then the related definition and formulation of each step and subsequently demonstrate the complete operation of the proposed algorithm using pseudocode. © Springer International Publishing AG 2018.","Automated negotiation; Construction domain; Multi-agent systems","Artificial intelligence; Autonomous agents; Decision making; Distributed computer systems; Intelligent agents; Multi agent systems; Algorithm architectures; Automated decision making; Automated negotiations; Negotiation algorithm; Pseudo-code; Software agents",2-s2.0-85022193803
"Li H., Sun J., Fan Y., Wang M., Zhang Q.","A New Steady-State MOEA/D for Sparse Optimization",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029585936&doi=10.1007%2f978-3-319-66939-7_10&partnerID=40&md5=49ded99dd852f45ed22e49e69e5ecd41","The classical algorithms based on regularization usually solve sparse optimization problems under the framework of single objective optimization, which combines the sparse term with the loss term. The majority of these algorithms suffer from the setting of regularization parameter or its estimation. To overcome this weakness, the extension of multiobjective evolutionary algorithm based on decomposition (MOEA/D) has been studied for sparse optimization. The major advantages of MOEA/D lie in two aspects: (1) free setting of regularization parameter and (2) detection of true sparsity. Due to the generational mode of MOEA/D, its efficiency for searching the knee region of the Pareto front is not very satisfactory. In this paper, we proposed a new steady-state MOEA/D with the preference to search the region of Pareto front near the true sparse solution. Within each iteration of our proposed algorithm, a local search step is performed to examine a number of solutions with similar sparsity levels in a neighborhood. Our experimental results have shown that the new MOEA/D clearly performs better than its previous version on reconstructing artificial sparse signals. © 2018, Springer International Publishing AG.","Evolutionary algorithm; MOEA/D; Multiobjective optimization; Sparse optimization","Artificial intelligence; Evolutionary algorithms; Iterative methods; Multiobjective optimization; Parameterization; Its efficiencies; MOEA/D; Multi objective evolutionary algorithms; Regularization parameters; Single objective optimization; Sparse optimizations; Sparse signals; Sparse solutions; Optimization",2-s2.0-85029585936
"Dubey A., Lohiya A., Narwal V., Jha A.K., Agarwal P., Schaefer G.","Natural image interpolation using extreme learning machine",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028587739&doi=10.1007%2f978-3-319-60618-7_34&partnerID=40&md5=57426bedc6d8d31001b220674ce9d805","Standard image interpolation methods use a uniform interpolation filter on the entire image. To achieve improved results on specific structures, content adaptive interpolation methods have been introduced. However, these are typically limited to fit image data into a linear model in each class. In this paper, we investigate replacing the linear model by a flexible non-linear model, resulting in a novel interpolation algorithm based on extreme learning machines. Extreme learning machines (ELMs) is a relatively recent learning algorithm for single hidden layer feed-forward neural networks, which compared with conventional neural network learning algorithms, overcomes slow training speed and over-fitting problems. Based on an extensive set of experiments, we show that our proposed approach yields improved image quality, as confirmed by both objective and subjective results. © Springer International Publishing AG 2018.","Extreme learning machine (ELM); Interpolation; Moore Penrose generalised inverse; Single-hidden layer feed forward neural networks (SLFNs); Zooming","Image quality; Interpolation; Knowledge acquisition; Learning systems; Pattern recognition; Soft computing; Extreme learning machine; Interpolation algorithms; Moore-Penrose; Neural network learning algorithm; Over fitting problem; Single-hidden layer feed-forward neural network; Uniform interpolations; Zooming; Learning algorithms",2-s2.0-85028587739
"Qinghua S., Juntao L.","BP-MPSO algorithm for PUMA robot vacumn path planning",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029483241&doi=10.1007%2f978-3-319-64861-3_1&partnerID=40&md5=66c0f5424058fd7b616cec15ee8da7f7","Path planning of robots is the key problem, and steering to achieve the goal is important for the PUMA robot. In this paper, we present the BP-MPSO algorithm for PUMA robot vacuum path planning that can well enhance the efficiency robot execution. Firstly, according to PUMA robot’s mechanical structure, the BP algorithm condition modeling and an attitude modeling were presented. Secondly, for the traditional particle swarm optimization (PSO) limitation in searching space and easily running into local optimal points, the re-initialization mechanism using the global information feedback to modified particle swarm optimization (MPSO) algorithm was introduced. Finally, the BP-MPSO algorithm is combined with BP network algorithm and the MPSO algorithm, which can not only avoids the difficulty in solving the inverse motion equations but also ensures that the optimal solution and can obtains the global optimal aim instead of falling into local extremer. © 2018, Springer International Publishing AG.","BP algorithm; MPSO algorithm; Path planning; PUMA robot; Target modeling",,2-s2.0-85029483241
"Jiuqing W., Xu C., Shaocong B., Li L.","Distributed data association in smart camera network via dual decomposition",2018,"Information Fusion",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018403070&doi=10.1016%2fj.inffus.2017.04.007&partnerID=40&md5=816d3ac1e90e522e3c57211edb4642ba","One of the fundamental requirements for pedestrian surveillance using smart camera network is the correct association of each person's observations generated on different camera nodes to the person's track. Recently, distributed data association methods that involve only local information processing on each camera node and mutual information exchanging between neighboring cameras have attracted many research interests due to their superiority in large scale applications. In this paper, we propose a new method that performs global data association in a distributed manner by fusing the appearance and spatio-temporal measurements of objects captured by all camera nodes in the entire network. Specifically, we formulate the data association problem in smart camera networks as an Integer Programming problem by introducing a set of linking variables, and propose two distributed algorithms, namely L-DD and Q-DD, to solve the Integer Programming problem using the dual decomposition technique. In our algorithms, the original Integer Programming problem is decomposed into several subproblems, which can be solved locally on each smart camera. Different subproblems reach consensus on their solutions in a rigorous way by adjusting their parameters iteratively based on the projected subgradient optimization. The proposed method is simple and flexible, in that (i) we can incorporate any feature extraction and matching technique into our framework to calculate the similarity between observations, which corresponds to the costs of links in our model, and (ii) we can decompose the original problem in any way as long as the resulting subproblem can be solved independently and efficiently. We show the competitiveness of our method in both accuracy and speed by theoretical analysis and experimental comparison with state-of-the-art algorithms. © 2017 Elsevier B.V.","Data association; Distributed algorithm; Dual decomposition; Smart camera network","Cameras; Feature extraction; Integer programming; Iterative methods; Optimization; Parallel algorithms; Security systems; Data association; Data association problem; Dual decomposition; Feature extraction and matching; Integer programming problems; Large-scale applications; Smart camera networks; State-of-the-art algorithms; Distributed computer systems",2-s2.0-85018403070
"Liu G., Hua Z., Zou J.","Local attribute reductions for decision tables",2018,"Information Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028990535&doi=10.1016%2fj.ins.2017.09.007&partnerID=40&md5=a50dd5079949621ceacfa3861f6b7dd8","Attribute reduction is among the most important areas of research in rough sets. This paper investigates the types of local attribute reduction for decision tables. We propose the concepts of lth decision class lower approximation reduction, lth decision class reduction, and lth decision class β-reduction for decision tables, and provide their corresponding reduction algorithms via discernibility matrices. We also establish the relationship between positive-region reduction and the lth decision class β-reduction, and report a case study using the University of California–Irvine dataset to verify the theoretical results. © 2017 Elsevier Inc.","Attribute reduction; Decision table; Discernibility matrix; Equivalence relation; Reduction algorithm","Approximation algorithms; Rough set theory; Attribute reduction; Discernibility; Discernibility matrix; Equivalence relations; Lower approximation; Positive region; Reduction algorithms; University of California; Decision tables",2-s2.0-85028990535
"Panyangam B., Kiewkanya M.","Software size estimation in design phase based on MLP neural network",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022176707&doi=10.1007%2f978-3-319-60663-7_8&partnerID=40&md5=0b5cd1c0b7d3620a7d5626a18c66edde","Size estimation is one of important processes related to success of software project management. This paper presents novel software size estimation model by using Multilayer Perceptron approach. Software size in terms of Lines of code is used as criterion variable. Structural complexity metrics are used as predictors. The metrics can be captured from a software design model named UML Class diagram. A high predictive ability of the model is shown with correlation coefficient measure. Moreover, four training algorithms; Levenberg-Marquardt, Scaled Conjugate Gradient, Broyden-Fletcher-Golfarb-Shanno and Bayesian Regularization, have been applied on the network for better estimation. The obtained results indicate the highest accuracy on the model with Bayesian Regularization algorithm. © Springer International Publishing AG 2018.","MLP neural network; Software metrics; Software size estimation; Training algorithm","Complex networks; Damage detection; Project management; Bayesian regularization; Bayesian regularization algorithms; MLP neural networks; Scaled conjugate gradients; Software metrics; Software project management; Software size estimation; Training algorithms; Software design",2-s2.0-85022176707
"Zhang T., Zhang X., Li Z., Bao J.","An improved MFSK Signal detection algorithm for mars probe entry, descent, landing phase",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028339314&doi=10.1007%2f978-981-10-4837-1_19&partnerID=40&md5=04744fbf659171ca2c3bbf686991588d","To solve the high computational complexity problem of carrier recovery enhancement for Maximum-Likelihood Doppler shift estimation algorithm (CRE-ML), the relationship between four searching dimensions and carrier recovery enhancement is analyzed. A time-domain matching-average periodogram algorithm based on 4-dimensions searching (4D-TDMAP) is proposed which decreases the algorithm complexity by reducing the Doppler rate matching accuracy requirement. Simulations are performed when the maximum Doppler frequency is 50, kHz, Doppler frequency rate varies from −1000 to 1000, Hz/s, which refers to the high dynamics during the EDL stage of Mars Science Laboratory (MSL). The results show the proposed algorithm reaches the same performance as the CRE-ML does with its computational complexity decreased to 0.26%, and its MFSK signal detection threshold decreased by up to 3, dB compared with traditional time-domain matching-average periodogram algorithm. © Tsinghua University Press, Beijing and Springer Nature Singapore Pte Ltd. 2018.","4-Dimensions searching; High dynamics; MFSK signal detection; Time-domain matching","Computational complexity; Doppler effect; Frequency shift keying; Martian surface analysis; Maximum likelihood; Maximum likelihood estimation; 4-Dimensions searching; Doppler shift estimation; High dynamic; Mars science laboratory; Maximum Doppler frequency; Periodogram algorithm; Signal detection algorithm; Time domain; Signal detection",2-s2.0-85028339314
"Wu G., Shen X., Li H., Chen H., Lin A., Suganthan P.N.","Ensemble of differential evolution variants",2018,"Information Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030692966&doi=10.1016%2fj.ins.2017.09.053&partnerID=40&md5=c3f8e1d8babe7012ed60d4127d86b815","Differential evolution (DE) is one of the most popular and efficient evolutionary algorithms for numerical optimization and it has gained much success in a series of academic benchmark competitions as well as real applications. Recently, ensemble methods receive an increasing attention in designing high-quality DE algorithms. However, previous efforts are mainly devoted to the low-level ensemble of mutation strategies of DE. This study investigates the high-level ensemble of multiple existing efficient DE variants. A multi-population based framework (MPF) is proposed to realize the ensemble of multiple DE variants to derive a new algorithm named EDEV for short. EDEV consists of three highly popular and efficient DE variants, namely JADE (adaptive differential evolution with optional external archive), CoDE (differential evolution with composite trial vector generation strategies and control parameters) and EPSDE (differential evolution algorithm with ensemble of parameters and mutation strategies). The whole population of EDEV is partitioned into four subpopulations, including three indicator subpopulations with smaller size and one reward subpopulation with much larger size. Each constituent DE variant in EDEV owns an indicator subpopulation. After every predefined generations, the most efficient constituent DE variant is determined and the reward subpopulation is assigned to that best performed DE variant as an extra reward. Through this manner, the most efficient DE variant is expected to obtain the most computational resources during the optimization process. In addition, the population partition operator is triggered at every generation, which results in timely information sharing and tight cooperation among the component DE variants. Extensive experiments and comparisons have been done based on the CEC2005 and CEC2014 benchmark suit, which shows that the overall performance of EDEV is superior to several state-of-the-art peer DE variants. The success of EDEV reveals that, through an appropriate ensemble framework, different DE variants of different merits can support one another to cooperatively solve optimization problems. © 2017 Elsevier Inc.","Differential evolution; Ensemble of differential evolution variants; Evolutionary algorithm; Multi-population; Numerical optimization","Benchmarking; Optimization; Population statistics; Silicate minerals; Adaptive differential evolutions; Computational resources; Differential Evolution; Differential evolution algorithms; Information sharing; Multi population; Numerical optimizations; Optimization problems; Evolutionary algorithms",2-s2.0-85030692966
"Alnabulsi H., Islam R., Mamun Q.","A novel algorithm to protect code injection attacks",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032693365&doi=10.1007%2f978-3-319-67071-3_35&partnerID=40&md5=7825a0218d7bd121dc7d78e544a60d0c","The Code Injection Attack (CIA) exploits a security vulnerability or computer bug that is caused by processing invalid data, CIA is a serious attack problem that attackers try to introduce any new methodologies to bypass the defense system. In this paper, we introduce a novel detection algorithm for detection of code injection attack. Our empirical performance shows that the proposed algorithm give better results compared to existing results. © 2018, Springer International Publishing AG.","Code injection attack; Security; SQL injection attack; XSS attack","Codes (symbols); Data handling; Code injection attacks; Detection algorithm; Empirical performance; Novel algorithm; Security; Security vulnerabilities; Sql injection attacks; Xss attacks; Network security",2-s2.0-85032693365
"Perlinski R.","Partial Board Tree Search",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030757546&doi=10.1007%2f978-3-319-67792-7_50&partnerID=40&md5=e85092e86c28d2a8b596728f6ec21b62","In this article, a new approach to solving selected two-person perfect information zero-sum games is proposed. This new approach involves dividing game board into smaller parts called partial boards. Every such partial board has an associated “border state” which is an information structure vital to the game solving process. Using partial boards, it is possible to generate partial board game trees. Such structures are sufficient for the purpose of searching complete game trees - in effect. The possibility of making different board divisions allows an entire partial board game tree to be stored in computer memory. As a result, tree search algorithms based on partial board game trees work very fast. This approach can be applied only for specific games. Examples of such games are Atari-Go, Hex, and Gomoku. Experimental results relating to the solving of the Atari-Go game are presented here. © 2018, Springer International Publishing AG.","Computer Go; Solving games; Tree search algorithms","Learning algorithms; Trees (mathematics); Computer Go; Computer memory; Information structures; New approaches; Perfect informations; Solving games; Tree search algorithm; Zero-sum game; Computer games",2-s2.0-85030757546
"Yu W.-J., Ji J.-Y., Gong Y.-J., Yang Q., Zhang J.","A tri-objective differential evolution approach for multimodal optimization",2018,"Information Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029711889&doi=10.1016%2fj.ins.2017.09.044&partnerID=40&md5=88ec974f2b0997074fe3cb283d5e8ea1","The multimodal optimization problems (MMOPs) need to find multiple optima simultaneously, so the population diversity is a critical issue that should be considered in designing an evolutionary optimization algorithm for MMOPs. Taking advantage of evolutionary multiobjective optimization in maintaining good population diversity, this paper proposes a tri-objective differential evolution (DE) approach to solve MMOPs. Given an MMOP, we first transform it into a tri-objective optimization problem (TOP). The three optimization objectives are constructed based on 1) the objective function of an MMOP, 2) the individual distance information measured by a set of reference points, and 3) the shared fitness based on niching technique. The first two objectives are mutually conflicting so that the advantage of evolutionary multiobjective optimization can be fully used. The population diversity is greatly improved by the third objective constructed by the niching technique which is insensitive to niching parameters. Mathematical proofs are given to demonstrate that the Pareto-optimal front of the TOP contains all global optima of the MMOP. Subsequently, DE-based multiobjective optimization techniques are applied to solve the converted TOP. Moreover, a modified solution comparison criterion and an adaptive ranking strategy for DE are introduced to improve the accuracy of solutions. Experiments have been conducted on 44 benchmark functions to evaluate the performance of the proposed approach. The results show that the proposed approach achieves competitive performance compared with several state-of-the-art multimodal optimization algorithms. © 2017 Elsevier Inc.","Differential evolution; Multimodal optimization problems; Multiobjective optimization; Niching method","Benchmarking; Evolutionary algorithms; Multiobjective optimization; Pareto principle; Differential Evolution; Evolutionary multiobjective optimization; Evolutionary optimization algorithm; Multi-modal optimization; Multi-modal optimization algorithms; Multi-objective optimization techniques; Multimodal optimization problems; Niching methods; Optimization",2-s2.0-85029711889
"Hore S., Chatterjee S., Shaw R.K., Dey N., Virmani J.","Detection of chronic kidney disease: A NN-GA-based approach",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031399525&doi=10.1007%2f978-981-10-6747-1_13&partnerID=40&md5=d2cea5ec5b7b86509fc38f97b99217d8","In the present work, a genetic algorithm (GA) trained neural network (NN)-based model has been proposed to detect chronic kidney disease (CKD) which has become one of the newest threats to the developing and undeveloped countries. Studies and surveys in different parts of India have suggested that CKD is becoming a major concern day by day. The financial burden of the treatment and future consequences of CKD could be unaffordable to many, if not detected at an earlier stage. Motivated by this, the NN-GA model has been proposed which significantly overcomes the problem of using local search-based learning algorithms to train NNs. The input weight vector of the NN is gradually optimized by using GA to train the NN. The model has been compared with well-known classifiers like Random Forest, Multilayer Perception Feedforward Network (MLP-FFN), and also with NN. The performance of the classifiers has been measured in terms of accuracy, precision, recall, and F-Measure. The experimental results suggest that NN-GA-based model is capable of detecting CKD more efficiently than any other existing model. © 2018, Springer Nature Singapore Pte Ltd.","Chronic kidney disease; Genetic algorithm; Neural network; Random forest","Decision trees; Learning algorithms; Neural networks; Chronic kidney disease; F measure; Feed-forward network; Input weights; Local search; Multi-layer perception; Random forests; Trained neural networks; Genetic algorithms",2-s2.0-85031399525
"Venizelou V., Philippou N., Hadjipanayi M., Makrides G., Efthymiou V., Georghiou G.E.","Development of a novel time-of-use tariff algorithm for residential prosumer price-based demand side management",2018,"Energy",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031997319&doi=10.1016%2fj.energy.2017.10.068&partnerID=40&md5=c54ba62d97810249254cb11cf9026e12","Through the application of flexible Time-of-Use (ToU) tariffs, demand side management (DSM) can be facilitated in order to alleviate grid congestion problems and potential network reinforcement. In this work, a novel approach to derive ToU tariffs for residential prosumers is described and the potential impact is verified in a pilot network within the distribution grid of Cyprus comprised of three hundred prosumers. This pilot network acts as a test-bed for defining the baseline scenario and subsequently verifying the developed ToU tariffs. The ToU block periods were determined by combining statistical analysis and a hybrid optimization function that utilizes annealing driven pattern search algorithms. The ToU rates were calculated by exploiting an optimization function that maintained a neutral electricity bill in the case where the load profile remained unchanged. The impact of the derived ToU tariffs was first analysed through a sensitivity analysis performed on the seasonal load profiles of the participants. The obtained sensitivity analysis results showed that for the summer and winter season, the maximum Load Factor (LF) was 42.83% and 33.33% respectively and occurred when load was shifted mainly to the off-peak period. Finally, with the ToU tariffs applied to the pilot network of prosumers, the effectiveness and potential response of the prosumers to the imposed tariffs, was verified. The results indicated that the LF was increased while the percentage of total consumption measured during peak hours was reduced by 3.19%, 1.03% and 1.40% for the summer, middle and winter season respectively. This led to the conclusion that the derived ToU tariffs are effective in persuading the prosumers to change their energy behaviour. © 2017 Elsevier Ltd","Demand side management; Electricity tariff design; Grid management; Photovoltaics; Time-of-use tariffs","Demand side management; Electric utilities; Housing; Sales; Sensitivity analysis; Traffic congestion; Electricity tariff; Grid management; Network reinforcements; Optimization function; Pattern search algorithm; Photovoltaics; Time of use (TOU) tariffs; Time-of-use tariffs; Optimization; algorithm; demand-side management; electricity generation; optimization; photovoltaic system; sensitivity analysis; statistical analysis; Cyprus",2-s2.0-85031997319
"Wei Y., Zhang X., Shi Y., Xia L., Pan S., Wu J., Han M., Zhao X.","A review of data-driven approaches for prediction and classification of building energy consumption",2018,"Renewable and Sustainable Energy Reviews",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030703701&doi=10.1016%2fj.rser.2017.09.108&partnerID=40&md5=d744ae502a07a34823268f17785ceccd","A recent surge of interest in building energy consumption has generated a tremendous amount of energy data, which boosts the data-driven algorithms for broad application throughout the building industry. This article reviews the prevailing data-driven approaches used in building energy analysis under different archetypes and granularities, including those methods for prediction (artificial neural networks, support vector machines, statistical regression, decision tree and genetic algorithm) and those methods for classification (K-mean clustering, self-organizing map and hierarchy clustering). The review results demonstrate that the data-driven approaches have well addressed a large variety of building energy related applications, such as load forecasting and prediction, energy pattern profiling, regional energy-consumption mapping, benchmarking for building stocks, global retrofit strategies and guideline making etc. Significantly, this review refines a few key tasks for modification of the data-driven approaches in the context of application to building energy analysis. The conclusions drawn in this review could facilitate future micro-scale changes of energy use for a particular building through the appropriate retrofit and the inclusion of renewable energy technologies. It also paves an avenue to explore potential in macro-scale energy-reduction with consideration of customer demands. All these will be useful to establish a better long-term strategy for urban sustainability. © 2017 Elsevier Ltd","Building; Classification; Data driven approach; Energy consumption; Prediction","Benchmarking; Buildings; Classification (of information); Cluster analysis; Clustering algorithms; Conformal mapping; Construction industry; Data mining; Decision trees; Energy management; Energy utilization; Forecasting; Genetic algorithms; Neural networks; Renewable energy resources; Retrofitting; Self organizing maps; Speech recognition; Trees (mathematics); Building energy analysis; Building energy consumption; Data-driven algorithm; Data-driven approach; Hierarchy clustering; Regional energy consumption; Renewable energy technologies; Statistical regression; Energy conservation",2-s2.0-85030703701
"Mullick D., Garg A., Bajaj A., Garg A., Aggarwal S.","Ant colony based fuzzy C-means clustering for very large data",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029455115&doi=10.1007%2f978-3-319-66824-6_51&partnerID=40&md5=fb603c09bf3d79943b0d9151e266067d","Fuzzy C-Means (FCM) is a popular technique for clustering of data. It combines the concepts of K-Means algorithm and Fuzzy set theory. However, FCM faces the challenges of running into a local optimal value, and of producing results which are sensitive to initialisation conditions. To solve these problems, there has been prior work which incorporates Ant Colony Optimisation (ACO) into the conventional FCM algorithm. The authors of this paper find that though the FCM-ACO algorithm is a definite improvement over the traditional FCM, there is still scope for improving the scalability and accuracy of the system. The authors propose using a Multi Round Sampling (MRS) technique along with Ant colony Optimisation. The proposed algorithm allows us to cluster the dataset without considering it entirely, hence allowing for a more space and time efficient system. This makes the system highly scalable and hence suitable for large datasets. Moreover, extensive experiments on several publicly available datasets, both large and small, prove that the proposed algorithm of Multi Round Sampling of Ant Colony based Fuzzy C-Means (MRSA-FCM) gives superior clustering results, over the FCM and FCM-ACO systems. © 2018, Springer International Publishing AG.","Ant colony optimisation; Big data; Fuzzy clustering; Multi round sampling","Artificial intelligence; Big data; Clustering algorithms; Fuzzy clustering; Fuzzy logic; Fuzzy set theory; Fuzzy sets; Fuzzy systems; Optimization; Pattern matching; ACO algorithms; Clustering results; Fuzzy C means clustering; k-Means algorithm; Large datasets; Local optimal; Space and time; Very large datum; Ant colony optimization",2-s2.0-85029455115
"Abele E., Holland L., Hönig P.","Image Acquisition and Image Processing Algorithm for Movement Analysis of Bearings' Rolling Elements",2018,"Journal of Tribology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027287389&doi=10.1115%2f1.4037066&partnerID=40&md5=60d04fe28b07afe25721d642a0dbd63a","Movement analyses of bearings with regard to stable and unstable motion behavior typically investigate the cage whirl. However, some experimental and simulation-based studies exist that analyze the movements of the rolling elements. The majority of these investigations focus on lower shaft speeds. This paper presents an image-based approach for investigating the rolling element motions under high-speed operation condition. A new evaluation algorithm is presented and its suitability is verified first by generic images and afterward by experiments on cylindrical roller bearings. © 2018 by ASME.","Bearing; cylindrical roller bearings; dynamic behavior analysis; moving behavior; rolling elements","Bearings (structural); Cylindrical roller bearings; Image acquisition; Image processing; Motion analysis; Dynamic behavior analysis; Evaluation algorithm; High-speed operation; Image processing algorithm; Motion behavior; Movement analysis; Moving behavior; Rolling elements; Roller bearings",2-s2.0-85027287389
"Sadowski T., Zdunek R.","Modified HALS Algorithm for Image Completion and Recommendation System",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029538012&doi=10.1007%2f978-3-319-67229-8_2&partnerID=40&md5=882ad571ca3a95c091bcf24162ce0c58","The paper is concerned with the task of reconstructing missing values in an observed incomplete matrix, assuming its low-rank approximation. The problem has important applications, especially in image processing and social sciences. In our approach, we focus on the problem of recovering missing pixels in images perturbed with impulse noise in a transmission channel as well as estimating unknown ratings in a recommendation system. For solving these problems, we used the modified version of the Hierarchical Least Squares Algorithm (HALS), including the smoothed version, and compared them with other algorithm, such as the SPC-QV. The numerical experiments are carried out for various cases of incomplete data. For image processing, the incomplete images are obtained by removing random pixels and regular grid lines from test images. For recommendation systems, we used real rating matrices from the MovieLens database that contains five-star movie recommendation ratings. The best performance is obtained if nonnegativity and smoothing constraints are imposed onto the estimated low-rank factors. © 2018, Springer International Publishing AG.","HALS algorithm; Image completion; Nonnegative Matrix Factorization; Recommendation systems","Approximation theory; Factorization; Impulse noise; Information systems; Matrix algebra; Pixels; Problem solving; Recommender systems; Image completion; Incomplete data; Least squares algorithm; Low rank approximations; Movie recommendations; Nonnegative matrix factorization; Numerical experiments; Transmission channels; Image processing",2-s2.0-85029538012
"Pang Y., Jiang X., Zou F., Gan Z., Wang J.","Research on Energy Consumption of Building Electricity Based on Decision Tree Algorithm",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030872666&doi=10.1007%2f978-3-319-68527-4_29&partnerID=40&md5=e36fbf9cf18a382b3951798960226010","The consumption of building energy was increasing every year in the past in China. It is a big problem to be solved about how to make the building energy consumption to be more reasonable. In order to obtain the feature of building energy consumption with its electrical instructions, a decision-tree algorithm is designed to mine the data of energy consumption of electricity. According to the analysis of the attribute quantity factors, comparing the factors classification information gain value, and analysis the proportion of power consumption factors, a typical energy consumption sample of a laboratory in university was modeled and analyzed in this paper. Experimental results show that the seasonal change factor has a great influence on the energy consumption of the building. And according to this conclusion, a suitable energy-efficiency device is planed. © 2018, Springer International Publishing AG.","Decision-tree; Energy consumption; ID3 algorithm; Information entropy","Buildings; Classification (of information); Data handling; Data mining; Decision trees; Energy efficiency; Energy utilization; Information analysis; Trees (mathematics); Building energy; Building energy consumption; Classification informations; Decision-tree algorithm; ID3 algorithm; Information entropy; Seasonal changes; Energy conservation",2-s2.0-85030872666
"Zubair S., Chaudhary N.I., Khan Z.A., Wang W.","Momentum fractional LMS for power signal parameter estimation",2018,"Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028745850&doi=10.1016%2fj.sigpro.2017.08.009&partnerID=40&md5=7cf88db62b4f6e3e268456d7b4f0f2e5","Fractional adaptive algorithms have given rise to new dimensions in parameter estimation of control and signal processing systems. In this paper, we present novel fractional calculus based LMS algorithm with fast convergence properties and potential ability to avoid being trapped into local minima. We test our proposed algorithm for parameter estimation of power signals and compare it with other state-of-the-art fractional and standard LMS algorithms under different noisy conditions. Our proposed algorithm outperforms other LMS algorithms in terms of convergence rate and accuracy. © 2017 Elsevier B.V.","Fractional algorithms; Parameter estimation; Power signal estimation; Signal processing","Adaptive algorithms; Adaptive control systems; Calculations; Signal analysis; Signal processing; Control and signal processing; Convergence rates; Fast convergence; Fractional calculus; Noisy conditions; Potential ability; Power signals; State of the art; Parameter estimation",2-s2.0-85028745850
"Pavani T., Rajeswari M., Padma Vani C.","Detecting the sonar target by using optimization technique",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029817126&doi=10.1007%2f978-981-10-4280-5_30&partnerID=40&md5=7cda3a3aacddd13901d4d6ec3a16dc25","The general important problems in a lot of application areas are to pull out the signal of interest from background noise. Background noise is an indiscriminate form; the occurrence of the signal and the performance of signal are also indiscriminate. Thus, it is sensible to deal with the signal removal problem using methods based on optimization technique and statistical estimation. Within this paper, signal and noise environment has been encountered in active sonar system. The optimum receiver is obtainable for range-Doppler-shift dispensation in a background-noise-limited environment using firefly optimization method for dropping the noise. There are various techniques for target detection, but this paper shows a new approach for target detection using a firefly algorithm to optimize the received signal by reducing the noise. FFT-based implementation for detection of CW active sonar target using firefly optimized algorithm has been shown. © Springer Nature Singapore Pte Ltd. 2018.","Ambiguity function; Background-noise-limited; FFT-based implementation; Firefly algorithm; Optimum detector","Bioluminescence; Fast Fourier transforms; Sonar; Active sonar systems; Ambiguity function; Background noise; Firefly algorithms; Optimization techniques; Optimized algorithms; Optimum detectors; Statistical estimation; Optimization",2-s2.0-85029817126
"Du H., Ma H., Li X.","Fuzzy Bi-objective Chance-Constrained Programming Model for Timetable Optimization of a Bus Route",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029592414&doi=10.1007%2f978-3-319-66939-7_27&partnerID=40&md5=6289cf3ff5e57fa13a305dd4f1696950","Timetable optimization is essential to the improvement of a bus operating company’s economic profits, quality of service and competitiveness in the market. The most previous researches studied the bus timetabling with assuming the passenger demand is certain but it varies in practice. In this study, we consider a timetable optimization problem of a single bus line under fuzzy environment. Assuming the passenger quantity in per time segment is a fuzzy value, a fuzzy bi-objective programming model that maximizes the total passenger volume and minimizes the total bus travel time under a capacity rate constraint is established. This chance constrained programming model is formulated with the passenger volume and capacity rate under certain chance constraints. Furthermore, a genetic algorithm of variable length is designed to solve the proposed model. Finally, we present a case study that utilizing real data obtained from a major Beijing bus operating company to illustrate the proposed model and algorithm. © 2018, Springer International Publishing AG.","Bi-objective programming; Fuzzy chance-constrained programming; Genetic algorithm; Timetable optimization","Artificial intelligence; Bus transportation; Buses; Computer programming; Constrained optimization; Genetic algorithms; Quality of service; Scheduling; Transportation; Travel time; Bi objective programming; Chance constraint; Chance-constrained programming model; Fuzzy chance-constrained programming; Fuzzy environments; Model and algorithms; Operating companies; Optimization problems; Optimization",2-s2.0-85029592414
"Ma Y., Xie K., Dong J., Tai H.-M., Hu B.","Optimal Generation Maintenance Schedule for Bundled Wind-Thermal Generation System",2018,"Journal of Energy Resources Technology, Transactions of the ASME",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028079864&doi=10.1115%2f1.4037536&partnerID=40&md5=a7d615e00b161af860d2893c0f635208","Bundled wind-thermal generation system (BWTGS) is an effective way to utilize remote large-scale wind power. The optimal generation maintenance schedule (GMS) for BWTGS is not only helpful to improve the system reliability level but also useful to enhance the system economic efficiency and extend the lifetime of components. This paper presents a model to optimize the GMS for BWTGS. The probabilistic production simulation technique is employed to calculate the system costs, and a sequential probabilistic method is utilized to capture the sequential and stochastic nature of wind power. A hybrid optimization algorithm (HOA) based on the simulated annealing (SA) and multipopulation parallel genetic algorithm (GA) is developed to solve the proposed model. Case studies demonstrate the effectiveness of this proposed model. Effects of the reliability deterioration of thermal generating units (TGUs) and the pattern of BWTGS transmission power are also investigated. Copyright © 2018 by ASME.",,"Genetic algorithms; Reliability; Simulated annealing; Stochastic systems; Wind power; Hybrid optimization algorithm; Large-scale wind power; Maintenance schedules; Parallel genetic algorithms; Probabilistic production simulation; Reliability deteriorations; Thermal generating units; Thermal generation system; Optimization",2-s2.0-85028079864
"Carotenuto P., Giordani S., Massari S., Vagaggini F.","A multi-depot periodic vehicle routing model for petrol station replenishment",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022181649&doi=10.1007%2f978-3-319-57105-8_21&partnerID=40&md5=3ce32d36022bc31c4405e4418429d2e3","The petrol station replenishment problem consists in delivering fuel oils from a set of storage depots to a set of petrol stations during a few days planning horizon. This problem is addressed by an oil company which, for example, has to decide simultaneously the weekly fuel oil replenishment plan for each station, and, for each day of the week, the tank truck (vehicle) routes from depots to stations, in order to deliver the planned fuel oil replenishment amounts to petrol stations. Assuming a fleet of homogeneous tank trucks, the aim is to minimize the total distance travelled by tank trucks during the week, while loading tank trucks possibly near to their capacity in order to maximize the resource utilization. We model the problem as a generalization of the Multi-Depot Periodic Vehicle Routing Problem (MDPVRP) and provide a mathematical formulation. Due to the large size of the real instances which the company has to deal with, we solve the problem heuristically. We propose a hybrid genetic algorithm that successfully address the problem. The algorithm is derived from a known hybrid genetic algorithm for the MDPVRP, and adopts additional techniques and features tailored for the particular fuel oil distribution problem. It is specifically designed to deal with real instances derived from the fuel oil distribution in the European context that are profoundly different from the MDPVRP instances available from the literature. The proposed algorithm is evaluated on a set of real case studies and on a set of randomly generated instances that hold the same characteristics of the former. © Springer International Publishing AG 2018.","Freight transport; Fuel oil distribution; Genetic algorithm; Metaheuristics; Transportation planning; Vehicle routing","Automobiles; Fleet operations; Freight transportation; Fuel storage; Fuels; Gasoline; Genetic algorithms; Petroleum transportation; Problem solving; Tank trucks; Tanks (containers); Trucks; Vehicle routing; Vehicles; Freight transport; Hybrid genetic algorithms; Mathematical formulation; Meta heuristics; Oil distributions; Periodic vehicle routing problem; Petrol station replenishments; Transportation planning; Fuel oils",2-s2.0-85022181649
"Chen X., Zhao X.","Revenue model for the inter-city railway system based on the stop stations and graded ticket fares",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026754133&doi=10.1007%2f978-981-10-3551-7_9&partnerID=40&md5=6bdd46309ef4a7787091ee110dc71a4d","With respect to the maximum revenue for the inter-city railway passenger transportation channel system with different grades of parallel trains, this paper has studied the matching relations between the system revenue and the passenger flow demand under confirmed demand conditions, analyzed the behavior selection process of passengers for trains with different speed grades within the channel, confirmed the passenger train flow transformation equation based on Logit sharing rate model as well as the collaborative optimization of stop stations and graded ticket fares, established the maximum revenue model of the system, and designed the hybrid particle swarm harmony search algorithm to solve the model. Besides, the new solution comparative law for the algorithm has also been formulated, which can improve the occurring probability of excellent solutions. Finally, verification has been made by taking Zhengzhou-Xi’an Railway Passenger Transportation Channel as an example, which has showed the effectiveness of the model and the algorithm, and the research results have showed that the redistribution of passenger flow realized through the stop stations and graded ticket fare policy can better improve the maximum revenue of the system. © Springer Science+Business Media Singapore 2018.","Particle swarm harmony search algorithm; Passenger flow; Railway passenger transportation channel; Transportation economy; Yield management","Economics; Intelligent systems; Intelligent vehicle highway systems; Learning algorithms; Optimization; Passenger cars; Railroad transportation; Railroads; Harmony search algorithms; Passenger flows; Railway passengers; Transportation economies; Yield management; Transportation",2-s2.0-85026754133
"Bai C., Zhang G., Qiu Y., Leng X., Tian M.","Direct nanofluids configuration optimization based on the evolutionary topology optimization method",2018,"International Journal of Heat and Mass Transfer",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030857292&doi=10.1016%2fj.ijheatmasstransfer.2017.09.135&partnerID=40&md5=9099e1c5abce3d80dd406af67dd88e6c","Nanofluids performance counts on nanoparticle configuration. The evolutionary topology optimization algorithm is applied in this work for direct nanoparticle configuration optimization. The initial random distribution of nanoparticles inside base fluid is found to well simulate practical nanofluids. The optimized nanofluids configuration proves to be continuous strips assembled by nanoparticles with width comparable to size of nanoparticles and length comparable to size of heat-transferring system. System overall thermal resistance is significantly reduced by the optimized nanoparticle configuration. Future nanofluids should be fabricated with strip-shaped nanoparticles in order to perform better. © 2017 Elsevier Ltd","Evolutionary topology optimization algorithm; Nanofluids configuration; Nanofluids fabrication; Nanoparticle size; Nanoparticle volume fraction; System overall thermal resistance","Evolutionary algorithms; Heat resistance; Nanoparticles; Optimization; Topology; Nanofluids; Nanoparticle sizes; Nanoparticle volume fractions; Optimization algorithms; Overall thermal resistance; Nanofluidics",2-s2.0-85030857292
"Zheng L., Hu X., Ding T.","Research of variable lane control method in the emergency evacuation area",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026780851&doi=10.1007%2f978-981-10-3551-7_56&partnerID=40&md5=fa68220b8462236a229d54065c837171","When unexpected disasters are coming, tens of thousands of people lost their lives because of no emergency aid caused by traffic jam. We need to build an emergency planning based on traffic evacuation. This paper proposes a method of variable lane control based on emergency evacuation area, establishes a bi-level programming model and designs solution algorithm based on harmony search to find the optimal solution quickly. After getting the optimal solution, we build the simulation experiment to verify the feasibility and effectiveness of proposed method according to the comparison of the saturation degree and the total travel time of system. © Springer Science+Business Media Singapore 2018.","Bi-level programming model; Emergency evacuation area; Harmony search algorithm; Method of variable lane control","Intelligent systems; Intelligent vehicle highway systems; Optimal systems; Traffic congestion; Transportation; Travel time; Bilevel programming models; Emergency evacuation; Emergency planning; Harmony search algorithms; Lane control; Optimal solutions; Saturation degree; Solution algorithms; Emergency traffic control",2-s2.0-85026780851
"Ahn J., Jo B., Jung S.","Multiple Domain-Based Spatial Keyword Query Processing Method Using Collaboration of Multiple IR-Trees",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032476579&doi=10.1007%2f978-981-10-6520-0_19&partnerID=40&md5=d00cff63b370d48280af43670f2bc8ba","In this paper, we propose multiple domain-based spatial keyword query, called the MDR (Multiple-Domain based Range) query, and query processing algorithm. The MDR query consists of two sub-queries. The first sub-query, called the primary range query, identifies a group of geo-textual objects that are within a query range. The second sub-query, called the refining range query, identifies the geo-textual objects whose neighboring geo-textual objects contain the desired keywords from the results of the primary range query. The problem is that the keywords domains of each sub-queries are different. Existing methods for spatial keyword queries cannot handle the MDR query efficiently because they are designed to handle the keywords of a single domain. In order to accommodate the keywords of various kinds of domains concurrently, we divide the geo-textual database by the domain of the keyword and construct IR-trees for each domain. Based on this approach, our query processing algorithm traverses multiple IR-trees simultaneously, in order to reduce the number of the refining query. Our performance studies show that our searching strategy significantly reduces the query response time. © 2018, Springer Nature Singapore Pte Ltd.","IR-tree collaboration algorithm; Multiple-domain based range (MDR) query; Spatial keyword search","Database systems; Forestry; Processing; Query languages; Refining; Search engines; Trees (mathematics); Collaboration algorithms; Keyword search; Multiple domains; Performance study; Processing method; Query processing algorithms; Query response time; Searching strategy; Query processing",2-s2.0-85032476579
"Ren A., Xue X.","A new solution method for a class of fuzzy random bilevel programming problems",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026789393&doi=10.1007%2f978-3-319-63856-0_29&partnerID=40&md5=3eac69dc38560002497d504f8d06d264","This paper investigates a kind of bilevel programming with fuzzy random variable coefficients in both objective functions and the right hand side of constraints. On the basis of the notion of Er-expected value of fuzzy random variable, the upper and lower level objective functions can be replaced with their corresponding Er-expected values. In terms of probability over defuzzified operator, fuzzy stochastic constraints can be converted into the equivalent forms. Based on these, the fuzzy random bilevel programming problem can be transformed into its deterministic one. Then we suggest differential evolution algorithm to solve the final crisp problem. Finally, a numerical example is given to illustrate the proposed method. © Springer International Publishing AG 2018.","Bilevel programming; Differential evolution algorithm; Er-expected value of fuzzy random variable; Fuzzy random variable","Erbium; Evolutionary algorithms; Fuzzy systems; Multimedia signal processing; Numerical methods; Optimization; Random variables; Stochastic systems; Bi-level programming; Bilevel programming problem; Differential evolution algorithms; Expected values; Fuzzy random variable; Objective functions; Solution methods; Stochastic constraints; Signal processing",2-s2.0-85026789393
"Goubko M.","Maximizing Wiener index for trees with given vertex weight and degree sequences",2018,"Applied Mathematics and Computation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029182588&doi=10.1016%2fj.amc.2017.07.077&partnerID=40&md5=fa26bc4c8ad1c9cec848688731a2f3fb","The Wiener index is maximized over the set of trees with the given vertex weight and degree sequences. This model covers the traditional “unweighed” Wiener index, the terminal Wiener index, and the vertex distance index. It is shown that there exists an optimal caterpillar. If weights of internal vertices increase in their degrees, then an optimal caterpillar exists with weights of internal vertices on its backbone monotonously increasing from some central point to the ends of the backbone, and the same is true for pendent vertices. A tight upper bound of the Wiener index value is proposed and an efficient greedy heuristics is developed that approximates well the optimal index value. Finally, a branch and bound algorithm is built and tested for the exact solution of this NP-complete problem. © 2017 Elsevier Inc.","Greedy algorithm; Optimal caterpillar; Upper-bound estimate; Wiener index for graph with weighted vertices","Branch and bound method; Computational complexity; Forestry; Molecular structure; Optimization; Trees (mathematics); Branch-and-bound algorithms; Degree sequence; Greedy algorithms; Greedy heuristics; Optimal caterpillar; Upper Bound; Vertex- weights; Wiener index; Graph theory",2-s2.0-85029182588
"Xue X., Ren A.","A large scale multi-objective ontology matching framework",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026783755&doi=10.1007%2f978-3-319-63856-0_31&partnerID=40&md5=e5f96da61d208205d77966245b9710a9","Multi-Objective Evolutionary Algorithm (MOEA) is emerging as a state-of-the-art methodology to solve the ontology meta-matching problem. However, the huge search scale of large scale ontology matching problem stops MOEA based ontology matching technology from correctly and completely identifying the semantic correspondences. To this end, in this paper, a large scale multi-objective ontology matching framework is proposed, which works with three sequential steps: (1) partition the large scale ontologies into similar ontology segment pairs; (2) utilize MOEA to match the similar ontology segments in parallel; (3) select the representative ontology segment alignments, which are further aggregated to obtain the final ontology alignment. In addition, a novel multi-objective model is also constructed for ontology matching problem and the MOEA and entity similarity measure that could be used in this framework are also recommended. The experimental result shows the effectiveness of our proposal. © Springer International Publishing AG 2018.","Large scale ontology matching; Multi-objective evolutionary algorithm; Ontology partition","Evolutionary algorithms; Multimedia signal processing; Semantics; Signal processing; Entity similarities; Large-scale ontologies; Matching problems; Multi objective evolutionary algorithms; Multi-objective modeling; Ontology alignment; Ontology matching; Semantic correspondence; Ontology",2-s2.0-85026783755
"Ewald D., Czerniak J.M., Zarzycki H.","OFNBee method used for solving a set of benchmarks",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029422088&doi=10.1007%2f978-3-319-66824-6_3&partnerID=40&md5=c17bd8000edefa4f20c96e8a30f6987f","In the article the results of three optimization algorithms has been compared. The first is the OFNBee algorithm, which uses the properties of ordered fuzzy numbers (OFN, KFN) and a bee-based model. The second algorithm is the ABC, currently the best-known optimization algorithm based on a bee swarm. The last is the PSO algorithm, a method based on a herd of particles that mimic the behaviors of people or insects. © 2018, Springer International Publishing AG.","ABC; Fuzzy logic; Fuzzy observation; OFN; OFNBee; PSO","Computer circuits; Fuzzy sets; Optimization; Particle swarm optimization (PSO); Pattern matching; Fuzzy observation; OFNBee; Optimization algorithms; Ordered fuzzy number; PSO algorithms; Fuzzy logic",2-s2.0-85029422088
"Sanwaliya A., Chinnamgari S.K., Desai A., Saha A.","Graph community detection: Normalized compression distance based implementation for text data",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028635814&doi=10.1007%2f978-3-319-60834-1_5&partnerID=40&md5=7f3bc31626b87b5c01a50f94c99e4b89","Community detection algorithms are widely used to study the structural properties of real-world networks. In this paper, we experimentally evaluate the qualitative performance of several community detection algorithms based on normalized compression distance (NCD) using diversified datasets like documents, feeds, articles and blogs. We compare the quality of the algorithms based on F-score measure. Text data when given as input to NCD performs better when compare to conventional feed like document term matrix as input. Finally, we reveal that label propagation community detection algorithm is more suitable for clustering text data as compare to other community detection algorithms and it creates more distinct communities on diversified data. © 2018, Springer International Publishing AG.","Graph community detection; Machine learning; NLP; Normalized compression distance; Text data","Learning systems; Population dynamics; Signal detection; Community detection; Community detection algorithms; F-score; Label propagation; Normalized compression distance; Real-world networks; Text data; Clustering algorithms",2-s2.0-85028635814
"Martinek R., Kahankova R., Nedoma J., Fajkus M., Nazeran H., Nowakova J.","Adaptive Signal Processing of Fetal PCG Recorded by Interferometric Sensor",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030851604&doi=10.1007%2f978-3-319-68527-4_26&partnerID=40&md5=f4eb22da12165ddb54cb5dbb5d9f1b74","This paper is focused on the design, implementation, and verification of an adaptive system for processing of the fetal phonocardiogram (fPCG) recorded by the novel interferometric sensor. The main interference to be suppressed in the abdominal signal is the maternal phonocardiogram (mPCG). In this article, adaptive methods based on Least Mean Square and Recursive Least Square algorithms are used for the elimination of the maternal component. Evaluation of the filtration quality is provided using the objective parameters (Signal Noise to Ratio, Sensitivity, and Positive Predictive Value). © 2018, Springer International Publishing AG.","Adaptive system; EMI-free; Fetal heart rate (fHR); Fetal Phonocardiography (fPCG); Fiber optic sensors; Interferometer; Least mean squares (LMS) algorithm; Maternal heart rate (mHR); Non-invasive measurements; Recursive least squares (RLS) algorithm","Adaptive systems; Block codes; Data handling; Fetal monitoring; Fiber optic sensors; Heart; Information analysis; Interferometers; Interferometry; Phonocardiography; Position control; Quality control; Signal processing; EMI-free; Fetal heart rate; Fetal phonocardiography; Heart rates; Least mean squares algorithm; Non- invasive measurements; Recursive least squares algorithms; Least squares approximations",2-s2.0-85030851604
"Harrison R.W., Freas C.","Fuzzy restricted boltzmann machines",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030696010&doi=10.1007%2f978-3-319-67137-6_43&partnerID=40&md5=47a9e7174e122867cc70865b277726b8","Restricted Boltzmann Machines are a reconstructive neural network. They derive an implicitly probabilistic model of data which can be used to reconstruct or filter missing data as well as to classify data. This paper develops a deterministic training algorithm and shows how to use that algorithm to automatically derive fuzzy membership classes. The algorithm developed in this paper combines many of the best features of fuzzy learning algorithms and Restricted Boltzmann machines. © Springer International Publishing AG 2018.","Data mining; Deep learning; Energy-based learning; Fuzzy machine learning; Restricted boltzmann machines","Classification (of information); Data mining; Deep learning; Filtration; Learning systems; Energy-based; Fuzzy membership; Missing data; Probabilistic modeling; Restricted boltzmann machine; Training algorithms; Learning algorithms",2-s2.0-85030696010
"Midha N., Singh V.","Classification of e-commerce products using reptree and k-means hybrid approach",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031425401&doi=10.1007%2f978-981-10-6620-7_26&partnerID=40&md5=e576d4e39022b38059b45b5580fd9bed","The paper discusses an algorithm that groups the items on the basis of their attributes and then classifies the clusters. In other words, the proposed algorithms first cluster the items on the basis of property, i.e., attributes available for the dataset. The clustering is performed by K-means clustering. Then this clustered data is classified using the RepTree. In other words, the proposed algorithm is the hybrid algorithm of K-means clustering and the RepTree classification. The proposed algorithm is compared with the RepTree algorithm using the WEKA tool. The comparison is done over clothing dataset downloaded from Internet. The proposed algorithm decreases the mean absolute error as well as the root-mean-square error. The decrease in error results in accurate classification. So the proposed algorithm clusters the items and classifies them on the basis of their attributes more accurately. © 2018, Springer Nature Singapore Pte Ltd.","Clustering; Data mining; K-means; RepTree","Big data; Data mining; Errors; Mean square error; Clustering; Hybrid algorithms; Hybrid approach; K-means; K-means clustering; Mean absolute error; RepTree; Root mean square errors; Clustering algorithms",2-s2.0-85031425401
"Muthukumaran K., Srinivas S., Malapati A., Neti L.B.M.","Software defect prediction using augmented bayesian networks",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028593555&doi=10.1007%2f978-3-319-60618-7_28&partnerID=40&md5=d68689127586210ca132411e9c8f3e87","Prediction models are built with various machine learning algorithms to identify defects prior to release to facilitate software testing, and save testing costs. Naïve Bayes classifier is one of the best performing classification techniques in defect prediction. It assumes conditional independence of features and for defect prediction problem some of the features are not actually conditionally independent. The interesting problem is to relax these conditional independence assumptions and to check whether there is any improvement in performance of classifiers. We have built Bayesian Network structures using different classes of algorithms namely score-based, constraint-based and hybrid algorithms. We propose an approach to augment these Bayesian Network structures with class node. Bayesian Network classifiers along with Random Forests, Logistic Regression and Naïve Bayes classifiers are then evaluated using measures like AUC and H-measure. We observe that RSMAX2 and Grow-Shrink classifiers (after augmentation) perform consistently better in defect prediction. © Springer International Publishing AG 2018.","Bayesian networks; Classification; Software defect prediction","Classification (of information); Decision trees; Defects; Evolutionary algorithms; Forecasting; Learning algorithms; Learning systems; Pattern recognition; Sodium; Soft computing; Software testing; Structures (built objects); Bayesian network classifiers; Bayesian network structure; Classification technique; Conditional independence assumption; Conditional independences; Logistic regressions; Performance of classifier; Software defect prediction; Bayesian networks",2-s2.0-85028593555
"Panday D., Cordeiro de Amorim R., Lane P.","Feature weighting as a tool for unsupervised feature selection",2018,"Information Processing Letters",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030177010&doi=10.1016%2fj.ipl.2017.09.005&partnerID=40&md5=71fe4b8c92251a72e352194133f8ddc3","Feature selection is a popular data pre-processing step. The aim is to remove some of the features in a data set with minimum information loss, leading to a number of benefits including faster running time and easier data visualisation. In this paper we introduce two unsupervised feature selection algorithms. These make use of a cluster-dependent feature-weighting mechanism reflecting the within-cluster degree of relevance of a given feature. Those features with a relatively low weight are removed from the data set. We compare our algorithms to two other popular alternatives using a number of experiments on both synthetic and real-world data sets, with and without added noisy features. These experiments demonstrate our algorithms clearly outperform the alternatives. © 2017 Elsevier B.V.","Algorithms; Clustering; Feature selection","Algorithms; Clustering algorithms; Data handling; Data visualization; Clustering; Data preprocessing; Feature weighting; Given features; Minimum information loss; Running time; Unsupervised feature selection; Within clusters; Feature extraction",2-s2.0-85030177010
"Vaishali, Sharma T.K., Abraham A., Rajpurohit J.","Enhanced asynchronous differential evolution using trigonometric mutation",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028599980&doi=10.1007%2f978-3-319-60618-7_38&partnerID=40&md5=773434df5c5ade69a893646d2ca698e4","The Asynchronous Differential Evolution (ADE) is based on Differential Evolution (DE) with some variations. In ADE the population is updated as soon as a vector with better fitness is found hence the algorithm works asynchronously. ADE leads to stronger exploration and supports parallel optimization. In this paper ADE is embedded with the trigonometric mutation operator (TMO) to enhance the convergence rate of basic ADE. The proposed hybridized algorithm is termed as ADE-TMO. The algorithm is verified over widely used 10 benchmark functions referred from the literature. The simulated results show that ADE-TMO perform better than basic ADE and other state-of-art algorithms. © Springer International Publishing AG 2018.","ADE-TMO; Asynchronous differential evolution; Convergence; Trigonometric mutation","Evolutionary algorithms; Pattern recognition; Soft computing; ADE-TMO; Benchmark functions; Convergence; Convergence rates; Differential Evolution; Hybridized algorithms; Parallel optimization; Trigonometric mutations; Optimization",2-s2.0-85028599980
"Huang Y.-F., Tan T.-H., Chen B.-A.","A novel genetic algorithm for resource allocation optimization in device-to-device communications",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032616188&doi=10.1007%2f978-981-10-6487-6_4&partnerID=40&md5=b0d80e5996611becfd858505b4081464","In this study, the resource blocks (RB) are allocated to user equipment (UE) according to the evolutional algorithms for long term evolution (LTE) systems. Genetic algorithm (GA) is one of the evolutionary algorithms, based on Darwinian models of natural selection and evolution. Therefore, we propose a novel GA for RB allocation to enhance the throughput of UEs and improve the system capacity performance. Simulation results show that the proposed GA with 100 populations, in 200 generations can converge to suboptimal solutions. Therefore, with comparing with the particle swarm optimization (PSO) algorithm the proposed GA can improve system capacity performance with 1.4 UEs. © Springer Nature Singapore Pte Ltd. 2018.","Device-to-device; Genetic algorithm; LTE communication systems; Resource allocation",,2-s2.0-85032616188
"Pradhan A.K., Chatterjee B.C., Oki E., De T.","Knapsack based multicast traffic grooming for optical networks",2018,"Optical Switching and Networking",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029176978&doi=10.1016%2fj.osn.2017.08.002&partnerID=40&md5=d73404ae43dc49002caee6a9b2914340","This paper proposes a light-tree based heuristic algorithm, called 0/1 knapsack based multicast traffic grooming, in order to minimize the network cost by reducing the number of higher layer electronic and optical devices, such as transmitters, receivers, and splitters, and used wavelengths in the network. The proposed algorithm constructs light-trees or sub light-trees, which satisfy sub bandwidth demands of all multicast requests. We present a light-tree based integer linear programming (ILP) formulation to minimize the network cost. We solve the ILP problem for sample four-node and six-node networks and compare the ILP results with the proposed heuristic algorithm. We observe that the performance of the proposed algorithm is comparable to the ILP in terms of cost. When the introduced ILP is not tractable for large network, the proposed algorithm still able to find the results. Furthermore, we compare the proposed heuristic algorithm to existing heuristic algorithms for different backbone networks. Numerical results indicate that the proposed heuristic algorithm outperforms the conventional algorithms in terms of cost and resource utilization. © 2017 Elsevier B.V.","Light-tree; Multicast requests; Network cost; Traffic grooming","Costs; Integer programming; Multicasting; Trees (mathematics); Conventional algorithms; Integer Linear Programming; Light tree; Multi cast traffic grooming; Multicast request; Network costs; Resource utilizations; Traffic Grooming; Heuristic algorithms",2-s2.0-85029176978
"Rostami A.S., Badkoobe M., Mohanna F., Hosseinabadi A.A.R., Balas V.E.","Imperialist competition based clustering algorithm to improve the lifetime of wireless sensor network",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029521634&doi=10.1007%2f978-3-319-62521-8_16&partnerID=40&md5=1980e330772035d8721281a2c92973ae","In Wireless Sensor Network (WSN) nodes have limited energy and cannot be recharged. Clustering is one of the major approaches to optimize consumption of energy and data gathering. In these networks, clustering must be special to prolong network lifetime. In WSN, clustering has heuristic nature and belongs to NP-hard problems. In complex problems, search space is too big and grows exponentially. Because it takes too much time and cost, finding a deterministic optimized solution is difficult in such a short time. In this situation population-based algorithms are beneficial in finding optimum solutions. In this paper, a clustering algorithm is investigated and a novel idea, in line with the population-based algorithm, is presented. The proposed algorithm uses Imperialist Competition Algorithm (ICA) for the clustering of nodes. The results show that this algorithm postpones the dead time of nodes and prolongs network lifetime, compared to other discussed clustering algorithms. © 2018, Springer International Publishing AG.","Clustering; Imperialist Competition Algorithm; Lifetime; WSN",,2-s2.0-85029521634
"Nikolovski F., Stojkovska I.","Complex-step derivative approximation in noisy environment",2018,"Journal of Computational and Applied Mathematics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021303176&doi=10.1016%2fj.cam.2017.05.046&partnerID=40&md5=72dfbe32331424dbe068d41909a5abf4","The complex-step derivative approximation is a powerful method for derivative approximations which has been successfully implemented in deterministic numerical algorithms. We explore and analyze its implementation in noisy environment through examples, error analysis and application to optimization methods. Numerical results show a promising performance of the complex-step gradient approximation in noisy environment. © 2017 Elsevier B.V.","Complex-step derivative approximation; Derivative approximation; Noisy environment; Nonmonotone line-search methods","Numerical methods; Complex steps; Gradient approximation; Noisy environment; Nonmonotone line search; Numerical algorithms; Numerical results; Optimization method; Approximation algorithms",2-s2.0-85021303176
"Sieradzka K., Leszczorz K., Garbulowski M., Polanski A.","Consensus approach for detection of cancer somatic mutations",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030764922&doi=10.1007%2f978-3-319-67792-7_17&partnerID=40&md5=97701de01cfcb2f0096f538a60e971d6","We present a consensus algorithm for detection of somatic mutations in cancer genomics data, based on integrating results of four published somatic mutation callers, MuTect2, MuSE, Varscan2 and Somatic Sniper. We generate consensus lists of cancer somatic mutations by using a simple voting mechanisms. Performances of cancer somatic mutations searching algorithms are verified by a quality index defined by the estimated proportion between driver and passenger mutations. We demonstrate, on the basis of three large NGS datasets from the TCGA database, that our consensus algorithm improves detection of cancer somatic mutations. © 2018, Springer International Publishing AG.","Cancer genomics; Consensus methods; Somatic mutations","Computer programming; Computer science; Cancer genomics; Consensus algorithms; Consensus methods; Quality indices; Searching algorithms; Somatic mutation; Voting mechanism; Diseases",2-s2.0-85030764922
"Thongkam P., Leesutthipornchai P.","Ensemble features selection algorithm by considering features ranking priority",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022225003&doi=10.1007%2f978-3-319-60663-7_5&partnerID=40&md5=3a86adaed6870f950cfd9e54c83b5e57","Feature selection is a pre-processing for choosing relevant features and ignores features that tend to have no predictive information. Feature selection is applied to improve the accuracy of classification process. High relevant features have a tendency to get high classification performance. This paper proposed the ensemble of multiple feature ranking techniques by considering ranker priority for feature selection. Five individual feature ranking algorithms (information gain, gain ratio, symmetrical uncertainty, reliefF and oneR) are investigated and considered together as ensemble, based on ranking priority. The lung cancer, lymphoma, breast cancer, ovarian cancer and leukemia datasets were gathered from Kent Ridge bio-medical data and Machine Learning data repository. The datasets are applied to ensemble features selection algorithm. The obtained results are compared to results from individual feature ranking algorithms and the existing ensemble algorithm. The selected features are applied to classification algorithms. Area under the curve (AUC), precision and recall values from six classification algorithms are used to evaluate the obtained features. The experimental results show that the selected features from proposed ensemble features selection algorithm are greater than those of individual feature ranking techniques and the existing ensemble features selection algorithm. © Springer International Publishing AG 2018.","Ensemble; Feature selection; Ranker","Diseases; Feature extraction; Accuracy of classifications; Area under the curves; Classification algorithm; Classification performance; Ensemble; Precision and recall; Predictive information; Ranker; Classification (of information)",2-s2.0-85022225003
"Chen E.Y.-J., Darwiche A., Choi A.","On pruning with the MDL Score",2018,"International Journal of Approximate Reasoning",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032672527&doi=10.1016%2fj.ijar.2017.10.023&partnerID=40&md5=7b54e67315dbdf46bc20b22307c5108f","The space of Bayesian network structures is prohibitively large and hence numerous techniques have been developed to prune this search space, but without eliminating the optimal structure. Such techniques are critical for structure learning to scale to larger datasets with more variables. Prior works exploited properties of the MDL score to prune away large regions of the search space that can be safely ignored by optimal structure learning algorithms. In this paper, we propose new techniques for pruning regions of the search space that can be safely ignored by algorithms that enumerate the k-best Bayesian network structures. Empirically, these techniques allow a state-of-the-art structure enumeration algorithm to scale to datasets with significantly more variables. © 2017 Elsevier Inc.","Bayesian networks; Structure learning","Learning algorithms; Structural optimization; Bayesian network structure; Enumeration algorithms; Large regions; Optimal structures; Search spaces; State of the art; Structure-learning; Bayesian networks",2-s2.0-85032672527
"Sabelfeld K.K.","A random walk on spheres based kinetic Monte Carlo method for simulation of the fluctuation-limited bimolecular reactions",2018,"Mathematics and Computers in Simulation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963801002&doi=10.1016%2fj.matcom.2016.03.011&partnerID=40&md5=c1e4438a199a659e65bf9fd759206083","To simulate spatially inhomogeneous bimolecular reactions driven by diffusion and tunneling we suggest a new stochastic algorithm which combines the well known Random Walk on Spheres (RWS) method and the kinetic Monte Carlo algorithm. This drastically decreases the computer time in the case of diffusion, and especially for low concentrations. This is the case, for instance, when the annihilation of spatially separate electrons and holes in a disordered semiconductor is studied. The method treats all kinds of reactions involved in a unified stochastic kinetic scheme. In particular, along the diffusion and tunneling, nonradiative recombinations in defect sites are taken into account. To validate the simulation algorithm, we compare our simulation results with the asymptotics of the intensity of annihilation which is known from theoretical predictions. Also, we compare the stochastic algorithms with finite-difference methods. © 2016 International Association for Mathematics and Computers in Simulation (IMACS)","Electron–hole kinetics; Fluctuation-limited reactions; Nonradiative recombination; Photoluminescence; Reaction–diffusion kinetics","Algorithms; Diffusion; Finite difference method; Kinetics; Photoluminescence; Random processes; Reaction kinetics; Stochastic systems; Disordered semiconductors; Electron hole; Fluctuation-limited reactions; Kinetic Monte Carlo methods; Non-radiative recombinations; Reaction-diffusion kinetics; Spatially inhomogeneous; Stochastic algorithms; Monte Carlo methods",2-s2.0-84963801002
"Kumar A., Singh B.K., Patro B.D.K.","Auto improved-PSO with better convergence and diversity",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031398013&doi=10.1007%2f978-981-10-3773-3_5&partnerID=40&md5=59f48cc7334eccf9e726e1e05792c495","Particle swarm optimization [PSO] is one of the most accepted optimization algorithm and due to its simplicity it has been used in many applications. Although PSO converges very fast, it has stagnation and premature convergence problem. To improve its convergence rate and to remove stagnation problem, some changes in velocity vector are suggested. These changes motivate each particle of PSO in different directions so that full search space can be covered and better solutions can be captured. Moreover, autotuning of random parameters are done to remove stagnation problem and local optima. This auto-improved version is named as AI-PSO algorithm. The performance of the proposed version is compared with various state-of-the-art algorithms such as PSO-TVAC and basic PSO. Results show the superiority of the algorithm. © Springer Nature Singapore Pte Ltd. 2018.","Local optima; Premature convergence; PSO; Stagnation","Optimization; Convergence rates; Local optima; Optimization algorithms; Pre-mature convergences; Random parameters; Stagnation; State-of-the-art algorithms; Velocity vectors; Particle swarm optimization (PSO)",2-s2.0-85031398013
"Krömer P., Platoš J.","Evaluation of Traveling Salesman Problem Instance Hardness by Clustering",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030859252&doi=10.1007%2f978-3-319-68527-4_41&partnerID=40&md5=e0316a19fbe672c1193d0592f79b0cfc","Traveling salesman problem (TSP) is a well-known NP-hard combinatorial optimization problem. It has been solved by a number of exact and approximate algorithms and serves as a testbed for new heuristic and metaheuristic optimization algorithms. However, it is often not easy to evaluate the hardness (complexity) of a TSP instance. Simple measures such as the number of cities or the minimum (maximum) route length do not capture the internal structure of a TSP instance sufficiently. In this work, we propose a new method for the assessment of TSP instance complexity based on clustering. The new approach is evaluated on a set of randomized TSP instances with different structure and its relation to the performance of a selected metaheuristic TSP solver is studied. © 2018, Springer International Publishing AG.",,"Combinatorial optimization; Data handling; Hardness; Heuristic algorithms; Information analysis; Optimization; Approximate algorithms; Combinatorial optimization problems; Complexity based; Different structure; Internal structure; Meta-heuristic optimizations; New approaches; Traveling salesman; Traveling salesman problem",2-s2.0-85030859252
"Stevanović M., Vujičić S., Gajić A.M.","Gross domestic product estimation based on electricity utilization by artificial neural network",2018,"Physica A: Statistical Mechanics and its Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026727387&doi=10.1016%2fj.physa.2017.07.023&partnerID=40&md5=47751abd14bedf2e549c6a38dae20040","The main goal of the paper was to estimate gross domestic product (GDP) based on electricity estimation by artificial neural network (ANN). The electricity utilization was analyzed based on different sources like renewable, coal and nuclear sources. The ANN network was trained with two training algorithms namely extreme learning method and back-propagation algorithm in order to produce the best prediction results of the GDP. According to the results it can be concluded that the ANN model with extreme learning method could produce the acceptable prediction of the GDP based on the electricity utilization. © 2017 Elsevier B.V.","Artificial neural network; Electrical energy; Estimation; Gross domestic product","Backpropagation algorithms; Electric power utilization; Estimation; Learning systems; Neural networks; ANN modeling; Electrical energy; Gross domestic products; Learning methods; Nuclear sources; Training algorithms; Backpropagation",2-s2.0-85026727387
"Krivetskiy V., Efitorov A., Arkhipenko A., Vladimirova S., Rumyantseva M., Dolenko S., Gaskov A.","Selective detection of individual gases and CO/H2 mixture at low concentrations in air by single semiconductor metal oxide sensors working in dynamic temperature mode",2018,"Sensors and Actuators, B: Chemical",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025579136&doi=10.1016%2fj.snb.2017.07.100&partnerID=40&md5=663d2cae69e23bf0fd013596560c1854","Highly selective detection of various individual gases (CO, H2, CH4, C3H8, NO, NO2, H2S, SO2) at low concentrations (0.01–667 ppm) in air by a single SnO2-based metal oxide sensor (MOX-sensor) is presented. The sensor operates in dynamic temperature mode combined with a number of adaptive signal processing algorithms. Artificial neural networks were proven to be more effective among the other adaptive algorithms implemented in this study. Identification of individual gases by a single sensor, averaged over all the gases and concentrations, resulted in only 13.2% false recognitions. Most of the failures were attributed to NO2 detection in 0.01–0.1 ppm concentrations range. The ability of a single sensor to identify gas mixtures in a complex background was tested on the example of CO + H2 mixture in air, which simulates smoldering in the early stages of fire. The algorithm showed the ability to identify and quantify CO + H2 mixture with less than 10% error rate, even in constant presence of background gas (NO2 1.4 ppm). Chemical modification of SnO2, increasing sensor response and sensitivity to individual components of the mixture, was proven to be beneficial for improvement of identification and quantification of gas mixture. Significant improvement in quantification accuracy (decrease in relative error from 7 to 2.5%) was achieved by utilizing a 3 sensor array in combination with an adaptive data processing algorithm, compared to the use of a single sensor alone. The prominent negative effect of humidity (Rh 30%, 25 °C) on the performance of adaptive algorithms, sensor signal processing, system selectivity, and gas mixture identification is demonstrated. © 2017 Elsevier B.V.","Adaptive algorithms; Gas sensors; Neural networks; Semiconductor metal oxide; Signal processing; SnO2","Adaptive algorithms; Chemical modification; Chemical sensors; Complex networks; Data handling; Gas mixtures; Metal working; Metallic compounds; Metals; Neural networks; Nitrogen compounds; Nitrogen oxides; Signal processing; Adaptive signal processing; Data processing algorithms; Identification of individuals; Individual components; Metal oxide sensors; Selective detection; Semiconductor metal oxides; SnO<sub>2</sub>; Gases",2-s2.0-85025579136
"Piza-Davila I., Sanchez-Diaz G., Lazo-Cortes M.S., Noyola-Medrano C.","Enhancing the Performance of YYC Algorithm Useful to Generate Irreducible Testors",2018,"International Journal of Pattern Recognition and Artificial Intelligence",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030870042&doi=10.1142%2fS0218001418600017&partnerID=40&md5=9f51a48d0290faa33da569e9c8cd1e70","In pattern recognition, irreducible testors have been used for feature selection. A number of exhaustive algorithms that find irreducible testors have been reported in the literature. One of the latest and more efficient algorithms reported is YYC, an incremental algorithm that finds all the irreducible testors from a training matrix. Its efficiency relies on building a smaller number of feature combinations by finding compatible sets from the top of the matrix to the current row. Nevertheless, as the number of sets currently found grows, YYC execution becomes too slow. This work proposes two improvements of YYC algorithm, incorporated in a pre-processing phase; additionally, a parallel version is implemented. The paper presents some experimental results using synthetic and real data. © 2018 World Scientific Publishing Company.","feature selection; Irreducible testors; pattern recognition; supervised classification","Feature extraction; Pattern recognition; Feature combination; Incremental algorithm; Irreducible testors; Its efficiencies; Parallel version; Pre-processing; Supervised classification; Synthetic and real data; Matrix algebra",2-s2.0-85030870042
"Pal M., Saha S., Bandyopadhyay S.","DECOR: Differential Evolution using Clustering based Objective Reduction for many-objective optimization",2018,"Information Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030678547&doi=10.1016%2fj.ins.2017.09.051&partnerID=40&md5=5c1d09b69184c7d9823044af188cfe4c","Challenges like scalability and visualization which make multi-objective optimization algorithms unsuitable for solving many-objective optimization problems, are often handled using objective reduction approaches. This work proposes a novel many-objective optimization algorithm, viz. Differential Evolution using Clustering based Objective Reduction (DECOR). Correlation distance based clustering of objectives from the approximated Pareto-front, followed by elimination of all but the centroid constituent of the most compact cluster (with special care to singleton cluster), yields the reduced objective set. During optimization, the objective set periodically toggles between full and reduced size to ensure both global and local exploration. For finer clustering, number of clusters is eventually increased until it is equal to the remaining number of objectives. DECOR is integrated with an Improved Differential Evolution for Multi-objective Optimization (IDEMO) algorithm which uses a novel elitist selection and ranking strategy to solve many-objective optimization problems. DECOR is applied on some DTLZ problems for 10 and 20 objectives which demonstrates its superior performance in terms of convergence and equivalence in terms of diversity as compared to other state-of-the-art optimization algorithms. The results have also been statistically validated. Source code of DECOR is available at http://decor.droppages.com/index.html. © 2017 Elsevier Inc.","Differential evolution; DTLZ test problems; Many-objective optimization; Objective reduction; Pareto-optimality","Evolutionary algorithms; Multiobjective optimization; Pareto principle; Reduction; Correlation distance; Differential Evolution; Improved differential evolutions; Many-objective optimizations; Number of clusters; Optimization algorithms; Pareto-optimality; Test problem; Optimization",2-s2.0-85030678547
"Zhong Z., Aveyard R., Rieger B., Bals S., Palenstijn W.J., Batenburg K.J.","Automatic correction of nonlinear damping effects in HAADF–STEM tomography for nanomaterials of discrete compositions",2018,"Ultramicroscopy",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032465293&doi=10.1016%2fj.ultramic.2017.10.013&partnerID=40&md5=567474eb4699c88c8042f0216ad95cb5","HAADF-STEM tomography is a common technique for characterizing the three-dimensional morphology of nanomaterials. In conventional tomographic reconstruction algorithms, the image intensity is assumed to be a linear projection of a physical property of the specimen. However, this assumption of linearity is not completely valid due to the nonlinear damping of signal intensities. The nonlinear damping effects increase w.r.t the specimen thickness and lead to so-called “cupping artifacts”, due to a mismatch with the linear model used in the reconstruction algorithm. Moreover, nonlinear damping effects can strongly limit the applicability of advanced reconstruction approaches such as Total Variation Minimization and discrete tomography. In this paper, we propose an algorithm for automatically correcting the nonlinear effects and the subsequent cupping artifacts. It is applicable to samples in which chemical compositions can be segmented based on image gray levels. The correction is realized by iteratively estimating the nonlinear relationship between projection intensity and sample thickness, based on which the projections are linearized. The correction and reconstruction algorithms are tested on simulated and experimental data. © 2017 Elsevier B.V.",,"Damping; Iterative methods; Nanostructured materials; Tomography; Chemical compositions; HAADF STEM tomographies; Non-linear relationships; Nonlinear damping effects; Reconstruction algorithms; Three dimensional morphology; Tomographic reconstruction algorithms; Total variation minimization; Image reconstruction; artifact; simulation; thickness; tomography",2-s2.0-85032465293
"Chen H., Wang Y.","Kernel-based sparse regression with the correntropy-induced loss",2018,"Applied and Computational Harmonic Analysis",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964956002&doi=10.1016%2fj.acha.2016.04.004&partnerID=40&md5=fee7d38596a17e5ad443efbdc60ea459","The correntropy-induced loss (C-loss) has been employed in learning algorithms to improve their robustness to non-Gaussian noise and outliers recently. Despite its success on robust learning, only little work has been done to study the generalization performance of regularized regression with the C-loss. To enrich this theme, this paper investigates a kernel-based regression algorithm with the C-loss and ℓ1-regularizer in data dependent hypothesis spaces. The asymptotic learning rate is established for the proposed algorithm in terms of novel error decomposition and capacity-based analysis technique. The sparsity characterization of the derived predictor is studied theoretically. Empirical evaluations demonstrate its advantages over the related approaches. © 2016 Elsevier Inc.","Correntropy-induced loss; Kernel-based regression; Learning rate; Learning theory; Sparsity","Algorithms; Gaussian noise (electronic); Regression analysis; Induced loss; Kernel based regression; Learning rates; Learning Theory; Sparsity; Learning algorithms",2-s2.0-84964956002
"Nikolaev N.","Verification of SVD based algorithm for voltage stability assessment against other methods",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031301762&doi=10.1007%2f978-3-319-68324-9_33&partnerID=40&md5=846b12a0d92d6ed8cdc6d92a96e73bfa","A novel algorithm for fast computation of the nearest operating point, where the power flow equations collapse was developed, based on singular value decomposition (SVD). It is claimed to be fast and capable to predict the loading direction to approach the maximum loading point of electric power systems, which requires introduction of minim power. This algorithm still needs to be verified against other established algorithms from the literature. This paper compares the SVD based algorithm against two other ones: (i) direct approach based on the second order Newton method and (ii) reference algorithm based on Monte-Carlo method. Several test systems are used as benchmark. The results confirm the robustness of the SVD based algorithm and its possibility for practical application. © 2018, Springer International Publishing AG.","Monte-Carlo method; Newton-Raphson method; Saddle-node bifurcation; Singular value decomposition; Voltage stability","Electric load flow; Electric power systems; Monte Carlo methods; Newton-Raphson method; System stability; Voltage control; Fast computation; Loading direction; Maximum loading points; Operating points; Power flow equations; Reference algorithm; Saddle node bifurcation; Voltage stability assessment; Singular value decomposition",2-s2.0-85031301762
"Imputato P., Avallone S.","An analysis of the impact of network device buffers on packet schedulers through experiments and simulations",2018,"Simulation Modelling Practice and Theory",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030759018&doi=10.1016%2fj.simpat.2017.09.008&partnerID=40&md5=9a1f245ac065a797c2bebb4577742af3","Keeping the delay experienced by packets while travelling from a source to a destination below certain thresholds is essential to successfully deliver a number of Internet services nowadays. Most of the packet delay can be usually ascribed to the time spent in the many queues encountered by the packet. In this context, the term bufferbloat has been recently coined to denote the uncontrolled growth of the queuing time due, among others, to the excessive size of the buffers and the attitude of TCP to increase the sending rate until a packet is dropped. In this paper, we focus on the queues employed by the traffic control infrastructure and by the network device drivers. Reducing the queuing time due to the former is the objective of a plethora of scheduling algorithms developed in the past years and referred to as Active Queue Management (AQM) algorithms. Conversely, the impact of the additional queuing in the buffer of the network device driver on performance and on the effectiveness of AQM algorithms has instead received much less attention. In this paper, we report the results of an experimental analysis we conducted to gain a better insight into the impact that network device buffers (and their size) have on performance. We also give an in-depth presentation of Dynamic Queue Limits (DQL), an algorithm recently introduced in the Linux kernel to dynamically adapt the size of the buffers held by network device drivers. The experiments we conducted show that DQL not only enables to reduce the queuing time in the network device buffers, which is essential to ensure the effectiveness of AQM algorithms, but also enables to keep latency stable, which is important to reduce the jitter. In order to faithfully reproduce through simulations the dynamics revealed by the experimental study we conducted, we implemented DQL for the popular ns-3 network simulator. In this paper, we describe the design of such implementation and report the results of a simulation study we conducted to show the ability of the simulator to accurately reproduce the experimental results. © 2017 Elsevier B.V.","Active queue management; Dynamic queue sizing; Experimental evaluation; Network simulations","Computer operating systems; Packet networks; Queueing theory; Scheduling; Scheduling algorithms; Active Queue Management; Active queue management algorithms; Control infrastructures; Experimental analysis; Experimental evaluation; Network device drivers; Network simulation; Simulation studies; Queueing networks",2-s2.0-85030759018
"Stoean R., Stoean C., Sandita A.","Evolutionary regressor selection in ARIMA model for stock price time series forecasting",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020452427&doi=10.1007%2f978-3-319-59424-8_11&partnerID=40&md5=23c5abd5e6fb89ce9e88904e1e563f23","Stock price prediction over time is a problem of practical concern in economics and of scientific interest in financial time series forecasting. The matter also expands toward detecting the variables that play an important role in its behaviour. The current study thus appoints an ARIMA model with regressors to predict the daily return of ten companies enlisted in the Romanian stock market on the base of nine exogenous predictors. In order to additionally outline the most informative attributes for the prediction, feature selection is also considered and performed by means of genetic algorithms. The experimental results justify the benefits of the model with the evolutionary selector. © Springer International Publishing AG 2018.","ARIMA; Feature selection; Financial time series forecasting; Genetic algorithms; Regressor; Stock price","Costs; Economics; Electronic trading; Evolutionary algorithms; Financial data processing; Financial markets; Forecasting; Genetic algorithms; Time series; ARIMA; ARIMA modeling; Financial time series forecasting; Informative attributes; Regressor; Stock price; Stock price prediction; Time series forecasting; Feature extraction",2-s2.0-85020452427
"Sakharov M., Karpenko A.","A new way of decomposing search domain in a global optimization problem",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031417761&doi=10.1007%2f978-3-319-68321-8_41&partnerID=40&md5=bb8834bc8e663e173525f4e3ec149fa6","This paper deals with a new method for decomposing search domain in a global optimization problem. Proposed method was designed for parallel population algorithms but also can be used as a diversification tool in sequential algorithms. New decomposition technique was compared with a traditional approach by means of numeric experiments with a use of multi-dimensional benchmark optimization functions and Mind Evolutionary Computation algorithm. Results of the experiments demonstrate the superiority of new technique over a canonical approach which resulted in a higher quality of obtained solutions. © Springer International Publishing AG 2018.","Global optimization; Mind evolutionary computation; Population algorithm; Problem decomposition","Global optimization; Optimization; Decomposition technique; Global optimization problems; Mind evolutionary computation; Multi dimensional; Optimization function; Problem decomposition; Sequential algorithm; Traditional approaches; Evolutionary algorithms",2-s2.0-85031417761
"Bejinariu S.-I., Costin H., Rotaru F., Luca R., Niţă C.D., Lazăr C.","Fireworks algorithm based image registration",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029505262&doi=10.1007%2f978-3-319-62521-8_44&partnerID=40&md5=a9057cac11234f67ebefd628c8967845","In the Image Processing (IP) domain, optimization algorithms have to be applied in many cases. Nature-inspired heuristics allow obtaining near optimal solutions using lower computing resources. In this paper the Fireworks Algorithm (FWA) behavior is studied for Image Registration (IR) problems. The IR results accuracy is analyzed for different types of images, mainly in case of pixel based registration using the Normalized Mutual Information. FWA is compared to Particle Swarming (PSO), Cuckoo Search (CSA) and Genetic Algorithms (GA) in terms of results accuracy and number of objective function evaluations required to obtain the optimal geometric transform parameters. Because the pixel based IR may fail in case of images containing graphic drawings, a features based IR approach is proposed for this class of images. Comparing to other nature inspired algorithms, FWA performances are close to those of PSO and CSA in terms of accuracy. Considering the required computing time, that is determined by the number of cost function evaluations, FWA is little slower than PSO and much faster than CSA and GA. © 2018, Springer International Publishing AG.","Fireworks Algorithm; Image registration; Optimization",,2-s2.0-85029505262
"Majeed S., Gupta A., Raj D., Rhee F.C.-H.","Uncertain fuzzy self-organization based clustering: An interval type-2 approach to adaptive resonance theory",2018,"Information Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030724454&doi=10.1016%2fj.ins.2017.09.062&partnerID=40&md5=b64265c38effc14b54a675f3def2e0d4","Conventional unsupervised learning algorithms require knowledge of the desired number of clusters beforehand. Even if such knowledge is not required in advance, empirical selection of the parameter values may limit the adaptive capability of the algorithm, thereby restricting the clustering performance. An inherent uncertainty in the number and size of clusters requires integration of fuzzy sets into a clustering algorithm. In this paper, we propose a type-1 (T1) fuzzy ART method that adaptively selects the vigilance parameter value, which is critical in determining the network dynamics. This results in improved clustering performance due to the added flexibility in dynamic selection of the number of clusters with the use of fuzzy sets. To further manage the uncertainty associated with memberships, we extend the proposed T1 fuzzy ART with adaptive vigilance to an interval type-2 (IT2) fuzzy ART method. Type reduction and defuzzification are then performed using the KM algorithm to obtain a defuzzified vigilance parameter value. We evaluate our proposed methods on several data sets to validate their effectiveness. © 2017 Elsevier Inc.","Adaptive resonance theory; Fuzzy ART; Interval type-2 fuzzy clustering; Type reduction; Unsupervised learning; Vigilance parameter","Arts computing; Fuzzy sets; Learning algorithms; Parameter estimation; Reduction; Unsupervised learning; Adaptive resonance theory; Fuzzy ART; Interval type-2 fuzzy; Type reduction; Vigilance parameter; Clustering algorithms",2-s2.0-85030724454
"Tharwat A., Gabel T., Hassanien A.E.","Parameter optimization of support vector machine using dragonfly algorithm",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029530556&doi=10.1007%2f978-3-319-64861-3_29&partnerID=40&md5=c6cfa254556fae368487ebe22e92cc3e","Support Vector Machine (SVM) parameters such as penalty and kernel parameters have a great influence on the complexity and accuracy of the classification model. In this paper, Dragonfly algorithm (DA) has been proposed to optimize the parameters of SVM; thus, the classification error can be decreased. To evaluate the proposed model (DA-SVM), the experiment adopted six standard datasets which are obtained from UCI machine learning data repository. For verification, the results of the DA-SVM algorithm are compared with two well-known optimization algorithms, namely, Genetic Algorithm (GA) and Particle Swarm Optimization (PSO). The experimental results demonstrated that the proposed model is capable to find the optimal values of the SVM parameters and avoids the local optima problem. © 2018, Springer International Publishing AG.","Dragonfly Algorithm (DA); Parameter optimization; Support Vector Machine (SVM)",,2-s2.0-85029530556
"Kato K., Takahashi K., Mizuguchi N., Ushiba J.","Online detection of amplitude modulation of motor-related EEG desynchronization using a lock-in amplifier: Comparison with a fast Fourier transform, a continuous wavelet transform, and an autoregressive algorithm",2018,"Journal of Neuroscience Methods",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032854200&doi=10.1016%2fj.jneumeth.2017.10.015&partnerID=40&md5=6a417c6092eace4c1aed0bdf54a4b672","Background Neurofeedback of event-related desynchronization (ERD) in electroencephalograms (EEG) of the sensorimotor cortex (SM1) using a brain–computer interface (BCI) paradigm is a powerful tool to promote motor recovery from post-stroke hemiplegia. However, the feedback delay attenuates the degree of motor learning and neural plasticity. New method The present study aimed to shorten the delay time to estimate amplitude modulation of the motor-imagery-related alpha and beta SM1-ERD using a lock-in amplifier (LIA) algorithm. The delay time was evaluated by calculating the value of the maximal correlation coefficient (MCC) between the time-series trace of ERDs extracted by the online LIA algorithm and those identified by an offline algorithm with the Hilbert transform (HT). Results The MCC and delay values used to estimate the ERDs calculated by the LIA were 0.89 ± 0.032 and 200 ± 9.49 ms, respectively. Comparison with Existing Method(s) The delay time and MCC values were significantly improved compared with those calculated by the conventional fast Fourier transformation (FFT), continuous Wavelet transformation (CWT), and autoregressive (AR) algorithms. Moreover, the coefficients of variance of the delay time and MCC values across trials were significantly lower in the LIA compared with the FFT, CWT, and AR algorithms. Conclusions These results indicate that the LIA improved the detection delay, accuracy, and stability for estimating amplitude modulation of motor-related SM1-ERD. This would be beneficial for BCI paradigms to facilitate neurorehabilitation in patients with motor deficits. © 2017","Brain–computer interface (BCI); Electroencephalogram (EEG); Event-related desynchronization (ERD); Lock-in amplifier (LIA); Motor imagery; Online neurofeedback; Sensorimotor cortex (SM1)","adult; algorithm; amplitude modulation; Article; comparative study; continuous wavelet transformation; controlled study; correlation coefficient; electroencephalography phase synchronization; Fourier transformation; human; human experiment; imagery; male; mathematical phenomena; measurement accuracy; normal human; priority journal; right handedness; sensorimotor cortex; waveform; young adult",2-s2.0-85032854200
"Ali M., Son L.H., Khan M., Tung N.T.","Segmentation of dental X-ray images in medical imaging using neutrosophic orthogonal matrices",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029473226&doi=10.1016%2fj.eswa.2017.09.027&partnerID=40&md5=e463320d8ac4c2eb6a4759e398ffc61c","Over the last few decades, the advance of new technologies in computer equipment, cameras and medical devices became a starting point for the shape of medical imaging systems. Since then, many new medical devices, e.g. the X-Ray machines, computed tomography scans, magnetic resonance imaging, etc., accompanied with operational algorithms inside has contributed greatly to successful diagnose of clinical cases. Enhancing the accuracy of segmentation, which plays an important role in the recognition of disease patterns, has been the focus of various researches in recent years. Segmentation using advanced fuzzy clustering to handle the problems of common boundaries between clusters would tackle many challenges in medical imaging. In this paper, we propose a new fuzzy clustering algorithm based on the neutrosophic orthogonal matrices for segmentation of dental X-Ray images. This algorithm transforms image data into a neutrosophic set and computes the inner products of the cutting matrix of input. Pixels are then segmented by the orthogonal principle to form clusters. The experimental validation on real dental datasets of Hanoi Medical University Hospital, Vietnam showed the superiority of the proposed method against the relevant ones in terms of clustering quality. © 2017 Elsevier Ltd","Dental X-ray image; Fuzzy clustering; Medical diagnosis; Neutrosophic orthogonal matrices","Biomedical equipment; Computerized tomography; Diagnosis; Fuzzy clustering; Image segmentation; Magnetic resonance imaging; Matrix algebra; Medical image processing; Medical imaging; Medical problems; Pattern recognition; X ray analysis; Clustering quality; Computed tomography scan; Computer equipments; Dental X-ray image; Experimental validations; Neutrosophic sets; Operational algorithms; Orthogonal matrix; Clustering algorithms",2-s2.0-85029473226
"Hedrick A., Zhu Y., Pu K.","Modeling transition and mobility patterns",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021422699&doi=10.1007%2f978-3-319-60591-3_48&partnerID=40&md5=bf0d6b39eb0ea7f420c17f8ce39a8ce5","We present a solution to model user transitions and mobility patterns without the need of accessing any cloud services, and thus completely preserving user privacy. Our algorithm relies solely on the sensor inputs of the mobile device to gather environmental fingerprints. A real-time hierarchical clustering algorithm efficiently organizes the individual signatures into a hierarchy of meaningful significant locations at various time scale. By applying (normalized) information measure and neural network based learning, we are able to identify the most salient transition patterns that best characterize the mobility data of the user. Our algorithms are completely online, and do not rely on any networked resources. Thus, user can gain insight to their own mobility activities, and has total control of how this information is to be shared with other applications. We will demonstrate using real-life data the effectiveness and efficiency of our approach. Several appealing visualizations will be showcased. The resulting transition models can be utilized towards better user experience for a variety of mobile applications such as activity scheduling and travel route planning. © Springer International Publishing AG 2018.","Human mobility; Modeling; Privacy","Data privacy; Human engineering; Mobile devices; Models; Effectiveness and efficiencies; Hierarchical clustering algorithms; Human mobility; Information measures; Network-based learning; Networked resources; Significant locations; Travel route planning; Clustering algorithms",2-s2.0-85021422699
"Melnik E., Klimenko A.","Agent-Based Approach to Distributed Information and Control System Reconfiguration",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029599706&doi=10.1007%2f978-3-319-67618-0_18&partnerID=40&md5=f70928256fef7729b1077cf8de5de116","A problem of distributed information and control system (DICS) dependability is relevant nowadays. The DICSs with the performance redundancy and decentralized dispatching implemented by multiagent system are in the scope of this paper. The peculiarities of this class of DICSs require special approaches to the monitoring, control and reconfiguration procedures. The agent-based approach to the DICS reconfiguration is represented. It takes into account a potential of performance redundancy in the aspect of fault-tolerance. The configuration forming problem is solved when it is required by local interactions between software agents via constraint satisfaction problem solving. The paper contains the brief review of the DICS dependability problem and related works, description of performance redundancy and reconfiguration distributed procedure. Two-step agent-based approach to DICS reconfiguration described in details, algorithms of agent interactions and some simulation results are represented and discussed briefly. © 2018, Springer International Publishing AG.","Agent interaction; Control system; Distributed algorithms; Distributed information and control system; Distributed method; Reconfiguration","Computational methods; Constraint satisfaction problems; Control systems; Fault tolerance; Intelligent systems; Multi agent systems; Parallel algorithms; Problem solving; Redundancy; Agent interaction; Agent-based approach; Control system reconfiguration; Distributed information; Distributed methods; Local interactions; Reconfiguration; Related works; Software agents",2-s2.0-85029599706
"Flores-Vidal P.A., Gómez D., Olaso P., Guada C.","A new edge detection approach based on fuzzy segments clustering",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029448934&doi=10.1007%2f978-3-319-66824-6_6&partnerID=40&md5=2c37ed3d0d470a88af31a7c38211f1cc","Edge detection comprises different stages that go from adaptation of the original image -conditioning- to the selection of the definitive edges. This last step, known as scaling, requires the application of a thresholding process over the gradients of luminosity values of the pixels. Traditionally, this is made through a local evaluation process that works pixel by pixel. As the edge candidate pixels are not independent, a wider strategy suggests the use of a more global evaluation. In this sense, this approach resembles more the human vision. This paper further develops ideas related to edge lists, first proposed in 1995 [1]. This paper will refer to edge lists as edge segments. These segments contain visual features similar to the ones that humans use, which might lead to better comparative results. In this paper we propose using clustering techniques to differentiate the appropriate segments or true segments from the false ones, and we introduce an algorithm that uses fuzzy clustering techniques. Finally, this paper shows that this fuzzy clustering over the segments performs at least as well as other standard algorithms used for edge detection. © 2018, Springer International Publishing AG.",,"Cluster analysis; Clustering algorithms; Edge detection; Fuzzy clustering; Fuzzy sets; Image processing; Pattern matching; Pixels; Candidate pixels; Clustering techniques; Detection approach; Different stages; Fuzzy clustering techniques; Original images; Standard algorithms; Visual feature; Fuzzy logic",2-s2.0-85029448934
"Vasavi S.","Extracting hidden patterns within road accident data using machine learning techniques",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031760909&doi=10.1007%2f978-981-10-5508-9_2&partnerID=40&md5=b40024edc7a4f44caa4c78266a591951","Road accidents may not be stopped altogether, but can be reduced. Driver emotions such as sad, happy, and anger can be one reason for accidents. At the same time, environment conditions such as weather, traffic on the road, load in the vehicle, type of road, health condition of driver, and speed can also be the reasons for accidents. Hidden patterns in accidents can be extracted so as to find the common features between accidents. This paper presents the results of the framework from the research study on road accident data of major national highways that pass through Krishna district for the year 2013 by applying machine learning techniques into analysis. These datasets collected from police stations are heterogeneous. Incomplete and erroneous values are corrected using data cleaning measures, and relevance attributes are identified using attribute selection measures. Clusters that are formed using K-medoids, and expectation maximization algorithms are then analyzed to discover hidden patterns using a priori algorithm. Results showed that the selected machine learning techniques are able to extract hidden patterns from the data. Density histograms are used for accident data visualization. © Springer Nature Singapore Pte Ltd. 2018.","Association rule mining; Clustering; Machine learning techniques; Preprocessing; Road accident data analysis; Visualization","Artificial intelligence; Data mining; Data visualization; Flow visualization; Highway accidents; Image segmentation; Learning algorithms; Learning systems; Maximum principle; Motor transportation; Roads and streets; Transportation; Visualization; Attribute selection; Clustering; Environment conditions; Expectation-maximization algorithms; Machine learning techniques; Preprocessing; Research studies; Road accident data; Accidents",2-s2.0-85031760909
"Abuelenin S., Elmougy S., Habeeb F.","Optimizing Deep Learning Based on Deep Auto Encoder and Genetic Algorithm",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029530201&doi=10.1007%2f978-3-319-64861-3_62&partnerID=40&md5=246fe3d0a348d9f28c3993f441086c96","Deep learning (DL) approaches have demonstrated the ability to learn useful features directly from data for a wide variety. The difficulties in learning deep generative or discriminative models can be overcome by an initial unsupervised learning step that maps the inputs to useful intermediate representations. DL systems can automatically discover and generate more combination, and high-level features from raw data sources. Auto encoder techniques include Deep Auto encoder (DAE), Stack Auto encoder (SAE), Contractive Auto encoder (CAE), and Denoising Auto encoder (DA). DAE aims to make good representations of data which can be utilized for reconstruction and classification. It is considered as one of the powerful algorithms that gives higher accuracy and best performance. The proposed method in this paper is based on using DAE and Genetic Algorithm (GA) through applying split-training and merging algorithms for DL. First, the network is divided into two initialized networks (DAE1 and DAE2) using DAE then both of these networks are merged using GA with adding additional dataset for Training process in DAE2. This proposed approach was evaluated based on MNIST dataset and the obtained results showed higher accuracy and lower error in the classification. © 2018, Springer International Publishing AG.","Deep Auto Encoder; Deep learning; Genetic Algorithm",,2-s2.0-85029530201
"Kowalski M., Meynard A., Wu H.-T.","Convex Optimization approach to signals with fast varying instantaneous frequency",2018,"Applied and Computational Harmonic Analysis",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84975166544&doi=10.1016%2fj.acha.2016.03.008&partnerID=40&md5=b1aa5cd893cba2504ea9b2332991d2c4","Motivated by the limitation of analyzing oscillatory signals composed of multiple components with fast-varying instantaneous frequency, we approach the time-frequency analysis problem by optimization. Based on the proposed adaptive harmonic model, the time-frequency representation of a signal is obtained by directly minimizing a functional, which involves few properties an “ideal time-frequency representation” should satisfy, for example, the signal reconstruction and concentrative time-frequency representation. FISTA (Fast Iterative Shrinkage-Thresholding Algorithm) is applied to achieve an efficient numerical approximation of the functional. We coin the algorithm as Time-frequency bY COnvex OptimizatioN (Tycoon). The numerical results confirm the potential of the Tycoon algorithm. © 2016 Elsevier Inc.","Chirp factor; Convex optimization; FISTA; Instantaneous frequency; Time-frequency analysis","Approximation algorithms; Convex optimization; Iterative methods; Time varying networks; Chirp factors; FISTA; Instantaneous frequency; Iterative shrinkage-thresholding algorithms; Numerical approximations; Optimization approach; Time frequency analysis; Time-frequency representations; Optimization",2-s2.0-84975166544
"Burduk R.","The AdaBoost algorithm with linear modification of the weights",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031419628&doi=10.1007%2f978-3-319-68720-9_11&partnerID=40&md5=afb81c58452f0a756d46af49c9bf657d","This paper presents a new extension of the AdaBoost algorithm. This extension concerns the weights used in this algorithm. In our approach the original weights are modified, we propose a linear modification of the weights. In our study we use the boosting by the reweighting method where each weak classifier is based on the linear classifier. The described algorithm was tested on Pima data set. The obtained results are compared with the original the AdaBoost algorithm. © 2018, Springer International Publishing AG.","AdaBoost algorithm; Ensemble of classifiers; Linear classifier","Image processing; AdaBoost algorithm; Data set; Ensemble of classifiers; Linear classifiers; Re-weighting; Weak classifiers; Adaptive boosting",2-s2.0-85031419628
"Lee C.-Y., Yeh J.-F., Chiang T.-C.","A many-objective evolutionary algorithm with reference point-based and vector angle-based selection",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032646459&doi=10.1007%2f978-981-10-6487-6_1&partnerID=40&md5=e6fd819a63b6f7e6d6363955aa576bdc","In this paper we proposed a many-objective evolutionary algorithm by combining the reference point-based selection in NSGA-III and the vector angle-based selection in VaEA. Performance of the proposed algorithm is verified by testing on the negative version of four DTLZ functions. The proposed algorithm is better than NSGA-III and is comparable to VaEA in terms of IGD. Besides, the proposed algorithm is more robust and can expand the front better. © Springer Nature Singapore Pte Ltd. 2018.","EMO; Evolutionary algorithm; Many-objective; Multiobjective; NSGA-III",,2-s2.0-85032646459
"Suarez E., Roldán A., Sagasta F., Gallego A., Benavent-Climent A.","Strategy for required data reduction in the practical implementation in a low-cost electronic platform of an index for damage assessment of seismic dampers",2018,"Measurement: Journal of the International Measurement Confederation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029170147&doi=10.1016%2fj.measurement.2017.08.050&partnerID=40&md5=5e14e1c603a36715e4dc58f2fae75a49","This paper presents a strategy to reduce the number of data required for the in-situ health evaluation of hysteretic energy dampers used for seismic protection of building structures. Such an optimization is essential in order to implement in practice the numerous indices now available for damage assessment of structures in real time, in the context of Structural Health Monitoring (SHM). In general, damage indices are implemented and verified in lab systems entailing expensive and very specialized equipment, which permits the use and management of large amounts of data. For real-time field applications, low-cost embedded computers with limited calculation and data recording capacity may be used; however, they require thorough study of the influence of variables involved in the algorithms for calculation of the damage indices, with ulterior optimization and required data reduction. While the proposed strategy can be followed in broader applications and SHM techniques, the present paper focuses on its application to data coming from vibration tests carried out to evaluate damage of a particular type of hysteretic damper, the Web Plastifying Damper (WPD). The WPD was patented by the University of Granada for the passive control of structures subjected to earthquakes, through a non-parametric damage index previously developed by the authors. This study describes two steps for reducing data: (1) An in-depth study of the calculation time spent on each step of the theoretical algorithm; (2) A parametric study of the influence of key signal parameters—window length, number of windows and duration of the signal—on the damage index calculation in order to minimize the resources needed. Results show a successful optimization that permits the damage index to be calculated with the low-cost Picocom platform. © 2017 Elsevier Ltd","Data reducing; Hysteretic dampers; Optimization algorithms; Structural health monitoring","Cost reduction; Costs; Damage detection; Damping; Hysteresis; Information management; Optimization; Seismology; Shape optimization; Structural health monitoring; Structural optimization; Data reducing; Hysteretic damper; Large amounts of data; Low-cost electronics; Optimization algorithms; Specialized equipment; Structural health monitoring (SHM); Theoretical algorithms; Data reduction",2-s2.0-85029170147
"Malik A., Walker C., O'Sullivan M., Sinnen O.","Satisfiability modulo theory (SMT) formulation for optimal scheduling of task graphs with communication delay",2018,"Computers and Operations Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028540011&doi=10.1016%2fj.cor.2017.08.012&partnerID=40&md5=ca87e4dd2ceb037e73ebf22a8096a93c","In scheduling theory and practise for parallel computing, representing a program as a task graph with communication delays is a popular model, due to its general nature, its expressiveness and relative simplicity. Unfortunately, scheduling such a task graph on a set of processors in such a way that it achieves its shortest possible execution time (P|pred, cij|Cmax in α|β|γ notation) is a strong NP-hard optimization problem without any known guaranteed approximation algorithm. Hence, many heuristics have been researched and are used in practise. However, in many situations it is necessary to obtain optimal schedules, for example, in the case of time-critical systems or for the evaluation of heuristics. Recent years have seen some advances in optimal algorithms for this scheduling problem, based on smart exhaustive state-space search or MILP (Mixed Integer Linear Programming) formulations. This paper proposes a novel approach based on SMT (Satisfiability Modulo Theory). We propose an elegant SMT formulation of the scheduling problem that only needs one decision variable and is very compact and comprehensible in comparison to the state-of-the-art MILP formulations. This novel optimal scheduling approach is extensively evaluated in experiments with more than a thousand task graphs. We perform experimental comparison with the best known MILP formulations, with attempts to further improve them, and deeply analyse the behaviour of the different approaches with respect to size, structure, number of processors, etc. Our proposed SMT-based approach in general outperforms the MILP-formulations and still possesses great potential for further optimization, from which MILP formulations have benefited in the past. © 2017 Elsevier Ltd","MILP; Parallel computing; SMT; Task scheduling with communication delays","Approximation algorithms; Computation theory; Embedded systems; Formal logic; Graph theory; Integer programming; Parallel processing systems; Scheduling; Scheduling algorithms; Surface mount technology; Communication delays; Experimental comparison; MILP; Mixed integer linear programming; Optimal scheduling; Optimization problems; Satisfiability modulo Theories; Time-critical systems; Optimization",2-s2.0-85028540011
"Chanda S., Muralidhar K., Nimdeo Y.M.","Joint estimation of thermal and mass diffusivities of a solute-solvent system using ANN-GA based inverse framework",2018,"International Journal of Thermal Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029502341&doi=10.1016%2fj.ijthermalsci.2017.09.008&partnerID=40&md5=c2f21112ddd82a103748735928fb439f","This work develops an inverse methodology to jointly estimate the thermal and mass diffusivities of a solute-solvent system. An inverse parameter estimation framework using a combination of evolutionary simulation and optimization algorithms namely Artificial Neural Network (ANN) and Genetic Algorithm (GA) is discussed. The direct problem is first solved by assuming thermal and mass diffusivities as constants and then as functions of temperature and concentration. Synthetic experimental data is generated by sprinkling noise sampled from three probability distributions namely Gaussian, Uniform and Logistic on the data obtained from direct numerical simulations carried out using prescribed values of diffusivities. This data is then fed into the inverse framework to estimate the parameters of interest and systematically quantify the associated uncertainties. In case of diffusivities dependent on temperature and concentration both, the higher order parameters are also jointly retrieved and associated uncertainties are quantified. Three sets of experiments namely diffusion of heat in water due to applied temperature difference, isothermal diffusion of salt solution in fresh water and diffusion of salt solution in fresh water along with simultaneous counter current heat diffusion are performed. The time evolving temperature and concentration fields are captured in the form of an interferogram using a Mach-Zehnder interferometer illuminated by a monochromatic laser source (Helium-Neon laser, λ = 632.8 nm). The temperature and concentration data thus obtained is used to estimate the thermal and mass diffusivities of the solute-solvent system using the inverse framework. The results obtained are compared against literature to validate the proposed parameter estimation methodology. © 2017 Elsevier Masson SAS","ANN and GA; Inverse framework; Mach-Zehnder interferometer; Non-traditional optimization; Thermal and mass diffusivities","Diffusion; Diffusion in solids; Evolutionary algorithms; Genetic algorithms; Helium neon lasers; Interferometers; Inverse problems; Mach-Zehnder interferometers; Network function virtualization; Neural networks; Optimization; Probability distributions; Solvents; Uncertainty analysis; Water; Concentration fields; Estimation methodologies; Evolutionary simulations; Inverse framework; Mass diffusivity; Monochromatic lasers; Non-traditional; Temperature differences; Parameter estimation",2-s2.0-85029502341
"Jemelka M., Chramcov B., Kříž P.","Increasing the Efficiency of Logistics in Warehouse Using the Combination of Simple Optimization Methods",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029604510&doi=10.1007%2f978-3-319-67618-0_21&partnerID=40&md5=8b87c48208700cf448b55f6aa28ebc9b","The paper focuses on increasing the efficiency of logistics process in warehouse. Today’s trend is to use simulation tools. To obtain effective solutions exist various optimization methods, optimization algorithms and heuristics. The presented experiment uses the combination of two simple optimization methods for searching the effective solution in reasonable time. The Random solutions algorithm and the All combinations algorithm are used together. Random solutions algorithm generates random combinations and can help indicate how solutions will vary, by giving a picture of the shape of the entire solution space for a scenario. All combinations algorithm is a method, which runs all constrained combinations. If sufficient time is available, this method guarantees that the optimal result will be found. An estimate of the time to be taken can be obtained in advance. This concrete two algorithms demonstration is a high quality and fast way to achieve effective (optimal) results in a short time. The Witness simulation environment is used for the experiments. © 2018, Springer International Publishing AG.","ABC classification; All combinations algorithm; Inventory; Logistics; Optimization; Random solutions algorithm; Simulation; Warehouse","Computational methods; Efficiency; Heuristic methods; Intelligent systems; Logistics; Warehouses; ABC classification; Effective solution; Inventory; Optimization algorithms; Optimization method; Random solutions; Simulation; Witness simulations; Optimization",2-s2.0-85029604510
"Porto A., Gomide F.","Evolving granular fuzzy min-max regression",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030704864&doi=10.1007%2f978-3-319-67137-6_18&partnerID=40&md5=30db1497dafd9a7299643a5778e8a3d4","This paper suggests an evolving granular min-max regression algorithm for fuzzy rule-based system modeling. The algorithm starts with an empty rule base, but adds or modifies the rule base as stream data are input. Granulation of data is done by partitioning the input space using hyperboxes and associating to each hyperbox a fuzzy set and a fuzzy functional rule with affine consequent. The model output is produced combining the affine consequents weighted by the normalized membership degrees of the active fuzzy rules. The parameters of the consequents are adjusted using the recursive least squares with a forgetting factor. The algorithm has an incremental nature, and learns with one-pass processing of the data. The recursive form of the algorithm allows gradual model changes using simple maximum, minimum, and comparison operations, an appealing feature when handling high-dimensional data. Computational experiments concerning time series forecasting and system identification show that the evolving granular fuzzy min-max algorithm is fast, memory efficient, and competitive with current state of the art approaches. © Springer International Publishing AG 2018.","Evolving systems; Fuzzy min-max regression; System modeling","Clustering algorithms; Data handling; Fuzzy inference; Fuzzy rules; Regression analysis; Computational experiment; Evolving systems; Min-max; Recursive least square (RLS); Regression algorithms; State-of-the-art approach; System modeling; Time series forecasting; Computational efficiency",2-s2.0-85030704864
"Ocłoń P., Cisek P., Rerak M., Taler D., Rao R.V., Vallati A., Pilarczyk M.","Thermal performance optimization of the underground power cable system by using a modified Jaya algorithm",2018,"International Journal of Thermal Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030675517&doi=10.1016%2fj.ijthermalsci.2017.09.015&partnerID=40&md5=826f10686e7497869be586abe9304961","This paper presents a modified Jaya algorithm for optimizing the material costs and electric-thermal performance of an Underground Power Cable System (UPCS). A High Voltage (HV) underground cable line with three 400 kV AC cables arranged in flat formation in an exemplary case study is considered. When buried underground, three XLPE high voltage cables are situated in thermal backfill layer for ensuring the optimal thermal performance of the cable system. The study discusses the effect of thermal conductivities of soil and cable backfill material on the UPCS total investment costs. The soil thermal conductivity is assumed constant and equal to 0.8 W/(m K). The cable backfills considered in the study are as follows: sand and cement mix, Fluidized Thermal Backfill™ (FTB) and Powercrete™ a product of Heidelberg Cement Group. Constant thermal conductivities of the backfills in the dry state are assumed, respectively, 1.0 W/(m K), 1.54 W/(m K) and 3.0 W/(m K). The cable backfill dimensions and cable conductor area are selected as design variables in the optimization problem. The modified JAYA algorithm is applied to minimize material costs of UPCS under the constraint that the cable conductor temperature shall not exceed its optimum value of 65 °C. The cable temperature is determined from the two-dimensional steady state heat conduction equation discretized using the Finite Element Method (FEM). The performance of the modified Jaya algorithm was compared with classical Jaya and PSO algorithms. The modified Jaya algorithm, for the presented case study, allows one to obtain lower values of the cost function. © 2017 Elsevier Masson SAS","Finite element method; High voltage; Jaya algorithm; Thermal backfill; Underground power cable system","Cables; Cements; Cost functions; Costs; Equations of state; Finite element method; Fluidization; Heat conduction; Investments; Optimization; Particle swarm optimization (PSO); Telecommunication cables; Underground cables; Conductor temperature; Heidelberg cement groups; High voltage; Optimization problems; Soil thermal conductivity; Steady-state heat conduction equation; Thermal backfill; Underground power cable system; Thermal conductivity",2-s2.0-85030675517
"Bai Y., Zhou Y., He Z., Ye S., Dong B., Xie S.","Compressed-sensing wavenumber-scanning interferometry",2018,"Optics and Laser Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027533282&doi=10.1016%2fj.optlastec.2017.08.003&partnerID=40&md5=bf109c3cae859b126514462129e70a7c","The Fourier transform (FT), the nonlinear least-squares algorithm (NLSA), and eigenvalue decomposition algorithm (EDA) are used to evaluate the phase field in depth-resolved wavenumber-scanning interferometry (DRWSI). However, because the wavenumber series of the laser's output is usually accompanied by nonlinearity and mode-hop, FT, NLSA, and EDA, which are only suitable for equidistant interference data, often lead to non-negligible phase errors. In this work, a compressed-sensing method for DRWSI (CS-DRWSI) is proposed to resolve this problem. By using the randomly spaced inverse Fourier matrix and solving the underdetermined equation in the wavenumber domain, CS-DRWSI determines the nonuniform sampling and spectral leakage of the interference spectrum. Furthermore, it can evaluate interference data without prior knowledge of the object. The experimental results show that CS-DRWSI improves the depth resolution and suppresses sidelobes. It can replace the FT as a standard algorithm for DRWSI. © 2017 Elsevier Ltd","Compressed-sensing; Fringe analysis; Interferometry; Transform","Eigenvalues and eigenfunctions; Interferometry; Inverse problems; Mathematical transformations; Signal reconstruction; Transfer matrix method; Eigenvalue decomposition; Fringe analysis; Interference data; Interference spectrum; Non-linear least squares algorithms; Nonuniform sampling; Standard algorithms; Wave number domain; Compressed sensing",2-s2.0-85027533282
"Jaworek-Korjakowska J., Kłeczek P., Tadeusiewicz R.","Detection and classification of pigment network in dermoscopic color images as one of the 7-point checklist criteria",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028712054&doi=10.1007%2f978-3-319-66905-2_15&partnerID=40&md5=74522c64594a348502776d386ecf2ee7","Malignant melanoma, which is a dangerous proliferation of melanocytes, is commonly diagnosed in all people, regardless of age, gender, or race. In the last several years an increasing melanoma incidence and mortality rate has been observed worldwide and it is rising faster than other forms of cancer. In this paper we present a new approach to the detection and classification of pigment network, one of the major feature in a widely used diagnostic algorithm 7-point checklist. Accurate assessment of pigment network is clinically important due to a significantly different occurrence in benign and malignant skin lesions. We describe a complex algorithm containing following steps: image enhancement, lesion segmentation, pigment network detection as well as classification. The algorithm has been tested on 300 dermoscopic images and achieved 91% sensitivity and classification accuracy of 85%. Compared to state-of-the-art, we obtain improved classification accuracy. © 2018, Springer International Publishing AG.",,"Biocybernetics; Biomedical engineering; Biophysics; Dermatology; Image classification; Oncology; Classification accuracy; Complex algorithms; Dermoscopic images; Diagnostic algorithms; Lesion segmentations; Malignant melanoma; Pigment network detections; State of the art; Image segmentation",2-s2.0-85028712054
"Malik S., Khatri S.K., Sharma D.","Analysing the genetic diversity of commonly occurring diseases",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031400065&doi=10.1007%2f978-981-10-6747-1_5&partnerID=40&md5=9d900928af8266cf9c9394a602a84293","It is generally believed that the existence of all organisms present on this earth has their point of convergence in a common gene pool. The current species passed through an evolutionary process which is still underway. The theoretical assumptions relating to the common descent of all organisms are based on four simple facts: first, they had wide geographical dispersal; second, the different life forms were not remarkably unique and did not possess mutually exclusive characteristics; third, some of their attributes which apparently served no purpose had an uncanny similarity with some of their lost functional traits; and last, based on their common attributes these organisms can be put together into a well-defined, hierarchical and coherent group, like a family tree. Phylogenetic networks are the main tools that can be used to represent biological relationship between different species. Biologists, mathematicians, statisticians, computer scientists and others have designed various models for the reconstruction of evolutionary networks and developed numerous algorithms for efficient predictions and analysis. Even though these problems have been studied for a very long time, but the computational model built to solve the biological problems fail to give accurate results while working on real biological data, which could be due to the premises on which the model is based. The objective of this paper is to test and analyse the transmission of commonly occurring diseases to fit into more realistic models. The problems are not only important because we need to know how they came into existence and how they migrated, but also helpful for the treatment of such diseases and drug discovery. © 2018, Springer Nature Singapore Pte Ltd.","Algorithms; Biological relationships; Genetic diversity; Phylogenetic reconstruction; Substitution model","Algorithms; Biodiversity; Bioinformatics; Biology; Evolutionary algorithms; Technology transfer; Biological relationships; Efficient predictions; Evolutionary network; Evolutionary process; Genetic diversity; Phylogenetic Networks; Phylogenetic reconstruction; Substitution models; Problem solving",2-s2.0-85031400065
"Ning X., Xu Y., Li Y., Li Y.","Particle swarm optimization-based time series data prediction",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026669001&doi=10.1007%2f978-3-319-63859-1_40&partnerID=40&md5=5c0b724ff8934f709d4d529af1d5e787","Time series data is one of the forms of product quality inspection data. It is significant for analyzing and processing big data of product quality inspection to research prediction method of time series data. In this paper, we focus on the problem of the existence of particle scattering and the problem of the lack of computational efficiency. Particle swarm optimization (PSO) is integrated into the standard particle filter algorithm, which improves the sampling process of the particle and optimizes the distribution of the sample, and accelerates the convergence of the particle set. Speed, and improve the performance of particle filter. On this basis, the similarity between particle filter and artificial fish swarm algorithm is analyzed. Based on this similarity, the foraging behavior and clustering behavior of artificial fish. The results show that the proposed algorithm can effectively analyze the time series data. The results show that the proposed algorithm can be used to analyze the residual life prediction of particle swarm optimization based on artificial particle swarm optimization. © Springer International Publishing AG 2018.","Optimization method; Particle filter; Sequence data analysis","Big data; Computational efficiency; Data handling; Forecasting; Monte Carlo methods; Multimedia signal processing; Optimization; Quality control; Signal processing; Time series; Artificial fish swarm algorithms; Foraging behaviors; Optimization method; Particle filter; Particle filter algorithms; Particle scattering; Residual life prediction; Sequence data; Particle swarm optimization (PSO)",2-s2.0-85026669001
"Xue X., Liu S., Wang J.","A Hybrid Central Force Optimization Algorithm for Optimizing Ontology Alignment",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030840313&doi=10.1007%2f978-3-319-68527-4_36&partnerID=40&md5=ff0c1bc28df9d73737516fea89a7ebca","Ontology is regarded as an effective solution to data heterogeneity on the semantic web. However, different ontology engineers might use different ways to define the concept, which causes the ontology heterogeneity problem and raises the heterogeneous problem to a higher level. Ontology matching technology, which is able to identify the same concepts in two heterogeneous ontologies, is recognized as a ground solution to tackle the ontology heterogeneity problem. Since different ontology matchers do not necessarily find the same correct correspondences, usually several competing matchers are applied to the same pair of entities in order to increase evidence towards a potential match or mismatch. How to select, combine and tune various ontology matchers to obtain the high quality ontology alignment becomes a crucial challenges in ontology matching domain. Recently, swarm intelligent algorithms are appearing as a suitable methodology to face this challenge, but the slow convergence and premature convergence are two main shortcomings that makes them incapable of effectively searching the optimal solution for large scale and complex ontology matching problems. To improve the ontology alignment’s quality, our work investigates a new emergent class of swarm intelligent algorithm, named Central Force Optimization (CFO) algorithm. To balance CFO’s exploration and exploitation, we proposes a Hybrid CFO (HCFO) by introducing the local search strategy into CFO’s evolving process, and utilize HCFO to automatically select, combine and tune various ontology matchers to optimize the ontology alignment. The experimental results show that our approach can significantly improve the ontology alignment’s quality of existing swarm intelligent algorithm based ontology matching technologies. © 2018, Springer International Publishing AG.","Hybrid central force optimization algorithm; Ontology heterogeneity problem; Ontology matching","Data handling; Information analysis; Optimization; Central force optimizations; Data heterogeneity; Exploration and exploitation; Heterogeneous ontology; Local search strategy; Ontology heterogeneities; Ontology matching; Pre-mature convergences; Ontology",2-s2.0-85030840313
"Nazeer W., Munir M., Kang S.M.","An intermixed algorithm for three strict pseudo-contractions in Hilbert spaces",2018,"Journal of Computational Analysis and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027301771&partnerID=40&md5=d0abaa6e89bdc6ea27d786dbb86ede5e","We generalize an intermixed algorithm to three and m-strict pseudo-contractions in Hilbert spaces and show that this algorithm converges strongly to the fixed points of three and m-strict pseudo-contractions in Hilbert spaces, independently. Consequently, we can find the common fixed points of these mappings. © 2018 by Eudoxus Press, LLC. All rights reserved.","Fixed point; Intermixed algorithm; Strict pseudo-contractions; Strong convergence",,2-s2.0-85027301771
"Pinto López I.N., Gil Lafuente A.M., Sánchez Flores G.","Pichat’s algorithm for the sustainable regional analysis management: Case study of Mexico",2018,"Studies in Systems, Decision and Control",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032671542&doi=10.1007%2f978-3-319-69989-9_20&partnerID=40&md5=7a1fecd3338f19798c56afe0816c90f9","The group of regions with common similarities allow the improvement of its competences management, support its integration processes, as well as strengthen the social and economic development of the regions that form a group. The analysis of regions with multidimensional characteristics, make necessary the application of concepts, models and algorithms that allow the analysis of ambiguous variables. The presented model seeks to contribute to an informed decision making, closer to reality while identifying those regions that because of its characteristics, share common features to relatively higher levels. The goal of this work is to design a process of grouping regions from the analysis of sustainable indicators, this will allow us maximize the resources in amplitude and quantity with the purpose to generate synergies in order to take the maximum advantage of the capacities of development and well-being. To reach such a goal, a methodological approximation based on Pichat’s algorithm is done using sustainable development indicators of each region as a reference and suggesting the degree of similarity among the regions so the determination of similar groups is possible. © 2018, Springer International Publishing AG.","Diffused logic; Grouping; Pichat’s algorithm; Social well-being; Sustainable growth",,2-s2.0-85032671542
"Liu Y., Geng H., Guo S., Yang W.","Experiment and performance analysis of iterative FX correlation combining algorithm for arraying in deep space network",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028305987&doi=10.1007%2f978-981-10-4837-1_5&partnerID=40&md5=21b84e080366ec25489d96e47855dbbb","Downlink antenna arraying is an effective method to improve the ground receiving capacity instead of the large-aperture antenna in the future deep space explorations, and that the arraying combining algorithm is the key factor in influencing the system performance. In allusion to the problem of the efficient combination under the lower SNR conditions at a Martian distance, an iterative FX correlation combining algorithm is proposed. The principle and performance of the algorithm are discussed and compared in detail, and the arraying application of the algorithm is presented in the CE mission. Simulation and experiment results intimate that adaptive FX correlation combining algorithm has a better performance than other arraying methods such as FSC and BC, and is acceptable for the arraying combining of the Martian weak received signal. © Tsinghua University Press, Beijing and Springer Nature Singapore Pte Ltd. 2018.","Combining algorithm; Downlink antenna arraying; FX correlator; Martian TT & C and communication","Antennas; Signal to noise ratio; Space flight; Antenna arraying; Deep space networks; Deep-space exploration; Key factors; Large aperture antenna; Performance analysis; Received signals; Iterative methods",2-s2.0-85028305987
"Zhu C.J., Lam K.-Y.","Deterministic improved round-trip spanners",2018,"Information Processing Letters",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030150493&doi=10.1016%2fj.ipl.2017.09.008&partnerID=40&md5=ec249571a12e8d813c0daf96eba3bf2b","In this paper, we study the deterministic construction of round-trip spanners for weighted directed graphs. We propose a deterministic algorithm which constructs, for any n-vertex graph G(V,E), a round-trip spanner H(V,E′⊆E) of stretch 2k+ϵ and size O((k/ϵ)⋅n1+1/klog⁡(nw)), where w is the maximum edge weight of G. Notably, this is the first deterministic construction of round-trip spanners and its stretch-size trade-off even improves the previous state-of-the-art randomized algorithm by Roditty et al. More specifically, the size is asymptotically reduced by a factor of k while the stretch factor remains the same. The result is the first clear improvement on round-trip spanners after about ten years and re-raises the open question that how best we can hope for the stretch-size trade-off of round-trip spanners in digraphs. © 2017 Elsevier B.V.","Deterministic algorithms; Graph algorithms; Graph spanners; Round-trip spanners; Shortest distances","Directed graphs; Economic and social effects; Deterministic algorithms; Graph algorithms; Graph spanners; Round trip; Shortest distances; Graph theory",2-s2.0-85030150493
"Galeshchuk S., Mukherjee S.","FOREX trading strategy optimization",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021726839&doi=10.1007%2f978-3-319-60882-2_9&partnerID=40&md5=4571929ed0f355bb47b53c763c7aa53f","Developing robust trading rules for forex trading remains a significant challenge for both academics and practitioners. We employ a genetic algorithm to evolve a diverse set of profitable trading rules based on weighted moving average method. We use the daily closing rates between four pairs of currencies – EUR/USD, GBP/USD, USD/JPY, USD/CHF – to develop and evaluate our method. Results are presented for all four currency pairs over the 16 years from 2000 to 2015. Developed approach yields acceptably high returns on out-of-sample data. The rules obtained using our genetic algorithm result in significantly higher returns than those produced by rules identified through exhaustive search. © Springer International Publishing AG 2018.","Evolutionary algorithms; Forex market; Trading rules; Weighted moving average","Artificial intelligence; Commerce; Distributed computer systems; Economics; Evolutionary algorithms; Genetic algorithms; Optimization; Forex markets; Forex trading; Sample data; Trading rules; Weighted moving averages; Electronic trading",2-s2.0-85021726839
"Hussain S.M., Zafar A., Khalid R., Abid S., Qasim U., Khan Z.A., Javaid N.","An efficient scheduling of electrical appliance in micro grid based on heuristic techniques",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026302061&doi=10.1007%2f978-3-319-61566-0_15&partnerID=40&md5=79147957b80b0db81747c63a481d6bc9","Unlike existing centralized grids, smart grids (SGs) have the ability to reduce fossil fuel combustion and carbon emissions up to a significant mark. Smart homes and smart building are becoming more attractable due to low energy consumption and high comfort. Different demand side management (DSM) programs have been proposed to involve users in decision making process of SGs. Power consumption pattern of shiftable home appliances is modified in response of some rebates to achieve certain benefits. In this paper, an energy management model is proposed using genetic algorithm (GA), teaching learning based optimization (TLBO), enhanced differential evolution (EDE) algorithm and our novel proposed EDTLA. The main objectives include: daily electricity bill minimization, peak to average ratio reduction and user comfort maximization. Simulation results validate the performance and applicability of our proposed model. © Springer International Publishing AG 2018.",,"Automation; Carbon; Decision making; Domestic appliances; Energy utilization; Evolutionary algorithms; Fuels; Genetic algorithms; Heuristic methods; Intelligent buildings; Optimization; Decision making process; Differential Evolution; Electrical appliances; Fossil fuel combustion; Heuristic techniques; Low energy consumption; Peak to average ratios; Teaching-learning-based optimizations; Electric power transmission networks",2-s2.0-85026302061
"Salehisadaghiani F., Pavel L.","Distributed Nash equilibrium seeking in networked graphical games",2018,"Automatica",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031744262&doi=10.1016%2fj.automatica.2017.09.016&partnerID=40&md5=1d91dd9a3e9155681621988f4b329990","This paper considers a gossip approach for finding a Nash equilibrium in networked games on graphs, where a player's cost function may be affected by the actions of any subset of players. An interference graph illustrates the partially-coupled cost functions, i.e., the asymmetric strategic interaction and information requirements. An algorithm is proposed whereby players make decisions based only on the estimates of their interfering players’ actions. Given the interference graph (not necessarily complete), a communication graph is designed so that players exchange only their required information. When the interference graph is sparse, the algorithm can offer substantial savings in communication and computation. Almost sure convergence to a Nash equilibrium is proved for diminishing step sizes. The effect of the second largest eigenvalue of the expected communication matrix on the convergence rate is quantified. © 2017 Elsevier Ltd","Communication graph; Distributed algorithms; Interference graph; Noncooperative games","Computation theory; Eigenvalues and eigenfunctions; Game theory; Parallel algorithms; Almost sure convergence; Communication graphs; Communication matrixes; Information requirement; Interference graphs; Noncooperative game; Second largest eigenvalue; Strategic interactions; Cost functions",2-s2.0-85031744262
"Zhang C., Ramirez-Marquez J.E., Li Q.","Locating and protecting facilities from intentional attacks using secrecy",2018,"Reliability Engineering and System Safety",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026886925&doi=10.1016%2fj.ress.2017.08.005&partnerID=40&md5=ccb9eb0bb7fdb0fb825f39150ea6ff7e","To preserve continued effective performance of facilities, their protection against intentional attacks needs to be considered while determining optimal facility location solutions. We propose a simultaneous game between a defender and an attacker to study facility protection against intentional attacks while keeping the information about protection resource allocation secret. To deal with the complexity of solving the proposed simultaneous game, we employ an algorithm with necessary adaptations to identify its mixed-strategy Nash equilibrium solution, which is used to evaluate the disruption inflicted by intentional attacks on the efficiency of a facility location solution. The facility location problem with protection against intentional attacks is then modeled as a multi-objective optimization problem, in order to balance the cost of opening facilities and the efficiency of facilities with and without facility failures inflicted by intentional attacks. MO-PSDA, a multi-objective evolutionary algorithm, is employed to solve the proposed multi-objective optimization problem. © 2017 Elsevier Ltd","Facility location; Intentional attacks; Multi-objective optimization; Secrecy; Simultaneous game","Efficiency; Evolutionary algorithms; Location; Optimization; Facility location problem; Facility locations; Intentional Attacks; Multi objective evolutionary algorithms; Multi-objective optimization problem; Optimal facility location; Secrecy; Simultaneous game; Multiobjective optimization",2-s2.0-85026886925
"Zhou Q., Lin C.-M., Chao F.","Adaptive Noise Cancelation Using Fuzzy Brain Emotional Learning Network",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029599148&doi=10.1007%2f978-3-319-66939-7_14&partnerID=40&md5=b104d16a62f1aace61e67f40cf9a4d46","This paper proposes a fuzzy brain emotional learning network for adaptive noise cancelation. The proposed network is based on brain emotional learning algorithm which is developed according to the emotional learning process of mammalian and the fuzzy inference is added for better ability to handle uncertainties. Parameters in the network are modified online by the derived adaption laws. In addition, a stable convergence is guaranteed by utilizing the Lyapunov stability theorem. Finally, in order to demonstrate the performance of the proposed filter, it is applied in a signal processing application where different source signals and noise signals are used. A comparison between the proposed method, Least mean square algorithm and a fuzzy cerebellar model articulation controller filter shows that the proposed method can converge faster even when the source signal is corrupted severely. © 2018, Springer International Publishing AG.","Adaptive noise cancelation; Emotional learning; Fuzzy inference","Artificial intelligence; Computation theory; Fuzzy inference; Inference engines; Intelligent control; Learning algorithms; Learning systems; Least squares approximations; Mammals; Signal processing; Spurious signal noise; Adaptive noise cancelations; Brain emotional learning; Emotional learning; Fuzzy cerebellar model articulation controllers; Least mean square algorithms; Lyapunov stability theorem; Signal processing applications; Source signals; Fuzzy filters",2-s2.0-85029599148
"Ježowicz T., Gajdoš P., Uher V., Mišák S., Snášel V.","Improving the speed and quality of extreme learning machine by conjugate gradient method",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028634811&doi=10.1007%2f978-3-319-60834-1_14&partnerID=40&md5=61822c1e4b7027a37e7a84a926444bb8","Extreme Learning Machine (ELM) is a novel learning algorithm. It is basically a feedforward neural network with one hidden layer, fixed input weights and fixed biases. ELM has become popular in recent years due to the fast learning speed and good generalization performance. A novel approach based on Conjugate Gradient Method (CG) is proposed in this Article to improve original ELM. As experiments show, proposed approach is both faster and have higher quality on all tested datasets. Results have also shown that higher quality can be achieved after four iterations of CG. This means that expensive pseudo-inverse operation used in the original algorithm can be replaced by four matrix-vector multiplication and several scalar products. Therefore the proposed approach is more suitable for parallel architectures or can be used for larger datasets. © 2018, Springer International Publishing AG.",,"Feedforward neural networks; Gradient methods; Inverse problems; Knowledge acquisition; Learning algorithms; Learning systems; Parallel architectures; Extreme learning machine; Generalization performance; Hidden layers; Input weights; Matrix vector multiplication; Original algorithms; Pseudo-inverses; Scalar product; Conjugate gradient method",2-s2.0-85028634811
"Gandhi R., Hajiaghayi M.T., Kortsarz G., Purohit M., Sarpatwar K.","On maximum leaf trees and connections to connected maximum cut problems",2018,"Information Processing Letters",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029579591&doi=10.1016%2fj.ipl.2017.06.002&partnerID=40&md5=01ba62991a5bc9412c7617c9c910a793","In an instance of the (directed) Max Leaf Tree (MLT) problem we are given a vertex-weighted (di)graph G(V,E,w) and the goal is to compute a subtree with maximum weight on the leaves. The weighted Connected Max Cut (CMC) problem takes in an undirected edge-weighted graph G(V,E,w) and seeks a subset S⊆V such that the induced graph G[S] is connected and ∑e∈δ(S)w(e) is maximized. We obtain a constant approximation algorithm for MLT when the weights are chosen from {0,1}, which in turn implies a Ω(1/log⁡n) approximation for the general case. We show that the MLT and CMC problems are related and use the algorithm for MLT to improve the factor for CMC from Ω(1/log2⁡n) (Hajiaghayi et al., ESA 2015) to Ω(1/log⁡n). © 2017 Elsevier B.V.","Approximation algorithms; Connected maximum cut; Maximum leaf trees","Approximation algorithms; Directed graphs; Forestry; Graph theory; Constant approximation algorithms; Edge-weighted graph; Graph G; MAX CUT; Maximum cut problems; Maximum cuts; Maximum leaf; Sub trees; Trees (mathematics)",2-s2.0-85029579591
"Tabibian S., Akbari A., Nasersharif B.","Discriminative keyword spotting using triphones information and N-best search",2018,"Information Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029726995&doi=10.1016%2fj.ins.2017.09.052&partnerID=40&md5=a9d146db2be095e1ae8882c639b0a0c4","Keyword Spotting (KWS) systems can be divided into two main groups: Hidden Markov Model (HMM)-based and Discriminative KWS (DKWS) systems. In this paper, we propose an approach to improve a DKWS system using advantages of HMM-based systems. The proposed DKWS system contains feature extraction and classification (that includes a classifier and a search algorithm) parts. The focus of this paper is on the feature extraction part and the search algorithm. At first, we propose a method for using the advantages of a triphone-based HMM system and improving the monophone-based feature extraction, (proposed in our previous works), to triphone-based one. Then, we propose an N-best search algorithm instead of one-best algorithm. The results on TIMIT database indicate that the true detection rate of the triphone-based Evolutionary DKWS (EDKWS) system with N-best search (Tph-EDKWS-N-Best), in false alarm rate per keyword per hour greater than two, is 4.6% higher than that of the monophone-based EDKWS system with one-best search (Mph-EDKWS-1-Best). This improvement costs about 0.4 unit degradation in Real Time Factor (a common metric of measuring the speed of an automatic speech recognition system). Additionally, Figure of Merit (average true detection rate for different false alarm per keyword per hour from 1 to 10) of the Tph-EDKWS-N-Best system is noticeably higher than that of HMM-based KWS systems. However, the computational complexity of the Tph-EDKWS-N-Best system is considerably higher than that of the HMM-based KWS systems. © 2017 Elsevier Inc.","Discriminative keyword spotting; Hidden Markov model; N-best search; One-best search; Phone recognizer; Triphone","Alarm systems; Errors; Extraction; Feature extraction; Learning algorithms; Markov processes; Speech recognition; Automatic speech recognition system; Feature extraction and classification; HMM-based systems; Keyword spotting; One-best search; Phone recognizer; Search Algorithms; Triphones; Hidden Markov models",2-s2.0-85029726995
"Viktorin A., Senkerik R., Pluhacek M., Kadavy T.","Towards better population sizing for differential evolution through active population analysis with complex network",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026313361&doi=10.1007%2f978-3-319-61566-0_22&partnerID=40&md5=4463788f96fa80545318c47c171583ee","This research paper presents an analysis of the population activity in Differential Evolution algorithm (DE) during the optimization process. A state-of-art DE variant – Success-History based Adaptive DE (SHADE) is used and the population activity is analyzed through Complex Network (CN) created from mutation, crossover and selection steps. The analysis is done on the CEC2015 benchmark set and possible future research directions for the population sizing are suggested. © Springer International Publishing AG 2018.",,"Arts computing; Evolutionary algorithms; Optimization; Differential Evolution; Differential evolution algorithms; Population activities; Population analysis; Population sizing; Possible futures; Research papers; Complex networks",2-s2.0-85026313361
"Tripathi A., Shukla S., Arora D.","A hybrid optimization approach for load balancing in cloud computing",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031426086&doi=10.1007%2f978-981-10-3773-3_19&partnerID=40&md5=69df35bf7c8cdbccf82814f66cfc5f94","Cloud computing is characterized as a technology which is recent and has an﻿ important effect on the field of IT in the nearby future. Load balancing is one of the fundamental issues in cloud computing. There could be various types of load such as CPU load, delay or network load, and capacity of the memory. Load balancing is the procedure of dispersing the load of work among numerous nodes in a system which is distributed for better response time in the job and also for better utilization of resources. Load balancing guarantees that all the processors in the system perform equalized amount of work at any particular instant of time. In this paper, a hybrid algorithm of ant colony optimization and bee colony algorithm is proposed. The proposed mechanism takes the characteristic of a complex network into consideration. The strategy is combined with the setting of other parameters of the upgraded bee colony algorithm to form a new ACO method. The new hybrid approach has been simulated using the Cloud Analyst tool. © Springer Nature Singapore Pte Ltd. 2018.","ABC; ACO; Cloud analyst; Cloud computing; Load balancing","Artificial intelligence; Cloud computing; Complex networks; Network function virtualization; Optimization; Resource allocation; ACO method; Bee colony algorithms; Hybrid algorithms; Hybrid approach; Hybrid optimization approaches; OR-networks; Utilization of resources; Ant colony optimization",2-s2.0-85031426086
"Cheng K., Lu Z.","Adaptive sparse polynomial chaos expansions for global sensitivity analysis based on support vector regression",2018,"Computers and Structures",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029824938&doi=10.1016%2fj.compstruc.2017.09.002&partnerID=40&md5=ac1007520a75f45c3f873e1fe6641185","In the context of uncertainty analysis, Polynomial chaos expansion (PCE) has been proven to be a powerful tool for developing meta-models in a wide range of applications, especially for sensitivity analysis. But the computational cost of classic PCE grows exponentially with the size of the input variables. An efficient approach to address this problem is to build a sparse PCE. In this paper, a full PCE meta-model is first developed based on support vector regression (SVR) technique using an orthogonal polynomials kernel function. Then an adaptive algorithm is proposed to select the significant basis functions from the kernel function. The selection criterion is based on the variance contribution of each term to the model output. In the adaptive algorithm, an elimination procedure is used to delete the non-significant bases, and a selection procedure is used to select the important bases. Due to the structural risk minimization principle employing by SVR model, the proposed method provides better generalization ability compared to the common least square regression algorithm. The proposed method is examined by several examples and the global sensitivity analysis is performed. The results show that the proposed method establishes accurate meta-model for global sensitivity analysis of complex models. © 2017 Elsevier Ltd","Adaptive kernel function; Global sensitivity analysis; Sparse polynomial chaos expansion; Support vector regression","Adaptive algorithms; Least squares approximations; Orthogonal functions; Polynomials; Regression analysis; Uncertainty analysis; Adaptive kernel functions; Generalization ability; Global sensitivity analysis; Least-square regression algorithms; Polynomial chaos expansion (PCE); Sparse polynomials; Structural risk minimization principle; Support vector regression (SVR); Sensitivity analysis",2-s2.0-85029824938
"Amador-Angulo L., Castillo O.","Comparative study of metrics that affect in the performance of the bee colony optimization algorithm through interval type-2 fuzzy logic systems",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030691173&doi=10.1007%2f978-3-319-67137-6_7&partnerID=40&md5=42e3daa65e4b8bd89fb1f72136baa171","A comparative study of different proposed methods using interval type-2 fuzzy logic systems (IT2FLS) to find optimal α and β values in a Bee Colony Optimization Algorithm (BCO) applied to the stabilization of the trajectory in an autonomous mobile robot (AMR) is presented. Three metrics are analyzed for finding the optimal values that affect in the efficiency of the BCO algorithm. Perturbation is added in the model. Simulation results indicate that the MSE error is an important metric for determine the optimal values in the effective of the execution in the BCO algorithm. © Springer International Publishing AG 2018.","Adjustment dynamic; Bee algorithm; Interval Type-2 Fuzzy Logic System; Mean square error","Computer circuits; Mean square error; Optimal systems; Optimization; Autonomous Mobile Robot; Bee Algorithm; Bee colony optimizations; Comparative studies; Interval type-2 fuzzy logic systems; Optimal values; Fuzzy logic",2-s2.0-85030691173
"Xu G., Gou Z., Zhang B.","An improved adaptive SRCKF Algorithm for non-cooperative target orbit determination",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028356976&doi=10.1007%2f978-981-10-4837-1_24&partnerID=40&md5=ecb58f856471cce23d8851fc4aa37749","In this paper, a novel filtering algorithm for the orbit determination of non-cooperative target is proposed to cope with the simplified dynamic model error problem. The algorithm is based on the nonlinear predictive filter (NPF) and the square root cubature Kalman (SCKF) filter, called adaptive square root cubature filter ASRCKF). In the filtering process, NPF is used to modify the orbit dynamic model and SRCKF takes the revised model for state estimation. The simulation results validate the proposed algorithm has higher tracking precision, stronger robustness and stability than traditional filter. © Tsinghua University Press, Beijing and Springer Nature Singapore Pte Ltd. 2018.","Adaptive SRCKF; Non-cooperative target; Revised model; Space based orbit determination","Dynamic models; Kalman filters; Orbits; Adaptive SRCKF; Dynamic model error; Filtering algorithm; Non-cooperative target; Orbit determination; Revised modeling; Tracking precision; Traditional filter; Adaptive filtering",2-s2.0-85028356976
"Du L., Sogabe T., Zhang S.-L.","A fast algorithm for solving tridiagonal quasi-Toeplitz linear systems",2018,"Applied Mathematics Letters",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025101171&doi=10.1016%2fj.aml.2017.06.016&partnerID=40&md5=8c3de38e01d8de513a3916dffa3e6afe","In this paper, we consider the solution of tridiagonal quasi-Toeplitz linear systems. By exploiting the special quasi-Toeplitz structure, we give a new decomposition form of the coefficient matrix. Based on this matrix decomposition form and combined with the Sherman–Morrison formula, we propose an efficient algorithm for solving the tridiagonal quasi-Toeplitz linear systems. Although our algorithm takes more floating-point operations (FLOPS) than the LU decomposition method, it needs less memory storage and data transmission and is about twice faster than the LU decomposition method. Numerical examples are given to illustrate the efficiency of our algorithm. © 2017 Elsevier Ltd","Direct methods; LU decomposition; Sherman–Morrison formula; Tridiagonal Toeplitz matrix","Digital storage; Linear systems; Algorithm for solving; Direct method; Floating point operations; Lu decomposition; LU decomposition method; Matrix decomposition; Toeplitz linear systems; Toeplitz matrices; Matrix algebra",2-s2.0-85025101171
"Zhang S., Liu X., Sheng Y.","Analysis and system simulation of flight vehicle sliding mode control algorithm based on PID neural network",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028366157&doi=10.1007%2f978-3-319-60744-3_33&partnerID=40&md5=a087b5da4ce97f7d4600698e55350420","In recent years, the unmanned aerial vehicle has been widely concerned because of its simple structure, high flexibility and other advantages, and it is of important application value. Based on the current research achievements and related theories, a flight control algorithm based on the PID neural network is designed, and the feasibility of the algorithm is verified by simulation experiment. Experiments show that the controller on a basis of the new algorithm actually has excellent performance on the attitude and position control. It can be used to control the aircraft system in general and get better control effect. © 2018, Springer International Publishing AG.","Neural network; PID; Sliding mode control algorithm","Flight simulators; Intelligent systems; Neural networks; Position control; Real time systems; Aircraft systems; Flight vehicles; High flexibility; PID neural network; Research achievements; Simple structures; System simulations; Sliding mode control",2-s2.0-85028366157
"Li J., Yang Z.","A QP-free algorithm without a penalty function or a filter for nonlinear general-constrained optimization",2018,"Applied Mathematics and Computation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028955761&doi=10.1016%2fj.amc.2017.08.013&partnerID=40&md5=a59eaadce1a32e1143ec93c3fc0bcdcf","In this paper, we present a QP-free algorithm without a penalty function or a filter for nonlinear general-constrained optimization. At each iteration, three systems of linear equations with the same coefficient matrix are solved to yield search direction; the nonmonotone line search ensures that the objective function or constraint violation function is sufficiently reduced. There is no feasibility restoration phase in our algorithm, which is necessary for filter methods. The algorithm possesses global convergence as well as superlinear convergence under some mild conditions including a weaker assumption of positive definiteness. Finally, some preliminary numerical results are reported. © 2017 Elsevier Inc.","Filter-free; General-constrained optimization; Global convergence; Penalty-function-free; QP-free algorithm; Superlinear convergence","Bandpass filters; Constrained optimization; Iterative methods; Linear equations; Filter-free; General constrained optimization; Global conver-gence; Penalty function; QP-free algorithm; Superlinear convergence; Optimization",2-s2.0-85028955761
"Castillo O., Soto C., Valdez F.","A review of fuzzy and mathematic methods for dynamic parameter adaptation in the firefly algorithm",2018,"Studies in Computational Intelligence",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030098521&doi=10.1007%2f978-3-319-67946-4_13&partnerID=40&md5=13cefe73d1b41a3703b668739f4450ba","The firefly algorithm is a bioinspired metaheuristic based on the firefly’s behavior. This paper presents a review on previous works on parameters analysis and dynamical parameter adjustment, using different mathematical approches and fuzzy logic. © Springer International Publishing AG 2018.","Firefly algorithm; Fuzzy adaptation; Mathematical functions; Optimization problems; Parameter adaptation",,2-s2.0-85030098521
"Aguilar M.A., Novelli A., Nemamoui A., Aguilar F.J., Lorca A.G., González-Yebra Ó.","Optimizing multiresolution segmentation for extracting plastic greenhouses from worldview-3 imagery",2018,"Smart Innovation, Systems and Technologies",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020460630&doi=10.1007%2f978-3-319-59480-4_4&partnerID=40&md5=7a5e34d66797081a89193557a4467e9e","Multiresolution segmentation (MRS) has been pointed out as one of the most successful image segmentation algorithms within the object-based image analysis (OBIA) framework. The performance of this algorithm depends on the selection of three tuning parameters (scale, shape and compactness) and the bands combination and weighting considered. In this work, we tested MRS on a World‐ View-3 bundle imagery in order to extract plastic greenhouse polygons. A recently published command line tool created to assess the quality of segmented digital images (AssesSeg), which implements a modified version of the supervised discrepancy measure named Euclidean Distance 2 (ED2), was used to select both the best aforementioned MRS parameters and the optimum image data source derived from WorldView-3 (i.e., panchromatic, multispectral and atmospherically corrected multispectral orthoimages). The best segmentation results were always attained from the atmospherically corrected multispectral World‐ View-3 orthoimage. © Springer International Publishing AG 2018.","AssesSeg; Multiresolution algorithm; Object based image analysis; Segmentation; WorldView-3","Greenhouses; Image analysis; Interactive computer systems; Multimedia services; Multimedia systems; Scales (weighing instruments); AssesSeg; Discrepancy measures; Image segmentation algorithm; Multi-resolution algorithms; Multiresolution segmentation; Object based image analysis; Object based image analysis (OBIA); WorldView-3; Image segmentation",2-s2.0-85020460630
"Burduk R.","Drift detection algorithm using the discriminant function of the base classifiers",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019229429&doi=10.1007%2f978-3-319-59162-9_51&partnerID=40&md5=849d6b2d4b37db7478f6d38ae07a7fd8","Recently, several approaches have been proposed to deal with the concept drift detection. In this paper we propose the new concept drift detection algorithm based on the decision templates. The decision templates are obtained from the outputs of the base classifier that form an ensemble of classifiers. Experiments on several publicly available data sets verify the effectiveness of the proposed algorithm. © Springer International Publishing AG 2018.","Decision templates; Drift detection; Multiple classifier system","Computer programming; Computer science; Base classifiers; Concept drifts; Decision template; Detection algorithm; Discriminant functions; Ensemble of classifiers; Multiple classifier systems; Signal detection",2-s2.0-85019229429
"Oleśków-Szłapka J., Pawłowski G., Fertsch M.","An optimization approach for scheduling and lot sizing problems in electromechanical industry using GA-based method",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028594169&doi=10.1007%2f978-3-319-64465-3_14&partnerID=40&md5=0dee31a75e3f3f6c5b06cf86c686e711","The paper presents a method to determine the lot size and production schedule for variable ranges of products based on genetic algorithm. The computer simulation checks the established deadlines for the various orders and strives to minimize the total cycle of production times and machine setup times. The authors present the assumptions of the model and its results concerning generation of the optimal production sequence for the analyzed products. The paper also comprises the analysis if it is reasonable to combine orders or separate them according to individual customer needs. © Springer International Publishing AG 2018.","Intelligent manufacturing systems; Lot size; Optimization problems; Scheduling algorithms","Genetic algorithms; Intelligent systems; Maintenance; Manufacture; Optimization; Production control; Scheduling algorithms; Electromechanical industry; Individual customers; Intelligent manufacturing system; Lot size; Lot sizing problems; Optimization approach; Optimization problems; Production schedule; Production",2-s2.0-85028594169
"Matla S., Subban R.","Objects detection and tracking strategies",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031433277&doi=10.1007%2f978-981-10-6614-6_17&partnerID=40&md5=12790f0517438ba57fbb431370c3e2f6","Object detection and tracking play a vital role in several applications like face detection, gait detection, vehicle detection and pose detection, and object recognition. The first step in the object detection algorithm is detecting the presence of any object in video images. The process of the object detection is accomplished using Hidden Markov Models, Support Vector Machines, Machine Learning Techniques, Pattern Recognition, Statistical Method, Scale Invariant Feature, structured visual dictionary (SVD), AdaBoost, Clustering Method, Bayesian Framework, Particle Filtering, Vector Quantization, and Feature Extraction, etc. This paper presents a comprehensive study and analysis on object detection and tracking techniques. © 2018, Springer Nature Singapore Pte Ltd.","AdaBoost; Machine learning techniques; Scale invariant feature; Statistical method; Support vector machines","Adaptive boosting; Artificial intelligence; Face recognition; Feature extraction; Gesture recognition; Hidden Markov models; Image processing; Learning algorithms; Learning systems; Markov processes; Object recognition; Pattern recognition; Statistical methods; Support vector machines; Bayesian frameworks; Clustering methods; Machine learning techniques; Object detection algorithms; Object detection and tracking; Particle Filtering; Scale invariant features; Visual dictionaries; Object detection",2-s2.0-85031433277
"Liang X., Zhao H., Huang J.","A real-time classification algorithm for multi-velocity measuring data",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028348162&doi=10.1007%2f978-981-10-4837-1_35&partnerID=40&md5=111adb73e72faf95232e9b08a489006d","This paper proposes a new real-time classification algorithm for multi-velocity measuring data under the response mode to improve the target trajectory stability. First, this paper analyses the defects of the existing method. Second, it designs a new classification algorithm which can classify the response data, the beacon data and the abnormal data. The key of the new algorithm is the selection of suitable classification references. The theoretical trajectory and the classified real measuring data at the historical moment are used as the classification references in different situations. Finally, validate the new algorithm with two kinds of typical real measuring data corresponding to two kinds of master stations configuration mode, the result shows that the algorithm can classify the three kinds of data correctly. On this basis, the real-time trajectory calculated is smooth and continuous and the data utilization is evidently increased. Therefore, the new classification algorithm of this paper is better than the existing method, which has guiding significance for improving the real-time data classification in different measuring systems. © Tsinghua University Press, Beijing and Springer Nature Singapore Pte Ltd. 2018.","Beacon data; Classification; Multi-velocity; Response data","Real time systems; Trajectories; Beacon data; Classification algorithm; Configuration modes; Guiding significances; Real-time trajectories; Response data; Theoretical trajectory; Velocity measuring; Classification (of information)",2-s2.0-85028348162
"Guedes J.J., Castoldi M.F., Goedtel A., Agulhari C.M., Sanches D.S.","Parameters estimation of three-phase induction motors using differential evolution",2018,"Electric Power Systems Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028727513&doi=10.1016%2fj.epsr.2017.08.033&partnerID=40&md5=9e703e2f4768569ac3116dc66a97a6c4","Three-phase induction motors are extensively used in the industry due to their robustness characteristics, low cost and easy maintenance. Usually, it is necessary to implement drive and control systems for such motors, which requires the knowledge of their mechanical and electrical parameters. However, in some cases, these data are not immediately available, or the values of the parameters may change due to the wear of motor components. Such problems can be circumvented if an efficient parameter estimation technique is available. In order to automatically estimate the parameters efficiently, the present work proposes a method, based on the differential evolution algorithm, aimed at the estimation of the electrical and mechanical parameters of three-phase induction motors. Such algorithm is capable of estimating the parameters of the equivalent electrical circuit, such as stator and rotor resistances and leakage inductances, the magnetizing inductance, and also mechanical parameters, such as moment of inertia and the friction coefficient. The performance of the proposed parameter estimation technique is evaluated for three different input signals: (i) current signal of a phase associated with the speed measured from a tachogenerator, (ii) current signal of a phase associated with the speed acquired from a torquemeter, and (iii) only the current signal of one phase. Finally, a series of simulated and experimental results are presented to validate the proposed technique, and the results show the good performance of the proposed strategies. © 2017 Elsevier B.V.","Differential evolution; Induction motor; Parameters estimation","AC motors; Digital storage; Electric machine control; Electric network parameters; Evolutionary algorithms; Friction; Inductance; Induction motors; Optimization; Differential Evolution; Differential evolution algorithms; Equivalent electrical circuits; Friction coefficients; Magnetizing inductance; Mechanical and electrical; Parameters estimation; Three phase induction motor; Parameter estimation",2-s2.0-85028727513
"Allahyari M.Z., Azab A.","Mathematical modeling and multi-start search simulated annealing for unequal-area facility layout problem",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028538602&doi=10.1016%2fj.eswa.2017.07.049&partnerID=40&md5=54ce817b66529b1ac4a5cee415922324","In this paper, a mixed integer nonlinear programming model (MINLP) is formulated to allocate the position of a number of unequal-area rectangular facilities within the continuum of a planar plant site with a predetermined fixed area. Facilities have predetermined dimensions and are not orientation-free. A continuous approach to the problem is taken. Constraints are developed to eliminate the possible overlap between the different facilities. The model accommodates for aisles, whether vertical or horizontal, as well as blocks and preference locations, where no facilities are allowed to be placed. The problem seeks to minimize total material handling the cost. Four test cases including one from the local industry is used to justify the developed model. The problem at hand is computationally intractable; hence, a novel Simulated Annealing (SA) algorithm is developed to solve large instances of the problem. A unique heuristic algorithm is used for initialization. A multi-start search mechanism is implemented to increase the diversity and mitigate the chances of getting entrapped in local optima. For validation, a group of benchmark problems is being used. © 2017 Elsevier Ltd","Facility layout problem; Heuristics; Mathematical modeling; Metaheuristics; Unequal-area facilities","Heuristic algorithms; Integer programming; Materials handling; Mathematical models; Nonlinear programming; Plant layout; Bench-mark problems; Continuous approach; Facility layout problems; Heuristics; Meta heuristics; Mixed integer nonlinear programming models; Simulated annealing algorithms; Unequal area facility layout problems; Simulated annealing",2-s2.0-85028538602
"Fissore F., Masiero A., Piragnolo M., Pirotti F., Guarnieri A., Vettore A.","Towards surveying with a smartphone",2018,"Lecture Notes in Geoinformation and Cartography",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028680487&doi=10.1007%2f978-3-319-56218-6_13&partnerID=40&md5=a84596888e9e35a95b4573198645ba91","Photogrammetry is one of the most used techniques for monitoring and surveying. It is widely used in several applications and in different working conditions. Accuracy of photogrammetry reconstruction methods may change depending on the working conditions (e.g. the number of acquired images, lighting conditions, baselines between images), and it is strictly related to the success of the solution of the Structure from Motion problem. Despite its widely spread use and the ever growing improvements to the reconstruction technique, photogrammetry still does not reach the same level of reliability of laser scanning surveying techniques: significant issues may occur in photogrammetric reconstructions when in presence of lighting problems or when the object of interest is not sufficiently textured. However, it relies on the use of much cheaper tools with respect to laser scanning techniques and surveying is usually much faster. This paper aims at showing the potential improvement that can be obtained by introducing information provided by the navigation system in the 3D reconstruction algorithm: the goal is that of making the solution algorithm of the Structure from Motion problem more reliable and accurate. As a side effect, faster reconstruction is typically achieved. The technique is validated on a building using images and navigation information got from a standard smartphone. © Springer International Publishing AG 2018.","Matching; Monitoring; Photogrammetry; SfM; Smartphone feature descriptor; Surveying","Environmental engineering; Geophysics; Global positioning system; Laser applications; Lighting; Monitoring; Navigation systems; Photogrammetry; Smartphones; Structural geology; Surface analysis; Surveying; Surveys; 3-D reconstruction algorithms; Feature descriptors; Matching; Navigation in formation; Reconstruction method; Reconstruction techniques; Solution algorithms; Structure from motion problems; Image reconstruction",2-s2.0-85028680487
"Gupta T., Yadav J., Chaudhary S., Agarwal U.","EMG pattern classification using neural networks",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032671274&doi=10.1007%2f978-3-319-68385-0_20&partnerID=40&md5=5c96573aaa713f35ca495529d07b1897","The functioning of electromyogram (EMG) driven prosthesis to control the performance of artificial prosthetic arms placed on people with missing limbs depends on the cumulative effect of multiple dynamic factors, some of which include electrode placement position, muscle contraction levels, forearm orientations, etc. However, the study of the combined influence of these dynamic factors has been limited and hence offered us scope to improve the accuracy of the previous studies. We used the data to extract multiple features through the Time Dependent Power Spectrum Descriptor (TD-PSD) algorithm, which has proven to be one of the best methods of feature extraction. Samples are classified using the Neural Pattern Recognition Toolbox with scaled conjugate gradient backpropagation as the training algorithm, which gives an improved accuracy over Support Vector Machine (SVM) classifier. Neural Network is trained using the EMG signals of 10 subjects performing multiple hand movements to achieve classification accuracy up to 94.7%. The results obtained are a testimony to the fact that the suggested method is competent to improve the operation of pattern recognition myoelectric signals. © Springer International Publishing AG 2018.","Classification; Clustering; Feature extraction; Pattern recognition","Backpropagation algorithms; Classification (of information); Electromyography; Extraction; Feature extraction; Intelligent systems; Pattern recognition; Prosthetics; Support vector machines; Classification accuracy; Clustering; Electrode placement; EMG pattern classification; Muscle contractions; Myoelectric signals; Scaled conjugate gradients; Training algorithms; Biomedical signal processing",2-s2.0-85032671274
"Meneses A.A.D.M., Araujo L.M., Nast F.N., da Silva P.V., Schirru R.","Application of metaheuristics to Loading Pattern Optimization problems based on the IAEA-3D and BIBLIS-2D data",2018,"Annals of Nuclear Energy",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029600054&doi=10.1016%2fj.anucene.2017.09.008&partnerID=40&md5=f89e653027a970c15be413a9fc4df189","The Loading Pattern Optimization (LPO) of a Nuclear Power Plant (NPP), or in-core fuel management optimization, is a real-world and prominent problem in Nuclear Engineering with the goal of finding an optimal (or near-optimal) Loading Pattern (LP), in terms of energy production, within adequate safety margins. Most of the reactor models used in the LPO problem are particular cases, such as research or power reactors with technical data that cannot be made available for several reasons, which makes the reproducibility of tests unattainable. In the present article we report the results of LPO of problems based upon reactor physics benchmarks. Since such data are well-known and widely available in the literature, it is possible to reproduce tests for comparison of techniques. We performed the LPO with the data of the benchmarks IAEA-3D and BIBLIS-2D. The Reactor Physics code RECNOD, which was used in previous works for the optimization of Angra 1 NPP in Brazil, was also used for further comparison. Four Optimization Metaheuristics (OMHs) were applied to those problems: Particle Swarm Optimization (PSO), Cross-Entropy algorithm (CE), Artificial Bee Colony (ABC) and Population-Based Incremental Learning (PBIL). For IAEA-3D, the best algorithm was the ABC. For BIBLIS-2D, PBIL was the best OMH. For Angra 1 / RECNOD optimization problem, PBIL, ABC and CE were the best OMHs. © 2017","Loading Pattern Optimization; Nuclear fuel; Nuclear Power Plant; Optimization Metaheuristics; Pressurized water reactor","Evolutionary algorithms; Heuristic algorithms; Nuclear energy; Nuclear fuels; Nuclear power plants; Particle swarm optimization (PSO); Pressurized water reactors; Artificial bee colonies (ABC); Energy productions; In-Core fuel Management optimizations; Loading patterns; Meta heuristics; Optimization problems; Population based incremental learning; Reproducibilities; Optimization",2-s2.0-85029600054
"Babichev D., Storchak M.","Quality characteristics of gearing",2018,"Mechanisms and Machine Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023612562&doi=10.1007%2f978-3-319-60399-5_4&partnerID=40&md5=9cd34adb1b4f38fbc58c66301276870d","Gears are the basis of most of the mechanics that drive machinery, ultimately determining their efficiency and durability. Selection of the parameters of gears is carried out by their quality characteristics. Analysis and synthesis of gears and machine engagements uses three types of quality characteristics: characteristic of gears, characteristic of machine engagements and universal characteristics. Each of these types is divided into local and global quality characteristics. The article suggests a classification of local and global quality characteristics, focused on a common approach to their calculation and display through computer analysis and synthesis of various gears. The developed system of primary characteristics is described, which is a set of simple local quality characteristics. These primary characteristics are invariant to the mechanism scheme and coordinate system used by analysis and synthesis of gears. Using these primary characteristics can calculate any of the considered local and global quality characteristics of the gears or the machine engagements. Analysis of the quality characteristics of synthesized full-strength gears is carried out. To conduct this analysis, a synthesis algorithm is developed. Using this calculation algorithm, the gears with constant tension along the engagement line are synthesized. The sensitivity of the synthesized gears to changes in the axle distance is analyzed. This analysis is carried out for gears with different gear ratios. The complex research is the basis for the development of interactive optimization synthesis of gears with the specified strength properties. © 2018, Springer International Publishing Switzerland.","Computer-aided engineering; Gear; Meshing zone; Quality characteristics; Synthesis","Computer aided engineering; Machinery; Optimization; Quality control; Synthesis (chemical); Analysis and synthesis; Calculation algorithms; Co-ordinate system; Computer analysis; Constant tensions; Interactive optimization; Quality characteristic; Synthesis algorithms; Gears",2-s2.0-85023612562
"Neydorf R., Aghajanyan A., Neydorf A., Vučinić D.","Monochrome multitone image approximation on lowered dimension palette with sub-optimization method based on genetic algorithm",2018,"Advanced Structured Materials",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024477113&doi=10.1007%2f978-3-319-59590-0_12&partnerID=40&md5=e51c41cf91bb8680469fc65328b2e6dd","The problem of sub-optimum approximation of monochrome multitone images (MMI) by a palette with reduced amount of tones, called support palette (SP), is solved. The SP palette tones are defined with the images analysis, which arise in related scientific topics as: technical sight, recognition of images, etc. In this work the research objective was to assess the opportunity of using efficiently such analysis, by applying the genetic algorithms (GA) for sub-optimum approximation of MMI, considering the original big size tones palette [1]. The proposed approximation consists in replacing the original MMI pixels with the approximated pixels from a smaller size tone palette. This procedure is of importance in the synthetic vision approach, where image recognition procedures are expected to define the main contours within the image. The developed method reduces the amount of tones used to display an image, whose approximation approach is presented in this paper. In order to solve it, two alternative problems are considered: (1) minimization of losses in such image transformation, and (2) minimization of the SP size (for example, to simplify the image recognition process). The approximated MMI quality is defined as the mean square deviation of pixels brightness (original to approximated). The chromosome in GA is SP, where tones are represented as genes. Such approximations are resulting from the mutational variation of the MMI palette tones, within gene alleles, which are formed by applying the original palette tones. The palette is iteratively changing from generation to generation, where the reduction of the stop risks is done on the local extremum. This fact increases the available search opportunities, as provided by the multi-point crossing-over algorithm, whose parameters are able to mutate during such an evolution process. In addition, to demonstrate the result of this work, an appropriate software has been developed, having an easy-to-use user interface, enabling to show the highly efficient processing of the investigated algorithm. The presented solutions are validated with photo examples of several technical objects, on which the sub-optimum method has been applied. © 2018, Springer International Publishing AG.","Chromosome; Gen; Genetic algorithm; Image approximation; Monochrome image; Optimization",,2-s2.0-85024477113
"Srivastava J.R., Sudarshan T.S.B.","Energy efficient cache node placement using genetic algorithm with probabilistic delta consistency using flexible combination of push and pull algorithm for wireless sensor networks",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029480251&doi=10.1007%2f978-3-319-62521-8_13&partnerID=40&md5=0c3a0d5d967fb20e7be6ae4aa63779d9","Minimum energy consumption and minimum service delay with maximizing quality of service is key to a worthy WSN. Network lifetime and network connectivity lead to optimization. However, to handle the uncertainties present in WSNs, we need powerful heuristics to solve the optimization problem. A possible way to minimize power consumption is by the use of caching popular data by optimally selecting and placing cache nodes in the network. We propose the use of a powerful searching tool and a well-known soft computing technique; a multi-objective genetic algorithm to achieve optimization goals in the presented work. The proposed work proceeds in two steps to give a complete optimized network system with increased network lifetime. In the first step we use genetic algorithm to carefully select and place cache nodes in the network with aims of maximizing field coverage and minimizing network energy usage. In the second step we perform cache consistency on the cache nodes for valid data retrieval. We use the Probabilistic Delta Consistency (PDC) with Flexible Combination of Push and Pull (FCPP) algorithm. The cache consistency algorithm is implemented on the MAC layer and comparisons are made with 802.11 MAC layer without cache consistency using metrics; routing load, packet delivery ratio, end-to-end delay, normalized load and energy consumed. The network overhead is reduced considerably leading to speedy data access. The algorithm is designed for a clustered environment and is an extension of our previous work where we have successfully proved that genetic algorithm gives better results for node deployment when compared to the state of the art node placement algorithm ScaPCICC. The results are obtained by running the experiments on Matlab and ns2. © 2018, Springer International Publishing AG.","Cache consistency; Clustering; Genetic algorithm; Optimization; Wireless Sensor Network",,2-s2.0-85029480251
"Jaddi N.S., Abdullah S.","Optimization of neural network using kidney-inspired algorithm with control of filtration rate and chaotic map for real-world rainfall forecasting",2018,"Engineering Applications of Artificial Intelligence",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032707160&doi=10.1016%2fj.engappai.2017.09.012&partnerID=40&md5=ddde26139dc95da8143d136619276f24","A broad variety of real-world problems have been solved using multilayer perceptron (MLP) artificial neural networks (ANNs). Optimization techniques aid ANNs to select suitable weights and achieve correct results. Recently, the kidney-inspired algorithm (KA) has been proposed for optimization problems. This algorithm is based on the filtration, reabsorption, secretion, and excretion processes that take place in the kidneys of the human body. In the KA, the value of α in the filtration rate formula is a constant value in the range of [0, 1] that is set in the initialization stage of the algorithm. In this paper, an improved KA for optimization of the ANN model is presented in which the filtration rate is controlled by changing the value of α from minimum to maximum during the search process, which helps in achieving a better balance between exploration and exploitation in the algorithm. In this algorithm if more solutes are filtered and moved to filtered blood it means that the algorithm has more exploration. In contrast, if more solutes move to waste it means that more exploitation is performed by the algorithm. In addition, the separate use of three chaotic maps instead of a random number in the movement formula of the modified KA is investigated in order to assess the ability of each map to help to achieve superior results. The proposed method is tested on benchmark classification and time series prediction problems. The method is also applied to a real-world rainfall forecasting problem. The results of a statistical analysis prove the ability of the method. © 2017 Elsevier Ltd","Artificial neural network; Chaotic map; Classification; Filtration rate control; Kidney-inspired algorithm; Real-world rainfall forecasting; Time series prediction","Chaotic systems; Classification (of information); Forecasting; Multilayer neural networks; Neural networks; Physiology; Rain; Time series; Weather forecasting; Benchmark classification; Chaotic map; Exploration and exploitation; Filtration rates; Multi layer perceptron; Optimization techniques; Rainfall forecasting; Time series prediction; Optimization",2-s2.0-85032707160
"Li L., Meng W.","A novel bitwise factor graph belief propagation detection algorithm for massive MIMO system",2018,"Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031305698&doi=10.1007%2f978-3-319-66625-9_44&partnerID=40&md5=2363e2dceb5824eeb26bb787612e954c","As a low computational complexity detection algorithm for Massive Multi-Input-Multi-Output (MIMO) system, the well known factor graph belief propagation (BP) detection algorithm is effective for binary phase shift keying (BPSK) signal, but not appropriate for quadrature amplitude modulation (QAM) signal. In this paper, the complex transmitted signal vector modulated by QAM is transformed into the real valued bitwise vector which can be viewed as a transmitting signal vector modulated by BPSK. With the real valued bitwise vector and transformed channel gain matrix, an improved bitwise factor graph (BFG) graphic model is developed, and a BFG-BP algorithm is proposed to detect QAM signals in Massive MIMO system. Over a finite time of polynomial computational complexity of O(NT) per symbol, where NT denotes the number of transmitted antennas, the proposed BFG-BP detection algorithm obtains the approximate optimum BER performance of maximum likelihood detection algorithm with rapid convergence rate, and also achieves the theoretical spectral efficiency at medium high average received signal-to-noise ratio. Simulation results prove the effeteness of the proposed BFG-BP for detecting QAM signals in Massive MIMO system. © 2018, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.","Belief propagation; Bit error rate (BER); Bitwise factor graph; Computational complexity; Detection algorithm; Massive MIMO","Amplitude shift keying; Backpropagation; Binary phase shift keying; Bit error rate; Computational complexity; Computational efficiency; Error statistics; Maximum likelihood; MIMO systems; Signal detection; Signal to noise ratio; Vectors; Belief propagation; Binary phase-shift keying signals; Detection algorithm; Factor graphs; Low computational complexity; Maximum likelihood detection; Multi-input multi-output system; Quadrature amplitude modulation signals; Quadrature amplitude modulation",2-s2.0-85031305698
"Dembrani M.B., Khanchandani K.B., Zurani A.","Extraction of FECG signal based on blind source separation using principal component analysis",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026752208&doi=10.1007%2f978-981-10-3373-5_17&partnerID=40&md5=d80b665e59f717661a6d0132cd78bf3c","Fetal electrocardiogram (FECG) gives faithful medical information of heartbeat rate of the fetal living. Extraction of FECG from abdomen of maternal woman consists of interferences and motion artifacts and noises. Maternal electrocardiogram (MECG) is a main source of interference signal present in FECG. This paper focuses on FECG extraction from blind adaptive filtering using principal component analysis (PCA). The abdominal ECG (AECG) is obtained by blind adaptive algorithm which consists of MECG and FECG QRS complex. Principal component analysis separates the two MECG and FECG. The experiments show that it can simultaneously accomplish maternal ECG and fetal QRS complexes enhancement for their detection. The simulation results show that FECG extracted from the peaks of R-R interval is noise-free signal, and extract FHR. © Springer Nature Singapore Pte Ltd. 2018.","Blind source separation (BSS); FECG extraction; MECG; Principal component analysis (PCA)","Adaptive algorithms; Adaptive filtering; Adaptive filters; Biomedical signal processing; Blind source separation; Computation theory; Electrocardiography; Extraction; Intelligent computing; Signal processing; Blind adaptive algorithms; Fetal electrocardiograms; Heart beat rates; Interference signal; MECG; Medical information; Motion artifact; Noise free signals; Principal component analysis",2-s2.0-85026752208
"Toivonen T., Jormanainen I., Tukiainen M.","An open robotics environment motivates students to learn the key concepts of artificial neural networks and reinforcement learning",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029412197&doi=10.1007%2f978-3-319-62875-2_29&partnerID=40&md5=0b990e960a491bc9cfb91e7cc3096e58","Educational robotics is a widely recognized tool to motivate students and concretize abstract and complex topics, such as artificial intelligence in computing education curricula. Lego Mindstorms series is one of the most popular robotics platform due to its flexibility and relatively cheap price. We used Lego Mindstorms EV3 robots with a novel Open Learning Environment for Artificial Intelligence (OLE-AI) to teach concepts of reinforcement learning and artificial neural networks (ANNs) to computer science students. OLE-AI uses a white box approach to expose internal structures of an ANN to students. Results from the pilot study with OLE-AI indicate that the participating students were able to deepend their knowledge about AI topics through a practical and open exercise that involved them in controlling EV3 robots by manipulating the ANN and Q-Learning algorithm. © 2018, Springer International Publishing AG.","Artifical neural networks; Educational robots; EV3 robots; Q-Learning; Reinforcement learning","Artificial intelligence; Computer aided instruction; Educational robots; Intelligent robots; Learning algorithms; Neural networks; Reinforcement learning; Robotics; Robots; Students; Artifical neural networks; Computer science students; Computing education; Educational robotics; Internal structure; Q-learning; Q-learning algorithms; Robotics platforms; Education",2-s2.0-85029412197
"Korman M., Poon S.-H., Roeloffzen M.","Line segment covering of cells in arrangements",2018,"Information Processing Letters",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029437579&doi=10.1016%2fj.ipl.2017.09.002&partnerID=40&md5=c715d4b35745cb29d3defa1ec145c60e","Given a collection L of line segments, we consider its arrangement and study the problem of covering all cells with line segments of L. That is, we want to find a minimum-size set L′ of line segments such that every cell in the arrangement has a line from L′ defining its boundary. We show that the problem is NP-hard, even when all segments are axis-aligned. In fact, the problem is still NP-hard when we only need to cover rectangular cells of the arrangement. For the latter problem we also show that it is fixed parameter tractable with respect to the size of the optimal solution. Finally we provide a linear time algorithm for the case where cells of the arrangement are created by recursively subdividing a rectangle using horizontal and vertical cutting segments. © 2017 Elsevier B.V.","Computational geometry; FPT; Geometric graph; NP-hardness; Vertex cover","Clustering algorithms; Computational geometry; Cytology; Geometric graphs; Line segment; Linear-time algorithms; NP-hard; NP-hardness; Optimal solutions; Vertex cover; Cells",2-s2.0-85029437579
"Enokido T., Duolikun D., Takizawa M.","Energy-efficient quorum selection algorithm for distributed object-based systems",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026309506&doi=10.1007%2f978-3-319-61566-0_4&partnerID=40&md5=c216f51995e50c9e4a5000e80a09ce80","Distributed applications are composed of multiple objects and each object is replicated in order to increase reliability, availability, and performance. On the other hand, the larger amount of electric energy is consumed in a system since multiple replicas of each object are manipulated on multiple servers. In this paper, the energy efficient quorum selection (EEQS) algorithm is proposed to construct a quorum for each method issued by a transaction in the quorum based locking protocol so that the total electric energy consumption of servers to perform methods can be reduced. We show the total energy consumption of servers, the average execution time of each transaction, and the number of aborted transactions can be reduced in the EEQS algorithm compared with the random algorithm in the evaluation. © Springer International Publishing AG 2018.","Data management; EEQS algorithm; Energy-aware information systems; Object-based systems; Quorum-based locking protocol","Energy utilization; Information management; Locks (fasteners); Average Execution Time; Distributed applications; Distributed objects; Electric energy consumption; Energy aware; Locking protocols; Object-based systems; Total energy consumption; Energy efficiency",2-s2.0-85026309506
"Novakovic J., Veljovic A., Ilic S.S., Veljovic V.","Improving the accuracy of SVM algorithm in classification problems with PCA method",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031427093&doi=10.1007%2f978-3-319-68321-8_7&partnerID=40&md5=fa79201797cbf8f2dda29501379e63bd","This paper investigates the use of SVM algorithm with PCA method in classification, which is one of the most common task of machine learning. Classification is the problem of identifying to which of a set of categories a new observation belongs, on the basis of a training set of data containing observations (or instances) whose category membership is known. SVM algorithm can produce accurate and robust classification results on a sound theoretical basis, even when input data are non-monotone and non-linearly separable. So they can help to evaluate more relevant information in a convenient way. PCA method reduces the dimensionality and the maximum number of new variables that can be obtained is equal to the original, with new variables are not correlated with each other. Experimental studies have shown that it is possible to improve the accuracy of SVM classification algorithm using PCA method. © Springer International Publishing AG 2018.","Classification problem; Dimensionality reduction; PCA; SVM","Learning systems; Dimensionality reduction; Input datas; Linearly separable; PCA method; Robust classification; SVM algorithm; SVM classification; Training sets; Classification (of information)",2-s2.0-85031427093
"Liu F., Yang H., Lv G.","Dual color image blind watermarking algorithm based on compressive sensing",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031417177&doi=10.1007%2f978-981-10-6499-9_5&partnerID=40&md5=c9dac9f9857df5057b43201336d0d89c","As a new information processing theory, Compressive Sensing (CS) should be further researched on the applications of digital watermarking. This paper presents a novel blind digital watermarking scheme embedding a color watermark into a color host image. By using Compressive Sensing theory, Gaussian random matrix is carried out to observe the sparse image and watermark is embedded in compressed observation domain. Finally a smooth norm algorithm is used to reconstruct watermarked image. The watermark extraction process is the blind extraction. The experimental results indicate that the algorithm meets the requirements of the watermark invisibility, robustness and security. © 2018, Springer Nature Singapore Pte Ltd.","Blind extraction; Compressive sensing; Digital watermarking; Information hiding","Color; Compressed sensing; Digital watermarking; Extraction; Intelligent systems; Blind digital watermarking; Blind extraction; Blind watermarking algorithm; Compressive sensing; Gaussian random matrices; Information hiding; Information processing theories; Watermark extraction process; Image watermarking",2-s2.0-85031417177
"El Aziz M.A., Ewees A.A., Hassanien A.E., Mudhsh M., Xiong S.","Multi-objective whale optimization algorithm for multilevel thresholding segmentation",2018,"Studies in Computational Intelligence",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032000437&doi=10.1007%2f978-3-319-63754-9_2&partnerID=40&md5=b37d3c611e3024aac5def573e453c800","This chapter proposes a new method for determining the multilevel thresholding values for image segmentation. The proposed method considers the multilevel threshold as multi-objective function problem and used the whale optimization algorithm (WOA) to solve this problem. The fitness functions which used are the maximum between class variance criterion (Otsu) and the Kapur’s Entropy. The proposed method uses the whale algorithm to optimize threshold, and then uses this thresholding value to split the image. The experimental results showed the better performance of the proposed method to solving the multilevel thresholding problem for image segmentation and provided faster convergence with a relatively lower processing time. © Springer International Publishing AG 2018.","Image segmentation; Multi-objective; Multilevel thresholding; Swarms optimization; Whale optimization algorithm",,2-s2.0-85032000437
"Antonič R., Ondroušek V.","Counting pedestrians in inner spaces using optical flow algorithm",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029221202&doi=10.1007%2f978-3-319-65960-2_72&partnerID=40&md5=bea19a5da54a4225cd8e0f0d30e5815a","Main aim of this paper is to design an algorithm that is able to count number of incomings and outgoings from the selected room in the building using video stream analysis. Designed solution is based on optical flow algorithm in combination with the Hungarian method and Kalman filter for predicting positions of pedestrians in some specific situations. Number of incomings and outgoings are computed during the analysis of the resulting trajectories. Proposed solution is verified using various datasets obtained from common overhead surveillance cameras. © 2018, Springer International Publishing AG.","Image processing; Kalman filter; Pedestrians counting; TV-L1","Combinatorial optimization; Image processing; Optical data processing; Optical flows; Security systems; Video streaming; Hungarian method; Optical flow algorithm; Pedestrians counting; Surveillance cameras; Kalman filters",2-s2.0-85029221202
"Liu Z.-L., Ma Y., Yuan S.-Z., Zhou Z.-C.","The path tracking control method based on los algorithm for surface self-propelled model",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031405744&doi=10.1007%2f978-981-10-6499-9_45&partnerID=40&md5=b4e128cbbed95a44a5a7dc3af82afe25","Aiming at the surface self-propulsion model system, the paper design a path tracking control method based on the LOS (Line of sight) algorithm to achieve automatic path tracking control purposes. The algorithm uses a simple principle to obtain the desired heading angle, and through the PID control, which makes the ship closer to the expected course, finally sailing at heading, complete path tracking control. Simulation and experiment results for a Surface Self-Propulsion Vessel are provided to validate our method. © 2018, Springer Nature Singapore Pte Ltd.","LOS algorithm; Path tracking control; Surface self-propelled model","Intelligent systems; Propulsion; Ship propulsion; Three term control systems; Heading angles; Line of Sight; Path tracking control; Self propulsion; Navigation",2-s2.0-85031405744
"Zhao F., Liu H., Zhang Y., Ma W., Zhang C.","A discrete Water Wave Optimization algorithm for no-wait flow shop scheduling problem",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029411091&doi=10.1016%2fj.eswa.2017.09.028&partnerID=40&md5=379f88bec640e12c09e85c708fbc320e","In this paper, a discrete Water Wave Optimization algorithm (DWWO) is proposed to solve the no-wait flowshop scheduling problem (NWFSP) with respect to the makespan criterion. Inspired by the shallow water wave theory, the original Water Wave Optimization (WWO) is constructed for global optimization problems with propagation, refraction and breaking operators. The operators to adapt to the combinatorial optimization problems are redefined. A dynamic iterated greedy algorithm with a changing removing size is employed as the propagation operator to enhance the exploration ability. In refraction operator, a crossover strategy is employed by DWWO to avoid the algorithm falling into local optima. To improve the exploitation ability of local search, an insertion-based local search scheme which is utilized as breaking operator, is applied to search for a better solution around the current optimal solution. A ruling out inferior solution operator is also introduced to improve the convergence speed. The global convergence performance of the DWWO is analyzed with the Markov model. In addition, the computational results based on well-known benchmarks and statistical performance comparisons are presented. Experimental results demonstrate the effectiveness and efficiency of the proposed DWWO algorithm for solving NWFSP. © 2017 Elsevier Ltd","Iterated greedy algorithm; Makespan; No-wait flow shop scheduling problem; Water Wave Optimization (WWO)","Benchmarking; Combinatorial optimization; Computation theory; Global optimization; Local search (optimization); Machine shop practice; Markov processes; Refraction; Scheduling; Water waves; Combinatorial optimization problems; Effectiveness and efficiencies; Global optimization problems; Iterated greedy algorithm; Makespan; No-wait flow-shop scheduling; Shallow water wave theories; Statistical performance; Optimization",2-s2.0-85029411091
"Nazeer W., Munir M., Kang S.M., Kausar S.","Strong convergence theorems of non-convex hybrid algorithm for quasi-Lipschitz mappings",2018,"Journal of Computational Analysis and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027313553&partnerID=40&md5=3a5fa4d51444b17aca44fa642190c375","The aim of this paper is to introduce a new non-convex hybrid algorithm for a family of countable quasi-Lipschitz mappings. We establish strong convergence theorems of common fixed points for a uniformly closed asymptotically family of countable quasi-Lipschitz mappings in a Hilbert space. © 2018 by Eudoxus Press, LLC. All rights reserved.","Asmptotically quasi-nonexpansive mapping; Hybrid algorithm; Nonexpansive mapping; Quasi-Lipschitz mapping; Quasi-nonexpansive mapping",,2-s2.0-85027313553
"Belevičius R., Juozapaitis A., Rusakevičius D.","Parameter study on weight minimization of network arch bridges",2018,"Periodica Polytechnica Civil Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032665121&doi=10.3311%2fPPci.10036&partnerID=40&md5=073afbf14384589e0649b8ab66a63c61","The article concerns optimization of network arch bridges. This is challenging optimization problem involving even for conventional scheme of network arch bridge the identification of some topological parameters as well as shape configurations and all sizing parameters of structural members, seeking the minimum weight. Optimal bridge scheme is sought tuning a large set of design parameters of diverse character: the type of hanger arrangement, the number of hangers, their inclination angles and placement distances, the arch shape and rise, etc. Mathematically, the optimization of the bridge scheme is a mixed-integer constrained global optimization problem solved employing stochastic evolutionary algorithm. Plane heavy/ moderate/and light-deck bridges of 18, 30, 42 and 54 m spans were optimized using proposed optimization technique. The decisive design parameters and their promising ranges were revealed. Also, the influence of some simplifications is shown: changing the arch shape from elliptical to circular, placing the hangers at equal distances, etc. © 2017, Budapest University of Technology and Economics. All rights reserved.","Network arch bridge; Shape and sizing parameters; Topology; Weight minimization","Arch bridges; Arches; Constrained optimization; Evolutionary algorithms; Global optimization; Integer programming; Optimization; Parameter estimation; Stochastic systems; Topology; Constrained global optimization; Network arch bridges; Optimization of network; Optimization techniques; Shape and sizing parameters; Stochastic evolutionary algorithms; Topological parameters; Weight minimization; Shape optimization",2-s2.0-85032665121
"Robak S., Gryszpanowicz K.","Comprehensive dimensioning of series braking resistor for transient stability improvement",2018,"Electric Power Systems Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027993226&doi=10.1016%2fj.epsr.2017.08.005&partnerID=40&md5=0d5238b6c78d7c8ee6f6a1f8b2a42c0a","This paper addresses comprehensive dimensioning of series braking resistors designed to improve transient stability of the power system. Since dynamic braking is one of the most cost-effective ways to improve transient stability, the applications of shunt and series braking resistors have recently expanded in the power industry. To find an effective algorithm for controlling series braking resistors appropriate resistor dimensioning should be performed first. This paper addresses the problem of dimensioning of series braking resistors. To solve that problem a mathematical model is employed for different operating states of the system equipped with a series braking resistor. This paper describes and discusses in detail the impact of series braking resistors on: power angle characteristics, intensity of dynamic braking in terms of transient stability improvement, voltage dynamic response during and after a fault, and turbo-generator shaft fatigue. Based on the analysis performed, criteria for the dimensioning of series braking resistors are formulated. Theoretical considerations are supported by simulation tests for nonlinear models of single-machine as well as multi-machine test systems. © 2017 Elsevier B.V.","Power system stability; Resistor dimensioning; Series braking resistor; Special protection systems; Stability improvement","Cost effectiveness; Electric equipment protection; Resistors; Scheduling algorithms; System stability; Turbogenerators; Braking resistor; Effective algorithms; Non-linear model; Power system stability; Simulation tests; Special protection system; Stability improvement; Transient stability improvement; Electric power system protection",2-s2.0-85027993226
"Eustáquio F., Camargo H., Rezende S., Nogueira T.","On fuzzy cluster validity indexes for high dimensional feature space",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029415048&doi=10.1007%2f978-3-319-66824-6_2&partnerID=40&md5=e5d601a872f1d76b5154776e9be26ff2","Fuzzy document clustering aims at automatically organizing related documents into clusters in a flexible way. At this context, the topics identification addressed by documents in every cluster is performed by automatically discovering cluster descriptors, which are relevant terms present in these documents. Since documents are represented by a high-dimensional feature space, the extraction of good descriptors is a big problem to be solved. This problem is even bigger using fuzzy clustering, since the same descriptor can be representative for more than one cluster. Moreover, it is well-known that the Fuzzy C-Means clustering algorithm is also affected by documents dimensionality and the choice of correct partition of a given document collection into clusters is still a challenging problem. In order to overcome this drawback, we have investigated the most common fuzzy clustering validity indexes to validate the organization of data with high dimensional feature space, since they are commonly used to evaluate fuzzy clusters from low dimensional data sets. © 2018, Springer International Publishing AG.","Documents; Flexible organization; Fuzzy clustering; Text mining; Validity indexes","Clustering algorithms; Data mining; Fuzzy clustering; Fuzzy sets; Pattern matching; Document Clustering; Documents; Fuzzy c-means clustering algorithms; High-dimensional feature space; Organization of datum; Text mining; Topics identifications; Validity index; Fuzzy logic",2-s2.0-85029415048
"Hemmati-Sarapardeh A., Varamesh A., Husein M.M., Karan K.","On the evaluation of the viscosity of nanofluid systems: Modeling and data assessment",2018,"Renewable and Sustainable Energy Reviews",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026781355&doi=10.1016%2fj.rser.2017.07.049&partnerID=40&md5=3da76426cd75adaa272ed5c98f51ac33","Viscosity of nanofluids can significantly affect pumping power, pressure drop, workability of the nanofluid as well as its convective heat transfer coefficient. Experimental measurements of this property for different nanoparticles and base fluids at various temperatures is cumbersome and expensive. In this communication, a comprehensive review of the most important modeling works on viscosity of nanofluids including theoretical models, empirical correlations, and computer-aided models is conducted. Next, four multilayer perceptron (MLP) models optimized with Levenberg-Marquardt (LM), Bayesian Regularization (BR), Scaled conjugate gradient (SCG), and Resilient Backpropagation (RB), two radial basis function (RBF) neural network models optimized with Genetic Algorithm (GA) and Particle Swarm Optimization (PSO), and one least square support vector machine (LSSVM) model optimized with coupled simulated annealing (CSA) were developed for the prediction of nanofluid viscosity based on 3144 data points. These data sets include 42 nanofluid systems under a wide range of operating conditions; including temperature from −35 to 80 °C, particle volume fraction from 0% to 10%, nanoparticle size from 4.6 to 190 nm, and viscosity of base fluid from 0.24 to 452.6 cP. Then, these seven models were combined in a single model using a committee machine intelligent system (CMIS). The proposed CMIS predicts all of the data with excellent accuracy with an average absolute relative error of less than 4%. Furthermore, the developed model was compared with five theoretical models and four empirical correlations through statistical and graphical error analyses. The results demonstrate that the proposed CMIS model significantly outperforms all of the existing models and correlations in terms of accuracy and range of validity. Finally, the quality of the experimental data was examined both graphically and statistically and the results suggested good reliability of the experimental data. © 2017","Committee machine intelligent system; LSSVM; MLP; Nanofluid; RBF; Viscosity","Backpropagation algorithms; Genetic algorithms; Heat convection; Heat transfer; Heat transfer coefficients; Intelligent systems; Nanoparticles; Particle swarm optimization (PSO); Radial basis function networks; Simulated annealing; Support vector machines; Viscosity; Committee machines; Convective heat transfer Coefficient; Least square support vector machines; LSSVM; Nanofluids; Particle volume fractions; Radial basis function neural networks; Scaled conjugate gradients; Nanofluidics",2-s2.0-85026781355
"Neydorf R., Yarakhmedov O., Polyakh V., Chernogorov I., Vucinic D.","Robot path planning based on ant colony optimization algorithm for environments with obstacles",2018,"Advanced Structured Materials",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024491461&doi=10.1007%2f978-3-319-59590-0_14&partnerID=40&md5=945c6f0e04bcb687500010300fd14e7d","In modern industrial processes, robotic equipment is widely used, and one of the most pressing problems is to have to have navigation available for mobile robots. In this paper, the ant algorithm for laying and optimizing the robots paths in 2-dimensional environments with obstacles, is described and shown on construction site examples. The most important requirement is to be able to plan the shortest or permissible robot navigation route in such a complex environment with obstacles. It is well known that one of the most effective solutions to resolve such optimization problems of route seals is provided by the ant colony optimization (ACO) algorithm. The exploratory nature of the ant colony behaviour requires a classical partition of the search space, which is incomparably smaller, when compared to the obstacles fragments, as considered within this paper. The ant’s agents use the traditional logic of selecting the transition from fragment to fragment: the memory of the most popular routes based on pheromone are investigated, and formulated within the task elements, adopting appropriate tactics and situational awareness, and based on the random decisions. In addition, the new elements of the decision-making tactics are formulated for each task. For example, “feeling” of targeted routes by laying points is added to the algorithm. The natural analogue of this mechanism is similar to sensing the odors by the mustaches of real ants. The special software tool “Path Planning Optimization with Obstacle Avoidances by Ant Algorithm” is designed as the research test bed. A comprehensive study of the proposed algorithm, which shows superior performance, is done by utilizing the developed software. The examples, of the construction site with different complexity, are provided to explain the finding of the suboptimal routes for the specially designed test tracks, with defined obstacles in the simulated construction site landscape. The analysis of the results confirms the relevance and effectiveness of the developed software, which is based on the ant algorithm for the robot path planning, and validated for the environments containing complex obstacles. © 2018, Springer International Publishing AG.","Ant colony algorithm; Group behavior; Mathematical model; Obstacle; Optimization; Pheromone; Route",,2-s2.0-85024491461
"Su W.Y., Guo L.Y., Yen C.W., Wu L.I.","Validation study for novel designed tri-axis force plate and development of algorithm for decomposing ground reaction force on a single force plate",2018,"IFMBE Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030867583&doi=10.1007%2f978-981-10-4361-1_54&partnerID=40&md5=ca74dda1f7ba327033fe97e91accad3f","This developed an algorithm to solve the footstep targeting problem by gait analysis of the novel force plate. Using the force plate and the novel force plate to measure 11 healthy participants, and each subject was required to perform three times of counter movement jumps (CMJ), and walks without footstep targeting on two force platforms. First of all, the data of Ground Reaction Force (GRF) from Counter Movement Jump (CMJ) performance would be collected, and be calculated the parameter, including body weight, flight time, and the peak value of the vertical component to validate the novel tri-axis force plate. Second, in the algorithm development, vertical GRF measure and vertical GRF computed during normal gait analysis from the motion force plate were compared with each other, and the algorithm was used to calculate the decompose force when stepping on the novel force plate. Finally, the decomposed force with the corresponding measure with motion would be verified. It was analyzed by Spearman rank correlation coefficient, and the results were: body weight (R = 0.99, p < 0.01), flight time(R = 0.92, p < 0.01), and peak value of the vertical ground reaction force (R = 0.91, p < 0.01). Additionally, the mean relative error between the vertical GRF and the corresponding was 6.77 ± 7.49%. Therefore, the decomposed vertical GRF of both force plate and novel force plate were compared and that disclosed the algorithm of decomposed the vertical GRF. At compared the cross correlation coefficients with decomposed GRF on novel force plate by algorithm and measured on motion lab, the result showed that the right footstep variations of cross correlation coefficients was 0.98 and left footstep was 0.99, so In this study, the novel force plate indeed has high validity representation by the experiments examine, and the algorithm to decompose the vertical ground reaction forces was validated when subjects stepping on the single novel force plate. It try to solve the “Targetting Step”. © Springer Nature Singapore Pte Ltd. 2018.","Counter movement jumps; Decompose; Gait analysis; Ground reaction force; Novel force plate","Anthropometry; Biomedical engineering; Biophysics; Algorithm development; Corresponding measures; Counter movement jumps; Cross-correlation coefficient; Decompose; Force plate; Ground reaction forces; Spearman rank correlation; Gait analysis",2-s2.0-85030867583
"Tayachi D.","Solving the P/Prec, pj,Cij/Cmax using an evolutionary algorithm",2018,"Operations Research/ Computer Science Interfaces Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032645378&doi=10.1007%2f978-3-319-58253-5_22&partnerID=40&md5=00559577a96731fedc4c6d93f4122d22","In this chapter, we tackle the problem of scheduling a set of related tasks on a set of identical processors taking into account the communication delays with the objective of minimizing the maximal completion time. This problem is well known as NP-Hard. As Particle swarm optimization PSO is a promising approach for solving NP-complete problems due to its simple implementation, fast convergence and its few parameters to adjust, the main contribution of this research is to use for the first time PSO to solve the multiprocessor scheduling problem with communication delays. The proposed approach HEA-LS is a hybrid algorithm involving particle swarm optimization PSO and local search algorithm LS. Experiments conducted on several benchmarks known in the literature prove the effectiveness of our approach and show that it compares very well to the state of the art methods. © Springer International Publishing AG 2018.","Communication delays; Evolutionary algorithm; Hybridizing; Local search; Particle swarm; Scheduling",,2-s2.0-85032645378
"Ozkan O., Ermis M., Bekmezci I.","Hybridization of branch and bound algorithm with metaheuristics for designing reliable wireless multimedia sensor network",2018,"Operations Research/ Computer Science Interfaces Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032617868&doi=10.1007%2f978-3-319-58253-5_11&partnerID=40&md5=b647945aae74d006476a95f5537e017c","Reliability is a key topic for Wireless Multimedia Sensor Networks (WMSNs) design which involves connectivity and coverage issues with node placement. The main contribution of this chapter is to deploy sensor nodes to maximize the WMSN reliability under a given budget constraint by considering terrain and device specifications. The reliable WMSN design with deployment, connectivity and coverage has NP-hard complexity, therefore a new hybridization of an exact algorithm with metaheuristics is proposed. A Branch&Bound (B&B) approach is embedded into Hybrid Simulated Annealing (HSA) and Hybrid Genetic Algorithm (HGA) to orient the cameras exactly. Since the complexity of the network reliability problem is NP-complete, a Monte Carlo (MC) simulation is used to estimate the network reliability. Experimental study is done on synthetically generated terrains with different scenarios. The results show that HGA outperforms the other approaches especially in large-sized sets. © Springer International Publishing AG 2018.","Branch and bound; Genetic algorithm; Hybrid metaheuristics; Network reliability; Reliable network design; Simulated annealing; Wireless multimedia sensor network",,2-s2.0-85032617868
"Wodzinski M., Skalski A., Kedzierawski P., Kuszewski T., Ciepiela I.","Usage of ICP algorithm for initial alignment in B-splines FFD image registration in breast cancer radiotherapy planning",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028700053&doi=10.1007%2f978-3-319-66905-2_12&partnerID=40&md5=c1a0c17e6b938e06c6bd89f0af080d13","Estimation of a resected tumor lodge localization after a breast cancer surgery is a demanding task for the radiotherapy planning. The image registration techniques can be used to improve the radiotherapy. The initial alignment of two volumes is an important aspect of medical image registration procedure. We propose usage of the iterative closest point in two different scenarios: as a initial alignment, replacing intensity based rigid registration and as a initial transform to speed-up traditional rigid registration process. Two versions of the algorithm are presented: a point matching between bone structures and a line matching between volume edges. The correctness and usefulness are evaluated using: a target registration error, comparison of the computation time and convergence ratios, and visual inspection. The results demonstrate that the usage of iterative closest point algorithm significantly improve the initial alignment process in terms of the computation time. © 2018, Springer International Publishing AG.","Breast cancer; FFD; ICP; Image registration; Radiotherapy","Alignment; Biocybernetics; Biomedical engineering; Biophysics; Diseases; Iterative methods; Medical imaging; Radiotherapy; Breast Cancer; Image registration techniques; Initial alignment; Iterative closest point algorithm; Iterative Closest Points; Radiotherapy planning; Rigid registration; Target registration errors; Image registration",2-s2.0-85028700053
"Neydorf R., Polyakh V., Chernogorov I., Yarakhmedov O., Vucinic D.","“Cut-Glue” approximation based on pseudo-genetic algorithm for strongly nonlinear parametric dependencies of mathematical models",2018,"Advanced Structured Materials",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024492430&doi=10.1007%2f978-3-319-59590-0_21&partnerID=40&md5=e7a199b0efd1e9f03d814932e0807260","In the present work we consider one of the basic methods of Cut-Glue approximation—the approximation method for fragments with essentially nonlinear dependencies. As an instrument of approximation, a hybrid application of the classical regression analysis is used and specially developed for the evolutionarily modified genetic algorithm. The proposed approach allows finding the optimal dependence of the specified fragment. © 2018, Springer International Publishing AG.","Approximation; Evolutionary-genetic algorithm; Experimental data; Heuristic methods; Mathematical model; Optimization; Regression analysis",,2-s2.0-85024492430
"Jiang L., Liu Q.","SelGenAmic: An algorithm for selenoprotein gene assembly",2018,"Methods in Molecular Biology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029582548&doi=10.1007%2f978-1-4939-7258-6_3&partnerID=40&md5=8280e8241ba245df9bebbc8ef27a5db1","Computational methods for identifying selenoproteins have been developed rapidly in recent years. However, it is still difficult to identify the open reading frame (ORF) of eukaryotic selenoprotein gene, because the TGA codon for a selenocysteine (Sec) residue in the active center of selenoprotein is traditionally a terminal signal of protein translation. A gene assembly algorithm SelGenAmic has been constructed and presented in this chapter for identifying selenoprotein genes from eukaryotic genomes. A method based on this algorithm was developed to build an optimal TGA-containing-ORF for each TGA in a genome, followed by protein similarity analysis through conserved sequence alignments to screen out selenoprotein genes from these ORFs. This method improved the sensitivity of detecting selenoproteins from a genome due to the design that all TGAs in the genome were investigated for its possibility of decoding as a Sec residue. The method based on the SelGenAmic algorithm is capable of identifying eukaryotic selenoprotein genes from their genomes. © 2018, Springer Science+Business Media LLC.","Gene assembly algorithm; Selenocysteine; Selenoprotein",,2-s2.0-85029582548
"Li J., Chen L., Huang W.","Detection of early bruises on peaches (Amygdalus persica L.) using hyperspectral imaging coupled with improved watershed segmentation algorithm",2018,"Postharvest Biology and Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029723295&doi=10.1016%2fj.postharvbio.2017.09.007&partnerID=40&md5=983a008eb3469e6c3d2a790a6e9ad102","Bruise is the most common type of damage to peaches in a major cause of quality loss. However, fast and nondestructive detection of early bruises on peaches is a challenging task. In this study, short-wave near infrared (SW-NIR) and long-wave near infrared (LW-NIR) hyperspectral imaging technologies were observed and compared the ability to discriminate bruised from sound regions. Principal components analysis (PCA) was utilized to select the effective wavelengths for each type of imaging mode. SW-NIR imaging mode was more suitable for detection of early bruises on peaches. A novel improved watershed segmentation algorithm based on morphological gradient reconstruction and marker extraction was developed and applied to the multispectral PC images. The detection results indicated that for all test peaches used in this experiment, 96.5% of the bruised and 97.5% of sound peaches were accurately identified, respectively. A proposed algorithm was superior to the common segmentation methods including Ostu and the global threshold value method. This study demonstrated that SW-NIR hyperspectral imaging coupled with the proposed improved watershed segmentation algorithm could be a potential approach for detection of early bruises on peaches. © 2017","Hyperspectral imaging; Image processing; Improved watershed segmentation algorithm; Peach bruise",,2-s2.0-85029723295
"Seo J., Park K.","Fast batch modular exponentiation with common-multiplicand multiplication",2018,"Information Processing Letters",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029373035&doi=10.1016%2fj.ipl.2017.09.003&partnerID=40&md5=788ef87a38e567552e0a8eb40f505b86","We present an efficient algorithm for batch modular exponentiation which improves upon the previous generalized intersection method with respect to the cost of multiplications. The improvement is achieved by adopting an extended common-multiplicand multiplication technique that efficiently computes more than two multiplications at once. Our algorithm shows a better time-memory tradeoff compared to the previous generalized intersection method. We analyze the cost of multiplications and storage requirement, and show how to choose optimal algorithm parameters that minimize the cost of multiplications. © 2017 Elsevier B.V.","Algorithm; Common-multiplicand multiplication; Cryptography; Modular exponentiation","Algorithms; Computer applications; Cryptography; Data processing; Common-multiplicand multiplication; Generalized intersection; Modular Exponentiation; Optimal algorithm; Storage requirements; Time-memory trade-offs; Costs",2-s2.0-85029373035
"Li L.","Analytical application of hadoop-based collaborative filtering recommended algorithm in tea sales system",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032693677&doi=10.1007%2f978-3-319-67071-3_51&partnerID=40&md5=8126e2e038366997752afae08a06f17c","With the continuous expansion of e-commerce applications in China, people not only enjoy the conveniences, but also encounter the difficulties of being unable to find their demands from a large number of e-commerce goods. On the basis of combination of Hadoop distributed system infrastructure with traditional collaborative filtering recommended algorithm, the sales records of the existing tea sales system is analyzed in this paper, so as to obtain the recommended principle that meets consumer preference and help users to find the tea they need more quickly. This helps tea enterprises to extend their marketing channel and improve tea sales. © 2018, Springer International Publishing AG.","Collaborative filtering recommended algorithm; E-commerce; Hadoop; Tea","Commerce; Electronic commerce; Sales; Analytical applications; Consumer preferences; E-Commerce applications; Hadoop; Hadoop distributed systems; Marketing channels; Collaborative filtering",2-s2.0-85032693677
"Zeng W.","Application of neural network algorithm based on PCA-BP in earthquake early warning of buildings",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028378229&doi=10.1007%2f978-3-319-60744-3_42&partnerID=40&md5=2ac0587d22879feedc18ce4700544e76","This paper established an efficient and practical earthquake damage prediction method for buildings by combining principal component analysis (PCA) with neural network. To avoid BP neural network from being caught in a local minimum, according to the features of PCA algorithm, this paper combined the two to form PCA-BP mixed model and trained the network through the initial weight of PCA-optimized neural network. Based on a collection of large quantities of earthquake damage data of buildings, this model was introduced in earthquake early warning for buildings. The results show that this method can predict earthquake for buildings in an effective and accurate way. © 2018, Springer International Publishing AG.","Earthquake early warning; Neural network; Principal component analysis","Buildings; Earthquakes; Forecasting; Geophysics; Intelligent systems; Neural networks; Real time systems; BP neural networks; Earthquake damage predictions; Earthquake damages; Earthquake early warning; Initial weights; Local minimums; Mixed modeling; Neural network algorithm; Principal component analysis",2-s2.0-85028378229
"Cruz Hernández H., de la Fraga L.G.","A multi-objective robust ellipse fitting algorithm",2018,"Studies in Computational Intelligence",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030113838&doi=10.1007%2f978-3-319-64063-1_6&partnerID=40&md5=6385068731aa20a9e2c8c2dca2ad280f","The ellipse fitting problem is very common in science and industry. There exists a broad research on this problem, and currently we can find deterministic as well as stochastic methods in the specialized literature. Within the deterministic methods we find the algebraic approaches that are time and memory efficient, but which are, on the other hand, very sensitive to noise and outliers. Stochastic methods aim to find good solutions by exploring a reduced number of the possible ellipses. Two of the main characteristics of stochastic methods is that they are very robust to outliers and noise while they have a higher cost, in terms of functions evaluations, compared to the algebraic methods (with closed form solutions). In this paper, we propose to approach the ellipse fitting problem via using a multi-objective genetic algorithm. We simultaneously optimize two contradictory fitting functions, as this approach helps to enhance the exploration of the genetic algorithm. From the solution set we introduce another function that selects the correct solution. To validate our approach we detect ellipses from data sets with high amounts of noise (up to 100%), and we compare our results to others obtained via a classical mono-objective approach. © Springer International Publishing AG 2018.","Computer vision; Ellipse fitting; Genetic algorithm; Multi-objective optimization; Robust optimization",,2-s2.0-85030113838
"Zhou J., Luo Z., Li C., Deng M.","Real-time deformation of human soft tissues: A radial basis meshless 3D model based on Marquardt's algorithm",2018,"Computer Methods and Programs in Biomedicine",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032437876&doi=10.1016%2fj.cmpb.2017.09.008&partnerID=40&md5=2af273dbd1f5eefa88d6e90a7718f4ce","Background When the meshless method is used to establish the mathematical-mechanical model of human soft tissues, it is necessary to define the space occupied by human tissues as the problem domain and the boundary of the domain as the surface of those tissues. Nodes should be distributed in both the problem domain and on the boundaries. Under external force, the displacement of the node is computed by the meshless method to represent the deformation of biological soft tissues. However, computation by the meshless method consumes too much time, which will affect the simulation of real-time deformation of human tissues in virtual surgery. Methods In this article, the Marquardt's Algorithm is proposed to fit the nodal displacement at the problem domain's boundary and obtain the relationship between surface deformation and force. When different external forces are applied, the deformation of soft tissues can be quickly obtained based on this relationship. Results and conclusions The analysis and discussion show that the improved model equations with Marquardt's Algorithm not only can simulate the deformation in real-time but also preserve the authenticity of the deformation model's physical properties. © 2017 Elsevier B.V.","Marquardt algorithm; Meshless method; Real-time deformation; Surface fitting; Virtual surgery","Deformation; Histology; Surgery; Three dimensional computer graphics; Virtual reality; Marquardt algorithm; Mesh-less methods; Real time deformations; Surface fitting; Virtual surgery; Tissue; human; human tissue; physical model; simulation; soft tissue; surgery",2-s2.0-85032437876
"Feng Z.-K., Niu W.-J., Cheng C.-T., Wu X.-Y.","Peak operation of hydropower system with parallel technique and progressive optimality algorithm",2018,"International Journal of Electrical Power and Energy Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026198480&doi=10.1016%2fj.ijepes.2017.07.015&partnerID=40&md5=3430e86d75538974e8d0eddcd230807e","With the rapid economic growth in recent years, the peak operation of hydropower system (POHS) is becoming one of the most important optimization problems in power system. However, the rapid expansion of system scale, refined management and operational constraints has greatly increased the optimization difficult of POHS. As a result, it is of great importance to develop effective methods that can ensure the computational efficiency of POHS. The progressive optimality algorithm (POA) is a commonly used technique for solving hydropower operation problem, but its execution time still grows sharply with the increasing number of hydropower plants, making it difficult to satisfy the efficiency requirement of POHS. To address this problem, a novel efficient method called parallel progressive optimality algorithm (PPOA) is presented in this paper. In PPOA, the complex problem is firstly divided into several two-stage optimization subproblems, and then the classical Fork/Join framework is used to realize parallel computation of subproblems, making a significant improvement on execution efficiency. The simulations in a real-world hydropower system demonstrate that as compared with the standard POA, PPOA can use abundant multi-core resources to reduce execution time while keeping the quality of solution, providing a new alternative to solve the complex hydropower peak operation problem. © 2017 Elsevier Ltd","Curse of dimensionality; Fork/Join framework; Hydropower reservoirs; Parallel computing; Peak operation; Progressive optimality algorithm","Computational efficiency; Economics; Efficiency; Hydroelectric power; Optimization; Parallel processing systems; Curse of dimensionality; Fork/Join framework; Hydropower reservoirs; Peak operation; Progressive optimality algorithm; Problem solving",2-s2.0-85026198480
"Ahmed M.M., Houssein E.H., Hassanien A.E., Taha A., Hassanien E.","Maximizing lifetime of wireless sensor networks based on whale optimization algorithm",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029508833&doi=10.1007%2f978-3-319-64861-3_68&partnerID=40&md5=673b0de3bdc8fb620324a823cd7cdc2c","The lifetime of wireless sensor networks (WSNs) are considered one of the most challenges that face the topology control of WSNs. Topology control of WSNs is a technique to optimize the connections between nodes to reduce the interference between them, save energy and extend network lifetime. In this paper proposed an algorithm based on Whale Optimization Algorithm (WOA) called WOTC, the paper provides a discrete version of the WOA, where the position of each Whale is calculate and represented in a binary format. The proposed fitness function is designed to consider two main target; a minimization in numbers of active nodes, and low energy consumption within these nodes to overcome challenges that face topology control to prolong the WSNs lifetime, the simulations were carried out using Attaraya a simulator. Consequently, the results showed that the final topology obtained by WOTC is better than A3 topology depending on the number of neighbors and their energies for active nodes, use a graph traversal function to ensure that all nodes which selected in network are covered in the best topology selection. © 2018, Springer International Publishing AG.","Swarm intelligence; Topology control protocol; Whale optimization algorithm; Wireless sensor networks",,2-s2.0-85029508833
"Elsayed D.H., Nasr E.S., El Ghazali A.E.D.M., Gheith M.H.","A new hybrid approach using genetic algorithm and q-learning for qos-aware web service composition",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029496479&doi=10.1007%2f978-3-319-64861-3_50&partnerID=40&md5=e48668ef71a36e715f87e8130e8a6708","Web Service composition (WSC) is a technology for building an application in Service Oriented Architecture (SOA). In WSC the sets of atomic Web services combine together to satisfy users’ requirements. Due to the increase in number of Web services with the same functionality and variety of Quality of Services (QoS), it became difficult to find a suitable Web service that satisfies the functional requirements, as well as optimizing the QoS. This has led to the emergence of QoS-aware WSC. However, to find an optimal solution in QoS-aware WSC is an NP-hard problem. In this paper, we propose a new approach that combines the use of Genetic Algorithm (GA) and Q-learning to find the optimal WSC. The performance of GAs depends on the initial population, so the Q-learning is utilized to generate the initial population to enhance the effectiveness of GA. We implemented our approach over the.NET Framework platform 4.7 using C# programming language. The experiment results show the effectiveness of our proposed approach compared to Q-learning algorithm and GA. © 2018, Springer International Publishing AG.","Genetic algorithm; Q-learning; Quality of Services; Web service composition",,2-s2.0-85029496479
"Fortes E.D.V., Macedo L.H., Araujo P.B.D., Romero R.","A VNS algorithm for the design of supplementary damping controllers for small-signal stability analysis",2018,"International Journal of Electrical Power and Energy Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021454775&doi=10.1016%2fj.ijepes.2017.06.017&partnerID=40&md5=d894ef8a876e4e85bdb2017f082075c1","This paper presents a variable neighborhood search (VNS) optimization algorithm for the design of the parameters of supplementary damping controllers: power system stabilizers (PSS) and the interline power flow controller–power oscillation damping (IPFC–POD) set. The objective is to insert damping to local and inter-area oscillation modes in multimachine power systems. The electric power system dynamics is represented by the current sensitivity model. Simulations were carried out using three systems: a test system known as Two-Area Symmetrical and two real systems, the New England and the Reduced Southern Brazilian. The VNS method was compared with a multi-start algorithm in terms of performance, showing better convergence rates. The proposal was also able to obtain solutions with high damping levels, that showed to be robust when changes on the operating point of the power system were considered. Finally, it has been verified that the PSS controllers were effective for damping the local mode oscillations, while the IPFC–POD set operated mainly damping the inter-area modes. © 2017 Elsevier Ltd","Interline power flow controller; Power oscillation damping; Power system stabilizers; Variable neighborhood search algorithm","Circuit oscillations; Controllers; Damping; Electric control equipment; Electric load flow; Electric power system control; Electric power systems; Flow control; Optimization; Oscillating flow; Interline power flow controllers; Multi machine power system; Power oscillation damping; Power System Stabilizer; Power system stabilizer (PSS); Small signal stability analysis; Supplementary damping controllers; Variable neighborhood search; Power control",2-s2.0-85021454775
"Palacios J.J., Puente J., Vela C.R., González-Rodríguez I., Talbi E.-G.","Surrogate-assisted multiobjective evolutionary algorithm for fuzzy job shop problems",2018,"Operations Research/ Computer Science Interfaces Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032637627&doi=10.1007%2f978-3-319-58253-5_24&partnerID=40&md5=08491c9d080c8ea2f301b0aa917856c2","We consider a job shop scheduling problem with uncertain processing times modelled as triangular fuzzy numbers and propose a multiobjective surrogate-assisted evolutionary algorithm to optimise not only the schedule’s fuzzy makespan but also the robustness of schedules with respect to different perturbations in the durations. The surrogate model is defined to avoid evaluating the robustness measure for some individuals and estimate it instead based on the robustness values of neighbouring individuals, where neighbour proximity is evaluated based on the similarity of fuzzy makespan values. The experimental results show that by using fitness estimation, it is possible to reach good fitness levels much faster than if all individuals are evaluated. © Springer International Publishing AG 2018.","Fuzzy job shop; Multiobjective evolutionary algorithm; Robust scheduling; Surrogate fitness",,2-s2.0-85032637627
"Maaziz M., Kharfouchi S.","Parameter estimation of Markov switching bilinear model using the (EM) algorithm",2018,"Journal of Statistical Planning and Inference",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028314216&doi=10.1016%2fj.jspi.2017.07.002&partnerID=40&md5=21a8e8d23d5f8d5f33132cb7933ac9e0","Markov Switching models have known a strong growth since their introduction by James Hamilton in the late 1980's. These models are used as an essential tool for the analysis of the economic cycles. In this paper, we are interested in a class of bilinear models with markov-switching regime MS−BL. These models first appeared in Bibi and Aknouche (2010). Parameter estimation via maximum likelihood (ML) of the MS−BL model has been considered in Bibi and Ghazel (2015). However, construction and numerical maximization in the approach proposed by Bibi and Ghazel (2015) are computationally intractable. Hence, we propose an expectation–maximization EM procedure that provides an alternative method for maximizing the likelihood function in such situations. Convergence and consistency of the EM algorithm are discussed in this context. Finally, a Monte Carlo study is presented and two real data examples are proposed. © 2017 Elsevier B.V.","(EM) algorithm; Bilinear models; Markov-switching; Maximum likelihood",,2-s2.0-85028314216
"Wichapa N., Khokhajaikiat P.","Solving a multi-objective location routing problem for infectious waste disposal using hybrid goal programming and hybrid genetic algorithm",2018,"International Journal of Industrial Engineering Computations",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020104449&doi=10.5267%2fj.ijiec.2017.4.003&partnerID=40&md5=18afc26a4a110718679cb7b5561c9fd8","Infectious waste disposal remains one of the most serious problems in the medical, social and environmental domains of almost every country. Selection of new suitable locations and finding the optimal set of transport routes for a fleet of vehicles to transport infectious waste material, location routing problem for infectious waste disposal, is one of the major problems in hazardous waste management. Determining locations for infectious waste disposal is a difficult and complex process, because it requires combining both intangible and tangible factors. Additionally, it depends on several criteria and various regulations. This facility location problem for infectious waste disposal is complicated, and it cannot be addressed using any stand-alone technique. Based on a case study, 107 hospitals and 6 candidate municipalities in Upper-Northeastern Thailand, we considered criteria such as infrastructure, geology and social & environmental criteria, evaluating global priority weights using the fuzzy analytical hierarchy process (Fuzzy AHP). After that, a new multi-objective facility location problem model which hybridizes fuzzy AHP and goal programming (GP), namely the HGP model, was tested. Finally, the vehicle routing problem (VRP) for a case study was formulated, and it was tested using a hybrid genetic algorithm (HGA) which hybridizes the push forward insertion heuristic (PFIH), genetic algorithm (GA) and three local searches including 2-opt, insertion-move and interexchange-move. The results show that both the HGP and HGA can lead to select new suitable locations and to find the optimal set of transport routes for vehicles delivering infectious waste material. The novelty of the proposed methodologies, HGP, is the simultaneous combination of relevant factors that are difficult to interpret and cost factors in order to determine new suitable locations, and HGA can be applied to determine the transport routes which provide a minimum number of vehicles and minimum transportation cost under the actual situation efficiently in this case. © 2018 Growing Science Ltd. All rights reserved.","Fuzzy analytic hierarchy process; Genetic algorithm; Goal programming; Location routing problem; Multi-objective facility location problem; Vehicle routing problem",,2-s2.0-85020104449
"Lu G.-F., Wang Y., Zou J., Wang Z.","Matrix exponential based discriminant locality preserving projections for feature extraction",2018,"Neural Networks",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032438175&doi=10.1016%2fj.neunet.2017.09.014&partnerID=40&md5=7de0f282583eacf2c45b946c05828fff","Discriminant locality preserving projections (DLPP), which has shown good performances in pattern recognition, is a feature extraction algorithm based on manifold learning. However, DLPP suffers from the well-known small sample size (SSS) problem, where the number of samples is less than the dimension of samples. In this paper, we propose a novel matrix exponential based discriminant locality preserving projections (MEDLPP). The proposed MEDLPP method can address the SSS problem elegantly since the matrix exponential of a symmetric matrix is always positive definite. Nevertheless, the computational complexity of MEDLPP is high since it needs to solve a large matrix exponential eigenproblem. Then, in this paper, we also present an efficient algorithm for solving MEDLPP. Besides, the main idea for solving MEDLPP efficiently is also generalized to other matrix exponential based methods. The experimental results on some data sets demonstrate the proposed algorithm outperforms many state-of-the-art discriminant analysis methods. © 2017 Elsevier Ltd","Dimensionality reduction; Discriminant locality preserving projections; Linear discriminant analysis; Matrix exponential","Discriminant analysis; Extraction; Feature extraction; Pattern recognition; Algorithm for solving; Dimensionality reduction; Discriminant analysis methods; Feature extraction algorithms; Linear discriminant analysis; Locality preserving projections; Matrix exponentials; Small sample size problems; Matrix algebra; algorithm; Article; calculation; discriminant analysis; mathematical analysis; mathematical computing; mathematical parameters; matrix exponential based discriminant locality preserving projection; priority journal; sample size",2-s2.0-85032438175
"Rahil H., Abou El Majd B., Bouchoum M.","Optimized air routes connections for real hub schedule using smpso algorithm",2018,"Operations Research/ Computer Science Interfaces Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032621665&doi=10.1007%2f978-3-319-58253-5_21&partnerID=40&md5=1f77a3db495cc226c33ff174758ead40","The choice to open new routes for air carriers, airports and regional governments have some tools to promote desirable connections to be offered toward specific destinations. With a given flight program, the air carrier decision to open new routes faces several constraints and affects the flight schedules in a remarkable way. This work is distinguished by the fact of being the first to introduce the problem of connectivity in the network of an airline whose main activity is based on air hub structure, optimizing the insertion of new airline routes while ensuring the best fill rate seats and avoiding significant delays during correspondence. Quality of Service Index (QSI) will be considered as a duel parameter for the profit of a new opened market. This aspect of decision making is formulated as multi-objective problem by testing the impact of a new insertion in term of delays, generated with related costs and financial gain, and the quality of service offered to a target customers. The SMPSO Algorithm is adopted to generate a Pareto-optimal front composed of many optimal departure times toward the new opening insuring the best filling ratio with minimum connecting times. Experiences are based on real instance of Royal Air Maroc flights schedule on the hub of Casablanca. © Springer International Publishing AG 2018.","Flight schedule; Hub and spokes; Multi-objective optimization; Outbound/Inbound connection; Pareto optimal; Route networks; SMPSO algorithm",,2-s2.0-85032621665
"Biswas P.P., Suganthan P.N., Amaratunga G.A.J.","Decomposition based multi-objective evolutionary algorithm for windfarm layout optimization",2018,"Renewable Energy",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028320311&doi=10.1016%2fj.renene.2017.08.041&partnerID=40&md5=6b20e7a212590e9cda044ee55b4632f3","An efficient windfarm layout to harness maximum power out of the wind is highly desirable from technical and commercial perspectives. A bit of flexibility on layout gives leeway to the designer of windfarm in planning facilities for erection, installation and future maintenance. This paper proposes an approach where several options of optimized usable windfarm layouts can be obtained in a single run of decomposition based multi-objective evolutionary algorithm (MOEA/D). A set of Pareto optimal vectors is obtained with objective as maximum output power at minimum wake loss i.e. at maximum efficiency. Maximization of both output power and windfarm efficiency are set as two objectives for optimization. The objectives thus formulated ensure that in any single Pareto optimal solution the number of turbines used are placed at most optimum locations in the windfarm to extract maximum power available in the wind. Case studies with actual manufacturer data for wind turbines of same as well as different hub heights and with realistic wind data are performed under the scope of this research study. © 2017 Elsevier Ltd","Efficiency; Hub heights; Multi-objective evolutionary algorithm; Power output; Wind turbine data; Windfarm turbine placement",,2-s2.0-85028320311
"Fraga E.S., Salhi A., Talbi E.-G.","On the impact of representation and algorithm selection for optimisation in process design: Motivating a meta-heuristic framework",2018,"Operations Research/ Computer Science Interfaces Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032645614&doi=10.1007%2f978-3-319-58253-5_9&partnerID=40&md5=e5c5f0798ad33f4442fafa38c18933e8","In an ideal world, it would be straightforward to identify the most suitable optimisation method to use in the solution of a given optimisation problem. However, although some methods may be more widely applicable than others, it is impossible a priori to know which method will work best. This may be due to the particular mathematical properties of the mathematical model, i.e. the formulation. It may also be due to the representation of the variables in the model. This combination of choices of method, representation and formulation makes it difficult to predict which combination may be best. This paper presents an example from process engineering, the design of heat exchanger networks, for which two different representations for the same formulation are available. Two different heuristic optimisation procedures are considered. The results demonstrate that any given combination will not lead to the best outcome across a range of case studies. This motivates the need for a multi-algorithm, multi-representation approach to optimisation, at least for process design. © Springer International Publishing AG 2018.","Genetic algorithm; Heat exchanger networks; Optimisation; Representation; Simulated annealing",,2-s2.0-85032645614
"Sadeghi M., Shafabakhsh G.","Estimation of intercity freight origin-destination matrix using simulated annealing algorithm",2018,"Uncertain Supply Chain Management",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022064114&doi=10.5267%2fj.uscm.2017.6.005&partnerID=40&md5=cf0c078e03a2acde48ce7b37f0d0f77d","The information of trip demand as the freight origin-destination (O-D) matrices plays a significant role in intercity transportation engineering and planning. Access to this matrix from conventional methods needs to spend time, money and human resources. During the recent years, numerous studies have been conducted in order to obtain the freight O-D matrix using freight vehicle count information in network links. Furthermore, the estimation of O-D matrix and its communicating with freight vehicles can greatly help planners improve logistic, safety and the maintenance issues. This paper presents a method based on the minimization of the deviations between the observed and estimated values for finding the freight O-D matrix. To solve the model, traffic count data of trucks in the network links as well as other related information resources are used. The model is solved for a case study in Iran using meta-heuristic Simulated Annealing Algorithm. © 2018 Growing Science Ltd. All rights reserved. and 2018 by the authors.","Commercial vehicles; Estimation of freight O-D matrix; Intercity transportation, assignment; Logistic; Simulated annealing algorithm; Traffic count",,2-s2.0-85022064114
"Hong L., Drake J.H., Woodward J.R., Özcan E.","A hyper-heuristic approach to automated generation of mutation operators for evolutionary programming",2018,"Applied Soft Computing Journal",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032719328&doi=10.1016%2fj.asoc.2017.10.002&partnerID=40&md5=b2e0ed8d1f19617ec24f59f4e339e78b","Evolutionary programming can solve black-box function optimisation problems by evolving a population of numerical vectors. The variation component in the evolutionary process is supplied by a mutation operator, which is typically a Gaussian, Cauchy, or Lévy probability distribution. In this paper, we use genetic programming to automatically generate mutation operators for an evolutionary programming system, testing the proposed approach over a set of function classes, which represent a source of functions. The empirical results over a set of benchmark function classes illustrate that genetic programming can evolve mutation operators which generalise well from the training set to the test set on each function class. The proposed method is able to outperform existing human designed mutation operators with statistical significance in most cases, with competitive results observed for the rest. © 2017 Elsevier B.V.","Automatic design; Continuous optimisation; Evolutionary programming; Genetic programming; Hyper-heuristics","Computer programming; Evolutionary algorithms; Genetic algorithms; Heuristic methods; Heuristic programming; Optimization; Personnel training; Population statistics; Probability distributions; Automated generation; Automatic design; Benchmark functions; Continuous optimisation; Evolutionary process; Hyper-heuristics; Optimisation problems; Statistical significance; Genetic programming",2-s2.0-85032719328
"Bureva V., Popov S., Sotirova E., Atanassov K.T.","Generalized net of mapreduce computational model",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031412191&doi=10.1007%2f978-3-319-65545-1_28&partnerID=40&md5=0c117362b3ec71e8c1c1abbdbdd06b87","The topic in the current research work is one of the Big data frameworks known as MapReduce paradigm. This is a programming model for parallel processing of large volumes of data in distributed environment. MapReduce is applied in the clusters of commodity machines. The workflow of the MapReduce computational model is constructed using the possibilities of Generalized nets. The Generaliezed net model which is presented allows us to observe and monitor the Mapreduce framework in detail. © Springer International Publishing AG 2018.","Big data; Cloud computing; Distributed algorithms; Distributed systems; Generalized net; Map-Reduce; Parallel computing","Big data; Cloud computing; Computation theory; Computational methods; Decision making; Decision support systems; Fuzzy sets; Parallel algorithms; Parallel processing systems; Computational model; Distributed environments; Distributed systems; Generalized net; Map-reduce; Mapreduce frameworks; Parallel processing; Programming models; Distributed computer systems",2-s2.0-85031412191
"Nishani L., Biba M.","Randomizing greedy ensemble outlier detection with GRASP",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026288922&doi=10.1007%2f978-3-319-61566-0_92&partnerID=40&md5=ce775056a89f41b025a0bc5907eedf57","Ensemble methods have been recently used in many applications of machine learning in different areas. In this context, outlier detection is an area where recently these methods have received increasing attention. This paper deals with randomization in ensemble methods for outlier detection. We have developed a novel algorithm exploiting stochastic local search heuristics to induce diversity in an ensemble outlier detection algorithm. We exploit the capability of the GRASP heuristic to induce diversity into the search process and to maintain a good balance of exploitation and diversification in building the ensemble. The conducted experiments show interesting improvements over the greedy ensemble method and open the path for novel research in this direction. © Springer International Publishing AG 2018.","Ensemble methods; GRASP; Machine learning; Outlier detection; Stochastic local search","Artificial intelligence; Education; Heuristic algorithms; Intelligent systems; Learning systems; Local search (optimization); Statistics; Stochastic systems; Ensemble methods; GRASP; In-buildings; Novel algorithm; Outlier Detection; Outlier detection algorithm; Search process; Stochastic local searches; Data handling",2-s2.0-85026288922
"Melo H., Zhang H., Vasant P., Watada J.","Training method for a feed forward neural network based on meta-heuristics",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026662697&doi=10.1007%2f978-3-319-63859-1_46&partnerID=40&md5=4ced0da20f5776abff3e471bacd835ca","This paper proposes a Gaussian-Cauchy Particle Swarm Optimization (PSO) algorithm to provide the optimized parameters for a Feed Forward Neural Network. The improved PSO trains the Neural Network by optimizing the network weights and bias in the Neural Network. In comparison with the Back Propagation Neural Network, the Gaussian-Cauchy PSO Neural Network converges faster and is immune to local minima. © Springer International Publishing AG 2018.","Cauchy distribution; Gaussian distribution; Neural network; Particle Swarm Optimization; Training algorithm","Backpropagation; Gaussian distribution; Heuristic methods; Multimedia signal processing; Neural networks; Optimization; Signal processing; Back propagation neural networks; Cauchy distribution; Meta heuristics; Network weights; Optimized parameter; Particle swarm optimization algorithm; Training algorithms; Training methods; Particle swarm optimization (PSO)",2-s2.0-85026662697
"Kuortti J., Malinen J., Ojalammi A.","Post-processing speech recordings during MRI",2018,"Biomedical Signal Processing and Control",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026776641&doi=10.1016%2fj.bspc.2017.07.017&partnerID=40&md5=69af23dcddfba9bf6c1b493df9948b81","We discuss post-processing of speech samples that have been recorded simultaneously during Magnetic Resonance Imaging (MRI) of the upper airways. Speech recordings contain acoustic noise from the MRI scanner. The required noise reduction is based on adaptive comb filtering designed for accurate formant extraction. Two kinds of speech materials were used to validate the post-processing algorithm. The primary material consists of samples of prolonged vowel productions during MRI. The comparison data was obtained from the same test subject, and it was recorded in anechoic chamber in a similar configuration as used during the MRI. Spectral envelopes and vowel formants were computed from the post-processed speech and from the comparison data. Vowel samples (with a known formant structure) were artificially contaminated using MRI scanner noise to determine performance of the post-processing algorithm. Resonances computed from a numerical acoustic model and spectra measured from 3D printed vocal tract physical models were used as comparison data. The properties of the recording instrumentation or the post-processing algorithm do not explain the observed frequency dependent discrepancy between the vowel formant data from two kinds of experiments: recordings during MRI and comparison data. It is shown that the discrepancy is statistically significant, in particular, where it is largest at ca. 1 kHz and 2 kHz. Numerical and experimental evidence suggests that the surfaces of the MRI head coil change the acoustics of speech which results in “exterior formants” at these frequencies. The discrepancy is too large to be neglected if the recordings during MRI are to be used for parameter estimation or validation of a numerical speech model, based on the MR images. However, the role of test subject adaptation to noise and constrained space acoustics during an MRI examination cannot be ruled out. © 2017 Elsevier Ltd","DSP; Helmholtz; MRI; Noise reduction; Speech","3D printers; Acoustic noise; Audio recordings; Linguistics; Magnetic resonance imaging; Noise abatement; Scanning; Speech enhancement; Speech processing; Constrained space; Experimental evidence; Frequency dependent; Helmholtz; Numerical acoustics; Postprocessing algorithms; Primary materials; Spectral envelopes; Speech; acoustics; adaptation; adult; algorithm; Article; case report; frequency analysis; human; male; noise reduction; normal human; nuclear magnetic resonance imaging; nuclear magnetic resonance scanner; physical model; post processing algorithm; priority journal; signal processing; speech analysis; vowel",2-s2.0-85026776641
"Hu S., Ren X., Zhao W.","Synchronous control of multi-motor driving servo systems",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030838102&doi=10.1007%2f978-981-10-6496-8_56&partnerID=40&md5=6f8a0442d1929c8e38fcccb2926b10e2","A nonlinear continuous predictive control method based on sliding mode is proposed to realize the synchronous control of multi-motor driving servo systems. The continuous-time recursive least-squares algorithm with forgetting factor is developed to estimate the disturbance and the unknown parameters, which compensates the influence of noise and guarantees that the parameter estimation converges to the true values. The continuous prediction control law is improved by using the sliding mode variable structure scheme, which ensures the rapid synchronization of the motors and deals with the problem of model uncertainty. The simulation results are presented to demonstrate the effectiveness of the method. © 2018, Springer Nature Singapore Pte Ltd.","Least-squares algorithm; Multi-motor driving servo system; Nonlinear continuous predictive control; Sliding mode control","Continuous time systems; Intelligent systems; Sliding mode control; Uncertainty analysis; Continuous-time recursive least squares algorithms; Least squares algorithm; Model uncertainties; Multi motors; Predictive control; Predictive control methods; Sliding mode variable structure; Synchronous control; Servomechanisms",2-s2.0-85030838102
"Zhu G., Liu H., Zhang S.","The extraction method for best match of food nutrition",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032711629&doi=10.1007%2f978-3-319-67071-3_44&partnerID=40&md5=fb85f1922bdab4f740f569460177032f","It is a hot study topic that how to obtain the food collocation and the effect of food collocation. The extraction method for best match of food nutrition is proposed to solve the problem in this paper. First, the method of forward maximum matching is used to segment sentences and filter stop words. Then, the nutrition content of food is abstracted as food collocation vector. At last, the classification results of the KNN algorithm are used to identify the verb of sentence. The average accuracy of the test is 45.9%. The experiments show that the method is effective. © 2018, Springer International Publishing AG.","Food collocation vector; Forward maximum matching; KNN algorithm","Extraction; Nutrition; And filters; Best match; Classification results; Extraction method; Food nutrition; k-NN algorithm; Maximum matchings; Stop word; Learning algorithms",2-s2.0-85032711629
"Eckert J.J., Corrêa F.C., Bertoti E., Yamashita R.Y., Silva L.C.A., Dedini F.G.","Powertrain optimization to improve vehicle performance and fuel consumption",2018,"Mechanisms and Machine Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031315192&doi=10.1007%2f978-3-319-67567-1_49&partnerID=40&md5=b9f8d36273d85b318e7d896370c4f4a9","The available gearbox transmission ratios associated with gear shifting strategies influence the vehicle performance and fuel consumption because it changes the powertrain inertia and the engine operation point. However, the best configuration for the vehicle powertrain, according to a specific driving condition, is difficult to be determined. Therefore, this paper presents an Interactive Adaptive-Weight Genetic Algorithm to optimize the vehicle powertrain gear ratios and the gear shifting strategies to allow the vehicle to operate in the best compromise among fuel consumption and performance in the urban driving scenario provided by the FTP-72 cycle. The optimization process results in a fuel saving of 10.61% and 50.12% improvement in the vehicle performance when using the best-compromised configuration. © 2018, Springer International Publishing AG.","Fuel consumption; Gear shifting; Genetic Algorithm Optimization; Powertrain; Vehicular performance","Fuel consumption; Fuel economy; Fuels; Genetic algorithms; Optimization; Powertrains; Vehicle transmissions; Vehicles; Adaptive weights; Driving conditions; Engine operations; Gear shifting; Genetic-algorithm optimizations; Transmission ratios; Vehicle powertrains; Vehicular performance; Vehicle performance",2-s2.0-85031315192
"Zhao Q.Q., Yun W.Y.","Determining the inspection intervals for one-shot systems with support equipment",2018,"Reliability Engineering and System Safety",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026898410&doi=10.1016%2fj.ress.2017.08.007&partnerID=40&md5=a7c3b98c9c27d76c022b71f6e6bf6141","This paper considers systems that comprise one-shot devices and support equipment. One-shot devices are stored for long periods of time, and failures are detected only upon inspection. The support equipment needed to operate one-shot devices is maintained immediately upon failure. This paper addresses the inspection schedule problem for such systems with limited maintenance resources. The interval availability and life cycle cost are used as optimization criteria. The aim is to determine near-optimal inspection intervals for one-shot systems to minimize the expected life cycle cost and satisfy the target interval availability between inspection periods. An estimation of distribution algorithm (EDA) and a heuristic method are proposed to find the near-optimal solutions, and numerical examples are given to demonstrate the effects of the various model parameters to the near-optimal inspection intervals. © 2017 Elsevier Ltd","Estimation of distribution algorithm; Interval availability; One-shot device; Support equipment","Equipment; Heuristic methods; Inspection; Life cycle; Numerical methods; Estimation of distribution algorithm (EDA); Estimation of distribution algorithms; Maintenance resources; Near-optimal solutions; One-shot device; Optimization criteria; Support equipments; Various model parameters; Optimization",2-s2.0-85026898410
"Satyanarayana P., Sujitha K., Sai Anitha Kiron V., Ajitha Reddy P., Ganesh M.","Assistance vision for blind people using k-NN algorithm and raspberry Pi",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029791193&doi=10.1007%2f978-981-10-4280-5_12&partnerID=40&md5=89e1790dc427065fba5ea909e7c31275","Eyes are the natural camera that human beings possess. But not all the people are lucky enough to have them. About 15 million people in India suffer with visual impairments. So, through this chapter, an attempt is made to help them by providing assistance for text reading from the documents and papers. The characters present in the text are isolated from cluttered background or the surrounding objects in the camera view. The characters are separated from one another by drawing contours. Once the text characters in the localized text regions are detected, they are binarized and trained using k-Nearest Neighbor (k-NN). The trained data is stored in a file and these will be the classifiers. These classifiers are loaded while testing. The text in the image is recognized based on the loaded classifiers file. This recognized text is stored and converted to speech. © Springer Nature Singapore Pte Ltd. 2018.","Classifiers; Contours; K-Nearest Neighbor; Optical character recognition; Speech conversion; Text detection","Cameras; Classifiers; Motion compensation; Nearest neighbor search; Optical character recognition; Pattern recognition; Speech recognition; Blind people; Cluttered backgrounds; Contours; K-nearest neighbors; k-NN algorithm; Speech conversion; Text detection; Visual impairment; Character recognition",2-s2.0-85029791193
"Chao F., Shan J., Gou J., Wu P., Ge L.","Study on the algorithm for solving two-fluid seven-equation two-pressure model",2018,"Annals of Nuclear Energy",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029693197&doi=10.1016%2fj.anucene.2017.09.021&partnerID=40&md5=9a335ead913ba0700274daed9ff8070a","Compared to the two-fluid single-pressure model, the two-fluid seven-equation two-pressure model has been proved to be well-posed (hyperbolic) due to its real characteristic values and exists a wide range of physical and industrial applications. In this paper, the partial differential equation system of the two-pressure model is discretized numerically using the finite volume integral method with staggered grids. The semi-implicit scheme is implemented to achieve accurate and stable numerical results. The source terms containing the heat and mass transfer, no instantaneous relaxation, wall drag and gravity field are included in this scheme. Eventually, the proposed numerical scheme is validated with several classical benchmark tests. The calculation results show that the proposed numerical scheme is accurate and robust in solving two-phase flows. © 2017 Elsevier Ltd","Finite volume method; Semi-implicit scheme; Two-fluid two-pressure model; Validation; Well-posedness","Benchmarking; Finite volume method; Gravitation; Mass transfer; Algorithm for solving; Characteristic value; Heat and mass transfer; Partial differential; Pressure modeling; Semi-implicit scheme; Validation; Wellposedness; Two phase flow",2-s2.0-85029693197
"Shi C.-X., Yang G.-H.","Robust consensus control for a class of multi-agent systems via distributed PID algorithm and weighted edge dynamics",2018,"Applied Mathematics and Computation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028986778&doi=10.1016%2fj.amc.2017.07.069&partnerID=40&md5=d708b3166f7f2a29be5ff945a20514ce","This paper studies the robust proportional-integral-derivative (PID) consensus control for a class of linear multi-agent systems (MASs) with external disturbances. Different from the existing results, both the consensus analysis and the transient performance characteristics for high-order linear MASs are considered. Based on a factorization of Laplacian matrix, the initial MAS is firstly transformed into the so-called weighted edge dynamics, and then a design equivalence between the proposed PID consensus controller and the corresponding stabilizing controller for such weighted edge dynamics is presented via some graph theory results. Furthermore, by combining Lyapunov theory and Barbalat's Lemma, it is proved that both the stabilization of weighted edge dynamics and the consensus of MAS can be guaranteed even in the presence of external disturbances. In particular, some relationships between the transient time performance of weighted edge dynamics and the PID design parameters are given. Finally, some numerical examples on LC oscillator network are provided to illustrate the validity of theoretical results. © 2017 Elsevier Inc.","Graph theory; Multi-agent systems; Proportional-integral-derivative (PID) Algorithm; Weighted edge dynamics","Controllers; Dynamics; Graph theory; Matrix algebra; Proportional control systems; Software agents; Two term control systems; Consensus analysis; Consensus control; Edge dynamics; External disturbances; Laplacian matrices; Proportional integral derivatives; Stabilizing controllers; Transient performance; Multi agent systems",2-s2.0-85028986778
"Hsieh J.-J., Hsu C.-H.","Estimation of the survival function with redistribution algorithm under semi-competing risks data",2018,"Statistics and Probability Letters",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032484131&doi=10.1016%2fj.spl.2017.09.003&partnerID=40&md5=5f14369c50c927709f6557c5321f5d82","This paper focuses on the estimation of the survival function of the non-terminal event time for semi-competing risks data. Without extra assumptions, we cannot make inference on the non-terminal event time because the non-terminal event time is dependently censored by the terminal event time. Thus, we utilize the Archimedean copula model to specify the dependency between the non-terminal event time and the terminal event time. Under the Archimedean copula assumption, we apply the redistribution method to estimate the survival function of the non-terminal event time and compare it with the copula-graphic estimator introduced by Lakhal et al. (2008). We also apply our suggested approach to analyze the Bone Marrow Transplant data. © 2017 Elsevier B.V.","Archimedean Copula model; Dependent censoring; Redistribution algorithm; Semi-competing risks data",,2-s2.0-85032484131
"Michael G., Thier R., Blaszkewicz M., Selinski S., Golka K.","Algorithm for the automated evaluation of NAT2 genotypes",2018,"Methods in Molecular Biology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029386988&doi=10.1007%2f978-1-4939-7234-0_7&partnerID=40&md5=d93b0066d2ff0b8e1b41ebf5a2c99929","N-Acetyltransferase 2 (NAT2) genotyping by PCR and RFLP-based methods provides information on seven single nucleotide polymorphisms (SNPs) without deriving the chromosomal phase (haplotype). So genotyping results must be processed to get all possible NAT2 haplotype (or allele) combinations. Here we describe the procedure for genotyping and present a program based on Microsoft® Access® which automatically generates all possible haplotype pairs for a given unphased NAT2 genotype. NAT2 haplotypes are important to predict the NAT2 phenotype. © Springer Science+Business Media LLC 2018.","Alleles; Automated evaluation; Computer program; Genotyping; Haplotype; N-Acetyltransferase 2","arylamine acetyltransferase; bovine serum albumin; bromophenol blue; DdeI protein; DNA fragment; ethidium bromide; FokI protein; KpnI protein; MspI protein; restriction endonuclease; Taq polymerase; TaqI protein; type II site specific deoxyribonuclease; unclassified drug; agar gel electrophoresis; algorithm; allele; amplicon; automation; data analysis software; DNA denaturation; DNA extraction; DNA isolation; evaluation study; genotype; haplotype; incubation time; phenotype; polymerase chain reaction; polymerase chain reaction system; restriction fragment length polymorphism; single nucleotide polymorphism",2-s2.0-85029386988
"Gao X., Tian Y., Sun B.","Multi-objective optimization design of bidirectional flow passage components using RSM and NSGA II: A case study of inlet/outlet diffusion segment in pumped storage power station",2018,"Renewable Energy",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029405168&doi=10.1016%2fj.renene.2017.09.011&partnerID=40&md5=c5eeb6d490bec47cc9c2a51e94bffec1","Frequent changes between inflow and outflow operations pose significant challenges in the design of bidirectional flow passage components with high efficiency and stability. In this study, hydraulic optimization of the inlet/outlet diffusion segment of a pumped storage power station was performed. First, a 3D-optimization platform was established for the inlet/outlet diffusion segment, and consists of parametric modelling, automatic mesh generation, CFD numerical calculation, and an optimization strategy. Three objective functions; the head loss, velocity uneven distribution, and discharge uneven distribution; were adopted to evaluate the overall performance of the inlet/outlet diffusion segment. Both dual- and triple-objective optimizations were adopted to optimize the shape of the inlet/outlet diffusion segment, the response surface methodology (RSM) was used to generate approximate functions relating to the objectives and design parameters, and the non-dominated sorting genetic algorithm (NSGA-II) was selected to conduct the optimizations. The objective of the present study was to use a numerical optimization method to determine the optimal inlet/outlet structure configurations yielding better hydraulic performance with bidirectional flow conditions. The results show that with triple-objective optimization, the head loss decreased by 2.71%, velocity uneven distribution decreased by 21.05%, and discharge uneven distribution decreased by 2.24%. © 2017 Elsevier Ltd","Genetic algorithm; Inlet/outlet; Multi-objective optimization; Optimization platform; Response surface methodology","Computational fluid dynamics; Diffusion; Genetic algorithms; Mesh generation; Numerical methods; Optimization; Structural optimization; Surface properties; Automatic mesh generation; Hydraulic optimizations; Inlet/outlet; Non dominated sorting genetic algorithm (NSGA II); Numerical optimizations; Pumped storage power station; Response surface methodology; Structure configuration; Multiobjective optimization; design method; efficiency measurement; genetic algorithm; numerical method; optimization; parameter estimation; performance assessment; power plant; response surface methodology; three-dimensional modeling",2-s2.0-85029405168
"Vanhaeren N., Ooms K., de Maeyer P.","Guiding people along more intuitive indoor paths",2018,"Lecture Notes in Geoinformation and Cartography",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031278650&doi=10.1007%2f978-3-319-63946-8_26&partnerID=40&md5=eda6e30bd87b1402b6e77e778d85dc20","Route planning algorithms in indoor navigation systems are currently limited to shortest path algorithms or derivatives. The development of a cognitive route planning algorithm, providing cognitive more comfortable paths to navigators, could improve these systems. The first phase of the development of such an algorithm entails the identification of relevant path characteristics of the indoor environment. Therefore, a user study is enrolled: an in-depth discussion with a focus group of experts is followed by an international online survey. © Springer International Publishing AG 2018.","Cognition; Indoor navigation; Route planning algorithm","Indoor positioning systems; Information theory; Navigation systems; Cognition; In-door navigations; Indoor environment; Indoor navigation system; Online surveys; Path characteristic; Route planning; Shortest path algorithms; Cognitive systems",2-s2.0-85031278650
"Paul S., Durgam U.K., Pati U.C.","Multimodal optical image registration using modified SIFT",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026741879&doi=10.1007%2f978-981-10-3373-5_11&partnerID=40&md5=2b3443818f5b101eef14d0604078f48f","Although a variety of feature-based remote sensing optical image registration algorithms has been proposed in past decades, most of the algorithms suffer from the availability of a sufficient number of matched features between the input image pairs. In this paper, a modified version of scale-invariant feature transform (SIFT) is proposed to increase the number of matched features between images. Initial matching between the input images is performed by modified SIFT algorithm with cross-matching technique. Then, matched features are refined by using random sample consensus (RANSAC) algorithm. © Springer Nature Singapore Pte Ltd. 2018.","Image registration; Random sample consensus; Scale-invariant feature transform","Computation theory; Geometrical optics; Intelligent computing; Iterative methods; Remote sensing; Cross-matching; Feature-based; Multi-modal; Optical image; Random sample consensus; Random sample consensus (RANSAC) algorithm; Scale invariant feature transforms; SIFT algorithms; Image registration",2-s2.0-85026741879
"Rubio Y., Montiel O., Sepúlveda R.","Cellular automata enhanced quantum inspired edge detection",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030691203&doi=10.1007%2f978-3-319-67137-6_15&partnerID=40&md5=322a261f33143b3b9e7e3debd6c23447","The developing of techniques for image processing based on quantum-inspired algorithms is a recent subject of study with promising results. Quantum-inspired edge detecting algorithms are a novel approach to detect fine details, especially in medical images. Since quantum inspired algorithms based on quantum measurement are susceptible to some noise related to their probabilistic nature their output can be degraded. This work proposes a quantum-inspired edge detection algorithm with an enhancement stage using cellular automata to reduce the degradation of the detected edges. The proposed method uses gradient operators applied to grayscale images that will be the input for a quantum-inspired measurement stage. After the measurement, a cellular automaton is used to eliminate noise and to obtain thinner edges. Comparative results are presented. © Springer International Publishing AG 2018.","Cellular automata; Edge detection; Image enhancement; Quantum inspired; Quantum measurement","Cellular automata; Image enhancement; Image processing; Medical imaging; Edge detecting algorithm; Edge detection algorithms; Gradient operators; Gray-scale images; Quantum inspired; Quantum measurement; Edge detection",2-s2.0-85030691203
"Wang S., Jian G., Wang J., Sun L., Wen J.","Application of entransy-dissipation-based thermal resistance for performance optimization of spiral-wound heat exchanger",2018,"International Journal of Heat and Mass Transfer",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029692859&doi=10.1016%2fj.ijheatmasstransfer.2017.09.061&partnerID=40&md5=be14c754b4050510a88935afcd8bf6a6","The effects of geometrical parameters on thermal resistance based on entransy dissipation caused by heat transfer (Rht) and fluid friction (Rff) of spiral-wound heat exchanger (SWHE) were studied by numerical method. The simulation results show that all geometrical parameters (spiral angle, external diameter, layer pitch, tube pitch) are negatively correlated with Rff because of flow pattern transition caused by the variation of geometrical parameters and the changing of effective flow area which would cause the decrease of entransy dissipation related to fluid friction. For the entransy dissipation due to the heat transfer, the increase of layer pitch are positive to it while both the tube pitch and external tube diameter are negative to Rht, and with the increase of the spiral angle, the Rht decrease at first and then increase. What is more, the MOGA optimization of SWHE was carried out based on different types of objective functions. Compared with the traditional objective functions (minimize ΔP and maximize K), Rff and Rht obtained from minimizing the entransy-dissipation-based thermal resistance reduce by an average of 90.51% and 34.13%, respectively. Compared with original structure, the comprehensive performance evaluation factor (Nu/f1/3) of traditional optimal results is improved by an average of 41.02%, while that of optimal structures obtained from entransy theory is strengthened by an average of 76.64%. The results demonstrate that the objective functions of minimizing the entransy-dissipation-based thermal resistance are better than that of traditional objective functions for optimization of spiral wound heat exchanger. © 2017 Elsevier Ltd","Entransy theory; Entransy-dissipation-based thermal resistance; Multi-Objective Genetic Algorithm; Optimization; Spiral-wound heat exchanger","Flow patterns; Friction; Genetic algorithms; Geometry; Heat resistance; Heat transfer; Numerical methods; Optimization; Structural optimization; Comprehensive performance evaluation; Entransy; Entransy dissipation; Entransy-dissipation-based thermal resistances; Flow pattern transition; Multi-objective genetic algorithm; Performance optimizations; Spiral wound; Heat exchangers",2-s2.0-85029692859
"Chon K.-W., Kim M.-S.","SSDMiner: A Scalable and Fast Disk-Based Frequent Pattern Miner",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032467262&doi=10.1007%2f978-981-10-6520-0_11&partnerID=40&md5=cf004b37b0012ee5f5f38bd21fa25fec","Frequent itemset mining is widely used as a fundamental data mining technique. Recently, there have been proposed a number of disk-based methods. However, the existing methods still do not have a good scalability due to large-scale intermediate data and non-trivial disk I/Os. We propose SSDMiner, a new fast and scalable disk-based method for frequent itemset mining that is based on Apriori-like method and has no intermediate data and small disk I/O overheads by exploiting SSD. We propose a concept of bitmap chunks for storing transactional database in disks and a fast support counting based on bitmap chunks. Through experiments, we demonstrate that SSDMiner has the enhanced scalability and the good performance similar to that in memory-based methods with robustness. © 2018, Springer Nature Singapore Pte Ltd.","Disk-based algorithm; Frequent pattern mining; Scalable algorithm; SSD","Database systems; Scalability; Disk I/O; Disk-based; Disk-based algorithm; Frequent itemset mining; Frequent pattern mining; Non-trivial; Scalable algorithms; Transactional database; Data mining",2-s2.0-85032467262
"Pulshashi I.R., Bae H., Choi H., Mun S.","Smoothing of Trajectory Data Recorded in Harsh Environments and Detection of Outlying Trajectories",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032473202&doi=10.1007%2f978-981-10-6520-0_10&partnerID=40&md5=5038c84f921c2a075147233edf1bf80f","The existence of an outlying trajectory, which is a trajectory that contains significant noise, can affect the quality of the movement analysis result. However, some outlying trajectories are repairable by detection and removal of noise. We propose trajectory-smoothing algorithms for automatic outlying trajectory repair, followed by application of various outlier detection algorithms to redetect outlying trajectories from among the smoothed trajectories. Our proposed approach was validated in a case study using real-life trajectories from a shipyard in South Korea. © 2018, Springer Nature Singapore Pte Ltd.","GPS; Movement analysis; Outlier detection; Shipyard; Smoothing trajectory","Data handling; Global positioning system; Motion analysis; Quality control; Ships; Shipyards; Statistics; Harsh environment; Movement analysis; Outlier Detection; Outlier detection algorithm; Smoothing algorithms; South Korea; Trajectory data; Trajectories",2-s2.0-85032473202
"Baskar A., Gireesh Kumar T.","Facial expression classification using machine learning approach: A review",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021196620&doi=10.1007%2f978-981-10-3223-3_32&partnerID=40&md5=727dc17b597d349e1c68b6485f0bcce1","Automatic Facial Expression analysis has enthralled increasing attention in the research community in excess of two decades and its expedient in many application like, face animation, customer satisfaction studies, human-computer interaction and video conferencing. The precisely classifying different emotion is an essential problem in facial expression recognition research. There are several machine learning algorithms applied to facial expression recognition expedition. In this paper, we surveyed three different machine learning algorithms such as Bayesian Network, Hidden Markov Model and Support Vector machine and we attempt to answer following questions: How classification algorithm used its characteristics for emotion recognition? How various parameters in learning algorithm is devoted for better classification? What are the robust features used for training? Finally, we examined how advances in machine learning technique used for facial expression recognition?. © Springer Nature Singapore Pte Ltd. 2018.","Bayesian network; Deep belief network; Facial expression; Hidden markov model; Machine learning; Support vector machine","Artificial intelligence; Bayesian networks; Customer satisfaction; Deep learning; Education; Face recognition; Hidden Markov models; Human computer interaction; Intelligent computing; Learning systems; Markov processes; Support vector machines; Video conferencing; Automatic facial expression analysis; Classification algorithm; Deep belief networks; Facial expression classification; Facial expression recognition; Facial Expressions; Machine learning approaches; Machine learning techniques; Learning algorithms",2-s2.0-85021196620
"Dalal V., Malik L.","Semantic graph based automatic text summarization for hindi documents using particle swarm optimization",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028421290&doi=10.1007%2f978-3-319-63645-0_31&partnerID=40&md5=90e6604d7abfaab1b9b43c50760ec2b2","Automatic text summarization can be defined as a process of extracting and describing important information from given document using computer algorithms. A number of techniques have been proposed by researchers in the past for summarization of English text. Automatic summarization of Indian text has received a very little attention so far. In this paper, we propose an approach for summarizing Hindi text based on semantic graph of the document using Particle Swarm Optimization (PSO) algorithm. PSO is one of the most powerful bio-inspired algorithms used to obtain optimal solution. The subject-object-verb (SOV) triples are extracted from the document. These triples are used to construct semantic graph of the document. A classifier is trained using PSO algorithm which is then used to generate semantic sub-graph and to obtain document summary. © Springer International Publishing AG 2018.","Bio-inspired algorithms; PSO; Semantic graph; Text mining; Text summarization","Data mining; Graphic methods; Intelligent systems; Natural language processing systems; Optimization; Semantics; Text processing; Automatic summarization; Automatic text summarization; Bio-inspired algorithms; Particle swarm optimization algorithm; Semantic graphs; Subject object verbs (SOV); Text mining; Text summarization; Particle swarm optimization (PSO)",2-s2.0-85028421290
"Gadamer M., Horzyk A.","Biologically inspired linguistic habit graph networks used for text correction",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028725655&doi=10.1007%2f978-3-319-66905-2_27&partnerID=40&md5=1701b57dda46c72ff8ca0ebcba1d8c11","This paper describes a biologically inspired Linguistic Habit Graphs (LHG) which could be used as a new way of storing, compressing, and processing sentences. The common letter and word orders from sentences are used to construct a special neural graph that is able to associate and memorize the natural human linguistic habits. The used algorithms can learn from texts written by people and transform the information of orders, frequencies, and contexts into a graph structure, labeled vertices with word properties, and weighted connections. Vertices of this graph are reactive to input data as well as neurons in biological brains. The way in which the human brain works is an inspiration for many known algorithms from contemporary computer science. In the brain, there is no time and no place for nested loops and other time consuming classic algorithms and computational techniques. Based on this approach, we developed new algorithms. They use a graph structure to perform a semi–automatic spell checking and text correction. The above mentioned functionalities of this model are always available in constant time. © 2018, Springer International Publishing AG.","Biological neural networks; Biology–inspired computing; Context–based inference; Linguistic Habit Graphs; Nature–inspired algorithms; NLP","Biocybernetics; Bioinformatics; Biomedical engineering; Biophysics; Graphic methods; Inference engines; Linguistics; Neural networks; Biological neural networks; Biologically inspired; Classic algorithm; Computational technique; Constant time; Graph networks; Graph structures; Spell-checking; Graph theory",2-s2.0-85028725655
"Rajak C.K., Mishra A.","Implementation of modified TEA to enhance security",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028396941&doi=10.1007%2f978-3-319-63673-3_46&partnerID=40&md5=1a1e85080ec6e062718e95c42dc5f1fc","Tiny Encryption Algorithm (TEA) is one of the fastest Encryption Algorithms. It is a lightweight cryptographic algorithm with minimal source code. Due to its simple logic in key scheduling TEA has suffered from related key and equivalent key attacks. Therefore a modified key schedule is proposed for TEA. The new key schedule applies Boolean function based SBox to generate different round keys for TEA. The resultant Modified TEA achieves better security than original TEA. The execution time analysis of modified TEA is also presented. © 2018, Springer International Publishing AG.","Enhanced TEA; Lightweight cryptography; Modified TEA; Real-time encryption; SBox design; Tiny encryption algorithm (TEA)","Boolean functions; Intelligent systems; Enhanced TEA; Light-weight cryptography; Modified TEA; Real time encryption; S-box design; Tiny Encryption algorithms; Cryptography",2-s2.0-85028396941
"Miriyala S.S., Subramanian V., Mitra K.","TRANSFORM-ANN for online optimization of complex industrial processes: Casting process as case study",2018,"European Journal of Operational Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020382151&doi=10.1016%2fj.ejor.2017.05.026&partnerID=40&md5=61f6e1ea7a33956cdf4c36b40761a4ae","Artificial Neural Networks (ANNs) are well known for their credible ability to capture non-linear trends in scientific data. However, the heuristic nature of estimation of parameters associated with ANNs has prevented their evolution into efficient surrogate models. Further, the dearth of optimal training size estimation algorithms for the data greedy ANNs resulted in their overfitting. Therefore, through this work, we aim to contribute a novel ANN building algorithm called TRANSFORM aimed at simultaneous and optimal estimation of ANN architecture, training size and transfer function. TRANSFORM is integrated with three standalone Sobol sampling based training size determination algorithms which incorporate the concepts of hypercube sampling and optimal space filling. TRANSFORM was used to construct ANN surrogates for a highly non-linear industrially validated continuous casting model from steel plant. Multiobjective optimization of casting model to ensure maximum productivity, maximum energy saving and minimum operational cost was performed by ANN assisted Non-dominated Sorting Genetic Algorithms (NSGA-II). The surrogate assisted optimization was found to be 13 times faster than conventional optimization, leading to its online implementation. Simple operator's rules were deciphered from the optimal solutions using Pareto front characterization and K-means clustering for optimal functioning of casting plant. Comprehensive studies on (a) computational time comparisons between proposed training size estimation algorithms and (b) predictability comparisons between constructed ANNs and state of art statistical models, Kriging Interpolators adds to the other highlights of this work. TRANSFORM takes physics based model as the only input and provides parsimonious ANNs as outputs, making it generic across all scientific domains. © 2017 Elsevier B.V.","Artificial Intelligence; Multiple objective programming; Neural Networks; Online optimization; Surrogate models","Artificial intelligence; Continuous casting; Energy conservation; Genetic algorithms; Interpolation; Mathematical transformations; Multiobjective optimization; Neural networks; Steelmaking; Complex industrial process; Conventional optimization; Estimation of parameters; Multiple objective programming; Non dominated sorting genetic algorithm (NSGA II); Online optimization; Surrogate model; Surrogate-assisted optimizations; Optimization",2-s2.0-85020382151
"Hrabuska R., Cedivodova V., Prauzek M., Hlavica J., Konecny J.","Electrical impedance distribution in human torax: A modeling framework",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031411597&doi=10.1007%2f978-3-319-68321-8_53&partnerID=40&md5=84592ecb76627f91b7d96299322e426f","Electrical impedance tomography (EIT) is an imaging system suitable for long-term monitoring. To extend current uses of EIT, improvements in the image reconstruction algorithms are essential. New image reconstruction methods for EIT can be tested on an impedance model of human body. Moreover, accurate anatomical impedance distribution models of human body are used to generate training data used in machine learning algorithms. Simulation framework, introduced in this paper, is capable of autonomous conversion of Computed tomography (CT) scans from DICOM format into 2D MESH human thorax impedance distribution model. Developed impedance models of large thorax structures achieve accurate results through segmentation of CT images and Fourier Fitting. Framework is developed in MATLAB as an extension to EIDORS and NETGEN frameworks. © Springer International Publishing AG 2018.","EIDORS; Electrical impedance tomography; Mesh framework; Thorax impedance model","Electric impedance; Electric impedance measurement; Electric impedance tomography; Image enhancement; Image processing; Image reconstruction; Image segmentation; Learning algorithms; Learning systems; MATLAB; Mesh generation; Network function virtualization; Tomography; Computed tomography scan; EIDORS; Electrical impe dance tomography (EIT); Electrical impedance tomography; Image reconstruction algorithm; Image reconstruction methods; Impedance modeling; Mesh framework; Computerized tomography",2-s2.0-85031411597
"Lei X., Zhang Y., Cheng S., Wu F.-X., Pedrycz W.","Topology potential based seed-growth method to identify protein complexes on dynamic PPI data",2018,"Information Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031784662&doi=10.1016%2fj.ins.2017.10.013&partnerID=40&md5=65d9f908acecfedd9b16d0b2ab72f395","Protein complexes are very important for investigating the characteristics of biological processes. Identifying protein complexes from protein–protein interaction (PPI) networks is one of the recent research endeavors. The critical step of the seed-growth algorithms used for identifying protein complexes from PPI networks is to detect seed nodes (proteins) from which protein complexes are growing up in PPI networks. Topology potential was proposed to understand the evolution behavior and organizational principles of complex networks such as PPI networks. Furthermore, PPI networks are inherently dynamic in nature. In this study, we proposed a new seed-growing algorithm (called TP-WDPIN) for identifying protein complexes, which employs the concept of topology potential to detect significant proteins and mine protein complexes from Weighted Dynamic PPI Networks. To investigate the performance of the method, the TP-WDPIN algorithm was applied to four PPI databases and compared the obtained results to those produced by six other competing algorithms. Experimental results have demonstrated that the proposed TP-WDPIN algorithm exhibits better performance than other methods such as MCODE, MCL, CORE, CSO, ClusterONE, COACH when experimenting with four PPI databases (DIP, Krogan, MIPS, Gavin). © 2017 Elsevier Inc.","Dynamic PPI network; Protein complexes; Seed-growth algorithm; Topology potential","Biology; Proteins; Topology; Biological process; Competing algorithms; Evolution behavior; Organizational principles; Ppi networks; Protein complexes; Protein interaction; Seed growths; Complex networks",2-s2.0-85031784662
"Długosz M., Deorowicz S., Kokot M.","Improvements in DNA reads correction",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030758026&doi=10.1007%2f978-3-319-67792-7_12&partnerID=40&md5=a87be335e3f7a89cdaa1f368fb1977d9","We introduce an improved version of RECKONER, an error corrector for Illumina whole genome sequencing data. By modifying its workflow we reduce the computation time even 10 times. We also propose a new method of determination of k-mer length, the key parameter of k-spectrum-based family of correctors. The correction algorithms are examined on huge data sets, i.e., human and maize genomes for both Illumina HiSeq and MiSeq instruments. © 2018, Springer International Publishing AG.","Algorithm parallelization; High-throughput sequencing; Read error correction; Sequencing reads simulation","Error correction; Computation time; Correction algorithms; High-throughput sequencing; Illumina; Maize genome; Parallelizations; Sequencing reads simulation; Whole genome sequencing; Genes",2-s2.0-85030758026
"Srivastava S., Singh S.","Performance optimization in cloud computing through cloud partitioning-based load balancing",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031397780&doi=10.1007%2f978-981-10-3773-3_30&partnerID=40&md5=9067f900c9e139d8f6cf75381ec403cf","Cloud computing is one of the today’s largest hearing fields and exciting technologies, because it is flexible and scalable, also it reduces the cost and complexity of applications. Consequently, arises the concept of large scale computing where there is geographical distribution of data centres and end users all across the globe. Thus, it becomes challenging issue for these data centres how to efficiently handle the huge number of incoming requests from different user bases. So, evaluation of performance of the cloud and its proper analysis is of utmost importance, so that the users can take right decisions. One of the very important issues in association with this domain is that of load balancing. The major object of algorithms concerned with balancing of load is how to efficiently designate the task to nodes, such that the overall response time of request is reduced and processing of request is brought about effectively. Thus, in this paper we have integrated the concept of Cloud partitioning along with the central load balancing algorithm so as to balance the load effectively. Due to the existence of partitions in the system, it is possible to apply good load balancing strategy and use optimal algorithms based on the state of the partition. We have carried out the implementation and simulation of our proposed work on CloudSim simulator. Thus, the task execution is done effectively and the results are better for the proposed modified central load balancing algorithm as compared to previous algorithm in large scale cloud computing environment. © Springer Nature Singapore Pte Ltd. 2018.","Cloud computing; Data centre; Load balancing; Virtual machine","Audition; Cloud computing; Geographical distribution; Network function virtualization; Resource allocation; Virtual machine; Cloud computing environments; Data centres; Large-scale computing; Load balancing algorithms; Load balancing strategy; Optimal algorithm; Performance optimizations; Task executions; Optimization",2-s2.0-85031397780
"Gaxiola F., Melin P., Valdez F., Castro J.R.","Optimization of deep neural network for recognition with human iris biometric measure",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030671092&doi=10.1007%2f978-3-319-67137-6_19&partnerID=40&md5=6a86047a75de665da0a34d68ba8fe3c0","In this paper an optimization approach with genetic algorithms for a deep neural network is applied. We optimize some parameters for the deep neural network that allowed optimize the results of the recognition of persons, like the number of neurons in the first and second hidden layer, and others. We work with the human iris like the biometric measure for the recognition of persons. Before give like input the human iris images to the deep neural network, pre-processing methods for eliminate the noise around the iris are applied. The proposed optimization allowed to the deep neural network increase the performance of recognition. © Springer International Publishing AG 2018.","Deep neural network; Genetic algorithm; Human iris; Person recognition","Biometrics; Genetic algorithms; Optimization; Hidden layers; Human Iris; Optimization approach; Person recognition; Pre-processing method; Deep neural networks",2-s2.0-85030671092
"Fu Z., Shen L., Cheng B.","A protection strategy of microgrid based on EtherCAT",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030860055&doi=10.1007%2f978-981-10-6496-8_48&partnerID=40&md5=d6da6259cca27354ad317c18c0d79b01","This paper proposes a protection scheme of microgrid and it is based on EtherCAT communication protocol. There are two algorithms in this scheme. One is used to detect fault, and it is based on superposition theorem. The other one is used to locate and eliminate the fault. In order to verify the correctness of the algorithm which is used to detect fault, a simulation model in MATLAB is established. Use the topology’s information of microgrid and fault’s information to construct matrix, then complete the work about locating fault and eliminating fault by matrix operation. In this paper, the advantages of EtherCAT communication protocol are discussed, and the primary design of master station and slave station is carried out. Lay the foundation for detailed design of microgrid protection system. © 2018, Springer Nature Singapore Pte Ltd.","EtherCAT; Fault detection; Fault location; Matrix algorithm; Microgrid protection","Electric fault location; Intelligent systems; MATLAB; EtherCAT; Matrix algorithms; Matrix operations; Microgrid protections; Protection schemes; Protection strategy; Simulation model; Superposition theorem; Fault detection",2-s2.0-85030860055
"Kureichik L., Kureichik V., Jr., Kureichik V., Leschanov D., Zaruba D.","Hybrid approach for VLSI fragments placement",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031418512&doi=10.1007%2f978-3-319-68321-8_36&partnerID=40&md5=0ac5db180bc0768773bb038c94d0b7db","The paper considers one of the most important problem in the design field – VLSI fragments placement within restricted construction area. The VLSI fragments placement problem is NP-hard and complex problem. In the work there are presented a description of the placement problem and transition from a circuit diagram to a graph model. To reduce dimension of the problem the authors suggest a hybrid approach based on two fractals aggregation and genetic search methods. As well as there is developed a genetic algorithm that allows to obtain sets quazi-optimal solutions during polynomial time. To confirm the effectiveness of the suggested approach there is shown an example of the VLSI fragments placement solution, developed software and computational experiment. Conducted tests and experiments approve promising of the suggested approach, a time complexity of developed algorithms is represented in the best case as ≈O(nlogn), in the worst case - O(n3). © Springer International Publishing AG 2018.","Design; Fractals aggregation; Genetic algorithm; Hybrid approach; VLSI","Computational complexity; Design; Fractals; Genetic algorithms; Polynomial approximation; Polynomials; Circuit diagrams; Complex problems; Computational experiment; Hybrid approach; Optimal solutions; Placement problems; Time complexity; VLSI; VLSI circuits",2-s2.0-85031418512
"Melin P., Prado-Arechiga G.","Neuro-fuzzy modular approaches for classification of arterial hypertension with a method for the expert rules optimization",2018,"SpringerBriefs in Applied Sciences and Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021758922&doi=10.1007%2f978-3-319-61149-5_4&partnerID=40&md5=4d44d6858e54daf4fcb68dabcc503f02","A Neuro fuzzy hybrid model (NFHM) is used as a new Artificial Intelligence method to classify high blood pressure (HBP). The NFHM uses techniques such as: neural networks, fuzzy logic and evolutionary computation, in the last technique genetic algorithms (GAs) are used. The objective is to model the behavior of blood pressure based on monitoring data of 24Â h per patient and to obtain the trend, which is classified using a fuzzy system based on rules given by an expert, these rules were optimized by a genetic algorithm to obtain the best possible number of rules for the classifier with the lowest classification error. Results are presented to show the advantage of the proposal model. © 2018, The Author(s).","Blood pressure; Fuzzy logic; Genetic algorithms; Neural networks","Blood pressure; Computation theory; Computer circuits; Fuzzy inference; Fuzzy neural networks; Genetic algorithms; Neural networks; Optimization; Arterial hypertension; Artificial intelligence methods; Classification errors; Genetic algorithm (GAs); High blood pressures; Hybrid model; Modular approach; Neural networks , fuzzy logic; Fuzzy logic",2-s2.0-85021758922
"Lu X., Kuzmin K., Chen M., Szymanski B.K.","Adaptive modularity maximization via edge weighting scheme",2018,"Information Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030665587&doi=10.1016%2fj.ins.2017.09.063&partnerID=40&md5=a932b0ccb9f7d39dfb95f8bd690164c2","Modularity maximization is one of the state-of-the-art methods for community detection that has gained popularity in the last decade. Yet it suffers from the resolution limit problem by preferring under certain conditions large communities over small ones. To solve this problem, we propose to expand the meaning of the edges that are currently used to indicate propensity of nodes for sharing the same community. In our approach this is the role of edges with positive weights while edges with negative weights indicate aversion for putting their end-nodes into one community. We also present a novel regression model which assigns weights to the edges of a graph according to their local topological features to enhance the accuracy of modularity maximization algorithms. We construct artificial graphs based on the parameters sampled from a given unweighted network and train the regression model on ground truth communities of these artificial graphs in a supervised fashion. The extraction of local topological edge features can be done in linear time, making this process efficient. Experimental results on real and synthetic networks show that the state-of-the-art community detection algorithms improve their performance significantly by finding communities in the weighted graphs produced by our model. © 2017 Elsevier Inc.","Community detection; Modularity maximization; Regularization; Scalability","Population dynamics; Regression analysis; Scalability; Community detection; Community detection algorithms; Maximization algorithm; Regularization; Resolution limits; State-of-the-art methods; Synthetic networks; Topological features; Topology",2-s2.0-85030665587
"Zhou H., Ji T., Wang R., Ge X., Tang X., Tang S.","Multipath ultrasonic gas flow-meter based on multiple reference waves",2018,"Ultrasonics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031999463&doi=10.1016%2fj.ultras.2017.07.010&partnerID=40&md5=f8c36655ae14e96dcd1c5de707160d19","Several technologies can be used in ultrasonic gas flow-meters, such as transit-time, Doppler, cross-correlation and etc. In applications, the approach based on measuring transit-time has demonstrated its advantages and become more popular. Among those techniques which can be applied to determine time-of-flight (TOF) of ultrasonic waves, including threshold detection, cross correlation algorithm and other digital signal processing algorithms, cross correlation algorithm has more advantages when the received ultrasonic signal is severely disturbed by the noise. However, the reference wave for cross correlation computation has great influence on the precise measurement of TOF. In the applications of the multipath flow-meters, selection of the reference wave becomes even more complicated. Based on the analysis of the impact factors that will introduce noise and waveform distortion of ultrasonic waves, an averaging method is proposed to determine the reference wave in this paper. In the multipath ultrasonic gas flow-meter, the analysis of each path of ultrasound needs its own reference wave. In case study, a six-path ultrasonic gas flow-meter has been designed and tested with air flow through the pipeline. The results demonstrate that the flow rate accuracy and the repeatability of the TOF are significantly improved by using averaging reference wave, compared with that using random reference wave. © 2017 Elsevier B.V.","Averaging method; Cross correlation; Multipath ultrasonic flow-meter; Reference wave; Transit-time method","Correlation detectors; Digital signal processing; Flow measurement; Flow of gases; Gas meters; Signal processing; Stress intensity factors; Ultrasonic applications; Ultrasonic waves; Averaging method; Cross correlations; Cross-correlation algorithm; Digital signal processing algorithms; Precise measurements; Reference waves; Transit time method; Waveform distortions; Flowmeters",2-s2.0-85031999463
"Devaraj D., Prasanna Kumar S.C.","Robust detection of hard exudates for diagnosis of non-proliferative diabetic retinopathy using integrated approach",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028607898&doi=10.1007%2f978-3-319-60618-7_52&partnerID=40&md5=2aca200666e206473d29bf057d366dbf","Diabetic retinopathy is seen in an individual suffering from diabetes for a long time. It is one of the main driving reasons for blindness. The severity of the disease will increase if it is not detected in the early stages. There will be formation of lesions in retina due to diabetes. Exudates are formed when the lipid is leaked from the retinal blood vessels. Exudates appear in the moderate stage of Diabetic retinopathy. Detection of exudates is an important step in the diagnosis of Non-proliferative diabetic retinopathy. The detection can be achieved by using the image processing algorithms. This paper deals with the usage of modified morphology algorithm which addresses the interference of the optic disc prior to the detection of exudates. The features of the detected exudates are then extracted and are fed to Support Vector machine to get the result. A Graphical user interface is created which helps in ease of usage of the computer aided algorithm. The sensitivity, specificity and accuracy achieved are 92.40%, 100% and 95.16% respectively for retinal images from standard databases and hospitals. © Springer International Publishing AG 2018.","Diabetic retinopathy; Entropy; Exudates; Morphology; Optic disc; Perimeter; Support vector machine","Blood vessels; Diagnosis; Entropy; Graphical user interfaces; Image processing; Morphology; Ophthalmology; Optical data processing; Pattern recognition; Soft computing; Support vector machines; User interfaces; Diabetic retinopathy; Exudates; Image processing algorithm; Integrated approach; Morphology algorithms; Optic disc; Perimeter; Retinal blood vessels; Eye protection",2-s2.0-85028607898
"Ma X., Chen X., Li X., Ding C., Wang Y.","Sustainable station-level planning: An integrated transport and land use design model for transit-oriented development",2018,"Journal of Cleaner Production",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031894773&doi=10.1016%2fj.jclepro.2017.09.182&partnerID=40&md5=a80630d8a417b0af3151bb4b024a3e23","Urban rail transit system in China has been rapidly constructed in response to the effects of urbanization, such as severe urban congestion and excessive air pollution. The sustainable land use planning (i.e. transit-oriented development, TOD) around the subway stations is important for the rail transit system because of its long-term influence on travel demand. However, there are limited studies that focus on the station level TOD planning. In this context, the aim of this study is to propose a multi-objective programming model that integrates transport and land use design for station-level TOD planning. In this study, one subway station in Beijing City is taken as the case, considering the unique features of urban development (e.g. high density and diversity), five objectives are taken to account in our model, including rail transit ridership, compactness, accessibility, conflict degree, and environmental effects. Meanwhile, an improved immune-genetic based algorithm is designed to obtain the optimal solutions under alternative land use schemes. The model results show that the proposed algorithm is superior to conventional genetic algorithms. This study is hoped to provide sustainable station-level planning for urban planning decision-makers. © 2017 Elsevier Ltd","Genetic algorithm; Land use; Sustainable development; Transit-oriented development","Decision making; Genetic algorithms; Light rail transit; Mass transportation; Motor transportation; Multiobjective optimization; Pollution control; Railroad traffic control; Railroads; Subway stations; Sustainable development; Transportation; Urban growth; Integrated transport; Multiobjective programming; Optimal solutions; Rail transit systems; Sustainable land use; Transit oriented development; Transport and land use; Urban rail transit systems; Land use",2-s2.0-85031894773
"Tziroglou G., Vafeiadis T., Ziogou C., Krinidis S., Voutetakis S., Tzovaras D.","Incident detection in industrial processes utilizing machine learning techniques",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028609231&doi=10.1007%2f978-3-319-64465-3_5&partnerID=40&md5=2b9ab45f7b774c4fe684deee7cb3906c","This work provides a comparative analysis of the most popular and widely used classification algorithms applied in industrial processes, in order to tackle the issue of incident detection of abnormal situations. The proposed analysis is based on actual datasets from derived by the operation of a chemical process system situated at the premises of CERTH/CPERI. The evaluation of the tested methods is based on cross-validation using a series of Monte-Carlo simulations among several free parameters of tested classifiers and finally the application of the Adaptive Boosting technique. The experimental results are highly reliable as the accuracy reaches 98% and the F-measure metric achieves a score over 97%. Therefore, the detection of potential malfunctions is achieved using the proposed machine learning techniques. © Springer International Publishing AG 2018.","AdaBoost; Incident detection; Machine learning techniques","Adaptive boosting; Artificial intelligence; Chemical analysis; Intelligent systems; Learning algorithms; Maintenance; Monte Carlo methods; Production; Chemical process systems; Classification algorithm; Comparative analysis; Cross validation; Free parameters; Incident detection; Industrial processs; Machine learning techniques; Learning systems",2-s2.0-85028609231
"Kong L., Pan J.-S., Chu S.-C., Roddick J.F.","Relay Node Selection Strategy for Wireless Sensor Network",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030838435&doi=10.1007%2f978-3-319-68527-4_25&partnerID=40&md5=75352fa6dd0fba9e7817b8b81b78c609","In the past few years, people have experienced advanced interest in the potential use of wireless sensor network in applications such as environment surveillance, military field protection and medical treatment. Usually hundreds even thousands of sensors are scattered randomly in remote environment. In generally, for the scalability of sensor network, cluster techniques are often used to group nodes into several sets. And in this paper, we proposed a new method called GF_CENTER to select the positions of centers, which is also a kind of k-center problem. And a new fitness function is presented for optimize the resolution. We compare our method with two other algorithms. GF_CENTER method minimizes the number of centers in the network. From the experiments, GF_CENTER find smaller number of centers than the other methods, which lower the construction fee of network. © 2018, Springer International Publishing AG.","Farthest first traversal; Genetic algorithm; Wireless sensor network","Data handling; Genetic algorithms; Information analysis; Military applications; Sensor nodes; Farthest first traversal; Fitness functions; K-center problem; Medical treatment; Military fields; Number of centers; Relay node selections; Remote environment; Wireless sensor networks",2-s2.0-85030838435
"Barolli A., Oda T., Ikeda M., Matsuo K., Barolli L., Takizawa M.","A GA-based simulation system for WMNs: Performance analysis for different WMN architectures considering weibull distribution, HWMP and TCP protocols",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026310942&doi=10.1007%2f978-3-319-61566-0_2&partnerID=40&md5=dcb14b17a5baa3c1569c32f449d963a6","In our previous work, we implemented WMN-GA system which is based on Genetic Algorithms (GAs) and used it for node placement problem in WMNs. In this paper, we evaluate the performance of Weibull distribution of mesh clients for two WMN architectures considering PDR, throughput, delay, fairness index and energy metrics. For simulations, we used ns-3, Hybrid Wireless Mesh Protocol (HWMP) and TCP. We compare the performance of both architectures. The simulation results show that the PDR for both WMN architectures is almost the same. The throughput of I/B WMN is a little bit higher than Hybrid WMN. The delay of Hybrid WMN is lower than I/B WMN. The fairness index and the remaining energy for both WMN architectures are almost the same. © Springer International Publishing AG 2018.",,"Genetic algorithms; Mesh generation; MESH networking; Transmission control protocol; Weibull distribution; Energy metrics; Fairness index; Genetic algorithm (GAs); Hybrid wireless mesh protocols (HWMP); Node placement problems; Performance analysis; Remaining energies; Simulation systems; Network architecture",2-s2.0-85026310942
"Yemelyanov A., Yemelyanov A.","Applying SSAT in computer-based analysis and investigation of operator errors",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021844253&doi=10.1007%2f978-3-319-60642-2_31&partnerID=40&md5=2b125b14ee902ef135310a49dbf6d0a7","Through the vision of the systemic-structural activity theory, a method of modeling human operator performance in complex systems, realized as a DSS, is presented. It allows to conduct a detailed analysis of an operator’s performance to observe the nature of his errors in different stages of his control action: the perception of a problem, the motivation for solving it, the evaluation of variants of a solution; then, making a decision and subsequently implementing it. This method provides a deeper analysis of underlying factors using the general model of activity self-regulation, along with the proposed frame descriptions for errors with logical, decision-making, and classification algorithms. The specific feature of the suggested approach is that it presents the opportunity to provide a comprehensive functional analysis of erroneous actions and their underlying factors in the process of collecting data on them, instead of following the traditional approach of drawing conclusions from investigation reports. © Springer International Publishing AG 2018.","Algorithms; Decision support system; Error analysis; Human operator; Modeling; Systemic-structural activity theory","Activity coefficients; Algorithms; Artificial intelligence; Decision support systems; Decision theory; Error analysis; Errors; Factor analysis; Models; Activity Theory; Classification algorithm; Computer-based analysis; Different stages; Human operator; Method of modeling; Traditional approaches; Underlying factors; Computer aided analysis",2-s2.0-85021844253
"Jarrah A., Al-Tamimi A.-K., Albashir T.","Optimized Parallel Implementation of Extended Kalman Filter Using FPGA",2018,"Journal of Circuits, Systems and Computers",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020210332&doi=10.1142%2fS0218126618500093&partnerID=40&md5=f49126dbbe797856af3aa4d22180ac64","There are enormous numbers of applications that require the use of tracking algorithms to predict the future states of a system according to its previous accumulated states. Thus, many efficient techniques are widely adopted to estimate the future states of a system at every point in time to get the desired performance levels. Kalman filter is a popular and an efficient method for online estimations for linear measurements. Extended Kalman Filter (EKF), on the other hand, is more suited for nonlinear measurements. However, EKF algorithm is well known to be computationally intensive, and may not achieve the strict requirements of real time applications. This issue has motivated researchers to consider the use of parallel processing platforms such as Field Programmable Gate Arrays (FPGAs) and Graphic Processing Units (GPUs) to meet the real time requirements. This paper provides an optimized parallel architecture for EKF using FPGA. Our approach exploits many optimization and parallel techniques such as pipelining, loop unrolling, dataflow, and inlining; and utilizes the inherently parallel architecture nature of FPGAs to accelerate the estimation process. Our experimental analyses show that our optimized implementation of EKF can achieve better results when compared to other implementations using GPU and multicore platforms. Moreover, higher performance levels can be achieved when operating on larger data sizes. This is due to our proposed optimization techniques that we have applied, and the exploited inherent parallelism among EKF operations. © 2018 World Scientific Publishing Company.","data modeling; data prediction; extended Kalman filter; field-programmable gate array (FPGA); high level synthesis tools (HLS Tools); optimization techniques; parallel architecture; time series analysis; Tracking algorithms","Bandpass filters; Data structures; Extended Kalman filters; Field programmable gate arrays (FPGA); Graphics processing unit; High level synthesis; Logic gates; Optimization; Parallel architectures; Program processors; Signal receivers; Time series analysis; Tracking (position); Data prediction; Graphic processing units (GPUs); Optimization techniques; Optimized implementation; Parallel implementations; Real time requirement; Real-time application; Tracking algorithm; Kalman filters",2-s2.0-85020210332
"Fang W., Haining L., Huazhong J., GuangBo L., Ou R.","A method for estimating the camera parameters based on vanishing points",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026313156&doi=10.1007%2f978-3-319-61566-0_45&partnerID=40&md5=00664aba592513947a1540c215765b84","This paper presented MMVD vanishing points detection algorithm which was inspired by multi-model estimation. It was operated in image pixel space, not parameter space. We first gave some vanishing points estimation model assumption based on the lines’ position and angle of each other. Then, the model assumption was used to construct the correlation matrix for line segments clustering and vanishing points estimation. Clustering algorithm produced vanishing points and they were refined by the EM algorithm to improve the accuracy. Experiments showed that the detection speed was good and the detection result can ensure good accuracy. © Springer International Publishing AG 2018.","Clustering; EM; Multi-model; Vanishing point","Computer programming; Computer science; Camera parameter; Clustering; Correlation matrix; Detection algorithm; Estimation models; Model assumptions; Multi model; Vanishing point; Clustering algorithms",2-s2.0-85026313156
"Ye X., Luo X.-G., Hu Y.-X., Lin M.","Multi controller software defined network link fault location based on tree decomposition method",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028392486&doi=10.1007%2f978-3-319-60744-3_44&partnerID=40&md5=8ae6a21dc030da7163c183158ae38736","In order to overcome the problem that the existing scheme is difficult to adapt to the network link additions and deletions to the situation, this paper proposes a link fault localization scheme based on tree decomposition. Firstly, a multi degree lossless image segmentation algorithm is proposed to divide the network into several independent sub networks. Secondly, the maximum width priority tree decomposition algorithm is proposed to generate multi loop in the sub graph. The average number of links and the total delay of the proposed algorithm are better than that of the genetic algorithm. Experiments show that the number of indicators such as static flows in the schema needed to be sent to the table and detection information needed to be sent to detect link faults is superior than the existing programs. © 2018, Springer International Publishing AG.","Decomposition tree; Image segmentation; Link fault locator; SDN","Forestry; Genetic algorithms; Intelligent systems; Real time systems; Software defined networking; Trees (mathematics); Average numbers; Decomposition trees; Detection informations; Fault localization; Fault locator; Image segmentation algorithm; Network links; Tree decomposition; Image segmentation",2-s2.0-85028392486
"Pio G., Serafino F., Malerba D., Ceci M.","Multi-type clustering and classification from heterogeneous networks",2018,"Information Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031801985&doi=10.1016%2fj.ins.2017.10.021&partnerID=40&md5=9a68e0abec0b221291b82a22690e4272","Heterogeneous information networks consist of different types of objects and links. They can be found in several social, economic and scientific fields, ranging from the Internet to social sciences, including biology, epidemiology, geography, finance and many others. In the literature, several clustering and classification algorithms have been proposed which work on network data, but they are usually tailored for homogeneous networks, they make strong assumptions on the network structure (e.g. bi-typed networks or star-structured networks), or they assume that data are independently and identically distributed (i.i.d.). However, in real-world networks, objects can be of multiple types and several kinds of relationship can be identified among them. Moreover, objects and links in the network can be organized in an arbitrary structure where connected objects share some characteristics. This violates the i.i.d. assumption and possibly introduces autocorrelation. To overcome the limitations of existing works, in this paper we propose the algorithm HENPC, which is able to work on heterogeneous networks with an arbitrary structure. In particular, it extracts possibly overlapping and hierarchically-organized heterogeneous clusters and exploits them for predictive purposes. The different levels of the hierarchy which are discovered in the clustering step give us the opportunity to choose either more globally-based or more locally-based predictions, as well as to take into account autocorrelation phenomena at different levels of granularity. Experiments on real data show that HENPC is able to significantly outperform competitor approaches, both in terms of clustering quality and in terms of classification accuracy. © 2017 Elsevier Inc.","Heterogeneous networks; Multi-type classification; Multi-type clustering","Autocorrelation; Heterogeneous networks; Information services; Arbitrary structures; Classification accuracy; Classification algorithm; Heterogeneous clusters; Heterogeneous information; Independently and identically distributed; Multi-type clustering; Type classifications; Clustering algorithms",2-s2.0-85031801985
"Seyfi B., Fatouraee N., Samani A.","A novel micro-to-macro structural approach for mechanical characterization of adipose tissue extracellular matrix",2018,"Journal of the Mechanical Behavior of Biomedical Materials",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029170563&doi=10.1016%2fj.jmbbm.2017.09.006&partnerID=40&md5=1d1c6bd9ce70a89bfc967f5b4d0e01c1","Mechanical characterization of adipose tissue micro-components is important for various biomedical applications such as tissue engineering and predicting adipose tissue response to forces involved in relevant medical intervention procedures (e.g. breast needle biopsy). For this characterization, we introduce a novel structural method for micromechanical modeling of the adipose tissue. The micromechanical model was developed using fluid-structure interaction (FSI) formulation. We utilized this model within an inverse problem framework to estimate the hyperelastic parameters of adipose tissue extracellular matrix (ECM). Using this framework, the ECM hyperelastic parameters were changed in the FSI model systematically using an optimization algorithm such that the mechanical response obtained from the FSI model matches the corresponding experimental response reported in previous studies. To account for adipocyte size variation, the hyperelastic parameters were determined for different adipocyte sizes in the FSI model. Results obtained in this investigation indicate that at various strains under quasi-static conditions, the stiffness of adipose tissue ECM is ~ (2–3) times higher than that of the adipose tissue. The results also indicate a very good fit between the FSI model responses and their experimental counterparts. This indicates the reliability of the proposed FSI model in capturing major elements of the adipose tissue micromechanics. As such, it is potentially useful in applications such as tissue engineering, estimating tissue deformation pertaining to medical intervention and cataloging the mechanical properties of adipose tissue under health and pathological conditions. It can also be utilized as a forward model for developing inversion algorithms designed to determine pathological adipose microstructural alterations. © 2017 Elsevier Ltd","Adipose tissue; Fluid-structure interaction; Mechanical properties; Microstructure","Biomechanics; Biopsy; Characterization; Composite micromechanics; Elasticity; Fluid structure interaction; Inverse problems; Matrix algebra; Mechanical properties; Medical applications; Microoptics; Microstructure; Molecular weight; Optimization; Tissue; Adipose tissue; Biomedical applications; Mechanical characterizations; Micro-mechanical modeling; Microstructural alterations; Optimization algorithms; Pathological conditions; Quasi-static conditions; Tissue engineering; fat droplet; adipocyte; adipose tissue; algorithm; animal tissue; Article; cell size; compression; elasticity; extracellular matrix; finite element analysis; fluid structure interaction model; macromechanical structure; mechanics; micromechanical structure; nonhuman; priority journal; process optimization; reliability; rigidity; structural model; structure analysis; tissue engineering; tissue interaction; tissue structure; validation process",2-s2.0-85029170563
"Abdelmohsen A.Z., El-Rayes K.","Optimizing the Planning of Highway Work Zones to Maximize Safety and Mobility",2018,"Journal of Management in Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032620279&doi=10.1061%2f%28ASCE%29ME.1943-5479.0000570&partnerID=40&md5=a974e93138b4570a5346394c65e435c7","Highway work zones create potential risks for both traffic and workers in addition to traffic congestion and delays that result in increased road user delay, traffic crashes, and vehicle emissions. The Federal Highway Administration (FHWA) and state departments of transportation (DOTs) are continuously seeking to improve work-zone safety and mobility. To accomplish this, the layout of highway work zones needs to be carefully planned and optimized to accomplish the multiple and often conflicting objectives of maximizing safety and mobility. This article presents the development of an innovative multiobjective optimization model to search for and identify a set of Pareto-optimal work-zone layouts that provide a wide range of optimal trade-offs between minimizing traffic delays and minimizing the probability of crashes. The model has four phases: (1) identify all relevant decision variables for work-zone layout, (2) formulate the optimization objective functions in the model, (3) define all relevant and practical constraints that affect the optimization problem, and (4) perform the model-optimization computations using multiobjective genetic algorithms. The performance of the developed optimization model was analyzed and verified using an application example of work-zone layout. The results of the analysis of this example illustrate the novel and unique capabilities of the developed model in searching for and identifying optimal work-zone layouts. These new and unique capabilities are expected to support state DOTs and construction planners in their ongoing efforts to maximize work-zone safety and reduce traffic delays in the work-zone area. © 2017 American Society of Civil Engineers.","Crash modification factor; Highway; Optimization; Safety; Traffic delay; Work-zone safety","Accident prevention; Accidents; Decision making; Economic and social effects; Genetic algorithms; Highway accidents; Highway administration; Highway planning; Motor transportation; Multiobjective optimization; Optimization; Pareto principle; Safety factor; Transportation; Highway; Modification factors; Multi-objective genetic algorithm; Multi-objective optimization models; Optimization objective function; State departments of transportations; Traffic delays; Work zone safety; Traffic congestion",2-s2.0-85032620279
"Deshmukh Amar B., Usha Rani N.","Face super resolution by tangential and exponential kernel weighted regression model",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028406827&doi=10.1007%2f978-3-319-63645-0_2&partnerID=40&md5=986cd115a8a8f0e30bbd2d17b887dd21","The need of recognizing individual from the low resolution non-frontal picture is hard hassle in video surveillance. In an effort to alleviate the hassle of popularity in low decision photograph, literature presents unique strategies for face recognition after converting the low decision photograph to excessive resolution. For this reason, this paper provides a method for multi-view face video notable decision using the tangential and exponential kernel weighted regression model. In this paper, a brand new hybrid kernel is proposed to carry out non-parametric kernel regression version for estimation of neighbor pixel within the first-rate decision after the face detection is done the usage of Viola-Jones algorithms. The experimentation is finished with the U.S. Face video databases and the quantitative results are analyzed the usage of the SDME with the prevailing strategies. From the result final results, we prove that the most SDME of 77.3db is obtained for the proposed approach compared with the existing techniques like, nearest interpolation, bicubic interpolation and bilinear interpolation. © Springer International Publishing AG 2018.","Face detection; Face video; Kernel; Second-derivative-like measure of enhancement (SDME); Super resolution; Viola-Jones algorithm","Intelligent systems; Interpolation; Optical resolving power; Photography; Regression analysis; Security systems; Face video; Kernel; Measure of enhancement; Super resolution; Viola - Jones algorithms; Face recognition",2-s2.0-85028406827
"Alickovic E., Kevric J., Subasi A.","Performance evaluation of empirical mode decomposition, discrete wavelet transform, and wavelet packed decomposition for automated epileptic seizure detection and prediction",2018,"Biomedical Signal Processing and Control",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026834393&doi=10.1016%2fj.bspc.2017.07.022&partnerID=40&md5=00652ad436efb2a2bbb53fb4893e03f9","This study proposes a new model which is fully specified for automated seizure onset detection and seizure onset prediction based on electroencephalography (EEG) measurements. We processed two archetypal EEG databases, Freiburg (intracranial EEG) and CHB-MIT (scalp EEG), to find if our model could outperform the state-of-the art models. Four key components define our model: (1) multiscale principal component analysis for EEG de-noising, (2) EEG signal decomposition using either empirical mode decomposition, discrete wavelet transform or wavelet packet decomposition, (3) statistical measures to extract relevant features, (4) machine learning algorithms. Our model achieved overall accuracy of 100% in ictal vs. inter-ictal EEG for both databases. In seizure onset prediction, it could discriminate between inter-ictal, pre-ictal, and ictal EEG with the accuracy of 99.77%, and between inter-ictal and pre-ictal EEG states with the accuracy of 99.70%. The proposed model is general and should prove applicable to other classification tasks including detection and prediction regarding bio-signals such as EMG and ECG. © 2017 Elsevier Ltd","Discrete wavelet transform (DWT); Electroencephalography (EEG); Empirical mode decomposition (EMD); Epilepsy; Multiscale PCA (MSPCA); Seizure detection and prediction; Wavelet packet decomposition (WPD)","Discrete wavelet transforms; Electroencephalography; Electrophysiology; Forecasting; Learning algorithms; Learning systems; Machine components; Principal component analysis; Wavelet analysis; Wavelet decomposition; Wavelet transforms; Empirical Mode Decomposition; Epilepsy; Multiscale PCA (MSPCA); Seizure detection; Wavelet packet decompositions; Signal processing; algorithm; Article; clinical article; electroencephalography; human; machine learning; measurement accuracy; principal component analysis; priority journal; seizure; wavelet analysis",2-s2.0-85026834393
"Wang B., Tang F., Liu H.","Spherical panorama stitching based on feature matching and optical flow",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031417522&doi=10.1007%2f978-981-10-6499-9_9&partnerID=40&md5=0423c78944d1494d5d294f12f9acc2ba","In recent yeas, 360° spherical panorama images and videos have seen huge adoption in virtual reality research. Image mosaic is the main technology to stitch the little scale images to a large scale panoramic image. Because of the gross distortion in the edge of fisheye lens, the misregistration on the corrected images leads to obvious ghosting after stitched. In this paper, we use pyramid LK optical flow algorithm to reduce the misregistration areas by remapping with interpolation algorithm. Additionally, we use sample point algorithm to adjust the brightness of images for minimize visual seams. Experiments show convincing evidence that the effect of our spherical panorama stitching improves significantly. © 2018, Springer Nature Singapore Pte Ltd.","Feature matching; Image mosaic; Optical flow; Spherical panorama","Intelligent systems; Spheres; Virtual reality; Corrected image; Feature matching; Image mosaic; Interpolation algorithms; Misregistration; Optical flow algorithm; Panoramic images; Spherical panorama; Optical flows",2-s2.0-85031417522
"Azizoğlu M., İmat S.","Workload smoothing in simple assembly line balancing",2018,"Computers and Operations Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027409609&doi=10.1016%2fj.cor.2017.08.006&partnerID=40&md5=f53536721c12cb4690950cabc224b319","This paper considers a simple assembly line balancing problem with fixed number of workstations and prespecified cycle time. Our objective is to minimize the sum of the squared deviations of the workstation loads around the cycle time, hence maintain workload smoothing. We develop several optimality properties and bounding mechanisms, and use them in our branch and bound algorithm. The results of our computational study reveal that our branch and bound algorithm is capable of solving medium sized problem instances in reasonable times. © 2017","Assembly lines; Branch and bound algorithm; Workload smoothing","Assembly; Assembly machines; Assembly line; Branch-and-bound algorithms; Computational studies; Fixed numbers; Optimality; Problem instances; Simple assembly line balancing; Workload smoothing; Branch and bound method",2-s2.0-85027409609
"Hraiech S.E., Chebbi A.H., Affi Z., Romdhane L.","Robust multi-objective design optimization of the 3-UPU TPM based on the ga-krawczyk method",2018,"Mechanisms and Machine Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026291141&doi=10.1007%2f978-3-319-60867-9_46&partnerID=40&md5=de899840ad224b79c6d7c88d92346dfd","This paper deals with the robust design optimization of the 3-UPU translational parallel manipulator. An approach, that regroups the genetic algorithm multi-objective optimization and the Krawczyk operator (GAMOK), is used to represent the optimal design vector of parameters and their uncertainties. This optimization leads to minimize the position error and relax the parameters intervals of tolerance. Based on this GAMOK algorithm, the designer can pick out the optimal design vector according to the desired accuracy in the workspace of the manipulator. © Springer International Publishing AG 2018.","Genetic algorithm; Interval analysis; Krawczyk operator; Optimization; Uncertainties","Genetic algorithms; Kinematics; Manipulators; Optimal systems; Optimization; Uncertainty analysis; Interval analysis; Krawczyk operators; Multi-objective design optimization; Parameters interval; Position errors; Robust design optimization; Translational parallel manipulator; Uncertainties; Multiobjective optimization",2-s2.0-85026291141
"Madan M.","Bio-inspired computation for optimizing scheduling",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031404708&doi=10.1007%2f978-981-10-6747-1_8&partnerID=40&md5=487dcaf61d9ff09673b1970ebc48ed5b","Profitability is an important factor for sustainability of an organization. Profitability is important but cash flow is also important for the basic obligations like taxes, payroll, etc. In this paper, we have worked on the optimization of resource-constrained scheduling with discounted cash flow (payment scheduling or RCPSPDCF). We have conceptualized bio-inspired computing algorithm namely Genetic Algorithm. Microsoft dependency injection is also being used. It can be further used for problems like resource optimization (Madan and Madan in GASolver-A solution to resource constrained project scheduling, 2013) [1], Time versus Cost optimization (Madan and Madan in Optimizing time cost trade off scheduling) [2]. © 2018, Springer Nature Singapore Pte Ltd.","Bio-inspired computation; Chromosome; Discounted cash flow; GASolver.core; Genetic algorithm","Chromosomes; Compensation (personnel); Economic and social effects; Genetic algorithms; Optimization; Profitability; Scheduling; Wages; Bio inspired computation; Bio-inspired computing; Dependency injection; Discounted cash flow; GASolver.core; Resource constrained project scheduling; Resource constrained scheduling; Resource optimization; Constrained optimization",2-s2.0-85031404708
"Xu X., Liu J.","Optimization Allocation Between Multiple Logistic Tasks and Logistic Resources Considered Demand Uncertainty",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029593034&doi=10.1007%2f978-3-319-66939-7_31&partnerID=40&md5=ceee871f15ea9097f08b8cc930d35ee0","Making an allocation scheme which can achieve the optimal overall efficiency that matching multiple logistics tasks and resources under the environment that the tasks’ demands are uncertain is difficult. In this paper, we build a mathematical model to describe the problem and try to solve it by the genetic algorithm. We also consider the daily usage amount of each resource should be as equilibrious as possible. The result of the case simulation proves the effectiveness of the model and the algorithm. As well as, we analyze the impact that the size of the uncertainty’s degree on the allocation result. © 2018, Springer International Publishing AG.","Genetic algorithm; Resource allocation; Resource equalization; Uncertainty","Artificial intelligence; Genetic algorithms; Resource allocation; Uncertainty analysis; Demand uncertainty; Optimization allocations; Overall efficiency; Resource equalization; Uncertainty; Optimization",2-s2.0-85029593034
"Kostrzewa D., Brzeski R.","The data dimensionality reduction in the classification process through greedy backward feature elimination",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030766803&doi=10.1007%2f978-3-319-67792-7_39&partnerID=40&md5=6a3636f26cebdfe3b8b3bc43b1fe314b","The article presents the author’s algorithm of dimensionality reduction of used data set, realized through Greedy Backward Feature Elimination. Results of the dimensionality reduction are verified in the process of classification for 2 selected data sets. These data sets contain the data for the realization of the multiclass classification. The article presents not only a description of the algorithm but also an example and the results of classification, carried out by selected classifier before and after the process of dimensionality reduction. At the end of article, a summary and the possibility of further work are provided. © 2018, Springer International Publishing AG.","Algorithm; Classification; DIGITS; Dimensionality reduction; Feature selection; Kappa; Multiclass; UCI; URBAN; WEKA","Algorithms; Classification (of information); Feature extraction; DIGITS; Dimensionality reduction; Kappa; Multiclass; URBAN; WEKA; Data reduction",2-s2.0-85030766803
"Qi H., Paz-Kagan T., Karnieli A., Jin X., Li S.","Evaluating calibration methods for predicting soil available nutrients using hyperspectral VNIR data",2018,"Soil and Tillage Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030719542&doi=10.1016%2fj.still.2017.09.006&partnerID=40&md5=0e8275c08f5f6d28ae54ee7c17015fdc","Soil nutrients, including available nitrogen (N), phosphorous (P), and potassium (K), are critical properties for monitoring soil fertility and function. Spectroscopy analysis has proven to be a rapid and effective means for predicting soil properties, in general, and NPK, in particular. However, different calibration methods, including preprocessing transformations (PPTs) and regression algorithms (RAs), considerably affect the performance of prediction models. In this study, raw spectrum and 21 PPTs, combined with three RAs, for a total of 66 calibration methods, were investigated for modeling and predicting soil NPK using hyperspectral VNIR data (400–1000 nm). The ratio of performance to deviation (RPD) of validation set was selected to evaluate the prediction accuracy and the ratio between the interpretable sum squared deviation and the real sum squared deviation (SSR/SST) of the validation set was also used to evaluate the explanatory power of the models. It was found that there is a tradeoff between RPD and SSR/SST values; under this tradeoff, the multiplicative scatter correction, combined with the back-propagation neural network, was preferred for predicting P (RPD = 2.23, SSR/SST = 0.81). The Savitzky-Golay filtering + logarithmic transformation, combined with the partial least squares – regression, was preferred for predicting K (RPD = 1.47, SSR/SST = 0.95). However, with extremely low RPD and SSR/SST values, the prediction of N was unreliable in this study. The evaluation approach presented in this paper suggests a framework for choosing a calibration method for spectroscopy analysis for predicting soil NPK and perhaps some other properties. © 2017 Elsevier B.V.","Calibration; Prediction methods; Regression algorithms; Soil measurements; Spectral analysis","Backpropagation; Calibration; Least squares approximations; Neural networks; Nutrients; Regression analysis; Soil testing; Soils; Spectrum analysis; Back propagation neural networks; Logarithmic transformations; Multiplicative scatter correction; Partial least square (PLS); Prediction methods; Regression algorithms; Savitzky Golay Filtering; Soil measurement; Forecasting; algorithm; calibration; model validation; multispectral image; numerical model; performance assessment; prediction; soil analysis; soil fertility; soil nutrient; spectral analysis",2-s2.0-85030719542
"Razzaghnoori M., Sajedi H., Jazani I.K.","Question classification in Persian using word vectors and frequencies",2018,"Cognitive Systems Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026525620&doi=10.1016%2fj.cogsys.2017.07.002&partnerID=40&md5=9d75b9df4b05758867cca261ae1f79cd","The necessity of the existence of Question Answering (QA) systems becomes evident by considering the fact that the enormous amount of unstructured data created by humans nowadays, results in ineffectiveness of search engines to provide the exact solution for a given question. However, an outstanding question answering system requires an outstanding Question Classification (QC) system. Question classifier is a system that assigns a label to each question. There exist different ways of solving this problem such as rule-based, machine learning, and hybrid approaches. This paper provides a better solution for QC using machine-learning approaches. Three methods of feature extraction are proposed in this paper. The First method uses clustering algorithms to partition vocabulary into clusters and acquires feature vector corresponding to each question using clustering information. The second one suggests a method of extracting features from questions to dispose of using recurrent neural networks and to use feedforward neural networks, which have the advantage of learning faster and less need for data, instead. Each question is converted to a feature vector, which is obtained by the Word2vec method and weighted by tf-idf coefficients. The results of question classification using Support Vector Machine and Neural Network classifiers indicate the effectiveness of this type of feature vector and based on that, high performance of the proposed QC system. Finally, the third approach keeps the innovation behind first approach, but it also keeps the fact that we are dealing with a sequence based type of data into consideration. Eventually, it would be concluded that even with a limited amount of data it is reasonable to take Recurrent Neural Networks into consideration. © 2017 Elsevier B.V.","Feedforward neural networks; LSTM; Question classification; Recurrent Neural Networks (RNN); Tf-idf; Word2vec","Artificial intelligence; Clustering algorithms; Feedforward neural networks; Image retrieval; Learning systems; Search engines; Vectors; LSTM; Question classification; Recurrent neural network (RNN); Tf-idf; Word2vec; Recurrent neural networks; algorithm; Article; artificial neural network; classifier; controlled study; information processing; learning; lingua franca; linguistics; machine learning; natural language processing; Persian (language); priority journal; question classification system; search engine; support vector machine",2-s2.0-85026525620
"Malhotra D., Malhotra M., Rishi O.P.","An innovative approach of web page ranking using hadoop- and map reduce-based cloud framework",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031424331&doi=10.1007%2f978-981-10-6620-7_40&partnerID=40&md5=9a421b4ac2c05ec97bd545048b06d4ee","In this era of Big Data, Web page searching and ranking in an efficient manner on WWW to satisfy the search needs of modern-day user is undoubtedly a major challenge for search engines. In this paper, we propose an innovative algorithm based on Hadoop–Map Reduce-supported cloud computing framework that can be implemented in the form of Meta Search and Page Ranking Tool to efficiently search and rank Big Data available on WWW which is increasing in the scale of megabytes to terabytes per day. An extensive experimental evaluation shows that the average ranking precision of proposed algorithm and Meta tool is better than other popular search engines. © 2018, Springer Nature Singapore Pte Ltd.","Big data analysis; Cloud computing; Cluster page ranking algorithm; Hadoop; HDFS; Map Reduce; Meta search tool; Web page ranking","Cloud computing; Cluster computing; Clustering algorithms; Distributed computer systems; Network function virtualization; Search engines; Websites; Hadoop; HDFS; Map-reduce; Meta search; Page ranking; Web page ranking; Big data",2-s2.0-85031424331
"Wang H., Zhu M., Zhou M.","Robust power allocation scheme in cognitive radio networks",2018,"Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031303051&doi=10.1007%2f978-3-319-66625-9_49&partnerID=40&md5=09f574aa66b43189ba38c453fb0e540e","Considering that the spectrum resources are becoming increasingly demand, maximum channel capacity is very crucial for future wireless communication systems, especially for cognitive radio networks (CRNs). However, most existing works usually assume that channel parameter estimation is perfect, which is often damped in practical systems. In this paper, we investigate the robust maximum channel capacity problem in the CRNs. Then assuming that channel parameter uncertainty is bounded, we consider that all channel parameter uncertainties are described by ellipsoid sets. From the perspective of worst-case optimization, we formulate it as a semi-infinite programming (SIP) problem. Furthermore, an optimal iterative algorithm based on the dual decomposition theory and Lagrange multiplier algorithm is applied. Simulation results validate that our robust scheme can achieve the channel capacity maximization considering the worst-case and strictly guarantee the power interference requirement of second users (SUs) under all parameters’ uncertainties. © 2018, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.","Capacity maximization; CRNs; Distributed algorithm; Ellipsoidal set; Robust optimization","Channel capacity; Cognitive systems; Iterative methods; Lagrange multipliers; Mathematical programming; Optimization; Parallel algorithms; Wireless telecommunication systems; Channel parameter estimation; Cognitive radio network; Cognitive radio networks (CRNs); CRNs; Ellipsoidal set; Robust optimization; Semi-infinite programming problems; Wireless communication system; Cognitive radio",2-s2.0-85031303051
"Houssein E.H., Kilany M., Hassanien A.E., Snasel V.","A two-stage feature extraction approach for ECG signals",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028676448&doi=10.1007%2f978-3-319-60834-1_30&partnerID=40&md5=852ae186187be22b6748a99013552873","This paper investigate various techniques of extracting features from the electrocardiogram (ECG) signal in order to analyze the ECG signals to detect the heart disease. Feature extraction, is a one of the widespread process of decompose the ECG data. This paper introduce a two-stage feature extraction approach to extract features from ECG signals for different types of arrhythmias. Firstly, Modified Pan-Tomkins Algorithm (MPTA) is implemented to remove noise and extract nine features. Then the proposed Improved Feature Extraction Algorithm (IFEA) is applied to extract additionally ten different features from the ECG signal. The MIT-BIH arrhythmia database have been used to test the proposed approach. It is obvious from the results that the proposed approach shows a high classification in terms of the following four statistical measures: Accuracy (Ac) 98.37%, Recall 48.29%, Precision 43.91%, F Measure 45.31%, and Specificity (Sp) 93.30%, respectively. © 2018, Springer International Publishing AG.","ECG; Feature extraction; Pan-tompkins algorithm; Wavelet transform","Diseases; Electrocardiography; Extraction; Feature extraction; Wavelet transforms; ECG signals; Electrocardiogram signal; Extracting features; F measure; Feature extraction algorithms; Heart disease; REmove noise; Statistical measures; Biomedical signal processing",2-s2.0-85028676448
"Fan Y., Xia Y., Liang W., Zhang X.","Latency-aware reliable controller placements in SDNs",2018,"Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031309856&doi=10.1007%2f978-3-319-66628-0_15&partnerID=40&md5=b7908bc68dfd9e2056b12ae990ef1615","Most existing research on controller placement in Software-Defined Networking (SDN) investigated controller placements without jointly taking into account both the communication reliability and the communication latency between controllers and switches if any link in the network fails. In this paper, we first introduce a new latency metric that considers the communication delay between the switches and the controllers with and without the single-link-failure. We then formulate a novel SDN controller placement problem with the aim to minimize the communication delay, for which we propose an efficient algorithm. We also show that there is a non-trivial trade-off between a primary path and its backup path in terms of communication delay. We finally conduct experiments through simulations. Experimental results demonstrate that the proposed algorithm is very promising. © 2018, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.","A single link failure; Multiple controller placements; Placement algorithms; SDN; The latency","Economic and social effects; Software reliability; Communication latency; Communication reliabilities; Controller placements; Multiple controllers; Placement algorithm; Single-link failures; Software defined networking (SDN); The latency; Controllers",2-s2.0-85031309856
"Georgieva T., Demirova S., Zlateva P.","An approach for monitoring transport and delivery chain of liquid fuels in Bulgaria",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031297803&doi=10.1007%2f978-3-319-68324-9_30&partnerID=40&md5=dd279de4d5bbaa466e6b83d1ccc2c7f1","In recent years in the field of transport services becomes more pervasive requirements to ensure the monitoring, evaluation and control of the transported liquid fuels. The aim of this publication is to offer an optimal solution for monitoring and control of the supply chain for the transport of liquid fuels in Bulgaria. Proposed is a one approach and algorithm to ensure the safety of supply of liquid fuels through logistics solutions and monitoring system for traffic. © 2018, Springer International Publishing AG.","Algorithm; Risk in the supply chain; Specialized software; Supply chain; Transportation of liquid fuels","Algorithms; Fuels; Liquid fuels; Supply chains; Bulgaria; Delivery chain; Logistics solution; Monitoring and control; Monitoring system; Optimal solutions; Specialized software; Transport services; Liquids",2-s2.0-85031297803
"Aymen F.","Internal Fuzzy Hybrid Charger System for a Hybrid Electrical Vehicle",2018,"Journal of Energy Resources Technology, Transactions of the ASME",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028056034&doi=10.1115%2f1.4037352&partnerID=40&md5=7ce74606d1f0b128ab89e30c448c2a47","Controlling the charging power system in an electrical vehicle, presents a serious challenge for the engineer in order to find the best solution that guarantee the system effectiveness and performance. Related to this objective, this paper is presented to offer an intelligent power management algorithm, which guarantees the best process of power extraction and injection, respectively, from an electrical generator (EG) linked to an internal combustion engine (ICE) to a system of batteries via a direct current to alternative current power converter. This intelligent process was based on the fuzzy technology and the system tuning is made after a various test. Obtaining the necessary power in the exact moment and in the specific condition, that presents the goal of the presented algorithm. For obtaining the best instruction from the present intelligent process, the state of charge (SOC) of the battery, the measured output voltage from the battery and the acceleration decision of the user, are used as a real's input parameters for having a real statue of the electrical vehicle. This new process will be an asset to the highway electrical vehicle for optimizing the power consumption. To evaluate the algorithm performance matlab/simulink is used and a simulation results are presented and discussed. Copyright © 2018 by ASME.","electrical vehicles; fuzzy controller; intelligent algorithms; MATLAB; power management; storage energy","Battery management systems; Charging (batteries); Electric batteries; Electric machine control; Electric power measurement; Energy management; Internal combustion engines; MATLAB; Power management; Secondary batteries; Vehicles; Algorithm performance; Electrical generators; Electrical vehicles; Fuzzy controllers; Hybrid electrical vehicle; Intelligent Algorithms; Storage energy; System effectiveness; Electric power system control",2-s2.0-85028056034
"Altarabsheh A., Kandil A., Ventresca M.","New Multiobjective Optimization Approach to Rehabilitate and Maintain Sewer Networks Based on Whole Lifecycle Behavior",2018,"Journal of Computing in Civil Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032442171&doi=10.1061%2f%28ASCE%29CP.1943-5487.0000715&partnerID=40&md5=5f1068886e19d09595d6d97c88cf95f9","This study proposes a new methodology for selecting renewal plans for sewer networks based on their impacts on the behavior of the networks over their whole lifecycle. The proposed approach combines a multiobjective genetic algorithm and Monte Carlo simulation to maximize network condition and serviceability while minimizing network risk of failure and total lifecycle cost for the entire planning period. The algorithm was applied to a sewer network in Sahab City, Jordan, in 16 different analysis scenarios that consider the uncertainty in the model variables. These different analysis scenarios varied the network age, deterioration rate, and available budget at each time step throughout the planning period. The model was then validated by statistically comparing its performance to an existing prioritization model that does not consider the long-term impact behavior of the wastewater system. The results show that the proposed algorithm outperforms the existing prioritization model because it results in statistically significant improvement in the network condition, risk of failure, serviceability, and the total lifecycle cost at the end of the planning period. © 2017 American Society of Civil Engineers.",,"Budget control; Genetic algorithms; Intelligent systems; Monte Carlo methods; Multiobjective optimization; Optimization; Sewers; Uncertainty analysis; Deterioration rates; Lifecycle costs; Long-term impacts; Model variables; Multi-objective genetic algorithm; Network condition; Waste water systems; Whole life cycles; Life cycle",2-s2.0-85032442171
"Khan S., Dembla D.","Implementation of modified K-means approach for privacy preserving in data mining",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031395248&doi=10.1007%2f978-981-10-3773-3_58&partnerID=40&md5=1d3ed1531f18eb0cdc95d4f9a0269086","Recent concerns regarding privacy breach issues have motivated the development of data mining methods, which preserve the privacy of individual data item. A cluster is gathering of information in such a way that the objects with similar properties are grouped into similar clusters and objects with dissimilar properties are placed into different clusters. The K-Means clustering algorithm is a broadly utilized plan to solve the clustering problem. In this paper, a comparative study of three clustering algorithms—K-means, Hierarchical and Cobweb across two different datasets is being performed. To form Clusters WEKA API has been used. The comparison is made with the variant of standard K-means technique that is Modified K-means technique. The Modified K-means technique has been developed to give better results as compared to existing K-means, Hierarchical and Cobweb techniques. This work also includes encryption and decryption of the formed clusters using AES algorithm to provide privacy to the data while transferring over networks. Experimental result proves that the performance of Modified K-means algorithm is better as compared to the existing K-Means and better than the hierarchical and Cobweb when tested on two datasets. K-Means and Hierarchical clustering is forming less number of clusters. In contrast, Cobweb is forming many clusters, which create memory issues. Therefore, Modified K-means forms an appropriate number of clusters in an organized manner and also takes minimum amount of time. © Springer Nature Singapore Pte Ltd. 2018.","AES; Clustering; File joining; File splitting; K-means","Cryptography; Data mining; Data privacy; Clustering; Clustering problems; Comparative studies; Encryption and decryption; File splitting; Hier-archical clustering; K-means; K-Means clustering algorithm; Clustering algorithms",2-s2.0-85031395248
"Krejsa J., Vechet S.","Determination of optimal local path for mobile robot",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029219705&doi=10.1007%2f978-3-319-65960-2_79&partnerID=40&md5=97f4c0c8315f5d8a2ddd2a98ae69485e","The paper presents the method of finding locally optimal path with respect to the safety of the mobile robot with non-holonomic constraints. The path is represented by the polyline and circular segments. Initial path is found in the geometrical centers of the corridors to pass through and is optimized using evolutionary algorithm. The complexity of path description can be sequentially increased, allowing to further improve the quality of the path while optimization can be interrupted any time. Minimal distance to the obstacles is taken as optimality criterion. © 2018, Springer International Publishing AG.","Genetic algorithm; Mobile robot; Optimization; Path planning","Computational complexity; Genetic algorithms; Mobile robots; Motion planning; Optimization; Robots; Minimal distance; Non holonomic constraint; Optimal paths; Optimality criteria; Polyline; Robot programming",2-s2.0-85029219705
"Trajdos P., Kurzynski M.","Permutation-based diversity measure for classifier-chain approach",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019228085&doi=10.1007%2f978-3-319-59162-9_43&partnerID=40&md5=cb19a940d30f46d30c0ad3ff92496864","In this paper, the problem of multilabel classification using the classifier chain scheme is addressed. We deal with the problem of building a diverse ensemble of the classifier-chain-based ensemble. For this purpose, we propose a permutation-based criterion of chain diversity. The final ensemble is build using a multi-objective genetic algorithm, which is used to optimise classification quality and chain diversity simultaneously. The proposed methods were evaluated using 29 benchmark datasets. The comparison was performed using four different multi-label evaluation measures. The experimental study reveals that the proposed approach provides a better classification quality than response-based diversity criteria. © Springer International Publishing AG 2018.","Classifier-chain; Diversity; Multi-label classification","Classification (of information); Genetic algorithms; Benchmark datasets; Classification quality; Classifier chains; Diversity; Evaluation measures; Multi label classification; Multi-label classifications; Multi-objective genetic algorithm; Chains",2-s2.0-85019228085
"Laribi M.A., Mlika A., Romdhane L., Zeghloul S.","Robust optimization of the RAF parallel robot for a prescribed workspace",2018,"Mechanisms and Machine Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026292524&doi=10.1007%2f978-3-319-60867-9_44&partnerID=40&md5=7d46da68ca33259b0f8faf48dc8a1330","This paper deals with the optimal synthesis of the RAF robot for a prescribed workspace. The RAF (Romdhane-Affi-Fayet) robot is a three translational parallel manipulator (3TPM). A method based on the genetic algorithm is used to solve the optimization problem. A multi-objective function, based on the mathematical concept of the power of a point with respect to a surface, is formulated. The suggested method is simple and effective in defining the geometry of the robot having the smallest workspace that includes a specified volume and the best kinematic performance. © Springer International Publishing AG 2018.","Dexterity index; Genetic algorithm; Optimal design; Power of a point; RAF parallel robot; Synthesis; Workspace","Functions; Genetic algorithms; Kinematics; Machine design; Optimization; Robots; Synthesis (chemical); Dexterity index; Optimal design; Parallel robots; Power of a point; Workspace; Manipulators",2-s2.0-85026292524
"Pandey S., Supriya M., Shrivastava A.","Data classification using machine learning approach",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032668039&doi=10.1007%2f978-3-319-68385-0_10&partnerID=40&md5=63893f0a0719813465d96d71327ff7f2","Currently, Internet has numerous effects on our everyday lifecycle. Its significance as an intermediate for commercial transactions will develop exponentially throughout the next years. In terms of the engaged marketplace volume, the Business to Business region will hereby be the supreme exciting area. As the extensive usage of electronic business transactions increase, great volume of products information gets generated and managing such large information automatically becomes a challenging task. The accurate classification of such products to each of the existing classes also becomes an additional multifarious task. The catalog classification is an essential part for operative electronic business applications and classical machine learning problems. This paper presents a supervised Multinomial Naïve Bayes Classifier machine learning algorithm to classify product listings to anonymous marketplaces. If the existing products are classified under the master taxonomy, the task is to automatically categorize a new product into one of the existing categories. Our algorithm approach proposes a method to accurately classify the existing millions of products. © Springer International Publishing AG 2018.","Categories; Classifier; Machine learning; Naïve bayes","Artificial intelligence; Classifiers; Commerce; Electronic commerce; Intelligent systems; Learning systems; Sodium; Algorithm approaches; Business to business; Categories; Commercial transactions; Data classification; Electronic business; Machine learning approaches; Machine learning problem; Learning algorithms",2-s2.0-85032668039
"Huang W., Ding H., Chen G.","A novel deep multi-channel residual networks-based metric learning method for moving human localization in video surveillance",2018,"Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024931703&doi=10.1016%2fj.sigpro.2017.07.015&partnerID=40&md5=29b194e0a65b829e7e179b1387e6f215","Moving human localization is the first pre-requisite step of human activity analysis in video surveillance. Identifying human targets accurately and efficiently is always of high demands in computer vision studies. Also, learning is often indispensable in contemporary moving human localization, and unknown parameters of proposed methods need to be properly adjusted to guarantee the final localization performance. Such a task can be facilitated with the help of popular deep learning techniques, especially when enormous surveillance video clips become commonly seen nowadays. In this study, the metric learning problem in moving human localization is emphasized, and a new deep multi-channel residual networks-based metric learning method is introduced for the first time. Specifically, the deep metric learning problem in this new method is solved within a ranking procedure via both the conventional stochastic gradient descent algorithm and a more efficient proximal gradient descent algorithm. Comprehensive experiments are conducted and this new method is compared with several other popular deep learning-based approaches. Qualitative and quantitative analysis are conducted from the statistical perspective, to evaluate all localization outcomes obtained by all compared methods based on two specific measurements. The localization performance of this new method is suggested to be promising after the comprehensive analysis. © 2017","Deep metric learning; Deep residual networks; Localization; Video surveillance","Education; Learning systems; Monitoring; Security systems; Stochastic systems; Gradient descent algorithms; Human activity analysis; Localization; Localization performance; Metric learning; Qualitative and quantitative analysis; Stochastic gradient descent algorithm; Video surveillance; Deep learning",2-s2.0-85024931703
"Tagesse Takore T., Rajesh Kumar P., Lavanya Devi G.","A robust and oblivious grayscale image watermarking scheme based on edge detection, SVD, and GA",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029782809&doi=10.1007%2f978-981-10-4280-5_6&partnerID=40&md5=c224f97955fd0ac2cffb1fefd02fd7ca","For multimedia data copyright protection application, robustness to various attacks is one of the most important requirements that a digital watermarking system should possess. Hence, using matrix factorization technique (i.e., singular value decomposition) and genetic algorithm, a new grayscale image watermarking system is presented in this paper which can satisfy the desired watermarking requirements. Canny edge detector is used to form two subimages and watermark is inserted into the first subimage by amending singular value coefficient based on the pixel value of a watermark. The genetic algorithm is employed in the proposed scheme to search the best multiple scaling factors which can give the highest robust watermarked image without losing transparency. The robustness and transparency of the scheme are measured using a quality metric, normalized-correlation-coefficient (NCC), and peak-signal-to-noise-ratio (PSNR), respectively. In this paper, to test the degree of robustness, watermarked image is attacked using a maximum number of image processing attacks compared to other existing methods and experimental results obtained show improved performance in terms of robustness. © Springer Nature Singapore Pte Ltd. 2018.","Edge detection; Genetic algorithm; Image watermarking; Robustness; Singular value decomposition; Transparency","Copyrights; Digital filters; Digital watermarking; Edge detection; Factorization; Genetic algorithms; Image processing; Robustness (control systems); Signal to noise ratio; Singular value decomposition; Transparency; Canny edge detectors; Copyright protections; Degree of robustness; Digital watermarking system; Matrix factorizations; Normalized correlation coefficient; Peak signal to noise ratio; Watermarking schemes; Image watermarking",2-s2.0-85029782809
"Srivastava S.","Novel method for predicting academic performance of students by using modified particle swarm optimization (PSO)",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031431276&doi=10.1007%2f978-981-10-6747-1_21&partnerID=40&md5=86ce303aadc6355e616a31f3d2fb9a6f","There are numerous methods for extracting useful information from data. This paper describes a method for predicting performance of students. This method modifies the basic particle swarm optimization (PSO) algorithm using a set of rules. An attribute is selected from a set of performance attributes of the students. This attribute is used to frame rules. These rules determine the value of a modifying factor. This factor changes the mathematical expression of the function used in PSO for finding the solution. These rules are based on number of students in a particular shift. Other attributes are assigned different indexes. These indexes indicate number of students deviating from average value. The modified PSO algorithm takes the values of these indexes as inputs and generates a solution set which minimizes the values of indexes. A comparison of the solution set given by modified PSO and the solution set with unmodified PSO is presented. A brief outline of the modified PSO is given. The selection of the modifying factor and design of rules is described. These rules are based on the number of students in a particular shift. The different possible classes for the shift attribute are given. Thus, a decision strategy for predicting performance is described. © 2018, Springer Nature Singapore Pte Ltd.","Modified PSO; Performance attributes; Rules, knowledge discovery, data mining","Data mining; Forecasting; Functions; Optimization; Students; Mathematical expressions; Modified particle swarm optimization; Modified pso; Modified pso algorithms; Modifying factors; Particle swarm optimization algorithm; Performance attributes; Predicting academic performance; Particle swarm optimization (PSO)",2-s2.0-85031431276
"Chang E.-C., Chu S.-C., Istanda V., Sung T.-W., Tseng Y.-M., Wu R.-C.","Robust optimal control technology for multimedia signal processing applications",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026786186&doi=10.1007%2f978-3-319-63856-0_11&partnerID=40&md5=e29574fea0520d01d55c11e577d78917","This paper develops a robust optimal control technology for multimedia signal processing (MSP) applications. The proposed control technology combines the advantages of nonsingular finite-time convergence sliding mode control (NFTCSMC) and genetic algorithm (GA). The NFTCSMC has finite system state convergence time including nonsingular merit unlike infinite-time exponential convergence of classic sliding mode control, but the chattering still occur under a highly uncertain disturbance. For multimedia signal processing applications, the chattering causes high voltage harmonics and inaccurate tracking control. To enhance the performance of multimedia signal processing, the GA is well adopted to tune the control gains of the NFTCSMC so that the chattering can be removed. Experimental results are given to conform that the proposed control technology can lead to high-quality AC output voltage and fast transient response. Because the proposed control technology is easier to realize than prior technologies and gives high tracking accuracy and low computational complexity algorithm, this paper will be of interest to designer of related MSP applications. © Springer International Publishing AG 2018.","Chattering; Genetic algorithm (GA); Multimedia signal processing (MSP); Nonsingular finite-time convergence sliding mode control (NFTCSMC); Voltage harmonics","Computational complexity; Genetic algorithms; Optimization; Quality control; Signal processing; Sliding mode control; Chattering; Exponential convergence; Fast transient response; Finite-time convergence; Low computational complexity; Robust optimal control; Uncertain disturbances; Voltage harmonics; Multimedia signal processing",2-s2.0-85026786186
"Chen J.-J., Zhang J.-C., Huo S.-Y.","Multi-objective optimization of asymmetric acoustic transmission with periodical structure",2018,"Ultrasonics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029355524&doi=10.1016%2fj.ultras.2017.09.007&partnerID=40&md5=7d3f98cf4e832be17ada5c4321969608","Asymmetric acoustic wave propagation is important for control and manipulation of the acoustic wave signals in various devices. However, previous approach to find optimal asymmetric acoustic transmission (AAT) is through repeatedly adjusting the geometrical parameters, thus causing time-consuming. Here we propose a study on the multi-objective optimization of the AAT, aiming to achieve the widest working frequency range (fr) and the highest transmittance peak (η) with regard to the design variables. For this purpose, the Radial Basis Function (RBF) neural work and finite element (FE) method are applied to obtain the valuable data in the procedure. Furthermore, local sensitivity analysis of design parameters on the fr and η are analyzed. Ultimately, the Non-Dominated Sorting Genetic Algorithm II (NSGA-II) is adapted for getting the Pareto-optimal solutions. The optimization results show great improvement for the overall performance of the AAT, which could be potentially significant in designing various sound devices. © 2017","Multi-objective optimization; NSGA-II; RBF model; Transmittance peak; Working frequency range","Acoustic wave propagation; Acoustic wave transmission; Acoustic waves; Finite element method; Genetic algorithms; Geometry; Pareto principle; Radial basis function networks; Sensitivity analysis; Local sensitivity analysis; Non dominated sorting genetic algorithm ii (NSGA II); NSGA-II; Pareto optimal solutions; Radial Basis Function(RBF); RBF model; Transmittance peak; Working frequency; Multiobjective optimization",2-s2.0-85029355524
"Shiue Y.-C., Lo S.-H., Tian Y.-C., Lin C.-W.","The study of salient object and BoF with SIFT for image retrieval",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031418051&doi=10.1007%2f978-981-10-3187-8_81&partnerID=40&md5=5f7ab5c9e80dccdf6a69ac2f0f744730","Big data generated search difficult problems, thus effectively retrieve digital images, image retrieval has attracted much attention in recent years. First, this study presents detection technology is expected to identify significant object image through the significant items, and reduce the influence of back-ground noise of the object. Through the significant object detection processed image, be used in the scale-invariant feature transform (SIFT) features to capture an image, and then through the k-means clustering algorithm clustering feature vectors for all of the images to obtain a bag-of-features (BoF) vectors as the basic conditions for images retrieval. Finally, the system is expected to improve through the search pattern, as well as improve the accuracy of images search, images search system to make a real attempt to solve the big data, images search difficult problems arising. © Springer Nature Singapore Pte Ltd. 2018.","Bag-of-features model; Content-based image retrieval; Image retrieval; K-means clustering; Scale-invariant feature transform","Big data; Clustering algorithms; Computation theory; Content based retrieval; Image enhancement; Object detection; Object recognition; Search engines; Bag of features; Clustering feature vectors; Content based image retrieval; Detection technology; K-means clustering; K-Means clustering algorithm; Processed images; Scale invariant feature transforms; Image retrieval",2-s2.0-85031418051
"Xie F., Wang Q., Zheng S., Li L., Ling L., Wei Z., Wanyan X., Wu X.","Optimization design and efficacy evaluation of crew cabin layout",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028731336&doi=10.1007%2f978-981-10-6232-2_95&partnerID=40&md5=03c90664dc9026702faed569b5bedbbe","The optimization design of special vehicle cabin layout is a non-deterministic Polynomial problem. The design experience of the past has not been able to meet the design requirements of the layout of modern special vehicle compartments. Through a number of typical compartments of the layout of the comparative analysis, we can see that there are many existing layout options to be optimized. Therefore, this paper proposes an optimization design method based on genetic algorithm. By setting the objective function and the constraint condition, an improved cabin layout scheme is obtained. And the operation domain and visual field of the operator were analyzed by three-dimensional human body simulation software, and the ergonomic evaluation of the cabin layout was carried out. The results of the study can provide some technical basis for the design of special vehicle compartments. © Springer Nature Singapore Pte Ltd. 2018.","3D human model; Ergonomics evaluation; Genetic algorithm; Layout optimization","Computer software; Ergonomics; Genetic algorithms; Optimization; Systems engineering; Three dimensional computer graphics; Vehicles; 3D human modeling; Comparative analysis; Constraint conditions; Ergonomic evaluation; Layout optimization; Objective functions; Optimization design; Simulation software; Design",2-s2.0-85028731336
"Pachalag V., Malhotra A.","Internet of emotions: Emotion management using affective computing",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028416772&doi=10.1007%2f978-3-319-63645-0_63&partnerID=40&md5=6a28ac4d05b198c907a8c8fae5644458","The many advantages of increase in Human Machine Interaction are obvious but it has also led to issues such as emotional imbalance, depression, reduction in interpersonal communication etc. Internet of Emotions can be broadly categorized as internet based technologies which aim to mitigate these problems and facilitate better Human to Human interaction in real world. IoE can be defined as an ecosystem where emotion packets travel via internet to manage user’s real time experience. We propose a system which will detect emotional state of the user, categorize it and actuate outer net elements to manage the emotion of the user. Detailed algorithm is given which includes use of the passive sensors, smartphone, big data analytics and machine learning. The framework is further explained with example of stress management. The proposed system based on affective computing will play a vital role in development of products and platforms which emphasises user involvement. © Springer International Publishing AG 2018.","Affective computing; Algorithm; Design; Emotion; Internet of Things; Sensors; Stress; System","Algorithms; Big data; Design; Intelligent systems; Internet; Internet of things; Learning systems; Sensors; Stresses; Affective Computing; Emotion; Emotion managements; Human machine interaction; Human-to-human interactions; Inter-personal communications; Internet based technology; System; Human computer interaction",2-s2.0-85028416772
"Zhang L., Bai Z., Bai F.","Crashworthiness design for bio-inspired multi-cell tubes with quadrilateral, hexagonal and octagonal sections",2018,"Thin-Walled Structures",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031099547&doi=10.1016%2fj.tws.2017.10.010&partnerID=40&md5=d179e5b9c946a1bcfa1a2c6a5f779333","Multi-cell tubes have been widely used in vehicle engineering for their excellent energy absorption capacity. In this paper, a group of bionic multi-cell tubes (BMCTs) with quadrilateral, hexagonal and octagonal sections were proposed. The BMCTs were constructed by filling the cylindrical tubes into different position of multi-cell tubes (MCTs), which was inspired by the microstructure of beetle forewings. The finite element (FE) models under axial impact loading were established and then validated by the Simplified Super Folding Element (SSFE) theory. The crashworthiness of different BMCTs and MCTs was compared, and the results showed that the sixth type of bionic multi-cell tube with octagonal section (O-BMCT-6) has the best crashing performance. Then, the multiobjective optimization design of O-BMCT-6 was conducted by using non-dominated sorting genetic algorithm II (NSGA-II) and radial basis function (RBF) metamodels. The optimal O-BMCT-6 showed superior crashworthiness and could be used as an energy absorber. © 2017 Elsevier Ltd","Bionic multi-cell tube; Crashworthiness; Microstructure; Multiobjective optimization; Theoretical validation","Bionics; Cells; Crashworthiness; Cytology; Energy absorption; Finite element method; Genetic algorithms; Microstructure; Multiobjective optimization; Radial basis function networks; Tubes (components); Crashworthiness designs; Cylindrical tubes; Energy absorption capacity; Multicell; Non dominated sorting genetic algorithm ii (NSGA II); Radial Basis Function(RBF); Theoretical validations; Vehicle engineering; Cell engineering",2-s2.0-85031099547
"Zhang X., Sun Z., Cui W.","Dynamic timetables optimization method of regional public transit under APTS",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026778640&doi=10.1007%2f978-981-10-3551-7_18&partnerID=40&md5=dfc5639d84cc923db6b1754418abe02a","The core of real-time operational control of public transit is compiling dynamic timetables. Considering the practical need of transfer time, this paper designs a new strategy for developing public transit timetables based on transfer time window: Firstly, for single transfer stations, aiming at minimizing the waiting time of passengers both in buses and outside buses, stop orders and dwell time are designed based on the degree of importance of transfer. Secondly, optimization model of regional public transit timetables is established and the model is the basis for optimization of public transit timetables. Thirdly, the model is solved by using genetic algorithm. Finally, practical case is given to verify the performance of the model. © Springer Science+Business Media Singapore 2018.","Advanced public transportation system; Dynamic timetables; Genetic algorithm; Regional public transit","Genetic algorithms; Intelligent systems; Intelligent vehicle highway systems; Mass transportation; Optimization; Scheduling; Transportation; Urban transportation; Dwell time; Operational control; Optimization method; Optimization modeling; Public transit; Real time; Transfer time; Waiting-time; Advanced public transportation systems",2-s2.0-85026778640
"Forczmański P.","Performance evaluation of selected thermal imaging-based human face detectors",2018,"Advances in Intelligent Systems and Computing",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019192247&doi=10.1007%2f978-3-319-59162-9_18&partnerID=40&md5=752b9d51473c21114d9f698c8cdfc5ca","The paper is devoted to the problem of face detection in thermal imagery. Its aim was to investigate several contemporary general-purpose object detectors known to be accurate when working in visible lighting conditions. Employed classifiers are based on AdaBoost learning method with three types of low-level descriptors, namely Haar–like features, Histogram of Oriented Gradients, and Local Binary Patterns. Additionally, the performance of recently proposed Max-Margin Object-Detection Algorithm joint with HOG feature extractor and Deep Neural Network-based approach have been investigated. Performed experiments, on images taken in controlled and uncontrolled conditions, gathered in our own benchmark database and in a few other databases support final observations and conclusions. © Springer International Publishing AG 2018.","AdaBoost; Biometrics; Deep neural network; Face detection; Haar–like features; Histogram of oriented gradients; Local binary patterns; Max-Margin object-detection algorithm; Thermovision","Adaptive boosting; Biometrics; Deep neural networks; Feature extraction; Graphic methods; Infrared imaging; Object detection; Object recognition; Signal detection; Benchmark database; Histogram of oriented gradients; Lighting conditions; Local binary patterns; Low level descriptors; Network-based approach; Object detection algorithms; Thermovision; Face recognition",2-s2.0-85019192247
"Wang H.","Research on intelligent standardized english test systems with artificial intelligence",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028412372&doi=10.1007%2f978-3-319-60744-3_4&partnerID=40&md5=428eb798009c78d32c3457cda0a774da","With the advent of the Internet era, computer technology has penetrated into the political, economic, cultural and other fields, which also includes the field of education. In the traditional education mode, large test is often faced with many difficult including high cost of examination, heavy examinations and so on. Therefore, it is an important research on designing a test system combine with Artificial Intelligence. This paper analyzes the related Artificial Intelligent standardized test system, and uses the improved Genetic Algorithm to refine the rules for an Intelligent test paper, and uses Fuzzy and Close matching to intelligent mark, combines with Artificial Intelligence to design optimized standardized English test systems. And does feasibility analysis and related comparisons by the experiment. The results showed that the Intelligent standardized test system not only ensured the fairness of the examination, reduced the costs of the examination, but also assessed the capacity of the candidates more effectively. © 2018, Springer International Publishing AG.","Artificial intelligence testing; Genetic Algorithm; Test system","Artificial intelligence; Genetic algorithms; Intelligent systems; Real time systems; Artificial intelligent; Computer technology; Feasibility analysis; Intelligent mark; Intelligent test; Standardized tests; Test systems; Traditional educations; Testing",2-s2.0-85028412372
"Xiang S., Yang J.","Performance reliability evaluation for mobile ad hoc networks",2018,"Reliability Engineering and System Safety",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026746993&doi=10.1016%2fj.ress.2017.08.001&partnerID=40&md5=8513c6ab0f128fc6f0ec349034e2c69a","The reliability of the mobile ad hoc network (MANET) is receiving increasing attention. Previous works are mainly focused on the connectivity reliability of the MANET; however, its performance reliability has not been considered. In the MANET, the paths connecting two nodes are prone to continuous changes due to the mobility of nodes, which can result in a huge uncertainty on the transmission performance. Thus it is necessary to research the evaluation method of the performance reliability of the MANET. In this study, the transmission reliability is defined to measure the reliability of the transmission performance of the MANET. The impact of interference on the transmission reliability is considered. The topology optimization of the MANET is studied based on the transmission reliability, and genetic algorithm is adopted to solve the optimization problem. In the numerical example, the effects of the involved parameters on the transmission reliability are discussed, and some applicable conditions of the optimal design are analyzed for practical applications. © 2017","Genetic algorithm; Interference; Mobile ad hoc network; Performance reliability; Transmission reliability","Ad hoc networks; Genetic algorithms; Optimization; Reliability; Wave interference; Applicable conditions; Connectivity reliability; Optimal design; Optimization problems; Performance reliability; Transmission performance; Transmission reliability; Mobile ad hoc networks",2-s2.0-85026746993
"Ay M., Koca G.O.","A dynamic feedback neural model for identification of the robot manipulator",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029218448&doi=10.1007%2f978-3-319-65960-2_43&partnerID=40&md5=e836a4064f1123fea8bf104b19582227","Robot manipulators are very powerful industrial systems. These systems are used in many different industrial applications. Since the derivation of the mathematical model of a robot manipulator has complex processing load, a suitable neural model can be designed. In this paper, both inverse and forward kinematics equations of a six degree of freedom (DoF) robot manipulator are given and also adapted to MATLAB environment with a graphical user interface to identify behaviors of the robot manipulator. At the same time, a multilayer artificial neural model is proposed to provide the robot manipulator identification. Back-propagation learning algorithm is used to train dynamic feedback neural model based on NARX network structure. The experimental results are presented to show the performance of the dynamic feedback neural model. © 2018, Springer International Publishing AG.","Back-propagation; Graphical user interface; NARX network; Neural model; Robot manipulator","Backpropagation; Backpropagation algorithms; Degrees of freedom (mechanics); Flexible manipulators; Graphical user interfaces; Industrial manipulators; Industrial robots; Modular robots; Robot applications; Robots; User interfaces; Backpropagation learning algorithm; Complex processing; Forward kinematics equations; MATLAB environment; NARX network; Neural modeling; Robot manipulator; Six degree-of-freedom; Manipulators",2-s2.0-85029218448
"Du J., Jing H.","Collaborative filtering-based matching and recommendation of suppliers in prefabricated component supply chain",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032683292&doi=10.1007%2f978-3-319-67071-3_19&partnerID=40&md5=1a2ffd19ad2cad4e4b2ae84d253e3217","In the past 20 years, with the continuous growth of the prefabricated component supply chain, the integration of fragmented information in the supply chain has aroused wide attention. At present, the information of all aspects in the supply chain is isolated, and the problem of the separation of each ring is serious, which not only results in the isolated decision-making of the parties and the waste of resources, but also lead to inefficient supply chain. B2B come into being, which provides real-time data and information interaction for the parties in supply chain, and improve the overall efficiency of the supply chain. This paper focuses on the problem of supplier matching, in B2B platform, proposing a collaborative filtering recommendation algorithm based on matching suppliers, which recommend suppliers for the buyers accurately and improve the overall efficiency of the prefabricated construction industry supply chain. © 2018, Springer International Publishing AG.","B2B platform; Clustering analysis; Collaborative filtering; Prefabricated component supply chain; Recommendation algorithm","Construction industry; Decision making; Efficiency; Supply chains; B2B platform; Clustering analysis; Collaborative filtering recommendations; Overall efficiency; Prefabricated components; Real-time data; Recommendation algorithms; Waste of resources; Collaborative filtering",2-s2.0-85032683292
"Tripathi J.P., Meghwani S.S., Thakur M., Abbas S.","A modified Leslie–Gower predator-prey interaction model and parameter identifiability",2018,"Communications in Nonlinear Science and Numerical Simulation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020384705&doi=10.1016%2fj.cnsns.2017.06.005&partnerID=40&md5=5391b995cd9dfaef302092e385676ab7","In this work, bifurcation and a systematic approach for estimation of identifiable parameters of a modified Leslie–Gower predator-prey system with Crowley–Martin functional response and prey refuge is discussed. Global asymptotic stability is discussed by applying fluctuation lemma. The system undergoes into Hopf bifurcation with respect to parameters intrinsic growth rate of predators (s) and prey reserve (m). The stability of Hopf bifurcation is also discussed by calculating Lyapunov number. The sensitivity analysis of the considered model system with respect to all variables is performed which also supports our theoretical study. To estimate the unknown parameter from the data, an optimization procedure (pseudo-random search algorithm) is adopted. System responses and phase plots for estimated parameters are also compared with true noise free data. It is found that the system dynamics with true set of parametric values is similar to the estimated parametric values. Numerical simulations are presented to substantiate the analytical findings. © 2017 Elsevier B.V.","Fluctuation lemma; Lyapunov function; Parameter estimation; Parameter identifiability; Pseudo-random search algorithm; Sensitivity analysis","Asymptotic stability; Bifurcation (mathematics); Hopf bifurcation; Learning algorithms; Lyapunov functions; Optimization; Parameter estimation; Sensitivity analysis; Estimated parameter; Fluctuation lemma; Functional response; Global asymptotic stability; Optimization procedures; Parameter identifiability; Predator-prey interaction; Pseudo random; Predator prey systems",2-s2.0-85020384705
"Jhawar G., Nagraj P., Ramesh Babu N.","Developing prototype for prosopagnosia using PCA",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031404363&doi=10.1007%2f978-981-10-6614-6_6&partnerID=40&md5=8c263b142f23239104d805e870d41aac","Prosopagnosia primarily known as face blindness is a brain disorder in which a person is not able to recognize faces. In the device a portable camera is used to capture the real time movement of a person. In the main system face is detected using Voila –Jones Algorithm & hue channel detection. Using Principal Component Analysis (PCA) face is recognized. It is compared with the trained database and displays the basic information about the person if a similar trained data is found otherwise, it is declared as unknown. For new database, system can be trained at any point of time. The prototype system is trained using 30 candidates’ images including 10 images per candidate under distinct angles. The system was able to achieve 98% face detection. It provides the patients an aid to help them recognize people in front of them in seconds. © 2018, Springer Nature Singapore Pte Ltd.","Eigen values; Face detection; Face recognition; Principal component analysis; Viola jones algorithm","Face recognition; Image processing; Brain disorders; Channel detection; Eigen-value; Prototype system; Real time; Viola - Jones algorithms; Principal component analysis",2-s2.0-85031404363
"Li Z., Li J., Mu W.","Space-ground TT&C resources integrated scheduling based on the hybrid ant colony optimization",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028337081&doi=10.1007%2f978-981-10-4837-1_15&partnerID=40&md5=88d00178542b73f36bc9bc96ecd5586d","Space-ground TT&C resource integrated scheduling problem (TTCRISP) is a representative of large combinative optimization problem, and its optimization process is very complicated, single ant colony optimization (ACO) strategy has disadvantage of low efficiency and poor performance. For this reason, this paper proposes two different serial structure hybrid approaches which combine ACO with genetic algorithm (GA) to tackle TTCRISP. GA is used to accelerate the low optimization efficiency due to the lack of pheromone in the early processing stage of ACO and to prevent premature convergence. Results indicate that the new method performs better than the previously presented methods from the subjective and objective viewpoints and is a viable and effective approach for the space-ground TT&C resource integrated scheduling problem. © Tsinghua University Press, Beijing and Springer Nature Singapore Pte Ltd. 2018.","Ant colony optimization; Genetic algorithm; Hybrid metaheuristics; Space-ground integrated scheduling; TT&C","Artificial intelligence; Efficiency; Genetic algorithms; Optimization; Scheduling; Ant Colony Optimization (ACO); Effective approaches; Hybrid ant colony optimization; Hybrid metaheuristics; Integrated scheduling; Optimization efficiency; Optimization problems; Pre-mature convergences; Ant colony optimization",2-s2.0-85028337081
"Nalepa J., Kawulok M., Dudzik W.","Tuning and evolving support vector machine models",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030754969&doi=10.1007%2f978-3-319-67792-7_41&partnerID=40&md5=9259c97bd5042aa08f0192db7ec56d1d","Support vector machines (SVMs) are a well-established classifier, already applied in a variety of pattern recognition tasks. However, they suffer from several drawbacks—selecting their appropriate hyper-parameter values (the SVM model) along with the training sets being the most important. In this paper, we study the influence of applying various kernel functions in SVMs. We verify not only the classification performance of the classifier, but also the number of selected support vectors and the training time for each kernel. Also, we perform the qualitative analysis of the retrieved support vectors using an artificially generated dataset. Finally, we show how to optimize the SVM models using a genetic algorithm. An extensive experimental study revealed that evolved SVM models provide high-quality classification and are retrieved in much shorter time compared with the trial-and-error approaches. © 2018, Springer International Publishing AG.","Classification; Genetic algorithm; Hyper-parameters; Kernel function; Support vector machine","Classification (of information); Genetic algorithms; Pattern recognition; Vectors; Classification performance; Hyper-parameter; Kernel function; Qualitative analysis; Support vector; Support vector machine (SVMs); Support vector machine models; Trial-and-error approach; Support vector machines",2-s2.0-85030754969
"Chern-Tong H., Aziz I.A.","A Performance Evaluation of Chi-Square Pruning Techniques in Class Association Rules Optimization",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029598698&doi=10.1007%2f978-3-319-67621-0_18&partnerID=40&md5=68d8481b92f9b67593940bb6869e206e","Associative classification is recognized by its high accuracy and strong flexibility in managing unstructured data. However, the performance is still induced by low quality dataset which comprises of noised and distorted data during data collection. The noisy data affected support value of an itemset and so it influenced the performance of an associative classification. The performance of associative classification is relied on the classification where the classification is worked based on the class association rules which generated from frequent rule mining process. To optimize the frequent itemsets based on the support value, in this research, we proposed a new optimization pruning technique to prune decision tree according to the correlation of each decision tree branches using genetic algorithm. © 2018, Springer International Publishing AG.","Association rules mining; Associative classification; Data mining; Decision tree; Genetic algorithm; Pruning","Association rules; Computational methods; Data acquisition; Decision trees; Genetic algorithms; Optimization; Trees (mathematics); Association rules mining; Associative classification; Class association rules; Data collection; Pruning; Pruning techniques; Support value; Unstructured data; Data mining",2-s2.0-85029598698
"Qiu Q., Cui L., Gao H., Yi H.","Optimal allocation of units in sequential probability series systems",2018,"Reliability Engineering and System Safety",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030567333&doi=10.1016%2fj.ress.2017.09.011&partnerID=40&md5=b5e905182eac7c157ec4f73bfab778a0","A concept of Sequential Probability Series System (SPSS) is developed in this paper, which widely exists in many practical sectors such as power plants, inventory management and security management. In SPSS the failure states of each unit are divided into two classes according to their consequences: dangerous failure and safe failure, where the former results in system failure while the latter has no impact on the system. Suppose that when a failure unit appears in SPSS, the system fails with probability p while the other units in SPSS can continue working with probability 1−p. This paper treats the problem of achieving optimal allocation of units in SPSSs that maximizes expected total working time of all units. Three optimal allocation models are formulated. We derive the analytical expressions for the optimal allocation solutions under certain assumptions. A genetic algorithm and a Monte Carlo method are provided to solve the allocation problems whose analytical solutions are difficult to obtain. An application can be found in Remote Power Feeding System (RPFS). Numerical examples for a RPFS are presented to demonstrate the application of the developed approach in each model. © 2017 Elsevier Ltd","Genetic algorithm; Monte Carlo; Optimal allocation; Remote Power Feeding System; Sequential probability series systems","Genetic algorithms; Inventory control; Materials handling equipment; Monte Carlo methods; Probability; Systems engineering; Allocation problems; Analytical expressions; Inventory management; Optimal allocation; Optimal allocation models; Remote power feeding; Security management; Series system; Outages",2-s2.0-85030567333
"Biagetti G., Crippa P., Falaschetti L., Orcioni S., Turchetti C.","Speaker identification in noisy conditions using short sequences of speech frames",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020386534&doi=10.1007%2f978-3-319-59424-8_5&partnerID=40&md5=1a6d4a755b8874faafda01999c32f87b","The application of speaker recognition technologies on domotic systems, cars, or mobile devices such as tablets, smartphones and smartwatches faces with the problem of ambient noise. This paper studies the robustness of a speaker identification system when the speech signal is corrupted by the environmental noise. In the everyday scenarios the noise sources are highly time-varying and potentially unknown. Therefore the noise robustness must be investigated in the absence of information about the noise. To this end the performance of speaker identification using short sequences of speech frames was evaluated using a database with simulated noisy speech data. This database is derived from the TIMIT database by rerecording the data in the presence of various noise types, and is used to test the model for speaker identification with a focus on the varieties of noise. Additionally, in order to optimize the recognition performance, in the training stage the white noise has been added as a first step towards the generation of multicondition training data to model speech corrupted by noise with unknown temporal-spectral characteristics. The experimental results demonstrated the validity of the proposed algorithm for speaker identification using short portions of speech also in realistic conditions when the ambient noise is not negligible. © Springer International Publishing AG 2018.","Cepstral analysis; Classification; Digitized voice samples; Discrete Karhunen-Loéve transform (DKLT); Environmental noise; Expectation Maximization (EM) algorithm; Feature extraction; Gaussian Mixture Model (GMM); Noise; Noisy conditions; Robust speaker identification; Short sequences; Speech; Speech frames; TIMIT","Acoustic noise; Classification (of information); Database systems; Feature extraction; Gaussian distribution; Image segmentation; Loudspeakers; Maximum principle; Speech; White noise; Cepstral analysis; Environmental noise; Expectation-maximization algorithms; Gaussian Mixture Model; Noise; Noisy conditions; Robust speaker identification; Short sequences; Speech frames; TIMIT; Speech recognition",2-s2.0-85020386534
"Tang J., Liu F., Zhang W., Ke R., Zou Y.","Lane-changes prediction based on adaptive fuzzy neural network",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029525192&doi=10.1016%2fj.eswa.2017.09.025&partnerID=40&md5=d1d6bceb4121e19ad32c5fa259cd4b0e","Lane changing maneuver is one of the most important driving behaviors. Unreasonable lane changes can cause serious collisions and consequent traffic delays. High precision prediction of lane changing intent is helpful for improving driving safety. In this study, by fusing information from vehicle sensors, a lane changing predictor based on Adaptive Fuzzy Neural Network (AFFN) is proposed to predict steering angles. The prediction model includes two parts: fuzzy neural network based on Takagi–Sugeno fuzzy inference, in which an improved Least Squares Estimator (LSE) is adopt to optimize parameters; adaptive learning algorithm to update membership functions and rule base. Experiments are conducted in the driving simulator under scenarios with different speed levels of lead vehicle: 60 km/h, 80 km/h and 100 km/h. Prediction results show that the proposed method is able to accurately follow steering angle patterns. Furthermore, comparison of prediction performance with several machine learning methods further verifies the learning ability of the AFNN. Finally, a sensibility analysis indicates heading angles and acceleration of vehicle are also important factors for predicting lane changing behavior. © 2017 Elsevier Ltd","Adaptive learning algorithm; Driving simulation; Fuzzy neural network; Lane changes; Steering prediction","Automobile steering equipment; Forecasting; Fuzzy logic; Fuzzy neural networks; Inference engines; Learning algorithms; Learning systems; Membership functions; Steering; Vehicles; Adaptive fuzzy neural network; Adaptive learning algorithm; Driving simulation; Lane change; Lane-changing behaviors; Least-squares estimator; Machine learning methods; Prediction performance; Fuzzy inference",2-s2.0-85029525192
"Feng J., Li X., Mao B., Xu Q.","Optimal model of timetable under the influence of train speed on the utilization rate of regenerative braking",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026772486&doi=10.1007%2f978-981-10-3551-7_78&partnerID=40&md5=dc829be43cf124ffdf2f1a8631987fdc","With expanded development of subway systems, regenerative braking energy utilization has been intensively studied from a timetable synchronize point of view. Yet, even successful modeling approaches such as those based on regenerative braking technique still do not fully take into account the fact that at lower than threshold speed, no energy can be utilized. To achieve a better performance on energy-efficient operation with the actual problem, this paper formulated a timetable rescheduling model (TR model) to optimize the timetable by maximizing the overlapping time between accelerating and regenerative braking actions of trains in the same substation with the consideration of regenerative braking process. We design a genetic algorithm (GA) to solve the model and present some numerical experiments based on the actual operation data of Beijing Yizhuang subway line in China. It is shown that the model can reduce the energy consumption by 25.3% compared with the current timetable. In addition, numerical experiments show that the dwell-time and lower limits of headway have a strong effort on regenerative energy utilization. © Springer Science+Business Media Singapore 2018.","Genetic algorithm; Regenerative braking; Subway system","Braking performance; Energy efficiency; Energy utilization; Genetic algorithms; Intelligent systems; Intelligent vehicle highway systems; Railroads; Scheduling; Subways; Transportation; Actual operation; Energy efficient operations; Numerical experiments; Regenerative braking energies; Regenerative energy; Subway systems; Threshold speed; Utilization rates; Regenerative braking",2-s2.0-85026772486
"Lee J.H., Kim H., Song Y.-H.","A Study on verification of changes in performance of a water-cooled VRF system with control change based on measuring data",2018,"Energy and Buildings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032877812&doi=10.1016%2fj.enbuild.2017.10.014&partnerID=40&md5=85425f659207055e4a2703626c461242","A variable refrigerant flow (VRF) system is convenient to install and manage as well as the operability via occupants is superior compared to a chiller system. Thus, the use of the VRF system has increased in East Asia and Europe in recent years. In particular, a water-cooled VRF system can solve a space problem of installation for outdoor units in existing air-cooled systems. Thus, it can be applicable to large-sized buildings. However, most cooling tower operations are done with the same setup regardless of the changes in outdoor conditions during the operating period, which is a conservative method for a water-cooled mode. The present study aims to improve the performance of outdoor units in the VRF by reducing the temperature of cooling water to a lower temperature than the existing setup value and verify this through actual measurements. To do this, a new algorithm for a cooling tower operation was developed and applied to a six-week operation during the summer to analyze the effect of the change in setup value. The result showed that power consumption of the cooling tower system and VRF outdoor unit was reduced by 24% and 5.9%, respectively due to the new setup and the coefficient of performance (COP) of the outdoor unit and system was improved by 7.3% and 12.7%, respectively thereby reducing an operation cost by 11%. © 2017 Elsevier B.V.","Algorithm; Cooling tower; Energy usage; High-efficiency; Variable refrigerant flow (VRF)","Algorithms; Cooling; Cooling systems; Cooling towers; Refrigerants; Towers; Actual measurements; Air cooled systems; Coefficient of Performance; Energy usage; High-efficiency; Lower temperatures; Operating periods; Refrigerant flow; Cooling water",2-s2.0-85032877812
"Mosaad M.I., Elkalashy N.I., Ashmawy M.G.","Integrating adaptive control of renewable distributed Switched Reluctance Generation and feeder protection coordination",2018,"Electric Power Systems Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029811584&doi=10.1016%2fj.epsr.2017.09.017&partnerID=40&md5=7ece719a68cd803e84bc9ae2f8bc37f3","This paper proposes an adaptive Proportional Integral (PI) control scheme of interconnected wind turbine-based distributed Switched Reluctance Generation (SRG). The introduced control facilitates the integration of protective relaying coordination of the distribution feeder using Artificial Neural Network (ANN). It adapts the turn-off angle of the SRG by the ANN-PI controller to regulate the injected power (and accordingly limits the injected current) from the generation unit to the network to avoid incorrect overcurrent protection coordination during grid faults. The parameters of the PI control are tuned off-line using Genetic Algorithm (GA) in order to minimize the associated Integral of Square of Error (ISE) between the reference updated power (function of the SRG voltage) and the SRG power over a wide range of abnormal grid conditions. The values of the reference updated power, the voltage level at SRG, and the corresponding optimized PI control parameters by GA are used to off-line training ANN. This proposed ANN-PI controller turns the controller into on-line one. Therefore, the proposed adaptive ANN-PI techniques could, on-line, tune the PI controller parameters for realizing an optimal response and integrating the SRG with the protection coordination by adapting the turn-off angle of SRG. By evaluating the proposed control integration with the protection coordination of an 11 kV Egyptian distribution feeder, the results provide evidences of efficient and robust performance of the proposed control for renewable distributed Switched Reluctance Generation either in steady state operation or during faults in distribution feeders. © 2017 Elsevier B.V.","Artificial Neural Network (ANN); Distributed generation (DG); Genetic Algorithm (GA); PI controller; Switched Reluctance Generation (SRG); Wind energy","Electric power system control; Electric power transmission networks; Feeding; Genetic algorithms; Neural networks; Overcurrent protection; Two term control systems; Wind power; Wind turbines; Control integration; Distribution feeders; PI Controller; PI controller parameters; Proportional-integral control; Protection coordination; Steady-state operation; Switched reluctance; Controllers",2-s2.0-85029811584
"Blum C., Blesa M.J.","Hybrid techniques based on solving reduced problem instances for a longest common subsequence problem",2018,"Applied Soft Computing Journal",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032285162&doi=10.1016%2fj.asoc.2017.10.005&partnerID=40&md5=79e4a29243e0d71abead5e52d0fe91f0","Finding the longest common subsequence of a given set of input strings is a relevant problem arising in various practical settings. One of these problems is the so-called longest arc-preserving common subsequence problem. This NP-hard combinatorial optimization problem was introduced for the comparison of arc-annotated ribonucleic acid (RNA) sequences. In this work we present an integer linear programming (ILP) formulation of the problem. As even in the context of rather small problem instances the application of a general purpose ILP solver is not viable due to the size of the model, we study alternative ways based on model reduction in order to take profit from this ILP model. First, we present a heuristic way for reducing the model, with the subsequent application of an ILP solver. Second, we propose the application of an iterative hybrid algorithm that makes use of an ILP solver for generating high quality solutions at each iteration. Experimental results concerning artificial and real problem instances show that the proposed techniques outperform an available technique from the literature. © 2017 Elsevier B.V.","Combinatorial optimization; Heuristic; Hybrid algorithm; Integer linear programming; Longest common subsequences","Combinatorial optimization; Data transfer; Heuristic programming; Integer programming; Iterative methods; Nucleic acids; Object recognition; Optimization; RNA; Combinatorial optimization problems; Heuristic; High-quality solutions; Hybrid algorithms; Integer Linear Programming; Longest arc-preserving common subsequences; Longest common subsequence problem; Longest common subsequences; Problem solving",2-s2.0-85032285162
"Tran D.K., Unoki M.","Study on speech representation based on spikegram for speech fingerprints",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026639316&doi=10.1007%2f978-3-319-63859-1_20&partnerID=40&md5=c8f675c8609cceaea204fdfedb2f9412","This paper investigates the abilities of spikegrams in representing the content and voice identifications of speech signals. Current speech representation models employ block-based coding techniques to transform speech signals into spectrograms to extract suitable features for further analysis. One issue with this approach is that a speaker produces different speech signals for the same speech content; therefore, processing speech signals in a piecewise manner will result in different spectrograms, and consequently, different fingerprints will be produced for the same spoken words by the same speaker. For this reason, the consistency of speech representation models in the variations of speech is essential to obtain accurate and reliable speech fingerprints. It has been reported that sparse coding surpasses block-based coding in representing speech signals in the way that it is able to capture the underlying structures of speech signals. An over-complete representation model - known as a spikegram - can be created by using a matching pursuit algorithm and Gammatone dictionary to provide a better alternative to a spectrogram. This paper reports the ability of spikegrams in representing the speech content and voice identities of speakers, which can be used for improving the robustness of speech fingerprints. © Springer International Publishing AG 2018.","Gammatone filterbank; Matching pursuit algorithm; Non-negative matrix factorization; Speech fingerprint; Spikegram","Codes (symbols); Factorization; Multimedia signal processing; Signal processing; Spectrographs; Speech; Speech communication; Coding techniques; Gammatone filterbank; Matching pursuit algorithms; Nonnegative matrix factorization; Over-complete representations; Representation model; Spikegram; Voice identification; Audio signal processing",2-s2.0-85026639316
"Han Z., Wang J.","A Fault Diagnosis Method Based on Active Example Selection",2018,"Journal of Circuits, Systems and Computers",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020484759&doi=10.1142%2fS0218126618500135&partnerID=40&md5=ae7cc568453fee3ade5bb923cd57113b","The fault diagnosis in the real world is often complicated. It is due to the fact that not all relevant fault information is available directly. In many fault diagnosis situations, it is impossible or inconvenient to find all fault information before establishing a fault diagnosis model. To deal with this issue, a method named active example selection (AES) is proposed for the fault diagnosis. AES could actively discover unseen faults and choose useful samples to improve the fault detection accuracy. AES consists of three key components: (1) a fusion model of combining the advantage of the unsupervised and supervised fault diagnosis methods, where the unsupervised fault diagnosis methods could discover unseen faults and the supervised fault diagnosis methods could provide better fault detection accuracy on seen faults, (2) an active learning algorithm to help the supervised fault diagnosis methods actively discover unseen faults and choose useful samples to improve the fault detection accuracy, and (3) an incremental learning scheme to speed up the iterative training procedure for AES. The proposed method was evaluated on the benchmark Tennessee Eastman Process data. The proposed method performed better on both unseen and seen faults than the stand-alone unsupervised, supervised fault diagnosis methods, their joint and referenced support vector machines based on active learning. © 2018 World Scientific Publishing Company.","active learning; data drive; Fault diagnosis; TEP","Artificial intelligence; Digital storage; Failure analysis; Iterative methods; Learning algorithms; Active Learning; Active-learning algorithm; Data drives; Fault diagnosis method; Fault diagnosis model; Incremental learning; Tennessee Eastman process; Training procedures; Fault detection",2-s2.0-85020484759
"Son L.H., Tuan T.M., Fujita H., Dey N., Ashour A.S., Ngoc V.T.N., Anh L.Q., Chu D.-T.","Dental diagnosis from X-Ray images: An expert system based on fuzzy computing",2018,"Biomedical Signal Processing and Control",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026747662&doi=10.1016%2fj.bspc.2017.07.005&partnerID=40&md5=854ee6251a3a563a1aa334b836e7cdda","Background Computerized medical diagnosis systems from X-Ray images are of great interest to physicians for accurate decision making of possible diseases and treatments. Subclinical disease has no recognizable clinical findings, thus it is desirable to segment the dental X-Ray image into groups and then use soft computing methods to check the possibility of whether or not any disease occurs therein. Methods The current work proposed a novel framework called Dental Diagnosis System (DDS) for dental diagnosis based on the hybrid approach of segmentation, classification and decision making. It utilized the best dental image segmentation method based on semi-supervised fuzzy clustering for the segmentation task. A new graph-based clustering algorithm called APC+ for the classification task was proposed. A new decision making procedure was designed to determine the final disease from a group of diseases found from the segments. Results The proposed DDS was modeled under the real dental case of Hanoi Medical University, Vietnam including 87 dental images of five popular diseases, namely: root fracture, incluse teeth, decay, missing teeth, and resorption of periodontal bone. The DDS accuracy is 92.74% which is superior to the other methods namely fuzzy inference system (89.67%), fuzzy k-nearest neighbor (80.05%), prim spanning tree (58.46%), kruskal spanning tree (58.46%), and affinity propagation clustering (90.01%). Conclusion Empirical results established that superior performance of the DDS to other related methods the findings of the achieved results can assist dental clinicians in their professional work. © 2017 Elsevier Ltd","Decision making; Dental X-Ray image; Graph-based clustering; Medical diagnosis; Semi-Supervised fuzzy clustering","Clustering algorithms; Computer aided diagnosis; Decision making; Expert systems; Fuzzy clustering; Fuzzy inference; Graphic methods; Image segmentation; Medical imaging; Nearest neighbor search; Soft computing; X ray analysis; Affinity propagation clustering; Decision making procedure; Dental X-ray image; Fuzzy inference systems; Fuzzy k nearest neighbor (FKNN); Graph-based clustering; Medical diagnosis system; Semi-supervised; Diagnosis; adolescent; adult; algorithm; Article; decision making; dental caries; expert system; female; fuzzy system; human; image segmentation; k nearest neighbor; major clinical study; male; priority journal; tooth disease; tooth fracture; tooth radiography; X ray picture; young adult",2-s2.0-85026747662
"Liu F., Zhu W., Zhao J.","Model-based dynamic optimal control of a CO2 heat pump coupled with hot and cold thermal storages",2018,"Applied Thermal Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029679394&doi=10.1016%2fj.applthermaleng.2017.09.098&partnerID=40&md5=4e44699a13d0a48730ad403c266eff67","This study presents a model-based dynamic optimization strategy for a dual-mode CO2 heat pump coupled with hot and cold thermal storages, which was proposed as a high-efficiency smart grid enabling option in heating and cooling services for buildings or industry. Dynamic optimal control for simultaneously charging of hot and cold thermal storages is very delicate. The optimal control of compressor discharge pressure were commonly used for optimal control of heat pump systems. In this study, the outlet water temperatures of hot and cold tanks are used as indicators in the dynamic optimal strategy for charging of hot and cold storages using a dual-mode heat pump. The Modelica based dynamic model of the coupled system was developed and validated. To optimize the overall coefficient of performance (COP) during energy process, the transient total COP is optimized by genetic algorithm based on Modelica-based modeling of dynamic system. A dynamic optimal control strategy was developed and implemented into an experimental system. Test results show that this developed model-based dynamic optimal control strategy is able to search the optimal transient total COP and optimize the overall COP of such coupled systems during energy charging; and the optimal results is better than those obtained using another two experiment-based methods. © 2017 Elsevier Ltd","CO2 heat pump; Dynamic optimal control; Genetic algorithm; Hot and cold storage; Modelica-based modeling","Carbon dioxide; Cold storage; Genetic algorithms; Heat convection; Optimal control systems; Optimization; Pumps; Coefficient of Performance; Cold thermal storage; Compressor discharge pressures; Heat pumps; Modelica; Optimal control strategy; Optimal controls; Outlet-water temperatures; Heat pump systems",2-s2.0-85029679394
"Fu X., Lu W., Zhu L., Zhou S.","Study of the establishment of a reliable English-Chinese machine translation system based on artificial intelligence",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028423686&doi=10.1007%2f978-3-319-60744-3_2&partnerID=40&md5=63d5ae6152389fd07abd78164cc75406","Since twenty-first Century, more and more communication among different countries has made the need for the language translation of the enterprises and individuals more and more. Artificial translation is accurate, but the cost is too high and time-consuming; while the cost of the machine translation is not only low, but the speed is fast. However, the accuracy of machine translation has been criticized by users, therefore, how to build a new generation of machine translation system to improve the accuracy has been imminent. Based on this, a reliable English-Chinese machine translation system based on artificial intelligence is established in this paper, and the principles that should be followed in the process of establishing the system are described in detail, the overall framework, the translation algorithm and the working flow of the system are discussed, and the sentence alignment method based on the translation is proposed. The research results show that the reliable English-Chinese machine translation system based on artificial intelligence designed in this paper can improve the credibility and accuracy of machine translation. © 2018, Springer International Publishing AG.","Artificial intelligence; English-Chinese machine translation; Reliability; Translation algorithm","Artificial intelligence; Computer aided language translation; Intelligent systems; Real time systems; Reliability; Language translation; Machine translation systems; Machine translations; Research results; Sentence alignment; Translation algorithms; Computational linguistics",2-s2.0-85028423686
"Beitollahi A., Kaveh A., Mahdavi V.R.","Locating emergency facilities using the weighted k-median problem: A graph-metaheuristic approach",2018,"Periodica Polytechnica Civil Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032676608&doi=10.3311%2fPPci.10665&partnerID=40&md5=7cc12f076dd150564fb6934dd0b31db0","An efficient approach is presented for addressing the problem of finding the optimal facilities location in conjunction with the k-median method. First the region to be investigated is meshed and an incidence graph is constructed to obtain connectivity properties of meshes. Then shortest route trees (SRTs) are rooted from nodes of the generated graph. Subsequently, in order to divide the nodes of graph or the studied region into optimal k subregions, k-median approach is utilized. The weights of the nodes are considered as the risk factors such as population, seismic and topographic conditions for locating facilities in the high-risk zones to better facilitation. For finding the optimal facility locations, a recently developed meta-heuristic algorithm that is called Colliding Bodies Optimization (CBO) is used. The performance of the proposed method is investigated through different alternatives for minimizing the cost of the weighted k-median problem. As a case study, the Mazandaran province in Iran is considered and the above graph-metaheuristic approach is utilized for locating the facilities. © 2017, Budapest University of Technology and Economics. All rights reserved.","Colliding bodies optimization; Graph methods; Optimal locating; Risk; Weighted k-median method","Heuristic algorithms; Location; Optimization; Risks; Trees (mathematics); Colliding bodies; Connectivity properties; Graph methods; K-median methods; Meta heuristic algorithm; Meta-heuristic approach; Optimal facility location; Optimal locating; Graph theory",2-s2.0-85032676608
"Song J., Cui L., Ma X., Su Y., Huang Z., Wang M.","Optimization the fermentation conditions of marasmius androsaceus by desirability function method",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032878039&doi=10.1007%2f978-981-10-4801-2_26&partnerID=40&md5=505a18dadcd7e9421cc0859891c65f2f","The objective of this study is to optimize fermentation conditions for large production of Marasmius androsaceus biomass and metablites production. The desirability function and chemometric methods were applied to optimize the fermentation conditions of M. androsaceus fermentation conditions in a 500 mL shake flask. Based on the desirability function methods, Plackett-Burman (PB) design was employed to optimize fermentation process parameters (culturing temperature, rotating speed, culture time, initial pH, inoculum size, inoculum age and inoculum volume). Culturing temperature, rotating speed were found to significantly impact Da value which were chosen as assessment criteria and were further optimized by Box-Behnken (BB) design. The response surface regression (RSM) and artificial neural network-genetic algorithm (ANN-GA) were employed to analyze the results. Finally, the optimum M. androsaceus submerged fermentation condition in a 500 mL shake flask were obtained as follows: initial pH of 6.0, rotating speed of 169 rpm, culture time 6.57 days, culture temperature 26.7 °C, inoculum size of 5%, inoculum age of 4 days and a loading volume of 200/500 mL, then the predictive Da value was 0.5059 and the average experimental Da value was 0.4941. The model possesses successfully fitness and more this study also provides experimental evidence that PB design and RSM are effective tools for mathematical modeling and factor analysis of optimization the fermentation process. © Springer Nature Singapore Pte Ltd. 2018.","Artifical neutral network combining genetic algorithm; Desirability function; Marasmius androsaceus; Optimization","Biotechnology; Bottles; Genetic algorithms; Neural networks; Optimization; Process control; Rotating machinery; Desirability function; Experimental evidence; Fermentation conditions; Fermentation process; Marasmius androsaceus; Neutral network; Plackett -burman design; Submerged fermentation; Fermentation",2-s2.0-85032878039
"Hwang Y.N., Lee J.H., Kim G.Y., Shin E.S., Kim S.M.","Characterization of coronary plaque regions in intravascular ultrasound images using a hybrid ensemble classifier",2018,"Computer Methods and Programs in Biomedicine",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031794120&doi=10.1016%2fj.cmpb.2017.10.009&partnerID=40&md5=e1640c2e4a84cc140c42ccfb4a41ce06","Background and objectives The purpose of this study was to propose a hybrid ensemble classifier to characterize coronary plaque regions in intravascular ultrasound (IVUS) images. Methods Pixels were allocated to one of four tissues (fibrous tissue (FT), fibro-fatty tissue (FFT), necrotic core (NC), and dense calcium (DC)) through processes of border segmentation, feature extraction, feature selection, and classification. Grayscale IVUS images and their corresponding virtual histology images were acquired from 11 patients with known or suspected coronary artery disease using 20 MHz catheter. A total of 102 hybrid textural features including first order statistics (FOS), gray level co-occurrence matrix (GLCM), extended gray level run-length matrix (GLRLM), Laws, local binary pattern (LBP), intensity, and discrete wavelet features (DWF) were extracted from IVUS images. To select optimal feature sets, genetic algorithm was implemented. A hybrid ensemble classifier based on histogram and texture information was then used for plaque characterization in this study. The optimal feature set was used as input of this ensemble classifier. After tissue characterization, parameters including sensitivity, specificity, and accuracy were calculated to validate the proposed approach. A ten-fold cross validation approach was used to determine the statistical significance of the proposed method. Results Our experimental results showed that the proposed method had reliable performance for tissue characterization in IVUS images. The hybrid ensemble classification method outperformed other existing methods by achieving characterization accuracy of 81% for FFT and 75% for NC. In addition, this study showed that Laws features (SSV and SAV) were key indicators for coronary tissue characterization. Conclusions The proposed method had high clinical applicability for image-based tissue characterization. © 2017 Elsevier B.V.","Ensemble classifier; Genetic algorithm; Intravascular ultrasound; Plaque characterization","Biological organs; Characterization; Content based retrieval; Diseases; Fast Fourier transforms; Feature extraction; Genetic algorithms; Heart; Histology; Image classification; Image processing; Tissue; Ultrasonics; Coronary artery disease; Ensemble classifiers; Gray level co occurrence matrix(GLCM); Intravascular ultrasound; Intravascular ultrasound images; Plaque characterizations; Statistical significance; Tissue characterization; Classification (of information); adipose tissue; adult; aged; Article; chronic total occlusion; clinical article; controlled study; coronary artery atherosclerosis; female; genetic algorithm; histogram; human; human tissue; intravascular ultrasound; male; sensitivity and specificity; tissue characterization; unstable angina pectoris",2-s2.0-85031794120
"Shen Y., Fu Q., Zhang D., Na P.","A systematic simulation and optimization of an industrial-scale p-xylene simulated moving bed process",2018,"Separation and Purification Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029035787&doi=10.1016%2fj.seppur.2017.08.064&partnerID=40&md5=b5b1944c33ffad903cd5fefedb2f1af5","This work presents a detailed study for the systematic analysis, simulation and optimization of an industrial-scale simulated moving bed process with Ba/K-exchanged faujasite-type zeolite as adsorbent for separating p-xylene from the C8 aromatic mixture. The adsorption equilibrium of C8 aromatic isomers and p-diethylbenzene on the commercial adsorbent were determined experimentally, while the lumped mass transfer coefficients were estimated through pulse experimental results. A generic mathematic model incorporating the fixed model, node model as well as dead volume model was developed to implement a numerical simulation of an industrial-scale p-xylene simulated moving bed process. Moreover, the accuracy of mathematic model was validated by industrial data. Furthermore, a dynamic optimization framework, with state of the art Sequential Quadratic programming optimization algorithm, was firstly proposed to obtain the optimal operating conditions for an existing industrial simulated moving bed unit. Optimization results reflect that the desorbent consumption of p-diethylbenzene was favorable to be selected as objective function to be minimized, which could achieve 3.12% increase in SMB unit productivity and 8.66% decrease in desorbent consumption for seven zone p-xylene simulated moving bed process. Two-level optimization procedure was also constructed to get the maximum feed throughput with a desired minimized desorbent consumption. Under the optimal operating conditions, the productivity increases by 16.63% while the PDEB consumption decreases by 18.85% for seven zone p-xylene simulated moving bed process. Eight zone p-xylene simulated moving bed process as a new operating mode, which was also analyzed, emulated and optimized through numerical calculation. Results show that the eight zone operation could achieve a much higher productivity and the desorbent consumption of p-diethylbenzene was almost the same in comparison with seven zone operation. © 2017 Elsevier B.V.","Modeling; Optimization; para-Xylene; Simulated moving bed; SQP algorithm","Aromatic compounds; Isomers; Mass transfer; Models; Productivity; Quadratic programming; Xylene; Optimal operating conditions; Optimization algorithms; Para-xylene; Sequential quadratic programming; Simulated Moving Bed; Simulated moving bed process; Simulation and optimization; SQP algorithm; Optimization",2-s2.0-85029035787
"Ranjbar S., Aghamohammadi M., Haghjoo F.","A new scheme of WADC for damping inter-area oscillation based on CART technique and Thevenine impedance",2018,"International Journal of Electrical Power and Energy Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026788194&doi=10.1016%2fj.ijepes.2017.07.010&partnerID=40&md5=abcc0fa711d6d1061966cb1295299030","In this paper, based on the CART technique and wide area measurement system (WAMS), a new scheme of wide area damping controller (WADC) is presented for inter-area oscillation in which each generator is equipped with an individual WADC which works based on the global inter-area signals. The proposed WADC scheme is an individual controller which uses angle and speed deviation of the center of inertia of the oscillating areas as global inter-area signals (GIS) (ΔωCOI, ΔδCOI). Each individual WADC consists of two CART1 and CART2 which perform as optimal gain estimators for estimating optimal gains K1 and K2 of the individual WADC of each generator. In fact, the proposed WADC scheme is an online and non-model based controller consisting of two CARTs which estimate optimal gains (K1, K2) from which inter-area control signal (ICS) is produced for direct presentation to AVR of generators. In this scheme, for selecting the most effective generators for participating in damping control, a combination index (CI) is presented which is maximized by binary genetic algorithm (BGA) for achieving most damping. The proposed CI index consists of generation pattern and Thevenin impedance of generators. For this purpose, for online estimation of Thevenin impedance of generators, an online approach is presented in which by using three consecutive measurements Thevenin impedance of generators are evaluated. The proposed CARTs are trained off line and then in the real time working mode of the proposed approach by using online GIS signals estimate optimal gains K1 and K2 from which individual control signal is deveopled. The proposed control scheme is demonstrated on IEEE 39-bus test system with promising damping effect for inter-area oscillation. © 2017 Elsevier Ltd","CART technique; Inter-area oscillations; Thevenin impedance; WAMS; Wide area damping controller (WADC)","Circuit oscillations; Damping; Electric power system measurement; Estimation; Genetic algorithms; Intelligent control; Vehicles; Binary genetic algorithm; CART technique; Consecutive measurements; Damping controllers; Damping inter-area oscillations; Inter-area oscillations; Thevenin impedance; Wide- area measurement systems (WAMS); Controllers",2-s2.0-85026788194
"Roy S., Banerjee R.","Multi-objective optimization of the performance-emission trade-off characteristics of a CRDI coupled CNG diesel dual-fuel operation: A GEP meta-model assisted MOGA endeavour",2018,"Fuel",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030830166&doi=10.1016%2fj.fuel.2017.10.003&partnerID=40&md5=f52617b27204cdd99cb8a9cd5bb4b7a3","A meta-model based multi-objective optimization endeavor was undertaken in the present work to investigate the potential of the off-line model based calibration technique to extend the actual CRDI-CNG dual-fuel experimental investigations in determining the possibility of unearthing viable potential trade-off domains hitherto unexplored by the constraints of resources, cost and time warranted by an experimental investigation. For the ensuing optimization study, CNG energy share, fuel injection pressure and load have been used as the decision variables while PM, NHC and BSFC were chosen as the output variables to be optimized. In absence of a closed form correlation between the participating variables under study, the explicit characterization capability of the Gene Expression Programming technique was harnessed. The appropriate GEP based meta-models were adopted from a previous study correlating the identical system output responses for the same set of decision variables of interest in the present study. Genetic algorithm was chosen as the optimization routine in the present study in view of its promising potential of extremely fast convergent speed, diversity of optimal solutions and simplicity of operation. Experimental validation of the obtained solutions pertaining to the desired objectives were carried out by actual experimentation. The present optimization endeavor was able to better the best vantage in category of the desired objective of minimum fuel consumption and exhaust emissions, obtained not only as compared to baseline diesel operation comprehensively but also was superior than the actual CRDI-CNG strategy during actual dual-fuel operation corresponding to actual experimentation. © 2017 Elsevier Ltd","CNG; Diesel; Gene Expression Programming; Genetic Algorithm; PM-NHC-BSFC optimization","Decision making; Economic and social effects; Fuels; Gene expression; Genes; Genetic algorithms; Optimization; Diesel; Experimental investigations; Experimental validations; Gene expression programming; Injection pressures; Minimum fuel consumption; Optimization routine; Optimization studies; Multiobjective optimization",2-s2.0-85030830166
"Nougarou F., Massicotte D., Descarreaux M.","Efficient procedure to remove ECG from sEMG with limited deteriorations: Extraction, quasi-periodic detection and cancellation",2018,"Biomedical Signal Processing and Control",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026728417&doi=10.1016%2fj.bspc.2017.07.019&partnerID=40&md5=97a7a3a279cd58f10be60346e649b611","The interpretations of the surface electromyography (sEMG) signals from the trunk region are strongly distorted by the heart activity (ECG), especially in case of low-amplitude EMG responses analyses. Many methods have been investigated to resolve this nontrivial problem, by using advanced data processing on the overall sEMG recorded signal. However, if they reduce ECG artifacts, those cancellation methods also deteriorate noiseless parts of the signal. This work proposes an original ECG cancellation method designed to limit the deterioration of sEMG information. To do that, the proposed techniques does not directly attempt to remove the ECG, but is based on two main steps: the localization of ECG and the cancellation of ECG but only where heart pulses have been detected. The phase of localization efficiently extracts the ECG contribution by combining the discrete wavelet transforms (DWT) and the method of independent component analysis (ICA). And finally, this phase takes advantage of quasi-periodic properties of ECG signals to accurately detect pulses localization with an original algorithm based on the fast Fourier transform (FFT). Intensive simulations were achieved in terms of relative errors, coherence and accuracy for different levels of ECG interference. And the correlation coefficients computed from the paraspinal muscles EMG signals of 12 healthy participants were also used to evaluate the developed method. The results from simulation and real data demonstrate that the proposed method accurately detects pulses positions and efficiently removes the ECG from EMG signals, even when both signals are strongly overlapped, and greatly limits the deterioration of the EMG. © 2017 Elsevier Ltd","Discrete wavelet transforms; ECG cancellation; Independent component analysis; Quasi-periodic signals detection","Data handling; Deterioration; Discrete wavelet transforms; Electrocardiography; Electromyography; Fast Fourier transforms; Independent component analysis; Wavelet transforms; Advanced data processing; Correlation coefficient; Independent component analysis(ICA); Original algorithms; Paraspinal muscles; Quasi-periodic signals; Recorded signals; Surface electromyography; Signal detection; adult; algorithm; Article; correlation coefficient; discrete wavelet transform; electrocardiogram; electromyograph electrode; electromyography; evaluation study; extraction; Fourier transformation; human; human experiment; independent component analysis; information; information processing; intermethod comparison; measurement accuracy; measurement error; normal human; paraspinal muscle; priority journal; pulse rate; sensor; signal detection; simulation; validation study; young adult",2-s2.0-85026728417
"Anderson K.E., Glenn N.F., Spaete L.P., Shinneman D.J., Pilliod D.S., Arkle R.S., McIlroy S.K., Derryberry D.R.","Estimating vegetation biomass and cover across large plots in shrub and grass dominated drylands using terrestrial lidar and machine learning",2018,"Ecological Indicators",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030456606&doi=10.1016%2fj.ecolind.2017.09.034&partnerID=40&md5=2a2219373f5e5114ae9d1235f48b53f4","Terrestrial laser scanning (TLS) has been shown to enable an efficient, precise, and non-destructive inventory of vegetation structure at ranges up to hundreds of meters. We developed a method that leverages TLS collections with machine learning techniques to model and map canopy cover and biomass of several classes of short-stature vegetation across large plots. We collected high-definition TLS scans of 26 1-ha plots in desert grasslands and big sagebrush shrublands in southwest Idaho, USA. We used the Random Forests machine learning algorithm to develop decision tree models predicting the biomass and canopy cover of several vegetation classes from statistical descriptors of the aboveground heights of TLS points. Manual measurements of vegetation characteristics collected within each plot served as training and validation data. Models based on five or fewer TLS descriptors of vegetation heights were developed to predict the canopy cover fraction of shrubs (R2 = 0.77, RMSE = 7%), annual grasses (R2 = 0.70, RMSE = 21%), perennial grasses (R2 = 0.36, RMSE = 12%), forbs (R2 = 0.52, RMSE = 6%), bare earth or litter (R2 = 0.49, RMSE = 19%), and the biomass of shrubs (R2 = 0.71, RMSE = 175 g) and herbaceous vegetation (R2 = 0.61, RMSE = 99 g) (all values reported are out-of-bag). Our models explained much of the variability between predictions and manual measurements, and yet we expect that future applications could produce even better results by reducing some of the methodological sources of error that we encountered. Our work demonstrates how TLS can be used efficiently to extend manual measurement of vegetation characteristics from small to large plots in grasslands and shrublands, with potential application to other similarly structured ecosystems. Our method shows that vegetation structural characteristics can be modeled without classifying and delineating individual plants, a challenging and time-consuming step common in previous methods applying TLS to vegetation inventory. Improving application of TLS to studies of shrub-steppe ecosystems will serve immediate management needs by enhancing vegetation inventories, environmental modeling studies, and the ability to train broader datasets collected from air and space. © 2017 Elsevier Ltd","Biomass; Carbon; Classification; Land cover; Lidar; Machine learning; Point cloud; Rangelands; Remote sensing; Structure from motion (SfM); Vegetation type","Artificial intelligence; Biomass; Carbon; Classification (of information); Data mining; Decision trees; Ecology; Ecosystems; Forecasting; Learning algorithms; Learning systems; Optical radar; Plants (botany); Remote sensing; Seebeck effect; Surveying instruments; Land cover; Point cloud; Rangelands; Structure from motion; Vegetation type; Vegetation; algorithm; environmental modeling; grass; lidar; machine learning; phytomass; shrub; shrubland; vegetation cover; vegetation structure; Idaho; United States; Artemisia tridentata; Poaceae",2-s2.0-85030456606
"Dhivya R., Justin J.","Assessment of speech denoising using a perceptual measure-PESQ",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028617560&doi=10.1007%2f978-3-319-60618-7_27&partnerID=40&md5=c265f9959e610867a8de668b0b83c45b","In this research work, speech denoising algorithms are assessed and their performances are evaluated using Perceptual Evaluation of Speech Quality (PESQ) measure. The spatial domain algorithms - Spectral Subspace algorithms, Statistical model based algorithm, Spectral Subtraction algorithm and Wiener algorithm are compared with Neighshrink algorithm (a wavelet thresholding technique). Ten speech sentences from NOIZEUS database are taken for the study. Eight real world noises at 4 noise levels are used for the assessment. It is observed that the performance of the wavelet thresholding technique is better compared to the spatial domain techniques. © Springer International Publishing AG 2018.","Neighshrink; NOIZEUS; PESQ; Speech enhancement; Speech quality assessment","Pattern recognition; Quality control; Soft computing; Speech enhancement; Neighshrink; NOIZEUS; Perceptual evaluation of speech qualities; PESQ; Spectral subtractions; Speech quality assessment; Statistical modeling; Sub-space algorithms; Speech",2-s2.0-85028617560
"Balakrishna A.S.V., Srinivasu N.","Effective security in social data security in OSNs",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021203251&doi=10.1007%2f978-981-10-3223-3_43&partnerID=40&md5=f930df4eedc8ee0ff02e7c3df6f1bc74","Assurance is a grinding center that enhances when trades perform intermediate in Online Social Networks (OSNs). Diverse gatherings of utilization innovation specialists have limited the ‘OSN security issue’ as one of surveillance, institutional or open security. In taking care of these issues they have moreover overseen them just as they were person. We adapt that the elite security issues are caught and that evaluation on genuine feelings of serenity in Online Social Networks would advantage from a more exhaustive method. Nowadays, points of interest systems mean a critical piece of relationship; by fail in security, these organizations will decrease a ton of pleasant areas to see as well. The inside motivation behind subtle elements security (Content Privacy) is risk control. There is a important deal of discovering works and exercises in privacy to risk control (ISRM, for example, NIST 800-30 and ISO/IEC 27005. Regardless, only few works of appraisal focus on Information Security danger diminishment, while the signs depict normal determinations and suggestions. They don’t give any use ideas concerning ISRM; truth be told diminishing the Information Security dangers in questionable conditions is cautious. Subsequently, these papers joined acquired counts (GA) for Information Security danger loss of weaknesses. Finally, the parity of the associated system was broke down through a reflection. © Springer Nature Singapore Pte Ltd. 2018.","Content security (Information Security); Genetic algorithm (GA); Online social networks; Privacy enhancing technology; Risk reduction","Genetic algorithms; Intelligent computing; Online systems; Security of data; Social networking (online); Social sciences computing; Content security; Iso/iec 27005; On-line social networks; Online social networks (OSNs); Points of interest; Privacy enhancing technologies; Risk reductions; Security issues; Network security",2-s2.0-85021203251
"Liu H., Yan B., Lv M., Wang J., Wang X., Wang W.","Adaptive CLAHE image enhancement using imaging environment self-perception",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028703144&doi=10.1007%2f978-981-10-6232-2_40&partnerID=40&md5=6bc238a9f8c330deeefe7fbf9afdf8fa","A novel Contrast Limited Adaptive Histogram Equalization (CLAHE) image enhancement method which uses the environment self-perception mechanism is proposed. First, the typical degraded image datasets are collected. Second, several Image Quality (IQ) evaluation metrics are used to assess the imaging effect of these datasets above. Third, a BP network is employed to build the connection between the IQ evaluation results above and the optimal control parameters tuning results of the classic CLAHE. The optimal control parameters tuning results are gotten by the subjective evaluation and the setting of the control parameters of the classic CLAHE. The expert experiences of the optimal enhancement are used as the evaluation benchmark. Finally, when a new degraded image is captured, its IQ evaluation metrics will be computed and its optimal control parameters will be forecasted by the BP network and the computed IQ evaluation metrics. Many experiment results have shown the effectiveness of proposed method. © Springer Nature Singapore Pte Ltd. 2018.","Adaptive algorithm; CLAHE; Environment adaptability; Environment perception; Image enhancement","Adaptive algorithms; Backpropagation; Image enhancement; Parameter estimation; Systems engineering; CLAHE; Contrast Limited Adaptive Histogram Equalization (CLAHE); Control parameters; Environment adaptability; Environment perceptions; Evaluation metrics; Evaluation results; Subjective evaluations; Quality control",2-s2.0-85028703144
"Gharbi N., Charabi L.","A recursive analysis approach for retrial mobile networks with two customers classes and non-preemptive priority",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022210832&doi=10.1007%2f978-981-10-5281-1_34&partnerID=40&md5=87b6c36da0f07a04c33c0c1f5506796a","Retrial queueing models with two classes of customers arise in various practical mobile networks and telecommunication systems. The consideration of retrials (or repeated attempts) introduces analytical difficulties and most of works consider either models with preemptive priority or non-preemptive priority in the single server case. This paper aims to propose a recursive algorithmic approach for the performance analysis of a multiserver retrial queueing model with non-preemptive priority and two customers classes: ordinary customers whose access to the service depends on the number of available servers and who join the orbit when blocked; and impatient priority customers who have access to all servers and are lost when no server is available. In addition, we develop the formulae of the main stationary performance measures. Through numerical examples, we study the effect of the system parameters on the blocking probability for ordinary customers and the loss probability for priority customers. © Springer Science+Business Media Singapore 2018.","Impatient customers; Mobile networks; Non-preemptive priority; Performance measures; Recursive algorithm; Retrial multiserver queueing model; Two customers classes","Blocking probability; Queueing networks; Queueing theory; Sales; Wireless networks; Wireless telecommunication systems; Impatient customers; Non-preemptive; Performance measure; Queueing model; Recursive algorithms; Two customers classes; Mobile telecommunication systems",2-s2.0-85022210832
"Kim M.","A survey of vehicular ad-hoc network security",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022217496&doi=10.1007%2f978-981-10-5281-1_35&partnerID=40&md5=6f56cde1725ed39770b51ab61a020e9f","A variety of functional control of vehicles has developed along with information and communication technology. In particular, with the application of wireless network for real-time information offering, it has been possible to establish Vehicular Ad-hoc Network (VANET), an intelligent vehicle service for convenience and safety, which makes possible collision accident warning and avoidance, warning of dangerous factors on road, traffic information offering, and other kinds of service offering. However, the VANET service environment has physical and technical vulnerabilities caused by the vehicular internal/external communication based on wireless network. Therefore, Vehicular Security has emerged as an essential factor to prevent malicious threats and privacy violation from vehicles, drivers, and traffic network. This study tries to find the main security components of the VANET environment, analyze the latest research trend to overcome security vulnerabilities in each area, and propose the future research direction of Vehicular Security. © Springer Science+Business Media Singapore 2018.","ITS (Intelligent transportation System); Routing algorithm; V2I (Vehicle to infrastructure); V2V (Vehicle to vehicle); V2X (Vehicle to everything); VANET (Vehicular ad-hoc network); Vehicle security","Accidents; Advanced traveler information systems; Intelligent systems; Intelligent vehicle highway systems; Routing algorithms; Transportation; Vehicles; Vehicular ad hoc networks; Wireless ad hoc networks; Wireless networks; Wireless telecommunication systems; Intelligent transportation systems; V2X (Vehicle to everything); VANET (Vehicular ad-hoc network); Vehicle security; Vehicle to vehicles; Vehicle-to-infrastructure; Network security",2-s2.0-85022217496
"Yu P., Low M.Y., Zhou W.","Development of a partial least squares-artificial neural network (PLS-ANN) hybrid model for the prediction of consumer liking scores of ready-to-drink green tea beverages",2018,"Food Research International",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032856159&doi=10.1016%2fj.foodres.2017.10.015&partnerID=40&md5=862b3fdd9cf7f988790b2d86cf79273e","In order to develop products that would be preferred by consumers, the effects of the chemical compositions of ready-to-drink green tea beverages on consumer liking were studied through regression analyses. Green tea model systems were prepared by dosing solutions of 0.1% green tea extract with differing concentrations of eight flavour keys deemed to be important for green tea aroma and taste, based on a D-optimal experimental design, before undergoing commercial sterilisation. Sensory evaluation of the green tea model system was carried out using an untrained consumer panel to obtain hedonic liking scores of the samples. Regression models were subsequently trained to objectively predict the consumer liking scores of the green tea model systems. A linear partial least squares (PLS) regression model was developed to describe the effects of the eight flavour keys on consumer liking, with a coefficient of determination (R2) of 0.733, and a root-mean-square error (RMSE) of 3.53%. The PLS model was further augmented with an artificial neural network (ANN) to establish a PLS-ANN hybrid model. The established hybrid model was found to give a better prediction of consumer liking scores, based on its R2 (0.875) and RMSE (2.41%). © 2017 Elsevier Ltd","Artificial neural network; Consumer liking; Genetic algorithm; Green tea; Hybrid modelling; Machine learning; Partial least squares regression; Regression","Beverages; Chemical analysis; Forecasting; Genetic algorithms; Learning systems; Least squares approximations; Mean square error; Neural networks; Consumer liking; Green tea; Hybrid modelling; Partial least squares regression; Regression; Regression analysis",2-s2.0-85032856159
"Huang X., Meng S.-H.","Wireless Sensor Network Routing Protocol Research for High Voltage Transmission Line Monitoring System",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030860362&doi=10.1007%2f978-3-319-68527-4_22&partnerID=40&md5=1496c732ee588f0f65fefdf0f01cd44f","Wireless sensor network (WSN) was applied to high voltage transmission line monitoring system, according to the characteristics of the high voltage transmission line, put forward a kind of wireless sensor network Routing Protocol - Driven Clustering Routing Protocol DCRP (Driven Clustering Routing Protocol), that suitable for high voltage transmission line monitoring. And according to the characteristics of the different data that is collected in the high voltage transmission line monitoring, it is divided into two work modes—normal and emergency, and energy of the network is optimized. DCRP has good real-time performance, can effectively prolong the network life cycle, to meet the application requirement of high voltage transmission line monitoring system. © 2018, Springer International Publishing AG.","Energy optimization; High voltage transmission line monitoring; Routing algorithm; WSN","Data handling; Electric lines; Information analysis; Internet protocols; Life cycle; Network routing; Routing algorithms; Routing protocols; Voltage measurement; Wireless sensor networks; Application requirements; Clustering routing protocol; Energy optimization; High voltage transmission lines; Network life cycle; Real time performance; Work mode; Monitoring",2-s2.0-85030860362
"Orozco-Alzate M., Villegas-Jaramillo E.-J., Uribe-Hurtado A.-L.","A block-separable parallel implementation for the weighted distribution matching similarity measure",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022210367&doi=10.1007%2f978-3-319-62410-5_29&partnerID=40&md5=914c1cc1812b568cb986e8ab065a147e","Automatic pattern recognition is often based on similarity measures between objects which are, sometimes, represented as high-dimensional feature vectors —for instance raw digital signals or high-resolution spectrograms. Depending on the application, when feature vectors turn extremely long, computations of the similarity measure might become impractical or even prohibitive. Fortunately, multi-core computer architectures are widely available nowadays and can be efficiently exploited to speed-up computations of similarity measures. In this paper, a block-separable version of the so-called Weighted Distribution Matching similarity measure is presented. This measure was recently proposed but has not been analyzed until now for a parallel implementation. Our analysis shows that this similarity measure can be easily decomposed into subproblems such that its parallel implementation provides a significant acceleration in comparison with its corresponding serial version. Both implementations are presented as Python programs for the sake of readability of the codes and reproducibility of the experiments. © Springer International Publishing AG 2018.","Block separability; Multi-core implementation; Parallel algorithm; Similarity measure; Weighted distribution matching","Artificial intelligence; Computer software; Distributed computer systems; Parallel algorithms; Pattern recognition; Automatic pattern recognition; Block separability; High dimensional feature; Multi core; Parallel implementations; Reproducibilities; Similarity measure; Weighted distribution; Computer architecture",2-s2.0-85022210367
"Li J., Fong S., Wong R.K., Chu V.W.","Adaptive multi-objective swarm fusion for imbalanced data classification",2018,"Information Fusion",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016392535&doi=10.1016%2fj.inffus.2017.03.007&partnerID=40&md5=6b582a17fdabebe7881a6f2f7424cbf8","Learning a classifier from an imbalanced dataset is an important problem in data mining and machine learning. Since there is more information from the majority classes than the minorities in an imbalanced dataset, the classifier would become over-fitted to the former and under-fitted to the latter classes. Previous attempts to address the problem have been focusing on increasing the learning sensitivity to the minorities and/or rebalancing sample sizes among classes before learning. However, how to efficiently identify their optimal mix in rebalancing is still an unresolved problem. Due to non-linear relationships between attributes and class labels, merely to rebalance sample sizes rarely comes up with optimal results. Moreover, brute-force search for the perfect combination is known to be NP-hard and hence a smarter heuristic is required. In this paper, we propose a notion of swarm fusion to address the problem – using stochastic swarm heuristics to cooperatively optimize the mixtures. Comparing with conventional rebalancing methods, e.g., linear search, our novel fusion approach is able to find a close to optimal mix with improved accuracy and reliability. Most importantly, it has found to be with higher computational speed than other coupled swarm optimization techniques and iteration methods. In our experiments, we first compared our proposed solution with traditional methods on thirty publicly available imbalanced datasets. Using neural network as base learner, our proposed method is found to outperform other traditional methods by up to 69% in terms of the credibility of the learned classifiers. Secondly, we wrapped our proposed swarm fusion method with decision tree. Notably, it defeated six state-of-the-art methods on ten imbalanced datasets in all evolution metrics that we considered. © 2017 Elsevier B.V.","Crossover rebalancing; Imbalanced data classification; Multi-objective; Swarm fusion; Swarm intelligence algorithm","Artificial intelligence; Data mining; Decision trees; Iterative methods; Learning systems; Optimization; Stochastic systems; Swarm intelligence; Computational speed; Imbalanced data; Imbalanced Data-sets; Multi objective; Non-linear relationships; Rebalancing; State-of-the-art methods; Swarm intelligence algorithms; Classification (of information)",2-s2.0-85016392535
"Mukesh S.D., Raval J.A., Upadhyay H.","Real-time framework for malware detection using machine learning technique",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028392721&doi=10.1007%2f978-3-319-63673-3_21&partnerID=40&md5=33d11ffa7689e26d55d74cbd84cbd516","In this epoch, current web world where peoples groups are associated through correspondence channel and the majority of their information is facilitated on the web associated assets. Thusly the security is the significant concern of this internet community to protect the resources and to ensure the assets and the information facilitated on these networks. In current trends, the greater part of the end client are depending on the end security items, for example, Intrusion detection system, firewall, Anti-viruses etc. In this paper, we propose a machine learning based architecture to distinguish existing and recently developing malware by utilizing network and transport layer traffic features. This paper influences the precision of Semi-supervised learning in identifying new malware classes. We show the adequacy of the framework utilizing genuine network traces. Amid this research, we will execute and design the proactive network security mechanism which will gather the malware traces. Assist those gathered malware traces can be utilized to fortify the signature based discovery mechanism. © 2018, Springer International Publishing AG.","ClamAV; Machine learning; Malware detection; Semi-supervised algorithm","Artificial intelligence; Computer crime; Computer system firewalls; Computer viruses; Intelligent systems; Intrusion detection; Learning algorithms; Learning systems; Malware; Network layers; Supervised learning; Viruses; ClamAV; Internet communities; Intrusion Detection Systems; Machine learning techniques; Malware detection; Proactive networks; Semi- supervised learning; Semi-supervised algorithm; Network security",2-s2.0-85028392721
"Malhotra S., Doja M.N., Alam B., Alam M.","Generalized query processing mechanism in cloud database management system",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031429367&doi=10.1007%2f978-981-10-6620-7_61&partnerID=40&md5=e88409f5aaadf4dd2a07169e4faf3dd9","This is an epoch of Big data, Cloud computing, Cloud Database Management techniques. Traditional database approaches are not suitable for such colossal amount of data. To overcome the limitations of RDBMS, Map Reduce codes can be considered as a probable solution for such huge amount of data processing. Map Reduce codes provide both scalability and reliability. Users till date can work snugly with traditional Database approaches such as SQL, MYSQL, ORACLE, DB2, etc., and they are not aware of Map Reduce codes. In this paper, we are proposing a model which can convert any RDBMS queries to Map Reduce codes. We also gear optimization technique which can improve the performance of such amalgam approach. © 2018, Springer Nature Singapore Pte Ltd.","CDBMS; Cloud database management system; Cross rack communication; Data processing; Hadoop; MapReduce; Optimized algorithm","Codes (symbols); Data handling; Data processing; Database systems; Information management; Management information systems; Query processing; CDBMS; Cloud database; Hadoop; Map-reduce; Optimized algorithms; Big data",2-s2.0-85031429367
"Bezerra E.L., Ho L.L., da Costa Quinino R.","GS2: An optimized attribute control chart to monitor process variability",2018,"International Journal of Production Economics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032746975&doi=10.1016%2fj.ijpe.2017.10.023&partnerID=40&md5=d0f634c1e1c485aef38bec9d66abea9b","Precise measurement of quality characteristics is expensive and time-consuming and requires instrument calibration. Furthermore, in destructive experiments, the sampled units are damaged and must be discarded. In these cases, an alternative is the classification of each sampled unit into a group using a device such as gauge rings. Operationally, this method is faster, and no measurement is taken on the sampled unit. In this paper, a new attribute control chart is proposed to monitor process variability. The statistic GS2 is calculated, and the chart signals whenever GS2&gt;CLG, where CLG is the control limit that is determined to satisfy a desired value of ARL0 and to minimize ARL1. The performance (fixed ARL1 and ARL0) of the proposed control chart can be economically compared with the traditional S2 control chart depending on the magnitude of the cost of the evaluation per measurement in relation to the cost of inspection by attributes. © 2017 Elsevier B.V.","ARL0; ARL1; Average inspection cost; Genetic algorithm; S2 control chart","Control charts; Costs; Flowcharting; Genetic algorithms; ARL0; ARL1; Attribute control charts; Destructive experiment; Inspection costs; Instrument calibrations; Precise measurements; Quality characteristic; Process control",2-s2.0-85032746975
"Saoud Z., Platoš J.","Community detection in bibsonomy using data clustering",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029525328&doi=10.1007%2f978-3-319-67220-5_14&partnerID=40&md5=6245d176bfe4d70cb9c946d9845ff043","Community detection aims to extract the related groups of nodes from complex networks, by exploiting the network topology. Different approaches have been proposed for community detection, where most of them are based on clustering algorithms. In this paper we investigate how we can use the clustering for the community detection in the academic social bookmarking website: Bibsonomy. Our goal is to determine the most suitable clustering algorithm for similar user detection in Bibsonomy. To realize that, we have compared three clustering algorithms: The k-means, the k-medoids and the Agglomerative clustering algorithms. Experimental results demonstrate that k-means performs better than the other algorithms, for community detection in Bibsonomy. © 2018, Springer International Publishing AG.","Clustering algorithms; Community detection; Data visualization",,2-s2.0-85029525328
"En E., Alam A., Khan K.U., Lee Y.-K.","Parallel Compression of Weighted Graphs",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032506122&doi=10.1007%2f978-981-10-6520-0_8&partnerID=40&md5=c07c2eb5ef885b2c14a337b3db19e6a9","Large graphs such as social network, web graph, biological network, are complex and facing the challenges of processing and visualization. Motivated by such issues, Taivonen et al. [1] proposed models and sequential algorithms for weighted graph with the intentions to generate a candidate compress graph. The proposed compression algorithm is expensive in terms of computation time because of the sequential process. The weighted graph compression algorithms can be made faster while adopting parallel processing technique. In this paper, we adopt parallel processing technique for weighted graph compression problem while using multi-selection nodes to perform merge-able technique with various graph clustering algorithms to avoid overlapping between nodes from different threads. For the performance evaluation purposes of the proposed method, we carry out series of tests on the real networks. We perform extensive experiments on parallel graph summarization while using different graph clustering algorithms. Our results demonstrate their effectiveness for parallel graph compression on real networks. © 2018, Springer Nature Singapore Pte Ltd.","Graph clustering; Graph compression; Graph mining; Network; Parallel processing; Weighted graph","Computation theory; Graphic methods; Networks (circuits); Graph clustering; Graph compressions; Graph mining; Parallel processing; Weighted graph; Clustering algorithms",2-s2.0-85032506122
"Ahuja S.K., Shukla M.K.","A survey of computer vision based corrosion detection approaches",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028367298&doi=10.1007%2f978-3-319-63645-0_6&partnerID=40&md5=40ec0fede01d7cb736069625ec0adec2","There are various destructive as well as non-destructive techniques available to detect corrosion in metallic surfaces. Digital Image Processing is widely being used for the corrosion detection in metallic surface. This non-destructive approach provides cost effective, fast and reasonably accurate results. Several algorithms have been developed by different researchers and research groups for detecting corrosion using digital image processing techniques. Several algorithms related to color, texture, noise, clustering, segmentation, image enhancement, wavelet transformation etc. have been used in different combinations for corrosion detection and analysis. This paper reviews the different image processing techniques and the algorithms developed and used by researchers in various industrial applications. © Springer International Publishing AG 2018.","Computer vision; Corrosion detection; Image processing","Clustering algorithms; Computer vision; Corrosion; Cost effectiveness; Image segmentation; Intelligent systems; Metallic compounds; Nondestructive examination; Surface measurement; Corrosion detection; Digital image processing technique; Image processing technique; Metallic surface; Non destructive; Non-destructive technique; Research groups; Wavelet transformations; Image processing",2-s2.0-85028367298
"Mandanas F., Kotropoulos C.","M-estimators for robust multidimensional scaling employing ℓ2,1 norm regularization",2018,"Pattern Recognition",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028691986&doi=10.1016%2fj.patcog.2017.08.023&partnerID=40&md5=46c3d29509499f3d5f9ef613f679fc69","Multidimensional Scaling (MDS) has been exploited to visualise the hidden structures among a set of entities in a reduced dimensional metric space. Here, we are interested in cases whenever the initial dissimilarity matrix is contaminated by outliers. It is well-known that the state-of-the-art algorithms for solving the MDS problem generate erroneous embeddings due to the distortion introduced by such outliers. To remedy this vulnerability, a unified framework for the solution of MDS problem is proposed, which resorts to half-quadratic optimization and employs potential functions of M-estimators in combination with ℓ2,1 norm regularization. Two novel algorithms are derived. Their performance is assessed for various M-estimators against state-of-the-art MDS algorithms on four benchmark data sets. The numerical tests demonstrate that the proposed algorithms perform better than the competing alternatives. © 2017 Elsevier Ltd","Half-quadratic optimization; M-estimators; Multidimensional scaling; Robustness; ℓ2,1 norm regularization","Benchmarking; Quadratic programming; Robustness (control systems); Statistics; 1-norm regularizations; Dissimilarity matrix; Half-quadratic optimizations; M-estimators; Multi-dimensional scaling; Potential function; Reduced-dimensional; State-of-the-art algorithms; Optimization",2-s2.0-85028691986
"Bieda R., Jaskot K., Łakota T., Jȩdrasiak K.","Combining Data from Vision and Odometry Systems for More Accurate Control of Mobile Robot",2018,"Studies in Systems, Decision and Control",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029682758&doi=10.1007%2f978-3-319-64674-9_7&partnerID=40&md5=6d3cc5e1ab6a153ef6c0cad4483b95ca","This paper describes control algorithms implemented in the experimental mobile robot. Presented solution based on combining data from vision and odometry systems. It is assumed that general motion planning is performed by the master control system, and only some basic tasks are realized by the robot itself. The powerful microcontroller is able to realize more complicated control algorithms locally on the robot, so the master system can focus on more challenging tasks. The reactive algorithms based on odometry and vision systems is realized by the on-board system, they can react much faster than it would be, if current encoder readings was sent to the master system, and decision was taken there. The proposed solution also allows to avoid sliding when desired speed changes stepwisely, it changes the real speed smoothly. Since most of tasks need knowledge about robot position and/or orientation, the algorithms that allow to estimate robot’s pose are also described here. © 2018, Springer International Publishing AG.","Control algorithms; Mobile robot; Noise filtering; Odometry; Vision system",,2-s2.0-85029682758
"Chongdarakul W., Sophatsathit P., Lursinsap C.","Theoretical and heuristic aspects of heterogeneous system scheduling with constraints on client's multiple I/O ports",2018,"Future Generation Computer Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028303850&doi=10.1016%2fj.future.2017.07.052&partnerID=40&md5=30b4eb5b24453f4652932dce2a01afbd","An effective scheduling algorithm for distributed computing systems is essential for assigning client's tasks to run on a set of processors at a minimum makespan. Existing algorithms permit the client tasks to be sent and received simultaneously to the processors without any possibility of collisions. This implies an unrealistic situation that there is an unlimited number of I/O ports which in fact is physically limited by the underlying architecture and technology. This paper takes this crucial constraint of I/O ports that no existing algorithm has addressed as a part of client task scheduling. Task to be scheduled are represented by a directed acyclic graph with arbitrary dependency structures and arranged by their critical paths. Two theoretical scheduling patterns under multiple I/O ports to achieve the optimal makespan with minimum latent delay are discovered and proved, namely, triangular and parallelogram patterns. They are used as the principal basis for the proposed scheduling algorithm. The focus is on collision avoidance of these tasks to be sent or received through the multiple I/O ports. Plots of task graph on performance comparison with other algorithms from the experiment show that the proposed algorithm outperforms other algorithms in terms of shorter makespan, less delay, and less number of ports used. In the real application data set, the makespan performance obtained by the proposed algorithm is better than other algorithms by 62.05%. © 2017 Elsevier B.V.","Collision avoidance; Directed acyclic graph; Multiple I/O ports; Task graph; Task scheduling","Collision avoidance; Directed graphs; Distributed computer systems; Graph theory; Multitasking; Scheduling; Dependency structures; Directed acyclic graph (DAG); Distributed computing systems; Heterogeneous systems; Multiple I/O ports; Performance comparison; Task graph; Task-scheduling; Scheduling algorithms",2-s2.0-85028303850
"Lee G.K., Ryu S.Y., Kim C.","Block-Incremental Deep Learning Models for Timely Up-to-Date Learning Results",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032506433&doi=10.1007%2f978-981-10-6520-0_24&partnerID=40&md5=436d305ee73c4eb37f51db9c8e51f77d","As mobile devices and personal computers have been more frequently used through the Internet, data generated by not only people but also devices have been continuously piling up. The data growing endlessly is called Big Data and Deep Learning algorithms with the Big Data have been introducing the next level of artificial intelligence. It is generally applicable that the more data deep learning algorithms train, the more accurate the deep learning algorithms are. Then, an important problem is which size of data is enough for deep learning algorithms to train the data. In many cases, it is not practical that we wait for the data to grow bigger enough, and thus we need a new learning model that can reduce this latency time and timely derive learning results with useful accuracy. In this paper, we propose novel block-incremental learning models for deep learning and experimentally show that the proposed model can timely derive learning results with useful accuracy and the final accuracy is even better than the traditional deep learning algorithms with the same size of training data. © 2018, Springer Nature Singapore Pte Ltd.","Incremental learning; Learning model; Machine learning","Artificial intelligence; Big data; Deep learning; Learning systems; Personal computers; Incremental learning; Latency time; Learning models; Training data; Learning algorithms",2-s2.0-85032506433
"Allaf Z., Adda M., Gegov A.","A Comparison Study on Flush+Reload and Prime+Probe Attacks on AES Using Machine Learning Approaches",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029600557&doi=10.1007%2f978-3-319-66939-7_17&partnerID=40&md5=47e5a7d2dbc0f99cb191010a81fd20bb","AES, ElGamal are two examples of algorithms that have been developed in cryptography to protect data in a variety of domains including native and cloud systems, and mobile applications. There has been a good deal of research into the use of side channel attacks on these algorithms. This work has conducted an experiment to detect malicious loops inside Flush+Reload and Prime+Prob attack programs against AES through the exploitation of Hardware Performance Counters (HPC). This paper examines the accuracy and efficiency of three machine learning algorithms: Neural Network (NN); Decision Tree C4.5; and K Nearest Neighbours (KNN). The study also shows how Standard Performance Evaluation Corporation (SPEC) CPU2006 benchmarks impact predictions. © 2018, Springer International Publishing AG.","AES; Flush+Reload; Machine learning; Prime+Probe; Side-channel attack","Artificial intelligence; Benchmarking; Cryptography; Data mining; Decision trees; Learning algorithms; Learning systems; Nearest neighbor search; Probes; Comparison study; Flush+Reload; Hardware performance counters; K nearest neighbours (k-NN); Machine learning approaches; Mobile applications; Neural network (nn); Standard performance; Side channel attack",2-s2.0-85029600557
"Bahri O., Amor N.B., Talbi E.-G.","Possibilistic framework for multi-objective optimization under uncertainty",2018,"Operations Research/ Computer Science Interfaces Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032646328&doi=10.1007%2f978-3-319-58253-5_2&partnerID=40&md5=c40195c17d080ffcf9b73d5de2c343b2","Optimization under uncertainty is an important line of research having today many successful real applications in different areas. Despite its importance, few works on multi-objective optimization under uncertainty exist today. In our study, we address combinatorial multi-objective problem under uncertainty using the possibilistic framework. To this end, we firstly propose new Pareto relations for ranking the generated uncertain solutions in both mono-objective and multi-objective cases. Secondly, we suggest an extension of two well-known Pareto-base evolutionary algorithms namely, SPEA2 and NSGAII. Finally, the extended algorithms are applied to solve a multi-objective Vehicle Routing Problem (VRP) with uncertain demands. © Springer International Publishing AG 2018.","Evolutionary algorithms; Multi-objective optimization; Possibilty theory; Uncertainty; Vehicle routing problem",,2-s2.0-85032646328
"Khanna S., Rakesh N., Chaturvedi K.N.","Operations on cloud data (classification and data redundancy)",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031422967&doi=10.1007%2f978-981-10-3773-3_17&partnerID=40&md5=1a5ab5ef054303cb8353707bcc3f88f7","Cloud computing is a turning in the field of information technology as it provides resources over network. Besides the features, cloud services are widely available for all. Content duplicacy increases the data redundancy problem in cloud. Files on cloud need an effective classification method so that the problem of cloud server efficiency may be optimized. In this paper, we have proposed two algorithms: Checker’s algorithm (to remove data redundancy from cloud) and Pronto-Key algorithm (to classify the files and enhance the performance of cloud) which overall increase the efficiency of the cloud. © Springer Nature Singapore Pte Ltd. 2018.","Classification; Cloud computing; Redundancy; Searching","Classification (of information); Cloud computing; Efficiency; Redundancy; Classification methods; Cloud data; Cloud servers; Cloud services; Data redundancy; S-algorithms; Searching; Distributed computer systems",2-s2.0-85031422967
"Nguyen T.T., Nguyen M.P., Pham X.C., Liew A.W.-C.","Heterogeneous classifier ensemble with fuzzy rule-based meta learner",2018,"Information Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029004946&doi=10.1016%2fj.ins.2017.09.009&partnerID=40&md5=2340894899ff5296644690b848d72eb1","In heterogeneous ensemble systems, each learning algorithm learns a classifier on a given training set to describe the relationship between a feature vector and its class label. As each classifier outputs different result on an observation, uncertainty is introduced. In this paper, we introduce a heterogeneous ensemble system with a fuzzy IF-THEN rule inference engine as the combiner to capture the uncertainty in the outputs of the base classifiers. In our method, fuzzy rules are generated on the outputs of an ensemble of base classifiers, which can be viewed as the class posterior probability of the observations. The performance of our method was evaluated on thirty datasets and in comparison with nine ensemble methods (AdaBoost, Decision Template, Decision Tree on meta-data, and six fixed combiners) and two single learning algorithms (SVM with L2-loss function and Decision Tree), and was shown to significantly outperforms these algorithms in terms of classification accuracy. © 2017 Elsevier Inc.",,"Adaptive boosting; Classification (of information); Data mining; Decision trees; Fuzzy inference; Fuzzy rules; Trees (mathematics); Base classifiers; Classification accuracy; Decision template; Fuzzy if-then rules; Fuzzy rule based; Heterogeneous classifiers; Heterogeneous ensembles; Posterior probability; Learning algorithms",2-s2.0-85029004946
"Anuradha T.","Parallel mining of frequent itemsets from memory-mapped files",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031402727&doi=10.1007%2f978-981-10-6620-7_43&partnerID=40&md5=71cc6d4b121e0690e57f5123964c4f17","Due to digitization of data in different fields, data are increasing in leaps and bounds. Mining of these large amounts of data requires two major issues to deal with. The first is the potential to deal with huge data which can be dealt with parallel algorithms as serial algorithms may take very long time or sometimes may not process. The second is the I/O overhead which can be dealt with memory mapping of files. This chapter brings together both parallelization and memory mapping of files concepts in mining the frequent itemsets. Our experiments proved that there is almost 20% more speedup on parallelizing our frequent itemset mining algorithm with memory mapping when compared to conventional I/O without memory mapping. © 2018, Springer Nature Singapore Pte Ltd.","Apriori; Frequent itemset; Memory-mapped file; Parallel mining","Mapping; Apriori; Frequent itemset; Frequent itemset mining; Large amounts of data; Memory-Mapped file; Parallel minings; Parallelizations; Serial algorithms; Big data",2-s2.0-85031402727
"Amritanjali","A new two-dimensional mesh topology with optical interlinks",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032636400&doi=10.1007%2f978-981-10-3376-6_47&partnerID=40&md5=1576c4109c0826fe58c33331c46c67a8","The performance of parallel computer heavily depends on the topology of the interconnection network. Two-dimensional mesh is a well-known topology for processor arrays. However, its large diameter increases execution time when the parallel algorithm requires communication between arbitrary pair of nodes. Wraparound connections between end nodes reduces its diameter, however, increases the complexity in the design of parallel algorithms. In this paper, we have proposed an intermediate approach, where additional links are used to reduce the diameter without increasing the design complexity. These additional optical links provides high-speed communication between nodes that are separated by half the number of nodes in each dimension. Also, we present efficient parallel algorithms for some elementary problems on the proposed system. © Springer Nature Singapore Pte Ltd. 2018.","Interconnection networks; Mesh topology; Parallel algorithms",,2-s2.0-85032636400
"Wang X., Guo Y., Wang Z.","Multi-view discriminative manifold embedding for pattern classification",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028381667&doi=10.1007%2f978-3-319-60744-3_18&partnerID=40&md5=fb55249c9f6fcd16bae687abeb79901a","While many dimensionality reduction algorithms have been proposed in recent years, most of them are designed for single view data and cannot cope with multi-view data directly. Dimensionality reduction algorithms in recent ten years, both in theory and application have great breakthrough. In the face of dozens, hundreds or even thousands of dimension by dimension reduction to the data from high dimensional space to a low dimensional space and extract the essential characteristics of low dimensional data. In many real-world pattern applications such as face recognition, multiple feature descriptors can provide complementary information in characterizing image from different viewpoints. Motivated by this concern, we propose a new multi-view discriminative manifold embedding (MDME) method for classification by making use of intra-class geometry and inter-class marginal information as well as complementary information of multiple feature representations. Experimental results on face recognition demonstrate the effectiveness of the proposed algorithm. © 2018, Springer International Publishing AG.","Dimensionality reduction; Discriminative manifold embedding; Multi-view learning; Pattern classification","Classification (of information); Data mining; Face recognition; Intelligent systems; Pattern recognition; Real time systems; Dimensionality reduction; Dimensionality reduction algorithms; Discriminative manifold embedding; Essential characteristic; High dimensional spaces; Low-dimensional spaces; Multi-view learning; Multiple feature descriptors; Data reduction",2-s2.0-85028381667
"Hancer E., Xue B., Zhang M., Karaboga D., Akay B.","Pareto front feature selection based on artificial bee colony optimization",2018,"Information Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029537929&doi=10.1016%2fj.ins.2017.09.028&partnerID=40&md5=43f4305ef38c9560eaa0436f6d936ee1","Feature selection has two major conflicting aims, i.e., to maximize the classification performance and to minimize the number of selected features to overcome the curse of dimensionality. To balance their trade-off, feature selection can be handled as a multi-objective problem. In this paper, a feature selection approach is proposed based on a new multi-objective artificial bee colony algorithm integrated with non-dominated sorting procedure and genetic operators. Two different implementations of the proposed approach are developed: ABC with binary representation and ABC with continuous representation. Their performance are examined on 12 benchmark datasets and the results are compared with those of linear forward selection, greedy stepwise backward selection, two single objective ABC algorithms and three well-known multi-objective evolutionary computation algorithms. The results show that the proposed approach with the binary representation outperformed the other methods in terms of both the dimensionality reduction and the classification accuracy. © 2017 Elsevier Inc.","Artificial bee colony; Classification; Feature selection; Multi-objective optimization","Benchmarking; Bins; Classification (of information); Economic and social effects; Evolutionary algorithms; Multiobjective optimization; Optimization; Artificial bee colonies; Artificial bee colony optimizations; Classification performance; Curse of dimensionality; Dimensionality reduction; Multi-objective artificial bee colonies; Multi-objective evolutionary; Multi-objective problem; Feature extraction",2-s2.0-85029537929
"Cueto-López N., Alaiz-Rodríguez R., García-Ordás M.T., González-Donquiles C., Martín V.","Assessing feature selection techniques for a colorectal cancer prediction model",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028655288&doi=10.1007%2f978-3-319-67180-2_46&partnerID=40&md5=289406dcbca169a8fb3c17c2486c4936","Risk prediction models for colorectal cancer play an important role to identify people at higher risk of developing this disease as well as the risk factors associated with it. Feature selection techniques help to improve the prediction model performance and to gain insight in the data itself. The assessment of the stability of feature selection/ranking algorithms becomes an important issue when the aim is to analyze the most relevant features. This work assesses several feature ranking algorithms in terms of performance and robustness for a set of risk prediction models. Experimental results demonstrate that stability and model performance should be studied jointly as RF turned out to be the most stable algorithm but outperformed by others in terms of model performance while SVM-wrapper and the Pearson correlation coefficient are moderately stable while achieving good model performance. © 2018, Springer International Publishing AG.","Colorectal cancer; Feature selection; Risk prediction model; Stability","Convergence of numerical methods; Correlation methods; Diseases; Forecasting; Risk assessment; Soft computing; Colorectal cancer; Model performance; Pearson correlation coefficients; Prediction model; Relevant features; Risk prediction models; Selection techniques; Stable algorithms; Feature extraction",2-s2.0-85028655288
"Caraveo C., Valdez F., Castillo O.","A new optimization metaheuristic based on the self-defense techniques of natural plants applied to the CEC 2015 benchmark functions",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029427958&doi=10.1007%2f978-3-319-66830-7_34&partnerID=40&md5=f0532d619a550087c67b9deb34afdb9b","A new optimization metaheuristic algorithm based on the mechanisms of self-defense of plants in nature in this work is presented. The proposed optimization algorithm is applied to optimize mathematical functions of CEC 2015, this suite of functions are proposed as a challenge for the area of algorithm bio-inspired, with the purpose of creating a competition of performance and stability between algorithms of search and optimization. We propose a new meta-heuristic inspired in the coping techniques of plants in nature, as there techniques are developed by plants as a defense from predators. The proposed algorithm is based on the Lotka and Volterra model better known as the prey predator model, this model consists of two non-linear equations and is used to model the growth of two populations that competing with each other. © 2018, Springer International Publishing AG.","Aggressor; Lotka and Volterra model; Lévy flights; Mechanism; Plants; Self-defense","Computer circuits; Functions; Fuzzy logic; Fuzzy sets; Mechanisms; Network security; Population statistics; Aggressor; Mathematical functions; Optimization algorithms; Optimization metaheuristic; Plants; Prey-predator models; Self-defense; Volterra model; Optimization",2-s2.0-85029427958
"Sureshan S., Penumacha A., Jain S., Vanahalli M., Patil N.","Mining closed colossal frequent patterns from high-dimensional dataset: Serial versus parallel framework",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026763613&doi=10.1007%2f978-981-10-3373-5_32&partnerID=40&md5=169861e24d16a1b44d82a3eed6105f97","Mining colossal patterns is one of the budding fields with a lot of applications, especially in the field of bioinformatics and genetics. Gene sequences contain inherent information. Mining colossal patterns in such sequences can further help in their study and improve prediction accuracy. The increase in average transaction length reduces the efficiency and effectiveness of existing closed frequent pattern mining algorithm. The traditional algorithms expend most of the running time in mining huge amount of minute and midsize patterns which do not enclose valuable information. The recent research focused on mining large cardinality patterns called as colossal patterns which possess valuable information. A novel parallel algorithm has been proposed to extract the closed colossal frequent patterns from high-dimensional datasets. The algorithm has been implemented on Hadoop framework to exploit its inherent distributed parallelism using MapReduce programming model. The experiment results highlight that the proposed parallel algorithm on Hadoop framework gives an efficient performance in terms of execution time compared to the existing algorithms. © Springer Nature Singapore Pte Ltd. 2018.","Closed colossal frequent patterns; Closed patterns; Frequent patterns; Hadoop; High-dimensional datasets; MapReduce; Minimum support","Computation theory; Intelligent computing; Parallel algorithms; Closed colossal frequent patterns; Closed pattern; Frequent patterns; Hadoop; High dimensional datasets; Map-reduce; Minimum support; Data mining",2-s2.0-85026763613
"Infante Acevedo J., Lelièvre T.","A non linear approximation method for solving high dimensional partial differential equations: Application in finance",2018,"Mathematics and Computers in Simulation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85004073519&doi=10.1016%2fj.matcom.2016.07.013&partnerID=40&md5=9b488c05c4dad86cd0d1791acbcd59e2","We study an algorithm which has been proposed by A. Ammar, B. Mokdad, F. Chinesta, R. Keunings in 2006 to solve high-dimensional partial differential equations. The idea is to represent the solution as a sum of tensor products and to compute iteratively the terms of this sum. This algorithm is related to the so-called greedy algorithms, as introduced by V.N. Temlyakov. In this paper, we investigate the application of the greedy algorithm in finance and more precisely to the option pricing problem. We approximate the solution to the Black–Scholes equation and we propose a variance reduction method. In numerical experiments, we obtain results for up to 10 underlyings. Besides, the proposed variance reduction method permits an important reduction of the variance in comparison with a classical Monte Carlo method. © 2016 International Association for Mathematics and Computers in Simulation (IMACS)","Black–Scholes partial differential equation; Greedy algorithms; Variance reduction","Economics; Electronic trading; Monte Carlo methods; Partial differential equations; Tensors; Black Scholes equations; Black-Scholes partial differential equations; Greedy algorithms; High-dimensional; Nonlinear approximation; Numerical experiments; Variance reduction methods; Variance reductions; Iterative methods",2-s2.0-85004073519
"Gupta R., Jivani A.G.","Analyzing the stemming paradigm",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028402595&doi=10.1007%2f978-3-319-63645-0_37&partnerID=40&md5=e1f337af2dd840201d9b85a14e6969e6","This paper discusses affix removal and statistical based Stemming algorithms in detail with stemmer-generated output from some Standard English text and dictionary. Comparative empirical studies of all these stemmers are also discussed here with respect to number of stem token generation from single root morphed word variants and computation time. First part of the paper deals with introductory discussion of stemming and lemmatization. Second part of the paper focuses on algorithms of affix and statistical based stemmers with their empirical output. Last part describes the steps of the comparative tool for the same. Finally conclusion section wraps up whole discussion about stemming. This paper can assist researchers working in the field of text mining. © Springer International Publishing AG 2018.","Index compression factor (ICF); Lemmatizing; Stemming; Text mining","Data mining; Intelligent systems; Text processing; Computation time; Empirical studies; Index compression; Lemmatization; Lemmatizing; Stemming; Stemming algorithms; Text mining; Natural language processing systems",2-s2.0-85028402595
"Petruck H., Mertens A.","Predicting human cycle times in robot assisted assembly",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028978488&doi=10.1007%2f978-3-319-60474-9_3&partnerID=40&md5=f4f003484d5a8d28190cd51c9530d8c4","Due to ever-shortening product life cycles and multi variant products the demand for flexible production systems that use human-robot collaboration (HRC) rises. One key factor in HRC is stress that occurs because of the unfamiliar work with the robot. To reduce stress induced strain for assembly tasks the cycle time should be adjusted to the human’s performance, so that the stress that is exerted on the working person by a waiting robot is minimized. In the presented approach the cycle times are adapted by predicting them based on Methods-Time Measurement (MTM) and the former performance of the working person. In this paper, two different prediction algorithms are presented and validated on data collected during an assembly study with a Stromberg carburetor. The results show a reduction of prediction errors compared to traditional MTM. By applying these algorithms to HRC-assembly scenarios a reduction of stress and mental load can be achieved. © 2018, Springer International Publishing AG.","Assembly cycle times; Human factors; Human-Robot collaboration; Stress-Strain","Ergonomics; Forecasting; Human computer interaction; Human engineering; Manufacture; Robots; Assembly tasks; Cycle time; Flexible production systems; Human-robot collaboration; Prediction algorithms; Prediction errors; Product life cycles; Stress strain; Life cycle",2-s2.0-85028978488
"Wray R.E., Stowers K.","Interactions between learner assessment and content requirement: A verification approach",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022195660&doi=10.1007%2f978-3-319-60018-5_4&partnerID=40&md5=60e390c79920d365d7ac00d41bbf2e01","A practical constraint in the design and development of algorithms and tools for personalized learning is the need to implement adaptive algorithms, oftentimes within complex software environments, without the benefit of a priori large-scale user testing. The lack of such testing makes it difficult to ensure that lessons and guidance from design recommendations and prior studies in other domains has been effectively applied in the training application. This paper summarizes efforts toward a testbed to support verification of adaptive training designs. The testbed operationalizes evidence-based guidance from the research literature and simulated students to enable exploration of design space prior to large-scale implementation. The paper motivates the approach with a specific design question, which is to examine trade-offs between the use of behavioral markers to assess proficiency and the resulting training-content requirements to take advantage of the information that such markers provide. © Springer International Publishing AG 2018.","Adaptive training; Training design","Adaptive algorithms; Human engineering; Software testing; Testbeds; Adaptive training; Complex software; Design and Development; Design questions; Design recommendations; Personalized learning; Training applications; Training design; Education",2-s2.0-85022195660
"Hora K.","Classifying exoplanets as potentially habitable using machine learning",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031398516&doi=10.1007%2f978-981-10-6602-3_20&partnerID=40&md5=3f60aac209445a097d716c3b57dcc0d0","With the launch of the ESA Gaia satellite observatory and the planned LSST, and the torrent of data coming through the Kepler space observatory, scientists will be able to collect data for more than 1 billion astronomical objects, including millions of exoplanets in the coming years. In this study, several predictive models are built using machine learning algorithms to classify exoplanets as potentially habitable, based on various characteristics of the planet and its star. I applied six supervised learning algorithms for the classification of planets, which include two decision trees, CART and Random Forest, Support Vector Machines, Logistic Regression, Feed-Forward Neural Network, and Naïve Bayes. I further applied CART to create a regression model to predict the value of the ESI (Earth Similarity Index) for an exoplanet. © 2018, Springer Nature Singapore Pte Ltd.","Artificial neural networks; Data mining; Decision trees; Logarithmic regression; Naïve bayes; Random forests; Support vector machines","Artificial intelligence; Data mining; Decision trees; Extrasolar planets; Forestry; Learning systems; Neural networks; Observatories; Regression analysis; Satellites; Sodium; Support vector machines; Astronomical objects; Logarithmic regression; Logistic regressions; Predictive models; Random forests; Regression model; Similarity indices; Space observatories; Learning algorithms",2-s2.0-85031398516
"Radlak K., Radlak N., Smolka B.","Static posed versus genuine smile recognition",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019228860&doi=10.1007%2f978-3-319-59162-9_44&partnerID=40&md5=00511b48f592020ad6d3948e891c0774","Recognition of a posed or fake smile is a vital and challenging research topic and a growing interest has been observed from the computer vision and machine learning community. The state-of-the-art algorithms related to this field focus on the facial expressions dynamics, while several psychologists suggest that the main difference between posed and spontaneous smile should be observed in different muscles contractions in the upper part of the face. Therefore, in this work we evaluate the accuracy of recognition based only on the face appearance using the High-Dimensional Local Binary Patterns. The smile authenticity is analyzed on the set of images extracted at the smile apex phase from the UvA-NEMO database. The obtained results indicate that the analyzed algorithms can spot a fake smile much better than a human, but worse than systems that incorporate the facial dynamics. © Springer International Publishing AG 2018.","Face analysis; Facial expressions; Smile genuineness; Smile recognition","Learning systems; Face analysis; Facial Expressions; High-dimensional; Local binary patterns; Machine learning communities; Smile genuineness; Smile recognition; State-of-the-art algorithms; Computer vision",2-s2.0-85019228860
"Abavisani M., Patel V.M.","Multimodal sparse and low-rank subspace clustering",2018,"Information Fusion",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019365201&doi=10.1016%2fj.inffus.2017.05.002&partnerID=40&md5=0900ce0c0cccf83fe4839b6596c83f7e","In this paper, we propose multimodal extensions of the recently introduced sparse subspace clustering (SSC) and low-rank representation (LRR) based subspace clustering algorithms for clustering data lying in a union of subspaces. Given multimodal data, our method simultaneously clusters data in the individual modalities according to their subspaces. In our formulation, we exploit the self expressiveness property of each sample in its respective modality and enforce the common representation across the modalities. We modify our model so that it is robust to noise. Furthermore, we kernelize the proposed algorithms to handle nonlinearities in data. The optimization problems are solved efficiently using the alternative direction method of multiplier (ADMM). Experiments on face clustering indicate the proposed method performs favorably compared to state-of-the-art subspace clustering methods. © 2017 Elsevier B.V.","Biometrics; Face clustering; Low-rank representation-based subspace clustering; Multimodal subspace clustering; Sparse subspace clustering; Subspace clustering","Biometrics; Optimization; Face clustering; Low-rank representations; Method of multipliers; Multi-modal data; Optimization problems; Sparse and low ranks; Sub-Space Clustering; Union of subspaces; Clustering algorithms",2-s2.0-85019365201
"Klukowski L.","Determining of an estimate of the equivalence relation on the basis of pairwise comparisons",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019219355&doi=10.1007%2f978-3-319-59162-9_10&partnerID=40&md5=ed6e6cf7f0431f819eb06c9723d802c5","The paper presents two approaches for solving of a discrete programming problem necessary for determining of estimates of the equivalence relation on the basis of pairwise comparisons with random errors. The problem minimizes sum of absolute differences between relation form and comparisons. The problem is NP hard and can be solved with the use of exact algorithms for moderate size of sets - about 50 elements. In the case of larger sets, at least 100 elements and/or multiple comparisons, it is necessary to apply heuristic algorithms. The paper presents original results: a statistical preprocessing, based on two tests proposed, which allows determining of the optimal or suboptimal solution for large sets with acceptable computational cost. © Springer International Publishing AG 2018.","Estimation of the equivalence relation; Nearest adjoining order idea; Pairwise comparisons","Random errors; Set theory; Computational costs; Discrete programming; Equivalence relations; Multiple comparison; Nearest adjoining order idea; Pair-wise comparison; Suboptimal solution; Sum of absolute differences; Heuristic algorithms",2-s2.0-85019219355
"Sanchez-Perez M.A., Gelbukh A., Sidorov G., Gómez-Adorno H.","Plagiarism Detection with Genetic-Based Parameter Tuning",2018,"International Journal of Pattern Recognition and Artificial Intelligence",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028295384&doi=10.1142%2fS0218001418600066&partnerID=40&md5=798a75d0e40bcfaea843b8a7336e2b5d","A crucial step in plagiarism detection is text alignment. This task consists in finding similar text fragments between two given documents. We introduce an optimization methodology based on genetic algorithms to improve the performance of a plagiarism detection model by optimizing its input parameters. The implementation of the genetic algorithm is based on nonbinary representation of individuals, elitism selection, uniform crossover, and high mutation rate. The obtained parameter settings allow the plagiarism detection model to achieve better results than the state-of-the-art approaches. © 2018 World Scientific Publishing Company.","genetic algorithms; optimization; Plagiarism detection; text alignment","Genetic algorithms; Optimization; High mutation rate; Optimization methodology; Parameter setting; Parameter-tuning; Plagiarism detection; State-of-the-art approach; Text alignments; Uniform crossovers; Intellectual property",2-s2.0-85028295384
"Komkhao M., Kubek M., Halang W.A.","Sequentially grouping items into clusters of unspecified number",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022209657&doi=10.1007%2f978-3-319-60663-7_28&partnerID=40&md5=281730641c713c03e69aaa2017fc0dc7","When run, most traditional clustering algorithms require the number of clusters sought to be specified beforehand, and all clustered items to be present. These two, for practical applications very serious shortcomings are overcome by a straightforward sequential clustering algorithm. Its most crucial constituent is a distance measure whose suitable choice is discussed. It is shown how sequentially obtained cluster sets can be improved by reclustering, and how items considered as outliers can be removed. The method’s feasible applicability to text analysis is shown. © Springer International Publishing AG 2018.","Clustering; Distance measures; Number of clusters; Outlier removal; Reclustering; Sequential clustering; Single-linkage; Text analysis","Image segmentation; Statistics; Clustering; Distance measure; Number of clusters; Outlier removals; Re-clustering; Sequential clustering; Single linkage; Text analysis; Clustering algorithms",2-s2.0-85022209657
"Akl S.G.","Computing shortest paths with cellular automata",2018,"Journal of Cellular Automata",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028535452&partnerID=40&md5=15a308c5c5749dca693a9bddaf9f7430","We describe cellular-automaton-based algorithms for solving two shortest path problems on arbitrary connected, directed, and weighted graphs with n vertices. The first problem is that of finding the shortest path from a given vertex to another given vertex of the graph. A two-dimensional cellular automaton, shaped as a triangle, with O(n2) cells, is used. The algorithm runs in O(n) time. The second problem requires that all shortest paths between pairs of vertices be obtained. An n × n cellular automaton solves the problem in O(n log n) time. © 2017 Old City Publishing, Inc.",,"Cellular automata; Directed graphs; Automaton-based algorithms; Shortest path; Shortest path problem; Two-dimensional cellular automata; Weighted graph; Graph theory",2-s2.0-85028535452
"Tricoire F., Scagnetti J., Beham A.","New insights on the block relocation problem",2018,"Computers and Operations Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028758267&doi=10.1016%2fj.cor.2017.08.010&partnerID=40&md5=1d27d9c87806274215bd26734284c879","This article presents new methods for the block relocation problem (BRP). Although much of the existing work focuses on the restricted BRP, we tackle the unrestricted BRP, which yields more opportunities for optimisation. Our contributions include fast heuristics able to tackle very large instances within seconds, fast metaheuristics that provide very competitive performance on benchmark data sets, as well as a new lower bound that generalises existing ones. We embed it in a branch-and-bound algorithm, then assess the influence of various factors on the efficiency of branch-and-bound algorithms for the BRP. © 2017 Elsevier Ltd","Block relocation problem; Branch-and-bound; Heuristics","Benchmarking; Optimization; Benchmark data; Branch-and-bound algorithms; Competitive performance; Fast heuristics; Heuristics; Meta heuristics; Optimisations; Relocation problem; Branch and bound method",2-s2.0-85028758267
"Rezaeimehr F., Moradi P., Ahmadian S., Qader N.N., Jalili M.","TCARS: Time- and Community-Aware Recommendation System",2018,"Future Generation Computer Systems",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018163776&doi=10.1016%2fj.future.2017.04.003&partnerID=40&md5=12121ff0d22a13a26f06bf74b64db66c","With the abundance of information produced by users on items (e.g., purchase or rating histories), recommender systems are a major ingredient of online systems such as e-stores and service providers. Recommendation algorithms use information available from users–items interactions and their contextual data to provide a list of potential items for each user. These algorithms are constructed based on similarity between users and/or items (e.g., a user is likely to purchase the same items as his/her most similar users). In this work, we introduce a novel time-aware recommendation algorithm that is based on identifying overlapping community structure among users. Users’ interests might change over time, and accurate modeling of dynamic users’ preferences is a challenging issue in designing efficient personalized recommendation systems. The users–items interaction network is often highly sparse in real systems, for which many recommenders fail to provide accurate predictions. The proposed overlapping community structure amongst the users helps in minimizing the sparsity effects. We apply the proposed algorithm on two real-world benchmark datasets and show that it overcomes these challenges. The proposed algorithm shows better precision than a number of state-of-the-art recommendation methods. © 2017 Elsevier B.V.","Network science; Overlapping community structure; Recommender systems; Reliability; Social networks","Recommender systems; Reliability; Social networking (online); Social sciences; Accurate prediction; Benchmark datasets; Interaction networks; Network science; Overlapping communities; Personalized recommendation systems; Recommendation algorithms; Recommendation methods; Online systems",2-s2.0-85018163776
"Tanwar R., Malhotra S.","Opinion formation based optimization in audio steganography",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028422629&doi=10.1007%2f978-3-319-63673-3_39&partnerID=40&md5=79ffd6de03184e2649bc28eb9ec771bc","In the present scenario where so many computational problems are being solved using nature inspired optimization algorithms. Human being the most the intelligent creature, deserves to inspire researchers by its method of opinion formation. Steganography is proving to be the ultimate tool of data security. The technique can be improved further by applying optimization. In this paper, a new technique is proposed where optimization is done on the basis of human opinion formation. © 2018, Springer International Publishing AG.","Human opinion formation; Optimization; Social impact theory; Substitution technique","Computation theory; Intelligent systems; Optimization; Audio steganography; Computational problem; Human being; Opinion formation; Optimization algorithms; Social impact theories; Substitution techniques; Steganography",2-s2.0-85028422629
"Li G., Chen Y., Zhang Z., Zhong J., Chen Q.","Social personalized ranking with both the explicit and implicit influence of user trust and of item ratings",2018,"Engineering Applications of Artificial Intelligence",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032675801&doi=10.1016%2fj.engappai.2017.10.006&partnerID=40&md5=d31560e6d2710702ecccdf31f206f6aa","Due to the inherent deficiency of social collaborative filtering algorithms based on rating prediction, social personalized ranking algorithms based on ranking prediction have recently received much more attention in recommendation communities due to their close relationship with real industry problem settings. However, most existing social personalized ranking algorithms focus on either explicit feedback data or implicit feedback data rather than making full use of the information in the dataset. Until now, no studies have been done on social personalized ranking algorithms by exploiting both the explicit and implicit influence of user trust and of item ratings. In order to overcome the defects of prior researches and to further solve the problems of data sparsity and cold start of collaborative filtering, a new social personalized ranking model (SPR_SVD++) based on the newest xCLiMF model and TrustSVD model was proposed, which exploited both the explicit and implicit influence of user trust and of item ratings simultaneously and optimized the well-known evaluation metric Expected Reciprocal Rank (ERR) Experimental results on practical datasets showed that our proposed model outperformed existing state-of-the-art collaborative filtering approaches over two different evaluation metrics NDCG and ERR, and that the running time of SPR_SVD++ showed a linear correlation with the number of users in the data collection and the number of observations in the rating and trust matrices. Due to its high precision and good expansibility, SPR_SVD++ is suitable for processing big data and has wide application prospects in the field of internet information recommendation. © 2017 Elsevier Ltd","Collaborative filtering; Explicit feedback; Implicit feedback; Recommended systems; Social personalized ranking","Big data; Data handling; Application prospect; Collaborative filtering algorithms; Evaluation metrics; Explicit feedback; Implicit feedback; Internet information; Recommended systems; Social personalized ranking; Collaborative filtering",2-s2.0-85032675801
"Neri A., Rosenthal J., Schipani D.","Fuzzy authentication using rank distance",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026637386&doi=10.1007%2f978-3-319-59265-7_7&partnerID=40&md5=7bd925ab2d9671e053e57d248ecb92e0","Fuzzy authentication allows authentication based on the fuzzy matching of two objects, for example based on the similarity of two strings in the Hamming metric, or on the similiarity of two sets in the set difference metric. Aim of this paper is to show other models and algorithms of secure fuzzy authentication, which can be performed using the rank metric. A few schemes are presented which can then be applied in different scenarios and applications. © Springer International Publishing AG 2018.",,"Authentication; Network layers; Example based; Fuzzy authentications; Fuzzy matching; Hamming metric; Models and algorithms; Rank distance; Cryptography",2-s2.0-85026637386
"Melin P., Prado-Arechiga G.","Introduction",2018,"SpringerBriefs in Applied Sciences and Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021774365&doi=10.1007%2f978-3-319-61149-5_1&partnerID=40&md5=d59f6e115bf93314e55f8598fe2d8745","In the book we present a novel model for classification, diagnosis and risk evaluation of high blood pressure using new hybrid intelligent systems, combining Modular Neural Networks, Fuzzy Logic and Genetic Algorithms. We focused on the development of hybrid intelligent systems; for classification of blood pressure levels using the experience of cardiologists and the guidelines of European Society of Cardiology, and for constructing a fuzzy logic classification method based on patient’s Blood pressure. © 2018, The Author(s).","Blood pressure classification; Hybrid Intelligent Systems; Modular Neural Networks","Blood pressure; Computer aided diagnosis; Computer circuits; Fuzzy neural networks; Genetic algorithms; Intelligent systems; High blood pressures; Hybrid intelligent system; Modular neural networks; Pressure level; Risk evaluation; Fuzzy logic",2-s2.0-85021774365
"Li X., Jiang X., Garraghan P., Wu Z.","Holistic energy and failure aware workload scheduling in Cloud datacenters",2018,"Future Generation Computer Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027731703&doi=10.1016%2fj.future.2017.07.044&partnerID=40&md5=6d728d78e22fa5864b55ea6235a7f106","The global uptake of Cloud computing has attracted increased interest within both academia and industry resulting in the formation of large-scale and complex distributed systems. This has led to increased failure occurrence within computing systems that induce substantial negative impact upon system performance and task reliability perceived by users. Such systems also consume vast quantities of power, resulting in significant operational costs perceived by providers. Virtualization – a commonly deployed technology within Cloud datacenters – can enable flexible scheduling of virtual machines to maximize system reliability and energy-efficiency. However, existing work address these two objectives separately, providing limited understanding towards studying the explicit trade-offs towards dependable and energy-efficient compute infrastructure. In this paper, we propose two failure-aware energy-efficient scheduling algorithms that exploit the holistic operational characteristics of the Cloud datacenter comprising the cooling unit, computing infrastructure and server failures. By comprehensively modeling the power and failure profiles of a Cloud datacenter, we propose workload scheduling algorithms Ella-W and Ella-B, capable of reducing cooling and compute energy while minimizing the impact of system failures. A novel and overall metric is proposed that combines energy efficiency and reliability to specify the performance of various algorithms. We evaluate our algorithms against Random, MaxUtil, TASA, MTTE and OBFIT under various system conditions of failure prediction accuracy and workload intensity. Evaluation results demonstrate that Ella-W can reduce energy usage by 29.5% and improve task completion rate by 3.6%, while Ella-B reduces energy usage by 32.7% with no degradation to task completion rate. © 2017 Elsevier B.V.","Cloud computing; Energy efficiency; Failures; Reliability; Thermal management; Workload scheduling","Cloud computing; Distributed computer systems; Economic and social effects; Energy utilization; Failure (mechanical); Green computing; Outages; Reliability; Scheduling; Scheduling algorithms; Systems engineering; Temperature control; Complex distributed system; Computing infrastructures; Efficiency and reliability; Energy-Efficient Scheduling; Flexible scheduling; Operational characteristics; System reliability; Workload intensities; Energy efficiency",2-s2.0-85027731703
"Geman O., Chiuchisan I., Covasa M., Doloc C., Milici M.-R., Milici L.-D.","Deep learning tools for human microbiome big data",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029511447&doi=10.1007%2f978-3-319-62521-8_21&partnerID=40&md5=b9ac13c2e213a207bfb61319fd1705fe","Deep Learning is a branch of Machine Learning, which focuses on a set of algorithms that model high-level abstractions in data by using a deep representation of multiple processing layers. The goal of Machine Learning is to map input patterns to output values. This paper will suggest a potential application of Deep Learning Algorithms for the analysis of large amounts of data produced by the research of the Human Microbiome. Humans have coevolved with microbes in the environment, and each body habitat has a unique set of microorganisms (microbiota). The most abundant and well-studied microbiota are found in the gut, where the bacterial density reaches 1011–1012Â cells/g in the distal human colon. The number of bacteria in the human gut has been estimated to exceed the number of somatic cells in the body by an order of magnitude and that the biomass of the gut microbiota may reach up to 1.5Â kg. This paper presents different methods that have been implemented and tested on a Human Microbiome Dataset. Besides the findings concerning accuracy and runtime, the results suggest that the Deep Learning algorithms could be successfully used to analyze large amounts of Microbiota data. © 2018, Springer International Publishing AG.","Big Data; Data Mining; Deep learning; Human Microbiome; Machine learning","Artificial intelligence; Bacteria; Big data; Data mining; Deep learning; Learning systems; Microorganisms; Soft computing; Bacterial density; Gut microbiota; High-level abstraction; Human microbiome; Input patterns; Large amounts of data; Learning tool; Multiple processing; Learning algorithms",2-s2.0-85029511447
"Klonowski M., Plata M., Syga P.","User authorization based on hand geometry without special equipment",2018,"Pattern Recognition",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028323702&doi=10.1016%2fj.patcog.2017.08.017&partnerID=40&md5=aa886a627033ecfd14c32cf085e3990f","Bioidentification is one of the most popular methods of user identification, one of the reasons is the fact that the ‘access tokens’ are part of user's body and cannot be simply lost or forgotten. Recently, the popularity of biometric methods increases even more due to the improved accuracy of measuring devices and lower error rates offered by the algorithms. Despite the technological progress, prices of the top tier equipment remain on a constant, high level. In this paper, we propose a hand geometry user identification algorithm that utilizes data acquired by a standard office scanner, and that has reasonable execution times of both data collection and the identification process. In order to achieve an algorithm that is as accurate as current state of the art algorithms (or even outperforms them) and utilizes only devices that are commonly available in most offices we had to include several non-standard hand geometric features, e.g. the crookedness of the fingers. Our algorithm was tested on 60 volunteer adults, with age ranging from early 20s to late 50s. The most important results are False Acceptance Rate (FAR) equal to 0.0% and False Rejection Rate (FRR) at the level of 1.19%, with Equal Error Rate (EER) 0.59% during authorization (referred to as verification mode since algorithm verifies the claimed identity), when using a template derived from three images. In identification mode we got results FAR=0.0%, FRR=1.19% and ERR=0.59%. We achieved Identification Rate (IR) equal to 100.0% when taking only subjects from the database in identification mode. The subjects were not limited regarding the position of their hand on the scanner, nor were hand injuries and jewelry a disqualifying factor. Moreover, we describe the performance and time needed in a real-life experiments, showing that the algorithm may be used by people without technical background at low cost and is adequate for systems that require medium to high level of security. © 2017","Basic devices; Bioidentification; Palm scan; Pattern recognition","Geometry; Pattern recognition; Real time systems; Scanning; Basic devices; Bioidentification; False acceptance rate; False rejection rate; Identification process; Palm scan; State-of-the-art algorithms; Technological progress; Palmprint recognition",2-s2.0-85028323702
"Merlet J.-P.","Computing cross-sections of the workspace of cable-driven parallel robots with 6 sagging cables",2018,"Mechanisms and Machine Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026290916&doi=10.1007%2f978-3-319-60867-9_21&partnerID=40&md5=35aac4d9b2e54e353cb3a5d56da76903","Finding the workspace of cable driven parallel robots (CDPR) with sagging cables (i.e. elastic and deformable cables) is a problem that has never been fully addressed in the literature as this is a complex issue: the inverse kinematics may have multiple solutions and the equations that describe the problem are non-linear and non algebraic. We address here the problem of determining an approximation of the border of horizontal cross-sections of the workspace for CDPR with 6 cables. We present an algorithm that give an outline of this border but also rises several theoretical issues. We then propose another algorithm that allow to determine a polygonal approximation of the workspace border induced by a specific constraint. All these algorithms are illustrated on a very large CDPR. © Springer International Publishing AG 2018.","Cable-driven parallel robots; Kinematics; Workspace","Approximation algorithms; Inverse kinematics; Inverse problems; Kinematics; Robots; Cable-driven; Horizontal cross section; Multiple solutions; Non linear; Parallel robots; Polygonal approximations; Workspace; Cables",2-s2.0-85026290916
"Duolikun D., Watanabe R., Enokido T., Takizawa M.","Energy-aware dynamic migration of virtual machines in a server cluster",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026327713&doi=10.1007%2f978-3-319-61566-0_7&partnerID=40&md5=f9958eb26c36f0300c0b01c57f0d6135","Virtual machines are now widely used to support applications with virtual computation service in server clusters. Here, a virtual machine can migrate from a host server to a guest server while processes are being performed. In this paper, we discuss a virtual machine migration approach to reducing the electric energy consumption of servers. In our previous studies, virtual machines are fixed in a cluster. In this paper, we consider a cluster where virtual machines are dynamically created and dropped. We propose a dynamic virtual machine migration (DVMM) algorithm to reduce the total electric energy consumption of servers. We evaluate the DVMM algorithm and show the total electric energy consumption and active time of servers and the average execution time of processes can be reduced compared with other non-migration algorithms. © Springer International Publishing AG 2018.",,"Distributed computer systems; Energy utilization; Network security; Power management; Average Execution Time; Computation service; Dynamic migration of virtual machines; Electric energy consumption; Energy aware; Migration algorithms; Server cluster; Virtual machine migrations; Virtual machine",2-s2.0-85026327713
"Yang X.-B., Chen Y.-P., Xiao Y.-L.","An Improved Scheme of Secure Access and Detection of Cloud Front-End Device",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030870895&doi=10.1007%2f978-3-319-68527-4_6&partnerID=40&md5=0524562def406de793b7cbca64ee9926","Security of accessing cloud services is very crucial problem for front-end devices in network. In the research literature, the typical methods aim for certificates and key mutual authentication of devices. However, in this paper, we propose a new efficient design scheme, the key idea of the scheme is to adopt the elliptic curve cryptography (ECC) algorithm for authentication, combined with attributes information of front-end device using smart card, and use the high security Advanced Encryption Standard (AES) algorithm to encrypt data instead of the conventional DES and 3DES algorithms. Especially, in the process of data transmission, the authentication server regularly detects the legitimacy identifier of access devices and synchronously update the share key of session to resist the key hijacking crack. Thus, the front-end device with the secure modular of smart card not only becomes trusted, but also the device’s information and data are well protected in the accessing cloud network. © 2018, Springer International Publishing AG.","AES; Authentication; Cloud service; Device attribute; ECC; Smart card","Authentication; Cryptography; Data handling; Data privacy; Distributed database systems; Information analysis; Public key cryptography; Smart cards; Transportation; Advanced Encryption Standard algorithms; Authentication servers; Cloud services; Device attribute; Efficient designs; Elliptic Curve Cryptography(ECC); Front-end devices; Mutual authentication; Network security",2-s2.0-85030870895
"Yuan Y., Feng Y., Lu X.","Structured dictionary learning for abnormal event detection in crowded scenes",2018,"Pattern Recognition",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027457946&doi=10.1016%2fj.patcog.2017.08.001&partnerID=40&md5=c592cf03d1bd2743033d4f533dfd3b33","Abnormal event detection is now a widely concerned research topic, especially for crowded scenes. In recent years, many dictionary learning algorithms have been developed to learn normal event regularities, and have presented promising performance for abnormal event detection. However, they seldom consider the structural information, which plays important roles in many computer vision tasks, such as image denoising and segmentation. In this paper, structural information is explored within a sparse representation framework. On the one hand, we introduce a new concept named reference event, which indicates the potential event patterns in normal video events. Compared with abnormal events, normal ones are more likely to approximate these reference events. On the other hand, a smoothness regularization is constructed to describe the relationships among video events. The relationships consist of both similarities in the feature space and relative positions in the video sequences. In this case, video events related to each other are more likely to possess similar representations. The structured dictionary and sparse representation coefficients are optimized through an iterative updating strategy. In the testing phase, abnormal events are identified as samples which cannot be well represented using the learned dictionary. Extensive experiments and comparisons with state-of-the-art algorithms have been conducted to prove the effectiveness of the proposed algorithm. © 2017","Abnormal event detection; Dictionary learning; Reference event; Sparse representation; Video surveillance","Image denoising; Image segmentation; Iterative methods; Learning algorithms; Abnormal event detections; Dictionary learning; Reference events; Sparse representation; Video surveillance; Security systems",2-s2.0-85027457946
"Bochenina K., Kesarev S., Boukhanovsky A.","Scalable parallel simulation of dynamical processes on large stochastic Kronecker graphs",2018,"Future Generation Computer Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027412386&doi=10.1016%2fj.future.2017.07.021&partnerID=40&md5=ff52c616ae2a62237cc7f221e0eb7c87","Complex networks are widely recognized today as a unified framework to model the dynamical processes in socio-technical systems at the level of interacting elements. A stochastic Kronecker graph (SKG) is a network generative model that allows reproducing real-world networks while keeping their important topological properties. When sizes of SKGs reach dozens of millions of nodes, there is a need to apply parallel computations to simulate processes on networks stored in a distributed manner. In general, parallel simulation of a dynamical process on a complex network implies all-to-all communication between subnetworks at each iteration. In this paper, we study the efficiency of different SKG partitioning algorithms and different data interchange algorithms for dynamical process simulation on large SKGs. We compare the theoretical efficiency given by parallel performance models with experimental results for different communication patterns. An experimental part of the study was carried out for sparse SKGs with a size up to one billion nodes using Lomonosov supercomputer (Moscow State University, Russian Federation). The results show that: (i) proposed algorithm of SKG partitioning provides highly balanced results, (ii) observed parallel performance is well agreed with presented theoretical models, (iii) the scheme with all-to-all-communications between subnetworks is the most efficient up to approximately one hundred cores, (iv) master–slave scheme with a single master per node outperforms all-to-all scheme for a large size of a communicator (for our experiments, it has achieved near-linear speedup for up to several hundred processes). © 2017 Elsevier B.V.","Complex networks; Dynamical processes; Load balancing; Parallel efficiency; Parallel simulation; Stochastic Kronecker graphs","Distributed computer systems; Efficiency; Iterative methods; Resource allocation; Stochastic models; Stochastic systems; Supercomputers; Topology; All-to-all communication; Dynamical process; Kronecker; Moscow State University; Parallel efficiency; Parallel simulations; Partitioning algorithms; Topological properties; Complex networks",2-s2.0-85027412386
"Bozorgi A., Bozorg-Haddad O., Chu X.","Anarchic society optimization (ASO) algorithm",2018,"Studies in Computational Intelligence",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021650833&doi=10.1007%2f978-981-10-5221-7_4&partnerID=40&md5=e774072d368fcb5af2883b8cb94edb52","Due to limited resources and equipment in most engineering projects, it is necessary to use optimization techniques. Older optimization techniques, including derivative and other mathematical methods may not be practical to new complex problems. Therefore new optimization algorithms are needed. In the past decades many algorithms were developed and used for different optimization problems, which can be divided into three categories including classic, evolutionary and heuristic algorithms. The evolutionary and heuristic algorithms which are used widely in recent years are based on animals’ life. In this chapter, one of the heuristic algorithms named Anarchic Society Optimization (ASO) algorithm based on human societies, is introduced. After a brief literature review of the ASO algorithm, more technical details on this method and its performance are described. © 2018, Springer Nature Singapore Pte Ltd.",,,2-s2.0-85021650833
"Mosca A., Magoulas G.D.","Distillation of deep learning ensembles as a regularisation method",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032328782&doi=10.1007%2f978-3-319-66790-4_6&partnerID=40&md5=d7aafa7d08e7aad96857969dafab7aa0","Ensemble methods are among the most commonly utilised algorithms that construct a group of models and combine their predictions to provide improved generalisation. They do so by aggregating multiple diverse versions of models learned using machine learning algorithms, and it is this diversity that enables the ensemble to perform better than any of its members taken individually. This approach can be extended to produce ensembles of deep learning methods that combine various good performing models, which are between them very diverse because they have reached different local minima and make different prediction errors. It has been shown that a large, cumbersome deep neural network can be approximated by a smaller network through a process of distillation, and that it is possible to approximate an ensemble of other learning algorithms by using a single neural network, with the help of additional artificially generated pseudo-data. We extend this work to show that an ensemble of deep neural networks can indeed be approximated by a single deep neural network with size and capacity equal to the single ensemble member, and we develop a recipe that shows how this can be achieved without using any artificial training data or any other special provisions, such as using the soft output targets during the distillation process. We also show that, under particular circumstances, the distillation process can be used as a form of regularisation, through its implicit reduction in learning capacity. We corroborate our findings with an experimental analysis on some common benchmark datasets in computer vision and deep learning. © 2018, Springer International Publishing AG.","Convolutional neural networks; Deep learning; Distillation; Ensembles","Artificial intelligence; Deep learning; Deep neural networks; Distillation; Learning systems; Neural networks; Artificial training; Benchmark datasets; Convolutional neural network; Distillation process; Ensembles; Experimental analysis; Learning capacity; Prediction errors; Learning algorithms",2-s2.0-85032328782
"Rosati G., Scaramuzza M., Pasqualotto E., De Toni A., Paccagnella A.","Optimization of cyclic voltammetric curve parameters to measure lactate concentration in urine samples",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029666059&doi=10.1007%2f978-3-319-55077-0_14&partnerID=40&md5=4764bd08e647ac5bd4172c1b528c045b","In this work, veal urine dilutions in Hepes-buffered Ringer’s solution (HBRS) are tested by both UV-visible absorption spectroscopy and Cyclic Voltammetry (CV) to assess their viability as mediums for the detection of lactate, through the Lactate Dehydrogenase enzyme (LDH) reaction which involves the formation of NADH. Several data analysis algorithms for the recorded CV data are proposed and compared, in order to optimize the NADH detection in the urine samples dilutions. UV-visible spectroscopy was adopted as reference for NADH quantification. © Springer International Publishing AG 2018.","Biosensors; Cyclic Voltammetry; Lactate; NADH; SPCE; Urine","Absorption spectroscopy; Biosensors; Body fluids; Curve fitting; Ultraviolet visible spectroscopy; Cyclic voltammetric curves; Data analysis algorithms; Lactate; NADH; SPCE; Urine; UV visible spectroscopy; UV-visible absorption spectroscopy; Cyclic voltammetry",2-s2.0-85029666059
"Salvi A.Z., Simoni R., Simas H.","Assembly sequence planning for shape heterogeneous modular robot systems",2018,"Mechanisms and Machine Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031295562&doi=10.1007%2f978-3-319-67567-1_12&partnerID=40&md5=9ec465c7154c55b6f72c025c190a75f4","Modular robots are robots capable of changing their morphology to perform various tasks and to adapt to different environments. In order to explore these versatile robots potentialities, they must be assembled and operated in as many different configurations as possible. This paper presents an original assembly sequence planning to target structures formed by shape heterogeneous modular robots systems. Each robot system is composed by any number of rectangular modules joined edge to edge, forming arbitrary shapes. The new planner is divided into three original algorithms and constitute a complete and novel method to build target structures without internal holes. © 2018, Springer International Publishing AG.","Assembly; Heterogeneous systems; Modular robot","Assembly; Modular robots; Robots; Arbitrary shape; Assembly sequence planning; Edge-to-edge; Heterogeneous systems; Modular robot systems; Original algorithms; Robot system; Target structure; Robot programming",2-s2.0-85031295562
"Coronato A., Paragliola G.","Towards a cognitive system for the identification of sleep disorders",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020400474&doi=10.1007%2f978-3-319-59480-4_10&partnerID=40&md5=8e8166e22a7001b7e06a3a8aeb932845","Alzheimer’s disease (AD) is the most common type of dementia. Patients with AD may show anomalous behaviors such as sleeping disorders. Due to the increasing attention focused on these kinds of behaviors, activities like monitoring and identification are becoming critical. In order to meet these requirements, we propose a cognitive approach based on a combination of machine learning algorithms and a prior knowledge base for the identification of anomalous behaviors during sleep. The results show an improvement in the identification of sleeping disorders of more than 10%. © Springer International Publishing AG 2018.",,"Cognitive systems; Interactive computer systems; Knowledge based systems; Learning algorithms; Learning systems; Multimedia services; Multimedia systems; Alzheimer; Anomalous behavior; Cognitive approaches; Prior knowledge; Sleep disorders; Sleep research",2-s2.0-85020400474
"Gaur M., Minocha B., Muttoo S.K.","A study of factors affecting mapreduce scheduling",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031403234&doi=10.1007%2f978-981-10-6620-7_27&partnerID=40&md5=553a349a672a1a072b25329ecb6f7692","MapReduce is a programming model for parallel distributed processing of large-scale data. Hadoop framework is an implementation of MapReduce. Since MapReduce processes data parallel on clusters of nodes, there is a need to have a good scheduling technique to optimize performance. Performance of MapReduce scheduling depends upon various points like execution time, resource utilization across the cluster, data locality, compute capacity, energy efficiency, heterogeneity, scaling, etc. Researchers have developed various algorithms to resolve some or the other problem and reach a near-optimal solution. This paper summarizes most of the research work done in this regard. © 2018, Springer Nature Singapore Pte Ltd.","Hadoop; MapReduce; Scheduling algorithms","Distributed computer systems; Energy efficiency; Scheduling; Scheduling algorithms; Hadoop; Hadoop frameworks; Map-reduce; Near-optimal solutions; Parallel distributed processing; Programming models; Resource utilizations; Scheduling techniques; Big data",2-s2.0-85031403234
"Zghaibeh M., Ul Hasan N.","SAM: Scalable addressing mechanism for structured P2P networks",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028633832&doi=10.1007%2f978-3-319-60834-1_13&partnerID=40&md5=cae33cace8cceb64069e2b46150d907f","Structured P2P network must be able to handle churn effectively and be resilient to nodes failure. The network must also scale to large number of nodes while maintaining a minimum diameter. In this paper we introduce SAM: A Scalable Addressing Mechanism for structured P2P networks. SAM places nodes based on geometric addressing, maps keys onto values using Distributed Hash Table (DHT), and locates keys in the network efficiently. Lookups in SAM are bounded to where d is the number of dimensions. Moreover, each node in SAM only maintains routing entries. Finally, SAM adapts to nodes dynamics and recovers lost paths by deploying two maintenance algorithms. © 2018, Springer International Publishing AG.","DHT; Latency; Overlay; P2P; Performance; Structured","Computer programming; Computer science; Distributed hash tables; Latency; Maintenance algorithms; Minimum diameters; Overlay; Performance; Structured; Structured P2P networks; Peer to peer networks",2-s2.0-85028633832
"Furini F., Shen X.","Matheuristics for the temporal bin packing problem",2018,"Operations Research/ Computer Science Interfaces Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032642420&doi=10.1007%2f978-3-319-58253-5_19&partnerID=40&md5=27f01e2e4d1501aeaf84c687e69fb019","We study an extension of the Bin Packing Problem, where items consume the bin capacity during a time window only. The problem asks for finding the minimum number of bins to pack all the items respecting the bin capacity at any instant of time. Both a polynomial-size formulation and an extensive formulation are studied. Moreover, various heuristic algorithms are developed and compared, including greedy heuristics and a column generation based heuristic. We perform extensive computational experiments on benchmark instances to evaluate the quality of the computed solutions with respect to strong bounds based on the linear programming relaxation of the proposed formulations. © Springer International Publishing AG 2018.","Column generation; Heuristic algorithms; Temporal bin packing problem",,2-s2.0-85032642420
"González R., Sánchez-González L., Vallepuga J., Ubero I.","Parallel performance of the boundary element method in thermoelastic contact problems",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028636631&doi=10.1007%2f978-3-319-67180-2_51&partnerID=40&md5=f40c7f82614d7dee2259f3c3e12359ad","This paper proposes two parallel algorithms to optimise a Fortran application that solves thermoelastic contact problems between three-dimensional solids using the Boundary Element Method. Parallel libraries like MPI are of great use when trying to minimise the execution time of numerical codes. Experiments carried out show the effectiveness of parallel programming and the study of the obtained results provides information on the main factors influencing that effectiveness. A reduction in the execution time of a 82.93% has been achieved. © 2018, Springer International Publishing AG.","Boundary element method; MPI; Parallel algorithms; Performance improvement; Thermoelastic contact problems","Parallel algorithms; Parallel programming; Sailing vessels; Soft computing; Thermoelasticity; Numerical code; Parallel library; Parallel performance; Performance improvement; Thermoelastic contacts; Three-dimensional solids; Boundary element method",2-s2.0-85028636631
"Melin P., Prado-Arechiga G.","Conclusions",2018,"SpringerBriefs in Applied Sciences and Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021727076&doi=10.1007%2f978-3-319-61149-5_7&partnerID=40&md5=6f8da41cddf7e13c2e8b83f555fa5b00","We present in this book a novel model for classification, diagnosis and risk evaluation of high blood pressure or arterial hypertension using new hybrid intelligent systems, combining Modular Neural Networks, Fuzzy Logic and Genetic Algorithms. The motivation of this research work is based on the importance of developing new methods using Computational Intelligence for application in medicine, particularly in the area of cardiology to diagnose cardiovascular diseases. In this particular case to help medical doctors diagnose, classify and determine the possible risk of developing high blood pressure. © 2018, The Author(s).",,"Blood pressure; Cardiology; Computation theory; Computer aided diagnosis; Diagnosis; Fuzzy neural networks; Genetic algorithms; Intelligent systems; Arterial hypertension; Cardio-vascular disease; High blood pressures; Hybrid intelligent system; Medical doctors; Modular neural networks; Risk evaluation; Fuzzy logic",2-s2.0-85021727076
"Narayanan S., Sahoo S.K., Makur A.","Greedy Pursuits Assisted Basis Pursuit for reconstruction of joint-sparse signals",2018,"Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027490036&doi=10.1016%2fj.sigpro.2017.08.007&partnerID=40&md5=dcbcef3113b88fbc384f5b1942dc5f65","Distributed Compressive Sensing (DCS) is an extension of compressive sensing from single measurement vector problem to Multiple Measurement Vectors (MMV) problem. In DCS, several reconstruction algorithms have been proposed to reconstruct the joint-sparse signal ensemble. However, most of them are designed for signal ensemble sharing common support. Since the assumption of common sparsity pattern is very restrictive, we are more interested in signal ensemble containing both common and innovation components. With a goal of proposing an MMV-type algorithm that is robust to outliers (absence of common sparsity pattern), we propose Greedy Pursuits Assisted Basis Pursuit for Multiple Measurement Vectors (GPABP-MMV). It employs modified basis pursuit and MMV versions of multiple greedy pursuits. We also formulate the exact reconstruction conditions and the reconstruction error bound for GPABP-MMV. GPABP-MMV is suitable for a variety of applications including time-sequence reconstruction of video frames, reconstruction of ECG signals, etc. © 2017 Elsevier B.V.","Modified basis pursuit; Multiple Measurement Vectors","Compressed sensing; Signal reconstruction; Vectors; Compressive sensing; Exact reconstruction; Joint sparse signals; Modified basis pursuit; Multiple measurement vector (MMV); Multiple measurement vectors; Reconstruction algorithms; Reconstruction error; Biomedical signal processing",2-s2.0-85027490036
"Vyas R., Kanumuri T., Sheoran G.","An approach for iris segmentation in constrained environments",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031420745&doi=10.1007%2f978-981-10-6747-1_12&partnerID=40&md5=745838ee2096e406a81c73959ff83e46","Iris recognition has become a popular technique for differentiating individuals on the basis of their iris texture with high accuracy. One of the decisive steps of iris recognition is iris segmentation because it notably affects the accuracy of feature extraction and matching steps. Most state-of-the-art algorithms use circular Hough transform (CHT) for segmenting the iris from an eye image. But, CHT does not work efficiently for eye images having less contrast. Therefore, a new approach is proposed here for isolating and normalizing the iris region, which is more robust than CHT. Experiments are performed on IITD iris database. The proposed algorithm works better than the traditional CHT. © 2018, Springer Nature Singapore Pte Ltd.","Circular Hough transform; Iris recognition; Iris segmentation; Normalization","Biometrics; Hough transforms; Circular Hough transforms; Feature extraction and matching; High-accuracy; Iris recognition; Iris segmentation; New approaches; Normalization; State-of-the-art algorithms; Feature extraction",2-s2.0-85031420745
"Fidanova S., Atanassova V., Roeva O.","Ant colony optimization application to GPS surveying problems: InterCriteria analysis",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031416574&doi=10.1007%2f978-3-319-65545-1_23&partnerID=40&md5=12afbb20c444d633ad34e88e1759911e","Ant Colony Optimization (ACO) has been used successfully to solve hard combinatorial optimization problems. This metaheuristics method is inspired by the foraging behavior of ant colonies, which manage to establish the shortest routes between their colonies to feeding sources and back. In this paper, ACO algorithms are developed to provide near-optimal solutions for Global Positioning System surveying problem (GSP). In designing Global Positioning System (GPS) surveying network, a given set of earth points must be observed consecutively (schedule). The cost of the schedule is the sum of the time needed to go from one point to another. The problem is to search for the best order in which this observation is executed, minimizing the cost of the schedule. We apply InterCriteria Analysis (ICrA) on the achieved results. Based on ICrA we examine some relations between considered GSPs and ACO algorithm performance. © Springer International Publishing AG 2018.","Ant colony optimization; GPS surveying; InterCriteria analysis","Artificial intelligence; Combinatorial optimization; Decision making; Decision support systems; Fuzzy sets; Global positioning system; Optimization; Surveying; Surveys; ACO algorithms; Ant Colony Optimization (ACO); Combinatorial optimization problems; Foraging behaviors; InterCriteria analysis; Meta heuristics; Near-optimal solutions; Shortest route; Ant colony optimization",2-s2.0-85031416574
"Gupta K., Chatterjee N.","Financial time series clustering",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028387625&doi=10.1007%2f978-3-319-63645-0_16&partnerID=40&md5=023d390285a66710ca46f3ab4776e199","Financial time series clustering finds application in forecasting, noise reduction and enhanced index tracking. The central theme in all the available clustering algorithms is the dissimilarity measure employed by the algorithm. The dissimilarity measures, applicable in financial domain, as used or suggested in past researches, are correlation based dissimilarity measure, temporal correlation based dissimilarity measure and dynamic time wrapping (DTW) based dissimilarity measure. One shortcoming of these dissimilarity measures is that they do not take into account the lead or lag existing between the returns of different stocks which changes with time. Mostly, such stocks with high value of correlation at some lead or lag belong to the same cluster (or sector). The present paper, proposes two new dissimilarity measures which show superior clustering results as compared to past measures when compared over 3 data sets comprising of 526 companies. abstract environment. © Springer International Publishing AG 2018.","Clustering; Cross-correlation; Finance; Forecasting; Time series","Finance; Financial data processing; Forecasting; Intelligent systems; Noise abatement; Time series; Clustering; Clustering results; Cross correlations; Dissimilarity measures; Dynamic time wrapping; Financial domains; Financial time series; Temporal correlations; Clustering algorithms",2-s2.0-85028387625
"Jaiyant Gopal S., Anita J.P., Sudheesh P.","Particle filtering technique for fast fading shadow power estimation in wireless communication",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030150925&doi=10.1007%2f978-3-319-67934-1_10&partnerID=40&md5=8fb5b897c840b29649414a43cbf2f650","There is a crucial importance of estimation of fading power in a mobile wireless communication system. This estimation is used for many handoff algorithms, power control, and adaptive transmission methods. This estimation of power loss can be used to reduce discrepancies and provide better wireless communication service to the user. Until now the window based weighted sample average estimator was used because of its simplicity. But it has its own disadvantages and hence use of Kalman filtering and adaptive Kalman filtering was proposed. Based on an autoregressive model of shadow fading power, particle filter algorithm is proposed in this paper in order to increase the efficiency of estimation and to obtain accurate results. The simulation and analysis presented in this paper have provided promising and supporting results. © Springer International Publishing AG 2018.","Particle filter; Power fading; Rayleigh; Shadow power estimation","Adaptive filtering; Adaptive filters; Kalman filters; Monte Carlo methods; Power control; Wireless telecommunication systems; Adaptive Kalman filtering; Mobile wireless communication system; Particle filter; Particle filter algorithms; Power estimations; Power fading; Rayleigh; Wireless communication services; Signal processing",2-s2.0-85030150925
"Liu L., Liu F.","Two degree forest based LT codes with feedback",2018,"Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031284968&doi=10.1007%2f978-3-319-66625-9_23&partnerID=40&md5=49c2ce213f662f05ecfbb04273347f94","The performance of belief propagation (BP) decoding algorithm for LT codes is significantly deteriorated, as the data-block length decreases, since the randomly encoding of LT codes causes lots of wasted output symbols, which is helpless for decoding. To solve this problem, this paper provides two degree forest based LT codes in order to help the sender to send badly needed symbols to accelerate decoding throughout entire receiving process. Through gathering two degree output symbols into separable trees, the decoder can easily get and feedback the indexes of the badly needed input symbols. Simulation results show that, in the short data-block length case, two degree forest based LT codes achieve much lower coding overhead, consume much smaller storage resources, and need less feedback opportunities compared with current LT codes algorithms. © 2018, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.","Feedback channel; LT codes; Robust soliton distribution; Two degree forest","Decoding; Digital storage; Forestry; Belief propagation decoding algorithms; Data blocks; Feedback channel; LT codes; Robust Soliton distributions; Storage resources; Two degree forest; Codes (symbols)",2-s2.0-85031284968
"Moon J., Song T., Lee D., Lee Y., Won D.","Cryptanalysis of chaos-based 2-party key agreement protocol with provable security",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021667890&doi=10.1007%2f978-3-319-60585-2_8&partnerID=40&md5=b5df21e61cad6a5945a5ff901ba18bd0","In a public communication environment, a remote user authentication scheme for establishing a secure session between a user and a server is a very important factor. Authentication schemes, which originate from a password-based authentication scheme, apply some mathematical algorithms to securely share session keys between users and servers. In a remote user authentication scheme, safety is a very important factor, but it is also important to reduce computational cost. Therefore, even if a mathematical algorithm is applied, it is necessary to select an algorithm that consumes a small amount of computation. Recently, Luo et al. proposed a chaos-based two-party key exchange protocol and claimed that the proposed scheme solved the off-line password guessing attack and was safe from other common attacks. They used a Chebyshev chaotic maps. This algorithm is used in many authentication schemes because it consumes a small amount of computation. However, we find that Luo et al.’s scheme is still insecure. In this paper, we show the problems of Chebyshev chaotic maps and demonstrate how an attacker can attempt some attacks. © Springer International Publishing AG 2018.","Chaotic map; Key agreement; User authentication","Chaotic systems; Cryptography; Human engineering; Lyapunov methods; Safety factor; Chaotic map; Key agreement; Key exchange protocols; Mathematical algorithms; Offline password guessing attack; Password-based authentication; Remote user authentication schemes; User authentication; Authentication",2-s2.0-85021667890
"Torky M., Hassanein A.E.","DeBruijn Cellular automata: A dynamic machine model based on debruijn graph approach",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029468488&doi=10.1007%2f978-3-319-64861-3_57&partnerID=40&md5=42d70bdd9ef7fe8f396efceb8ad7465f","Cellular Automata (CA) plays a vital role in simulating the dynamic system behaviors in an automated fashion. CA-designers always seek to build new regular CA models for realizing the complex behavior of dynamic systems. This Paper introduces a novel algorithm for converting a deBruijn graph G(k) of order k into a novel design of automata called deBruijn Cellular Automata (BCA). The BCA’s configuration can be in one-dimension, two-dimensions, or three-dimensions. According to the input’s size N of deBruign graph G(k) and the number of cells M in the target BCA-design model, the verification results proved that the time complexity (i.e. efficiency) of the proposed algorithm can be computed as T(N,M)= 5M+3N-2, which є O(N*M). The proposed algorithm is the first one can be used for generating CA models from the deBruijn graph. This findings demonstrate that BCA is a promising tool for designing new BCA-based algorithms for solving a variety of problems especially in cryptography area. © 2018, Springer International Publishing AG.","Algorithms design and analysis; Cellular automata; de Bruijn graph",,2-s2.0-85029468488
"Wani M.A., Jabin S.","Big data: Issues, challenges, and techniques in business intelligence",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031400676&doi=10.1007%2f978-981-10-6620-7_59&partnerID=40&md5=96bfe3efb905fe4ca4bf79b1efc27f0d","During the last decade, the most challenging problem the world envisaged was big data problem. The big data problem means that data is growing at a much faster rate than computational speeds. And it is the result of the fact that storage cost is getting cheaper day by day, so people as well as almost all business or scientific organizations are storing more and more data. Social activities, scientific experiments, biological explorations along with the sensor devices are great big data contributors. Big data is beneficial to the society and business but at the same time, it brings challenges to the scientific communities. The existing traditional tools, machine learning algorithms, and techniques are not capable of handling, managing, and analyzing big data, although various scalable machine learning algorithms, techniques, and tools (e.g., Hadoop and Apache Spark open source platforms) are prevalent. In this paper, we have identified the most pertinent issues and challenges related to big data and point out a comprehensive comparison of various techniques for handling big data problem. © 2018, Springer Nature Singapore Pte Ltd.","Apache Spark; Big data; Big data analytics; Business intelligence; Hadoop MapReduce; Online social networks","Artificial intelligence; Competitive intelligence; Data handling; Digital storage; Information analysis; Learning algorithms; Learning systems; Social networking (online); Comprehensive comparisons; Data analytics; Hadoop MapReduce; Issues and challenges; On-line social networks; Open source platforms; Scalable machine learning; Scientific experiments; Big data",2-s2.0-85031400676
"Venkata Dasu M., VeeraNarayana Reddy P., Chandra Mohan Reddy S.","A proposal on application of nature inspired optimization techniques on hyper spectral images",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021239400&doi=10.1007%2f978-981-10-3223-3_29&partnerID=40&md5=9bf7381d881cc42e4a3d23835d289dcc","Hyper spectral image are used in various applications such as geological systems, geo sciences and astronomy. These images are acquired using remote sensing. Remote sensing is the process of getting information about an object without making any physical contact with the object. Satellite Images referred as hyper spectral images are the most used images in remote sensing and are of more interest to find out the classification of objects in those images. The classification can give us the important factors like vegetation, buildings, roads and more. Satellite images can be of assistance in supervision of effects due to natural disasters, to recognize mining areas which are hidden from human view, biodiversity examination, rural and urban environment detection for analysis, etc. However, occasionally the Satellite images acquired can be affected by unforeseen distortions, artificial unwanted structures called artifacts that are formed by the tool itself or sometimes due to the diverse pre-processing procedures involved. Optimization algorithms in combination with Image processing methods are used to classify the objects in satellite images for easy perception and analysis. In this paper, various optimization techniques like particle swarm optimization (PSO), DPSO, HSO, and Proposed MFA optimization algorithms are compared to obtain optimal classification of objects in a satellite image. © Springer Nature Singapore Pte Ltd. 2018.","Darwinian PSO; Enhancement; HSO; MFA; Particle swarm optimization (PSO); Segmentation","Biodiversity; Disasters; Image acquisition; Image analysis; Image enhancement; Image segmentation; Intelligent computing; Optimization; Particle swarm optimization (PSO); Processing; Remote sensing; Satellites; Spectroscopy; Darwinian PSO; Geological systems; Hyper-spectral images; Image processing - methods; Optimal classification; Optimization algorithms; Optimization techniques; Physical contacts; Image processing",2-s2.0-85021239400
"Griffin P.H.","Adaptive weak secrets for authenticated key exchange",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021636197&doi=10.1007%2f978-3-319-60585-2_2&partnerID=40&md5=8dc3d88bb46e54546b1d2b8c3347e9df","This paper describes biometric-based cryptographic techniques that use weak secrets to provide strong, multi-factor and mutual authentication, and establish secure channels for subsequent communications. These techniques rely on lightweight cryptographic algorithms for confidential information exchange. Lightweight algorithms are suitable for use in resource constrained environments such as the Internet of Things where implementations require efficient execution, limited access to memory and small code size. Password Authenticated Key Exchange, and Biometric Authenticated Key Exchange protocols based on user knowledge extracted from biometric sensor data, both rely on weak secrets. These secrets are shared between a client and an access controlled server, and used as inputs to Diffie-Hellman key establishment schemes. Diffie-Hellman provides forward secrecy, prevents user credentials from being exposed during identity authentication attempts, and thwarts man-in-the-middle and phishing attacks. This paper describes the operation of these protocols using an adaptive knowledge substitution process that frequently modifies the weak secrets used for protocol operation without requiring disruptive user password changes. The password substitution strings used to implement this process can be far longer and more complex than the weak secrets people can easily memorize. The process described in this paper allows people with diverse abilities to use simple, easily recalled, quickly entered passwords and still benefit from the strength of long, complex strings when operating cryptographic protocols. © Springer International Publishing AG 2018.","Authentication; Biometrics; Key exchange; Password; Security","Biometrics; Cryptography; Human engineering; Knowledge management; Authenticated key exchange; Authenticated key exchange protocols; Cryptographic algorithms; Key establishment schemes; Key exchange; Password; Password-authenticated key exchange; Security; Authentication",2-s2.0-85021636197
"Tüysüzoğlu G., Yaslan Y.","Sparse coding based classifier ensembles in supervised and active learning scenarios for data classification",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029431633&doi=10.1016%2fj.eswa.2017.09.024&partnerID=40&md5=7018248bd43b36b1dbe6f22feb0b2ffa","Sparse coding and dictionary learning has recently gained great interest in signal, image and audio processing applications through representing each problem instance by a sparse set of atoms. This also allows us to obtain different representations of feature sets in machine learning problems. Thus, different feature views for classifier ensembles can be obtained using sparse coding. On the other hand, nowadays unlabelled data is abundant and active learning methods with single and classifier ensembles received great interest. In this study, Random Subspace Dictionary Learning (RDL) and Bagging Dictionary Learning (BDL) algorithms are examined by learning ensembles of dictionaries through feature/instance subspaces. Besides, ensembles of dictionaries are evaluated under active learning framework as promising models and they are named as Active Random Subspace Dictionary Learning (ARDL) and Active Bagging Dictionary Learning (ABDL) algorithms. Active learning methods are compared with their Support Vector Machines counterparts. The experiments on eleven datasets from UCI and OpenML repositories has shown that selecting instance and feature subspaces for dictionary learning model increases the number of correctly classified instances for the most of the data sets while SVM has superiority over all of the applied models. Furthermore, using an active learner generally increases the chance of improved classification performance as the number of iterations is increased. © 2017 Elsevier Ltd","Active learning; Bagging; Dictionary learning; Ensemble classifiers; Random subspace feature selection","Artificial intelligence; Audio signal processing; Codes (symbols); Image coding; Learning algorithms; Learning systems; Support vector machines; Vectors; Active Learning; Bagging; Dictionary learning; Ensemble classifiers; Random subspaces; Classification (of information)",2-s2.0-85029431633
"Rezaei H., Bozorg-Haddad O., Chu X.","Grey wolf optimization (GWO) algorithm",2018,"Studies in Computational Intelligence",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021656432&doi=10.1007%2f978-981-10-5221-7_9&partnerID=40&md5=7f5930579b268417da1cabaea061cfbb","This chapter describes the grey wolf optimization (GWO) algorithm as one of the new meta-heuristic algorithms. First, a brief literature review is presented and then the natural process of the GWO algorithm is described. Also, the optimization process and a pseudo code of the GWO algorithm are presented in this chapter. © 2018, Springer Nature Singapore Pte Ltd.",,,2-s2.0-85021656432
"Li J., Zhao Z., Liu Y., Cheng Z., Wang X.","A comparative study on machine classification model in lung cancer cases analysis",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031402914&doi=10.1007%2f978-981-10-3187-8_34&partnerID=40&md5=f77505f529ecf7eb1b01988c52ffe0c0","Due to the differences of machine classification models in the application of medical data, this paper selected different classification methods to study lung cancer data collected from HIS system with experimental analysis, applying the R language on decision tree algorithm, Bagging algorithm, Adaboost algorithm, SVM, KNN and neural network algorithm for lung cancer data analysis, in order to explore the advantages and disadvantages of each machine classification algorithm. The results confirmed that in lung cancer data research, Adaboost algorithm and neural network algorithm have relatively high accuracy, with a good diagnostic performance. © Springer Nature Singapore Pte Ltd. 2018.","Adaboost algorithm; Cross validation; Machine classification model; Neural network","Adaptive boosting; Biological organs; Classification (of information); Computation theory; Decision trees; Diagnosis; Diseases; Neural networks; Trees (mathematics); AdaBoost algorithm; Classification methods; Cross validation; Decision-tree algorithm; Diagnostic performance; Experimental analysis; Machine classifications; Neural network algorithm; Data mining",2-s2.0-85031402914
"Brbić M., Kopriva I.","Multi-view low-rank sparse subspace clustering",2018,"Pattern Recognition",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028510979&doi=10.1016%2fj.patcog.2017.08.024&partnerID=40&md5=39557f71d8c1a72745b67050ab3f84ab","Most existing approaches address multi-view subspace clustering problem by constructing the affinity matrix on each view separately and afterwards propose how to extend spectral clustering algorithm to handle multi-view data. This paper presents an approach to multi-view subspace clustering that learns a joint subspace representation by constructing affinity matrix shared among all views. Relying on the importance of both low-rank and sparsity constraints in the construction of the affinity matrix, we introduce the objective that balances between the agreement across different views, while at the same time encourages sparsity and low-rankness of the solution. Related low-rank and sparsity constrained optimization problem is for each view solved using the alternating direction method of multipliers. Furthermore, we extend our approach to cluster data drawn from nonlinear subspaces by solving the corresponding problem in a reproducing kernel Hilbert space. The proposed algorithm outperforms state-of-the-art multi-view subspace clustering algorithms on one synthetic and four real-world datasets. © 2017 Elsevier Ltd","Alternating direction method of multipliers; Low-rank; Multi-view data; Reproducing kernel Hilbert space; Sparsity; Subspace clustering","Constrained optimization; Hilbert spaces; Matrix algebra; Optimization; Problem solving; Vector spaces; Alternating direction method of multipliers; Low-rank; Multi-view datum; Reproducing Kernel Hilbert spaces; Sparsity; Sub-Space Clustering; Clustering algorithms",2-s2.0-85028510979
"He Q., Zhou W., Xu H., Cui L., Li X., Liu J.","A Distributed Network Alarm Correlation Analysis Mechanism for Heterogeneous Networks",2018,"Journal of Circuits, Systems and Computers",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020701261&doi=10.1142%2fS0218126618500123&partnerID=40&md5=1621c16a82b1520b84fd5cd644c09991","The current China State Grid network consists of a set of heterogeneous and distributed networks. In such a heterogeneous environment, it is a challenging task to provide efficient network alarm management, and further to analyze the correlation of alarms. Thus, an efficient and distributed network alarm analysis scheme is becoming necessary and indispensable. To this end, we have attached our emphasis on two aspects of the aforementioned problem and proposed the corresponding algorithms, respectively. Firstly, we introduced an intra-network alarm treatment process to manage the heterogeneous network alarms. Especially, we leverage on the fuzzy clustering method and fuse alarms within the same cluster into comprehensive alarms by utilizing the Dempster-Shafer theory. Secondly, we proposed an inter-network alarm analysis process to mine the correlation rules of alarms through a distributed scheme based on the Frequent Pattern-Growth (FP-Growth) association rule mining algorithm. Compared with the traditional centralized scheme and another Apriori-based distributed algorithm, our proposed scheme has a higher time efficiency for the effective management of network alarms. With the aid of such a two-step network alarm management scheme, it is easy for the network management system to make a better management of alarms in heterogeneous and distributed networks. © 2018 World Scientific Publishing Company.","alarm fusion; correlation analysis; distributed and heterogeneous network; Network alarms","Correlation methods; Data mining; Formal logic; Fuzzy clustering; Heterogeneous networks; Network management; Alarm correlation analysis; Correlation analysis; Effective management; Frequent pattern growth; Fuzzy clustering method; Heterogeneous environments; Network management systems; Rule mining algorithms; Alarm systems",2-s2.0-85020701261
"Đurišić Ž., Papić V.","Power system frequency tracking based on LES technique with constant matrix",2018,"Measurement: Journal of the International Measurement Confederation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030703579&doi=10.1016%2fj.measurement.2017.09.045&partnerID=40&md5=7deaae93413f94f2eb14d7f504b6bb30","This paper describes a new algorithm for measuring the frequency in electric power systems. The algorithm is based on the Least Error Squares (LES) technique and uses digitized samples of voltage at a relay location. The algorithm uses one matrix with constant coefficients which can be previously calculated. It was successfully tested using computer simulated signals and using signals obtained through laboratory tests and field measurements. The test results demonstrate the ability of this algorithm to estimate voltage and frequency with acceptable accuracy. © 2017 Elsevier Ltd","Algorithms; Digital signal processing; Frequency estimation; Least squares methods","Algorithms; Digital signal processing; Electric power systems; Least squares approximations; Signal processing; Constant coefficients; Constant matrix; Field measurement; Laboratory test; Least error squares; Least squares methods; Power system frequencies; Simulated signals; Frequency estimation",2-s2.0-85030703579
"Han D., Lv F., Sun W.","Recovery of signals from unordered partial frame coefficients",2018,"Applied and Computational Harmonic Analysis",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963734966&doi=10.1016%2fj.acha.2016.04.002&partnerID=40&md5=e7ef5d1650bf000be0973c05d37d6788","In this paper, we study the feasibility and stability of recovering signals in finite-dimensional spaces from unordered partial frame coefficients. We prove that with an almost self-located robust frame, any signal except from a Lebesgue measure zero subset can be recovered from its unordered partial frame coefficients. However, the recovery is not necessarily stable with almost self-located robust frames. We propose a new class of frames, namely self-located robust frames, that ensures stable recovery for any input signal with unordered partial frame coefficients. In particular, the recovery is exact whenever the received unordered partial frame coefficients are noise-free. We also present some characterizations and constructions for (almost) self-located robust frames. Based on these characterizations and construction algorithms, we prove that any randomly generated frame is almost surely self-located robust. Moreover, frames generated with cube roots of different prime numbers are also self-located robust. © 2016 Elsevier Inc.","Erasure recovery; Robust frames; Self-located robust frames","Harmonic analysis; Mathematical techniques; Construction algorithms; Finite dimensional space; Lebesgue measure; Prime number; Robust frames; Recovery",2-s2.0-84963734966
"Amasyali K., El-Gohary N.M.","A review of data-driven building energy consumption prediction studies",2018,"Renewable and Sustainable Energy Reviews",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029080224&doi=10.1016%2fj.rser.2017.04.095&partnerID=40&md5=f0c2e1a87e727aed8fc24f8a10e07baf","Energy is the lifeblood of modern societies. In the past decades, the world's energy consumption and associated CO2 emissions increased rapidly due to the increases in population and comfort demands of people. Building energy consumption prediction is essential for energy planning, management, and conservation. Data-driven models provide a practical approach to energy consumption prediction. This paper offers a review of the studies that developed data-driven building energy consumption prediction models, with a particular focus on reviewing the scopes of prediction, the data properties and the data preprocessing methods used, the machine learning algorithms utilized for prediction, and the performance measures used for evaluation. Based on this review, existing research gaps are identified and future research directions in the area of data-driven building energy consumption prediction are highlighted. © 2017 Elsevier Ltd","Building energy; Data-driven methods; Energy consumption prediction; Machine learning","Artificial intelligence; Buildings; Energy conservation; Forecasting; Historic preservation; Learning algorithms; Learning systems; Building energy; Building energy consumption prediction; Data preprocessing; Data-driven methods; Data-driven model; Energy consumption prediction; Future research directions; Performance measure; Energy utilization",2-s2.0-85029080224
"Klimenko A., Gorelova G., Korobkin V., Bibilo P.","The Cognitive Approach to the Coverage-Directed Test Generation",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029604606&doi=10.1007%2f978-3-319-67621-0_34&partnerID=40&md5=c123133de02f264798edc7ce75d1fd29","The important contemporary issue of VLSI design verification is its time-consuming. The hardware model, written, for instance, with VHDL, is verified by formal and dynamic verification approaches. Dynamic verification (simulation) is widely-used due to the possibility of full automation of the process, but takes too much time due to its redundancy. The concept of the coverage-directed test generation is to redirect the test generator such as to reach uncovered metric points. There are several approaches for this, including genetic algorithms using, Bayesian network, Data mining, etc. The new cognitive approach to the coverage-directed test generation (CA CDG) is proposed within this paper. It is based on a cognitive map usage. The CA CDG is described, some simulation results are given. Also the future work areas are outlined. © 2018, Springer International Publishing AG.","Cognitive map; Coverage-directed test generation; Simulation; Verification; VHDL","Bayesian networks; Cognitive systems; Computational methods; Computer hardware description languages; Data mining; Genetic algorithms; Testing; Verification; Cognitive approaches; Cognitive maps; Contemporary issues; Dynamic verifications; Hardware models; Simulation; Test generations; VLSI design; Statistical tests",2-s2.0-85029604606
"Patsadu O., Watanapa B., Nukoolkit C.","A multiple-stage classification of fall motions using kinect camera",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022188800&doi=10.1007%2f978-3-319-60663-7_11&partnerID=40&md5=190415f79f27a2b45bf4487c391a46bd","This paper proposes a model of fall detection using hybrid classification methods in video streaming. In particular, we are interested in a stream of data representing time sequential frames of fifteen body joint positions capturable by Kinect camera. A set of features is then extracted and fed into the designated multiple-stage classification. The first stage classifies a fall as a different event from normal activities of daily living (ADLs). The second stage is to classify types of fall once the fall was detected in the first stage, for aiding the diagnosis and treatment of a fall by a physician. We selected a number of reliable machine learning algorithms (MLP, SVM, and decision tree) in forming a hybrid model. Experimental results show that the first stage classifier can differentiate falls and ADLs with 99.98% accuracy and the second stage classifier can identify type of fall with 99.35% accuracy. © Springer International Publishing AG 2018.","Fall detection; Hybrid classification methods; Kinect camera; Multiple-stage classifier; Smart home system","Automation; Cameras; Decision trees; Intelligent buildings; Learning algorithms; Motion analysis; Video streaming; Fall detection; Hybrid classification; Kinect cameras; Multiple stages; Smart-home system; Data mining",2-s2.0-85022188800
"Suchánek P., Bucki R.","Modelling of the logistic supplier-consumer behavior",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020437970&doi=10.1007%2f978-3-319-59394-4_21&partnerID=40&md5=9630b0d5d0b5b1b9d0ceff664e86349b","The paper highlights the problems of mathematical modelling in the delivery system. The system describes the suppliers who offer different types of products as well as the consumers who order different products. Products are ordered at stochastic times, however, manufacturers offer predictable demand. The problem becomes more complex when the number of orders grows. The structure of the system is shown, equations of state are introduced and control algorithms as well as criteria are proposed. Orders change their state which leads to modifying it at every decision stage. The same concerns the actual output of manufacturers which also has to be modified. Therefore, the problem consists of the design of such a delivery pattern which can minimise losses of the discussed company. The goal of the paper is to present the mathematical model of the logistic system taking into account the consumer-supplier relations. The model forms the basis for the subsequent information support tool. © Springer International Publishing AG 2018.","Business process management; Computational modelling; Delivery system; Heuristic algorithms; Information support; Logistic modelling; Mathematical modelling; Optimisation; Simulation","Administrative data processing; Consumer behavior; Enterprise resource management; Equations of state; Heuristic algorithms; Information management; Manufacture; Mathematical models; Optimization; Stochastic systems; Business process management; Computational modelling; Delivery systems; Information support; Logistic modelling; Optimisations; Simulation; Multi agent systems",2-s2.0-85020437970
"Qasem M.H., Qatawneh M.","Parallel Matrix Multiplication for Business Applications",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029585876&doi=10.1007%2f978-3-319-67621-0_3&partnerID=40&md5=2abddc5a0f692a244458bbbc86185b00","Business applications, such as market shops, use matrix multiplication to calculate yearly, monthly, or even daily profits based on price and quantity matrices. Matrices comprise large data in computer applications and other fields, which make the efficiency of matrix multiplication a popular research topic. Although the task of computing matrix products is a central operation in many numerical algorithms, it is potentially time consuming, making it one of the most well-studied problems in this field. In this paper, Message Passing Interface (MPI), MapReduce, and Multithreaded methods have been implemented to demonstrate their effectiveness in expediting matrix multiplication in a multi-core system. Simulation results show that the efficiency rates of MPI and MapReduce are 90.11% and 47.94%, respectively, with a multi-core processor on the Market Shop application, indicating better performances compared with those of the multithreaded and sequential methods. © 2018, Springer International Publishing AG.","Business application; Hadoop; MapReduce; Matrix multiplication; MPI","Commerce; Computational methods; Distributed computer systems; Efficiency; Message passing; Business applications; Hadoop; Map-reduce; MAtrix multiplication; Message passing interface; Multi-core processor; Numerical algorithms; Parallel matrix multiplication; Matrix algebra",2-s2.0-85029585876
"Patel K., Dubey S.K., Singh A.S.","A clustering techniques to detect e-mail spammer and their domains",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028426820&doi=10.1007%2f978-3-319-63645-0_71&partnerID=40&md5=d5c6880f3265093d1da7c1ce9bcb40ef","The latest internet has become a collaboration and communications platform, in that e-mail system is one of the most reliable internet services. Sending a spam e-mail is an economically useful commerce for intruders, with the very good earning of millions of dollars. The spam e-mail has become a critical issue to web and society, to stop/reduce the spam e-mails filtering techniques is not sufficient. This paper proposes to recognize spam domain by reading spam e-mails. These spam domains are nothing but Uniform Resource Locator (URL) of the website that intruder is promoting. The approach is based on extracting mail content; links from URL injected e-mail and subject of spam e-mails. These extracted parameters are grouped together through clustering algorithms and evaluated. This proposed work can be help as additional accessory to already available anti-spam tool to recognize intruders. © Springer International Publishing AG 2018.","Clustering algorithms; Data mining; Spam; Spam e-mail; Spam URL","Clustering algorithms; Data mining; Intelligent systems; Clustering techniques; Communications platform; Critical issues; E-mail systems; Filtering technique; Internet services; Spam; Spam e-mails; Electronic mail",2-s2.0-85028426820
"Bichindaritz I., Breen C., Cole E., Keshan N., Parimi P.","Feature selection and machine learning based multilevel stress detection from ECG signals",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019722181&doi=10.1007%2f978-3-319-59397-5_22&partnerID=40&md5=451508e3a7976f8619067d37db05d218","Physiological sensor analytics aims at monitoring health as the availability of sensor-enabled portable, wearable, and implantable devices become ubiquitous in the growing Internet of Things (IoT). Physiological multi-sensor studies have been conducted previously to detect stress. In this study, we focus on electrocardiography (ECG) monitoring that can now be performed with minimally invasive wearable patches and sensors, to develop an efficient and robust mechanism for accurate stress identification, for example in automobile drivers. A unique aspect of our research is personalized individual stress analysis including three stress levels: low, medium and high. Using machine learning algorithms from the ECG signals alone, our system achieves up to 100% accuracy and area under ROC curve of 1 depending on the experimental setting in detecting three classes of stress using feature selection from a combination of fiducial points and multiscale entropy as a fine-grained indicator of stress level. © Springer International Publishing AG 2018.","Data mining; ECG; Machine learning; Sensors; Stress medicine","Artificial intelligence; Automobile drivers; Data mining; Electrocardiography; Feature extraction; Health care; Implants (surgical); Internet of things; Learning algorithms; Learning systems; Physiology; Sensors; Stress analysis; Wearable technology; Area under roc curve (AUC); Implantable devices; Internet of Things (IOT); Minimally invasive; Multi-scale entropies; Physiological sensors; Robust mechanisms; Stress detection; Wearable sensors",2-s2.0-85019722181
"Setlak G., Bodyanskiy Y., Pliss I., Vynokurova O., Peleshko D., Kobylin I.","Adaptive fuzzy clustering of multivariate short time series with unevenly distributed observations based on matrix neuro-fuzzy self-organizing network",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029437434&doi=10.1007%2f978-3-319-66827-7_28&partnerID=40&md5=64ac3302b5b87d2d1b63d962c90d3be1","In the paper the method of fuzzy clustering task for multivariate short time series with unevenly distributed observations is proposed. Proposed method allows to process the time series both in batch mode and sequential on-line mode. In the first case we can use the matrix modification of fuzzy C-means method, and in second case we can use the matrix modification of neuro-fuzzy network by T. Kohonen, which is learned using the rule “Winner takes more”. Proposed fuzzy clustering algorithms are enough simple in computational implementation and can be used for solving of wide class of Big Data and Data Stream Mining problems. The effectiveness of proposed approach is confirmed by many experiments based on real data sets. © 2018, Springer International Publishing AG.","Adaptive fuzzy clustering; Matrix neuro-fuzzy self-organizing network; Multivariate short time series; Unevenly distributed observations","Big data; Clustering algorithms; Computation theory; Data mining; Fuzzy clustering; Fuzzy inference; Fuzzy neural networks; Fuzzy sets; Matrix algebra; Pattern matching; Time series; Time series analysis; Computational implementations; Fuzzy C means method; Matrix modification; Neuro-Fuzzy; Neuro-fuzzy network; Self-organizing network; Short time series; Unevenly distributed observations; Fuzzy logic",2-s2.0-85029437434
"Vidhate D.A., Kulkarni P.","Expertise based cooperative reinforcement learning methods (ECRLM) for dynamic decision making in retail shop application",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028412719&doi=10.1007%2f978-3-319-63645-0_39&partnerID=40&md5=8b68c252e0d2df7760e85f310c1ec09c","A novel approach for dynamic decision making in retail application by expertise based cooperative reinforcement learning methods (ECRLM) is proposed in this paper. Different cooperation schemes for cooperative reinforcement learning i.e. EGroup scheme, EDynamic scheme, EGoal-oriented scheme proposed here. Implementation outcome includes demonstration of recommended cooperation schemes that are competent enough to speed up the collection of agents that achieves excellent action policies. This approach is developed for a three retailer shops in the retail market. Retailers be able to help with each other and can obtain profit from cooperation knowledge through learning their own strategies that exactly stand for their aims and benefit. The retailers are the knowledge agents in the hypothesis and employ reinforcement learning to learn cooperatively in situation. Assuming significant hypothesis on the dealer’s stock policy, refill period, and arrival process of the consumers, the approach is modeled as Markov decision process model thus making it possible to apply learning algorithms. © Springer International Publishing AG 2018.","Cooperation schemes; Multi-agent learning; Reinforcement learning","Behavioral research; Costs; Decision making; Intelligent systems; Learning algorithms; Learning systems; Markov processes; Multi agent systems; Sales; Action policies; Collection of agents; Cooperation schemes; Cooperative reinforcement learning; Dynamic decision making; Knowledge agents; Markov decision process models; Multi-agent learning; Reinforcement learning",2-s2.0-85028412719
"Ko K.-E., Sim K.-B.","Deep convolutional framework for abnormal behavior detection in a smart surveillance system",2018,"Engineering Applications of Artificial Intelligence",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032504854&doi=10.1016%2fj.engappai.2017.10.001&partnerID=40&md5=156a9a30249e1f4f903251a2feb60dac","The ability to instantly detect risky behavior in video surveillance systems is a critical issue in a smart surveillance system. In this paper, a unified framework based on a deep convolutional framework is proposed to detect abnormal human behavior from a standard RGB image. The objective of the unified structure is to improve detection speed while maintaining recognition accuracy. The deep convolutional framework consists of (1) a human subject detection and discrimination module that is proposed to solve the problem of separating object entities, in contrast to previous object detection algorithms, (2) a posture classification module to extract spatial features of abnormal behavior, and (3) an abnormal behavior detection module based on long short-term memory (LSTM). Experiments on a benchmark dataset evaluate the potential of the proposed method in the context of smart surveillance. The results indicate that the proposed method provides satisfactory performance in detecting abnormal behavior in a real-world scenario. © 2017 Elsevier Ltd","Behavior recognition; Convolutional neural network; Long short-term memory; Smart surveillance system","Behavioral research; Brain; Convolution; Long short-term memory; Monitoring; Network function virtualization; Neural networks; Object detection; Abnormal behavior detections; Behavior recognition; Convolutional neural network; Detection and discriminations; Object detection algorithms; Posture classification; Smart surveillance systems; Video surveillance systems; Security systems",2-s2.0-85032504854
"Kamanksha D.P., Sanjay A.","A critical analysis of twitter data for movie reviews through ‘random forest’ approach",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028391349&doi=10.1007%2f978-3-319-63645-0_52&partnerID=40&md5=f6a23e307d84998c9fade0e754715dcd","Using Sentiment analysis one can understand interaction of a user with the movies through their feedback. Here analysis is done based on the movie reviews that can be collected from many sources. Twitter is one among the foremost frequent on-line social media and micro blogging services. Due to the popularity of twitter it has become a useful resource for collecting sentiments through API or other data mining techniques. Our work here presents an examination on the evaluation of the machine learning algorithms (Random Forest, bagging, SVM and Naïve Bayes) in R together the public opinion for example opinion about ‘Civil War’ Movie. Here we have used ‘Random Forest’ to show its better performance in the analysis of movie reviews. © Springer International Publishing AG 2018.","Natural language processing; Opinion mining; Sentiment analysis; Sentiment classification; Twitter","Decision trees; Intelligent systems; Learning algorithms; Learning systems; Motion pictures; Natural language processing systems; Social aspects; Social networking (online); Critical analysis; Micro-blogging services; Opinion mining; Public opinions; Random forests; Sentiment analysis; Sentiment classification; Twitter; Data mining",2-s2.0-85028391349
"Beirow B., Figaschewsky F., Kühhorn A., Bornhorn A.","Modal Analyses of an Axial Turbine Blisk With Intentional Mistuning",2018,"Journal of Engineering for Gas Turbines and Power",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029795984&doi=10.1115%2f1.4037588&partnerID=40&md5=98c211ca4fff22075476bd166055c668","The potential of intentional mistuning to reduce the maximum forced response is analyzed within the development of an axial turbine blisk for ship diesel engine turbocharger applications. The basic idea of the approach is to provide an increased aerodynamic damping level for particular engine order (EO) excitations and mode shapes without any significant distortions of the aerodynamic performance. The mistuning pattern intended to yield a mitigation of the forced response is derived from an optimization study applying genetic algorithms. Two blisk prototypes have been manufactured a first one with and another one without employing intentional mistuning. Hence, the differences regarding the real mistuning and other modal properties can be experimentally determined and evaluated as well. In addition, the experimental data basis allows for updating structural models which are well suited to compute the forced response under operational conditions. In this way, the real benefit achieved with the application of intentional mistuning is demonstrated. Copyright © 2018 by ASME.",,"Aerodynamics; Axial flow turbomachinery; Diesel engines; Engines; Genetic algorithms; Modal analysis; Aero-dynamic performance; Aerodynamic damping; Forced response; Intentional mistuning; Modal properties; Operational conditions; Optimization studies; Structural models; Turbines",2-s2.0-85029795984
"Ding T., Wang B., Zheng L., Xi J., Wang S., Xu S.","Research on parking choice model based on shared private parking space",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026776491&doi=10.1007%2f978-981-10-3551-7_75&partnerID=40&md5=82b30ba995f8e03f6a306e23ea93e486","As the number of vehicles increases, the problem of parking has become more and more highlighted. This paper proposes the practice of sharing private parking space when not in use, to meet the ever-increasing parking demand through maximizing utilization of private parking lots. Optimal route and optimal parking location are two main focuses in this study on private parking sharing selection. Optimal route is a decision-making process based on the shortest travel time, using improved ant colony optimization algorithms to determine the route and travel time from travel origin to a shared private parking space, and to prepare for the quantification of the evaluation index for travel time in the shared parking space choice model, which first determines the quantified evaluation indexes according to the factors of interest when a person chooses a private parking space. Optimal parking location is determined by factoring in all the evaluation indexes and using the weighted TOPSIS model. © Springer Science+Business Media Singapore 2018.","Ant colony optimization algorithms; Parking choice; Route guidance; Shared parking; TOPSIS","Ant colony optimization; Artificial intelligence; Decision making; Intelligent systems; Intelligent vehicle highway systems; Optimization; Transportation; Transportation routes; Travel time; Ant Colony Optimization algorithms; Decision making process; Improved ant colony optimization; Number of vehicles; Quantified evaluations; Route guidance; Shortest travel time; TOPSIS; Parking",2-s2.0-85026776491
"Milkova E., Salem A.-B.M.","Advantages of intelligent multimedia application",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026768150&doi=10.1007%2f978-3-319-53934-8_35&partnerID=40&md5=01963eb0c8bc15337fd74ce4ab194ddf","The aim of subjects dealing with graph theory and combinatorial optimization is above all to develop and deepen students’ capacity for logical and algorithmic thinking. It should also support the ability to form images in mind. Students should be able to describe various situations with the aid of graphs, solve the given problem expressed by the graph, and translate the solution back into the initial situation. As a lot of our students are visual learners it is useful to complete teaching and learning using various multimedia applications. One of the programs enabling visual representation of basic graph-concepts and graph-algorithms is introduced in the paper, as well as relevant educational principles, which have been applied in the course of many years. The paper can serve to the teachers and instructors as an inspirational material when dealing with graph theory and combinatorial optimization. © Springer International Publishing AG 2018.",,"Combinatorial optimization; Education; Students; Teaching; Algorithmic thinking; Educational principles; Graph algorithms; Initial situation; Intelligent multimedia; Multimedia applications; Teaching and learning; Visual representations; Graph theory",2-s2.0-85026768150
"Kowaluk T., Woźniak A.","Influence of measurement parameters settings on the results of the CT measurement",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029223156&doi=10.1007%2f978-3-319-65960-2_75&partnerID=40&md5=e4c86340b4f71592c6e33a065b0fef6a","Nowadays X-ray computed tomography for industrial applications is most frequently used for defectoscopy analysis or nondestructive testing. However, it is increasingly used for geometric measurements. The accuracy of geometric measurements is influenced by many factors such as: measurement parameters (X-ray tube and detector settings), environmental conditions, reconstruction algorithms, element alignment, threshold value etc. The article presents the influence of setting parameters of the X-ray tube (voltage and current) and detector (integration time and gain) on the results of geometric measurements. Studies were performed using Carl Zeiss computer tomograph METROTOM 800. Ceramic balls (Si3N4) of G5 accuracy class were selected as the reference master artifacts. © 2018, Springer International Publishing AG.","Measurement; Measurement parameters; X-ray tomography","Computerized tomography; Geometry; Measurements; Nondestructive examination; Tomography; X ray tubes; Computer tomographs; Environmental conditions; Geometric measurements; Measurement parameters; Reconstruction algorithms; Setting parameters; X-ray computed tomography; X-ray tomography; Parameter estimation",2-s2.0-85029223156
"Shabelnikov A.N., Lyabakh N.N.","Intellectualization of sorting processes control on the basis of instrumental determination of analogies",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031310363&doi=10.1007%2f978-3-319-68324-9_15&partnerID=40&md5=c19f59809997e8b0fbf368400a51c41b","An analogy represents a component of human and/or machine intellectual activity. The task of mathematical definition of the analogies has been formed and solved which allowed a transition from a traditional logical and linguistic handling of analogies to the instrumental utilization thereof, thus ensuring a possibility to apply a well-developed mathematical instrumentarium for analysis and control of the complex technical and technological and socio-economical systems. The task of sorting processes control on the basis of analogies has been actualized. The main notions related to analogies have been commented on the example of the mentioned technical and technological task. In this work, two algorithms of sorting processes control using expert information and iterative teaching of decision-making to a machine have been offered. © 2018, Springer International Publishing AG.","Analogy-based control algorithms; Analogy: verbal and instrumental determination; Gravity hump; Retarding mechanism","Decision making; Iterative methods; Analogy: verbal and instrumental determination; Analysis and controls; Economical systems; Expert informations; Intellectual activities; Mathematical definitions; Retarding mechanism; Sorting process; Process control",2-s2.0-85031310363
"Yahyaoui H., Own H.S.","Unsupervised clustering of service performance behaviors",2018,"Information Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029812169&doi=10.1016%2fj.ins.2017.08.065&partnerID=40&md5=ab05203855d268495cc49092567a8766","We propose in this paper a novel approach for unsupervised clustering of services’ behaviors. These behaviors are modeled as multivariate time series that capture the evaluation of several service quality attributes for a period of time. The importance weights of quality attributes are derived based on the Shannon's entropy concept and the service data is flattened in a format that is convenient for clustering. The flattening process spans over a time oriented aggregation transformation, which leverages Haar reduction. The reduction is modeled as a maximization of an objective function. The absence of ground truth is tackled by performing a set of tests to determine the best number of clusters and clustering algorithms. Extensive experiments were conducted to validate the proposed unsupervised clustering approach. © 2017 Elsevier Inc.","Behaviors; Performance; Services; Time series; Unsupervised clustering","Reduction; Time series; Behaviors; Multivariate time series; Objective functions; Oriented aggregation; Performance; Service performance; Services; Unsupervised clustering; Clustering algorithms",2-s2.0-85029812169
"Kosjek T., Negreira N., Heath E., López de Alda M., Barceló D.","Aerobic activated sludge transformation of vincristine and identification of the transformation products",2018,"Science of the Total Environment",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027566800&doi=10.1016%2fj.scitotenv.2017.08.061&partnerID=40&md5=934109a87129fa8af0e075528e261428","This study aims to identify (bio)transformation products of vincristine, a plant alkaloid chemotherapy drug. A batch biotransformation experiment was set-up using activated sludge at two concentration levels with and without the addition of a carbon source. Sample analysis was performed on an ultra-high performance liquid chromatograph coupled to a high-resolution hybrid quadrupole-Orbitrap tandem mass spectrometer. To identify molecular ions of vincristine transformation products and to propose molecular and chemical structures, we performed data-dependent acquisition experiments combining full-scan mass spectrometry data with product ion spectra. In addition, the use of non-commercial detection and prediction algorithms such as MZmine 2 and EAWAG-BBD Pathway Prediction System, was proven to be proficient for screening for transformation products in complex wastewater matrix total ion chromatograms. In this study eleven vincristine transformation products were detected, nine of which were tentatively identified. © 2017 Elsevier B.V.","Biodegradation; Mass spectrometry; Transformation; Transformation product; Vincristine; Wastewater","Biodegradation; Carbon; Chemotherapy; Chromatographic analysis; Drug products; Ions; Linear transformations; Mass spectrometry; Spectrometry; Wastewater; Commercial detections; Concentration levels; Full-scan mass spectrometry; Prediction algorithms; Transformation; Transformation products; Ultra high performance; Vincristine; Metadata",2-s2.0-85027566800
"Abdelwahab S., Gaber T., Wahed M.","Trust and bio-inspired-based clustering techniques in wireless sensor networks: A survey",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029530914&doi=10.1007%2f978-3-319-64861-3_67&partnerID=40&md5=3a752b05f4927fe902d0c2c06b63785c","Energy efficiency and network lifetime are critical parameters in Wireless Sensor Networks (WSNs). Clustering is one of the most popular solutions help in improving these parameters. Many of the current clustering models depend on biologically inspired optimization algorithms as they have proven their abilities to give efficient results. Due to the importance of security in WSNs, many of recent proposed clustering solutions consider it as an essential parameter in cluster head election process. In this paper, we analyze the current trusted-based and bio-inspired clustering techniques in WSNs. The presented models are classified into three classes: bio-inspired, trusted-based and trusted-bio-inspired-based models. We give a brief description for the presented models, show their pros and cons and compare between them based on CH selection scheme, heterogeneity, energy efficiency, dynamic clustering, clusters count, security support and the used bio-inspired algorithm. Finally, the paper presents the open issues in trust-based clustering which are identified from the survey. © 2018, Springer International Publishing AG.","Bio-inspired optimization algorithms; Clustering; Energy efficiency; Network lifetime; Security; Trust; Wireless sensor networks",,2-s2.0-85029530914
"Pop F., Iosup A., Prodan R.","HPS-HDS: High Performance Scheduling for Heterogeneous Distributed Systems",2018,"Future Generation Computer Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029745754&doi=10.1016%2fj.future.2017.09.012&partnerID=40&md5=1f4f7c7c80d233d5cade30eb2c019507","Heterogeneous Distributed Systems (HDS) are often characterized by a variety of resources that may or may not be coupled with specific platforms or environments. Such type of systems are Cluster Computing, Grid Computing, Peer-to-Peer Computing, Cloud Computing and Ubiquitous Computing all involving elements of heterogeneity, having a large variety of tools and software to manage them. As computing and data storage needs grow exponentially in HDS, increasing the size of data centers brings important diseconomies of scale. In this context, major solutions for scalability, mobility, reliability, fault tolerance and security are required to achieve high performance. More, HDS are highly dynamic in its structure, because the user requests must be respected as an agreement rule (SLA) and ensure QoS, so new algorithm for events and tasks scheduling and new methods for resource management should be designed to increase the performance of such systems. In this special issues, the accepted papers address the advance on scheduling algorithms, energy-aware models, self-organizing resource management, data-aware service allocation, Big Data management and processing, performance analysis and optimization. © 2017","Big data; Fault tolerance; Heterogeneous distributed systems; Resource management; Scheduling algorithms",,2-s2.0-85029745754
"Kumar V., Pujari A.K., Padmanabhan V., Sahu S.K., Kagita V.R.","Multi-label classification using hierarchical embedding",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029144279&doi=10.1016%2fj.eswa.2017.09.020&partnerID=40&md5=1c9b9d7f0cdc3e133f9054e6d0dafcef","Multi-label learning is concerned with the classification of data with multiple class labels. This is in contrast to the traditional classification problem where every data instance has a single label. Multi-label classification (MLC) is a major research area in the machine learning community and finds application in several domains such as computer vision, data mining and text classification. Due to the exponential size of the output space, exploiting intrinsic information in feature and label spaces has been the major thrust of research in recent years and use of parametrization and embedding have been the prime focus in MLC. Most of the existing methods learn a single linear parametrization using the entire training set and hence, fail to capture nonlinear intrinsic information in feature and label spaces. To overcome this, we propose a piecewise-linear embedding which uses maximum margin matrix factorization to model linear parametrization. We hypothesize that feature vectors which conform to similar embedding are similar in some sense. Combining the above concepts, we propose a novel hierarchical matrix factorization method for multi-label classification. Practical multi-label classification problems such as image annotation, text categorization and sentiment analysis can be directly solved by the proposed method. We compare our method with six well-known algorithms on twelve benchmark datasets. Our experimental analysis manifests the superiority of our proposed method over state-of-art algorithm for multi-label learning. © 2017 Elsevier Ltd","Label correlation; Matrix factorization; Multi-label learning","Data mining; Factorization; Learning algorithms; Learning systems; Matrix algebra; Piecewise linear techniques; Text processing; Classification of data; Hierarchical matrix factorizations; Label correlations; Linear parametrization; Machine learning communities; Matrix factorizations; Multi label classification; Multi-label learning; Classification (of information)",2-s2.0-85029144279
"Arunkumar B., Kousalya G.","Analysis of AES-GCM cipher suites in TLS",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032655011&doi=10.1007%2f978-3-319-68385-0_9&partnerID=40&md5=83f635188632bf2b03b429e6ba458f82","Encryption and decryption are the two most important complex methods for achieving security in any type of smart devices and systems/machines through transport layer security protocol (TLS). The symmetric key algorithms are the significant method for encrypting and decrypting the data/information using block cipher or stream cipher which is used for TLS protocol. The primary symmetric key block cipher algorithm used in TLS is Advanced Encryption standard (AES) and it provides security based on the key bits used in AES operation. The TLS protocol provides confidentiality(C), integrity (I) and Authenticity (A) in a single pass communication that is Authentication Encryption and Authentication Data (AEAD) between web browser and web server. It uses well known TLS cipher suite AES-GCM (Galois Counter mode) which is commonly used in TLS1.2. Suppose AES-NI hardware acceleration is not available in smart devices like tablets it causes performance issues in smart devices using TLS 1.2 protocol. If the smart device does not possess AES-NI, it can use software for running AES-GCM but it takes a lot of time for encryption/decryption of information, ergo causing the battery performance in smart devices. The newer symmetric Stream cipher CHACHA20-POLY1305 provides AEAD for securing the communication in smart devices thus reducing the battery cycles which is used for TLS 1.3. The paper discusses the pros and cons of AES-GCM authentication encryption used in TLS 1.2. © Springer International Publishing AG 2018.","AEAD; AES-GCM; TLS 1.2","Authentication; Data privacy; Electric batteries; Intelligent systems; Public key cryptography; Security of data; Seebeck effect; Standards; Advanced Encryption Standard; AEAD; AES-GCM; Authentication encryption; Encryption and decryption; Encryption/decryption; Symmetric key algorithms; Transport layer security protocols; Cryptography",2-s2.0-85032655011
"Ferreira R., Cavalcanti G.D.C., Freitas F., Lins R.D., Simske S.J., Riss M.","Combining sentence similarities measures to identify paraphrases",2018,"Computer Speech and Language",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025124168&doi=10.1016%2fj.csl.2017.07.002&partnerID=40&md5=4bef24cc43644845eb40dd87def061ab","Paraphrase identification consists in the process of verifying if two sentences are semantically equivalent or not. It is applied in many natural language tasks, such as text summarization, information retrieval, text categorization, and machine translation. In general, methods for assessing paraphrase identification perform three steps. First, they represent sentences as vectors using bag of words or syntactic information of the words present the sentence. Next, this representation is used to measure different similarities between two sentences. In the third step, these similarities are given as input to a machine learning algorithm that classifies these two sentences as paraphrase or not. However, two important problems in the area of paraphrase identification are not handled: (i) the meaning problem: two sentences sharing the same meaning, composed of different words; and (ii) the word order problem: the order of the words in the sentences may change the meaning of the text. This paper proposes a paraphrase identification system that represents each pair of sentence as a combination of different similarity measures. These measures extract lexical, syntactic and semantic components of the sentences encompassed in a graph. The proposed method was benchmarked using the Microsoft Paraphrase Corpus, which is the publicly available standard dataset for the task. Different machine learning algorithms were applied to classify a sentence pair as paraphrase or not. The results show that the proposed method outperforms state-of-the-art systems. © 2018 Elsevier Ltd","Graph-based model; Paraphrase identification; Sentence similarity; Sentence simplification","Artificial intelligence; Education; Learning systems; Natural language processing systems; Semantics; Syntactics; Text processing; Graph-based modeling; Machine translations; Paraphrase identifications; Semantic components; Sentence similarity; Sentence simplification; State-of-the-art system; Syntactic information; Learning algorithms",2-s2.0-85025124168
"Cornuéjols A., Wemmert C., Gançarski P., Bennani Y.","Collaborative clustering: Why, when, what and how",2018,"Information Fusion",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018638429&doi=10.1016%2fj.inffus.2017.04.008&partnerID=40&md5=6e0a838c6626677029a9327649ba796a","Clustering is one type of unsupervised learning where the goal is to partition the set of objects into groups called clusters. Faced to the difficulty to design a general purpose clustering algorithm and to choose a good, let alone perfect, set of criteria for clustering a data set, one solution is to resort to a variety of clustering procedures based on different techniques, parameters and/or initializations, in order to construct one (or several) final clustering(s). The hope is that by combining several clustering solutions, each one with its own bias and imperfections, one will get a better overall solution. In the cooperative clustering model, as Ensemble Clustering, a set of clustering algorithms are used in parallel on a given data set: the local results are combined to get a hopefully better overall clustering. In the collaborative framework, the goal is that each local computation, quite possibly applied to distinct data sets, benefit from the work done by the other collaborators. This paper is dedicated to collaborative clustering. In particular, after a brief overview of clustering and the major issues linked to, it presents main challenges related to organize and control the collaborative process. © 2017 Elsevier B.V.","Clustering combining; Collaborative clustering; Cooperative clustering","Cluster analysis; Clustering combining; Clustering procedure; Clustering solutions; Collaborative clustering; Collaborative framework; Collaborative process; Cooperative Clustering; Ensemble clustering; Clustering algorithms",2-s2.0-85018638429
"Chen J., Zhu L., Chen T.Y., Towey D., Kuo F.-C., Huang R., Guo Y.","Test case prioritization for object-oriented software: An adaptive random sequence approach based on clustering",2018,"Journal of Systems and Software",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032007990&doi=10.1016%2fj.jss.2017.09.031&partnerID=40&md5=b657182eefc5bdd268044b5beca3b75f","Test case prioritization (TCP) attempts to improve fault detection effectiveness by scheduling the important test cases to be executed earlier, where the importance is determined by some criteria or strategies. Adaptive random sequences (ARSs) can be used to improve the effectiveness of TCP based on white-box information (such as code coverage information) or black-box information (such as test input information). To improve the testing effectiveness for object-oriented software in regression testing, in this paper, we present an ARS approach based on clustering techniques using black-box information. We use two clustering methods: (1) clustering test cases according to the number of objects and methods, using the K-means and K-medoids clustering algorithms; and (2) clustered based on an object and method invocation sequence similarity metric using the K-medoids clustering algorithm. Our approach can construct ARSs that attempt to make their neighboring test cases as diverse as possible. Experimental studies were also conducted to verify the proposed approach, with the results showing both enhanced probability of earlier fault detection, and higher effectiveness than random prioritization and method coverage TCP technique. © 2017 Elsevier Inc.","Adaptive random sequence; Cluster analysis; Object-oriented software; Test cases prioritization; Test cases selection","Black-box testing; Cluster analysis; Fault detection; Object oriented programming; Software testing; Testing; Transmission control protocol; Clustering techniques; Fault detection effectiveness; Object oriented software; Prioritization; Random sequence; Test case; Test case prioritization; Testing effectiveness; Clustering algorithms",2-s2.0-85032007990
"Jain R., Trivedi M.C., Tiwari S.","Impact analysis of contributing parameters in audio watermarking using DWT and SVD",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031405234&doi=10.1007%2f978-981-10-3773-3_41&partnerID=40&md5=0359923ef3355b6f99fb2edfd477b117","This paper proposes a non-blind audio watermarking algorithm for copyright protection of audio files which has proved to satisfy the minimum requirements of optimal audio watermarking standards set by International Federation of Photographic Industry (IFPI). The algorithm is set to meet the IFPI requirements as it includes the two powerful mathematical tools: Discrete wavelet transform (DWT) and singular value decomposition (SVD). In this paper, we have also analyzed the contribution of parameters like watermark size and the embedding intensity factor on the algorithm. © Springer Nature Singapore Pte Ltd. 2018.","DWT decomposition; Embedding intensity factor; Imperceptibility; SVD transformation","Copyrights; Digital watermarking; Discrete wavelet transforms; Mathematical transformations; Signal reconstruction; Singular value decomposition; Wavelet decomposition; Wavelet transforms; Copyright protections; Imperceptibility; Intensity factors; International federation; Mathematical tools; Minimum requirements; Photographic industry; Watermarking algorithms; Audio watermarking",2-s2.0-85031405234
"Drake B., Huang T., Beavers A., Du R., Park H.","Event detection based on nonnegative matrix factorization: Ceasefire violation, environmental, and malware events",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021658769&doi=10.1007%2f978-3-319-60585-2_16&partnerID=40&md5=20b065693c3200ff64e3f1205ae5f728","Event detection is a very important problem across many domains and is a broadly applicable encompassing many disciplines within engineering systems. In this paper, we focus on improving the user’s ability to quickly identify threat events such as malware, military policy violations, and natural environmental disasters. The information to perform these detections is extracted from text data sets in the latter two cases. Malware threats are important as they compromise computer system integrity and potentially allow the collection of sensitive information. Military policy violations such as ceasefire policies are important to monitor as they disrupt the daily lives of many people within countries that are torn apart by social violence or civil war. The threat of environmental disasters takes many forms and is an ever-present danger worldwide, and indiscriminate regarding who is harmed or killed. In this paper, we address all three of these threat event types using the same underlying technology for mining the information that leads to detecting such events. We approach malware event detection as a binary classification problem, i.e., one class for the threat mode and another for non-threat mode. We extend our novel classifier utilizing constrained low rank approximation as the core algorithm innovation and apply our Nonnegative Generalized Moody-Darken Architecture (NGMDA) hybrid method using various combinations of input and output layer algorithms. The new algorithm uses a nonconvex optimization problem via the nonnegative matrix factorization (NMF) for the hidden layer of a single layer perceptron and a nonnegative constrained adaptive filter for the output layer estimator. We first show the utility of the core NMF technology for both ceasefire violation and environmental disaster event detection. Next NGMDA is applied to the problem of malware threat events, again based on the NMF as the core computational tool. Also, we demonstrate that an algorithm should be appropriately selected for the data generation process. All this has critical implications for design of solutions for important threat/event detection scenarios. Lastly, we present experimental results on foreign language text for ceasefire violation and environmental disaster events. Experimental results on a KDD competition data set for malware classification are presented using our new NGMDA classifier. © Springer International Publishing AG 2018.","Adaptive filtering; Classification; Clustering; Event detection; Hybrid classifier; Malware detection; Nonnegative matrix factorization; Perceptron; Topic modeling","Adaptive filtering; Adaptive filters; Approximation algorithms; Classification (of information); Computer crime; Constrained optimization; Data mining; Disasters; Environmental technology; Factorization; Filtration; Human engineering; Malware; Neural networks; Optimization; Clustering; Event detection; Hybrid classifier; Malware detection; Nonnegative matrix factorization; Topic Modeling; Matrix algebra",2-s2.0-85021658769
"Goto T., Sano Y., Mori T., Shimizu M., Funahashi K.","Improving measurement accuracy for rheumatoid arthritis medical examinations",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019702523&doi=10.1007%2f978-3-319-59397-5_17&partnerID=40&md5=7c6b60566e8165a5f133890e8a33735e","Super-resolution techniques have been widely used in fields such as television, aerospace imaging, and medical imaging. In medical imaging, X-rays commonly have low resolution and a significant amount of noise, because radiation levels are minimized to maintain patient safety. So, we proposed a novel super-resolution method for X-ray images, and a novel measurement algorithm for treatment of rheumatoid arthritis (RA) using X-ray images generated by our proposed super-resolution method. In this paper, we improve measurement accuracy for our proposed method. Moreover, to validate it for our proposed algorithm, we make a model for measurement algorithm about joint space distance using a 3D printer, and X-ray images are obtained to photograph it. Experimental results show that high quality super-resolution images are obtained, and the measurement distances are measured with high accuracy. Therefore, our proposed measurement algorithm is effective for RA medical examinations. © Springer International Publishing AG 2018.","Joint space distance; Medical examinations; Rheumatoid Arthritis; Super-resolution","3D printers; Diagnosis; Diseases; Health care; Optical resolving power; Three dimensional computer graphics; X ray analysis; Joint space distance; Measurement accuracy; Measurement algorithms; Medical examinations; Radiation levels; Rheumatoid arthritis; Super resolution; Superresolution methods; Medical imaging",2-s2.0-85019702523
"Caraveo C., Valdez F., Castillo O.","A new metaheuristic based on the self-defense mechanisms of the plants with a fuzzy approach applied to the CEC2015 functions",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030705504&doi=10.1007%2f978-3-319-67137-6_12&partnerID=40&md5=e5b1f44b8fa36d618677649baf4d3783","In this paper a new metaheuristic based on coping strategies of plants with a fuzzy approach is presented. In this work the authors propose a variant of the original algorithm of the plants with a fuzzy approach, The new proposal consists of adding fuzzy logic to adapt the parameters of the algorithm dynamically. In this work, a fuzzy controller is responsible of find the optimal values of the variables α, β, δ, λ, in order to help the algorithm to have a greater performance in solving problems, in the previous works the authors apply the original algorithm to optimization problems, and the parameters of the variables are moved manually, however the results obtained are acceptable in some cases, but we consider that they can be improved using the intelligent technique for the adaptation of parameters. © Springer International Publishing AG 2018.","Fuzzy logic; Lotka and Volterra model; Lévy flights; Mechanism; Plants; Self-defense","Computer circuits; Fuzzy logic; Mechanisms; Network security; Parameter estimation; Adaptation of parameters; Fuzzy controllers; Intelligent techniques; Optimization problems; Original algorithms; Plants; Self-defense; Volterra model; Optimization",2-s2.0-85030705504
"Zhou X.-G., Yang X.-P., Wang P.-H.","Quadratic programming with max-product fuzzy relation inequality constraints",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030756891&doi=10.1007%2f978-3-319-66514-6_24&partnerID=40&md5=9044437b7d78bb57f582c6638d20aab7","In this paper, a new method for quadratic programming with max-product fuzzy relation inequality constraints is proposed. First, the properties of the optimal solution are analyzed in several special cases of fuzzy relation quadratic programming. Simultaneously, some rules are presented to simplify the original fuzzy relation quadratic programming problem. Then, an algorithm is presented, based on rules, the branch and bound method and numerical algorithm for solving traditional quadratic programming problems with interval constraints. The proposed algorithm does not need to find all feasible minimal solutions. Hence, the amount of calculation is reduced. Some numerical examples are given to illustrate the feasibility and effectiveness of the proposed algorithm. © Springer International Publishing AG 2018.","Fuzzy relation quadratic programming; Max-product fuzzy relation inequality; Optimal solution; Quadratic programming","Constraint theory; Fuzzy logic; Numerical methods; Optimal systems; Quadratic programming; Fuzzy relations; Inequality constraint; Interval constraint; Max-product; Minimal solutions; Numerical algorithms; Optimal solutions; Quadratic programming problems; Branch and bound method",2-s2.0-85030756891
"Li F., Zhang Y.","Adaptive tracking a linear system with unknown periodic signal in multi-agent systems",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031404010&doi=10.1007%2f978-981-10-6499-9_61&partnerID=40&md5=98373d5711cf5c6bde545485f2ee575b","This paper studies the tracking control problem of multi-agent systems where each agent has homogeneous sensor and heterogeneous dynamic system, the moving target has unknown periodic input signal and the unknown periodic input can be modelled as a finite dimensional Fourier decomposition. Since some agents can not detect the target, a distributed estimation based tracking control algorithm is applied. We first design a consensus based distributed observer to estimate the state and the unknown periodic input of the system from the available measurement outputs. Leader-follower consensus protocol is applied, and the stability condition of the estimation errors is given. Then, based on the estimations, a model reference adaptive control (MRAC) algorithm is adopted to design the tracking controller. It is proved that under the proposed distributed estimation based tracking control algorithm, each agent can asymptotically track the target. A numerical simulation is given to prove the feasibility of the algorithm in this paper. © 2018, Springer Nature Singapore Pte Ltd.","Distributed estimation MRAC; Multi-agent systems; Tracking control","Intelligent agents; Intelligent systems; Linear systems; Model reference adaptive control; Navigation; Software agents; Target tracking; Distributed estimation; Fourier decomposition; Heterogeneous dynamics; Leader-follower consensus; Tracking control algorithms; Tracking control problem; Tracking controller; Tracking controls; Multi agent systems",2-s2.0-85031404010
"Kokot M., Deorowicz S., Długosz M.","Even faster sorting of (not only) integers",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030759671&doi=10.1007%2f978-3-319-67792-7_47&partnerID=40&md5=1bfb0b1fec781081fb20f4771bb28136","In this paper we introduce RADULS2, the fastest parallel sorter based on radix algorithm. It is optimized to process huge amounts of data making use of modern multicore CPUs. The main novelties include: high performance algorithm for handling tiny arrays (up to about a hundred of records) that could appear even billions times as subproblems to handle and improved processing of larger subarrays with better use of non-temporal memory stores. © 2018, Springer International Publishing AG.",,"Computer programming; Computer science; High performance algorithms; Multi-core cpus; Sub-arrays; Sub-problems; Temporal memory; Program processors",2-s2.0-85030759671
"Olson C.C., Judd K.P., Nichols J.M.","Manifold learning techniques for unsupervised anomaly detection",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029517499&doi=10.1016%2fj.eswa.2017.08.005&partnerID=40&md5=2d74107a65e0693a4e9fec483093b47b","Appropriately identifying outlier data is a critical requirement in the decision-making process of many expert and intelligent systems deployed in a variety of fields including finance, medicine, and defense. Classical outlier detection schemes typically rely on the assumption that normal/background data of interest are distributed according to an assumed statistical model and search for data that deviate from that assumption. However, it is frequently the case that performance is reduced because the underlying distribution does not follow the assumed model. Manifold learning techniques offer improved performance by learning better models of the background but can be too computationally expensive due to the need to calculate a distance measure between all data points. Here, we study a general framework that allows manifold learning techniques to be used for unsupervised anomaly detection by reducing computational expense via a uniform random sampling of a small fraction of the data. A background manifold is learned from the sample and then an out-of-sample extension is used to project unsampled data into the learned manifold space and construct an anomaly detection statistic based on the prediction error of the learned manifold. The method works well for unsupervised anomaly detection because, by definition, the ratio of anomalous to non-anomalous data points is small and the sampling will be dominated by background points. However, a variety of parameters that affect detection performance are introduced so we use here a low-dimensional toy problem to investigate their effect on the performance of four learning algorithms (kernel PCA, two versions of diffusion map, and the Parzen density estimator). We then apply the methods to the detection of watercraft in an ensemble of 22 infrared maritime scenes where we find kernel PCA to be superior and show that it outperforms a commonly employed baseline algorithm. The framework is not limited to the tested image processing example and can be used for any unsupervised anomaly detection task. © 2017","Anomaly detection; Image processing; Manifold learning; Manifolds; Target detection","Automobile engine manifolds; Decision making; Image processing; Intelligent systems; Learning systems; Statistics; Target tracking; Anomaly detection; Computational expense; Decision making process; Manifold learning; Out-of-sample extension; Parzen density estimator; Underlying distribution; Unsupervised anomaly detection; Learning algorithms",2-s2.0-85029517499
"Chen F., Shi T., Duan S., Wang L., Wu J.","Diffusion least logarithmic absolute difference algorithm for distributed estimation",2018,"Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028836229&doi=10.1016%2fj.sigpro.2017.07.014&partnerID=40&md5=719fb30468d272345c2149ba3456ccb9","The popular distributed estimation algorithms based on the mean-square error criterion is not robust against impulsive noise in the adaptive networks. To address the problem, the diffusion least logarithmic absolute difference (LLAD) algorithm is proposed in this article, which adopts both the logarithm operation and sign operation to the error. The algorithm can elegantly and gradually adjust the conventional cost functions in its optimization based on the error variation. Compared with centralized LLAD algorithm, the diffusion LLAD algorithm performs a good balance between communications and performance. The theoretical stability of mean and mean-square performance of the algorithm is analyzed. Simulation results indicate that the algorithm achieves a better performance, compared with diffusion LMS and diffusion sign-error LMS algorithms, even in the impulsive noise environment. © 2017 Elsevier B.V.","Distributed estimation; Impulsive interference; Least logarithmic absolute difference","Cost functions; Diffusion; Errors; Impulse noise; Mean square error; Absolute difference; Adaptive networks; Distributed estimation; Impulsive interference; Impulsive noise environment; Logarithm operations; Mean square error criterions; Mean-square performance; Optimization",2-s2.0-85028836229
"Muthukumaran K., Dasgupta A., Abhidnya S., Neti L.B.M.","On the effectiveness of cost sensitive neural networks for software defect prediction",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028598796&doi=10.1007%2f978-3-319-60618-7_55&partnerID=40&md5=7d2b78371d8de6737b1e4f4011576a1d","The cost of fixing a software defect varies with the phase in which it is uncovered. Defect found during post-release phase costs much more than the defect that is uncovered in pre-release phase. Hence defect prediction models have been proposed to predict bugs in pre-release phase. For any prediction model, there are two kinds of misclassification errors - Type I and Type II errors. Type II errors are found to be more costly than Type I errors for defect prediction problem. However there have been only few studies that have considered misclassifications costs while building or evaluating defect predictions models. We have built classification models using three cost-sensitive boosting Neural Network methods, namely, CSBNN-TM, CSBNN-WU1 and CSBNN-WU2. We have compared the performance of these cost sensitive Neural Networks with the traditional machine learning algorithms like Logistic Regression, Naive Bayes, Random Forest, Bayesian Network, Neural Networks, k-Nearest Neighbors and Decision Tree. We have compared the performance of the resultant models using cost centric measure - Normalized Expected Cost of Misclassification (NECM). © Springer International Publishing AG 2018.","Cost-sensitive neural networks; Misclassification cost; Software defect prediction","Bayesian networks; Data mining; Decision trees; Defects; Errors; Forecasting; Learning algorithms; Learning systems; Nearest neighbor search; Pattern recognition; Soft computing; Classification models; Cost-sensitive neural networks; Defect prediction models; Expected cost of misclassification; Misclassification costs; Misclassification error; Software defect prediction; Type I and type II errors; Costs",2-s2.0-85028598796
"Swamy K.V., Radhika V., Kumar S.S.","Image fusion using uniformity in HT domain",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031760531&doi=10.1007%2f978-981-10-5508-9_8&partnerID=40&md5=89537b02272b7695873f984fa3af7cc7","The intent of the digital image fusion is a process to obtain important information from acquired images and then form as a distinct fused image. Image fusion algorithms are popular in transform domain than spatial domain methods. The usual methods in transform domain are block-based and multi-resolution transforms. Commonly used orthogonal transforms for image processing are SVD, DCT, KLT, CT, and DWT, but hardware implementation of these transforms is difficult because of the floating-point arithmetic operations. Hadamard transform (HT) is preferred, where the computational speed is the criterion for real-time implementation. In general, block-based methods suffer from blocking artifacts. It influences the features of the fused image. To reduce these problems, statistical measures like mean, contrast, and variance are applied. In the current proposal, statistical measures like entropy and uniformity are explored in HT domain. Further, all statistical measures in HT domain are compared and analyzed. Application of statistical measures in HT domain gives better image fusion results than conventional HT domain fused techniques. Dominance of the uniformity measure in HT domain is observed based on the experimental results. © Springer Nature Singapore Pte Ltd. 2018.","Entropy; Hadamard transform; Image fusion; Uniformity","Computerized tomography; Digital arithmetic; Entropy; Hadamard transforms; Hardware; Image processing; Real time control; Floating point arithmetic operation; Hardware implementations; Image fusion algorithms; Multi-resolution transforms; Orthogonal transforms; Real-time implementations; Spatial domain methods; Uniformity; Image fusion",2-s2.0-85031760531
"Lee J.H., Kwon S.J., Chung T.-S.","ERF: Efficient cache eviction strategy for e-commerce applications",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022208835&doi=10.1007%2f978-981-10-5281-1_33&partnerID=40&md5=a5bb7cc9d0176a814660acdbdffb3ac6","Most vendors of e-commerce applications deploy the cache memory to deliver the web objects to clients faster. However, they face many problems in dealing with the cache memory due to limited resources and dynamic access patterns. As a result, we need to efficiently manage the cache memory by evicting the unused data. The performance of cache manager depends upon the efficiency of delete determination. In this paper, we propose ERF, a cache eviction policy using natural exponential function on time with frequency in order to cope with dynamic nature of e-commerce business with limited memory. It sorts the caches in the order of result value which come from coordination between frequency and recency and evicts the caches according to it. We evaluate the performance of ERF by using the workload which reflects the real-world applications and compare it with conventional algorithms. By increasing the cache hit ratio with ERF, we can expect the decrease of copy and delete operations of cache with improving the overall system performance. © Springer Science+Business Media Singapore 2018.","Multimedia databases and file systems","Commerce; Electronic commerce; Exponential functions; Wireless telecommunication systems; Cache hit ratio; Conventional algorithms; Dynamic access patterns; Dynamic nature; E-Commerce applications; E-commerce business; File systems; Limited memory; Cache memory",2-s2.0-85022208835
"Chen B.-W., Rho S., Yang L.T., Gu Y.","Privacy-preserved big data analysis based on asymmetric imputation kernels and multiside similarities",2018,"Future Generation Computer Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006981923&doi=10.1016%2fj.future.2016.11.008&partnerID=40&md5=059377a5ae71827a17b0601a6d44126a","This study presents an efficient approach for incomplete data classification, where the entries of samples are missing or masked due to privacy preservation. To deal with these incomplete data, a new kernel function with asymmetric intrinsic mappings is proposed in this study. Such a new kernel uses three-side similarities for kernel matrix formation. The similarity between a testing instance and a training sample relies not only on their distance but also on the relation between the testing sample and the centroid of the class, where the training sample belongs. This reduces biased estimation compared with typical methods when only one training sample is used for kernel matrix formation. Furthermore, centroid generation does not involve any clustering algorithms. The proposed kernel is capable of performing data imputation by using class-dependent averages. This enhances Fisher Discriminant Ratios and data discriminability. Experiments on two open databases were carried out for evaluating the proposed method. The result indicated that the accuracy of the proposed method was higher than that of the baseline. These findings thereby demonstrated the effectiveness of the proposed idea. © 2016 Elsevier B.V.","Cloud computing; Data analytics; Data imputation; Incomplete data analysis; Kernel method; Kernel ridge Regression (KRR); Missing values; Multiside similarity; Partial similarity; Privacy preservation","Cloud computing; Clustering algorithms; Data handling; Data privacy; Information analysis; Matrix algebra; Regression analysis; Sampling; Data analytics; Data imputation; Incomplete data; Kernel methods; Kernel ridge regression (KRR); Missing values; Multiside similarity; Partial similarities; Privacy preservation; Big data",2-s2.0-85006981923
"Jin J., Ma X.","A multi-criteria intelligent control for traffic lights using reinforcement learning",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022210559&doi=10.1007%2f978-3-319-57105-8_22&partnerID=40&md5=8841cd310ad77c4066c92166a46a1f76","Traffic signal control plays a crucial role in traffic management and operation practices. In the past decade, adaptive signal control systems, capable of adjusting control schemes in response to traffic patterns, have shown the abilities to improve traffic mobility. On the other hand, the negative impacts on environments by increased vehicles attract increased attentions from traffic stakeholders and the general public. Most of the prevalent adaptive signal control systems do not address energy and environmental issues. The present paper proposes an adaptive signal control system capable of taking multi-criteria strategies into account. A general multi-agent framework is introduced for modeling signal control operations. The behavior of each cognitive agent is modeled by a Constrained Markov Decision Process (CMDP). Reinforcement learning algorithms are applied to solve the MDP problem. As a result, the signal controller makes intelligent timing decisions according to a pre-defined policy goal. A case study is carried out for the stage-based control scheme to investigate the effectiveness of the adaptive signal control system from two perspectives, traffic mobility and energy efficiency. The control approach can be further applied to a large network in a decentralized manner. © Springer International Publishing AG 2018.","Adaptive traffic light control; Intelligent timing decision; Multi-criteria strategies; Reinforcement Learning","Adaptive control systems; Control systems; Education; Energy efficiency; Intelligent agents; Learning algorithms; Markov processes; Multi agent systems; Reinforcement learning; Street traffic control; Adaptive signal control systems; Adaptive traffic lights; Constrained Markov decision process; Environmental issues; Multi-criteria; Multiagent framework; Timing decisions; Traffic signal control; Traffic signals",2-s2.0-85022210559
"Kruthika K.R., Rajeswari, Pai A., Maheshappa H.D.","Classification of Alzheimer and MCI phenotypes on MRI data using SVM",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030162236&doi=10.1007%2f978-3-319-67934-1_23&partnerID=40&md5=d24ca1d12c3b35b946b412893d3e5b45","Alzheimer disease (AD) is a common form of dementia affecting people older than the age of 65. Moreover, AD is commonly diagnosed by behavioural paradormants, cognitive tests, and is followed by brain scans. Computer Aided Diagnosis (CAD), applies medical imaging and machine learning algorithms, to aid in the early diagnosis of Alzheimer’s severity and advancement from prodromal stages i.e. Mild Cognitive Impairment (MCI) to diagnosed Alzheimer’s disease. In this work, SVM (support vector machine) is used for dementia stage classification. Anatomical structures of the brain were obtained from FreeSurfer’s processing of structural Magnetic Resonance Imaging (MRI) data and is utilized for as features for SVM. To be more precise, the system is processed using T1-weighted brain MRI datasets consisting of: 150 mild cognitive impairment (MCI) patients, 80 AD patients and 130 normal controls (NC) obtained from Alzheimer Disease Neuroimaging Initiative (ADNI) database. The volumes of brain structures (hippocampus, medial temporal lobe, whole brain, ventricular, cortical grey matter, entorhinal cortex and fusiform) are employed as biomarkers for multi-class classification of AD, MCI, and NC. © Springer International Publishing AG 2018.","Alzheimer disease; FreeSurfer; Machine learning; Mild cognitive impairment; Normal control; Structural magnetic resonance imaging; SVM","Artificial intelligence; Brain; Computer aided instruction; Diagnosis; Disease control; Image segmentation; Learning algorithms; Learning systems; Magnetic resonance imaging; Medical imaging; Neurodegenerative diseases; Neuroimaging; Signal processing; Support vector machines; Alzheimer disease; Computer Aided Diagnosis(CAD); FreeSurfer; Mild cognitive impairments; Mild cognitive impairments (MCI); Multi-class classification; Normal controls; SVM(support vector machine); Computer aided diagnosis",2-s2.0-85030162236
"Driouache S., Naja N., Jamali A.","Mixed Method: An Aggregated Method for Handover Decision in Heterogeneous Wireless Networks",2018,"Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032661416&doi=10.1007%2f978-3-319-67837-5_2&partnerID=40&md5=fbf1b2c14945de2e432863b2a921fa2a","The next generation of wireless networks is marked by a variety of access networks. A mobile user desires to run a service seamlessly regardless of his access network. This makes the continuity of service during handover and QoS relevant issues to deal with. In this context, Media Independent Handover (MIH) standard was developed to facilitate the interworking between IEEE and non-IEEE Access technologies. This paper suggests an aggregated method for the best access network selection. This method combines Technique for Order Preference by Similarity to Ideal Solution (TOPSIS) and VIse Kriterijumska Optimizacija kompromisno Resenja (VIKOR) decision algorithms together with Shannon entropy to assign handover criteria weights. Entropy is an adequate tool to weigh up the handover criteria. Compared with TOPSIS and VIKOR, mixed method performs better in terms of handovers number, packet loss rate, end to end delay, and throughput. Simulations are realized within the scope of MIH using NS3 simulator. © 2018, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.","Heterogeneous networks; QoS; Seamless handover","Developing countries; Heterogeneous networks; Mobile telecommunication systems; Quality of service; Access network selections; Continuity of services; Decision algorithms; Heterogeneous wireless network; Media Independent Handover (MIH); Packet loss rates; Seamless Handover; Technique for order preference by similarity to ideal solutions; Wireless networks",2-s2.0-85032661416
"Fadaee S.S., Ghaemi M.S., Soufiani H.A., Sundaram R.","Chiron: A robust recommendation system with graph regularizer",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019230833&doi=10.1007%2f978-3-319-59162-9_38&partnerID=40&md5=ad8ef78e22b01e3846240760a4c36b49","Recommendation systems have been widely used by commercial service providers for giving suggestions to users. Collaborative filtering (CF) systems, one of the most popular recommendation systems, utilize the history of behaviors of the aggregate user-base to provide individual recommendations and are effective when almost all users faithfully express their opinions. However, they are vulnerable to malicious users biasing their inputs in order to change the overall ratings of a specific group of items. CF systems largely fall into two categories -neighborhood-based and (matrix) factorization-based - and the presence of adversarial input can influence recommendations in both categories, leading to instabilities in estimation and prediction. Although the robustness of different collaborative filtering algorithms has been extensively studied, designing an efficient system that is immune to manipulation remains a challenge. We propose a novel hybrid recommendation system with an adaptive graph user/item similarity-regularization - Chiron. Chiron ties the performance benefits of dimensionality reduction (via factorization) with the advantage of neighborhood clustering (through regularization). We demonstrate, using extensive comparative experiments, that Chiron is resistant to manipulation by large and lethal attacks. © Springer International Publishing AG 2018.",,"Collaborative filtering; Factorization; Collaborative filtering algorithms; Collaborative filtering systems; Commercial services; Comparative experiments; Dimensionality reduction; Estimation and predictions; Hybrid recommendation; Performance benefits; Recommender systems",2-s2.0-85019230833
"Cuzzocrea A.","Effectively and Efficiently Supporting Encrypted OLAP Queries over Big Data: Models, Issues, Challenges",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032510201&doi=10.1007%2f978-981-10-6520-0_36&partnerID=40&md5=f765c50ff12095e07694c2217ae0581c","Due to emerging technologies like Clouds, recently the problem of encrypting and querying big data is of great interest trough the community. Here, the main problem consists in devising effective and efficient encryption schemes for big data, and then effective and efficient query algorithms for querying such data in their encrypted form directly. By comparing both lines of research, it emerges that querying encrypted big data plays the major role, as the encryption phase is usually conducted on top of well-recognized state-of-the-art encryption schemes. On the other hand, OLAP data are a knowledge-rich class of big data that are extremely important for latest big data analytics tools. Inspired by these two authoritative research trends, in this paper we provide the following contributions: (i) an overview of most relevant initiatives in the scientific field of querying encrypted OLAP data; (ii) critical discussion on open issues and research challenges that will dominate the future scene of the investigated research topic. © 2018, Springer Nature Singapore Pte Ltd.",,"Cryptography; Critical discussions; Emerging technologies; Encryption schemes; Query algorithms; Research challenges; Research trends; Scientific fields; State of the art; Big data",2-s2.0-85032510201
"Benzerga S., Hauf D., Pretz M., Bounfour A.","When energy revolution meets digital transformation",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020401573&doi=10.1007%2f978-3-319-59424-8_7&partnerID=40&md5=c411020ed2575d4f629dfc35f4b19ace","Digital transformation can be observed in business as well as in broader society, but we are far from having identified and defined all the issues and implications of this ongoing transformation and how it impacts on a traditional company. In an attempt to better understand this phenomenon and the changing role of IT that it brings with it, this article presents the field of energy efficiency as an example of the strategic implementation in the context of digital transformation. In the first section, the Digital Economy trend will be presented in order to better understand to what extent this trend could be a key to the future of traditional industries on the macro level. The paper goes into more detail in the second section with the definition of digital transformation. Its dimensions will be addressed in order to better understand the inherent strategic impacts. Coming to the micro level of the plant in a manufacturing company then, the specific case of energy efficiency will be analyzed, which is supported by a patented process innovation based on digital technologies such as self-learning algorithms and hence on an increasing role of IT in the production area. Finally, in order to encourage researchers and practitioners to advance in the field, future areas of interest are identified and further application fields are proposed as a conclusion to this article. © Springer International Publishing AG 2018.","Digital economy; Digital transformation; Energy efficiency; Industrie 4.0; IT function; Smart factory","Engineering education; Industrial economics; Digital economy; Digital technologies; Digital transformation; Industrie 4.0; It functions; Manufacturing companies; Self learning algorithms; Traditional industry; Energy efficiency",2-s2.0-85020401573
"Deng Z., Kitamura T., Matsushiro N., Nishimura H., Zhu Z., Xu M., Xiong K., Chen Y.-W.","Semi-automatic segmentation of paranasal sinuses from CT images using active contour with group similarity constraints",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019700113&doi=10.1007%2f978-3-319-59397-5_10&partnerID=40&md5=f4ca36c729326cb310fb04a07e7dc95f","Computerized tomographic (CT) scanning has dramatically improved the imaging of paranasal sinus anatomy as compared to sinus radiographs. Increasingly, subtle bony anatomic variations and mucosal abnormalities of this region are being detected. The morphological knowledge of nasal cavity and paranasal sinuses has an important clinical value. It is used for the detection of sinus pathologies, for determination of therapy, planning of endoscopic surgeries and for surgical simulations. Current research and industry assisting systems need a workspace definition of the paranasal sinuses, which is realized by segmentation. This paper presents a semi-automatic segmentation method for the paranasal sinuses which allows us to locate structures. In general, the traditional active contour methods like Snake, Levelset can resolve the CT images of paranasal sinuses normal without any anatomic variations caused by sinusitis. However, in the clinical practice, the diseased radiological image has more significances so that these classical methods can not work satisfied very well as the boundaries of sinuses has been covered by impurity inflammation produced. At this point, we proposed a novel method group similarity based on Low Rank to repair the lost part of the boundary. The experiment results proved that our proposed method outperformed conventional algorithms especially in abnormal images. © Springer International Publishing AG 2018.",,"Endoscopy; Health care; Image segmentation; Industrial research; Medicine; Pathology; Surgery; Active contour method; Classical methods; Clinical practices; Conventional algorithms; Endoscopic surgery; Radiological images; Semi-automatic segmentation; Surgical simulation; Computerized tomography",2-s2.0-85019700113
"Mehrotra L., Saxena P.S.","An assessment report on: Statistics-based and signature-based intrusion detection techniques",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031727857&doi=10.1007%2f978-981-10-5508-9_31&partnerID=40&md5=a59a5a20e941147ca6dcd8f531792651","With the growing size of data, its security has become a great challenge, and security of data is a major issue in most of the research areas. A detailed study of existing IDS is presented in the current paper so as to detect threats or intrusions on the data residing on system/network. It is a bit difficult to stop security threats and breaches entirely using present security technologies. Detecting the presence of intruder is very crucial for maintaining the network security. It is found that intrusion detection systems (IDSs) that are signature-based are restricted in their areas of detecting intrusions, because of the fact that the signature-based intrusion detection system is based on matching a signature with the network details. The system using signatures or patterns can detect only known attacks and threats, but they mostly fail when it comes to novel attacks.﻿ Thus preventing/detecting the new or special types of attracts whose signature is not specified. Although signature-based IDS does not give false alarms at genuine cases, but still is inept for unknown attacks or masked attacks. Later in the paper, another category of IDS is discussed which is statistical-based intrusion detection system (SBIDS). The statistical-based intrusion detection systems have an upper hand when it is compared with the signature-based intrusion detection system. During the study, it has been found that many researchers have solved this problem by data mining classification algorithms. © Springer Nature Singapore Pte Ltd. 2018.","Data mining; HIDS; IDS; NIDS; SBIDS","Computer crime; Data mining; Intrusion detection; Mercury (metal); Security of data; Security systems; Data mining classification algorithms; HIDS; Intrusion Detection Systems; NIDS; SBIDS; Security technology; Security threats; Unknown attacks; Network security",2-s2.0-85031727857
"Zhang T., Ke L., Li J., Li J., Huang J., Li Z.","Metaheuristics for the tabu clustered traveling salesman problem",2018,"Computers and Operations Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026413102&doi=10.1016%2fj.cor.2017.07.008&partnerID=40&md5=6fed8cf2d86831383597c604d3dd1a4b","This paper considers a new variant of traveling salesman problem (TSP), called tabu clustered TSP (TCTSP). The nodes in TCTSP are partitioned into two kinds of subsets: clusters and tabu node sets, then the salesman has to visit exactly one node for each tabu node set and ensures that the nodes within a same cluster are visited consecutively, and the problem calls for a minimum cost cycle. The TCTSP can be used to model a class of telemetry tracking and command (TT&C) resources scheduling problem (TTCRSP), the goal of which is to efficiently schedule the TT&C resources in order to enable the satellites to be operated normally in their designed orbits. To solve it, two metaheuristics combined with path relinking are proposed. The one is Ant Colony Optimization (ACO) and the other is Greedy Randomized Adaptive Search Procedure (GRASP). The proposed algorithms are tested on the benchmark instances and real-life instances of the TTCRSP. The computational results show that the hybrid ACO with two path relinking strategies works the best among the studied metaheuristics in terms of solution quality within the same computational time. © 2017 Elsevier Ltd","Ant Colony Optimization; Greedy Randomized Adaptive Search Procedure; Metaheuristics; Tabu clustered traveling salesman problem; TT&C resources scheduling problem","Ant colony optimization; Artificial intelligence; Benchmarking; C (programming language); Heuristic algorithms; Optimization; Scheduling; Ant Colony Optimization (ACO); Clustered traveling salesman problems; Computational results; Computational time; Greedy randomized adaptive search procedure; Meta heuristics; Resources scheduling; Solution quality; Traveling salesman problem",2-s2.0-85026413102
"Skublewska-Paszkowska M.","Motion Repeatability of Tennis Forehand Preparation Phase Without the Ball Using Three Dimensional Data",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029516114&doi=10.1007%2f978-3-319-67229-8_14&partnerID=40&md5=8f2f5b1c60d9ad7a3d02753f4e8a3e0c","The forehand is one of the key shot in tennis. Its reparability is a very important aspect of gaining points. The first purpose of this paper is to create the algorithms for calculating the motion parameters for the preparation phase of the forehand, such as: the position of the head of the tennis racket relative to the player’s body, the elbow angle (i.e. whether the arm is bent or straight) and the placement of the player’s feet towards the front of the pelvis. The second aim of the study is to calculate the repeatability of the selected motion parameters (both for the body and the racket) of the preparation phase of the tennis forehand using coefficient of variation. The shots were performed in the motion capture laboratory using the Plug-in Gait biomechanical model. The described parameters are computed from three dimensional data, stored in C3D file. The obtained results indicate that the placement of the head of the tennis racket towards the player’s body is repeatable only for first two defined positions (above the forehead and between it and the shoulder). The participant puts his feet repeatable, after average 46% time he puts his left leg forward. The arrangement of the arm during the preparation phase of the forehand is also repeatable. © 2018, Springer International Publishing AG.","3D algorithms; Motion capture; Repeatability; Tennis forehand",,2-s2.0-85029516114
"Perez-Wohlfeil E., Chicano F., Alba E.","An Intelligent Data Analysis of the Structure of NP Problems for Efficient Solution: The Vehicle Routing Case",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030854346&doi=10.1007%2f978-3-319-68527-4_40&partnerID=40&md5=7a1b3b42e96c0f50683034416e377223","The Vehicle Routing Problem is a combinatorial problem with considerable industrial applications such as in traditional logistics and transportation, or in modern carpooling. The importance of even small contributions to this problem is strongly reflected in a significant cost savings, pollution, waste, etc., given the high impact of the sector in almost any economic transaction. The VRP is often treated as an optimization problem, however, the fitness function converges quickly and the algorithms become stagnant in late steps of the executions, which is a recurrent problem. In this work, we perform an analysis of the structure of solutions to identify potential use of existing ideas from other domains to achieve higher efficiency. In this sense, the feasibility of applying the Partition Crossover –an operator initially designed to tunnel through local optima for the Travelling Salesman Problem– to the Capacitated Vehicle Routing Problem is studied in order to escape local optima. Moreover, an implementation is provided along with an analysis applied to real use-cases, which show a promising rate of local optima tunneling. © 2018, Springer International Publishing AG.","Crossover operator; Data analysis; Genetic algorithms; Graph theory; Local optima; Optimization; Smart cities","Data handling; Data reduction; Genetic algorithms; Graph theory; Information analysis; Optimization; Smart city; Vehicle routing; Vehicles; Capacitated vehicle routing problem; Crossover operator; Economic transactions; Intelligent data analysis; Local optima; Logistics and transportations; Travelling salesman problem; Vehicle Routing Problems; Traveling salesman problem",2-s2.0-85030854346
"Panboonyuen T., Vateekul P., Jitkajornwanich K., Lawawirojwong S.","An enhanced deep convolutional encoder-decoder network for road segmentation on aerial imagery",2018,"Advances in Intelligent Systems and Computing",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022177717&doi=10.1007%2f978-3-319-60663-7_18&partnerID=40&md5=c143c4e792fd2254552d0ac8e5f25697","Object classification from images is among the many practical examples where deep learning algorithms have successfully been applied. In this paper, we present an improved deep convolutional encoder-decoder network (DCED) for segmenting road objects from aerial images. Several aspects of the proposed method are enhanced, incl. incorporation of ELU (exponential linear unit)—as opposed to ReLU (rectified linear unit) that typically outperforms ELU in most object classification cases; amplification of datasets by adding incrementally-rotated images with eight different angles in the training corpus (this eliminates the limitation that the number of training aerial images is usually limited), thus the number of training datasets is increased by eight times; and lastly, adoption of landscape metrics to further improve the overall quality of results by removing false road objects. The most recent DCED approach for object segmentation, namely SegNet, is used as one of the benchmarks in evaluating our method. The experiments were conducted on a well-known aerial imagery, Massachusetts roads dataset (Mass. Roads), which is publicly available. The results showed that our method outperforms all of the baselines in terms of precision, recall, and F1 scores. © Springer International Publishing AG 2018.","Deep convolutional neural network; Deep learning; Image processing; Remote sensing; Road segmentation","Aerial photography; Classification (of information); Convolution; Decoding; Deep neural networks; Education; Image processing; Image segmentation; Learning algorithms; Neural networks; Remote sensing; Roads and streets; Transportation; Convolutional encoders; Convolutional neural network; Landscape metrics; Object classification; Object segmentation; Overall quality; Road segmentation; Training data sets; Deep learning",2-s2.0-85022177717
"Zhang R., Tan H.","An integrated human reliability based decision pool generating and decision making method for power supply system in LNG terminal",2018,"Safety Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028037576&doi=10.1016%2fj.ssci.2017.08.010&partnerID=40&md5=99c989fb03c613438c0b5ede9a023df3","In this paper, an integrated model is presented to support human reliability based decision producing and making process by evaluating safety promotion plan for power supply system in LNG (Liquid Natural Gas) terminal. This model is mainly mathematically treated through fuzzy Cognitive Reliability and Error Analysis Method (CREAM) in combination with Genetic Algorithms (GA) and Adaptive Neuro-Fuzzy Inference System (ANFIS). The fuzzy CREAM accounts the operators’ individual factors, organization factors, environmental factors and technique factors together to identify the fuzzy membership degree of each control mode and to calculate Human Error Probability (HEP). However, when the calculated HEP fails to meet the requirement, the GA will identify the target membership degree of each CREAM control mode, and adopting such target membership degree and fuzzy logic rule to generate a decision pool for safety promotion. Finally, an experts’ evaluation result based ANFIS provides a standard evaluating system for plan choice and update. The proposed model has been tested on a power supply system for an LNG terminal in Beihai China. © 2017 Elsevier Ltd","ANFIS; Decision producing and making; Fuzzy CREAM; Genetic algorithms; Human reliability based","Decision making; Electric power systems; Fuzzy logic; Fuzzy neural networks; Fuzzy systems; Genetic algorithms; Inference engines; Oil terminals; Reliability; Reliability analysis; Adaptive neuro-fuzzy inference system; ANFIS; Cognitive reliability; Decision producing and making; Decision-making method; Fuzzy CREAM; Human error probability; Human reliability; Fuzzy inference",2-s2.0-85028037576
"Pektaş A., Acarman T.","Identification of application in encrypted traffic by using machine learning",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030770543&doi=10.1007%2f978-3-319-67792-7_53&partnerID=40&md5=074b3c441f55eb7d7433b817d41802c9","Identification of Internet protocol from raw network traffic plays a crucial role at maintaining and improving the security of back-end and front-end computer systems. A significant amount of research work is carried out while exploiting a variety of identification techniques. Although certain level in success at detection of network protocols for unencrypted traffic has been achieved, accuracy and performance is rather poor for encrypted traffic. But considering technological trends, new and existing applications have been adopted to use encryption mechanism to protect information and privacy. Therefore, classification of encrypted network traffic is mandatory for security purposes. In this study, we propose a method for automatic extraction of features from raw network capture and accurate identification of network applications by applying machine learning algorithms. The proposed method is evaluated with two independent datasets. The first dataset is publicly available (known as NISM dataset) and the second dataset is generated with a particular emphasis on accurate labeling of network traffic, it contains 713851 and 448 network flows, respectively. The proposed method classifies network flows provided by the first dataset into their corresponding application categories with the accuracy over 0.997 and F1-score of 0.99, the second dataset with an accuracy over 0.96 and F1-score of 0.95. © 2018, Springer International Publishing AG.","Encrypted traffic identification; Machine learning; Network flow; Security","Artificial intelligence; Cryptography; Internet protocols; Learning algorithms; Learning systems; Network protocols; Automatic extraction; Encrypted traffic; Identification techniques; Network applications; Network flows; Protect information; Security; Technological trends; Network security",2-s2.0-85030770543
"Park J.H., Park S.U., Zia Uddin M., Al-Antari M.A., Al-Masni M.A., Kim T.-S.","A single depth sensor based human activity recognition via convolutional neural network",2018,"IFMBE Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030873681&doi=10.1007%2f978-981-10-4361-1_92&partnerID=40&md5=4214e196674f7bbb5db155c7b249a901","Human activity recognition (HAR) has become an active research topic in the various fields. Depth sensor-based HAR recognizes human activities using features from depth human silhouettes via classifiers such as Hidden Markov Model (HMM), Conditional Random Fields Model etc. In this paper, we propose a new HAR system via Convolutional Neural Network (CNN), one of deep learning algorithms. We extract joint angles from multiple body joints changing in time and create a spatiotemporal feature matrix (i.e., multiple body joint angles in time). With these derived features, we train and test our CNN for HAR. In order to evaluate our system, we have compared the performance of our CNN-based HAR against the HMM- and Deep Belief Network (DBN)-based HAR using a database of Microsoft Research Cambridge-12 (MSRC-12). Our test results show that the proposed CNN-based HAR is able to recognize twelve human activities reliably and it outperforms the HMM- and DBN-based systems. We have achieved the average recognition accuracy of 98.59% for the activities. The results are 6.1% more accurate than that of the HMM-based HAR and 1.05% more accurate than that of the DBN-based HAR. © Springer Nature Singapore Pte Ltd. 2018.","Convolutional neural network; Deep learning; Depth imaging sensor; Human activity recognition","Biomedical engineering; Convolution; Deep learning; Learning algorithms; Markov processes; Neural networks; Pattern recognition; Conditional random field; Convolutional neural network; Deep belief network (DBN); Depth imaging; Human activity recognition; Microsoft researches; Recognition accuracy; Spatio temporal features; Hidden Markov models",2-s2.0-85030873681
"Liu H., Wu L., Zhang D., Jian M., Zhang X.","Multi-perspective User2Vec: Exploiting re-pin activity for user representation learning in content curation social network",2018,"Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028813353&doi=10.1016%2fj.sigpro.2017.07.002&partnerID=40&md5=889886ddf2169baf7d4f4992547bb143","Content curation social networks (CCSN) develop rapidly. Pinterest and Huaban are two typical CCSNs. Recently, there is active research on CCSNs. As a kind of content based social network, CCSNs involve not only the explicit social relations from user “following”, but also content-based social relations from re-pin paths and so on. In this paper, we propose a novel user representation learning algorithm, Multi-perspective User2Vec Representation (MUVR). It combines the two types of social relations to get the rich user sequences. Then the representation learning is implemented by using the skip-gram algorithm. Experimental results on Huaban.com demonstrate that the proposed algorithm can represent network well. It presents more competitive results in the followee recommendation, re-pinner recommendation and multi-label classification. © 2017","Content curation; Network representation; Re-pin path","Classification (of information); Content curation; Content-based; Multi label classification; Multi-perspective; Network representation; Social relations; Learning algorithms",2-s2.0-85028813353
"Tripathy T., Nagavarapu S.C., Azizian K., Ramasamy Pandi R., Dauwels J.","Solving Dial-A-Ride Problems Using Multiple Ant Colony System with Fleet Size Minimisation",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029587102&doi=10.1007%2f978-3-319-66939-7_28&partnerID=40&md5=b245073efee121ff2ec6ab15553cf290","This paper proposes an ant colony optimization (ACO) based algorithm to minimise the fleet size required to solve dial-a-ride problem (DARP). In this work, a static multi-vehicle case of DARP is considered where routes of multiple vehicles are designed to serve customer requests which are known a priori. DARP necessitates the need of high quality algorithm to provide optimal feasible solutions. We employ an improved ACO algorithm called ant colony system (ACS) to solve DARP. The fleet minimisation is also achieved by using ACS. In summary, multiple ACS are employed to minimise the fleet size while generating feasible solutions for DARP. Furthermore, the theoretical results are also validated through simulations. © 2018, Springer International Publishing AG.","Ant colony optimisation; Dial-a-ride problem; Fleet size minimisation","Artificial intelligence; Optimization; ACO algorithms; Ant Colony Optimization (ACO); Ant colony systems; Dial-a-ride problem; Feasible solution; Minimisation; Multi-vehicles; Optimal feasible solution; Ant colony optimization",2-s2.0-85029587102
"Hao W., Dong J., Peng K., Jia M., Wang Q.","Pulp concentration control based on dynamic matrix control",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031411253&doi=10.1007%2f978-981-10-6499-9_67&partnerID=40&md5=85452228bd2e811b17991d3a07fcb52e","In the papermaking industry, the stability of the pulp concentration determines the quality of the paper. However, the change of the pulp concentration is in a state of fluctuation for a long time and the pulp concentration control system has the characteristics of large lag, non-linearity and time-varying. It is difficult to achieve the desired control effect by using the traditional PID controller in the concentration control process. Therefore, use of dynamic matrix control algorithm to design the controller can solve the problem of disturbance and modeling complexity. In this paper, dynamic matrix control algorithm and PID control simulation results show that the dynamic matrix control algorithm has better control quality. The output satisfies the constraint limit with higher probability, and the output constraints and performance index can be met. © 2018, Springer Nature Singapore Pte Ltd.","Dynamic matrix control; PID control; Pulp concentration","Controllers; Intelligent systems; Pulp; Three term control systems; Concentration control; Constraint limits; Control simulation; Dynamic matrix control; Dynamic matrix control algorithms; Papermaking industry; Performance indices; Pulp concentration; Quality control",2-s2.0-85031411253
"Tan F., Hou M., Zhao H., Duan G.","Input-Constrained Controller Design of Linear Time-Varying Systems Based on Piecewise State Estimation",2018,"Journal of Dynamic Systems, Measurement and Control, Transactions of the ASME",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029188861&doi=10.1115%2f1.4037389&partnerID=40&md5=8cdec276c02c48fcb1fd606db39daf3a","Finite-time control problem of linear time-varying systems with input constraints is considered in this paper. Successive ellipsoidal approximations are used to estimate the state evolution of linear time-varying systems during a certain finite-time interval. An algorithm to design a controller based on approximations of state evolution is proposed. According to the proposed algorithm, the speed of state approaching equilibrium is optimized piecewisely using admissible control. The controller gain can be obtained by solving several quasi-convex optimization problems, which makes the design process computationally tractable. Simulation results show that the proposed controller can quickly reduce state deviation without violating input constraints. Copyright © 2018 by ASME.",,"Approximation algorithms; Convex optimization; Design; Optimization; Time varying control systems; Time varying systems; Admissible control; Controller designs; Convex optimization problems; Ellipsoidal approximations; Finite time intervals; Finite-time control; Input constraints; Linear time-varying systems; Controllers",2-s2.0-85029188861
"Tang X., Ji Y.","Research on agricultural intelligent robot based on path planning",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028443906&doi=10.1007%2f978-3-319-60744-3_12&partnerID=40&md5=0dac1a59a41b7782e852b6be9f49372e","Based on research and application of agricultural robot’s path planning and autonomous navigation, this paper proposed path planning proposal relied on genetic algorithm, which programmed and calculated some elements, such as target identification, image segmentation and two dimensional grid map of rough sets technology. Through the test, it was observed that harvesting robots can efficiently segment and extract ripe fruits. Besides, it can complete multi-goal tasks. It was proved by practice that rough sets genetic algorithm can obviously improve the speed of path planning. Benefit from it, the efficiency of harvesting task can be promoted as well. © 2018, Springer International Publishing AG.","Agricultural intelligent robot; Integrated design; Path planning","Agriculture; Genetic algorithms; Image segmentation; Intelligent robots; Intelligent systems; Machine design; Real time systems; Robot programming; Robots; Rough set theory; Agricultural robot; Autonomous navigation; Harvesting robot; Integrated designs; Research and application; Target identification; Two-dimensional grids; Motion planning",2-s2.0-85028443906
"Xiu Q., Shen X., Zhang T., Zhao L.","An immersive roaming method based on panoramic video",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031405064&doi=10.1007%2f978-981-10-6499-9_41&partnerID=40&md5=9cfcac723203e34237cc796abb1fb903","The idea for panoramic video immersive roaming is from the current mature street view, such as Google Street View, and Baidu Street View. The method of video’s immersive roaming proposed in this paper will overcome the disadvantages of the Google Street View which based on panoramic pictures. The method mainly involves the adaptive tuning of the camera algorithm, the immersive viewing angle forward and camera switching algorithm. Finally, the method is proved to achieve panoramic video immersive roaming through panoramic video, and there is high practical value. © 2018, Springer Nature Singapore Pte Ltd.","Adaptive tuning of the camera; Camera switching; Panoramic video immersive roaming; Street view","Intelligent systems; Adaptive tuning; Immersive; Panoramic video; Switching algorithms; Viewing angle; Cameras",2-s2.0-85031405064
"Prabodha L.H.C., Vithanage W.R.R., Ranaweera L.T., Dissanayake D.M.M.A.I.B., Ranathunga S.","Monitoring health of large scale software systems using drift detection techniques",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026310907&doi=10.1007%2f978-3-319-61566-0_14&partnerID=40&md5=1b9ac6b1ddf69ccdad141221c8208748","Anomaly detection in large-scale software systems is important to guarantee smooth operation of the system. Upon detection of an anomaly, it is vital to identify the root cause behind the anomaly to decipher actionable information and prevent future incidents. Isolation of root causes becomes inherently difficult as the number of components and parameters in each component increase. This paper discusses successful application of three drift detection techniques, namely meta algorithm, fixed cumulative window model and Page-Hinckley test to identify the parameters that correlate to system abnormalities in a large scale complex software system. Out of these, change detection meta algorithm produced the best result. © Springer International Publishing AG 2018.",,"Application programs; Computer software; Signal detection; Anomaly detection; Change detection; Complex software systems; Large-scale software systems; Meta-algorithms; Number of components; Root cause; Software testing",2-s2.0-85026310907
"Deng N., Chen X., Ruan O., Wang C., Ye Z., Tian J.","Paeffextr: A method to extract effect statements automatically from patents",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026291590&doi=10.1007%2f978-3-319-61566-0_62&partnerID=40&md5=3f8a3aa41adf51486f7da136b2c6410c","Patents contain a lot of technical, economic and legal information, and they are the main references of enterprises’ technological innovation. As a tool of patent analysis and mining, technology/effect matrix provides important support for technological innovation and avoidance. In the process of building technology/effect matrix, most of current technical efficiency annotation is by manually work, which requires heavy labor. Considering the distribution and morphological characteristics of patent abstract texts, this paper proposes a multi-features fused scoring algorithm named PaEffExtr, which automatically extracts effect statements from patent abstract texts. The experimental results show that the algorithm has good recall and accuracy. © Springer International Publishing AG 2018.",,"Computer programming; Computer science; Building technologies; Legal information; Morphological characteristic; Multi features; Patent analysis; Scoring algorithms; Technical efficiency; Technological innovation; Patents and inventions",2-s2.0-85026291590
"Prabhakar S.K., Rajaguru H.","Expectation maximization based PCA and hessian LLE with suitable post classifiers for epilepsy classification from EEG signals",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028606303&doi=10.1007%2f978-3-319-60618-7_36&partnerID=40&md5=546d1d5f33c18c95ce93dc779cae2f29","Brain is a highly complicated structure which contains billions of neurons which help in maintaining the electrical charges of the system. Due to the sudden and unexpected electrical discharges occurring in the brain, epilepsy occurs and is a most commonly occurring neurological disorder next to stroke. For the easy monitoring of the activities of the brain, Electroencephalography (EEG) is widely used. For the primary purpose of assessment of brain activities, EEG serves as a valuable treasure and an indispensable tool. The various information related to the physiological state of the brain can be bought out by EEG. For the analysis of the EEG records in a visual manner, expert neurologists consume more time and to detect the epileptic seizures, only EEG signals are used widely as it contains vital information. The EEG recording contains a lot of noise and so it is difficult to isolate the seizures from other artifacts with resembles more or less similar time-frequency patterns. Various automatic detection and machine learning algorithms have been used to predict the risk of epileptic seizures in raw EEG signals. In this study, the dimensions of the EEG signals are reduced initially with the help of two approaches, namely, Expectation Maximization Based Principal Component Analysis (EM-PCA) approach and Hessian Local Linear Embedding (HLLE) approach. The dimensionally reduced values are then classified to predict the risk of epilepsy from EEG signals with the help of two post classifiers namely Weighted K Nearest Neighbour (WKNN) and Linear Support Vector Machine (L-SVM). The performance metrics are analyzed in terms of various measures like Performance Index, Accuracy, Time Delay, Specificity and Sensitivity. The study shows that the best result is obtained when HLLE is used as a dimensionality reduction technique and classified with WKNN as it gives the highest perfect classification rate with an average accuracy of 97.743%. © Springer International Publishing AG 2018.","EEG; EM-PCA; Epilepsy; HLLE; L-SVM; WKNN","Brain; Electric discharges; Electroencephalography; Electrophysiology; Learning algorithms; Learning systems; Maximum principle; Nearest neighbor search; Neurology; Neurophysiology; Pattern recognition; Principal component analysis; Soft computing; Support vector machines; Time delay; EM-PCA; Epilepsy; HLLE; L-SVM; WKNN; Biomedical signal processing",2-s2.0-85028606303
"Komarova A., Menshchikov A., Negols A., Korobeynikov A., Gatchin Y., Tishukova N.","Comparison of authentication methods on web resources",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031428044&doi=10.1007%2f978-3-319-68321-8_11&partnerID=40&md5=8b163fe0bfc17656bcf3cecf52cbec67","These days web resources keep and process a lot of valuable information. Confidential data and private pages have to be protected due to business processes. To implement this requirement and limit the number of people having access to the restricted resources, you need to configure a proper authentication on website. Unfortunately authentication is often implemented incorrectly which leads to information leaks. Frequently websites have only password protection and use other simple methods. The article deals with different comparison of authentication methods, using both simple and advanced approaches including cryptography and biometrics. Moreover, the authors give the comparative analysis of different approach parameters. Usability, performance, security and other features of the methods are analyzed. The most convenient to use, the easiest to implement and the most secure methods are found. A conclusion about the most suitable application areas of each method on World Wide Web resource is made. Possible combinations of approaches and their further implementation tendency are also discussed. An analysis of domestic and foreign literary sources, scientific articles and publications on our topic is made for the finding verification. We perform Russian and international literature search on the scientific databases as well as on the electronic library systems. Furthermore, patent research is made for finding practical implementations. It includes patents of the business organizations related to web authentication methods. The results of this research show the topic relevance, the increasing number of patented authentication methods on web resources, as well as a fairly high potential of the new method development. This way should base on improvement and unification of existing approaches and on developing of new original algorithms. As a result, it is concluded that further improvements in the trends are in the field of hybrid systems. © Springer International Publishing AG 2018.","Authentication; Biometrics; Cryptography; Dynamic passwords; Passwords; Patents; Tokens; Web resources","Biometrics; Cryptography; Digital libraries; Hybrid systems; Information dissemination; Patents and inventions; Websites; Authentication methods; Business organizations; Comparative analysis; Original algorithms; Passwords; Patents; Tokens; Web resources; Authentication",2-s2.0-85031428044
"Rezaei H., Bozorg-Haddad O., Chu X.","League championship algorithm (LCA)",2018,"Studies in Computational Intelligence",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021680949&doi=10.1007%2f978-981-10-5221-7_3&partnerID=40&md5=ca3344f40e7cf5bcb91ef6f18f0f62d3","This chapter briefly describes the league championship algorithm (LCA) as one of the new evolutionary algorithms. In this chapter, a brief literature review of LCA is first presented; and then the procedure of holding a common league in sports and its rules are described. Finally, a pseudo code of LCA is presented. © 2018, Springer Nature Singapore Pte Ltd.",,,2-s2.0-85021680949
"Chawla A., Ghumman N.S.","Package-based approach for load balancing in cloud computing",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031413348&doi=10.1007%2f978-981-10-6620-7_9&partnerID=40&md5=3e095c5d8a0aa4bf61f24bec83cd6612","Cloud computing is a developing technology in today’s Internet world which offers the users with on demand access to resources through different service models. In spite of providing many advantages over the traditional computing, there are some critical issues in cloud computing. Load balancing is a crucial issue in cloud computing that distributes the user’s requests to the nodes in such a manner to balance the load on nodes. A proper load balancing algorithm is required to execute the process and manage the resources. The common objective of load balancing algorithm is to achieve the minimum execution time and proper utilization of resources. In this paper, we proposed a new technique to achieve the load balancing called packet-based load balancing algorithm. The motive of this algorithm is to design the concept of load balancing using the grouping of packages and perform the virtual machine replication, if requested package is not available. In this paper, task is achieved with minimum execution time and execution cost which is profitable for the service provider and the user. © 2018, Springer Nature Singapore Pte Ltd.","Cloudlets; Load balancing; Task length; Virtual machine (VM)","Big data; Network function virtualization; Network security; Resource allocation; Virtual machine; Access to resources; Cloudlets; Different services; Load balancing algorithms; Service provider; Task length; Traditional computing; Utilization of resources; Cloud computing",2-s2.0-85031413348
"Speckmann B., Verbeek K.","Homotopic C-oriented routing with few links and thick edges",2018,"Computational Geometry: Theory and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031668733&doi=10.1016%2fj.comgeo.2017.10.005&partnerID=40&md5=f6759decf7d8110aa9b2e980a45c4b3c","We study the NP-hard optimization problem of finding non-crossing thick C-oriented paths that are homotopic to a set of input paths in an environment with C-oriented obstacles, with the goal to minimize the total number of links of the paths. We introduce a special type of C-oriented paths—smooth paths—and present a 2-approximation algorithm for smooth paths that runs in O(n3log⁡κ+kinlog⁡n+kout) time, where n is the total number of paths and obstacle vertices, kin and kout are the total complexities of the input and output paths, and κ=|C|. The algorithm also computes an O(κ)-approximation for general C-oriented paths. In particular we give a 2-approximation algorithm for rectilinear paths. Our algorithm not only approximates the minimum number of links, but also simultaneously minimizes the total length of the paths. As a related result we show that, given a set of (possibly crossing) C-oriented paths with a total of L links, non-crossing C-oriented paths homotopic to the input paths can require a total of Ω(Llog⁡κ) links. © 2017 Elsevier B.V.","C-oriented; Homotopic; Minimum-link; Routing; Thick paths","Approximation algorithms; Homotopic; Input and outputs; Minimum-link; Optimization problems; Rectilinear path; Routing; Smooth paths; Thick paths; Optimization",2-s2.0-85031668733
"Wang N., Hu X., Yuan T., Zhou W.","The calibration method of channel consistency of distributed digital phased array",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028359673&doi=10.1007%2f978-981-10-4837-1_33&partnerID=40&md5=19fae4742f63579fbc1ae7f58403733d","In this paper, a new valid calibration method is put forward to satisfy the request of channel consistency of distributed digital phased array. Firstly, the time delay estimation algorithm based on temporal coherence is used to align the large time delay among channels. Then, the frequency domain equalization algorithm based on the least squares fitting is used to achieve consistency of magnitude and phase among channels. The effectiveness of above method is validated through analyzing of equalization result on MATLAB platform. The results shows that the magnitude and phase differences between reference channel and mismatch channel in the pass band are rescaled in the range of 0.015, dB and 0.1° respectively after the calibration of equalizer. Furthermore, this method has been applied in practical engineering project. © Tsinghua University Press, Beijing and Springer Nature Singapore Pte Ltd. 2018.","Channel consistency; Distributed digital phased array; Frequency domain equalization; Time delay estimation","Antenna phased arrays; Calibration; Equalizers; Frequency domain analysis; Frequency estimation; Calibration method; Channel consistency; Frequency domain equalization; Least squares fitting; Practical engineering; Reference channels; Time delay estimation; Time delay estimation algorithms; Time delay",2-s2.0-85028359673
"Grychowski T., Jabłoński K.","Early detection of fire hazard using fuzzy inference system",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030756689&doi=10.1007%2f978-3-319-67792-7_27&partnerID=40&md5=e8a4be825403745e227aa2af3c4438d9","Fast detection of fire allows to protect human’s health and life as well as avoid loss of property. Most fire sensors have simple construction, consisting of one or two sensing elements (usually detecting smoke and temperature) and an uncomplicated algorithm. This paper presents an idea of using fuzzy inference for early fire detection based on simultaneous analysis of data from multiple sensors. The measurement system includes a head with two accurate sensors: electrochemical carbon monoxide sensor and resistance temperature sensor. The implemented fuzzy inference algorithm accepts as inputs the values measured by the sensors, signal rise rate and signal variability. The main goal of the system is to early detect fire hazard or sensors malfunction. A series of experiments and detailed analysis of results were performed. It has been proved that fuzzy inference is suitable to the presented application. © 2018, Springer International Publishing AG.","Data fusion; Fire hazard detection; Fuzzy logic; Fuzzy sensors; Measurement head; Multisensory systems","Carbon; Carbon monoxide; Data fusion; Fire hazards; Fires; Fuzzy logic; Hazards; Inference engines; Carbon monoxide sensor; Fuzzy inference algorithms; Fuzzy inference systems; Fuzzy sensors; Hazard detection; Multisensory systems; Resistance temperature sensor; Simultaneous analysis; Fuzzy inference",2-s2.0-85030756689
"Anoop V.S., Asharaf S., Deepak P.","Topic modeling for unsupervised concept extraction and document ranking",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032702838&doi=10.1007%2f978-3-319-68385-0_11&partnerID=40&md5=dba6eef1c6debd15c958ac49e68479d0","This paper proposes a framework which induces semantically rich concepts from probabilistically generated topics by a topic modeling algorithm. In this method an off-the-shelf tool has been used to extract noun-phrases as word bi-grams and tri-grams from the static document corpus and then models the topics using Latent Dirichlet Allocation algorithm. Additionally, we show that a small extension to our proposed framework can better rank documents in a large collection, which is a well studied area in information retrieval. Experiments conducted on three real world datasets show that this proposed framework outperforms state-of-the-art methods used for extracting concepts and ranking documents. When compared with the baselines chosen, our proposed concept extraction method showed an increased f-measure in the range of 16.65% to 22.04% and the proposed topic modeling guided document retrieval method showed 7.6%–16.61% increase in f-measure. © Springer International Publishing AG 2018.","Concept extraction; Document ranking; Latent dirichlet allocation; Topic modeling","Extraction; Information retrieval; Intelligent systems; Search engines; Statistics; Concept extraction; Document ranking; Extracting concept; Latent Dirichlet allocation; Real-world datasets; State-of-the-art methods; Topic Modeling; Topic modeling algorithms; Data mining",2-s2.0-85032702838
"Uwitonze A., Huang J., Ye Y., Cheng W.","Constrained space information flow",2018,"Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031307465&doi=10.1007%2f978-3-319-66628-0_45&partnerID=40&md5=c7c6798d101aac6469843e0d51fe3926","Space Information Flow (SIF), also known as Space Network Coding, is a new research paradigm which studies network coding in Euclidean space, and it is different with Network Information Flow proposed by Ahlswede et al. This paper focuses on the problem of Constrained Space Information Flow (CSIF), which aims to find a min-cost multicast network in 2-D Euclidean space under the constraint on the number of relay nodes to be used. We propose a new polynomial-time heuristic algorithm that combines Delaunay triangulation and linear programming techniques to solve the problem. Delaunay triangulation is used to generate several candidate relay nodes, after which linear programming is applied to choose the optimal relay nodes and to compute their connection links with the terminal nodes. The simulation results shows the effectiveness of the proposed algorithm. © 2018, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.","Delaunay triangulation; Network coding in space; Network Information Flow; Space Information Flow","Codes (symbols); Geometry; Heuristic algorithms; Heuristic programming; Linear programming; Polynomial approximation; Surveying; Triangulation; Constrained space; Delau-nay triangulations; Euclidean spaces; Information flows; Linear programming techniques; Multicast network; Network information flow; Polynomial-time; Network coding",2-s2.0-85031307465
"Bejuri W.M.Y.W., Mohamad M.M., Radzi R.Z.R.M., Salleh M., Yusof A.F.","A proposal of location aware shopping assistance using memory-based resampling",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022177285&doi=10.1007%2f978-981-10-5281-1_54&partnerID=40&md5=762e9b55b2d2f1b68e7bf56b09eabd76","The range of memory specifications of location aware shopping assistance poses difficulties for the developer (in terms of increased time and effort) when it comes to developing a resampling algorithm for mobile devices. Thus, a new resampling algorithm is required with a flexible capacity that would cater for a range of computing device memory devices specifications. This paper develops a memory based resampling in standard particle filter. The memory resampling is capable to read memory specifications of mobile devices before determines the most suitable resampling functions. The authors aim to extend this work in future by implementing their proposed method in a number of different emerging applications (in example, medical applications and real time locator systems). © Springer Science+Business Media Singapore 2018.","Memory consumption; Particle filter; Resampling; Sequential implementation","Medical applications; mHealth; Monte Carlo methods; Specifications; Wireless telecommunication systems; Emerging applications; Memory consumption; Memory specification; Particle filter; Resampling; Resampling algorithms; Sequential implementation; Shopping assistance; Real time systems",2-s2.0-85022177285
"Abdulali A., Jeon S.","Data-driven rendering of anisotropic haptic textures",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026446749&doi=10.1007%2f978-981-10-4157-0_67&partnerID=40&md5=26fb4f4e1abe1a55bcdb9ce09d9b7a21","It is common to interact with a wide range of surfaces with anisotropic haptic textures in our daily life. However, the rendering techniques were not capable of incorporating the directional grain in a virtual world. In our previous work, we have proposed a data-driven model for anisotropic haptic textures, which stores and interpolates contact vibration patterns. In this paper, we have developed a complementary rendering algorithm. This algorithm has been implemented in form of a cross-platform computing library, and deployed to the tablet-PC-based demonstration setup. A set of eight anisotropic and one isotropic textures is prepared for the demonstration. Two demonstration scenarios have been provided for the realism evaluation. © Springer Nature Singapore Pte Ltd. 2018.","Anisotropic texture; Data-driven rendering; RBF networks","Demonstrations; Radial basis function networks; Virtual reality; Anisotropic texture; Contact vibration; Cross-platform; Data driven; Data-driven model; Haptic textures; Rendering algorithms; Virtual worlds; Anisotropy",2-s2.0-85026446749
"Brochero Martínez F.E., Reis L.","Factoring polynomials of the form f(xn)∈Fq[x]",2018,"Finite Fields and their Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032269280&doi=10.1016%2fj.ffa.2017.10.003&partnerID=40&md5=85ac1087a2d39d82fa8f5599b33f44de","Let f(x)∈Fq[x] be an irreducible polynomial of degree m and exponent e. For each positive integer n, such that νp(q−1)≥νp(e)+νp(n) for all prime divisors p of n, we show a fast algorithm to determine the irreducible factors of f(xn). Using this algorithm, we give the complete factorization of xn−1 into irreducible factors in the case where n=dpt, p is an odd prime, q is a generator of the group Zp2 ⁎ and either d=2m with m≤ν2(q−1) or d=ra, where r is a prime dividing q−1 but not p−1. © 2017 Elsevier Inc.","Cyclotomic polynomials; Irreducible factors; Irreducible polynomial in a finite field","Algebra; Finite element method; Cyclotomic polynomials; Fast algorithms; Finite fields; Irreducible factors; Irreducible polynomials; Odd prime; Positive integers; Polynomials",2-s2.0-85032269280
"Oswald C., Akshay Vyas V., Arun Kumar K., Vijay Sri L., Sivaselvan B.","Hierarchical clustering approach to text compression",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026769679&doi=10.1007%2f978-981-10-3373-5_35&partnerID=40&md5=4fbbd4e2f5babde7a8524e570f12e11e","A novel data compression perspective is explored in this paper and focus is given on a new text compression algorithm based on clustering technique in Data Mining. Huffman encoding is enhanced through clustering, a non-trivial phase in the field of Data Mining for lossless text compression. The seminal hierarchical clustering technique has been modified in such a way that optimal number of words (patterns which are sequence of characters with a space as suffix) are obtained. These patterns are employed in the encoding process of our algorithm instead of single character-based code assignment approach of conventional Huffman encoding. Our approach is built on an efficient cosine similarity measure, which maximizes the compression ratio. Simulation of our proposed technique over benchmark corpus clearly shows the gain in compression ratio and time of our proposed work in relation to conventional Huffman encoding. © Springer Nature Singapore Pte Ltd. 2018.","Compression ratio; Cosine similarity measure; Hierarchical clustering; Huffman encoding; Lossless compression","Cluster analysis; Compression ratio (machinery); Computation theory; Data mining; Encoding (symbols); Intelligent computing; Signal encoding; Clustering techniques; Code assignments; Cosine similarity measures; Hier-archical clustering; Hierarchical clustering approach; Huffman encoding; Lossless compression; Text compressions; Clustering algorithms",2-s2.0-85026769679
"Liu D., Lin J., Wang J., Qiu H., Chen Y.","Dynamic power control for throughput maximization in hybrid energy harvesting node",2018,"Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031287531&doi=10.1007%2f978-3-319-66628-0_3&partnerID=40&md5=9182d1242b4bac3c90250f375660f131","In this paper, we consider a wireless communication node with hybrid energy harvesting (EH) sources which results in great difficulty in obtaining the statistical knowledge of joint EH process. In addition, the wireless channel fluctuates randomly due to fading. Our goal is, under this condition, to develop a dynamic power control policy for the transmitter such that the time average throughput of the system is maximized over an infinite horizon, taking into account the circuit energy consumption and inefficiency of the rechargeable battery. Such a dynamic power control problem is formulated as a stochastic network optimization problem. The problem is solved by utilizing Lyapunov optimization and an efficient on-line algorithm with quite low complexity is obtained. Simulation results illustrate that the proposed algorithm has the same performance as the optimal one with giving statistical knowledge of the stochastic processes. © 2018, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.","Energy harvesting; Hybrid energy sources; Lyapunov optimization; Throughput maximization; Wireless communication","Energy policy; Energy utilization; Optimization; Power control; Random processes; Stochastic systems; Throughput; Wireless telecommunication systems; Dynamic power control; Hybrid energy sources; Infinite horizons; On-line algorithms; Statistical knowledge; Stochastic network optimizations; Throughput maximization; Wireless communications; Energy harvesting",2-s2.0-85031287531
"Li R., Shi Y.","The intelligent flight control of quadrotor in tunnel based on simple sensors",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031409965&doi=10.1007%2f978-981-10-6499-9_2&partnerID=40&md5=1ff2e181deb62256c7b72cafa7f367b5","This paper studies the automation flight control problem of a quadrotor in the tunnel. The LED lamp belt is installed in the tunnel and two moving points are the tracking target of the quadrotor. The velocity-control-mode is first well done before the tracking control algorithm is considered. A control law is then designed to achieve tracking task in the straight tunnel. When the parameter is properly designed, the quadrotor still can perform tracking task for the moving points even in the bent tunnel. Moreover, we prove that the collision between the quadrotor and the tunnel can be avoided by using the proposed control law. The validity of the proposed control algorithm is also demonstrated through numerical simulations. © 2018, Springer Nature Singapore Pte Ltd.","Automation flight; Collision avoidance; Quadrotor; Tracking","Collision avoidance; Control theory; Intelligent systems; Light emitting diodes; Surface discharges; Control laws; Flight control problems; Intelligent flight controls; LEd lamps; Quad rotors; Tracking control algorithms; Tunnels",2-s2.0-85031409965
"Su X., Lin X., Zeng J., Xiao C.","Coverage and capacity optimization based on tabu search in ultra-dense network",2018,"Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031307919&doi=10.1007%2f978-3-319-66628-0_6&partnerID=40&md5=174fe9961f7d4813a5a9c8beffb010c5","To meet the requirements of high system capacity and coverage of 5G network, ultra-dense network is viewed as the key technology for networking evolution. And for densely deployed small cell network, self-optimization is crucial in the aspect of reducing the cost of network management while optimizing the network performance. This paper focuses on the coverage and capacity optimization, proposing a mathematical combined optimization function to balance the conflicting key performance indicators. And under this model, we propose the tabu search algorithm for generating new antenna transmit power to optimize the performance. Simulation results show that our proposed algorithm gets significant improvement in network performance and outperforms the adaptive simulated annealing in convergence speed while optimizing. © 2018, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.","Coverage and capacity optimization; Small cell; Tabu search; Ultra-dense network","Benchmarking; Functions; Network performance; Simulated annealing; Tabu search; Adaptive simulated annealing; Capacity optimization; Dense network; Key performance indicators; Optimization function; Small cell Networks; Small cells; Tabu search algorithms; Optimization",2-s2.0-85031307919
"Jelassi A., Chaker A., Mlika A.","3-RRR spherical parallel robot optimization with minimum of singularities",2018,"Mechanisms and Machine Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026297344&doi=10.1007%2f978-3-319-60867-9_34&partnerID=40&md5=863d3e1aecda7e7a30de1e2aff61128d","This paper deals with the optimization of the 3-RRR Spherical parallel Manipulator SPM. In addition to workspace constraints and dexterity performance; singilarity positions and distribution appeared to have considerable effects when treating control issues. Thus, this additional parameter is integrated in a Genetic Algorithm (GA) Based synthesis process. A multi objective problem is then formulated and results were analysed. The effect of self rotation u was also explored throught three differentsvalues. Results were finally discussed. © Springer International Publishing AG 2018.","Dexterity; GA; Optimization; Self rotation; Singularity; SPM","Gallium; Kinematics; Manipulators; Optimization; Control issues; Dexterity; Multi-objective problem; Self rotations; Singularity; Spherical parallel manipulator; Spherical parallel robot; Synthesis process; Genetic algorithms",2-s2.0-85026297344
"Kaur G., Bhardwaj N., Singh P.K.","An analytic review on image enhancement techniques based on soft computing approach",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031417556&doi=10.1007%2f978-981-10-6614-6_26&partnerID=40&md5=7e9d10d414e6128ae7278901d0c1db16","This paper discusses various image enhancement techniques using soft computing approaches. The approaches used are genetic algorithm, fuzzy-based enhancement, neural networks, and optimization techniques (ant colony, bee colony, particle swarm optimization, etc.). The main objective of this paper is to identify the status of currently used soft computing approaches in image enhancement. Our study may help future researchers to overcome the current issues with existing approaches to improve the overall image quality. © 2018, Springer Nature Singapore Pte Ltd.","Digital image processing; Image enhancement; Image quality; Soft computing approaches","Ant colony optimization; Fuzzy neural networks; Genetic algorithms; Image processing; Image quality; Particle swarm optimization (PSO); Soft computing; Ant colonies; Optimization techniques; Soft computing approaches; Image enhancement",2-s2.0-85031417556
"Rios E., Ochi L.S., Boeres C., Coelho V.N., Coelho I.M., Farias R.","Exploring parallel multi-GPU local search strategies in a metaheuristic framework",2018,"Journal of Parallel and Distributed Computing",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029145308&doi=10.1016%2fj.jpdc.2017.06.011&partnerID=40&md5=61c4d2b293550f63eac6024cea721f45","Optimization tasks are often complex, CPU-time consuming and usually deal with finding the best (or good enough) solution among alternatives for a given problem. Parallel metaheuristics have been used in many real-world and scientific applications to efficiently solve these kind of problems. Local Search (LS) is an essential component for some metaheuristics and, very often, represents the dominant computational effort accomplished by an algorithm. Several metaheuristic approaches try to adapt traditional LS models to parallel platforms without considering the intrinsic features of the available architectures. In this work, we present a novel local search strategy, so-called Distributed Variable Neighborhood Descent (DVND), specially designed for CPU and multi-GPU environment. Furthermore, a new neighborhood search strategy, so-called Multi Improvement, is introduced, taking advantage of GPU massive parallelism in order to boost up LS procedures. A hard combinatorial problem is considered as case of study, the Minimum Latency Problem (MLP). For tackling this problem, a hybrid metaheuristic algorithm is considered, which combines good quality initial solutions, generated by a Greedy Randomized Adaptive Search Procedures, with a flexible and powerful refinement procedure, inside the scope of an Iterated Local Search. The DVND was compared to the classic local search procedures, producing results that outperformed the best known sequential algorithm found in the literature. The speedups ranged from 7.3 to 13.7, for the larger MLP instances with 500 to 1000 clients. Results demonstrate the effectiveness of the proposed techniques in terms of solution quality, performance and scalability. © 2017 Elsevier Inc.","GRASP; ILS; Local search; Minimum latency problem; Multi-GPU; Parallel metaheuristic; VND","Graphics processing unit; Heuristic algorithms; Optimization; GRASP; Local search; Minimum latency problems; Multi-gpu; Parallel metaheuristic; Local search (optimization)",2-s2.0-85029145308
"Lin Y., Zhou Y.-L., Fan S.-T., Jia Y.-M.","Analysis on time triggered flexible scheduling with safety-critical system",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031400619&doi=10.1007%2f978-981-10-6499-9_47&partnerID=40&md5=de8f5b3befe30a104e9460eb65fd4a60","Time triggered Network communication technology has been applied to the China’s next generation multi-purpose complex Aerospace Vehicle. This vehicle is based on the technology in the system satisfy safety critical communication need, and can also take into account other large amount of data of low priority communication tasks. In this paper, combined with the actual characteristics of aerospace vehicle’s mission requirements, according to the study of the key security information system level scheduling method based on this technology, a global optimal requirement decomposition and message scheduling algorithm based on automatic planning is proposed. The automatic generation algorithm of message scheduling table according to the system message transmission needs, and to meet the needs of key safety messages in the table does not meet the labeling and suggestions, providing the basis for the design of aircraft overall communication timing and strategy. Matlab/Simulink is used to modeling, simulating and verifying the algorithm. The simulation results meet the requirements of the communication design of the aircraft system. © 2018, Springer Nature Singapore Pte Ltd.","Design iteration; Message scheduling; Safety critical; Time triggered","Aerospace vehicles; Aircraft communication; Intelligent systems; Iterative methods; MATLAB; Safety engineering; Scheduling; Scheduling algorithms; Vehicles; Design iteration; Message scheduling; Message transmissions; Network communications; Safety critical systems; Safety-critical communication; Security information systems; Time triggered; Vehicle to vehicle communications",2-s2.0-85031400619
"Kornatowski E.","Detection of the transient vibrations amplitude of power transformer’s active part",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028329849&doi=10.1007%2f978-3-319-64474-5_14&partnerID=40&md5=68831dca8dc55615abaf10c003055be6","The vibroacoustic diagnostics is currently one of the most important methods used for assessment of the mechanical condition of power transformers’ active part (windings and core). The analysis of transformer’s tank vibrations is performed for the steady state (stable load or no load) and for the transient state, during the first couple of seconds after unloaded transformer energization. Vibrations signal is recorded with accelerometric sensor attached to the transformer tank. In the case of transient state it is very important to determine the envelope of tank vibrations recorded signal. There is very often used for this purpose amplitude detector AM-DSB, which algorithm is based on the Hilbert filter. However recorded signal of vibrations (proportional to the acceleration) does not fulfill conditions of AM-DSB signal. Using the standard envelope detection (Hilbert filter) leads to wrong conclusions. In this paper a modified algorithm of envelope detector is presented, which can be used each time, where there is a need to determine signal’s envelope, that does not fulfill conditions of amplitude modulation AM-DSB. The quality of proposed algorithm was experimentally verified on the example of two transformers: low and medium power (0.8 MVA and 16 MVA). © Springer International Publishing AG 2018.","Ttransformer; Vibration signal envelope; Vibroacoustics","Amplitude modulation; Fault tolerance; Power transformers; Tanks (containers); Low and medium power; Modified algorithms; Transformer energization; Transient vibrations; Ttransformer; Vibration signal; Vibroacoustic diagnostics; Vibroacoustics; Vibration analysis",2-s2.0-85028329849
"Zhang P., Chan L., Zhou H., Yu X.","Target recognition of radar HRRP Using the envelope reconstruction",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028331523&doi=10.1007%2f978-981-10-4837-1_23&partnerID=40&md5=f09b2986efe2e59020bcccf3aefa26f6","In target recognition based on high range resolution profile (HRRP), the major challenge is to extract invariant and robust features from the measured high dimension range profile samples. Focused on the reduction of dimensionality, a novel algorithm for extracting HRRP features is proposed in this paper, and the Legendre moments with orthogonal and translation-invariant properties was adopted. The proposed algorithm utilizes the average HRRP in aspect-frame, and then preprocesses the HRRP with amplitude ℓ1 normalization. The Legendre moments are calculated with mapping range values into orthogonal definition domain to provide invariant feature vectors. Meanwhile, spectrum analysis (SA), which can be regard as first-order approximation of relax algorithm, is adopted to reconstruct the real HRRP obtained by inverse fast fourier transform (IFFT) in order to desensitize moments in low SNR environment. Several experiments with four different targets measured data demonstrate that Legendre moments features with flexible maximum order to be chosen have significant advantages over central moments. SA can provide a more robust recognition performance in low signal noise ratio (SNR) environment as 5, dB compared with those of HRRP directly obtained by IFFT. © Tsinghua University Press, Beijing and Springer Nature Singapore Pte Ltd. 2018.","High-resolution range profile (HRRP); Moments feature; Spectrum analysis (SA); Target recognition","Approximation algorithms; Fast Fourier transforms; Image resolution; Signal to noise ratio; Spectrum analysis; First-order approximations; High range resolution profile; High resolution range profiles; Inverse fast Fourier transforms; Moments feature; Reduction of dimensionality; Target recognition; Translation invariant properties; Radar target recognition",2-s2.0-85028331523
"Kaing D., Medsker L.","Competitive hybrid ensemble using neural network and decision tree",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030669103&doi=10.1007%2f978-3-319-67137-6_16&partnerID=40&md5=ecaac6d6d425069629dccdc972c9ef51","A group of experts can offer a more-informed opinion than any individual expert. In machine learning, the ensemble algorithm mirrors this real-world approach by combining predictions of multiple models, yielding higher performance than any individual model. However, having many models does not ensure optimal performance, the challenge is to choose the best set of models that are both diverse and accurate. In this paper, we propose an ensemble model selection algorithm for a hybrid ensemble, called competitive hybrid ensemble (CHE). CHE first creates a population of models, and then ranks the performance of each model on the validation set. From this ranking, CHE assembles the ensemble candidates and evaluates them on the training set. Finally, the best performing candidate is selected as the final hybrid ensemble. We tested our algorithm using neural network and decision tree as the base models. We compared CHE with random forest, a simple hybrid ensemble without the proposed method, and four types of neural network ensembles. Results show that CHE significantly outperforms or is on-par with most of the other methods. © Springer International Publishing AG 2018.","Decision tree; Ensemble; Hybrid; Neural network","Decision trees; Learning systems; Neural networks; Ensemble; Ensemble algorithms; Ensemble modeling; Hybrid; Individual modeling; Neural network ensembles; Optimal performance; Random forests; Data mining",2-s2.0-85030669103
"Khan A., Kim H.S.","Assessment of sensor debonding failure in system identification of smart composite laminates",2018,"NDT and E International",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030998591&doi=10.1016%2fj.ndteint.2017.09.014&partnerID=40&md5=ae11529109586325f6e17c60df5cf931","System identification is an inverse algorithm of developing/improving mathematical representation of a physical system from input-output responses. This paper assessed a mathematical model of smart composite laminate identified with spurious output data due to sensor debonding failure. Improved layerwise theory and higher-order electric potential field were incorporated to develop electromechanically coupled finite element based mathematical model of the smart composite laminate with or without sensor debonding failure. The input-output data of the developed model were fed into the direct system identification algorithm to identify the state-space model of the smart structure. The developed theory was numerically implemented on a 16-layer cross-ply laminate with surface bonded piezoelectric sensor and actuator. Results showed that system identification algorithm misapprehended the true dynamic behavior of the smart structure in the presence of sensor debonding failure. In addition, principal component analysis was used to detect the presence and severity of partial sensor debonding in the identified state-space model. © 2017 Elsevier Ltd","Piezoelectric; Principal component analysis; Sensor debonding failure; Smart composite laminate; System identification","Debonding; Electric potential; Finite element method; Identification (control systems); Laminated composites; Laminates; Piezoelectricity; Religious buildings; State space methods; Debonding failure; Electric potential fields; Improved layerwise theory; Mathematical representations; Piezoelectric; Piezoelectric sensor and actuator; Smart composites; System identification algorithms; Principal component analysis",2-s2.0-85030998591
"Vengadeswaran S., Balasundaram S.R.","Grouping-aware data placement in HDFS for data-intensive applications based on graph clustering",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031398984&doi=10.1007%2f978-981-10-3773-3_3&partnerID=40&md5=615d119ee74c2a4906b1ea4d0db93437","The time taken to execute a query and return the results, increase exponentially as the data size increases, leading to more waiting times of the user. Hadoop with its distributed processing capability can be considered as an efficient solution for processing such large data. Hadoop’s default data placement strategy (HDDPS) places the data blocks randomly across the cluster of nodes without considering any of the execution parameters. Also, it is commonly observed that most of the data-intensive applications show grouping semantics. During any query execution only a part of the big data set is utilized. Since such grouping behavior is not considered, the default placement does not perform well, leading to increased execution time, query latency, etc. Hence an optimal data placement strategy based on grouping semantics is proposed. Initially by analyzing the user history log, the access pattern is identified and depicted as an execution graph. By applying Markov clustering algorithm, grouping pattern of the data is identified. Then optimal data placement algorithm based on statistical measures is proposed, which re-organizes the default data layouts in HDFS. This in turn increases parallel execution, resulting in improved data locality and reduced query execution time compared to HDDPS. The experimental results have strengthened the proposed algorithm and has proved to be more efficient for Big-Data sets to be processed in hetrogenous distributed environment. © Springer Nature Singapore Pte Ltd. 2018.","Big data; Data placement; Graph clustering; Grouping semantics; Hadoop; Interest locality","Clustering algorithms; Data handling; Semantics; Data placement; Data-intensive application; Distributed environments; Distributed processing; Graph clustering; Hadoop; Interest locality; Statistical measures; Big data",2-s2.0-85031398984
"Ahmed A., Arif M., Rizwan A.R., Jabbar M., Ahmed Z., Ullah M.S.","Mainindex sorting algorithm",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029481796&doi=10.1007%2f978-3-319-62521-8_20&partnerID=40&md5=09c85ce829f7fd2f0dd06568d38b2989","Sorting algorithm remained hot topic in computer science from the birth of computer science to achieve maximum performance. Fortunately this achievement became possible due to good and fast sorting algorithms, such as heap sort, merge sort, radix sort and other sorting algorithms. Till this achievement is also under research to find more efficient algorithms. In sorting algorithm arrays and link list data structures are commonly used. We know arrays are efficient if we need consecutive kind of data structure and link lists are useful when we need to add and remove items in the data structure. In other word we can say both data structures have own its merits and demerits. So in our sorting algorithm we are going to use both kinds of data structure. We will use in our MainIndex sorting algorithm arrays as the MainIndex and link list as sorting cells. MainIdex sorting algorithm need some kind of information just the length of the number which is going to sort and the value of the number which is going to sort in sorting cell. © 2018, Springer International Publishing AG.","Bubble sort; Link list; MainIndex; Merge sort; Quick sort; Selection sort; Sorting cell",,2-s2.0-85029481796
"Kim M., Noh S., Hyeon J., Hong S.","Fair-share scheduling in single-ISA asymmetric multicore architecture via scaled virtual runtime and load redistribution",2018,"Journal of Parallel and Distributed Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030086350&doi=10.1016%2fj.jpdc.2017.08.012&partnerID=40&md5=0adc2ccc3e31dec38dbee6c3981cf9f5","Performance-asymmetric multicore processors have been increasingly adopted in embedded systems due to their architectural benefits in improved performance and power savings. While fair-share scheduling is a crucial kernel service for such applications, it is still at an early stage with respect to performance-asymmetric multicore architecture. In this article, we first propose a new fair-share scheduler by adopting the notion of scaled CPU time that reflects the performance asymmetry between different types of cores. Using the scaled CPU time, we revise the virtual runtime of the completely fair scheduler (CFS) of the Linux kernel, and extend it into the scaled virtual runtime (SVR). In addition, we propose an SVR balancing algorithm that bounds the maximum SVR difference of tasks running on the same core types. The SVR balancing algorithm periodically partitions the tasks in the system into task groups and allocates them to the cores in such a way that tasks with smaller SVR receive larger SVR increments and thus proceed more quickly. We formally show the fairness property of the proposed algorithm. To demonstrate the effectiveness of the proposed approach, we implemented our approach into Linaro's scheduling framework on ARM's Versatile Express TC2 board and performed a series of experiments using the PARSEC benchmarks. The experiments show that the maximum SVR difference is only 4.09 ms in our approach, whereas it diverges indefinitely with time in the original Linaro's scheduling framework. In addition, our approach incurs a run-time overhead of only 0.4% with an increased energy consumption of only 0.69%. © 2017 Elsevier Inc.","Fair-share scheduling; Load balancing; Multicore; Performance-asymmetry","Computer operating systems; Embedded systems; Energy utilization; Linux; Resource allocation; Scheduling; Software architecture; Asymmetric multicore; Balancing algorithms; Fair share; Fairness properties; Load redistribution; Multi core; Performance-asymmetry; Scheduling frameworks; Computer architecture",2-s2.0-85030086350
"Quddus M.A., Chowdhury S., Marufuzzaman M., Yu F., Bian L.","A two-stage chance-constrained stochastic programming model for a bio-fuel supply chain network",2018,"International Journal of Production Economics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030783874&doi=10.1016%2fj.ijpe.2017.09.019&partnerID=40&md5=8e5a76db61e3fccb87542c663d6e1d48","This study presents a two-stage chance-constrained stochastic programming model that captures the uncertainties due to feedstock seasonality in a bio-fuel supply chain network. The chance-constraint ensures that, with a high probability, Municipal Solid Waste (MSW) will be utilized for bio-fuel production. To solve our proposed optimization model, we use a combined sample average approximation algorithm. We use the state of Mississippi as a testing ground to visualize and validate the modeling results. Our computational experiments reveal some insightful results about the impact of MSW utilization on a bio-fuel supply chain network performance. © 2017","Bio-fuel supply chain network; Chance-constrained optimization; Multi-modal facility; Sample average approximation","Approximation algorithms; Constrained optimization; Fuels; Municipal solid waste; Optimization; Stages; Stochastic programming; Stochastic systems; Supply chains; Chance-constrained; Chance-constrained optimizations; Computational experiment; Multi-modal; Municipal solid waste (MSW); Optimization modeling; Sample average approximation; Stochastic programming model; Stochastic models",2-s2.0-85030783874
"Zheng W., Du J., Lai J., Liang M., Luo A.","Microblogging event search based on LSTM model",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030866216&doi=10.1007%2f978-981-10-6496-8_26&partnerID=40&md5=72640e7078c22976785dd7fc65e4a98b","With the rapid development of the online social media, microblogging events surveillance has become a major research topic. Traditional search method does not consider the characteristics of the events, the search algorithm has its limitations. To solve this problem, we proposed a microblogging event search method based on Long Short Term Memory (LSTM) networks called MESL. Using training corpus to extract the common characteristics of microblogging events. The establishment of event search model effectively improves the microblogging event search quality. Experimental results on the real microblogging datasets show that MESL model is better than the traditional methods for microblogging event search. © 2018, Springer Nature Singapore Pte Ltd.","Event search; LSTM; Microblogging","Intelligent systems; Social networking (online); Event search; LSTM; Microblogging; Online social medias; Research topics; Search Algorithms; Search quality; Training corpus; Long short-term memory",2-s2.0-85030866216
"Zhen S., Cao D., Jian S.","Modeling and Simulation of Draghead on Trailing Suction Hopper Dredger",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031401652&doi=10.1007%2f978-981-10-3187-8_71&partnerID=40&md5=0c2c42367616c74d72bc1c69b9fda8ee","In this paper, particle filter algorithm is applied to the trailing suction hopper dredger for analyzing drag head parameters. A particle filter is designed in the process of trailing suction hopper dredger for predicting the drag head density. Using the filtering results and measured results to evaluate its performance based on multiple sets of measured data, and the results performed well. The filter has certain help for the development of trailing suction hopper dredger decision support system. © Springer Nature Singapore Pte Ltd. 2018.","Drag head density; Modeling; Particle filter; Simulation; Trailing suction hopper dredger","Artificial intelligence; Computation theory; Decision support systems; Drag; Dredging; Hoppers; Models; Monte Carlo methods; Measured results; Model and simulation; Multiple set; Particle filter; Particle filter algorithms; Performance based; Simulation; Trailing suction hopper dredger; Dredges",2-s2.0-85031401652
"Gorzałczany M.B., Rudziński F.","Time-series-dynamics modeling and forecasting – An accurate and interpretable genetic-fuzzy approach",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029442007&doi=10.1007%2f978-3-319-66824-6_15&partnerID=40&md5=035576353ab37b6e4006619f331217bf","In this paper, we present the application of our fuzzy rule-based modeling technique with genetically optimized accuracy-interpretability trade-off to time-series-dynamics discovery, modeling, and forecasting. The so-called Box-Jenkins’ benchmark, i.e., measurement-based time series describing the behavior of an industrial gas furnace is considered. We employ – as a multi-objective evolutionary optimization algorithm – our generalization – characterized by a higher spread and a better balanced distribution of solutions – of the well-known SPEA2 method. Our approach has been compared with several alternative techniques applied to the same time series data. © 2018, Springer International Publishing AG.","Accuracy-interpretability trade-off optimization; Fuzzy rule-based systems; Multi-objective evolutionary optimization; Time-series-dynamics modeling and forecasting","Dynamics; Economic and social effects; Evolutionary algorithms; Forecasting; Fuzzy inference; Fuzzy rules; Fuzzy sets; Multiobjective optimization; Optimization; Pattern matching; Time series; Fuzzy rule-based models; Genetic fuzzy approach; Interpretability; Measurement-based; Multi-objective evolutionary optimizations; Time series dynamics; Time-series data; Trade off; Fuzzy logic",2-s2.0-85029442007
"Wojtowicz J., Wojtowicz H.","Electrohydrodynamic effect simulation and method of its optimization",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020383513&doi=10.1007%2f978-3-319-59421-7_5&partnerID=40&md5=d58dd8fabc15c1395e3a778b51f5652e","The paper presents an optimization method for electrohydrodynamic effect basing on results of its simulation. The EHD effect is simulated using neural networks and differential equations describing a mathematical model of the phenomenon, which are solved using Runge -Kutta algorithm. The optimization of this effect allows finding for particular input parameters of the generator an optimal diameter of the wire, which burned in a thermo-physical process gives a maximal energy release in the form of an acoustic pressure wave. © Springer International Publishing AG 2018.","Electrohydrodynamic effect; Neural networks; Optimization","Differential equations; Neural networks; Optimization; Runge Kutta methods; Acoustic pressures; Electrohydrodynamic effects; Energy release; Input parameter; Optimal diameters; Optimization method; Physical process; Runge-Kutta algorithms; Electrohydrodynamics",2-s2.0-85020383513
"Shaikh A.M., Shah P.D.","Extended BB84 protocol using lucas series and identity based encryption",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028391995&doi=10.1007%2f978-3-319-63673-3_10&partnerID=40&md5=b1358d68aeba8f4b56548b6ef358fb71","In 1984 Bennett and Brassard proposed a Quantum Key Distribution (QKD) protocol known as BB84 protocol to distribute a random and frequently changed key using quantum mechanism. A major problem in this Protocol is to prove authentication. One of a solution of this problem has already been proposed in [4]. But in presence of Hardware Fault or Interception, above protocol is not applicable. In This paper Proposed System, Key Distillation has been added to overcome Hardware Fault or Interception with minor changes were not available in [4] and was available in original algorithm. It may increase performance of the Proposed System. © 2018, Springer International Publishing AG.","BB84; Hybrid key; Identity key; Quantum key distribution (QKD)","Cryptography; Distillation; Hardware; Intelligent systems; BB84; BB84 protocol; Hardware faults; Hybrid key; Identity Based Encryption; Identity key; Original algorithms; Quantum key distribution protocols; Quantum cryptography",2-s2.0-85028391995
"Bieńkowski R., Leśniewski K., Radziszewska W.","Spatial data analysis in archaeology: Computer-aided selection of priority location for archaeological survey",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031397219&doi=10.1007%2f978-3-319-65545-1_21&partnerID=40&md5=0be7ff017ac2d8199560327f528119cb","The article describes a method to help experts selecting the most probable locations of settlements inhabited by the people in Crete under the Venetian rule (1204–1669). The method ranks the possible location in the designated area based on a set of criteria, but also considering the natural obstacles, e.g. terrain. This multi-criteria task is solved using a modification of the Bellman-Ford algorithm for each criteria and then combining them using weighted sum. The explanation is supported by a small test case. © Springer International Publishing AG 2018.",,"Behavioral research; Decision making; Decision support systems; Fuzzy sets; Location; Surveys; Archaeological surveys; Area-based; Bellman-Ford algorithms; Computer aided; Multi-criteria; Spatial data analysis; Test case; Weighted Sum; Computer aided analysis",2-s2.0-85031397219
"Gusev M., Ristovski A., Guseva A.","Pattern recognition of a digital ECG",2018,"Advances in Intelligent Systems and Computing",3,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021133120&doi=10.1007%2f978-3-319-68855-8_9&partnerID=40&md5=34146a34d9c48220524c09e84ab9b40e","The process of assisted ECG diagnosing mimics the way a medic would act upon. Such a process inevitably comprises the feature extraction step, when the standard ECG signal components: the QRS complex, the P wave and T wave are detected. Using a pattern recognition algorithm for the purpose is one of the available options. In this article, the pattern recognition approach for the feature extraction routine is explained by analysis of consecutive steps and its effectiveness is discussed in comparison to other means of QRS complex detection. © Springer International Publishing AG 2018.","Pattern recognition; Performance engineering; QRS detection","Biomedical signal processing; Cognitive systems; Complexation; Electrocardiography; Extraction; Feature extraction; Seismic waves; Digital ECG; ECG signals; P waves; Pattern recognition algorithms; Performance engineering; QRS complex detection; QRS complexes; QRS detection; Pattern recognition",2-s2.0-85021133120
"Fanti M.P., Mangini A.M., Pedroncelli G., Ukovich W.","A decentralized control strategy for the coordination of AGV systems",2018,"Control Engineering Practice",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032438242&doi=10.1016%2fj.conengprac.2017.10.001&partnerID=40&md5=f14edab887c3d6824ec6b75489822a88","This paper deals with the complex problem of controlling and coordinating Autonomous Guided Vehicles (AGV) by a decentralized approach. Each AGV selects its route by a consensus algorithm based on some Integer Linear Programming problem solutions. Moreover, the AGVs move inside a zone-controlled guidepath network and coordinate their movements by a decentralized protocol based on a zone-controlled approach, which guarantees the avoidance of deadlocks and collisions. The proposed decentralized strategy is applied to a guidepath network by means of a simulation software. © 2017 Elsevier Ltd","Autonomous guided vehicles; Consensus algorithms; Deadlock avoidance; Decentralized control; Integer linear programming","Computer software; Decentralized control; Integer programming; Transportation; Autonomous guided vehicles; Complex problems; Consensus algorithms; Deadlock avoidance; Decentralized approach; Decentralized protocols; Integer Linear Programming; Simulation software; Automatic guided vehicles",2-s2.0-85032438242
"Zhang H., Watada J.","Building fuzzy variance gamma option pricing models with jump levy process",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020452162&doi=10.1007%2f978-3-319-59424-8_10&partnerID=40&md5=4e6a5ce7c9192097c13ab05c3830b5dd","Option pricing models are at core of financial area, and it includes various uncertain factors, such as the randomness and fuzziness. This paper constructs an jump Levy process by combining option pricing models with fuzzy theory, and it sets the drift, diffusion and trend terms as fuzzy random variable. Then, we adopts a Monte Carlo algorithm for numerical simulation, compares and analyses the variance gamma (VG) option pricing model through a simulation experiment, and determines the VG option pricing model and BS model pricing results. The results indicate that VG option pricing with fuzzy settings is feasible. © Springer International Publishing AG 2018.","European-style option; Fuzzy random variable; Levy process; Monte Carlo simulation","Costs; Electronic trading; Financial markets; Fuzzy set theory; Fuzzy systems; Intelligent systems; Monte Carlo methods; Random processes; Random variables; European-style option; Fuzzy random variable; Fuzzy settings; Levy process; Monte carlo algorithms; Option pricing; Option pricing models; Uncertain factors; Economics",2-s2.0-85020452162
"Cichy A., Sakowicz B., Kaminski M.","Detailed model for calculation of life-cycle cost of cable ownership and comparison with the IEC formula",2018,"Electric Power Systems Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029782470&doi=10.1016%2fj.epsr.2017.09.009&partnerID=40&md5=9d7a35243912078e0f18b224979057ab","The purpose of this paper is to validate the model for the selection of the optimal power cable conductor cross section presented in the IEC Standard 60287-3-2. To this end, a detailed model for the calculation of the life-cycle cost of cable ownership is presented. The formula takes into account both the material and labor costs in the production of a power cable as well as the cost of losses during its operation. Since the formula is fairly complex, a genetic algorithm is proposed to solve the optimization problem. A real-life numerical example is presented. © 2017 Elsevier B.V.","Economic optimization; Genetic algorithms; High-voltage power cables; Optimal conductor size","Cables; Compensation (personnel); Costs; Genetic algorithms; Optimization; Standards; Telecommunication cables; Wages; Detailed modeling; Economic optimization; High voltage power cables; IEC standards; Lifecycle costs; Optimal conductor size; Optimal power; Optimization problems; Life cycle",2-s2.0-85029782470
"Rungtaveesak M., Chartkajekaew N., Thongthavorn T., Narongkhachavana W., Prabhavat S.","A dynamic routing for load distribution in mobile Ad-Hoc network",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022177147&doi=10.1007%2f978-3-319-60663-7_22&partnerID=40&md5=78e2eb4c25e4fe833ee3d11c4659e3f2","Mobile Ad Hoc Network is a group of mobile nodes which can communicate with each other directly without infrastructure device. Most conventional protocols do not consider energy on route discovery. Route breaks may occur frequently since the energy of some intermediate nodes exhausts. This interrupts the packet forwarding. In this paper, we propose load distribution algorithm based on remaining energy of nodes to prolong network lifetime and load balancing. Simulation results show that our work can increase the number of remaining nodes in the network while maintaining high packet delivery ratio. © Springer International Publishing AG 2018.","AODV; Availability; Load distribution; MANET; Network lifetime","Availability; Dynamic routing algorithms; Electric power plant loads; AODV; Intermediate node; Load distributions; MANET; Network lifetime; Packet delivery ratio; Packet forwarding; Remaining energies; Mobile ad hoc networks",2-s2.0-85022177147
"Pungila C., Negru V.","FAST: A high-performance architecture for heterogeneous big data forensics",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028640008&doi=10.1007%2f978-3-319-67180-2_60&partnerID=40&md5=aff82b3ffab47e203f29770a5fb9acbe","We are presenting a highly-efficient, novel architecture (which we call FAST, or Forensic Analysis of Sensitive Traces) for high-performance big data forensics for heterogeneous systems (CPU and GPU-based). Our model uses a highly-compact storage format of the widely known Aho-Corasick algorithm [1], as well as a partial pruning mechanism to ensure the lowest possible memory footprint, while maximizing throughput performance. We are comparing our performance with classic methods used in data forensics and observe significant memory footprint improvements, as well as massive throughput improvements throughout all stages of big data processing. © 2018, Springer International Publishing AG.","Aho-corasick; Big data; Data forensics; Efficient storage; GPU processing; High performance computing","Data handling; Digital storage; Graphics processing unit; Memory architecture; Soft computing; Aho-Corasick; Aho-Corasick algorithms; Data forensics; GPU processing; High performance architectures; High performance computing; Throughput improvement; Throughput performance; Big data",2-s2.0-85028640008
"Bejuri W.M.Y.W., Mohamad M.M., Radzi R.Z.R.M., Salleh M., Yusof A.F.","Adaptive resampling for emergency rescue location: An initial concept",2018,"Lecture Notes in Electrical Engineering",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022203930&doi=10.1007%2f978-981-10-5281-1_30&partnerID=40&md5=b613fd351dbd33701209808c72e74ade","The different of memory specification mobile devices or smart phone make it hard for developer to establish a resampling in emergency rescue location for specific smart phone. It took much time for developer to develop it. In this paper, we will introduce a good solution for developer to develop a resampling algorithm for different mobile devices or smart phone. The proposed resampling can adapt memory specification of mobile device in order to determine which suitable resampling operation or function for specific mobile device. As overall, the paper just present a concept that can be used as a guideline to develop a flexible resampling. © Springer Science+Business Media Singapore 2018.","Memory consumption; Particle filter; Resampling; Sequential implementation","Smartphones; Specifications; Telephone sets; Wireless telecommunication systems; Adaptive resampling; Emergency rescue; Memory consumption; Memory specification; Particle filter; Resampling; Resampling algorithms; Sequential implementation; Mobile devices",2-s2.0-85022203930
"Martínez Soltero E.G., Lopéz-Franco C., Alanis A.Y., Arana-Daniel N.","Outdoor robot navigation based on particle swarm optimization",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030712288&doi=10.1007%2f978-3-319-67137-6_24&partnerID=40&md5=99799f8beca932ccc268d69fea9e6b5e","This paper presents an approach to perform local navigation in outdoor environments using a bio-inspired algorithm. The proposed approach uses the Particle Swarm Optimization (PSO) to perform the robot navigation. The PSO particles represent a possible new position in the navigation task. The best PSO particle is chosen and is transformed into latitude and longitude values. Finally, given the desired latitude and longitude values a controller is used to move the robot from its current position and orientation to the valid and best PSO particle in each iteration until reaching the goal given in latitude and longitude. © Springer International Publishing AG 2018.","GPS; Mobile robots; Outdoor navigation; Particle swarm optimization","Air navigation; Global positioning system; Iterative methods; Mobile robots; Navigation; Robots; Swarm intelligence; Bio-inspired algorithms; Local navigation; Navigation tasks; New position; Outdoor environment; Outdoor navigation; Position and orientations; Robot navigation; Particle swarm optimization (PSO)",2-s2.0-85030712288
"Du W., Yuan D., Duan X., Wang J., Ma Y., Zhang H.","Development of an interface for volumetric measurement on a ground-glass opacity nodule",2018,"Studies in Computational Intelligence",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020411828&doi=10.1007%2f978-3-319-60170-0_16&partnerID=40&md5=342a543baf1bcb31568322b73b9af83b","Although radiologists easily recognize lung nodules in CT volume data, and then judge their benign or malignant based on the type of lung nodules, some lung nodules also are difficult to be detected because of their size or shape and so on such as ground-glass opacity nodules (GGO). Some features of GGO nodules are necessary because they can help radiologists to recognize benign or malignant of GGO nodules such as to find the boundaries in order to obtain the volume of GGO nodules. However, different radiologists can give different boundaries of GGO nodules depended on radiologists’ personal habits. It was difficult to obtain the boundaries of GGO nodules which were satisfied with all radiologists. This study is to develop an interface to obtain the boundaries of GGO nodules by using expectation–maximization (EM) algorithm (US Cancer Statistics Working Group. United States cancer statistics: 19992012. Incidence and mortalityWeb-based report. Atlanta, GA: US Department of Health and Human Services, CDC, National Cancer Institute, 2015, [1]) and the histogram method as radiologists’ personal habits because the parameters of the EM algorithm and the threshold values of the histogram method can be adjusted. Experimental results showed the proposed interface can obtain the boundaries of GGO nodules as radiologists’ personal habits. This study can reduce the burden of radiologists effectively. © Springer International Publishing AG 2018.",,"Biological organs; Diseases; Glass; Graphic methods; Department of healths; EM algorithms; Ground-glass opacity; Histogram method; Lung nodule; National Cancer Institute; Volumetric measurement; Working groups; Opacity",2-s2.0-85020411828
"Lee D., Lim H., Kim T., Cho H., Kang K.-I.","Advanced planning model of formwork layout for productivity improvement in high-rise building construction",2018,"Automation in Construction",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032501929&doi=10.1016%2fj.autcon.2017.09.019&partnerID=40&md5=be368bd8eb95c5bad1d0dc086daf7542","The recent trend toward irregular shapes in high-rise building construction makes planning formwork layouts a more complex and laborious task that has been mainly conducted by a heuristic method based on the intuitive judgment of formwork engineers. This study suggests a new planning approach integrated with practical software for formwork layout that is optimized for deploying formwork panels around structural obstacles while minimizing manual efforts. The proposed approach uses a harmony search algorithm (HSA); it has demonstrated improvement in work efficiency of formwork and has reduced formwork costs by minimizing both the use of nonstandard panels and the total number of panels. A case verification showed that the proposed planning method provided a 56% decrease in nonstandard panel-covered area with 14.1% lower cost than the previous heuristic approach by a formwork expert. Moreover, the results indicated that HSA was more efficient than the genetic algorithm (GA) in layout planning of formwork panels. The advanced planning method will support formwork engineers and will also contribute to increasing formwork productivity. © 2017","Formwork layout planning; Formwork productivity; Harmony search; High-rise building construction; Optimization model","Construction; Genetic algorithms; Optimization; Productivity; Tall buildings; Formwork; Harmony search; High-rise building constructions; Layout planning; Optimization modeling; Heuristic methods",2-s2.0-85032501929
"Gull K.C., Angadi A.B.","A methodical study on behavior of different seeds using an iterative technique with evaluation of cluster validity",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031414277&doi=10.1007%2f978-981-10-6602-3_7&partnerID=40&md5=6ccbaf2b4a981344b794fce28284131e","Data analysis methods are vital for analyzing the rising colossal scale of high-dimensional data. Today, cluster analysis is a widely known technique applied and universally practised in many research areas. Among ‘n’ different clustering techniques we briefly deal with centroid model, i.e., K-means, which is an iterative clustering technique. The recital of this algorithm is dependent on certain factors, which include the selection of initial centroid and the approach used in performing reckoning from each data point to different cluster centers. Initial pattern considered randomly by K-means algorithm often make the clustering results reach the local optima, i.e., choice of initial seed (pattern) greatly affects the ultimate clusters that results, in terms of inter and intra cluster distances and firmness. In this research paper author experimented the behaviors of different patterns with different distance metrics on k-means. Finally estimated validity check, i.e., cluster division ratios for every distance measure used and patterns considered. The experimental grades showed the maximum cluster parting and observed better cluster quality when chosen the initial seed as per the assumptions made, compared to patterns randomly picked. The pragmatic results were met when tried with different sample set and different k values. Further an addition of automatic detection of ideal initial pattern as mentioned by author statements leads to an additional trait to k-means. © 2018, Springer Nature Singapore Pte Ltd.","Centroid; Cluster analysis; Initial cluster centres (ICC); K-means","Cluster analysis; Clustering algorithms; Automatic Detection; Centroid; Clustering techniques; Data analysis methods; High dimensional data; Initial cluster centres (ICC); Iterative clustering; K-means; Iterative methods",2-s2.0-85031414277
"Jin Z., Wang L., Chang Y.","Clustering XML documents using frequent edge-sets",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032663906&doi=10.1007%2f978-3-319-67071-3_50&partnerID=40&md5=bd2f1103b602d2fc04cc72dc11b1f59f","Clustering of XML documents is a useful technique for knowledge discovery in XML databases. However, the process of clustering XML documents is always time-consuming due to the semi-structured characteristics of the documents. In this paper, we present an efficient clustering algorithm called Frequent Edge-based XML Clustering (FEXC) to cluster XML documents using frequent edge sets. First, we represent XML documents using edge sets, and then discover the frequent edge sets for each document employing a traditional frequent pattern mining approach. Second, for each frequent edge set, we find all the documents containing it, and then compute a measure called entropy overlap, which indicates the document relevance (overlap) with the ones containing all other frequent edge sets. Clustering is then performed using the entropy overlap measure. Third, we perform a merging process which removes redundant clusters, therefore reducing the number of clusters. Experimental results show that our proposed method outperforms the traditional distance-based XML clustering algorithm in terms of efficiency without compromising the quality of clustering. © 2018, Springer International Publishing AG.","Clustering; Frequent edge set; Semi-structured data; XML","Entropy; XML; Clustering; Edge-sets; Frequent pattern mining; Merging process; Number of clusters; Overlap measures; Quality of clustering; Semi structured data; Clustering algorithms",2-s2.0-85032663906
"Mehmood K.K., Khan S.U., Lee S.-J., Haider Z.M., Rafique M.K., Kim C.-H.","A real-time optimal coordination scheme for the voltage regulation of a distribution network including an OLTC, capacitor banks, and multiple distributed energy resources",2018,"International Journal of Electrical Power and Energy Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021319550&doi=10.1016%2fj.ijepes.2017.06.024&partnerID=40&md5=f272b3e3668b355e23196f50640a566d","The progression towards smarter grids, incorporating clean energy resources, has increased the integration of distributed generators (DGs) into power distribution networks. The DGs often cause a rise in voltage at their points of common coupling. Ordinary voltage regulation devices such as on-load tap changers (OLTCs) are not capable of addressing these issues adequately without careful coordination with DGs. In this paper, a new supervisory control and data acquisition-based two-stage voltage control scheme for the coordination of an OLTC transformer, capacitor banks (CBs) and the DGs is presented. The proposed scheme sets forth a new criterion for the selection of tap positions of an OLTC. In the first stage, tap positions of the OLTC are changed optimally using the micro genetic algorithm, whereas in the second stage, a recursive genetic algorithm is run to minimise the power losses in order to find the optimal reactive powers for the distribution network. Stochastic modelling of wind speed and solar irradiance data is also performed. The scheme is verified by studying it under four different test cases. An OLTC, CBs, photovoltaic panels, wind power DGs and dispatchable DGs are installed in the distribution network, and an IEEE 37-node test feeder is used for the verification of the proposed scheme. The simulation results show that the scheme achieves the objective of voltage regulation. © 2017 Elsevier Ltd","Distributed generation; Radial distribution networks; Reactive power optimisation; SCADA; Smart grid; Voltage regulation","Distributed power generation; Electric circuit breakers; Electric power distribution; Electric power transmission networks; Energy resources; Genetic algorithms; Optimization; Photovoltaic cells; Reactive power; Stochastic control systems; Stochastic systems; Voltage control; Voltage regulators; Wind power; Distributed Energy Resources; Distributed generator (DGs); Power distribution network; Power optimisation; Radial distribution networks; SCADA; Smart grid; Supervisory control and data acquisition; Smart power grids",2-s2.0-85021319550
"Ni A., Lin X., Luo J.","Stochastic traffic assignment model considering park & ride network and travel time reliability",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026765574&doi=10.1007%2f978-981-10-3551-7_70&partnerID=40&md5=59ce08c203a65929dc16fc3571b4f103","Most existing state-of-the-art combined-modal traffic assignment models seldomly consider the influence of travel time reliability on travel behaviors. In order to reveal the influence of travel time reliability on travelers’ route and mode choice behaviors, this paper constructs a combined inter-modal assignment model based on travel time reliability, which takes travel time and travel time reliability jointly constitute travel cost. The solution is then designed based on K-shortest paths algorithm coupled with successive average method. The validation of the proposed model and algorithm of solution are conducted using a real road network of Shanghai North Bund. The results are compared with that of the traditional models without consideration of the impact of travel time reliability. In addition, this research analyzes the effect of P&R policy on reducing traffic congestion as well as improving travel time reliability and demonstrates the three-dimensional relationship among the proportion of travel demand using two alternative modes, reliability preference factor and travel demand utility factor. © Springer Science+Business Media Singapore 2018.","Combined-modal; Elastic demand; Stochastic traffic assignment; Travel time reliability","Highway traffic control; Intelligent systems; Intelligent vehicle highway systems; Motor transportation; Reliability; Stochastic models; Stochastic systems; Traffic control; Transportation; Travel time; Combined-modal; Elastic demand; Model and algorithms; Stochastic traffic assignments; Successive average method; Traditional models; Traffic assignment models; Travel time reliability; Traffic congestion",2-s2.0-85026765574
"Caliskan A., Yuksel M.E., Badem H., Basturk A.","Performance improvement of deep neural network classifiers by a simple training strategy",2018,"Engineering Applications of Artificial Intelligence",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030685135&doi=10.1016%2fj.engappai.2017.09.002&partnerID=40&md5=e751db39bfea4d9d5a72caa91249280b","Improving the classification performance of Deep Neural Networks (DNN) is of primary interest in many different areas of science and technology involving the use of DNN classifiers. In this study, we present a simple training strategy to improve the classification performance of a DNN. In order to attain our goal, we propose to divide the internal parameter space of the DNN into partitions and optimize these partitions individually. We apply our proposed strategy with the popular L-BFGS optimization algorithm even though it can be applied with any optimization algorithm. We evaluate the performance improvement obtained by using our proposed method by testing it on a number of well-known classification benchmark data sets and by performing statistical analysis procedures on classification results. The DNN classifier trained with the proposed strategy is also compared with the state-of-the-art classifiers to demonstrate its effectiveness. Our classification experiments show that the proposed method significantly enhances the training process of the DNN classifier and yields considerable improvements in the accuracy of the classification results. © 2017 Elsevier Ltd","Autoencoder; Deep learning; Deep neural network; Limited memory BFGS; Softmax classifier; Stacked autoencoder","Benchmarking; Classification (of information); Deep learning; Learning systems; Optimization; Auto encoders; Classification performance; Classification results; Internal parameters; Limited memory bfgs; Neural network classifier; Optimization algorithms; Science and Technology; Deep neural networks",2-s2.0-85030685135
"Yongfei Y., Minghe L., Xinghua S., Xiao Z.","A security reactive routing strategy for Ad Hoc network",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031427028&doi=10.1007%2f978-981-10-3187-8_36&partnerID=40&md5=c6b19b9e3e473e973bf34bd9019035c9","Routing protocol algorithm is the basis for establishing a communication link between nodes, and its performance affects the survival of Ad Hoc networks directly. If the malicious node control network communication link, it will launch a variety of attacks, in order to achieve the purpose of stealing network data or destroy the network environment. Considering the weak security of traditional reactive routing protocol in Ad Hoc network, a secure strategy is proposed to resist the attack behavior. The secure reactive routing strategy consists of two parts, the routing request and the routing response. The route establishment based on the successful authenticated for relevant nodes, and then the data is encrypted and transmitted. The algorithm is combined with the identity authentication, hash function, public key encryption and other security strategy, reduce the control probability for the routing information by malicious nodes effectively, and ensure the data communication between the source node and the destination node can be on a safe and reliable route. © Springer Nature Singapore Pte Ltd. 2018.","Ad Hoc networks; Distributed CA; Hash chain; Identity authentication; Secure reactive routing strategy","Ad hoc networks; Authentication; Computation theory; Cryptography; Hash functions; Internet protocols; Network protocols; Network routing; Public key cryptography; Routing algorithms; Routing protocols; Hash chains; Identity authentication; Network environments; Public-key encryption; Reactive routing; Reactive routing protocol; Routing information; Security strategies; Network security",2-s2.0-85031427028
"Chen J., Yuan S., Qiu L., Wang H., Yang W.","On-line prognosis of fatigue crack propagation based on Gaussian weight-mixture proposal particle filter",2018,"Ultrasonics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032002302&doi=10.1016%2fj.ultras.2017.07.016&partnerID=40&md5=b07e3f019f2671804dc7f42cb2709792","Accurate on-line prognosis of fatigue crack propagation is of great meaning for prognostics and health management (PHM) technologies to ensure structural integrity, which is a challenging task because of uncertainties which arise from sources such as intrinsic material properties, loading, and environmental factors. The particle filter algorithm has been proved to be a powerful tool to deal with prognostic problems those are affected by uncertainties. However, most studies adopted the basic particle filter algorithm, which uses the transition probability density function as the importance density and may suffer from serious particle degeneracy problem. This paper proposes an on-line fatigue crack propagation prognosis method based on a novel Gaussian weight-mixture proposal particle filter and the active guided wave based on-line crack monitoring. Based on the on-line crack measurement, the mixture of the measurement probability density function and the transition probability density function is proposed to be the importance density. In addition, an on-line dynamic update procedure is proposed to adjust the parameter of the state equation. The proposed method is verified on the fatigue test of attachment lugs which are a kind of important joint components in aircraft structures. © 2017 Elsevier B.V.","Fatigue crack propagation prognosis; Guided wave; Mixture proposal; On-line crack monitoring; Particle filter","Aircraft manufacture; Airframes; Bandpass filters; Crack propagation; Cracks; Environmental technology; Equations of state; Fatigue crack propagation; Fatigue testing; Fighter aircraft; Guided electromagnetic wave propagation; Mixtures; Monte Carlo methods; Probability; Crack monitoring; Environmental factors; Importance densities; Particle degeneracy; Particle filter; Particle filter algorithms; Prognostics and health managements; Transition probabilities; Probability density function",2-s2.0-85032002302
"Chauhan R.P.S., Dwivedi R., Asthana R.","A high-speed image fusion method using hardware and software co-simulation",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028383625&doi=10.1007%2f978-3-319-63673-3_6&partnerID=40&md5=5b6d7d8a8b8c021eff9dc4f56ef6df2b","The process of adding significant information of two source images obtained from various sources into one image is called image fusion. Large volumes of data informations are obtained from various remote sensors. These informations are useful for image diagnosis through image fusion. Thus image fusion is the promising area of research. Many methods of image fusion have been suggested by the previous authors to produce a fused image having higher spatial resolution, but due to large amounts of data calculations, it is a time-consuming process. Therefore, a reconfigurable hardware system having high speed such as Field-programmable Gate Array (FPGA) is used for solving complex algorithm with reduced computation time to achieve parallel operation with high-speed characteristics. This paper describe the design and implementation of improved speed discrete wavelet transform based multisensor image fusion process with its implementation on hardware. MATLAB 2016a Simulink tools are used to integrate the Xilinx System generator with averaging method for image fusion. Algorithm design has been synthesized in Xilinx ISE 14.1and the same is implemented on ML 605 Virtex-6 FPGA kit. From the result, it is observed that the design consumes a total power of 4.36, W and operates at a maximum frequency of 851. 06, MHz. © 2018, Springer International Publishing AG.","DWT; Field programmable gate array (FPGA); Image fusion; Xilinx system generator (XSG)","Computer hardware; Computer software; Data fusion; Discrete wavelet transforms; Field programmable gate arrays (FPGA); Hardware; Image processing; Integrated circuit design; Intelligent systems; Logic gates; Logic Synthesis; MATLAB; Reconfigurable hardware; Remote sensing; Wavelet transforms; Complex algorithms; Design and implementations; Hardware and software; Large amounts of data; Multisensor image fusion; Parallel operations; Xilinx system generator; Xilinx system generators (XSG); Image fusion",2-s2.0-85028383625
"Dong Y., Pan Z., Kang K., Liu J., Shimamoto S., Wicaksono R.P., Kunishige S., Chang K.","Fairness-aware hybrid resource allocation with cross-carrier scheduling for LTE-U system",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022179041&doi=10.1007%2f978-981-10-5281-1_13&partnerID=40&md5=fbd25b9ce14e94a599ba30069ee3cb3e","Recently, the 3rd Generation Partnership Project (3GPP) proposes to extend the Long Term Evolution Advanced (LTE-A) to the unlicensed spectrum, named Long Term Evolution Unlicensed (LTE-U), which enables LTE to operate in both the licensed band and the unlicensed band. In this paper, we consider how to make LTE-U get even higher throughput in the high traffic unlicensed band. In order to achieve this target, there is a big challenge to make LTE-U a good neighbor to the existing wireless communication technologies in the unlicensed band, such as WIFI system in the 5 GHz band. In our research, we assume two carriers aggregated, one is from licensed band, and the other is from unlicensed. We also define two kinds of frequency resources in the unlicensed band. One is the normal frequency resource that has not been utilized by the WIFI systems, and the other is the special frequency resource that has been utilized by the WIFI systems already. We propose a novel hybrid resource allocation algorithm by combining two different frequency sharing schemes (Underlay and Interweave) and apply different resource allocation algorithm to achieve higher throughput for all kinds of user equipment (UE) from LTE-U when the WIFI system’s traffic is heavy. We also consider the fairness for all UEs from LTE-U system and guarantee that the interference to the WIFI UEs (WUEs) is acceptable. © Springer Science+Business Media Singapore 2018.","Carrier aggregation; Cognitive radio; Fairness; Hybrid; LTE-U; Resource allocation; Unlicensed band","Cognitive radio; Long Term Evolution (LTE); Mobile telecommunication systems; Resource allocation; Ternary alloys; Wireless local area networks (WLAN); 3rd generation partnership project (3GPP); Carrier aggregations; Different frequency; Fairness; Hybrid; Resource allocation algorithms; Unlicensed band; Wireless communication technology; Wireless telecommunication systems",2-s2.0-85022179041
"Dong X., Zhang X., Yi Z., Peng Y.","Incentive mechanism for crowdsensing platforms based on multi-leader stackelberg game",2018,"Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031312219&doi=10.1007%2f978-3-319-66625-9_14&partnerID=40&md5=c9ccddd22abc0a6333b854f9f19064f8","Nowadays, the exponential growth of smartphones creates a potential paradigm of mobile crowdsensing. A sensing task originator accomplishes its sensing data collection work by publishing them on crowdsensing platforms. All the platforms want to attract the task originator to use their services in order to make higher profit. Thus, the issue of competition arises. In this paper, we study the incentive mechanism based on pricing strategy for crowdsensing platforms. We formulate the competition among platforms as a dynamic non-cooperative game and use a multi-leader Stackelberg game model, where platforms are leaders and the task originator is the follower. In the real world, it is difficult for a platform to know the strategies of others. So we propose an iterative learning algorithm to compute its Nash equilibrium. The iterative learning algorithm is that each platform learns from its historic strategy and the originator’s response. Through extensive simulations, we evaluate the performance of our incentive mechanism. © 2018, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.","Crowdsensing; Incentive mechanism; Nash equilibrium; Pricing strategy; Stackelberg game","Computation theory; Game theory; Iterative methods; Crowdsensing; Incentive mechanism; Nash equilibria; Pricing strategy; Stackelberg Games; Learning algorithms",2-s2.0-85031312219
"Chen Y., Hao J.-K.","Two phased hybrid local search for the periodic capacitated arc routing problem",2018,"European Journal of Operational Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021288873&doi=10.1016%2fj.ejor.2017.06.025&partnerID=40&md5=53e028984dabfc562f7ee3de6c4be63a","The periodic capacitated arc routing problem (PCARP) is a challenging general model with important applications. The PCARP has two hierarchical optimization objectives: a primary objective of minimizing the number of vehicles (Fv) and a secondary objective of minimizing the total cost (Fc). In this paper, we propose an effective two phased hybrid local search (HLS) algorithm for the PCARP. The first phase makes a particular effort to optimize the primary objective while the second phase seeks to further optimize both objectives by using the resulting number of vehicles of the first phase as an upper bound to prune the search space. For both phases, combined local search heuristics are devised to ensure an effective exploration of the search space. Experimental results on 63 benchmark instances demonstrate that HLS performs remarkably well both in terms of computational efficiency and solution quality. In particular, HLS discovers 44 improved best known values (new upper bounds) for the total cost objective Fc while attaining all the known optimal values regarding the objective of the number of vehicles Fv. To our knowledge, this is the first PCARP algorithm reaching such a performance. Key components of HLS are analyzed to better understand their contributions to the overall performance. © 2017 Elsevier B.V.","Bi-level optimization; Capacitated arc routing; Constrained combinatorial search; Heuristics","Benchmarking; Computational efficiency; Constrained optimization; Heuristic algorithms; Local search (optimization); Network routing; Vehicles; Arc routing; Bi-level optimization; Capacitated arc routing problem; Combinatorial search; Heuristics; Hierarchical optimization; Local search heuristics; Minimizing the number of; Optimization",2-s2.0-85021288873
"Aggarwal V., Jajoria S., Sood A.","Text retrieval from scanned forms using optical character recognition",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031398822&doi=10.1007%2f978-981-10-6614-6_21&partnerID=40&md5=06214aadc474343f6d5566a1dc7cbddb","This paper investigates the use of image processing techniques and machine learning algorithm of logistic regression to extract text from scanned forms. Conversion of printed or handwritten documents into digital modifiable text is a tedious task and requires a lot of human effort. In order to automate this task, we apply the machine learning algorithm of logistic regression. The main components of this system are (i) text detection from the scanned document and (ii) character recognition of the individual characters in the detected text. In order to complete these tasks, we firstly use the image processing techniques to do line segmentation, character segmentation, and then ultimately character recognition. The character recognition is done by a one-vs-all classifier which is trained using the training data set and learns the parameters with the help of this data set. Once the classifier has learned the parameters, it could identify a total of 39 characters which include capital English alphabets, numerals, and a few symbols. © 2018, Springer Nature Singapore Pte Ltd.","Classifier; Logistic regression; OCR; Segmentation","Artificial intelligence; Classification (of information); Classifiers; Electronic document exchange; Image processing; Image segmentation; Learning algorithms; Learning systems; Optical character recognition; Optical data processing; Regression analysis; Character segmentation; Handwritten document; Image processing technique; Line segmentation; Logistic regressions; Text detection; Text retrieval; Training data sets; Character recognition",2-s2.0-85031398822
"Huang X., Dai W., Zhang Z., Huang Q., Chen Q.","Energy-efficient resource allocation in distributed antenna systems",2018,"Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031293001&doi=10.1007%2f978-3-319-66625-9_10&partnerID=40&md5=c5a1876413eb05ebe422aa2a77dcde61","In this paper, we introduce an energy-efficient resource allocation scheme in distributed antenna systems (DASs). Throughout the paper, the resource allocation includes distributed antenna units (DAU) selection, subcarriers assignment and power allocation. Our aim is to optimize energy efficiency (EE) of the whole system, which is defined as the ratio of total data rate to total consumed power, under the constraints of the overall transmit power of each DAU and minimum required data rate of each user. Due to the mixed combinatorial features of the formulation, we focus on low-complexity suboptimal algorithm design. Firstly, a joint DAU selection and subcarriers assignment algorithm is developed with equal power allocation. Secondly, EE maximization problem is a non-convex fractional programming problem, we transform the problem into a subtractive form, then solve it by using the Lagrangian dual decomposition. The simulation results show the convergence performance, and demonstrate the advantage of the proposed resource allocation scheme compared with the random resource allocation scheme. © 2018, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.","Distributed antenna systems; Energy efficiency; Resource allocation","Antennas; Computational complexity; Mathematical programming; Resource allocation; Convergence performance; Distributed antenna system; Energy-efficient resource allocation; Equal power allocation; Fractional programming; Lagrangian-dual decompositions; Resource allocation schemes; Sub-optimal algorithms; Energy efficiency",2-s2.0-85031293001
"Kumar A., Kumar D., Jarial S.K.","A novel hybrid K-means and artificial bee colony algorithm approach for data clustering",2018,"Decision Science Letters",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019015096&doi=10.5267%2fj.dsl.2017.4.003&partnerID=40&md5=84d0746679eafffcfd271cc59e4ab61c","Clustering is a popular data mining technique for grouping a set of objects into clusters so that objects in one cluster are very similar and objects in different clusters are quite distinct. K-means (KM) algorithm is an efficient data clustering method as it is simple in nature and has linear time complexity. However, it has possibilities of convergence to local minima in addition to dependence on initial cluster centers. Artificial Bee Colony (ABC) algorithm is a stochastic optimization method inspired by intelligent foraging behavior of honey bees. In order to make use of merits of both algorithms, a hybrid algorithm (MABCKM) based on modified ABC and KM algorithm is proposed in this paper. The solutions produced by modified ABC are treated as initial solutions for the KM algorithm. The performance of the proposed algorithm is compared with the ABC and KM algorithms on various data sets from the UCI repository. The experimental results prove the superiority of the MABCKM algorithm for data clustering applications. © 2018 Growing Science Ltd. All rights reserved.","Artificial bee colony; Data clustering; F-measure; K-means; Objective function value; Tournament selection",,2-s2.0-85019015096
"Zhou D., Chen G., Zhang F., Wu G.","A fast inversion free iterative algorithm for solving X + A * X-1A = I",2018,"Journal of Computational Analysis and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027373568&partnerID=40&md5=c31bd6382783d3ca161c24333d3fa0c9","We introduce a new inversion free variant of the basic fixed point iteration method for obtaining a maximal positive definite solution of the nonlinear matrix equation X + A*X-1A = I with A normal. It has fewer operations and matrix-matrix multiplications than the existing algorithms. We derive convergence conditions for the iteration and some numerical results to illustrate the behavior of the new algorithm. © 2018 EUDOXUS PRESS, LLC.","Convergence rate; Fixed point iteration method; Hermitian positive definite solution; Nonlinear matrix equation",,2-s2.0-85027373568
"Koprowski R.","Algorithm sensitivity to parameter changes",2018,"Studies in Computational Intelligence",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024104873&doi=10.1007%2f978-3-319-61340-6_7&partnerID=40&md5=3ac9568a7070e81437165006ef9dfc8b","Assessment of the algorithm sensitivity to parameter changes is a very important element [193–197]. All algorithms, especially as complex as the ones presented here, have some dozens of parameters set manually or automatically. In the case of manual selection of the parameter values, the question arises how their change ranging from 5 to 10% can affect the results obtained. © 2018, Springer International Publishing AG.",,,2-s2.0-85024104873
"Zhang H., Li L.","Facial expression recognition using histogram sequence of local gabor gradient code-horizontal diagonal and oriented gradient descriptor",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031413759&doi=10.1007%2f978-981-10-6499-9_24&partnerID=40&md5=c76afb865658538145daa082a1780218","This paper present a original method for facial expression recognition, which fused with the Gabor filter and Local Gradient Code-Horizontal Diagonal (LGC-HD) as well as Histogram of Oriented Gradient (HOG). This approach firstly is used Viola-Jones algorithm to resize the facial expression image and convolve the facial expression image with Gabor filters to extract the Gabor Coefficients Maps (GCM). Then, we obtain Average Gabor Maps (AGM) by folding GCM of four orientations in each scale to reduce dimensions. The LGC-HD and HOG is applied on each AGM to obtain the LGGC-HD-HOG descriptor. At last, the Support Vector Machine (SVM) is adopted as classifier. We conclude that the method in this paper is better in recognition rate than other similar methods by analyzing the experimental result. © 2018, Springer Nature Singapore Pte Ltd.","Gabor filters; Histogram of oriented gradient; Local gradient code-horizontal diagonal; Support vector machine","Codes (symbols); Gabor filters; Graphic methods; Intelligent systems; Support vector machines; Descriptors; Facial expression recognition; Facial Expressions; Gabor coefficients; Histogram of oriented gradients (HOG); Local gradients; Oriented gradients; Viola - Jones algorithms; Face recognition",2-s2.0-85031413759
"Roy P., Antwi-Boasiako E.","A decision making based authentication scheme in cooperative vehicular ad-hoc network",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022194219&doi=10.1007%2f978-981-10-5281-1_23&partnerID=40&md5=e34c39e803f95f27e69863c5ed6bd7ca","With the growth and advancement in Intelligent Transport Systems comes the comfort and ease of driving at a rapid pace. People are also able to get both information and entertainment services when they are travelling. However, as Intelligent Transportation System (ITS) is becoming popular, the number of attacks on Vehicular Ad-Hoc Network (VANET) has also increased. One of the most important security threats is authenticity since most of the on road decisions are taken on the basis of the messages received. This paper proposes a simple decision making algorithm that helps in determining the authenticity of the occurrence of an incident and thus helping the vehicle under consideration to take decision regarding its future mobility pattern. © Springer Science+Business Media Singapore 2018.","Authentication; VANET","Authentication; Decision making; Intelligent systems; Intelligent vehicle highway systems; Traffic control; Transportation; Wireless telecommunication systems; Authentication scheme; Decision-making algorithms; Entertainment services; Intelligent transport systems; Intelligent transportation systems; Mobility pattern; Security threats; VANET; Vehicular ad hoc networks",2-s2.0-85022194219
"Jena G., Jena S., Rajesh Bonam V.","Image enhancement using FUZZY set",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021400400&doi=10.1007%2f978-3-319-60591-3_13&partnerID=40&md5=c13bc1227f7c584d84f5c05892acd6cf","In this paper, FUZZY set is used to deal with image enhancement problems of some uncertain and inaccurate image. The traditional image enhancement method like histogram modification, image smoothing, image sharpening in verse filters and wiener filter for inaccurate and uncertain image is undesirable. As fuzzy system is capable of representing diverse, non-exact, uncertain and inaccurate knowledge of information, it has attracted the attention of for image enhancement. The generalized enhancement algorithm proposed by Dong Liang Peng and Tie-Jun-Wu in 2002 [1] is not suitable for images having very less gray values, lower contrast, more uncertainly and inaccuracy. A novel approach to generalized image enhancement using fuzzy set is proposed in this paper to overcome the problem. © Springer International Publishing AG 2018.","FE; Fourier; FT; Fuzzy enhancement method; FUZZY set; Gray transformation; GT; Membership; Transform","Fuzzy sets; Human engineering; Iron; Mathematical transformations; Enhancement algorithms; Fourier; Fuzzy enhancement; Gray transformation; Histogram modification; Image sharpening; Image smoothing; Membership; Image enhancement",2-s2.0-85021400400
"Altendorf E., Schütz R., Canpolat Y., Weßel G., Flemisch F.","A study on the human and the automation in automated driving: Getting to know each other",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022346691&doi=10.1007%2f978-3-319-60441-1_65&partnerID=40&md5=2daf1dcb12a541c8472cc4933fb6b33c","In recent years, advanced driver assistant systems (ADAS) and solutions for automated driving have been introduced by several automotive original equipment manufacturers (OEMs) and suppliers. Currently, these types of automation are designed for partially automated driving, but the step towards higher levels of automation can be expected to be made soon. One of the most commonly addressed use cases is driving on a highway such as the German Autobahn. In this paper, we propose an approach for adapting the automation’s behavior to the human’s driving preferences, providing a cognitive automation system with a machine-learning algorithm. This system has been implemented in a simulator for automated driving and has been used in a study addressing conditional automation. Within the presented experiment, typical situations for automated driving under varying conditions have been tested in the driving simulator. During cooperative human-machine driving, the automation can learn the human’s preferences regarding relevant driving states. © Springer International Publishing AG 2018.","Automated driving; Cooperative automation; Cooperative driving; Cooperative guidance and control; Driver-vehicle interaction; Human-systems integration; Humanmachine systems; Machine learning; Neural networks","Automation; Automobile drivers; Automobile manufacture; Behavioral research; Education; Human computer interaction; Human engineering; Learning algorithms; Learning systems; Man machine systems; Neural networks; Automated driving; Cooperative driving; Guidance and control; Human systems integration; Vehicle interactions; Advanced driver assistance systems",2-s2.0-85022346691
"Sabelfeld K.K.","Stochastic projection methods and applications to some nonlinear inverse problems of phase retrieving",2018,"Mathematics and Computers in Simulation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994156495&doi=10.1016%2fj.matcom.2016.08.001&partnerID=40&md5=2a3e6173f68e27ff460afc110f2a3ec4","In this short paper we present a stochastic projection based Monte Carlo algorithm for solving a nonlinear ill-posed inverse problem of recovering the phase of a complex-valued function provided its absolute value is known, under some additional information. The method is developed here for retrieving the step structure of the epitaxial films from the X-ray diffraction analysis. We suggest to extract some additional information from the measurements which makes the problem well-posed, and with this information, the method suggested works well even for noisy measurements. Results of simulations for a layer structure recovering problem with 26 sublayers are presented. © 2016 International Association for Mathematics and Computers in Simulation (IMACS)","Epitaxial layers; Inverse problem; Phase retrieving; Stochastic projections; X-ray diffraction","Epitaxial layers; Stochastic systems; X ray diffraction; X ray diffraction analysis; Complex valued functions; ILL-posed inverse problem; Monte carlo algorithms; Noisy measurements; Non-linear inverse problem; Phase retrieving; Projection method; Stochastic projections; Inverse problems",2-s2.0-84994156495
"Crawford B., Soto R., Cortés E., Astorga G.","A New Thermodynamic Equilibrium-Based Metaheuristic",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029602525&doi=10.1007%2f978-3-319-67618-0_31&partnerID=40&md5=c89ba8c8b920d2021dfb731f851ea316","In this work, a new optimization method inspired on the Thermodynamic Equilibrium is described to address nonlinear problems in continuous domains. In our proposal, each decision variable is treated as the most volatile chemical component of a saturated binary liquid mixture at a determined pressure and temperature. The optimization procedure is started with an initial solution randomly generated. The search is done by changing the equilibrium state of each mixture. The search is carried out by accepting worse solutions to avoid being left trapped in local optimums. The search includes the random change of the mixtures. The algorithm was tested by using known mathematical functions as benchmark functions showing competitive results in comparison with other metaheuristics. © 2018, Springer International Publishing AG.","Combinatorial optimization; Metaheuristics; Single-solution based metaheuristic; Stochastic search methods","Combinatorial optimization; Computational methods; Functions; Heuristic algorithms; Intelligent systems; Liquids; Mixtures; Stochastic systems; Binary-liquid mixtures; Mathematical functions; Meta heuristics; Metaheuristic; Optimization procedures; Pressure and temperature; Stochastic search methods; Thermodynamic equilibria; Optimization",2-s2.0-85029602525
"Dang T.T., Pham H.X., Trinh A.Q., Huynh C., Dinh A.","Wireless footstep counter",2018,"IFMBE Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030838847&doi=10.1007%2f978-981-10-4361-1_27&partnerID=40&md5=7b63a30b3227dadae5142253b9cbbf0b","This paper presents a device, called WiFoCo, to count footsteps by designing a kit using an accelerometer, a seismic sensor, with an adaptive algorithm. First, raw data are calibrated twice to reduce the effect of gravity and noises from environment. Next, adaptive modeling is shown to be an effective means to detect footsteps. Two conditions are implemented for different circumstances, when speed is stable or fluctuates. Finally, the study focuses on the changing rule of acceleration to choose proper parameter values. The result with two parameters—error rate and distance, proves the effectiveness of the counter. This counter is useful for monitoring the motion status of patients, athletes, and people with disabilities because it operates accurately and stably under different types of movement. © Springer Nature Singapore Pte Ltd. 2018.","Accelerometer; Adaptive threshold; Wireless transceiver","Accelerometers; Adaptive algorithms; Biomedical engineering; Adaptive modeling; Adaptive thresholds; Error rate; People with disabilities; Seismic sensor; Two parameter; Wireless transceiver; Radio transceivers",2-s2.0-85030838847
"Zhang C., Nemhauser G., Sokol J., Cheon M.-S., Keha A.","Flexible solutions to maritime inventory routing problems with delivery time windows",2018,"Computers and Operations Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028778557&doi=10.1016%2fj.cor.2017.08.011&partnerID=40&md5=dcbc44bb0f132775538e9d19e5ce9711","This paper studies a Maritime Inventory Routing Problem with Time Windows (MIRPTW) for deliveries with uncertain disruptions. We consider disruptions that increase travel times between ports and ultimately affect the deliveries in one or more time windows. The objective is to find flexible solutions that can accommodate unplanned disruptions. We propose a Lagrangian heuristic algorithm for obtaining flexible solutions by introducing auxiliary soft constraints that are incorporated in the objective function with Lagrange multipliers. To evaluate the flexibility of solutions, we build a simulator that generates disruptions and recovery solutions. Computational results show that by incurring a small increase in initial cost (sometimes zero), our planning strategies generate solutions that are often significantly less vulnerable to potential disruptions. We also consider the effect of lead time in being able to respond to the disruptions. © 2017 Elsevier Ltd","Inventory routing; Lagrangian heuristic; Simulation; Uncertainty","Distribution of goods; Heuristic algorithms; Travel time; Computational results; Delivery time windows; Inventory routing; Lagrangian heuristics; Maritime inventory routing; Objective functions; Simulation; Uncertainty; Lagrange multipliers",2-s2.0-85028778557
"Yuan H., Zheng J., Lai L.L., Tang Y.Y.","Semi-supervised graph-based retargeted least squares regression",2018,"Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025590978&doi=10.1016%2fj.sigpro.2017.07.027&partnerID=40&md5=2b8b7e94eeedebfe0e35fd6d1608ae67","In this paper, we propose a semi-supervised graph-based retargeted least squares regression model (SSGReLSR) for multicategory classification. The main motivation behind SSGReLSR is to utilize a graph regularization to restrict the regression labels of ReLSR, such that similar samples should have similar regression labels. However, in SSGReLSR, constructing the graph structure and learning the regression matrix are two independent processes, which can't guarantee an overall optimum. To overcome this shortage of SSGReLSR, we also propose a semi-supervised graph learning retargeted least squares regression model (SSGLReLSR), where linear squares regression and graph construction are unified into a same framework to achieve an overall optimum. To optimize our proposed SSGLReLSR, an efficient iteration algorithm is proposed. Extensive experiments results confirm the effectiveness of our proposed methods. © 2017 Elsevier B.V.","Graph learning; Multicategory classification; Retargeted least squares regression (ReLSR)","Education; Graphic methods; Iterative methods; Graph construction; Graph learning; Graph structures; Iteration algorithms; Least squares regression; Multi-category classification; Regression matrices; Semi-supervised graphs; Regression analysis",2-s2.0-85025590978
"Jenhani F., Gouider M.S., Said L.B.","Social stream clustering to improve events extraction",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020383090&doi=10.1007%2f978-3-319-59424-8_30&partnerID=40&md5=191e98e899000c24dabe6be6eace4ab8","Events extraction from social media data is a tedious task because of their volume, velocity and informality. In a previous work [25], we proposed a successful approach for events extraction from social data. However, messages were processed individually which generates many meaningless events because of missing details scattered within millions of text segments. In addition, many unnecessary texts were analyzed which increased processing time and decreased the performance of the system. In this paper, we aim to cope with the abovementioned weaknesses and ameliorate the performance of the system. We propose clustering to group semantically-related text segments, filter noise, reduce the volume of data to process and promote only relevant text segments to the information extraction pipeline. We port the clustering algorithm to a stream processing framework namely Storm in order to build a stream clustering solution and scale up to continuously growing volumes of data. © Springer International Publishing AG 2018.","Apache storm; Clustering; Events extraction; Social stream; Twitter","Data mining; Information analysis; Social networking (online); Storms; Clustering; Events extractions; Processing time; Social media datum; Social streams; Stream clustering; Stream processing; Twitter; Clustering algorithms",2-s2.0-85020383090
"Vu L., Kim H., Benson E., Amonette W., Hanson A., Perera J., Rajulu S.","Development of a depth camera-based instructional tool for resistive exercise during spaceflight",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021772018&doi=10.1007%2f978-3-319-60822-8_9&partnerID=40&md5=05c35c474671b067abff9e39691c56aa","Resistive exercise is essential to maintaining proper musculoskeletal health during spaceflight. Therefore crewmembers receive instruction from strength, conditioning, and rehabilitation specialists on proper exercise technique to maximize exercise effectiveness and prevent injuries. However, long duration missions can make real-time exercise instruction and feedback problematic. A depth camera-based software tool was developed to provide exercise instruction and feedback during the deadlift exercise. The software tool uses a machine learning algorithm to identify 5 common deadlift technique mistakes. A subset containing 2 subjects with no deadlift training experience were coached on the deadlift exercise and separated into 2 groups: experimental group using the software tool or a control group without the tool. Motion-capture data were collected to evaluate the kinematic characteristics between the test and control group. It was found that the software tool assisted with increased torso, hip, and knee joint angle consistency and improved form during deadlifts. © Springer International Publishing AG 2018.","Biomechanics; Exercise performance assessment; Motion learning; Virtual coaching","Biomechanics; Cameras; Computer software; Education; Feedback; Human computer interaction; Human engineering; Joints (anatomy); Sports; Experimental groups; Kinematic characteristics; Long duration missions; Motion capture data; Motion learning; Performance assessment; Training experiences; Virtual coaching; Learning algorithms",2-s2.0-85021772018
"Sangeeta, Duhan N.","Collaborative filtering-based recommender system",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031397727&doi=10.1007%2f978-981-10-6602-3_19&partnerID=40&md5=14d2b8514b34c924ab2177b6f0c48f38","Recommender systems have changed the way people find products, information, and services on the web. These kinds of systems study patterns of behavior to know someone’s interest will in a collection of things he has never experienced. Collaborative filtering is a popular recommendation algorithm that works to find user’s interest patterns and recommendations based on the ratings or behavior of other users or target user in the system. The assumption behind this method is to find a user with similar interest to the active user and use his/her preference for recommendation to the active user. But several issues exist in the kind of method. For example, accuracy, sparsity, and cold start. In this paper, an improved recommendation technique is proposed to address the issues identified. © 2018, Springer Nature Singapore Pte Ltd.","Collaborative filtering; Item groups; Recommender systems; Similarity computation","Recommender systems; Cold start; Item groups; Recommendation algorithms; Recommendation techniques; Similar Interests; Similarity computation; Collaborative filtering",2-s2.0-85031397727
"Zhou G., Cheng P.","Research and implementation of multi-objects centroid localization system based on FPGA&DSP",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032679845&doi=10.1007%2f978-3-319-67071-3_56&partnerID=40&md5=a38bdad2c39379f8976e206474c61892","Because of the advantage of centroid localization systembased on FPGA&DSP in machine vision measuring system, Centroid location algorithm for multi-objective is proposed which achieves image histogram in FPGA, computes adaptive threshold based on histogram in DSP, marks the objects in FPGA with modified connected component labeling and then calculates the centroid of the objects. Experimental results shows that the results of Multi-object Centroid Localization System is consistent with the actual results, and the system can run 70 fps in maximum, which is much higher than the processing speed with single DSP or computer. Multi-objects centroid localization system can be applied to machine vision measurement system for its accuracy and real-time. © 2018, Springer International Publishing AG.","Adaptive threshold; Centroid localization; Connected component labeling; FPGA; Histogram","Computer vision; Digital signal processing; Graphic methods; Image processing; Adaptive thresholds; Centroid localization; Connected component labeling; Histogram; Image histograms; Localization system; Location algorithms; Processing speed; Field programmable gate arrays (FPGA)",2-s2.0-85032679845
"Gonçalves R.S., Carvalho J.C.M., Lobato F.S.","Workspace analysis of a parallel manipulator using multi-objective optimization and bio-inspired methods",2018,"Mechanisms and Machine Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031291714&doi=10.1007%2f978-3-319-67567-1_10&partnerID=40&md5=cc3a34313096d1a43f3be93eb9af1a68","In robotic field, manipulators with parallel architecture have inherent advantages in relation to serial manipulators in various applications, such as high stiffness, accurate positioning and high movement velocities. In this context, the determination of volume position is one of the most important aspects considered during the manipulator project because it determines the geometrical limits of task that can be performed. In this contribution, Bio-inspired Optimization Methods (BiOM) are applied to solve a multi-objective problem that considers as objectives the maximization of volume position and the maximization of orientation workspace of CaPaMan (Cassino Parallel Manipulator). The strategy proposed consists in extension of the BiOM to problems with multiple objectives through the incorporation of two operators into the original algorithm: (i) the rank ordering, and (ii) the crowding distance. The results demonstrated that the proposed methodology represents an interesting approach to solve multi-objective problems in the robotic context. © 2018, Springer International Publishing AG.","Bio-inspired optimization methods; CaPaMan; Parallel manipulators; Workspace optimization","Multiobjective optimization; Parallel architectures; Problem solving; Robotics; Bio-inspired methods; Bio-inspired optimizations; CaPaMan; Multi-objective problem; Orientation workspace; Original algorithms; Parallel manipulators; Serial manipulators; Manipulators",2-s2.0-85031291714
"Wang L.-E., Li X.","A graph-based multifold model for anonymizing data with attributes of multiple types",2018,"Computers and Security",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030689561&doi=10.1016%2fj.cose.2017.09.003&partnerID=40&md5=49d8a94e4cdf60bc6f733a094d0b9465","Transactional data with attributes of multiple types may be extremely useful to secondary analysis (e.g., learning models and finding patterns). However, anonymization of such data is challenging because it contains multiple types of attributes (e.g., relational and set-valued attributes). Existing privacy-preserving techniques are not applicable to address this problem. In this paper, we propose a novel graph-based multifold model to anonymize data with attributes of multiple types. Under this model, such data are modelled as a graph, and multifold privacy is guaranteed through fuzzing on sensitive attributes and converting associations among items into an uncertain form. Specifically, we define a multi-objective attack model in a graph and devise a safety parameter and algorithm to prevent such attacks. Experiments have been performed on real-life data sets to evaluate the performance. © 2017 The Author(s)","Anonymization; Data publishing; High-dimensional data; Privacy protection; Transactional data; Uncertain graph","Clustering algorithms; Graphic methods; Anonymization; Data publishing; High dimensional data; Privacy protection; Transactional data; Uncertain graphs; Data privacy",2-s2.0-85030689561
"Repecho V., Biel D., Ramos-Lara R., Vega P.G.","Fixed-Switching Frequency Interleaved Sliding Mode Eight-Phase Synchronous Buck Converter",2018,"IEEE Transactions on Power Electronics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032013719&doi=10.1109%2fTPEL.2017.2662327&partnerID=40&md5=3fc6a078efbb696297e4c1904dc00980","This paper describes the design of an interleaved sliding mode control for a multiphase synchronous buck converter, which inherits the properties of sliding mode control, operates with fixed switching frequency in the steady-state, and ensures current equalization among phases. Moreover, a power management algorithm is added in order to decide the number of active phases as function of the power load demand, thus optimizing the converter efficiency. The system uses a Master-Slave structure where each phase can actuate as the Master one in such a way that the overall system reliability is improved. Experimental results in a 1.5 kW eight-phase synchronous buck converter show that interleaving operation, robust output voltage regulation, phase current equalization, switching frequency regulation, and power management are achieved. © 2017 IEEE.","Chattering reduction; current equalization; fixed switching frequency; interleaving; power management; sliding mode control (SMC)","Energy management; Equalizers; Power converters; Power management; Sliding mode control; Switching; Voltage regulators; Chattering reductions; Fixed switching frequency; Frequency regulations; interleaving; Interleaving operation; Output voltage regulation; Power management algorithms; Synchronous buck converter; DC-DC converters",2-s2.0-85032013719
"Yu H., Ma H., Du H., Li X., Xiao R., Du Y.","Bus Scheduling Timetable Optimization Based on Hybrid Bus Sizes",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029584412&doi=10.1007%2f978-3-319-66939-7_29&partnerID=40&md5=c0d083ee94d09d4bbd341fbdc00e43f3","For bus carriers, it is the most basic and important problem to create the bus scheduling timetable based on bus fleet configuration and passenger flow demand. Considering different technical and economic properties, vehicle capacities and limited available number of heterogeneous buses, as well as the time-space characteristics of passenger flow demand, this paper focuses on creating the bus timetables and sizing the buses simultaneously. A bi-objective optimization model is formulated, in which the first objective is to minimum the total operation cost, and the second objective is to maximum the passenger volume. The proposed model is a nonlinear integer programming, thus a genetic algorithm with self-crossover operation is designed to solve it. Finally, a case study in which the model is applied to a real-world case of a bus line in the city of Beijing, China, is presented. © 2018, Springer International Publishing AG.","Bus timetable; Fleet configuration; Hybrid sizes; Load factor","Artificial intelligence; Bus transportation; Fleet operations; Genetic algorithms; Integer programming; Optimization; Scheduling; Transportation; Bi-objective optimization; Crossover operations; Fleet configuration; Hybrid sizes; Load factors; Non-linear integer programming; Total operation costs; Vehicle capacity; Buses",2-s2.0-85029584412
"Sunil Kumar Reddy T., Naga Raju D., Kumar P.R., Raj Kumar S.R.","Power aware-based workflow model of grid computing using ant-based heuristic approach",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031418431&doi=10.1007%2f978-981-10-6620-7_18&partnerID=40&md5=7a4009a06efe6406c46ec274aa65d541","Grid computing is treated as one of the emerging fields in distributed computing; it exploits the services like sharing of resources and scheduling of workflows. One of the major issues in grid computing is resource scheduling, this can be handled using the ant colony optimization algorithm, and it can be implemented in PERMA-G framework and it is an extended version of our previous work. The ant colony optimization is used to reduce the energy consumption and execution time of the tasks. It follows the nature of ant colony mechanism to compute the total execution time and power consumption of the tasks scheduled dynamically, the experimental results show the performance of the proposed model. © 2018, Springer Nature Singapore Pte Ltd.","Grid scheduling; Pheromone; Power estimation; Power reduction","Ant colony optimization; Artificial intelligence; Big data; Distributed computer systems; Electric power transmission networks; Energy utilization; Heuristic methods; Optimization; Power management; Scheduling; Ant Colony Optimization algorithms; Grid scheduling; Heuristic approach; Pheromone; Power estimations; Power reductions; Resource-scheduling; Workflow modeling; Grid computing",2-s2.0-85031418431
"Cho H.K., Considine J.M., Rammer D.R., Rowlands R.E.","Design of bolted connection in composite beams for moment resistance",2018,"Conference Proceedings of the Society for Experimental Mechanics Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032476439&doi=10.1007%2f978-3-319-63552-1_1&partnerID=40&md5=bb8107bdffb534fced53f182bdbb35e9","Bolted/pinned joints in orthotropic composite materials have received considerable attention over the years. Bolt fastening is one of the most commonly used methods to connect wood to wood and/or wood to steel, etc. Stresses at such connections can be the “Achilles’ heel”, causing structural failures. Notwithstanding the challenges in stress analyzing bolted joints, their advantages and widespread use motivate developing ability to optimize their design. Acknowledging the above, a finite element code is combined here with a screening optimization algorithm to optimize a bolt-hole pattern used to connect orthotropic wood members. A loaded wood beam having four connecting bolt holes at one end is optimized. The ultimate goal is to find optimal hole pattern and/or individual hole position under given load and displacement boundary conditions. © The Society for Experimental Mechanics, Inc. 2018.","Bolted joints; FEA; Hole; Optimization; Orthotropic material; Wood","Biological materials; Bolted joints; Finite element method; Fracture mechanics; Joints (structural components); Mechanics; Optimization; Wood; Developing abilities; Displacement boundary conditions; Finite element codes; Hole; Optimization algorithms; Orthotropic composite materials; Orthotropic materials; Structural failure; Bolts",2-s2.0-85032476439
"Yin X., Ma Y., Liu Q., Su W.","Quality-of-service driven resource allocation via stochastic optimization for wireless multi-user relay networks",2018,"Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031278525&doi=10.1007%2f978-3-319-66625-9_31&partnerID=40&md5=93a6fb7e225821bf96324d410ec07e88","This paper presents a power allocation algorithm for optimizing network resources while considering the delay provisioning in multi-user relay networks. Our aim is to minimize the average power consumed by the relay nodes while satisfying the minimum Qos requirement of all users. Employing the convex optimization theory, we derive an optimal power allocation policy in a quasi-closed form and give two rules of how to select the relay nodes. Furthermore, a stochastic power method is developed to learn the fading state of the channels and carry out the optimal strategy immediately. Moreover, numerical results are provided to demonstrate the performance of the proposed resource allocation policies. © 2018, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.","Convex optimization; Effective capacity; QoS; Resource allocation; Stochastic optimization; Wireless relay networks","Convex optimization; Optimization; Relay control systems; Resource allocation; Site selection; Stochastic systems; Convex optimization theory; Effective capacity; Multi-user relay networks; Optimal power allocation; Power allocation algorithms; Resource allocation policy; Stochastic optimizations; Wireless relay networks; Quality of service",2-s2.0-85031278525
"Guo J., Gao Z., Liu N., Wu Y.","Recommend products with consideration of multi-category inter-purchase time and price",2018,"Future Generation Computer Systems",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014016147&doi=10.1016%2fj.future.2017.02.031&partnerID=40&md5=4dda7798cc632a4ae95a50c4194d0348","This study focuses on diversifying recommendations and improving recommendation accuracy by incorporating multi-category purchase interval and price in a novel way. We suggest a method to model the drift of a user's interest for different categories based on sequential pattern mining. Additionally, we propose a new approach to model personalized multi-category inter-purchase interval for the user. By employing fuzzy set theory, we also put forward an approach to model the price preferences for each user. We propose a recommender system that incorporates the methods mentioned above. The experimental results based on real purchase records show that the proposed recommendation algorithm has high stability and superior performance in recommending products with different characteristics. The results also demonstrate the effectiveness of incorporating purchase interval and price factor in recommender systems. This study demonstrates the existence of particular inter-purchase intervals among different categories, and indicates that price is an important factor influencing customers’ decision making. © 2017 Elsevier B.V.","Multi-category; Price; Purchase interval; Recommender system","Costs; Decision making; Fuzzy set theory; Sales; Inter-purchase time; Multi-category; New approaches; Price; Recommendation accuracy; Recommendation algorithms; Sequential-pattern mining; User's interest; Recommender systems",2-s2.0-85014016147
"Chalise B.K., Himed B.","GLRT Detector in Single Frequency Multi-static Passive Radar Systems",2018,"Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028045773&doi=10.1016%2fj.sigpro.2017.07.001&partnerID=40&md5=b0f4f2bd3b179e20b2144237d4178c2b","The target detection problem in multi-static passive radar systems (MS-PRS) is investigated, where multiple transmitters operate at a single frequency and a single multi-antenna radar receiver processes the received signals. In contrast to multi-frequency MS-PRS, the detector design is challenging due to the fact that the detector sees a mixture of transmitted signals which may not be separately treated. We propose the design of generalized likelihood ratio test (GLRT) receivers to optimize the detection performance. The beamformers at the radar receiver are optimized so that the received signals can be seen as statistically independent signals from multiple reference channels and a surveillance channel. The detector optimization problem is accurately approximated with a convex optimization algorithm. It is analytically shown that the performance of the proposed GLRT receiver approaches that of the active radar. Computer simulations verify the analytical results. © 2017 Elsevier B.V.","Convex optimization; Generalized likelihood ratio test detector; Passive radar systems; Target detection","Convex optimization; Multistatic radars; Optimization; Radar; Radar receivers; Radar signal processing; Target tracking; Tracking radar; Convex optimization algorithms; Detection performance; Generalized Likelihood Ratio Test; Generalized likelihood ratio test receivers; Multi-antenna radars; Multiple transmitters; Optimization problems; Passive radars; Radar systems",2-s2.0-85028045773
"Ritesh M., Ashwani S.","A comparative study of various color texture features for skin cancer detection",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031418670&doi=10.1007%2f978-981-10-6614-6_1&partnerID=40&md5=7aa8de43f6c1d3151be4d2e8f09dccd8","Detection of skin cancer gives the best chance of being diagnosed early. Biopsy method for skin cancer detection is much painful. Human interpretation contains difficulty and subjectivity; therefore, automated analysis of skin cancer-affected images has become important. This paper proposes an automatic medical image classification method to classify two major type skin cancers: melanoma and non-melanoma. In this paper, we have used the color and texture features in combination which gives better results than using color or gray-level information alone. We have used k-means clustering algorithm to segment the lesion. The features are extracted by seven different color texture feature extractors from the segmented images. Classification accuracy of our proposed system is evaluated on four different types of classifiers, and their values are compared with one another. The results of the proposed system are computed on fivefolds of cross-validation in order to perform better analysis of our proposed method. © 2018, Springer Nature Singapore Pte Ltd.","Co-occurrence matrix; Color features; Color percentiles; Cross-validation; Gabor features; Gray-level co-occurrence matrices; Integrative co-occurrence matrix; K-means clustering; Linear classifier; Local binary patterns; NMC classifiers; NN classifiers; Support vector machine; Texture features","Clustering algorithms; Cobalt compounds; Color; Dermatology; Diseases; Image classification; Image segmentation; Medical imaging; Oncology; Support vector machines; Co-occurrence-matrix; Color features; Cross validation; Gabor feature; Gray-level co-occurrence matrix; K-means clustering; Linear classifiers; Local binary patterns; NN classifiers; Texture features; Image processing",2-s2.0-85031418670
"Herman J.D., Giuliani M.","Policy tree optimization for threshold-based water resources management over multiple timescales",2018,"Environmental Modelling and Software",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031504985&doi=10.1016%2fj.envsoft.2017.09.016&partnerID=40&md5=b9f887f1108ad06c668352e2fc9e70f4","Water resources systems face irreducible uncertainty in supply and demand, requiring policies to respond to changing conditions on multiple timescales. For both short-term operation and long-term adaptation, thresholds or “decision triggers” where a policy links observed indicators to actions, have featured prominently in recent studies. There remains a need for a general method to conceptualize threshold-based policies in an easily interpretable structure, and a corresponding search algorithm to design them. Here we propose a conceptual and computational framework where policies are formulated as binary trees, using a simulation-optimization approach. Folsom Reservoir, California serves as an illustrative case study, where policies define the thresholds triggering flood control and conservation actions. Candidate operating rules are generated across an ensemble of climate scenarios, incorporating indicator variables describing longer-term climate shifts to investigate opportunities for adaptation. Policy tree optimization and corresponding open-source software provide a generalizable, interpretable approach to policy design under uncertainty. © 2017 Elsevier Ltd",,"Binary trees; Economics; Flood control; Open source software; Open systems; Reservoirs (water); Software engineering; Computational framework; Conservation actions; Corresponding search algorithms; Indicator variables; Short-term operation; Simulation optimization; Water resources management; Water resources systems; Water resources; adaptive management; conceptual framework; optimization; policy making; threshold; timescale; uncertainty analysis; water management; water planning; water resource; California; Folsom Lake; United States",2-s2.0-85031504985
"Li S., Ren X., Li Y., Qiu H.","Nonlinear tracking control for image-based visual servoing with uncalibrated stereo cameras",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031399211&doi=10.1007%2f978-981-10-6499-9_32&partnerID=40&md5=10ff938bccf79178795a4419fc589c25","This paper considers the problem of uncertain camera pose and camera parameters for a 3-degree-of-freedom (DOF) robot manipulator in nonlinear visual servoing tracking control. To solve this problem, the typical Kalman filter (KF) algorithm is designed to estimate the image Jacobian matrix online, which can reduce the system noises to improve the robustness of the control system. Visual optimal feedback controller is developed to precisely track the desired position of the robot manipulator. In addition, stereo cameras are incorporated into the robot manipulator system such that the tracking errors in both camera image frame and robot base frame can simultaneously converge to zero. Experimental results are included to illustrate the effectiveness of the proposed approach. © 2018, Springer Nature Singapore Pte Ltd.","Image jacobian; Kalman filter; Robot manipulator; Visual servoing","Cameras; Flexible manipulators; Image enhancement; Industrial robots; Intelligent systems; Jacobian matrices; Kalman filters; Modular robots; Navigation; Potassium compounds; Robot applications; Robots; Stereo image processing; Uncertainty analysis; Visual servoing; Image based visual servoing; Image Jacobian; Image jacobian matrix; Kalman filter algorithms; Non-linear tracking control; Robot manipulator; Robot manipulator systems; Tracking controls; Manipulators",2-s2.0-85031399211
"Yuan H., Wu H., Feng D., Gong Y.","Visual tracking via clustering-based patch weighing and masking",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031426603&doi=10.1007%2f978-981-10-3773-3_67&partnerID=40&md5=a93bd4873c59b7d1df5081a591c65cb9","A novel visual tracking method via clustering-based patch weighing and masking is presented in this paper. At initialization stage, we divide the object region defined by the given object bounding box and its surrounding background region into non-overlapping patches, and introduce a robust clustering algorithm to build patch-based object and background models. Then a structure mask is constructed from the discrimination between the object and background models. During tracking, we calculate each pixel’s object probability inside the search region by patch weighing. The best object location is found by maximum a posteriori estimation with dense sampling and structure masking constraint. Experimental results demonstrate that the proposed tracking method is effective and it outperforms several state-of-the-art methods in challenging scenarios. © Springer Nature Singapore Pte Ltd. 2018.","Clustering; Object tracking; Patch weighing; Structure mask","Weighing; Background model; Background region; Clustering; Initialization stage; Maximum a posteriori estimation; Object Tracking; State-of-the-art methods; Visual Tracking; Clustering algorithms",2-s2.0-85031426603
"Tahara A., Hayashida Y., Thu T.T., Shibata Y., Oguri K.","Power performance analysis of FPGA-based particle filtering for realtime object tracking",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026328570&doi=10.1007%2f978-3-319-61566-0_41&partnerID=40&md5=33ab1a740d40c46bade3d64de8cc6fae","Real-time image processing with a compact FPGA-based architecture plays a key role in dynamic state-space models. This paper presents an energy efficient FPGA acceleration architecture of a particle filter, which is based on stream processing structure with a parallel resampling algorithm. Particle filters solve the state estimation problems with three steps: prediction, likelihood calculation and resampling. By accomplishing the resampling in a valid pixel area of an input image frame, while executing prediction in a synchronization region, our approach achieves real-time object tracking. This paper mainly highlights implementation alternatives using different clock frequencies and resource usages of FPGA. The result shows the comparisons of power consumption for the compact architecture with an accelerated clock frequency (135 MHz) compared to the larger circuit size with clock frequency (27 MHz). Interestingly, the larger architecture with a slower clock frequency shows lower power consumption. © Springer International Publishing AG 2018.",,"Clocks; Computer architecture; Distributed computer systems; Electric power utilization; Energy efficiency; Image processing; Monte Carlo methods; Signal filtering and prediction; Target tracking; Compact architecture; Estimation problem; FPGA-based architectures; Lower-power consumption; Real-time image processing; Real-time object tracking; Resampling algorithms; State - space models; Field programmable gate arrays (FPGA)",2-s2.0-85026328570
"Smith H.K., Smith J.P., Glencross D.K., Cassim N., Coetzee L.M., Carmona S., Stevens W.","Siting of HIV/AIDS diagnostic equipment in South Africa: a case study in locational analysis",2018,"International Transactions in Operational Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012932122&doi=10.1111%2fitor.12366&partnerID=40&md5=018a3438fcb1b9061a7f9a33d003b73b","This paper describes a practical application of locational analysis to the siting of HIV/AIDS diagnostic equipment in laboratories across South Africa. Classical location analytical techniques were extended to ensure that laboratories are sited as close as possible to major centers of demand from hospitals and clinics. A particular advantage of the modified set covering algorithm developed is that choices between laboratory sites are made in a transparent manner. In order to find appropriate numbers and ideal placement of CD4 laboratories, runs were undertaken for various scenarios based on maximum travel time from health facilities to laboratory sites. Results demonstrated to decision makers showed close comparisons with pilot review projects undertaken in four health districts of South Africa. The research has potential to impact health-care delivery to HIV sufferers in the poorest rural regions of the country. © 2017 The Authors. International Transactions in Operational Research © 2017 International Federation of Operational Research Societies","combinatorial analysis; developing countries; health service; HIV/AIDS diagnostics; location; point-of-care devices","Decision making; Developing countries; Diseases; Laboratories; Travel time; Combinatorial analysis; Diagnostic equipment; Health facilities; Health services; HIV/AIDS; Maximum travel time; Point of care; Set covering algorithms; Location",2-s2.0-85012932122
"Mircea I.-G., Bocicor I., Czibula G.","A reinforcement learning based approach to multiple sequence alignment",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031413358&doi=10.1007%2f978-3-319-62524-9_6&partnerID=40&md5=504d5afe598fb640653de2bf4cf949ad","Multiple sequence alignment plays an important role in comparative genomic sequence analysis, being one of the most challenging problems in bioinformatics. This problem refers to the process of arranging the primary sequences of DNA, RNA or protein to identify regions of similarity that may be a consequence of functional, structural or evolutionary relationships between the sequences. In this paper we tackle multiple sequence alignment from a computational perspective and we introduce a novel approach, based on reinforcement learning, for addressing it. The experimental evaluation is performed on several DNA data sets, two of which contain human DNA sequences. The efficiency of our algorithm is shown by the obtained results, which prove that our technique outperforms other methods existing in the literature and which also indicate the potential of our proposal. © Springer International Publishing AG 2018.","Bioinformatics; Machine learning; Multiple sequence alignment; Reinforcement learning","Bioinformatics; DNA; DNA sequences; Learning algorithms; Learning systems; Nucleic acids; Soft computing; Comparative genomic; DNA data sets; Evolutionary relationships; Experimental evaluation; Multiple sequence alignments; Primary sequences; Reinforcement learning",2-s2.0-85031413358
"Zelenka J., Kasanický T., Budinská I.","A self-adapting method for 3D environment exploration inspired by swarm behaviour",2018,"Mechanisms and Machine Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028298502&doi=10.1007%2f978-3-319-61276-8_52&partnerID=40&md5=c5d302cbf65c6d37d16bce003a75dec2","A problem of finding an optimal size of a swarm of robots in a way of effective cooperation is not an easy task to solve. There are many factors, which influence the optimal size of the robotic swarm. Among major factors that have to be considered, belong communication, structure of environment and behavior of agents in the swarm. This paper presents a method for creating a decentralized self-adapting swarm of robots. The task is to set an optimal size of the swarm in a role of space exploration. Communication among robots is restricted to communication through the environment. The only way how agents communicate, is through artificial pheromone marks. This fact gives us an ability to create a decentralized algorithm for controlling and coordination of a robotic swarm, which is robust and efective. © 2018, Springer International Publishing AG.","3D space exploration; Biological inspired method; Selt-adaptation; Swarm robotics","Robotics; Robots; Space research; 3-D environments; 3-D space; Biological inspired method; Decentralized algorithms; Selt-adaptation; Space explorations; Swarm of robots; Swarm robotics; Swarm intelligence",2-s2.0-85028298502
"Li X., Xiong C., Guo J., Liu G.","Quantitative deliberation model and the method of consensus building",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026289979&doi=10.1007%2f978-3-319-61566-0_58&partnerID=40&md5=b5e96259fb9b4595c5a3528fda2c0379","Deliberation is an effective method to solve complex problems. Unlike the persuasion and negotiation, deliberation is necessary to consider uncertainty information representation and processing. This paper proposes a quantitative deliberation model (QuDM) based on IBIS. Firstly, the IBIS model is simplified, without considering the specialization and generalization of the issue in the model, and the argument is divided into two parts: the premise and the conclusion. Premise and conclusion are all called statement. Then the uncertainty of argument’s premise and the intensity of argument are expressed by certainty-factors. In order to determine the certainty-factors of positions, a consensus building method is proposed, and the credibility values of all statements are calculated by a recursive algorithm. Finally, an example is used to verify the validity and rationality of the proposed method. © Springer International Publishing AG 2018.",,"Computer programming; Certainty factors; Complex problems; Consensus buildings; Recursive algorithms; Uncertainty informations; Computer science",2-s2.0-85026289979
"Amato F., Cozzolino G., Mazzeo A., Vivenzio E.","Using multilayer perceptron in computer security to improve intrusion detection",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020405125&doi=10.1007%2f978-3-319-59480-4_22&partnerID=40&md5=92d5109729f7d144452b1512c3d0449a","Nowadays computer and network security has become a major cause of concern for experts community, due to the growing number of devices connected to the network. For this reason, optimizing the performance of systems able to detect intrusions (IDS - Intrusion Detection System) is a goal of common interest. This paper presents a methodology to classify hacking attacks taking advantage of the generalization property of neural networks. In particular, in this work we adopt the multilayer perceptron (MLP) model with the back-propagation algorithm and the sigmoidal activation function. We analyse the results obtained using different configurations for the neural network, varying the number of hidden layer sand the number of training epochs in order to obtaina low number of false positives. The obtained results will be presented in terms of type of attacks and training epochs and we will show that the best classification is carried out for DOS and Probe attacks. © Springer International Publishing AG 2018.","Intrusion detection; Machine learning; Multilayer perceptron; Network security; Neural networks","Backpropagation; Backpropagation algorithms; Interactive computer systems; Intrusion detection; Learning systems; Mercury (metal); Multilayer neural networks; Multilayers; Multimedia services; Multimedia systems; Neural networks; Personal computing; Security of data; Common interests; Computer and network security; Generalization properties; Intrusion Detection Systems; Multi layer perceptron; Performance of systems; Sigmoidal activation functions; Training epochs; Network security",2-s2.0-85020405125
"Esparza G.G., de-Luna A., Zezzatti A.O., Hernandez A., Ponce J., Álvarez M., Cossio E., Nava J.J.","A sentiment analysis model to analyze students reviews of teacher performance using support vector machines",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022213747&doi=10.1007%2f978-3-319-62410-5_19&partnerID=40&md5=d2353aec00ce350a726720aea9fcc263","Teacher evaluation is considered an important process in higher education institutions to know about teacher performance and implement constructive strategies in order to benefit students in their education. The opinion of students has become one of the main factors to consider when evaluating teachers. In this study we present a Model called SocialMining using a corpus of real comments in Spanish about teacher performance assessment. We applied Support Vector Machines algorithm with three kernels: linear, radial and polynomial, to predict a classification of comments in positive, negative or neutral. We calculated sensibility, specificity and predictive values as evaluation measures. The results of this work may help other experiments to improve the classification process of comments and suggest teacher improvement courses for teachers. © Springer International Publishing AG 2018.","Performance evaluation; Support vector machines; Teacher performance assessment","Artificial intelligence; Distributed computer systems; Education; Education computing; Students; Support vector machines; Classification process; Evaluation measures; Higher education institutions; Performance assessment; Performance evaluation; Sentiment analysis; Support vector machines algorithms; Teacher evaluations; Teaching",2-s2.0-85022213747
"Bormane D.S., Ohatkar S.N.","Interference minimization for hybrid channel allocation in cellular network with swarm intelligence",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028437261&doi=10.1007%2f978-3-319-63645-0_33&partnerID=40&md5=34ff22d9031c9c7eb732858128b82d67","In the wireless cellular networks in order to deal with irregular and expanding demand, channel must be allocated in such a way that spectrum is used efficiently, capacity is maximized with a minimum level of interference; this problem is called Channel/frequency Allocation Problem. The swarm intelligence category of Heuristic technique, i.e. Particle Swarm Optimization and Ant Colony Optimization for Hybrid Channel Allocation is investigated to find the optimal solution to the minimum interference. The fitness function designed is based on Graph Theory in PSO. The designing of fitness function is the probabilistic model with Sequential packing and ordering technique is explored with ACO. The interference level is represented by edges indicating co-channel and co-site. The signal to interference ratio is measured for Kunz benchmarks and the computation time is obtained. The performance of applied PSO and ACO is compared with the literature reported with Genetic algorithm (GA). © Springer International Publishing AG 2018.","Ant colony optimization; Cellular network; Hybrid channel allocation; Particle swarm optimization; Signal to interference ratio","Ant colony optimization; Artificial intelligence; Cellular radio systems; Computation theory; Genetic algorithms; Graph theory; Heuristic methods; Intelligent systems; Mobile telecommunication systems; Optimization; Swarm intelligence; Wireless networks; Cellular network; Heuristic techniques; Hybrid channel allocations; Interference minimizations; Minimum interference; Probabilistic modeling; Signal to interference ratio; Wireless cellular networks; Particle swarm optimization (PSO)",2-s2.0-85028437261
"Liu Z.-S.","Optimum design and control research of direct drive hub motor",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026624289&doi=10.1007%2f978-3-319-63859-1_31&partnerID=40&md5=8304f744d520cad23deb4418faf6a5ab","Using the improved genetic algorithm (IGA) and according to the characteristics of the hub motor, a novel direct drive outer rotor hub motors which is known as permanent magnet synchronous motor (PMSM) used in vehicle was developed. Aiming to the design requirements, the overall design scheme of the outer rotor hub motor was given, and the main size and the overall electromagnetic structure were analyzed and calculated. By using ANSYS software, the internal electromagnetic field analysis of the machine was made. Finally, applying the direct torque control method on the hub motor (PMSM) based on SPWM through MATLAB/SIMULINK, and the simulation results show that the performance of the prototype designed reasonably. © Springer International Publishing AG 2018.","Direct drive; Hub motor; IGA; PMSM; Simulation","Electromagnetic fields; Genetic algorithms; MATLAB; Multimedia signal processing; Permanent magnets; Signal processing; Torque control; Direct drive; Direct torque control methods; Electromagnetic field analysis; Electromagnetic structure; Hub motors; Permanent Magnet Synchronous Motor; PMSM; Simulation; Synchronous motors",2-s2.0-85026624289
"Ling Y., Zhou J., Nan H., Zhu L., Yin Y.","A shrinkage cavity model based on pressure distribution for Ti-6Al–4V vertical centrifugal castings",2018,"Journal of Materials Processing Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028752509&doi=10.1016%2fj.jmatprotec.2017.08.025&partnerID=40&md5=25e4831ba2592cf5f44dbac7e27f0fdf","Vertical centrifugal castings from Ti-6Al–4V alloy are investigated, with detailed analysis of evolution of isolated liquid volumes and shrinkage location in each isolated liquid volume, in order to predict the shrinkage cavities. Based on the minimum potential energy principle, the shrinkage distribution rule and boundary criterion used in the search algorithm for isolated liquid areas were formulated. The applied boundary criterion estimates the critical pressure, at which an isolated liquid volume can be fed by another one. In each isolated liquid volume, the shrinkage cavities would be distributed at the zero isostatic surface. Pressure values are critical for the proposed shrinkage cavities prediction model, the flowchart and solutions for which are discussed in detail. The proposed model feasibility was verified by a series of the U-type vertical centrifugal casting experiments and simulations on Ti-6Al–4V alloy. © 2017 Elsevier B.V.","Isolated liquid volume; Numerical simulation; Pressure distribution; Shrinkage prediction; Ti-6Al–4V alloy; Vertical centrifugal castings","Centrifugal casting; Centrifugation; Computer simulation; Forecasting; Liquids; Potential energy; Pressure distribution; Shrinkage; Critical pressures; Distribution rule; Liquid volume; Minimum potential energy principle; Search Algorithms; Shrinkage cavities; Shrinkage prediction; Vertical centrifugal castings; Aluminum",2-s2.0-85028752509
"Seeja K.R., Rana J., Priya S., Ahuja L.","A novel edge based image steganography technique",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028588151&doi=10.1007%2f978-3-319-60618-7_7&partnerID=40&md5=e8df9ca631241acf20529a4d6052c6bc","Security of information is one of the important issues of digital communication. Steganography is one of the solutions to ensure secure data transmission over the network. In this paper, a novel secure edge based image steganography technique for 24-bit RGB images has been proposed. The proposed method first encrypts the secret data using encryption algorithm and then the edge pixels of the cover image is used for embedding the encrypted data in the order of strongest to weakest edge pixels depending on message length. To make interception of secret message difficult, XOR between the green component of pixel and mutually decided secret key has been used as location deciding factor among red and blue components of pixel. The performance evaluation shows that with this two level security, the proposed method can protect data from unauthorized access. © Springer International Publishing AG 2018.","Edge pixel; LSB substitution; RGB image; Stegnagraphy","Cryptography; Digital communication systems; Pattern recognition; Pixels; Security of data; Soft computing; Steganography; Digital communications; Edge pixels; Encryption algorithms; Image steganography; LSB substitutions; RGB images; Stegnagraphy; Unauthorized access; Edge detection",2-s2.0-85028588151
"Lai X., Liu L., Li S., Zeleke M., Liu Q., Wang Z.","A non-ordinary state-based peridynamics modeling of fractures in quasi-brittle materials",2018,"International Journal of Impact Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029596235&doi=10.1016%2fj.ijimpeng.2017.08.008&partnerID=40&md5=943ac0d20e1df4737205af2c106f15ae","In this work, we have developed a non-ordinary state-based peridynamics model for brittle fracture in ceramics or fracture in quasi-brittle materials in general. The model is firstly validated by three numerical benchmark tests, and then it is applied to simulate the edge-on impact and drop ball test experiments. We have implemented the modified Johnson Holmquist (JH-2) constitutive damage model into the peridynamics framework at finite strain. Furthermore, the contact algorithm between the projectile and target is discussed. It is shown that the numerical results obtained from peridynamics simulations are in general agreement with those from the experiment. The comparison of experimental and numerical results indicates that the proposed peridynamics model has the ability to capture the damage propagation and other features of the brittle fracture. © 2018","Brittle fracture; Ceramics; Johnson–Holmquist model; Non-local mechanics model; Peridynamics; Quasi-brittle materials","Benchmarking; Brittleness; Ceramic materials; Continuum mechanics; Fracture; Ceramics; Contact algorithms; Damage propagation; Mechanics modeling; Numerical benchmark; Numerical results; Peridynamics; Quasibrittle material; Brittle fracture",2-s2.0-85029596235
"Kotekar S., Sowmya Kamath S.","Enhancing web service discovery using meta-heuristic CSO and PCA based clustering",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032630465&doi=10.1007%2f978-981-10-3376-6_43&partnerID=40&md5=5d926117e878242cae38f5c3f94aafaa","Web service discovery is one of the crucial tasks in service-oriented applications and workflows. For a targeted objective to be achieved, it is still challenging to identify all appropriate services from a repository containing diverse service collections. To identify the most suitable services, it is necessary to capture service-specific terms that comply with its natural language documentation. Clustering available Web services as per their domain, based on functional similarities would enhance a service search engine’s ability to recommend relevant services. In this paper, we propose a novel approach for automatically categorizing the Web services available in a repository into functionally similar groups. Our proposed approach is based on the Meta-heuristic Cat Swarm Optimization (CSO) Algorithm, further optimized by Principle Component Analysis (PCA) dimension reduction technique. Results obtained by experiments show that the proposed approach was useful and enhanced the service discovery process, when compared to traditional approaches. © Springer Nature Singapore Pte Ltd. 2018.","Bio-inspired algorithms; Document clustering; Semantics; Swarm intelligence; Web service discovery",,2-s2.0-85032630465
"Briot S., Goldsztejn A.","Topology optimization of a reactionless four-bar linkage",2018,"Mechanisms and Machine Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026318356&doi=10.1007%2f978-3-319-60867-9_47&partnerID=40&md5=b57bfeb1585d605c6b75c125f162992a","Most of existing works on the optimal design of balanced four-bar linkages deal essentially with the minimization of their inertia or input torques under balancing constraints. These approaches are not suitable to include constraints based on the elastic behavior of the mechanism. In order to solve this issue, we propose in this paper to perform the topology optimization of a reactionless four-bar linkage. Conditions for balancing the mechanism are first recalled and a topology optimization algorithm is run in order to maximize the first natural frequency while ensuring the balancing and constraining the mechanism compliance. We show that in order to obtain an interesting design solution, it is necessary to modify the balancing constraints in order to penalize them. Interesting design solutions are obtained in a rather short computational time. © Springer International Publishing AG 2018.","Four-bar linkage; Optimal design; Shaking force and shaking moment balancing; Topology optimization","Compliant mechanisms; Kinematics; Motion control; Optimal systems; Optimization; Shape optimization; Computational time; Design solutions; Elastic behavior; Four-bar linkage; Optimal design; Optimization algorithms; Reactionless; Shaking moment; Topology",2-s2.0-85026318356
"Roland M., Tjardes T., Dahmen T., Slusallek P., Bouillon B., Diebels S.","Personalized orthopedic trauma surgery by applied clinical mechanics",2018,"Lecture Notes in Applied and Computational Mechanics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028951266&doi=10.1007%2f978-3-319-59548-1_17&partnerID=40&md5=9b5da1e26654edca679817572255846f","In this study, the concept of applied clinical mechanics is used to present first steps in the direction of personalized orthopedic trauma surgery. As example process, a complex distal tibia fracture treated with an implant is chosen. Based on an automated workflow, routinely acquired tomographic data is segmented, assigned with material parameters and extended to an adaptive volume-mesh with hanging nodes. For the finite element simulations, this bone-implant system is equipped with realistic axial loading conditions. An optimization algorithm is then used to analyze the amount of fracture healing that will provide a full weight bearing capacity of the injured extremity in combination with the implant. © Springer International Publishing AG 2018.",,"Bone; Finite element method; Fracture; Optimization; Automated workflow; Bone-implant-system; Distal tibia fracture; Finite element simulations; Fracture healing; Material parameter; Optimization algorithms; Tomographic data; Surgery",2-s2.0-85028951266
"Liu J., Wu C., Wang J.","Gated recurrent units based neural network for time heterogeneous feedback recommendation",2018,"Information Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029707301&doi=10.1016%2fj.ins.2017.09.048&partnerID=40&md5=160bfb8d6aa5b8d2b5b1cf34f789634d","Nowadays, recommender systems face the problem of time heterogeneous feedback recommendation, in which items are recommended according to several kinds of user feedback with time stamps. Previously proposed recurrent neural network based recommendation method (RNNRec) cannot analyze feedback sequences on multiple time scales, and gradient vanishing may occur when the model is trained through back propagation through time (BPTT) algorithm. To address these issues, we propose a gated recurrent units (GRU) based neural network to predict which items users will access in the future. The GRU layer in the model can analyze feedback sequences on multiple time scales and can avoid gradient vanishing during training. The proposed approach is verified on three large-scale real-life datasets, and the comparison indicates that the proposed approach outperforms several state-of-the-art methods. © 2017 Elsevier Inc.","Collaborative filtering; Gated recurrent units; Recommender system; Recurrent neural network; Time heterogeneous feedback","Backpropagation; Backpropagation algorithms; Recommender systems; Recurrent neural networks; Back propagation through time (bptt); Gated recurrent units; Multiple time scale; Real life datasets; Recommendation methods; State-of-the-art methods; Time stamps; User feedback; Collaborative filtering",2-s2.0-85029707301
"Sunil Kumar B.S., Manjunath A.S., Christopher S.","Improvisation in HEVC performance by weighted entropy encoding technique",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021212602&doi=10.1007%2f978-981-10-3223-3_16&partnerID=40&md5=899b33097e6f8b208db6fb6678c39a18","Now a day multimedia applications are growing rapidly and at the same time the volume of video transactions is raising exponentially. This demands an efficient technique to encode the video and to reduce the congestion in the transmission channel. This paper presents an improvisation technique; weighted encoding for High Efficiency Video Coding (HEVC). This method optimizes the spatial and temporal redundancy during the motion compensation by the optimal choice of code block. The blocks are chosen on the basis of weights- assigned to it using the firefly algorithm. On encoding it reduces the size of the video with perceptually better quality video or Peak Signal to Noise Ratio (PSNR). © Springer Nature Singapore Pte Ltd. 2018.","Compression; Encoding; Entropy HEVC; PSNR; Scalable video coding","Codes (symbols); Compaction; Encoding (symbols); Entropy; Intelligent computing; Motion compensation; Optimal systems; Optimization; Signal to noise ratio; Video signal processing; Entropy encoding; Firefly algorithms; High-efficiency video coding; Multimedia applications; Peak signal to noise ratio; PSNR; Spatial and temporal redundancies; Transmission channels; Scalable video coding",2-s2.0-85021212602
"Chen Y., Chen H., Chai R.","A joint bandwidth and power allocation scheme for heterogeneous networks",2018,"Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031293409&doi=10.1007%2f978-3-319-66628-0_26&partnerID=40&md5=f84e83c221965046869b2c3254f959c0","Heterogeneous networks (HetNets) composed of macrocells and small cells are expected to improve the transmission performance of users significantly. In this paper, a joint bandwidth and power allocation scheme is proposed for femto base stations (FBSs) in HetNets. By taking into account bandwidth requirements of femto user equipments and bandwidth resource characteristics of the network, a bankruptcy game based bandwidth resource scheme is proposed for the FBSs, based on which a multi-objective optimization based power allocation scheme is proposed in which the energy efficiency optimization problem of each FBS is formulated respectively and is solved via ideal point method and genetic algorithm. Simulation results demonstrate the efficiency of the proposed scheme. © 2018, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.","Bandwidth allocation; Bankruptcy game; Heterogeneous networks; Multi-objective optimization; Power allocation","Bandwidth; Energy efficiency; Femtocell; Frequency allocation; Genetic algorithms; Multiobjective optimization; Optimization; Bandwidth requirement; Bandwidth resource; Bankruptcy game; Energy efficiency optimizations; Heterogeneous network (HetNets); Ideal point methods; Power allocations; Transmission performance; Heterogeneous networks",2-s2.0-85031293409
"Abdelsadek Y., Chelghoum K., Herrmann F., Kacem I., Otjacques B.","Community extraction and visualization in social networks applied to Twitter",2018,"Information Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030873337&doi=10.1016%2fj.ins.2017.09.022&partnerID=40&md5=edf2b7a3679c25f1030a53b3198dc797","Nowadays, social network analysis attracts more interest from the scientific community. However, it becomes trickier to analyse the generated data by the social networks due to their complexity, which hides the underlying patterns. In this work we propose an approach for social media analysis, especially for Twitter's network. Our approach relies on two complementary steps: (i) a community identification based on a new community detection algorithm called Tribase, and (ii) an interactive community visualization, which provides gradual knowledge acquisition using our visualization tool, called NLCOMS. In order to assess the proposed approach, we have tested it on real-world data of the ANR Info-RSN project. This project is related to information propagation and community detection in Twitter's network, more precisely on a collection of tweets dealing with media articles. The results show that our approach allows us to visually reveal the community structure and the related characteristics. © 2017 Elsevier Inc.","Community detection; Interactive visualization; Social network analysis; Twitter; Visualization tool","Information dissemination; Population dynamics; Social networking (online); Community detection; Community detection algorithms; Community identification; Information propagation; Interactive visualizations; Social media analysis; Twitter; Visualization tools; Visualization",2-s2.0-85030873337
"Lukka S., Shaik R.","A well organized phrase-based document clustering using ASCII values and adjacency list",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028609300&doi=10.1007%2f978-3-319-60618-7_12&partnerID=40&md5=75b027a8a9e2fd0206f977b2139b56b4","Document Clustering is the process of collecting similar kind of documents into one group based on any particular similarity function. Document clustering is also referred as text clustering. Informative features like phrases and their weights are considered to be more important to perform efficient document clustering. This paper mainly deals on two key parts for achieving efficient document clustering. The first part is a phrase based document model named as the Document Adjacency List, it explains about the construction of a phrase based model of the document set. It produces efficient phrase matching which is useful to decide the similarity among the documents. The second part is the document clustering algorithm that is proposed to enhance the Document Adjacency List for clustering based on the similarity measure. The combination of the above two parts leads to better calculation of similarity among documents and similarity further helps to calculate document clustering. © Springer International Publishing AG 2018.","Document adjacency list; Document clustering; Document similarity; Phrase based analysis; Phrase matching","Cluster analysis; Information retrieval; Pattern recognition; Soft computing; Adjacency lists; Document Clustering; Document similarity; Phrase based analysis; Phrase matching; Clustering algorithms",2-s2.0-85028609300
"Ren Z., Li J., Zhu R., Cui K., He Q., Wang H.","Phase-shifting optical fiber sensing with rectangular-pulse binary phase modulation",2018,"Optics and Lasers in Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027526153&doi=10.1016%2fj.optlaseng.2017.08.010&partnerID=40&md5=d9f41647c7054f3b71f8ab5881647c83","We propose and demonstrate a new method of phase-shifting optical fiber sensing, wherein rectangular-pulse binary phase modulation is imposed on the laser source of an interferometric fiber optic sensor to generate three phase-shifting steps of −π/2, 0, and π/2 radians at the output, and the phase shifts that carry the vibration signals are demodulated with an orthogonal demodulation algorithm. This approach offers the advantages of high efficiency and low complexity because it is simple in design and implementation. Moreover, this method can be applied to successfully realize the demodulation of multiplexed systems based on different multiplexing techniques. The techniques are theoretically analyzed and experimentally demonstrated with recovering the sinusoid wave applied to the sensor. Also, in this paper, a simple multiplexed system is proposed and discussed. © 2017","Fiber optic sensors; Multiplexed system; Orthogonal demodulation; Phase modulation; Phase-shifting","Bins; Demodulation; Fiber optic sensors; Fiber optics; Fibers; Modulation; Optical fibers; Optical variables measurement; Phase modulation; Binary phase modulations; Demodulation algorithms; Design and implementations; Interferometric fiber optic sensors; Multiplexed systems; Multiplexing techniques; Optical fiber sensing; Phase-shifting; Optical signal processing",2-s2.0-85027526153
"Wang Z., Bai G., Shen H.","Protecting location privacy through crowd collaboration",2018,"Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031313573&doi=10.1007%2f978-3-319-66625-9_18&partnerID=40&md5=8dbf81fcd211793c9051d96211f2cb6e","Location-based services (LBSs) enable users to sense their surroundings at the risk of exposing coordinates to attackers. Worse yet, a strong adversary with arbitrary knowledges probably derive more privacy especially in continuous query scenarios. To address the problems, a multi-player privacy game mechanism is proposed to satisfy users’ location privacy against adaptive attacks while maximizing utility, building upon which a heuristic algorithm is applied to iteratively converge to the optimal equilibrium point. The gain stems from the collaboration of mobile devices: users share information and forward queries for each other. We evaluate our mechanism against the Bayesian localization attack and maximum possible moving speed attack. The simulations with real map data and mobility traces indicate that our mechanism is effective to preserve privacy at an acceptable price of utility and time complexity. © 2018, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.","Adaptive attack; Inference privacy; Joint differential-distortion privacy; Location-based service; Multi-player privacy game","Encoding (symbols); Error analysis; Heuristic algorithms; Iterative methods; Knowledge based systems; Location; Mobile devices; Mobile telecommunication systems; Telecommunication services; Adaptive attack; Continuous queries; Equilibrium point; Location privacy; Mobility traces; Moving speed; Multi-player privacy game; Time complexity; Location based services",2-s2.0-85031313573
"Mizev A., Shmyrova A., Mizeva I., Pshenichnikova-Peleneva I.","Exhaled breath barbotage: A new method of pulmonary surfactant dysfunction assessing",2018,"Journal of Aerosol Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032802631&doi=10.1016%2fj.jaerosci.2017.10.011&partnerID=40&md5=687dbfece47b51990eacccc08d87a48e","Exhaled air contains submicron droplets of alveolar lining fluid (ALF), which are generated in the small airways of human lungs and are in fact ALF micro-samples. The trapping of these droplets makes it possible to collect a native material from respiratory tract in a non-invasive manner, which holds great promise for lung diagnostics. In this work, we present an aerosol droplet sampling technique based on the exhaled breath barbotage (EBB) procedure. The proposed technique offers a unique opportunity to accumulate pulmonary surfactant (PS), a major constituent of ALF, on a liquid surface. The Wilhelmy plate method was used to measure the variation of the surface pressure over the surface area for the EBB samples collected in a Langmuir trough. A data processing algorithm was derived to evaluate the surface pressure (π) – surface concentration (Γ) isotherm from the raw data. With this algorithm, one can restore the isotherm even in the case when the amount of surfactant adsorbed on the surface is unknown. The (π−Γ) isotherms found for the samples collected in the groups of healthy volunteers and patients with pulmonary tuberculosis were compared with the isotherms obtained for artificial PS. It has been established that the isotherms measured for healthy people and artificial surfactant coincide, and the isotherms obtained in the TB group have lower inclination, which is indicative of a lower surface activity. The EBB method developed in this study can be used as a diagnostic tool for assessment of the functional status of PS in screening tests and subsequent treatment. © 2017 Elsevier Ltd","Exhaled breath barbotage; Pulmonary surfactant sampling; Tensiometry","Air; Data handling; Diagnosis; Drops; Isotherms; Phospholipids; Data processing algorithms; Exhaled breaths; Healthy volunteers; Pulmonary surfactants; Pulmonary tuberculosis; Surface activities; Surface concentration; Tensiometry; Surface active agents",2-s2.0-85032802631
"Wong X.-F., Goi B.-M., Lee W.-K., Phan R.C.-W.","Speeding up the montgomery exponentiation with CMM-SDR over GPU with maxwell and Pascal architecture",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022231821&doi=10.1007%2f978-981-10-5281-1_9&partnerID=40&md5=b0ce4f6ce89567cd7e99a79a31a2efab","RSA is an algorithm widely used in protecting the key exchange between two parties for secure mobile and wireless communication. Modular exponentiation is the main operation involved in RSA, which is very time consuming when the bit-size is large, usually in the range of 1024-bit to 4096-bit. The speed performance of RSA comes to concerns when thousands or millions of authentication requests are needed to handle by the server at a time, through a massive number of connected mobile and wireless devices. The performance of RSA can be improved by utilizing parallel computing architecture or enhancing existing modular exponentiation algorithm. In this paper, we exploit the massively parallel architecture in GPU to perform RSA computations. Various optimization techniques were proposed in this paper to achieve higher throughput in RSA computation in two GPU platforms. Moreover, we also incorporated signed-digit recoding to further improve the performance. To allow a fair comparison with existing implementation techniques, we proposed to evaluate the speed performance in the best case (least ‘0’ in exponent bits), average case (random exponent bits) and worse case (all ‘1’ in exponent bits). The overall throughput achieved by our implementation is about 12% higher in random exponent bits and 50% higher in all 1’s exponent bits compared to the implementation without signed-digit recoding technique. Our implementation is able to achieve 17713 and 89043 1024-bit modular exponentiation per second on random exponent bits in GTX 960 M and GTX 1080, which represent the two state of the art GPU architecture. © Springer Science+Business Media Singapore 2018.","GPU; Montgomery exponentiation; RSA; Signed-digit recoding","Computer architecture; Graphics processing unit; Optimization; Wireless telecommunication systems; Exponentiations; Implementation techniques; Mobile and wireless communication; Modular Exponentiation; Modular exponentiation algorithms; Optimization techniques; Parallel computing architecture; Signed-digit recoding; Parallel architectures",2-s2.0-85022231821
"Juarez F., Ejarque J., Badia R.M.","Dynamic energy-aware scheduling for parallel task-based application in cloud computing",2018,"Future Generation Computer Systems",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85003666406&doi=10.1016%2fj.future.2016.06.029&partnerID=40&md5=a674981d2df0280fb716d55d5ac0ec41","Green Computing is a recent trend in computer science, which tries to reduce the energy consumption and carbon footprint produced by computers on distributed platforms such as clusters, grids, and clouds. Traditional scheduling solutions attempt to minimize processing times without taking into account the energetic cost. One of the methods for reducing energy consumption is providing scheduling policies in order to allocate tasks on specific resources that impact over the processing times and energy consumption. In this paper, we propose a real-time dynamic scheduling system to execute efficiently task-based applications on distributed computing platforms in order to minimize the energy consumption. Scheduling tasks on multiprocessors is a well known NP-hard problem and optimal solution of these problems is not feasible, we present a polynomial-time algorithm that combines a set of heuristic rules and a resource allocation technique in order to get good solutions on an affordable time scale. The proposed algorithm minimizes a multi-objective function which combines the energy-consumption and execution time according to the energy-performance importance factor provided by the resource provider or user, also taking into account sequence-dependent setup times between tasks, setup times and down times for virtual machines (VM) and energy profiles for different architectures. A prototype implementation of the scheduler has been tested with different kinds of DAG generated at random as well as on real task-based COMPSs applications. We have tested the system with different size instances and importance factors, and we have evaluated which combination provides a better solution and energy savings. Moreover, we have also evaluated the introduced overhead by measuring the time for getting the scheduling solutions for a different number of tasks, kinds of DAG, and resources, concluding that our method is suitable for run-time scheduling. © 2016 Elsevier B.V.","Cloud computing; Distributed computing; Energy-aware scheduling; Green computing; Multi-heuristic resource allocation; Task-based applications","Carbon; Carbon footprint; Cloud computing; Computational complexity; Computer resource management; Energy conservation; Energy policy; Energy utilization; Optimization; Polynomial approximation; Polynomials; Power management; Resource allocation; Scheduling; Distributed computing platform; Energy-aware scheduling; Green computing; Polynomial-time algorithms; Reducing energy consumption; Resource allocation techniques; Sequence-dependent setup time; Task-based; Distributed computer systems",2-s2.0-85003666406
"Woo M.W., Lee J., Park K.","A reliable IoT system for Personal Healthcare Devices",2018,"Future Generation Computer Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017546428&doi=10.1016%2fj.future.2017.04.004&partnerID=40&md5=10dd06a83b825217446fe1d36d148b57","Healthcare applications in IoT systems have been receiving increasing attention because they help facilitate remote monitoring of patients. In this paper, we propose a reliable oneM2M-based IoT system for Personal Healthcare Devices. In order to use a Personal Healthcare Device as an Application Dedicated Node in the proposed system, a protocol conversion between ISO/IEEE 11073 protocol messages and oneM2M protocol messages is performed in gateways located between Personal Healthcare Devices and the PHD management server. The proposed oneM2M-based IoT system for Personal Healthcare Device is constructed, and evaluated in various experiments. The experiments show that the protocol conversion performs effectively, and that the conversion process does not cause the system to suffer serious performance degradation, even when the number of Application Dedicated Node is quite large. Some Personal Healthcare Device data is too precious to lose due to system failures under u-healthcare environments. However, until now, few studies have focused on fault-tolerant health data services. Therefore, we also propose a fault-tolerant algorithm for the reliable IoT system in which gateways on the same layer in the system are linked to form a daisy chain for fault tolerance at the level, and a gateway stores the backup copy of the previous gateway positioned immediately ahead of the gateway in the daisy chain. The upper-layered gateway stores the parity data of the daisy chain as well. In this manner, as many as two gateway faults occurred at the same time can be recovered. For experiments, the resource trees of the oneM2M-based IoT system were expanded to store information on daisy chains, backup copies, and parity. Our experiments reveal that the proposed algorithm can recover from faults on gateways in the oneM2M-based IoT system. © 2017 Elsevier B.V.","Daisy chain; Fault-tolerant; IoT; OneM2M; Personal Healthcare Device; u-healthcare","Chains; Fault tolerance; Gateways (computer networks); Health care; Remote patient monitoring; Systems engineering; Fault tolerant algorithms; Fault-tolerant; Health care application; OneM2M; Performance degradation; Personal health care; Protocol conversion; u-Healthcare; Internet of things",2-s2.0-85017546428
"Bose S., Misra I.S.","FPGA-based equalizer design using a novel adaptive reward-punishment VSSLMS algorithm for rayleigh fading channel",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032622084&doi=10.1007%2f978-981-10-3376-6_58&partnerID=40&md5=8d2ca726dc94cfac4dc6df2a8c922bca","In this paper, a new and novel Reward-Punishment-based Variable Step Size Least Mean Square (RP-VSSLMS) algorithm has been proposed and a novel methodology is used to construct a Rayleigh fading channel adaptive equalizer employing the proposed algorithm in hardware domain. As the Rayleigh fading channel reveals the property of real-time wireless communication environment, it is chosen here. The Spartan 6 FPGA board is configured here to model the digital circuitry of the proposed RP-VSSLMS algorithm using a novel “Hardware Co-simulation” technique. The hardware co-simulation analysis showed that, the proposed RP-VSSLMS algorithm has faster convergence speed, smaller steady-state misadjustment, and lesser computational complexity than the existing LMS and VSSLMS algorithms. The performance of the proposed algorithm is observed by calculating the Bit Error Rate (BER) of different modulated signals under Rayleigh Fading channel. © Springer Nature Singapore Pte Ltd. 2018.","8-QAM; Adaptive equalizer; BER; BPSK; LMS; QPSK; Rayleigh fading channel; RP-VSSLMS; Step size; VSSLMS",,2-s2.0-85032622084
"Kanrar S., Chaki N., Chattopadhyay S.","A graph-based mutual exclusion algorithm using tokens",2018,"Studies in Systems, Decision and Control",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028979558&doi=10.1007%2f978-981-10-5559-1_4&partnerID=40&md5=0966206d483614deae5d4ea522065b8a","In some of the earlier works, token-based algorithms for ME are presented for the distributed environment. These are for inverted tree topology. However, such a stable, hierarchical topology is quite unrealistic for many types of networks, e.g., mobile ad-hoc networks (MANET), due to frequent link failures. © Springer Nature Singapore Pte Ltd. 2018.",,,2-s2.0-85028979558
"Kalluri N.V.S.N., Yarlagadda D.V., Sattenapalli S., Bothra L.S.","Erudition of transcendence of service and load scrutinizing of cloud services through nodular approach, rough clairvoyance fuzzy C-means clustering and ad-judicature tactic method",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028440864&doi=10.1007%2f978-3-319-63645-0_60&partnerID=40&md5=f0a34c1485d34a0eb156299875c97e0d","Cloud computing is a facsimile for enabling ubiquitous, on-demand access to a shared pool of configurable reckoning resources which can be rapidly provisioned and released with minimal management effort. The services accorded by cloud are benevolent to many patrons. They are many new fangled ways to exert services of cloud but the prominent thing here is transcendence of service of service exerted by patron and the time spend by the patron for using the service. In cloud computing it is very important that patrons should be able to exert the service with exquisite transcendence and also patron should exert the service that he desires without waiting for long time. So the concept induced in this paper is new-fangled method for forthcoming patrons to exert service of desired transcendence and service which has fewer loads among the services available in cloud. Rough Clairvoyance Fuzzy C-means clustering (RCFCM) algorithm is exerted for clustering the services based on service transcendence by congregating feedback testimony from patrons who exerted the service. This RCFCM algorithm helps in giving testimony to forthcoming patrons regarding service transcendence of services available in cloud. While congregating feedback testimony and storing feedback testimony lot of security, fidelity issues arises, so in this paper decision trait is included therefore only valid feedback testimony from patrons is cogitated. Collateral method provides security while congregating feedback testimony. If patrons know which service transcendence is best then everyone tries to ingress only the services with exquisite transcendence and load of services with exquisite transcendence increases. As load increases again it takes lot of time for the patrons to access the service to solve this load predicament ad-judicature is exerted. Unfeigned and proficient co-conspirators are recruited for accomplishing complex and secure tasks in methodology by using nodular method. Therefore the methods induced in this paper are benevolent for the forthcoming patron’s to gain erudition about services transcendence and to exert desired service by patrons that having less load among available services in cloud so that patrons feel ecstatic and satiated by using the cloud services. © Springer International Publishing AG 2018.","Ad-judicature tactic method; Cloud services; Collateral method; Feedback testimony; Load scrutinizing; Nodular method; RCFCM clustering; Transcendence of service traits","Cloud computing; Distributed database systems; Fuzzy systems; Intelligent systems; Ubiquitous computing; Web services; Ad-judicature tactic method; Cloud services; Collateral method; Nodular method; RCFCM clustering; Transcendence of service traits; Clustering algorithms",2-s2.0-85028440864
"Bazilinskyy P., Beaumont C., Van Der Geest X., De Jonge R., Van Der Kroft K., De Winter J.","Blind driving by means of a steering-based predictor algorithm",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022338337&doi=10.1007%2f978-3-319-60441-1_45&partnerID=40&md5=cda455c5ccfe3fdc79bb5f089f8ab56d","The aim of this work was to develop and empirically test different algorithms of a lane-keeping assistance system that supports drivers by means of a tone when the car is about to deviate from its lane. These auditory assistance systems were tested in a driving simulator with its screens shut down, so that the participants used auditory feedback only. Five participants drove with a previously published algorithm that predicted the future position of the car based on the current velocity vector, and three new algorithms that predicted the future position based on the momentary speed and steering angle. Results of a total of 5 h of driving across participants showed that, with extensive practice and knowledge of the system, it is possible to drive on a track with sharp curves for 5 min without leaving the road. Future research should aim to improve the intuitiveness of the auditory feedback. © Springer International Publishing AG 2018.","Auditory display; Driver support; Driving simulator; Human–machine interface; Road safety","Automobile drivers; Automobile simulators; Human engineering; Roads and streets; Auditory display; Driver support; Driving simulator; Machine interfaces; Road safety; Automobile steering equipment",2-s2.0-85022338337
"Wu S.-J.","Commodities selection of supermarket email-flyers by recommender systems",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031429593&doi=10.1007%2f978-981-10-3187-8_64&partnerID=40&md5=664f08ede124da21d35ebd30eb63c5e4","Traditional physical retail stores often attract customers by sending email-flyers (or promotional electronic Direct Mail, DM). However, most customers will treat electronic DM as junk mail if it includes too many types of commodities or is sent too frequently. To avoid this problem, we propose a recommendation algorithm to select a small and fixed number of commodities for preparing customized electronic DM suitable for a well-known Taiwanese supermarket. Our method first selects a small and fixed number of commodity types that customers will most likely purchase; then, at product level, the method selects one commodity of each commodity type to promotion. Considering the habits of customers have already purchased commodities will buy again, when the recommendation success rate for recommending commodity types (or commodities) reached a certain value, we could replace some commodity types (or commodities) those the customers had already purchased in the last month. Compared to two item-based collaborative filtering approaches, Cosine and Bigram, the experimental results show that our approach has higher recommendation success rate and then increases the possibility of customers back to physical retail stores to purchase. © Springer Nature Singapore Pte Ltd. 2018.","Collaborative filtering; Recommender system; Retailing","Collaborative filtering; Computation theory; Electronic mail; Recommender systems; Retail stores; Sales; Direct mails; Fixed numbers; Item-based collaborative filtering; Junk mails; Most likely; Recommendation algorithms; Retailing; Electronic trading",2-s2.0-85031429593
"Zhang Z.-H., Hu Y., Xiao K., Yuan S., Chen Z.","A rule extraction for outsourced software project risk classification",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031429033&doi=10.1007%2f978-981-10-3773-3_10&partnerID=40&md5=fd6a7d31fc8f42b7fc61f2d92ee03cbd","A rule extraction algorithm based on K-means clustering with interval-valued intuitionistic fuzzy sets (IVIFS) information, which is the combination of K-means clustering and IVIFS, is proposed in this paper. First, we introduce IVIFS and its distance. Second, we introduce IVIFS method and its application to the classification of software project. Finally, we present a rule extraction model according to IVIFS fuzziness and its K-means clustering, and apply them to pattern classification of outsourced software project risk to demonstrate the advantages of this model. The experimental results show that the rules from IVIFS model are better than that from the conventional K-means clustering model in rule extraction, and the prediction effect from the former is more effective than that from the latter. According to this combinational rule extraction method, based on database from a special and professional investigation for Chinese small and medium software-outsourced enterprise, we obtain some valuable, realistic and available project development risks decision rules. © Springer Nature Singapore Pte Ltd. 2018.","Interval-valued intuitionistic fuzzy sets; K-means clustering; Outsourced software project risk; Rule extraction","Application programs; Computer software; Extraction; Fuzzy sets; Interval-valued intuitionistic fuzzy sets; ITS applications; K-means clustering; Project development; Rule extraction; Rule extraction algorithms; Rule extraction method; Software project risks; Risks",2-s2.0-85031429033
"Luo J., Pan R.","Research and implementation of intelligent risk recognition model based on engineering construction of neural network",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028375235&doi=10.1007%2f978-3-319-60744-3_34&partnerID=40&md5=154de509d12075c58588d95508617dfc","Since the reform and opening up, both domestic economy and people’s living level acquire great improvement. People also pay more strong attention to risk issues of on-going engineering projects’ construction. At present, science and technology have stepped onto high-speed development stage and the world is rapidly changing. Uncertainty of social external condition may lead enterprises to encounter more and larger risks during the construction process of engineering projects. Traditional engineering construction risk recognition model can’t already fully and effectively identify risks. Therefore a new type of intelligent risk recognition mode is in urgently needed in construction of engineering projects. This paper proposes a kind of risk recognition model based on neural network so as to intelligently recognize different forms of potential risks, thus decreasing the damage from risks to a minimum. Relevant model below is established according to characteristics of engineering projects on purpose of doing quantitative analysis of risk rating in the engineering construction industry at present. It utilizes Genetic Algorithm to correct network, whose process increases accuracy and stability of all networks. Based on neural network, this paper establishes the model which could do risk rating during the project operation process in the engineering construction industry. It also does classification and research according to characteristics of potential risks in engineering projects, thus helping a project leader to more accurately predict, prevent and control risks, which guarantees safe and smooth operation of engineering projects. © 2018, Springer International Publishing AG.","Intelligent risk recognition model; Neural network; Risk rating; Uncertainty","Construction industry; Genetic algorithms; Intelligent systems; Neural networks; Rating; Real time systems; Risk assessment; Construction process; Engineering construction industries; Engineering constructions; Risk ratings; Risk recognition; Science and Technology; Traditional engineerings; Uncertainty; Risk analysis",2-s2.0-85028375235
"Qiu S., Wang Z., Zhao H., Qin K., Li Z., Hu H.","Inertial/magnetic sensors based pedestrian dead reckoning by means of multi-sensor fusion",2018,"Information Fusion",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018906357&doi=10.1016%2fj.inffus.2017.04.006&partnerID=40&md5=ba5b8e3b469bb5829cab4abc14ea18e8","The challenges of self-contained sensor based pedestrian dead reckoning (PDR) are mainly sensor installation errors and path integral errors caused by sensor variance, and both may dramatically decrease the accuracy of PDR. To address these challenges, this paper presents a multi-sensor fusion based method in which subjects perform specified walking trials at self-administered speeds in both indoor and outdoor scenarios. After an initial calibration with the reduced installation error, quaternion notation is used to represent three-dimensional orientation and an extend Kalman filter (EKF) is deployed to fuse different types of data. A clustering algorithm is proposed to accurately distinguish stance phases, during which integral error can be minimized using Zero Velocity Updates (ZVU) method. The performance of proposed PDR method is evaluated and validated by an optical motion tracking system on healthy subjects. The position estimation accuracy, stride length and foot angle estimation error are studied. Experimental results demonstrate that the proposed self-contained inertial/magnetic sensor based method is capable of providing consistent beacon-free PDR in different scenarios, achieving less than 1% distance error and end-to-end position error. © 2017 Elsevier B.V.","Body sensor network; Inertial/magnetic sensors; Multi-sensor fusion; Pedestrian dead-reckoning","Body sensor networks; Clustering algorithms; Navigation; Extend kalman filters; Multi-sensor fusion; Optical motion tracking; Pedestrian dead reckoning (PDR); Pedestrian dead reckonings; Position estimation; Sensor installation; Three-dimensional orientation; Errors",2-s2.0-85018906357
"Liang L., Wei M., Szymczak A., Petrella A., Xie H., Qin J., Wang J., Wang F.L.","Nonrigid iterative closest points for registration of 3D biomedical surfaces",2018,"Optics and Lasers in Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030830756&doi=10.1016%2fj.optlaseng.2017.08.005&partnerID=40&md5=880f64f1a6590e7112ac5ad3f85ccda6","Advanced 3D optical and laser scanners bring new challenges to computer graphics. We present a novel nonrigid surface registration algorithm based on Iterative Closest Point (ICP) method with multiple correspondences. Our method, called the Nonrigid Iterative Closest Points (NICPs), can be applied to surfaces of arbitrary topology. It does not impose any restrictions on the deformation, e.g. rigidity or articulation. Finally, it does not require parametrization of input meshes. Our method is based on an objective function that combines distance and regularization terms. Unlike the standard ICP, the distance term is determined based on multiple two-way correspondences rather than single one-way correspondences between surfaces. A Laplacian-based regularization term is proposed to take full advantage of multiple two-way correspondences. This term regularizes the surface movement by enforcing vertices to move coherently with their 1-ring neighbors. The proposed method achieves good performances when no global pose differences or significant amount of bending exists in the models, for example, families of similar shapes, like human femur and vertebrae models. © 2017 Elsevier Ltd","Bone; Multiple two-way correspondences; Nonrigid iterative closest points (NICPs); Surface registration","Bone; Computer graphics; Three dimensional computer graphics; Biomedical surfaces; Iterative closest point; Iterative Closest Points; Objective functions; Regularization terms; Surface registration; Surface registration algorithms; Two ways; Iterative methods",2-s2.0-85030830756
"Shi C., Ren Z., He X.","Research on load balancing for software defined cloud-fog network in real-time mobile face recognition",2018,"Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031295619&doi=10.1007%2f978-3-319-66628-0_12&partnerID=40&md5=7fb4dcf8b218cd8eeacad2a72ccd979b","The real-time camera-equipped mobile devices have been widely researched recently. And cloud computing has been used to support those applications. However, the high communication latency and unstable connections between cloud and users influence the Quality of Service (QoS). To address the problem, we integrate fog computing and Software Defined Network (SDN) to the current architecture. Fog computing pushes the computation and storage resources to the network edge, which can efficiently reduce the latency and enable mobility support. While SDN offers flexible centralized control and global knowledge to the network. For applying the software defined cloud-fog network (SDC-FN) architecture in the real-time mobile face recognition scenario effectively, we propose leveraging the SDN centralized control and fireworks algorithm (FWA) to solve the load balancing problem in the SDC-FN. The simulation results demonstrate that the SDN-based FWA could decrease the latency remarkably and improve the QoS in the SDC-FN architecture. © 2018, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.","Cloud computing; Cloud-fog network; Fog computing; Load balancing; Mobile face recognition; Software Defined Network","Cloud computing; Computer architecture; Face recognition; Fog; Integrated control; Network architecture; Quality of service; Resource allocation; Software defined networking; Centralized control; Communication latency; Fireworks algorithms; Global knowledge; Load balancing problem; Mobile face recognition; Mobility supports; Storage resources; Distributed computer systems",2-s2.0-85031295619
"Makwana K., Patel J., Shah P.","An Ontology Based Recommender System to Mitigate the Cold Start Problem in Personalized Web Search",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028433096&doi=10.1007%2f978-3-319-63673-3_15&partnerID=40&md5=9fc3ba599d0c27ecfff90d953a16a8af","With the increase in the diversity of data available on the web, excellence of various searches and the need for personalizing the search results arises. The densely distributed web and heterogeneous information environment creates challenges for search engines such as Storage space, crawling speed, computational speed and retrieval of most relevant documents. It becomes difficult to identify the relevancy of the result due to instability in the search query context. In this paper, the framework to personalize web search through modeling user profile by content based analysis and recommendation model is proposed. The framework will use knowledgebase in form of query hierarchy which is specified for individual user to filter discovered results. The proposed approach is also used to discover current search context of particular user by alluding useful links through item-item collaborative filtering techniques. Due to integration of content based analysis and item to item collaborative filtering algorithm, the proposed framework will retrieved the results of user context on query and also suggest links that had been already clicked by the users within same context. © 2018, Springer International Publishing AG.","Cold start problem; Information retrieval; Ontology; Personalized web search; Recommendation","Collaborative filtering; Digital storage; Information retrieval; Intelligent systems; Ontology; Recommender systems; Websites; Cold start problems; Collaborative filtering algorithms; Collaborative filtering techniques; Computational speed; Content-based analysis; Heterogeneous information; Personalized web searches; Recommendation; Search engines",2-s2.0-85028433096
"Uccheddu F., Servi M., Furferi R., Governi L.","Comparison of mesh simplification tools in a 3D watermarking framework",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020377245&doi=10.1007%2f978-3-319-59480-4_7&partnerID=40&md5=29e3a3205c61d420329ec16a3e181695","Given a to-be-watermarked 3D model, a transformed domain analysis is needed to guarantee a robust embedding without compromising the visual quality of the result. A multiresolution remeshing of the model allows to represent the 3D surface in a transformed domain suitable for embedding a robust and imperceptible watermark signal. Simplification of polygonal meshes is the basic step for a multiresolution remeshing of a 3D model; this step is needed to obtain the model approximation (coarse version) from which a refinement framework (i.e. 3D wavelet analysis, spectral analysis, …) able to represent the model at multiple resolution levels, can be performed. The simplification algorithm should satisfy some requirements to be used in a watermarking system: the repeatability of the simplification, and the robustness of it to noise or, more generally, to slight modifications of the full resolution mesh. The performance of a number of software packages for mesh simplification, including both commercial and academic offerings, are compared in this survey. We defined a benchmark for testing the different software in the watermarking scenario and reported a comprehensive analysis of the software performances based on the geometric distortions measurement of the simplified versions. © Springer International Publishing AG 2018.","3D watermarking; Mesh comparison; Mesh simplification; Wavelets 3D","Graphic methods; Interactive computer systems; Mesh generation; Multimedia services; Multimedia systems; Quality control; Software testing; Spectrum analysis; Wavelet analysis; 3D watermarking; Comprehensive analysis; Imperceptible watermarks; Mesh comparison; Mesh simplifications; Model approximations; Simplification algorithms; Software performance; Watermarking",2-s2.0-85020377245
"Ribeiro C., Pinto T., Vale Z., Baptista J.","Data mining for prosumers aggregation considering the self-generation",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022227545&doi=10.1007%2f978-3-319-62410-5_12&partnerID=40&md5=469df361d2af50e6be332bc0ae28c621","Several challenges arrive with electrical power restructuring, liberalized electricity markets emerge, aiming to improve the system’s efficiency while offering new economic solutions. Privatization and liberalization of previously nationally owned systems are examples of the transformations that have been applied. Microgrids and smart grids emerge and new business models able to cope with new opportunities start being developed. New types of players appear, allowing aggregating a diversity of entities, e.g. generation, storage, electric vehicles, and consumers, Virtual Power Players (VPPs) are a new type of player that allows aggregating a diversity of players to facilitate their participation in the electricity markets. A major task of VPPs is the remuneration of generation and services (maintenance, market operation costs and energy reserves), as well as charging energy consumption. The paper proposes a normalization method that supports a clustering methodology for the remuneration and tariffs definition. This model uses a clustering algorithm, applied on normalized load values, the value of the micro production, generated in the bus associated to the same load, was subtracted from the value of the consumption of that load. This calculation is performed in a real smart grid on buses with associated micro production. This allows the creation of sub-groups of data according to their correlations. The clustering process is evaluated so that the number of data sub-groups that brings the most added value for the decision making process is found, according to players characteristics. © Springer International Publishing AG 2018.",,"Artificial intelligence; Commerce; Digital storage; Distributed computer systems; Electric power system economics; Electric power transmission networks; Energy utilization; Power markets; Privatization; Smart power grids; Clustering process; Decision making process; Economic solutions; Liberalized electricity market; Micro productions; New business models; Normalization methods; Virtual power players; Clustering algorithms",2-s2.0-85022227545
"Nazari Gooran A., Rafiei H., Rabani M.","Modeling risk and uncertainty in designing reverse logistics problem",2018,"Decision Science Letters",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019021632&doi=10.5267%2fj.dsl.2017.5.001&partnerID=40&md5=84155e2a328358d35fd04f15b16d1137","Increasing attention to environmental problems and social responsibility lead to appear reverse logistic (RL) issues in designing supply chain which, in most recently, has received considerable attention from both academicians and practitioners. In this paper, a multi-product reverse logistic network design model is developed; then a hybrid method including Chance-constrained programming, Genetic algorithm and Monte Carlo simulation, are proposed to solve the developed model. The proposed model is solved for risk-averse and risk-seeking decision makers by conditional value at risk, sum of the excepted value and standard deviation, respectively. Comparisons of the results show that minimizing the costs had no direct relation with the kind of decision makers; however, in the most cases, risk-seeking decision maker gained more return products than risk-averse ones. It is clear that by increasing returned products to the chain, production costs of new products and material will be reduced and also by this act, environmental benefits will be created. © 2018 Growing Science Ltd. All rights reserved.","Chance-constrained programming; Conditional value at risk; Genetic algorithms; Monte Carlo simulation; Reverse logistic; Risk; Uncertainty",,2-s2.0-85019021632
"Xu Z., Liu W., Zhu Y., Zhang S.","Building domain keywords using cognitive based sentences framework",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031430425&doi=10.1007%2f978-981-10-3187-8_2&partnerID=40&md5=890bc65d1d3506624a478a4027dc15a9","As the novel web social media emerges on the web, large scale unordered sentences are springing up in the forms: news headlines, microblogs, comments and so on. Domain keywords extraction is very important for information extraction, information retrieval, classification, clustering, topic detection and tracking, and so on. Although these massive sentences contain rich information, their loose semantic association and highly unordered semantic organization make web users extremely difficult to capture the rich information due to the lack of semantic coherence. Sentence ordering is a significant research area focusing on obtaining coherent sentence orders which could assist web user to easily understand these unordered sentences. TextRank is a common graph-based algorithm for keywords extraction. For TextRank, only edge weights are taken into account. We proposed a new text ranking formula that takes into account both edge and node weights of words, named F2N-Rank. The results show our model can obtain coherent sentence orders with higher accuracy in less iterations. The proposed sentence ordering model can be applied in automatic text organization and summarization. © Springer Nature Singapore Pte Ltd. 2018.","Domain keywords; Sentence ordering; TextRank","Computation theory; Data mining; Graphic methods; Information retrieval systems; Semantics; Websites; Domain keywords; Graph-based algorithms; Keywords extraction; Semantic associations; Sentence ordering; Text rankings; TextRank; Topic detection and tracking; Classification (of information)",2-s2.0-85031430425
"Senturk I.F., Balakrishnan P., Abu-Doleh A., Kaya K., Malluhi Q., Çatalyürek Ü.V.","A resource provisioning framework for bioinformatics applications in multi-cloud environments",2018,"Future Generation Computer Systems",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85002809617&doi=10.1016%2fj.future.2016.06.008&partnerID=40&md5=7eb3cf23a39b52b411ca4aa63b3ae8e1","The significant advancement in Next Generation Sequencing (NGS) have enabled the generation of several gigabytes of raw data in a single sequencing run. This amount of raw data introduces new scalability challenges in processing, storing and analyzing it, which cannot be solved using a single workstation, the only resource available for the majority of biological scientists, in a reasonable amount of time. These scalability challenges can be complemented by provisioning computational and storage resources using Cloud Computing in a cost-effective manner. There are multiple cloud providers offering cloud resources as a utility within various business models, service levels and functionalities. However, the lack of standards in cloud computing leads to interoperability issues among the providers rendering the selected one unalterable. Furthermore, even a single provider offers multiple configurations to choose from. Therefore, it is essential to develop a decision making system that facilitates the selection of the suitable cloud provider and configuration together with the capability to switch among multiple providers in an efficient and transparent manner. In this paper, we propose BIOCLOUD as a single point of entry to a multi-cloud environment for non-computer savvy bio-researchers. We discuss the architecture and components of BIOCLOUD and present the scheduling algorithm employed in BIOCLOUD. Experiments with different use-cases and scenarios reveal that BIOCLOUD can decrease the workflow execution time for a given budget while encapsulating the complexity of resource management in multiple cloud providers. © 2016 Elsevier B.V.","Bioinformatics; Cloud broker; Cloud computing; Interoperability; Multi-cloud","Bioinformatics; Budget control; Cost effectiveness; Decision making; Digital storage; Interoperability; Scalability; Scheduling algorithms; Bioinformatics applications; Cloud brokers; Decision-making systems; Multi-clouds; Multiple configurations; Next-generation sequencing; Provisioning framework; Resource management; Cloud computing",2-s2.0-85002809617
"Silva S., Costa P., Gouvea M., Lacerda A., Alves F., Leite D.","High impedance fault detection in power distribution systems using wavelet transform and evolving neural network",2018,"Electric Power Systems Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029810257&doi=10.1016%2fj.epsr.2017.08.039&partnerID=40&md5=5b57771efe5f0b87f9ac75dc8f9ef5a6","This paper concerns how to apply an incremental learning algorithm based on data streams to detect high impedance faults in power distribution systems. A feature extraction method, based on a discrete wavelet transform that is combined with an evolving neural network, is used to recognize spatial–temporal patterns of electrical current data. Different wavelet families, such as Haar, Symlet, Daubechie, Coiflet and Biorthogonal, and different decomposition levels, were investigated in order to provide the most discriminative features for fault detection. The use of an evolving neural network was shown to be a quite appropriate approach to fault detection since high impedance faults is a time-varying problem. The performance of the proposed evolving system for detecting and classifying faults was compared with those of well-established computational intelligence methods: multilayer perceptron neural network, probabilistic neural network, and support vector machine. The results showed that the proposed system is efficient and robust to changes. A classification performance in the order of 99% is exhibited by all classifiers in situations where the fault patterns do not significantly change during tests. However, a performance drop of about 13–24% is exhibited by non-evolving classifiers when fault patterns suffer from gradual or abrupt change in their behavior. The evolving system is capable, after incremental learning, of maintaining its detection and classification performance even in such situations. © 2017 Elsevier B.V.","Evolving neural network; High impedance fault detection; Pattern recognition; Power distribution system; Wavelet transform","Data mining; Discrete wavelet transforms; Electric fault currents; Electric fault location; Electric power system protection; Feature extraction; Learning algorithms; Neural networks; Pattern recognition; Pattern recognition systems; Wavelet decomposition; Wavelet transforms; Classification performance; Computational intelligence methods; Evolving neural network; Feature extraction methods; High impedance fault detection; Multi-layer perceptron neural networks; Power distribution system; Probabilistic neural networks; Fault detection",2-s2.0-85029810257
"Lestari P., Schade H.-P.","RGB-depth image based human detection using viola-jones and chan-vese active contour segmentation",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030179852&doi=10.1007%2f978-3-319-67934-1_25&partnerID=40&md5=2f718a26cf4fd96c50cf6a73bc758f1d","Human detection refers to the process of detecting human region from an image or from video frames. Most of the recent advanced human detection systems use the segmentation scheme by incorporating the depth information of the scene. In such systems, the scene gets captured by a RGB-D camera and the candidate area is segmented by setting an appropriate depth threshold for the captured depth images. In practice, depth data obtained from this depth analysis having critical problems, such as optical noise, absence of depth information for certain regions like hair area, and unmatched boundaries. The proposed approach mainly focus on restoring the actual edge information and hair area of the subject in the pre-segmented image by applying Viola Jones Algorithm for face area detection and Chan-Vese active contour detection for restoring hair and edge areas of the image over the detected face area. This final segmentation mask is used for segmenting the accurate human region from the original image with hair area and with boundaries similar to the ground truth. Experimental results prove the improvement in the visual quality of the segmented human area. © Springer International Publishing AG 2018.","Active contour detection; Depth analysis; Kinect","Edge detection; Image segmentation; Signal processing; Active contour segmentation; Active contours; Depth analysis; Kinect; Pre-segmented images; Segmentation masks; Segmentation scheme; Viola - Jones algorithms; Color image processing",2-s2.0-85030179852
"Lv Z., Zhang C., Zhou B., Gao X., Wu X.","Design and implementation of an eye gesture perception system based on electrooculography",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029447816&doi=10.1016%2fj.eswa.2017.09.017&partnerID=40&md5=57321683b830102917054f7f38a0a773","People with motor diseases have suffered from deprivation of both verbal and non-verbal communication abilities. Fortunately, some of them still retain coordination of brain and eye-motor. To establish a stable communication way for these disabled people, this paper presents an eye gesture perception system based on Electrooculography (EOG). In order to implement a high-accuracy of unit saccadic EOG signals recognition, we propose a new feature extraction algorithm based on Common Spatial Pattern (CSP). We first establish a CSP spatial filter bank corresponding to 8 saccadic tasks (i.e., up, down, left, right, right-up, left-up, right-down, and left-down), then use it to linearly project raw EOG signals and treat the outputs as feature parameters. Furthermore, eye gestures recognition has been carried out by identifying and merging unit saccadic segments in terms of pre-defined time sequences. Experiential results over 10 subjects show that the recognition precision of unit saccadic EOG and eye gesture are 96.8% and 95.0% respectively, which reveal the proposed system has a good performance of eye gestures perception. © 2017","Common spatial pattern (CSP); Electrooculography (EOG); Eye gesture; Joint approximate diagonalization; Support vector machine (SVM); Unit saccadic signals","Support vector machines; Common spatial patterns; Design and implementations; Eye-gestures; Feature extraction algorithms; Feature parameters; Joint approximate diagonalization; Non-verbal communications; Perception systems; Electrooculography",2-s2.0-85029447816
"Micek M., Pacholczyk M.","Searching for cancer signatures using data mining techniques",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030786738&doi=10.1007%2f978-3-319-67792-7_16&partnerID=40&md5=a4b5d45268140ac61a1e146de5404a12","Data mining finds many uses in biotechnology and one of them may be to analyze multi-platform data in order to allow searching for genomic cancer signatures. The importance of the topic arises as nowadays cancer is noted one of the leading causes of deaths in highly developed countries. The goal of this work was to search for colorectal cancer signatures, consisting of somatic mutations, somatic gene copy number alterations (SCNAs) as well as abnormal expression levels. After acquiring mutation, SCNA and expression data from cBioPortal, frequent itemset mining was performed using basket analysis and apriori algorithm. We also performed survival analysis of colorectal cancer patients using the discovered signatures as differentiating factor for Kaplan-Meier curve comparison. Frequent itemset mining returned modifications of genes that can be regarded as potential colorectal cancer signatures or signatures of carcinogenic processes in general. While methods used in the project consisted of use of simple or even basic tools, the results suggest that searching for cancer signatures amidst multi-platform data may be worth developing and improving. © 2018, Springer International Publishing AG.","Apriori; Basket analysis; Colorectal cancer; Data mining; Survival analysis","Bioinformatics; Data mining; Gene expression; Genes; Apriori; Apriori algorithms; Basket analysis; Carcinogenic process; Colorectal cancer; Developed countries; Frequent itemset mining; Survival analysis; Diseases",2-s2.0-85030786738
"Lee S.S., Kim K.Y., Seo J.W.","Development of a trip time for bit exchange simulator for drilling time estimation",2018,"Geothermics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028540521&doi=10.1016%2fj.geothermics.2017.07.006&partnerID=40&md5=7db338032b17fb3e60fd3239e63a43ca","The development of geothermal power generation technologies for applications in non-volcanic areas, based on artificial reservoir creation, has prompted numerous studies on the efficient and economic execution of costly deep subsurface drilling operations. However, the difficulties in predicting the duration and cost of boring work with acceptable reliability make the efficient and organized management of drilling operations very difficult. The trip time for drill bit (i.e., the time taken to withdraw the drill stem to replace bits worn-out, followed by its re-entry into the borehole) that is required because of the abrasion and replacement of bits has a large impact on drilling time and performance. Therefore, a methodology for predicting the time required for a trip for bit exchange at a given depth will enable reliable drilling time and cost estimation for better drilling production management. This study divided the abrasion condition of roller bits into eight steps and used bit life expectancy time for developing a simulation algorithm for Trip Time for Bit Exchange (TTBE). A methodology that can classify the depth of drilling well based on the characteristics of the formation and drilling parameters has also been suggested based on the Bourgoyne and Young model to forecast drilling rates and the extent of bit abrasion. © 2017 Elsevier Ltd","Bourgoyne and Young model; Drilling; Engineered geothermal system; Rate of penetration; Trip time for bit exchange","Abrasion; Cost estimating; Drilling; Drills; Forecasting; Geothermal energy; Geothermal fields; Tribology; Artificial reservoirs; Drilling parameters; Engineered geothermal systems; Geothermal power generation; Production management; Rate of penetration; Simulation algorithms; Trip time; Boring",2-s2.0-85028540521
"Zhao H., Ru Z., Zhu C.","Reliability-based support optimization of rockbolt reinforcement around tunnels in rock masses",2018,"Periodica Polytechnica Civil Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032691075&doi=10.3311%2fPPci.10420&partnerID=40&md5=de2b41aa104630bd94b524e3d11adb3a","Traditionally, the design of tunnels is based on determinate parameter values. In practice, both the performance and safety of tunnels are affected by numerous uncertainties: for example,it is difficult for engineers to predict uncertainties in geological conditions and rock mass properties. The purpose of reliability-based optimization (RBO) is to find a balanced design that is not only economical but also reliable in the presence of uncertainty. In the past few decades, numerous reliability optimization techniques have been proposed for taking uncertainty into account in the design of engineering structures. In the present study, the first-order reliability method (FORM) was used to compute the reliability index using Excel Solver. The least squares support vector machine (LSSVM) approach was adopted to build a relationship between reliability index and design variables,and the artificial bee colony (ABC) algorithm was employed for the reliability-based optimization. A proposed LSSVM/ABC-based reliability optimization method was applied to the case of a tunnel with rockbolt reinforcement. The mechanical parameters of the rock mass, in-situ stress and internal pressure were considered as the random variables. The reliability index of tunnel was analysed. The length, distance out of plane and the number of rockbolts were determined and optimized considering the uncertainty based on RBO. The proposed method improved the efficiency of RBO while maintaining high accuracy. The results showed that the proposed method not only meets the design accuracy, but also improves the efficiency of reliability-based optimization. © 2017, Budapest University of Technology and Economics. All rights reserved.","Artificial bee colony; First-order reliability method; Least squares support vector machine; Reliability analysis; Reliability-based optimization","Efficiency; Least squares approximations; Optimization; Reinforcement; Reliability; Rock mechanics; Rocks; Structural analysis; Support vector machines; Tunnels; Artificial bee colonies; Artificial bee colony algorithms (ABC); Engineering structures; First order reliability methods; Geological conditions; Least squares support vector machines; Reliability based optimization; Reliability optimization; Reliability analysis; Apoidea",2-s2.0-85032691075
"He Y., Liao N., Zhou Y.","Analysis on provincial industrial energy efficiency and its influencing factors in China based on DEA-RS-FANN",2018,"Energy",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032855828&doi=10.1016%2fj.energy.2017.10.011&partnerID=40&md5=7a8fadeb64238327ed090d1f28ad7d72","Data envelopment analysis (DEA), rough set theory (RS) and fuzzy artificial neural network (FANN) are combined as DEA-RS-FANN procedure to explore the effects of influencing factors on energy efficiency in China's provincial industry sectors. The analysis begins with the DEA technique to evaluate energy efficiency in provincial industries, followed by fuzzy c-means (FCM) algorithm to classify energy efficiency and the influencing factors to three categories (low-, medium- and high-levels). This process facilitates the construction of the decision table from condition attribute (the influencing factors) to decision attribute (energy efficiency). Then significance analysis of attributes in RS theory is adopted to investigate the significance of the influencing factors and determine the primary factors. Finally, FANN is utilized to further analyze the marginal effect of primary factors on energy efficiency in three specific categories, comprising of those provinces with different levels of energy efficiency. The proposed method takes into consideration non-linear and lag effects between energy efficiency and the influencing factors, as well as the characteristics of the impreciseness and incompleteness of the statistical data, ultimately leading to more precise and reliable results, as compared to conventional methods. © 2017 Elsevier Ltd","DEA-RS-FANN method; Industrial energy efficiency; Influencing factors","Data envelopment analysis; Decision tables; Factor analysis; Neural networks; Rough set theory; Condition attributes; Conventional methods; DEA-RS-FANN method; Fuzzy artificial neural networks (FANN); Fuzzy C-means algorithms; Industrial energy efficiency; Influencing factors; Significance analysis; Energy efficiency; data envelopment analysis; decision making; energy efficiency; energy market; fuzzy mathematics; statistical analysis; China",2-s2.0-85032855828
"Bai R., Woodward J.R., Subramanian N., Cartlidge J.","Optimisation of transportation service network using κ-node large neighbourhood search",2018,"Computers and Operations Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020507853&doi=10.1016%2fj.cor.2017.06.008&partnerID=40&md5=3dee2c1c18ae0125c6b78823085cd6d0","The Service Network Design Problem (SNDP) is generally considered as a fundamental problem in transportation logistics and involves the determination of an efficient transportation network and corresponding schedules. The problem is extremely challenging due to the complexity of the constraints and the scale of real-world applications. Therefore, efficient solution methods for this problem are one of the most important research issues in this field. However, current research has mainly focused on various sophisticated high-level search strategies in the form of different local search metaheuristics and their hybrids. Little attention has been paid to novel neighbourhood structures which also play a crucial role in the performance of the algorithm. In this research, we propose a new efficient neighbourhood structure that uses the SNDP constraints to its advantage and more importantly appears to have better reachability than the current ones. The effectiveness of this new neighbourhood is evaluated in a basic Tabu Search (TS) metaheuristic and a basic Guided Local Search (GLS) method. Experimental results based on a set of well-known benchmark instances show that the new neighbourhood performs better than the previous arc-flipping neighbourhood. The performance of the TS metaheuristic based on the proposed neighbourhood is further enhanced through fast neighbourhood search heuristics and hybridisation with other approaches. © 2017 The Author(s)","Large neighbourhood search; Logistics; Metaheuristics; Service network design; Transportation network","Benchmarking; Heuristic algorithms; Local search (optimization); Logistics; Mass transportation; Tabu search; Transportation routes; Large neighbourhood searches; Local search metaheuristics; Meta heuristics; Neighbourhood search; Service network designs; Transportation network; Transportation services; Transportation-logistics; Transportation",2-s2.0-85020507853
"Reder M., Yürüşen N.Y., Melero J.J.","Data-driven learning framework for associating weather conditions and wind turbine failures",2018,"Reliability Engineering and System Safety",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031740982&doi=10.1016%2fj.ress.2017.10.004&partnerID=40&md5=28afa616dbad1bc11aaf60b80633e882","The need for cost effective operation and maintenance (O&M) strategies in wind farms has risen significantly with the growing wind energy sector. In order to decrease costs, current practice in wind farm O&M is switching from corrective and preventive strategies to rather predictive ones. Anticipating wind turbine (WT) failures requires sophisticated models to understand the complex WT component degradation processes and to facilitate maintenance decision making. Environmental conditions and their impact on WT reliability play a significant role in these processes and need to be investigated profoundly. This paper is presenting a framework to assess and correlate weather conditions and their effects on WT component failures. Two approaches, using (a) supervised and (b) unsupervised data mining techniques are applied to pre-process the weather and failure data. An apriori rule mining algorithm is employed subsequently, in order to obtain logical interconnections between the failure occurrences and the environmental data, for both approaches. The framework is tested using a large historical failure database of modern wind turbines. The results show the relation between environmental parameters such as relative humidity, ambient temperature, wind speed and the failures of five major WT components: gearbox, generator, frequency converter, pitch and yaw system. Additionally, the performance of each technique, associating weather conditions and WT component failures, is assessed. © 2017 Elsevier Ltd","Association rule mining; Big data; Data mining; Failure; k-means clustering; Machine learning; Operation & maintenance; Weather; Wind turbine","Big data; Computer system recovery; Cost effectiveness; Decision making; Electric utilities; Learning systems; Maintenance; Meteorology; Weathering; Wind; Wind power; Wind turbines; Environmental conditions; Environmental parameter; K-means clustering; Logical interconnections; Maintenance decision making; Operation and maintenance; Preventive strategies; Rule mining algorithms; Data mining",2-s2.0-85031740982
"Nagaraju S., Sudhakara Reddy P.","High-throughput low-power variable rate network intrusion detection system using unique SRAM controller",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029819987&doi=10.1007%2f978-981-10-4280-5_18&partnerID=40&md5=1c44d04909bf29fdd18c621c69d5fac6","Network intrusion detection system (NIDS) is a major research area for security mechanism. In recent years, the demand for digital systems in network field increase due to the development of 4G technology and high network traffic rate. In this paper, we propose a bit-based pattern matching algorithm with unique SRAM architecture for parallel processing. To reduce the bit transitions during matching process state encoded finite-state machines (FSMs) were used which the main core in the pattern is matching process, where a number of states remain constant over pattern length. To avoid synchronization problem over variable rate pattern match unique controllers are used which is driven by adaptive digital phase locked loop (ADPLL). The functionality is proved through the test bench simulation using Modelsim and power efficiency is verified using FPGA synthesis. In this work, memory size requirements are reduced by 8 times with an early detection scheme and the overall throughput rate is attained in the range of 13 Gbps. Finally, the dynamic power consumption is greatly reduced by 7% through gated logic. © Springer Nature Singapore Pte Ltd. 2018.","ADPLL; FPGA; FSM; Low power; Network intrusion detection system (NIDS); Parallel processing; SRAM","Computer crime; Field programmable gate arrays (FPGA); Low power electronics; Mercury (metal); Pattern matching; Static random access storage; Adaptive digital phase locked loops; ADPLL; Dynamic power consumption; Low Power; Network intrusion detection systems; Parallel processing; Pattern matching algorithms; Synchronization problem; Intrusion detection",2-s2.0-85029819987
"Maulik R., San O.","Explicit and implicit LES closures for Burgers turbulence",2018,"Journal of Computational and Applied Mathematics",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021307153&doi=10.1016%2fj.cam.2017.06.003&partnerID=40&md5=3a528bfa9145b559711250f843b5742d","In this paper, we perform an a posteriori error analysis on implicit and explicit large eddy simulation (LES) closure models for solving the Burgers turbulence problem. Our closure modeling efforts include both functional and structural models equipped with various low-pass filters. We introduce a family of discrete binomial smoothing filters and an enhanced version of the Van Cittert algorithm to accelerate the convergence of the approximate deconvolution (AD) process. Our implicit modeling efforts consist of various high-order numerical strategies including compact and non-compact fifth-order upwind schemes as well as weighted essential non-oscillatory (WENO) and compact reconstructed WENO (CRWENO) schemes. The resulting implicit approaches are shown to effectively converge to the direct numerical simulation (DNS) for increasing resolutions. Compared to the DNS and underresolved DNS computations, our numerical assessments illustrate the ability of the proposed implicit and explicit closure models to capture the energy content near the grid cut-off scale. Based on the current study, it can be concluded that AD-LES using the Padé filter with control parameter α=0.3 produces the best results. In addition, the AD-LES result could be further improved with an even better filter choice. That being said, both the relaxation filtering (using the same Padé filter as AD-LES, but with α=0.495) and the CRWENO schemes are also found to produce accurate results without pile-up. Therefore, these three LES closures should be investigated in greater detail for more complicated flows in future work. © 2017 Elsevier B.V.","Approximate deconvolution; Closure modeling; Explicit filtering; Implicit LES; Large eddy simulations; Shock capturing","Error analysis; Large eddy simulation; Piles; Turbulence; Approximate deconvolution; Closure models; Control parameters; Implicit LES; Numerical strategies; Posteriori error analysis; Shock-capturing; Van Cittert algorithms; Low pass filters",2-s2.0-85021307153
"Okoye K., Tawil A.-R.H., Naeem U., Islam S., Lamine E.","Semantic-based model analysis towards enhancing information values of process mining: Case study of learning process domain",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028594873&doi=10.1007%2f978-3-319-60618-7_61&partnerID=40&md5=97958985f7a812d26c753825b7211889","Process mining results can be enhanced by adding semantic knowledge to the derived models. Information discovered due to semantic enrichment of the deployed process models can be used to lift process analysis from syntactic level to a more conceptual level. The work in this paper corroborates that semantic-based process mining is a useful technique towards improving the information value of derived models from the large volume of event logs about any process domain. We use a case study of learning process to illustrate this notion. Our goal is to extract streams of event logs from a learning execution environment and describe formats that allows for mining and improved process analysis of the captured data. The approach involves mapping of the resulting learning model derived from mining event data about a learning process by semantically annotating the process elements with concepts they represent in real time using process descriptions languages, and linking them to an ontology specifically designed for representing learning processes. The semantic analysis allows the meaning of the learning objects to be enhanced through the use of property characteristics and classification of discoverable entities, to generate inference knowledge which are used to determine useful learning patterns by means of the Semantic Learning Process Mining (SLPM) algorithm - technically described as Semantic-Fuzzy Miner. To this end, we show how data from learning processes are being extracted, semantically prepared, and transformed into mining executable formats to enable prediction of individual learning patterns through further semantic analysis of the discovered models. © Springer International Publishing AG 2018.","Event logs; Knowledge discovery; Learning process; Ontology; Process mining; Semantic annotation","Inference engines; Learning algorithms; Learning systems; Ontology; Pattern recognition; Semantics; Soft computing; Event logs; Execution environments; Individual learning; Learning process; Process descriptions; Process mining; Semantic annotations; Semantic enrichment; Data mining",2-s2.0-85028594873
"Chiang C.-W., Chen L.-C., Liu J.-W.","Developing the framework for evaluating the interaction design of mobile augmented reality systems for cultural learning",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031418756&doi=10.1007%2f978-981-10-3187-8_95&partnerID=40&md5=d7d4febfaff95af061cbe873c6bf2756","Mobile augmented reality (MAR) is an increasingly popular technology for enhancing how students interact with and learn about the cultural environment and cultural objects in the physical world. Sometime the learning effect is influenced by the delighted value, which is always subjective and learning—driven. In order to ensure successful launch the mobile augment reality of cultural interactive learning tool, it is extremely important to predict the delighted value of design alternatives systematically based on the common language understood by both students and designers. However, the framework for communicating and evaluating such value from interested perspective is not available in the literature. Therefore, the objective of this research is to extract key frameworks of delighted value from interested perspective and develop an effective algorithm to evaluate MAR cultural learning system. First, through literature review and the interview of participants, many scenarios of learning influence were collected. A focus group was invited to identify the essential elements that influence the delighted value of MAR cultural learning system. Followed by a large scale questionnaire survey and factor analysis, four frameworks were extracted. These frameworks, name as CARE framework in brief, included communication, association, reflection, and engagement. Second, the perception differences of MAR cultural learning paper prototypes were conducted to verify the validity of CARE framework for comparative studied. The findings of this study demonstrated that CARE framework was effective for solution designing in MAR cultural interactive learning tool. © Springer Nature Singapore Pte Ltd. 2018.","Cultural learning; Frameworks of delighted value; Mobile augmented reality design","Augmented reality; Computation theory; Educational technology; Learning systems; Network function virtualization; Surveys; Cultural environment; Cultural learning; Effective algorithms; Frameworks of delighted value; Interaction design; Interactive learning tools; Mobile augmented reality; Questionnaire surveys; Education",2-s2.0-85031418756
"Hemjot, Sharma A.","Pattern classification and retrieval of content-based images—A step towards amelioration",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031413875&doi=10.1007%2f978-981-10-6614-6_2&partnerID=40&md5=55f80dda029ad075ed183a14da2adcd5","The progressive web and computerized advancements have forced endless increment in the measure of visual data accessible to users. This trend prompted the advancement of exploration area where retrieval of images is done through the content of information which became familiar as CBIR (content-based image retrieval). CBIR frameworks are to a great extent utilized as a part of medicinal picture annotation, face recognition systems, security frameworks and so on. In this paper, we will discuss about an efficient system for retrieving images faster since speed and precision are important as well as techniques to obtain better classification of images. To conquer the issue of extensive number of features extracted which obliges vast measure of memory and processing force, we need to build a blend of 3 techniques (SURF, SVM and LDA) which best portray the information with adequate precision. Hence, we are using dimensionality reduction algorithm LDA in combination with SVM for the classification purpose and SURF which is quick and robust interest point detector. © 2018, Springer Nature Singapore Pte Ltd.","Classification; Colour histogram; Content-based image retrieval (CBIR); Linear discriminant analysis (LDA); Pattern recognition; Speeded up robust features (SURF); Support vector machine (SVM)","Classification (of information); Content based retrieval; Discriminant analysis; Face recognition; Image classification; Image processing; Network security; Pattern recognition; Support vector machines; Colour histograms; Content based images; Content-Based Image Retrieval; Dimensionality reduction algorithms; Face recognition systems; Interest Point Detectors; Linear discriminant analysis; Speeded up robust features; Image retrieval",2-s2.0-85031413875
"Hosseini B., Kiani K.","FWCMR: A scalable and robust fuzzy weighted clustering based on MapReduce with application to microarray gene expression",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028982337&doi=10.1016%2fj.eswa.2017.08.051&partnerID=40&md5=1ef4ea2c1bc4ff88072d26ab99dfe82f","Data clustering is a very useful data mining technique to find groups of similar objects present in the dataset. Scalability to handle immense volumes, robustness to intrinsic outlier data and validity of clustering results are the main challenges of any data clustering approach. In order to address these challenges, a fuzzy weighted clustering approach which is comprehensibly parallel and distributed in every phase, is proposed in this research. Although the proposed method can be used for various data clustering purposes, it has been applied in gene expression clustering to reveal functional relationships of genes in a biological process. Conforming to MapReduce, the proposed method also presents a novel similarity measure which benefits from combining ordered weighted averaging and Spearman correlation coefficient. In the proposed method, density reachable genes were joined to establish subclusters. Afterwards, final cluster results were obtained by merging these subclusters. A voting system detects the best weights and consequently the most valid clusters among all possible results for each distinct dataset. The whole algorithm is implemented on a distributed processing platform and it is scalable to process any size of data stored in cloud infrastructures. Precision of resulting clusters were evaluated using some of the well-known cluster validity indexes in the literature. Also, the efficiency of the proposed method in scalability and robustness was compared with recently published similar researches. In all the mentioned comparisons, the proposed method outperformed recent works on the same datasets. © 2017 Elsevier Ltd","Big data; Decision making; Distributed density based clustering; Fuzzy weighted clustering; Gene expression microarray; MapReduce","Big data; Cluster analysis; Clustering algorithms; Data mining; Decision making; Genes; Scalability; Voting machines; Density-based Clustering; Fuzzy weighted clustering; Gene expression clustering; Gene expression microarray; Map-reduce; Microarray gene expression; Ordered weighted averaging; Spearman correlation coefficients; Gene expression",2-s2.0-85028982337
"Coelho E.K.F., Mateus G.R.","A capacitated plant location model for Reverse Logistics Activities",2018,"Journal of Cleaner Production",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028041800&doi=10.1016%2fj.jclepro.2017.07.238&partnerID=40&md5=271373e4a5dc6a2f5edaa23b934af1a2","Product remanufacturing is one of the most profitable activities in reverse logistics. Running a business plan, in which companies take responsibility for the waste generated at their end-of-life products, involves making important strategic decisions. One of the challenges in planning the reverse flow of products is decide where installing the reprocessing facilities. This decision influences directly the transport variables costs and the facilities installation fixed costs. This paper proposes a model for the Capacitated Plant Location Problem in Reverse Logistics (CPL-RL), in which we assume that offered material in each collection center is aimed at a single facility for reprocessing. This restriction includes specific cases where there is no logistic availability in the network to send the collected material to different locations. The Mixed Integer Problem (MILP) is solved using an algorithm in two steps. In the first step, reduction tests are performed, which ones determine a priori which facilities are opened/closed. If all facilities are fixed opened or closed then the solution is optimal. Although not all facilities can have their status defined that way, the resultant problem has a less number of variables and it is solved using Benders method. The dataset was randomly generated and the results showed that the applied techniques are appropriate, achieving the optimal solution for all test problems. © 2017 Elsevier Ltd","Algorithms; Benders decomposition; Reduction tests; Reverse logistics","Algorithms; Integer programming; Location; Statistical tests; Benders decomposition; End-of-life products; Location problems; Mixed integer problems; Product remanufacturing; Reprocessing facilities; Reverse logistics; Strategic decisions; Logistics",2-s2.0-85028041800
"Rajinikanth V., Fernandes S.L., Bhushan B., Harisha, Sunder N.R.","Segmentation and analysis of brain tumor using tsallis entropy and regularised level set",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029795470&doi=10.1007%2f978-981-10-4280-5_33&partnerID=40&md5=56f3f60cbef24c183a989b2928e760ae","Image processing is extensively considered in medical field for computer-supported disease assessment. Brain tumor is one of the deadliest cancers for the human community and requires image/signal processing approaches to record and analyze the disease-affected regions. In this work, Cuckoo Search Algorithm (CA) assisted approach is proposed to segment tumor from a two-dimensional Magnetic Resonance Image (MRI). Primarily, Tsallis entropy-monitored multilevel thresholding is implemented for the brain MRI dataset based on CA. Afterward, the skull section is detached by means of an image filtering approach. The skull stripped image is then treated using the image morphological function in order to obtain a smooth image exterior. Lastly, the tumor section is mined using the regularized level set technique. The efficiency and the clinical importance of presented method are confirmed based on the image similarity measures and the statistical measures. Experimental results of the proposed approach offer better values of Jaccard, Dice, precision, sensitivity, and accuracy values. Hence the proposed approach is clinically significant and in future, it can be used to diagnose the brain tumor images. © Springer Nature Singapore Pte Ltd. 2018.","Brain MRI; Cuckoo search; Level set segmentation; Tsallis entropy","Brain; Entropy; Image processing; Image segmentation; Medical imaging; Optimization; Tumors; Brain MRI; Cuckoo search algorithms; Cuckoo searches; Level set segmentation; Magnetic resonance images (MRI); Multilevel thresholding; Statistical measures; Tsallis entropies; Magnetic resonance imaging",2-s2.0-85029795470
"Kumar A., Roy D., Verter V., Sharma D.","Integrated fleet mix and routing decision for hazmat transportation: A developing country perspective",2018,"European Journal of Operational Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021724261&doi=10.1016%2fj.ejor.2017.06.012&partnerID=40&md5=fc4926ea8dcb7a43e0b0e493682d36bf","In developing countries, truck purchase cost is the dominant criteria for fleet acquisition-related decisions. However, we contend that other cost factors such as loss due to the number of en route truck stoppages based on a truck type and recovery cost associated with a route choice decision, should also be considered for deciding the fleet mix and minimizing the overall costs for long-haul shipments. The resulting non-linear model, with integer variables for the number and type of trucks, and the route choices, is solved via genetic algorithm. Using real data from a bulk liquid hazmat transporter, the trade-offs between the cost of travel, loss due to number of truck stoppages, and the long-term recovery cost associated with the risk of exposure due to a hazmat carrier accident are discussed. The numerical experiments show that when factors related to public safety and truck stoppages are taken into account for transportation, the lowest total cost and optimal route choice do not align with the cheapest truck type option; rather, the optimal solution corresponds to another truck type and route with total costs significantly less than the total costs associated with the cheapest truck type. Our model challenges the current truck purchasing strategy adopted in developing countries using the cheapest truck criteria. © 2017 Elsevier B.V.","Logistics; OR in societal problem analysis; Risk analysis; Routing","Accidents; Costs; Developing countries; Genetic algorithms; Logistics; Risk analysis; Risk assessment; Transportation routes; Truck transportation; Trucks; Hazmat transportation; Integer variables; Long-term recovery; Numerical experiments; Optimal solutions; OR in societal problem analysis; Risk of exposures; Routing; Fleet operations",2-s2.0-85021724261
"Dhinakaran K., Kirtana R., Gayathri K., Devisri R.","Enhance hybrid cloud security using vulnerability management",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028591850&doi=10.1007%2f978-3-319-60618-7_47&partnerID=40&md5=a9828bddfa76fb3163f0be0ac094e8cb","Cloud computing is one of the emerging technologies in last decade; this technology provides a service model to organizations and public users. Organization users and developers, they start and maintain their organization without any hardware and software infrastructure they can develop their company with the help of cloud technology. Cloud deployment is categorized into three types, private, public and hybrid cloud environment and here public and private cloud more secure comparatively hybrid cloud because when data is moving from private to public cloud security problem is occur. Data communication is most important task in a network environment so the proposed model is focus on data security in hybrid cloud environment. In a hybrid cloud the participation of private cloud and its nodes very important after that the data transmission is depends on active node, In this node selection is based on genetic algorithm. The result of proposed model is going to compare with private and public cloud security parameters. © Springer International Publishing AG 2018.","Cloud security; Hybrid cloud; Private cloud; Public cloud; Vulnerability","Genetic algorithms; Soft computing; Cloud securities; Hybrid clouds; Private clouds; Public clouds; Vulnerability; Pattern recognition",2-s2.0-85028591850
"Zhao Y., Chung H.","Numerical simulation of the transition of metal transfer from globular to spray mode in gas metal arc welding using phase field method",2018,"Journal of Materials Processing Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028715749&doi=10.1016%2fj.jmatprotec.2017.08.036&partnerID=40&md5=a01b45f8fcc39da9aa50c09cb8503bfb","A numerical model is constructed based on the solution of the magnetohydrodynamic equations within the framework of phase field algorithm to simulate the metal transfer process and investigate the mechanism of the transition of metal transfer from globular to spray mode. Surface tension is the strongest driving force acting on the pendent droplet in globular transfer, while the governing force shifts to the electromagnetic pinch force in spray transfer. Driving force balance in the axial direction could be the indicator of detachment in globular transfer, while that force balance doesn't exist in spray transfer. The condition for the transition from globular to spray transfer is that the local pressure at the root of the droplet caused by the electromagnetic pinch force exceeds the surface tension pressure at the droplet tip corresponding to a droplet radius equals to the wire radius. Compared with volume of fluid method, phase field method shows a more physically realistic estimation of the current path from the drop to the arc plasma and leads to a better agreement with experimental data. © 2017 Elsevier B.V.","Gas metal arc welding (GMAW); Globular transfer; Magnetohydrodynamics; Phase field method; Spray transfer","Computational fluid dynamics; Drops; Electric arc welding; Electric welding; Gas welding; Magnetohydrodynamics; Magnetoplasma; Metals; Numerical methods; Numerical models; Phase transitions; Surface tension; Welding; Gas metal arc welding (GMAW); Globular transfer; Local pressures; Magnetohydrodynamic equations; Phase field methods; Phase-field algorithms; Spray transfer; Volume of fluid method; Gas metal arc welding",2-s2.0-85028715749
"Liu W., Li Z., Song Z., Li J.","Seismic reliability evaluation of gas supply networks based on the probability density evolution method",2018,"Structural Safety",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030781237&doi=10.1016%2fj.strusafe.2017.10.001&partnerID=40&md5=668f71561b3f712de4279e16926a6dd9","An accurate and efficient reliability evaluation is necessary for network systems with uncertain conditions, especially for the lifeline networks subjected to earthquakes. This study takes gas supply networks as examples and establishes an approach to evaluate the seismic reliability of networks on the basis of the probability density evolution method. First, a nonlinear finite element model is established to simulate buried pipe networks that are subjected to earthquakes. Then, the seismic stresses of the pipes are derived, and the von Mises stresses of the pipes are calculated and used to judge pipe failure. Second, a connectivity index is defined to describe the connectivity between the source and the terminal. Third, on the basis of the probability density evolution method, network reliability is obtained after introducing a physically-based model to simulate ground motion field. Finally, two networks are used as examples to demonstrate the proposed approach, and the results are validated by the Monte Carlo simulation method and compared with a selective recursive decomposition algorithm. © 2017 Elsevier Ltd","Connectivity index; Network reliability; Probability density evolution method; Seismic analysis","Earthquakes; Gas supply; Geophysics; Intelligent systems; Monte Carlo methods; Probability; Probability density function; Random processes; Reliability; Reliability analysis; Seismology; Connectivity indices; Monte Carlo simulation methods; Network reliability; Non-linear finite element model; Physically based modeling; Probability density evolution method; Recursive decomposition algorithms; Seismic analysis; Finite element method",2-s2.0-85030781237
"Zhao L.J., Huang L., Lv Q., Yang T., Wei D.","WAMS/SCADA Data Fusion Method Study Based on Time-Series Data Correlation Mining",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028660064&doi=10.1007%2f978-3-319-67349-3_11&partnerID=40&md5=d052442f1f572880e79caca250ebf4cd","Hybrid measurement state estimation of WAMS data and the SCADA system is an effective method to improve the traditional state estimation. However, as the WAMS data and the SCADA data belong to different systems, there are great differences between them. To solve this problem, WAMS/SCADA data fusion method based on the correlation mining of time-series data is proposed in this paper. Firstly, WAMS/SCADA correlation estimation is done with the derivation of Pearson correlation coefficient. Then, solving the function model for the time difference issue and the alignment problem of correlation curves. After that, analyzing the measurement precision by considering the measurement weight and calculate the matrix of time series data weight to complete the optimization for the measurement precision. Finally, forming the effective fusion scheme based on the correlation of timing data. Simulation results on the IEEE 118 nodes system, with set a comparison of different hybrid measurement state estimation and different state estimation algorithm, effectiveness and stability of the proposed method has been proved. © 2018, Springer International Publishing AG.","correlation mining; Time-series data; WAMS/SCADA data fusion","Biomedical engineering; Correlation methods; Data fusion; SCADA systems; State estimation; Alignment Problems; Correlation estimation; Correlation mining; Data fusion methods; Measurement precision; Pearson correlation coefficients; State estimation algorithms; Time-series data; Time series",2-s2.0-85028660064
"Mahmoudimehr J., Shabani M.","Optimal design of hybrid photovoltaic-hydroelectric standalone energy system for north and south of Iran",2018,"Renewable Energy",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028323606&doi=10.1016%2fj.renene.2017.08.054&partnerID=40&md5=69e2b70b10a42774e111d4d917798495","This study is concerned with the optimal design of a hybrid photovoltaic-hydroelectric standalone energy system for coastal areas in the north and south of Iran. In this regard, a novel approach, which is a combination of a straightforward quasi-steady operational strategy and Genetic Algorithm, is employed. Investment cost and loss of power supply probability (LPSP) are considered as objective functions. Number of PV modules, turbine capacity, charge and discharge pipes diameters, and reservoir volume, installation height and depth to diameter ratio constitute the set of design variables. To the best of our knowledge; it is the first time that such a wide range of design variables is being considered. The results show that the proposed approach is able to reach a design with the full satisfaction of fluctuating power demand and system constraints. In this case, for the yearly-averaged demand of 32.4 kW, the investment cost is obtained to be 2.13M$ and 1.59M$ for the north and south of Iran. Moreover, a compromise between objective functions results in 26.1%/17.6% reduction in investment cost at the expense of 13.8%/11.1% increase in LPSP for the north/south region. The paper compares in detail the optimal system designs and operations obtained for the two regions. © 2017 Elsevier Ltd","Hydro storage technology; Optimal design; Photovoltaic array; Standalone energy system","Costs; Genetic algorithms; Optimal systems; Photovoltaic cells; Charge and discharge; Energy systems; Installation heights; Loss of power supply probability; Operational strategies; Optimal design; Photovoltaic arrays; Storage technology; Investments",2-s2.0-85028323606
"Seyfi B., Fatouraee N., Imeni M.","Mechanical modeling and characterization of meniscus tissue using flat punch indentation and inverse finite element method",2018,"Journal of the Mechanical Behavior of Biomedical Materials",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030461441&doi=10.1016%2fj.jmbbm.2017.09.023&partnerID=40&md5=9f5812ead32c8fbf67731b49ef328f7d","In this paper, to characterize the mechanical properties of meniscus by considering its local microstructure, a novel nonlinear poroviscoelastic Finite Element (FE) model has been developed. To obtain the mechanical response of meniscus, indentation experiments were performed on bovine meniscus samples. The ramp-relaxation test scenario with different depths and preloads was designed to capture the mechanical characteristics of the tissue in different regions of the medial and lateral menisci. Thereafter, a FE simulation was performed considering experimental conditions. Constitutive parameters were optimized by solving a FE-based inverse problem using the heuristic Simulated Annealing (SA) optimization algorithm. These parameters were ranged according to previously reported data to improve the optimization procedure. Based on the results, the mechanical properties of meniscus were highly influenced by both superficial and main layers. At low indentation depths, a high percentage relaxation (p < 0.01) with a high relaxation rate (p < 0.05) was obtained, due to the poroelastic and viscoelastic nature of the superficial layer. Increasing both penetration depth and preload level involved the main layer response and caused alterations in hyperelastic and viscoelastic parameters of the tissue, such that for both layers, the shear modulus was increased (p < 0.01) while the rate and percentage of relaxation were decreased (p < 0.01). Results reflect that, shear modulus of the main layer in anterior region is higher than central and posterior sites in medial meniscus. In contrast, in lateral meniscus, posterior side is stiffer than central and anterior sides. © 2017 Elsevier Ltd","Finite element; Indentation; Mechanical property; Meniscus; Microstructure; Optimization; Preload","Biomechanics; Elastic moduli; Indentation; Inverse problems; Mechanical properties; Microstructure; Optimization; Shear strain; Simulated annealing; Tissue; Viscoelasticity; Constitutive parameters; Experimental conditions; Inverse finite element methods; Mechanical characteristics; Meniscus; Optimization algorithms; Pre loads; Visco-elastic parameters; Finite element method",2-s2.0-85030461441
"Patel S.B., Mukhopadhyay S., Tiwari A.P.","Estimation of reactivity and delayed neutron precursors’ concentrations using a multiscale extended Kalman filter",2018,"Annals of Nuclear Energy",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030660464&doi=10.1016%2fj.anucene.2017.09.033&partnerID=40&md5=075fc4618117865afe5e1f906fb7799a","A wavelet based multiscale extended Kalman filtering technique for estimation of reactivity and delayed neutron precursors’ concentrations is presented in this paper. Reactivity which indicates the criticality status of the reactor core can only be measured in indirect way. Similarly delayed neutron precursors’ concentrations, the source of the delayed neutrons which play important role in reactor control cannot be measured directly. Nuclear reactor is an example of multirate nonlinear system in which different state variables evolve with widely varying dynamics. The state estimation algorithm presented here is based on and preserves merits of Extended Kalman Filtering (EKF) technique. In addition, use of wavelet filters enables multiscale decomposition of the state variables that in turn, effectively captures the multirate nature of the system. Estimation has been carried out using reactor power as the only input. In order to justify effectiveness of the proposed method, simulation results are shown for completely known power variation dataset and experimental power variation datasets collected from one of the Indian research reactors. © 2017 Elsevier Ltd","Extended Kalman filter; Nuclear reactor; Reactivity meter; Wavelet filters","Bandpass filters; Extended Kalman filters; Neutrons; Nuclear reactors; Reactivity (nuclear); Wavelet decomposition; Delayed Neutron Precursor; Delayed neutrons; Different state variables; Extended Kalman filtering; Multi-scale Decomposition; Power variations; State estimation algorithms; Wavelet filters; Kalman filters",2-s2.0-85030660464
"Hajihashemi V., Gharahbagh A.A.","A fast, block based, copy-move forgery detection approach using image gradient and modified K-means",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032654583&doi=10.1007%2f978-3-319-68385-0_25&partnerID=40&md5=82cf72e4ba9bd9fb6fceecbea835f9e0","In recent years, due to the fast development of digital images, a rapid growth of research interest in the forgery detection in digital images has been happened. One of the most common techniques in creating forged images is copy-move (region duplication) technique. In this paper, a new method for copy-move forgery detection in digital images is proposed. In this paper a region duplication detection technique which utilizes the image gradient is proposed. In the proposed approach, first the gradient of image is divided into overlapped blocks. Using gradient versus other techniques, decreases processing time in feature extraction step. A fast pre clustering algorithm is another added step to speedup method by dividing search area into some subset. The unknown parameters of proposed method are determined by implementing different conditions on two standard databases. Finally, the performance of the proposed method is compared with some state of art methods and the acceptable accuracy and lower run time of it, is verified. © Springer International Publishing AG 2018.","Copy-move; Fast k means; Forgery detection; Image forgery; Image gradient","Clustering algorithms; Intelligent systems; Copy moves; Forgery detections; Image forgery; Image gradients; K-means; Computer crime",2-s2.0-85032654583
"Jedrusik P., Walusiak Ł., Bednarek I., Koprowski R., Wróbel Z.","Image processing and analysis in lung cancer cells growth",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019231667&doi=10.1007%2f978-3-319-59162-9_36&partnerID=40&md5=3312b41cef3896d22e7d517ac142b52b","Modern diagnostic methods allow to get multiple information regarding research material. Patients diagnosis is performed using highly specialized tools, effectively supporting any medical diagnostic processes. This paper focuses on the analysis of lung cancer cell cultures growth and migration in vitro. Most of the publications on the growth rate of cells is based on the analysis of changes in surface area, less wide cracks. This study determined there are additional parameters like cells angle, number of cells and distance between cells, with separate cells up and down the scratch in all parameters, that affect how the migration of cells which have not been considered previously. Analysis on the arrangement of the cells and the distances between them, allow for determination of the level of cell migration. Experience has shown that on the first day a high proliferation of cells, and then clear their migration, increasing the distance. It was also noted changing the angle of the cells that begin migration. The performed analysis confirmed that those additional parameters differentiate correctly evaluated a group of images. Developed algorithm of image processing and analysis, operates on data from a collection of microscopic images of lung cancer cells in vitro propagation, acquiring data on the growth and migration of cancer cells. As a result the data contain a description of parameters studied images in the form of growth profiles over time and the type of growth. © Springer International Publishing AG 2018.","Algorithms; Cell culture; Cell migration; Image processing; Lung cancer; Wound healing","Algorithms; Biological organs; Cell culture; Cytology; Data flow analysis; Diagnosis; Diseases; Image analysis; Image processing; Cell migration; Diagnostic methods; Image processing and analysis; Lung Cancer; Lung cancer cells; Medical diagnostics; Specialized tools; Wound healing; Cells",2-s2.0-85019231667
"Shi C., Han M., Ju Y.","Evaluation of smart city developmental level based on principal component analysis and GA-BP neural network",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031425083&doi=10.1007%2f978-981-10-3187-8_35&partnerID=40&md5=1ad80a430b0f000a1739206113d76657","Smart city assessment issue is an important component of smart city construction. On one hand, it can help the government to guide and direct the activities of Smart-city Construction, on the other hand, it can reflect and give feedbacks to the audience. In this paper, according to the existing evaluation system of Smart City at home and abroad and the division standard of the latest cities in China, we create a more complete and comprehensive evaluation system. At first, we use the Principal Component Analysis (PCA) to reduce index that is according to design the evaluation index of smart city developmental level. Then, these index after reducing let input BP neural network optimized by Genetic Algorithm to train and simulate, find the error of between the actual output value and expected value reach the expected goal. At last, we use directly BP neural network and compare the errors and find using GA-BP neural network prefer. Thus further proves the scientificity and rationality of the evaluation method. © Springer Nature Singapore Pte Ltd. 2018.","Developmental level; GA-BP neural network; PCA theory; Smart city","Computation theory; Genetic algorithms; Neural networks; Smart city; BP neural networks; City construction; Comprehensive evaluation system; Developmental level; Evaluation index; Expected values; Ga-bp neural networks; PCA theory; Principal component analysis",2-s2.0-85031425083
"Sánchez-Silva D.M., Acosta-Mesa H.G., Romo-González T.","Semi-Automatic Analysis for Unidimensional Immunoblot Images to Discriminate Breast Cancer Cases Using Time Series Data Mining",2018,"International Journal of Pattern Recognition and Artificial Intelligence",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026352050&doi=10.1142%2fS0218001418600042&partnerID=40&md5=b052b03e133d9175781c358d56064a26","Breast cancer (BC) is one of the leading causes of death in adult women worldwide and the best way to reduce mortality and improve prognosis is through early diagnosis. Thus, it is necessary to optimize diagnostic methods; one option could be the automatic detection of patterns in 1D-II. In that respect, through recent analysis of unidimensional Immunoblot Images (1D-II), it was possible to distinguish between women with and without breast disease using as a discrimination criterion the presence of autoantibodies (bands) in their blood. However, the analysis of 1D-II is a difficult task even for an expert, generating great subjectivity and complexity in the process of interpretation. In the present study, a semi-automatic methodology for the bands' analysis contained in the 1D-II's was implemented and evaluated, the bands were extracted using digital image processing techniques. This was possible through the recognition of banding patterns represented as time series to distinguish between three classes: women with breast cancer (BC), women with benign breast pathology (BBP) and women without breast pathology (H). The classification was performed using the machine learning algorithm k-nearest neighbors (KNN) with different parameters over the time series representation. The semi-automatic method here presented was able to reduce the time, complexity and subjectivity of the image analysis with the performance metrics compared, obtaining similar percentages for both representations. With the traditional analysis, binary representation [Accuracy 72.8%, Precision 73.42% for three classes (BC, BBP and H) and Accuracy 90.91% Accuracy 92.55% Sensitivity 93.57% and Specificity 92.99% for two classes (BC and H)], versus Time series representation [Accuracy 66.4%, Precision 67.07% for three classes (BC, BBP and H) and Accuracy 86.36% Accuracy 87.31% Sensitivity 95.86% and Specificity 85.56% for two classes (BC and H)]. © 2018 World Scientific Publishing Company.","Breast cancer; digital image processing; protein bands; semi-automatic method; time series data mining; unidimensional immunoblot","Automation; Data mining; Diagnosis; Diseases; Image analysis; Image processing; Learning algorithms; Medical imaging; Nearest neighbor search; Pathology; Pattern recognition; Time series; Breast Cancer; Immunoblots; Protein bands; Semiautomatic methods; Time series data mining; Time series analysis",2-s2.0-85026352050
"Hong T., Yoo H., Kim J., Koo C., Jeong K., Lee M., Ji C., Jeong J.","A model for determining the optimal lease payment in the solar lease business for residences and third-party companies – With focus on the region and on multi-family housing complexes",2018,"Renewable and Sustainable Energy Reviews",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030457104&doi=10.1016%2fj.rser.2017.09.068&partnerID=40&md5=e39d479222f551e60e212e782ace7765","The solar lease business is a recent market trend that has been introduced in many countries. An example is the U.S. solar lease payment (LP) business, which is a payment facility for leasing the solar PV system, where the customers pay a certain amount to a third-party company. In the solar lease business, the profit obtained by residences and third-party companies depends on the solar LP. Several impact factors should be simultaneously considered when estimating the solar LP that guarantees the profitability of the business for both sides. This study aimed to develop a model for determining the optimal solar LP in the solar lease business for residences and third-party companies. A genetic algorithm was utilized to solve the trade-off problem, among the many factors involved. The optimal solar LP was provided according to two categories: (i) the electricity generation rate by region; and (ii) the electricity consumption rates of multi-family housing complexes. In terms of the region, the optimal solar LP depended on the electricity generation rate, and the difference between the highest and lowest monthly solar LPs per unit was US$0.30. In terms of the electricity consumption rate, the optimal solar LP depended on the electricity consumption rate and the number of units, and the difference between the highest and lowest monthly solar LPs per unit was US$3.14. The developed model makes it possible for the government to suggest the optimal solar LP for promoting the solar lease business, and to develop a solar PV system. © 2017 Elsevier Ltd","Integrated multi-objective optimization model; Residence; Solar lease business; Third-party companies; Trade-off problem","Economic and social effects; Electric power utilization; Genetic algorithms; Housing; Multiobjective optimization; Optimization; Profitability; Electricity generation; Electricity-consumption; Multi-family housings; Multi-objective optimization models; Residence; Solar PV systems; Third parties; Trade-off problem; Electric power generation",2-s2.0-85030457104
"Taghilou M., Sefidan A.M., Sojoudi A., Saha S.C.","Solid-liquid phase change investigation through a double pipe heat exchanger dealing with time-dependent boundary conditions",2018,"Applied Thermal Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029481548&doi=10.1016%2fj.applthermaleng.2017.09.069&partnerID=40&md5=cc97d1d12af103ba74fdc7f73706140a","The use of phase change materials has been seriously recommended due to their high capacity of energy saving and delivering arising from phase change process. In addition, a constant temperature of melting or freezing provides a desirable condition to transfer a large amount of heat in a low-temperature fluctuation. This work attempts to present a numerical study to simulate the solid-liquid phase change considering a double pipe heat exchanger dealing with time-dependent boundary conditions. For this reason, a time dependent boundary condition of the third kind is applied. In a condition which the amplitude and periodicity of both bulk temperature and heat transfer coefficient (HTC) are varying in the sinusoidal form. The PCM container involves two separate sections to insert two different PCMs of RT28HC and RT35. In addition, in order to make up for the low thermal conductivity of PCMs, a porous medium with high thermal conductivity is located in PCM containers. Numerical model benefits the enthalpy-porosity approach based on the finite volume method, which models the phase change in the fixed grid domain. Moreover, in order to accurate simulation, fluid flow arising from Boussinesq approximation in the liquid phase is also considered using PISO algorithm. According to the results, the arrangement of RT35 in section A and RT28HC in section B accelerates the system response to the boundary oscillation. In addition, increasing the periodicity of the bulk temperature variation increases the amount of phase changing process in both sections while varying the same parameter of HTC does not influence the liquid fraction of PCMs considerably. © 2017 Elsevier Ltd","Double pipe heat exchanger; Numerical study; Solid-liquid phase change; Thermal conductivity enhancement; Time dependent boundary condition","Approximation algorithms; Boundary conditions; Containers; Energy conservation; Finite volume method; Flow of fluids; Fluid dynamics; Heat exchangers; Heat transfer; Liquids; Numerical methods; Porous materials; Temperature; Temperature distribution; Thermal conductivity; Thermal conductivity of solids; Double-pipe heat exchangers; Numerical study; Solid liquid phase change; Thermal conductivity enhancement; Time-dependent boundary conditions; Phase change materials",2-s2.0-85029481548
"Leung K.H., Choy K.L., Siu P.K.Y., Ho G.T.S., Lam H.Y., Lee C.K.M.","A B2C e-commerce intelligent system for re-engineering the e-order fulfilment process",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029469080&doi=10.1016%2fj.eswa.2017.09.026&partnerID=40&md5=791f5e9f5ff50aeadd94d86cd7d6ce6c","In today's world of digitization, the rise of the e-commerce business around the globe has brought a tremendous change not only in our purchasing habits, but also to the entire retail and logistics industry. Given the irregular e-commerce order arrival patterns, limited time for order processing in e-fulfilment centres, and the guaranteed delivery schedules offered by e-retailers, such as same-day or next-day delivery upon placing an order, logistics service providers (LSPs) must be extremely efficient in handling outsourced e-commerce logistics orders. Without re-engineering the order fulfilment processes, the LSPs are found to have difficulties in executing the order fulfilment process due to the tight handling requirements. This, in turn, delays the subsequent processes in the supply chain, such as last-mile delivery operations, consequently affecting customer satisfaction towards both the retailer and the LSP. In view of the need to improve the efficiency in handling e-commerce orders, this study aims at re-engineering the fulfilment process of e-commerce orders in distribution centres. The concept of warehouse postponement is embedded into a new cloud-based e-order fulfilment pre-processing system (CEPS), by incorporating the genetic algorithm (GA) approach for e-commerce order grouping decision support and a rule-based inference engine for generating operating guidelines and suggesting the use of appropriate handling equipment. Through a case study conducted in a logistics company, the CEPS provides order handling solutions for processing e-commerce logistics orders very efficiently, with a significant reduction in order processing time and traveling distance. In turn, improved operating efficiency in e-commerce order handling allows LSPs to better align strategically with online retailers, who provide customers with aggressive, guaranteed delivery dates. © 2017 Elsevier Ltd","Business process re-engineering; E-commerce logistics; Expert systems; O2O retailing; Order fulfilment; Warehouse postponement applications","Commerce; Customer satisfaction; Decision support systems; Efficiency; Expert systems; Genetic algorithms; Inference engines; Intelligent systems; Reengineering; Sales; Supply chains; Warehouses; Business process re-engineering; Distribution centres; Logistics service provider; O2O retailing; Operating guidelines; Order fulfilment; Order processing time; Rule-based inference; Electronic commerce",2-s2.0-85029469080
"Rezaee Jordehi A.","Enhanced leader particle swarm optimisation (ELPSO): An efficient algorithm for parameter estimation of photovoltaic (PV) cells and modules",2018,"Solar Energy",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032828827&doi=10.1016%2fj.solener.2017.10.063&partnerID=40&md5=c8acf56ebf25a67c1abd5d01eb33b45c","Today, photovoltaic (PV) systems are generating a significant share of electric power. Parameter estimation of photovoltaic cells and modules is a hot research topic and plays an important role in modelling PV systems. This problem is commonly converted into an optimisation problem and is solved by metaheuristic optimisation algorithms. Among metaheuristic optimisation algorithms, particle swarm optimisation (PSO) is a popular leader-based stochastic optimisation algorithm. However, premature convergence is the main drawback of PSO which does not let it to provide high-quality solutions in multimodal problems such as PV cells/modules parameter estimation. In PSO, all particles are pulled toward the leader, so the leader can significantly affect collective performance of the particles. A high-quality leader may pull all particles toward good regions of search space and vice versa. Therefore, in this research, an improved PSO variant, with enhanced leader, named as enhanced leader PSO (ELPSO) is used. In ELPSO, by enhancing the leader through a five-staged successive mutation strategy, the premature convergence problem is mitigated in a way that more accurate circuit model parameters are achieved in the PV cell/module parameter estimation problem. RTC France silicon solar cell, STM6-40/36 module with monocrystalline cells and PVM 752 GaAs thin film cell have been used as the case studies of this research. Parameter estimation results for various PV cells and modules of different technologies confirm that in most of the cases, ELPSO outperforms conventional PSO and a couple of other state of the art optimisation algorithms. © 2017 Elsevier Ltd","Metaheuristics; Parameter estimation; Particle swarm optimisation; PV; PV modeling",,2-s2.0-85032828827
"Saleh F.Z., Sayed S.G., Mohamed A.E.","Low complexity intra-prediction algorithm for video coding standards",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029542095&doi=10.1007%2f978-3-319-64861-3_13&partnerID=40&md5=fba0f9670c15ae4676d20d128d4042eb","In this paper, two intra-prediction techniques have been developed to improve the performance of the video coding standards such as H.264/AVC and H.265/HEVC by minimizing their computational complexity. The first algorithm is named Hybrid Intra-prediction algorithm. This algorithm considers the 16 × 1 and 4 × 4 intra-prediction modes. The second algorithm, named weighted intra-prediction algorithm, has been proposed for the 4 × 4 intra-prediction. In this algorithm, few modes including the DC, the vertical, and the horizontal modes are weighted together into only one mode to predict the 4 × 4 macroblock. The simulation results show that both algorithms can minimize the computational time complexity of the H.264/AVC with limited degradation in the peak signal to noise ratio (PSNR). The simulation results of the hybrid Intra-prediction algorithm show that the time complexity is decreased by around 39% while the PSNR is decreased by 0.3%. In addition, the simulation results of the weighted intra-prediction algorithm show that the time complexity is decreased by 52% and the PSNR is decreased by only 0.7% dB. © 2018, Springer International Publishing AG.","AVC/HEVC; Fast mode decision; Intra prediction coding; Video codec",,2-s2.0-85029542095
"Veloso A.C.A., Silva L.M., Rodrigues N., Rebello L.P.G., Dias L.G., Pereira J.A., Peres A.M.","Perception of olive oils sensory defects using a potentiometric taste device",2018,"Talanta",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028578332&doi=10.1016%2fj.talanta.2017.08.066&partnerID=40&md5=3766c8bce47ba95d47bfd11fbadf5324","The capability of perceiving olive oils sensory defects and intensities plays a key role on olive oils quality grade classification since olive oils can only be classified as extra-virgin if no defect can be perceived by a human trained sensory panel. Otherwise, olive oils may be classified as virgin or lampante depending on the median intensity of the defect predominantly perceived and on the physicochemical levels. However, sensory analysis is time-consuming and requires an official sensory panel, which can only evaluate a low number of samples per day. In this work, the potential use of an electronic tongue as a taste sensor device to identify the defect predominantly perceived in olive oils was evaluated. The potentiometric profiles recorded showed that intra- and inter-day signal drifts could be neglected (i.e., relative standard deviations lower than 25%), being not statistically significant the effect of the analysis day on the overall recorded E-tongue sensor fingerprints (P-value = 0.5715, for multivariate analysis of variance using Pillai's trace test), which significantly differ according to the olive oils’ sensory defect (P-value = 0.0084, for multivariate analysis of variance using Pillai's trace test). Thus, a linear discriminant model based on 19 potentiometric signal sensors, selected by the simulated annealing algorithm, could be established to correctly predict the olive oil main sensory defect (fusty, rancid, wet-wood or winey-vinegary) with average sensitivity of 75±3% and specificity of 73±4% (repeated K-fold cross-validation variant: 4 folds×10 repeats). Similarly, a linear discriminant model, based on 24 selected sensors, correctly classified 92±3% of the olive oils as virgin or lampante, being an average specificity of 93±3% achieved. The overall satisfactory predictive performances strengthen the feasibility of the developed taste sensor device as a complementary methodology for olive oils’ defects analysis and subsequent quality grade classification. Furthermore, the capability of identifying the type of sensory defect of an olive oil may allow establishing helpful insights regarding bad practices of olives or olive oils production, harvesting, transport and storage. © 2017 Elsevier B.V.","Chemometrics; Olive oil; Potentiometric electronic tongue; Sensory analysis; Sensory defects","Defects; Electronic tongues; Multivariant analysis; Olive oil; Potentiometers (electric measuring instruments); Quality control; Sensory perception; Simulated annealing; Chemometrics; K fold cross validations; Linear discriminant model; Multivariate analysis of variances; Potentiometric electronic tongue; Predictive performance; Relative standard deviations; Simulated annealing algorithms; Sensory analysis",2-s2.0-85028578332
"Ojeda-Magaña B., Quintanilla-Domínguez J., Ruelas R., Barba L.G., Andina D.","Improvement of the Image Sub-Segmentation for Identification and Differentiation of Atypical Regions",2018,"International Journal of Pattern Recognition and Artificial Intelligence",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030866237&doi=10.1142%2fS021800141860011X&partnerID=40&md5=0150832c84e746618a121b96269670cf","A new sub-segmentation method has been proposed in 2009 which, in digital images, help us to identify the typical pixels, as well as the less representative pixels or atypical of each segmented region. This method is based on the Possibilistic Fuzzy c-Means (PFCM) clustering algorithm, as it integrates absolute and relative memberships. Now, the segmentation problem is related to isolate each one of the objects present in an image. However, and considering only one segmented object or region represented by gray levels as its only feature, the totality of pixels is divided in two basic groups, the group of pixels representing the object, and the others that do not represent it. In the former group, there is a sub-group of pixels near the most representative element of the object, the prototype, and identified here as the typical pixels, and a sub-group corresponding to the less representative pixels of the object, which are the atypical pixels, and generally located at the borders of the pixels representing the object. Besides, the sub-group of atypical pixels presents greater tones (brighter or towards the white color) or smaller tones (darker or towards black color). So, the sub-segmentation method offers the capability to identify the sub-region of atypical pixels, although without performing a differentiation between the brighter and the darker ones. Hence, the proposal of this work contributes to the problem of image segmentation with the improvement on the detection of the atypical sub-regions, and clearly recognizing between both kind of atypical pixels, because in many cases only the brighter or the darker atypical pixels are the ones that represent the object of interest in an image, depending on the problem to be solved. In this study, two real cases are used to show the contribution of this proposal; the first case serves to demonstrate the pores detection in soil images represented by the darker atypical pixels, and the second one to demonstrate the detection of microcalcifications in mammograms, represented in this case by the brighter atypical pixels. © 2018 World Scientific Publishing Company.","atypical pixels; Hybrid clustering; regions of interest; sub-segmentation","Calcification (biochemistry); Clustering algorithms; Image enhancement; Image segmentation; Digital image; Hybrid clustering; Microcalcifications; Possibilistic; Regions of interest; Segmentation methods; Segmented objects; Segmented regions; Pixels",2-s2.0-85030866237
"Rajić T., Stojanović Z.","An algorithm for longitudinal differential protection of transmission lines",2018,"International Journal of Electrical Power and Energy Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026359401&doi=10.1016%2fj.ijepes.2017.07.001&partnerID=40&md5=3e1dabed3068fe29a95ffa857ec6641d","This paper describes a new algorithm for longitudinal differential protection of transmission lines. Classic stabilization is an unreliable method for avoiding unnecessary relay tripping in case of current transformer saturation during faults outside the protected zone. There are various methods for detecting current transformer saturation. The paper's thesis is that rather than the stabilization current, the direction of the currents introduced into the relay should be monitored. The proposed algorithm has been compared to the algorithms used by renowned relay producers. Different types of faults have been simulated, both within and outside of the protected zone, and the paper demonstrates how the relay trips when the algorithm in question is used. The results have proven that current transformer saturation does not affect protection operation, and that a prompt relay response is obtained for faults occurring within the protected zone. © 2017 Elsevier Ltd","Differential relay; Power system protection; Transmission line","Electric currents; Electric equipment protection; Electric instrument transformers; Electric lines; Electric power system protection; Electric power transmission; Electric relays; Electric transformers; Stabilization; Current transformer saturation; Differential relay; Longitudinal differential protection; Power system protection; Protected zones; Transformer protection",2-s2.0-85026359401
"Sharma S., Patel A.K., Mitra R., Jauhari R.","Reinforcement based optimal routing algorithm for multiple sink based wireless sensor networks",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032644534&doi=10.1007%2f978-981-10-3376-6_52&partnerID=40&md5=bdfab43b767024f6a6a8c943893f9bb2","Routing in wireless sensor networks has been a recent area of research because of its increased use in diverse application environments. Sensor nodes are energy constrained which possess a formidable challenge in designing efficient routing algorithms for them. Most of the scenarios where sensor networks are used such as battle field surveillance, health monitoring are delay sensitive in nature. To mitigate these problems, we have proposed two routing algorithms in this paper: one based on multiple static sink based scenario and the other based on multiple mobile sink based scenario. Both of these protocols use reinforcement learning methodology in order to solve the routing problem in an intelligent and efficient way. © Springer Nature Singapore Pte Ltd. 2018.","Reinforcement; Routing; Sensor; Sink",,2-s2.0-85032644534
"Raghavendra C.G., Vilas I.M., Prasad N.N.S.S.R.K.","Improvement in PMEPR reduction for OFDM radar signal using PTS algorithm",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021213717&doi=10.1007%2f978-981-10-3223-3_17&partnerID=40&md5=66ae23c1b1df91c33443c76f6ece2657","In this paper we suggest a method to address the complication of variable amplitude in multicarrier signal. Multifrequency Complementary Phase-Coded (MCPC) signal has fluctuations in amplitude because it is the sum of carriers with different frequency. To avoid non linear working of power amplifiers at transmitter, it is desirable to reduce Peak to Mean Envelope Power Ratio (PMEPR) of the signal. We have tried two algorithms to reduce PMEPR and sidelobes. Namely, clipping technique which is a signal distortion technique and one from signal scrambling technique called as Partial Transmit Sequence (PTS) algorithm. © Springer Nature Singapore Pte Ltd. 2018.","Multifrequency Complementary Phase-Coded radar (MCPC); Partial Transmit Sequence (PTS); Peak to Mean Envelope Power Ratio (PMEPR)","Intelligent computing; Orthogonal frequency division multiplexing; Power amplifiers; Clipping techniques; Different frequency; Distortion techniques; Multi frequency; Multicarrier signal; Partial transmit sequence; Peak to mean envelope power ratio; Variable amplitudes; Radar",2-s2.0-85021213717
"Malashin R.O.","Core algorithm for structural verification of keypoint matches",2018,"Intelligent Systems Reference Library",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032580759&doi=10.1007%2f978-3-319-67516-9_9&partnerID=40&md5=563d3d42ac22ef384e99a17797f255fd","Outlier elimination is a crucial stage in keypoints-based methods, especially in extreme conditions. In this chapter, a fast and robust “Core” Structural Verification Algorithm (CSVA) for a variety of applications and feature extraction methods is developed. The proposed algorithm pipeline involves many-to-one matches’ exclusion, the improved Hough clustering of keypoint matches, and cluster verification procedure. The Hough clustering is improved through an accurate incorporation of translation parameters of similarity transform and “partially ignoring” the boundary impact using two displaced accumulators. The cluster verification procedure involves the use of modified RANSAC. It is also shown that the use of the nearest neighbour ratio may eliminate too many inliers, when two images are matched (especially in extreme conditions), and the preferable method is a simple many-to-one matches exclusion. The theory and experiment prove the propriety of the suggested parameters, algorithms, and modifications. The developed cluster analysis algorithms are robust and computationally efficient at the same time. These algorithms use some specific information (rigidity of objects in a scene), consume low volume memory and only 3 ms in average on a standard Intel i7 processor for verification of 1,000 matches (i.e. magnitudes less than the time needed to generate those matches). The CSVA has been successfully applied to practical tasks with minor adaptation, such as the matching of 3D indoor scenes, retrieval of images of 3D scenes based on the concept of Bag of Words (BoWs), and matching of aerial and cosmic photographs with strong appearance changes caused by season, day-time, and viewpoint variation. Eliminating a huge number of outliers using geometrical constraints allowed to reach the reliability and accuracy in all solutions. © 2018, Springer International Publishing AG.","3D images; Aerospace images; Bag of words; Hough clustering; Keypoint-based methods; Nearest neighbour ratio; Outlier elimination; RANSAC; Scene geometry; Structural analysis",,2-s2.0-85032580759
"Gamal M., Rizk R., Mahdi H., Elhady B.","Bio-inspired load balancing algorithm in cloud computing",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029515855&doi=10.1007%2f978-3-319-64861-3_54&partnerID=40&md5=f3af3d53f6a3cb419a534aa380d31af5","Cloud computing is a widespread computing concepts which access a huge amount of data that can be used by more clients. Therefore, load balancing between resources is an important field for scheduling tasks to achieve better performance. In this paper, a Hybrid artificial Bee and Ant Colony optimization (H_BAC) load balancing algorithm is proposed. It depends on joining the important behavior of Ant Colony Optimization (ACO) such as discovering good solutions rapidly and Artificial Bee Colony (ABC) Algorithm such as collective interaction of bees and sharing information by waggle dancing. The experimental results show that H_BAC improves execution time, response time, makespan, resource utilization and standard deviation. This improvement reaches about 40% in the execution time and response time and 30% in the makespan over the other algorithms. © 2018, Springer International Publishing AG.","Ant Colony Optimization; Artificial Bee Colony; Bio-inspired systems; Cloud computing; Load balancing",,2-s2.0-85029515855
"Bica M., Gorgan D.","Data locality aware algorithm for task execution on distributed, cloud based environments",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026315452&doi=10.1007%2f978-3-319-61566-0_51&partnerID=40&md5=0f7fdc8c59b2bb37a95db999a139b477","A solution that proactively analyzes the shape of the operator graph of a task based cloud application is studied in this paper. Based on the analysis of the execution graph and operator metadata, the nodes of the execution graph are properly clustered so that highly connected operators are scheduled on the same or nearby computing resources. Two graph partitioning algorithms are studied, implemented and compared. The graph partitioning efficiency is visually analyzed and compared by using existing graph visualization software. © Springer International Publishing AG 2018.","Application execution; Distributed systems; Graph partitioning","Computer programming; Computer science; Application execution; Cloud applications; Computing resource; Connected operator; Distributed systems; Graph Partitioning; Graph visualization; Task executions; Graph theory",2-s2.0-85026315452
"Sarkar A.K., Tan Z.-H.","Incorporating pass-phrase dependent background models for text-dependent speaker verification",2018,"Computer Speech and Language",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029045929&doi=10.1016%2fj.csl.2017.07.010&partnerID=40&md5=6fce18d24070bf50378c1035e2cde26e","In this paper, we propose pass-phrase dependent background models (PBMs) for text-dependent (TD) speaker verification (SV) to integrate the pass-phrase identification process into the conventional TD-SV system, where a PBM is derived from a text-independent background model through adaptation using the utterances of a particular pass-phrase. During training, pass-phrase specific target speaker models are derived from the particular PBM using the training data for the respective target model. While testing, the best PBM is first selected for the test utterance in the maximum likelihood (ML) sense and the selected PBM is then used for the log likelihood ratio (LLR) calculation with respect to the claimant model. The proposed method incorporates the pass-phrase identification step in the LLR calculation, which is not considered in conventional standalone TD-SV systems. The performance of the proposed method is compared to conventional text-independent background model based TD-SV systems using either Gaussian mixture model (GMM)-universal background model (UBM) or hidden Markov model (HMM)-UBM or i-vector paradigms. In addition, we consider two approaches to build PBMs: speaker-independent and speaker-dependent. We show that the proposed method significantly reduces the error rates of text-dependent speaker verification for the non-target types: target-wrong and impostor-wrong while it maintains comparable TD-SV performance when impostors speak a correct utterance with respect to the conventional system. Experiments are conducted on the RedDots challenge and the RSR2015 databases that consist of short utterances. © 2018 Elsevier Ltd","GMM-UBM; HMM-UBM; I-vector; Pass-phrase dependent background models (PBMs); Speaker verification; Text-dependent","Gaussian distribution; Hidden Markov models; Learning algorithms; Lunar surface analysis; Markov processes; Maximum likelihood; Speech processing; Trellis codes; Background model; GMM-UBM; HMM-UBM; I vectors; Speaker verification; Text-dependent; Speech recognition",2-s2.0-85029045929
"Grunt O., Plucar J., Štáková M., Janečko T., Zelinka I.","Modeling of marketing processes using markov decision process approach",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031420987&doi=10.1007%2f978-3-319-68321-8_48&partnerID=40&md5=a5fb019a058c212bf75bd9577cb2b93e","In this paper, an application of Markov Decision Processes (MDP) for modeling selected marketing process is presented. The process is converted into MDP model, where states of the MDP are determined by a configuration of state vector. Elements of the state vector represent most important attributes of the customer in the modeled process. Movement between the states is determined by actions of the customer. In constructed MDP model, individual states with assigned initial reward values then represent consequences of action chosen by the customer resulting in either incresing or reducing the revenue following moving into these states. Value iteration method is then used for computation of the expected final rewards for each state. Based on provided realistic data, customer behavior is analyzed and the best course of action is proposed. Model suitability for future predictions of desired action outcome rate is discussed as well. © Springer International Publishing AG 2018.",,"Behavioral research; Commerce; Iterative methods; Learning algorithms; Marketing; Markov processes; Course of action; Customer behavior; Future predictions; Marketing process; Markov Decision Processes; Model suitability; State vector; Value iteration; Sales",2-s2.0-85031420987
"Grandi F.","On the analysis of Bloom filters",2018,"Information Processing Letters",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029811498&doi=10.1016%2fj.ipl.2017.09.004&partnerID=40&md5=78a14dccf4c7e12c90d08439dd49fa90","The Bloom filter is a simple random binary data structure which can be efficiently used for approximate set membership testing. When testing for membership of an object, the Bloom filter may give a false positive, whose probability is the main performance figure of the structure. We complete and extend the analysis of the Bloom filter available in the literature by means of the γ-transform approach. Known results are confirmed and new results are provided, including the variance of the number of bits set to 1 in the filter. We consider the choice of bits to be set to 1 when an object is inserted both with and without replacement, in what we call standard and classic Bloom filter, respectively. Simple iterative schemes for the computation of the false positive probability and a new non-iterative approximation, taking into account the variance of bits set to 1, are also provided. © 2017 Elsevier B.V.","Analysis of algorithms; Bloom filters; Data structures; γ-Transform","Bandpass filters; Iterative methods; Analysis of algorithms; Bloom filters; False positive; Gamma transforms; Iterative schemes; Non-iterative; Random binary data; Set membership; Data structures",2-s2.0-85029811498
"Teppan E.C., Friedrich G.","Heuristic constraint answer set programming for manufacturing problems",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032333019&doi=10.1007%2f978-3-319-66790-4_7&partnerID=40&md5=1a7fc90984ee090056c9c0466f2575f1","Constraint answer set programming (CASP) is a family of hybrid approaches integrating answer set programming (ASP) and constraint programming (CP). These hybrid approaches have already proven to be successful in various domains. In this paper we present the CASP solver ASCASS (A Simple Constraint Answer Set Solver) which provides novel methods for defining and exploiting search heuristics. Beyond the possibility of using already built-in problem-independent heuristics, ASCASS allows on the ASP level the definition of problem-dependent variable selection, value selection and pruning strategies which guide the search of the CP solver. In this context, we investigate the applicability and performance of CASP in general and ASCASS in particular in two important manufacturing problem domains: system configuration and job scheduling. © 2018, Springer International Publishing AG.",,"Computer programming; Constraint theory; Heuristic algorithms; Heuristic programming; Logic programming; Manufacture; Answer set programming; Constraint programming; Dependent variables; Hybrid approach; Problem domain; Pruning strategy; Search heuristics; System configurations; Heuristic methods",2-s2.0-85032333019
"Edincliler A., Cabalar A.F., Cevik A., Isik H.","New formulations for dynamic behavior of sand-waste tire mixtures in a small range of strain amplitudes",2018,"Periodica Polytechnica Civil Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032689848&doi=10.3311%2fPPci.8698&partnerID=40&md5=3b8738e9bbea2d2b04066b16db6d4547","This paper describes the results of a series of cyclic triaxial tests on sand - waste tire mixtures, and applications of genetic programming (GP) and stepwise regression (SR) for the prediction of damping ratio and shear modulus of the mixtures tested. In the tests, shear modulus, and damping ratio of the geomaterials were measured for a strain range of 0.0001% up to 0.04%. The input variables in the developed GP and SR models are the waste tire content (0%, 10%, 20%, and 30%), waste tire type (tire crumbs or tire buffings), strain, and confining pressures (40 kPa, 100 kPa, and 200 kPa), and outputs are shear modulus and damping ratio. Test results show that the shear modulus and the damping ratio of the mixtures are strongly influenced by the waste tire inclusions. The performance of the proposed GP models (R2 = 0.95 for shear modulus, and R2 = 0.94 for damping ratio) are observed to be more accurate than that of the SR models (R2 = 0.87 for shear modulus, and R2 = 0.91 for damping ratio). © 2017, Budapest University of Technology and Economics. All rights reserved.","Cyclic triaxial testing; Genetic programming; Sand; Stepwise regression; Waste tire","Damping; Elastic moduli; Genetic algorithms; Genetic programming; Mixtures; Sand; Shear strain; Confining pressures; Cyclic tri-axial tests; Cyclic triaxial testing; Dynamic behaviors; Input variables; Stepwise regression; Strain amplitude; Waste tires; Tires",2-s2.0-85032689848
"Aksyonov K., Antonova A., Goncharova N.","Choice of the scheduling technique taking into account the subcontracting optimization",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030176419&doi=10.1007%2f978-3-319-67934-1_26&partnerID=40&md5=cd37bf6aa86877a381ec3c6f7005a7d4","This paper analyzes a number of scheduling technique from classical network planning techniques to hybrid techniques based on the integration of knowledge-based simulation, evolutionary modeling, and heuristic search. The choice of the scheduling technique is based on the following criteria. First, solving the problems of subcontracting optimization, works rescheduling, analysis of alternative plans, renewable and non-renewable resources consideration. Secondly, application of the knowledge-based modeling and heuristic methods in the process of these problems solving. Taking into account the above criteria, a hybrid technique of multiagent genetic optimization has been chosen as the scheduling technique with subcontracting optimization. © Springer International Publishing AG 2018.",,"Heuristic algorithms; Heuristic methods; Knowledge based systems; Optimization; Scheduling; Analysis of alternatives; Evolutionary models; Genetic optimization; Integration of knowledge; Knowledge-based model; Network planning technique; Renewable and non-renewable resources; Scheduling techniques; Signal processing",2-s2.0-85030176419
"Pavão L.V., Miranda C.B., Costa C.B.B., Ravagnani M.A.S.S.","Efficient multiperiod heat exchanger network synthesis using a meta-heuristic approach",2018,"Energy",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031935209&doi=10.1016%2fj.energy.2017.09.147&partnerID=40&md5=1b4111f3e9358ea95edf6e71f56df329","Multiperiod heat exchanger networks (HEN) are required in plants with seasonal alterations to operating conditions. Like for single-period HEN, the synthesis of multiperiod HEN can be formulated as a mathematical programming optimization problem. However, since the network needs to feasibly perform heat integration under different process conditions, additional constraints are required and problem complexity is increased. Studies on the subject based on mathematical programming often use deterministic approaches and rely on commercial solvers. In this work, a meta-heuristic two-level method based on Simulated Annealing and Rocket Fireworks Optimization (SA-RFO), originally developed for single-period HEN synthesis, is adapted to handle multiperiod HEN optimization. A new post-optimization (PO) strategy is coupled with the main method in order to improve the results. Four case studies are investigated and results are compared to the literature. The solutions achieved presented lower total annual costs (TAC) than those obtained by other methods and the new PO scheme was able to significantly improve the results. © 2017 Elsevier Ltd","Meta-heuristics; Multiperiod heat exchanger networks; Optimization","Heat exchangers; Heuristic algorithms; Mathematical programming; Optimization; Rockets; Simulated annealing; Commercial solvers; Deterministic approach; Heat exchanger network; Heat exchanger network synthesis; Mathematical programming / optimization; Meta heuristics; Meta-heuristic approach; Operating condition; Heuristic methods; complexity; energy efficiency; heat transfer; heuristics; linear programing; network analysis; operations technology; optimization; simulated annealing",2-s2.0-85031935209
"Rajesh Kumar P., Arun Prasath T., Pallikonda Rajasekaran M., Vishnuvarthanan G.","Brain subject estimation using PSO K-means clustering - An automated aid for the assessment of clinical dementia",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028423828&doi=10.1007%2f978-3-319-63673-3_58&partnerID=40&md5=efb9760887e6ef1f8679b662a5c45030","Structural brain imaging plays an essential role in acknowledgement of variations that presence in brain relevant to Alzheimer’s disease and different kind of brain disorders. Mostly MR Imaging has preferred because of its higher resolution capabilities to diagnose AD than other modalities. Magnetic resonance imaging is an efficient for visualization and diagnosing various brain disorder in brain. Pathology segmentation for differentiate the diseases affected region to make separation of necrosis and similar damaged tissues cause by disease from normal tissue using clustering principle take up in image processing. Clustering is implemented to make grouping similar characteristics pixels together as a group. In this paper k-mean clustering is performed to separate White Matter (WM), Grey Matter (GM), Cerebrospinal Fluid (CSF), Lateral ventricle, hippocampus region as different individual group with accomplice of Partial Swarm Optimization (PSO) in brain. Different k- mean cluster initialization methods were executed and an exact segmentation were done using PSO k-mean clustering. Volume of both grey matter and white matter are estimated to make comparison with the bench mark images for classifying the various stages of AD. © 2018, Springer International Publishing AG.","Alzheimer’s disease (AD); K-means clustering; Magnetic resonance imaging; Particle swarm optimization (PSO)","Brain mapping; Clustering algorithms; Diagnosis; Image processing; Image segmentation; Intelligent systems; Magnetic resonance imaging; Neuroimaging; Particle swarm optimization (PSO); Pathology; Tissue; Alzheimer; Cerebro spinal fluids; Cluster initialization methods; Higher resolution; K-mean clustering; K-means clustering; Lateral ventricles; Partial swarm optimizations; Cerebrospinal fluid",2-s2.0-85028423828
"Athertya J.S., Saravana Kumar G.","Sensitivity analysis on effect of biomechanical factors for classifying vertebral deformities",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028590997&doi=10.1007%2f978-3-319-60618-7_2&partnerID=40&md5=5c876bec875f3cfd0d8cc30c693c5a7d","Classification of degenerations prevalent in human population is considered to be a crucial task which is performed by a physician or the radiologist. With numerous data being generated and innumerable features getting extracted, identification of normal and pathological case becomes a daunting process. Data learning techniques provide valuable resources in automating the entire procedure easing the burden on the consultant physician. However, since the inception of various machine learning techniques, feasible solution at the cost of computational expense needs to be evaluated. Factors considered for classification play a significant role in defining the accuracy of a system. The current study aims at demonstrating the trade off achieved at the expense of accuracy amongst the number of features and instances. In this article, vertebral column dataset from UCI repository is used for training and testing. Effect of various data pre-processing techniques are presented alongside an extensive study on feature selection method. For validation, breast tissue dataset from the former repository is considered and analyzed. © Springer International Publishing AG 2018.",,"Data handling; Economic and social effects; Learning algorithms; Learning systems; Sensitivity analysis; Soft computing; Statistical tests; Biomechanical factors; Computational expense; Data preprocessing; Feature selection methods; Learning techniques; Machine learning techniques; Pathological case; Training and testing; Pattern recognition",2-s2.0-85028590997
"Lin Z., Du J., Li Y., Ye L., Luo A.","Scenic negative comment clustering based on balance weighted comment topic model",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030838127&doi=10.1007%2f978-981-10-6496-8_28&partnerID=40&md5=c0e9ee889c4c15d3495768e34da24cc3","The scenic comment information from visitors often hidden the different aspects of the recommendations and expectations of the attractions, the extraction of these key information will help the spot managers find their own shortcomings and improve themselves. In this paper, we improved the author topic model and proposed a model of clustering the negative comments of the scenic spots. There are two improvements from our proposed model. Firstly, we added the importance of the comment category to the text clustering. Secondly, in order to prevent the stop words accumulating in the sampling process, we introduced the balance weight to the proposed model. Experiments showed that the model could not only effectively cluster these data, but also could extract the rich information related to different comment categories from the clustering results, which could help the managers of the scenic spots to better manage the attractions and attract tourists. © 2018, Springer Nature Singapore Pte Ltd.","Clustering analysis; Data mining; Scenic negative comment; Topic model","Clustering algorithms; Intelligent systems; Managers; Clustering analysis; Clustering results; Sampling process; Scenic negative comment; Scenic spot; Stop word; Text Clustering; Topic Modeling; Data mining",2-s2.0-85030838127
"Poon L.K.M., Liu A.H., Zhang N.L.","UC-LTM: Unidimensional clustering using latent tree models for discrete data",2018,"International Journal of Approximate Reasoning",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032704689&doi=10.1016%2fj.ijar.2017.10.020&partnerID=40&md5=5e4e6526344834c950f4b27ccdbe8ab1","This paper is concerned with model-based clustering of discrete data. Latent class models (LCMs) are usually used for this task. An LCM consists of a latent variable and a number of attributes. It makes the overly restrictive assumption that the attributes are conditionally independent given the latent variable. We propose a novel method to relax this assumption. The key idea is to partition the attributes into groups such that correlations among the attributes in each group can be properly modeled by using a single latent variable. The latent variables for the attribute groups are then used to build a number of models, and one of them is chosen to produce the clustering results. The new method produces unidimensional clustering using latent tree models and is named UC-LTM. Extensive empirical studies were conducted to compare UC-LTM with several model-based and distance-based clustering methods. UC-LTM outperforms the alternative methods in most cases, and the differences are often large. Further, analysis on real-world social capital data further shows improved results given by UC-LTM over results given by LCMs in a previous study. © 2017 Elsevier Inc.","Latent class models; Latent tree models; Probabilistic graphical models; Unidimensional clustering; Unsupervised learning","Clustering algorithms; Equivalence classes; Unsupervised learning; Clustering results; Empirical studies; Latent class model; Model-based clustering; Model-based OPC; Probabilistic graphical models; Tree models; Unidimensional clustering; Trees (mathematics)",2-s2.0-85032704689
"Hajek P.","Predicting corporate investment/non-investment grade by using interval-valued fuzzy rule-based systems—A cross-region analysis",2018,"Applied Soft Computing Journal",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032451278&doi=10.1016%2fj.asoc.2017.10.037&partnerID=40&md5=5733868fba5d5c28d5dbd1cd7f172c21","Systems for predicting corporate rating have attracted considerable interest in soft computing research due to the requirements for both accuracy and interpretability. In addition, the high uncertainty associated primarily with linguistic uncertainties and disagreement among experts is another challenging problem. To overcome these problems, this study proposes a hybrid evolutionary interval-valued fuzzy rule-based system, namely IVTURS, combined with evolutionary feature selection component. This model is used to predict the investment/non-investment grades of companies from four regions, namely Emerging countries, the EU, the United States, and other developed countries. To evaluate prediction performance, a yield measure is used that combines the return and default rates of companies. Here, we show that using interval-valued fuzzy sets leads to higher accuracy, particularly with the growing granularity at the fuzzy partition level. The proposed prediction model is then compared with several state-of-the-art evolutionary fuzzy rule-based systems. The obtained results show that the proposed model is especially suitable for high-dimensional problems, without facing rule base interpretability issues. This finding indicates that the model is preferable for investors oriented toward developed markets such as the EU and the United States. © 2017 Elsevier B.V.","Credit rating; Evolutionary algorithms; Financial distress; Interval-valued fuzzy rule-based systems","Evolutionary algorithms; Forecasting; Fuzzy rules; Knowledge based systems; Rating; Soft computing; Corporate investments; Credit ratings; Financial distress; High-dimensional problems; Interval-valued; Interval-valued fuzzy sets; Linguistic uncertainty; Prediction performance; Fuzzy inference",2-s2.0-85032451278
"Chen P., Wilbik A., van Loon S., Boer A.-K., Kaymak U.","Finding the optimal number of features based on mutual information",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029416210&doi=10.1007%2f978-3-319-66830-7_43&partnerID=40&md5=99d341c1ecfdfd6925679a1ca4b7ba53","For high dimensional data analytics, feature selection is an indispensable preprocessing step to reduce dimensionality and keep the simplicity and interpretability of models. This is particularly important for fuzzy modeling since fuzzy models are widely recognized for their transparency and interpretability. Despite the substantial work on feature selection, there is little research on determining the optimal number of features for a task. In this paper, we propose a method to help find the optimal number of feature effectively based on mutual information. © 2018, Springer International Publishing AG.","Feature selection; Fuzzy models; Mutual information; Number of features","Clustering algorithms; Computer circuits; Feature extraction; Fuzzy sets; Fuzzy modeling; Fuzzy models; High dimensional data; Interpretability; Mutual informations; Number of features; Optimal number; Pre-processing step; Fuzzy logic",2-s2.0-85029416210
"Walkowiak T.","Language processing modelling notation – Orchestration of NLP microservices",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020785890&doi=10.1007%2f978-3-319-59415-6_44&partnerID=40&md5=a429f935ac40248556817e8d5b077409","The paper presents Language Processing Modelling Notation (LPMN). It is a formal language used to orchestrate a set of NLP microservices. The LPMN allows modeling and running complex workflows of language and machine learning tools. The scalability of the solution was achieved by a usage of message-oriented middleware. LPMN is used for developing text mining application with web-based interface and performing research experiments that requires a usage of NLP and machine learning tools. © Springer International Publishing AG 2018.","Microservices; Natural language processing; Orchestration; Text mining; Web-based application","Artificial intelligence; Data mining; Formal languages; Learning algorithms; Learning systems; Middleware; Multimedia systems; Natural language processing systems; Websites; Complex workflows; Language processing; Message oriented middleware; Microservices; Orchestration; Text mining; Web-based applications; Web-based interface; Modeling languages",2-s2.0-85020785890
"Rahab H., Zitouni A., Djoudi M.","SIAAC: Sentiment Polarity Identification on Arabic Algerian Newspaper Comments",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029574192&doi=10.1007%2f978-3-319-67621-0_12&partnerID=40&md5=5aa1edec5b5b104f1ffeb4f527d6d716","It is a challenging task to identify sentiment polarity in Arabic journals comments. Algerian daily newspapers interest more and more people in Algeria, and due to this fact they interact with it by comments they post on articles in their websites. In this paper we propose our approach to classify Arabic comments from Algerian Newspapers into positive and negative classes. Publicly-available Arabic datasets are very rare on the Web, which make it very hard to carring out studies in Arabic sentiment analysis. To reduce this gap we have created SIAAC (Sentiment polarity Identification on Arabic Algerian newspaper Comments) a corpus dedicated for this work. Comments are collected from website of well-known Algerian newspaper Echorouk. For experiments two well known supervised learning classifiers Support Vector Machines (SVM) and Naïve Bayes (NB) were used, with a set of different parameters for each one. Recall, Precision and F_measure are computed for each classifier. Best results are obtained in term of precision in both SVM and NB, also the use of bigram increase the results in the two models. Compared with OCA, a well know corpus for Arabic, SIAAC give a competitive results. Obtained results encourage us to continue with others Algerian newspaper to generalize our model. © 2018, Springer International Publishing AG.","Arabic comments; Machine learning; Natural Language Processing; Naïve Bayes; Newspaper; Opinion mining; Sentiment analysis; Support Vector Machines","Artificial intelligence; Computational methods; Data mining; Learning algorithms; Learning systems; Linguistics; Natural language processing systems; Newsprint; Sodium; Support vector machines; Websites; Algeria; Arabic comments; Daily newspapers; Learning classifiers; Newspaper; Opinion mining; Sentiment analysis; Taxonomies",2-s2.0-85029574192
"Wiercioch M.","Feature selection in texts",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019213117&doi=10.1007%2f978-3-319-59162-9_35&partnerID=40&md5=7a8b2df79eb5e7bf52ca3c03c577e1b4","Feature selection is used in many application areas relevant to expert and intelligent systems, such as machine learning, data mining, cheminformatics and natural language processing. In this study we propose methods for feature selection and features analysis based on Support Vector Machines (SVM) with linear kernels. We explore how these techniques can be used to obtain some interesting information for further exploration of text data. The results provide satisfactory observations which may lead to progress in feature selection field. © Springer International Publishing AG 2018.","Dimension reduction; Feature selection; Support vector machines; Text classification","Classification (of information); Data mining; Intelligent systems; Learning algorithms; Learning systems; Natural language processing systems; Support vector machines; Text processing; Application area; Cheminformatics; Dimension reduction; Interesting information; Linear kernel; NAtural language processing; Text classification; Text data; Feature extraction",2-s2.0-85019213117
"De Vito S., Fattoruso G., Esposito E., Salvato M., Agresta A., Panico M., Leopardi A., Formisano F., Buonanno A., Delli Veneri P., Di Francia G.","A distributed sensor network for waste water management plant protection",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029624585&doi=10.1007%2f978-3-319-55077-0_39&partnerID=40&md5=d623d65360d9f49d1b4254d9a683dab5","Waste water management process has a significant role in guarantee sea and surface water bodies water quality with direct impact on tourism based economy and public health. Protection of this critical infrastructure form illicit discharges is hence paramount for the whole society. Here, We propose a pervasive monitoring centered approach to the protection of wastewater management plant. An hybrid sensor network is actually deployed along the wastewater network including several different transducers. Incepted data are harmonized and processed with an integrated SWMM model and machine learning based approach in order to forecast water qualitative and quantitative aspects, detect and localize anomalies. An advanced WEBGIS-SOS based interface conveys relevant information to the management entity allowing it to take appropriate actions in a timely way, reducing and mitigating the impacts of illicit discharges. © Springer International Publishing AG 2018.","Distributed sensor network; Plant protection; Wastewater management; Water quality monitoring","Hybrid sensors; Learning algorithms; Learning systems; Sensor networks; Surface waters; Water management; Water quality; Direct impact; Distributed sensor networks; Pervasive monitoring; Plant protection; Surface water body; Wastewater management; Wastewater network; Water quality monitoring; Waste management",2-s2.0-85029624585
"Suryanarayana D., Kanakam P., Hussain S.M., Gupta S.","High-performance linguistics scheme for cognitive information processing",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026736387&doi=10.1007%2f978-981-10-3373-5_37&partnerID=40&md5=61f7a986bf3de013f9fbc34353d7a58a","Natural language understanding is a principal segment of natural language processing in semantic analysis to the use of pragmatics to originate meaning from context. Information retrieval (IR) is one of the emerging areas to deal with enormous amounts of data, which are in the form of natural language. Content of the query posed will affect both volume of data and design of IR applications. This paper presents a cognition-applied methodology termed as High-Performance Linguistics (HPL), which is a question-answering system for interpreting a natural language sentence/query. It constitutes three phases of computations: parsing, triplet generation and triplet mapping/matching. The generation of the triplets for the knowledge base is to create new data and compare them with that of stored triplets in the database. Thus, the generation of the cognitive question-answering system can make easy using this machine learning techniques on the generated triplet database. © Springer Nature Singapore Pte Ltd. 2018.","Indexing; Information retrieval; Linguistics; Ontology; Pragmatics; RDF; Semantics; Triplets","Artificial intelligence; Computation theory; Indexing (of information); Information retrieval; Intelligent computing; Knowledge based systems; Learning algorithms; Learning systems; Linguistics; Ontology; Query processing; Semantic Web; Semantics; Syntactics; Cognitive information processing; Machine learning techniques; Natural language understanding; Natural languages; Pragmatics; Question answering systems; Semantic analysis; Triplets; Natural language processing systems",2-s2.0-85026736387
"Schophuizen M., Kreijns K., Stoyanov S., Kalz M.","Eliciting the challenges and opportunities organizations face when delivering open online education: A group-concept mapping study",2018,"Internet and Higher Education",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028089126&doi=10.1016%2fj.iheduc.2017.08.002&partnerID=40&md5=11fd259cf95477d37ac291efd93b9841","The global attention for open online education (OOE) caused a situation in which higher education institutions (HEIs) reconsider the way they deliver education to the population. With a funding policy, the Dutch Government aims to stimulate OOE in HEIs. The goal is to create more expedient, accessible and personalized learning experiences, that contribute to an improvement of quality of education and study success. However, many projects are failing to embed OOE within the institution. In this study, we elicited the challenges and opportunities of OOE projects within an organizational context of Dutch HEIs by using group concept mapping. Multidimensional scaling and hierarchical clustering resulted in a cluster map and a pattern match graph for interpreting the experts’ ideas and opinions, clarifying and structuring the collective understanding. Core themes that represent the challenges and opportunities with regard to OOE identified in this study were: 1. Online teaching, 2. Supporting mechanisms, 3. Assessment, 4. External target groups, 5. Educational flexibility, 6. Quality of education, 7. Institutional reputation, and 8. Educational efficiency. The results indicated a skills gap among educators and a lack of central support for the development of OOE. Organizational efforts to implement OOE should take educational flexibility and online teaching into account and support mechanisms for OOE should be provided. © 2017 The Authors","Educational innovation; Group concept mapping; Higher education; MOOCs; Open online education; Organizational research","Clustering algorithms; Distance education; Education; Mapping; Societies and institutions; Concept mapping; Educational innovations; Higher education; MOOCs; On-line education; Organizational research; E-learning",2-s2.0-85028089126
"Khalfay A., Crispin A., Crockett K.","Applying the intelligent decision heuristic to solve large scale technician and task scheduling problems",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020375633&doi=10.1007%2f978-3-319-59421-7_7&partnerID=40&md5=c8dbca77e7ea86d5f42103b6ae842593","Scheduling personnel to complete tasks is a complex combinatorial optimisation problem. In large organisations, finding quality solutions is of paramount importance due to the costs associated with staffing. In this paper we have generated and solved a set of novel large scale technician and task scheduling problems. The datasets include complexities such as priority levels, precedence constraints, skill requirements, teaming and outsourcing. The problems are considerably larger than those featured previously in the literature and are more representative of industrial scale problems, with up to 2500 jobs. We present our data generator and apply two heuristics, the intelligent decision heuristic and greedy heuristic, to provide a comparative analysis. © Springer International Publishing AG 2018.","Combinatorial optimisation; Data generator; Intelligent decision heuristic; Large scale technician and task scheduling problems","Combinatorial optimization; Multitasking; Outsourcing; Scheduling algorithms; Comparative analysis; Data generator; Greedy heuristics; Industrial scale; Intelligent decisions; Precedence constraints; Skill requirements; Task scheduling problem; Optimization",2-s2.0-85020375633
"Singh S.P., Kumar A., Darbari H., Rastogi A., Jain S., Joshi N.","Building machine learning system with deep neural network for text processing",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028386788&doi=10.1007%2f978-3-319-63645-0_56&partnerID=40&md5=0d3755efdc0b93f389c6e4ea8a27e161","This paper provides the method and process to build machine learning system using Deep Neural Network (DNN) for lexicon analysis of text. Parts of Speech (POS) tagging of word is important in Natural language processing either it is speech technology or machine translation. The recent advancement of Deep Neural Network would help us to achieve better result in POS tagging of words and phrases. Word2vec tool of Dl4j library is very popular to represent the words in continuous vector space and these vectors capture the syntactic and semantic meaning of corresponding words. If we have a database of sample words with their POS category, it is possible to assign POS tag to the words but it fails when the word is not present in database. Cosine similarity concept plays an important role to find the POS Tags of the words and phrases which are not previously trained or POS Tagged. With the help of Cosine similarity, system assign the appropriate POS tags to the words by finding their nearest similar words using the vectors which we have trained from Word2vec database. Deep neural network like RNN outperforms as compare to traditional state of the art as it deals with the issue of word sense disambiguation. Semi-supervised learning is used to train the network. This approach can be applicable for Indian languages as well as for foreign languages. In this paper, RNN is implemented to build a machine learning system for POS-tagging of the words in English language sentences. © Springer International Publishing AG 2018.","Cosine similarity; Machine learning; Natural language processing (NLP); Recurrent neural network (RNN); Word2vec","Artificial intelligence; Computational linguistics; Database systems; Deep learning; Intelligent systems; Learning algorithms; Learning systems; Natural language processing systems; Recurrent neural networks; Semantics; Speech transmission; Supervised learning; Syntactics; Text processing; Vector spaces; Cosine similarity; English languages; Machine translations; Recurrent neural network (RNN); Semi- supervised learning; Speech technology; Word Sense Disambiguation; Word2vec; Deep neural networks",2-s2.0-85028386788
"Wang X., Zuo M., Song L.","A feature selection method based on information gain and BP neural network",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030834457&doi=10.1007%2f978-981-10-6496-8_3&partnerID=40&md5=6634e51afb5306b905d91af51a1f5d3c","Data mining and machine learning fields are facing with a great challenge of mass data with high dimensionality. Feature selection can contribute a lot to address this issue with the concept of reducing the number of features by eliminating the redundant and irrelevant ones while preserving the information of original features maximally. This paper analyzes and compares two common feature selection methods, then puts forward a novel method for feature selection based on information gain and BP neural network (IGBP). The experimental result shows that IGBP method can reduce the time cost and improve the accuracy of the model at the meantime. The scientificity and superiority of IGBP are demonstrated in this paper, making it an efficient approach to deal with high-dimensional data. © 2018, Springer Nature Singapore Pte Ltd.","BP neural network; Data mining; Feature selection; IGBP method; Information gain","Clustering algorithms; Feature extraction; Intelligent systems; Learning systems; Neural networks; BP neural networks; Common features; Feature selection methods; High dimensional data; High dimensionality; IGBP method; Information gain; Time cost; Data mining",2-s2.0-85030834457
"Smiatacz M.","Playback attack detection: The search for the ultimate set of antispoof features",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019208598&doi=10.1007%2f978-3-319-59162-9_13&partnerID=40&md5=f409c14c2371046792e9205ebb3e6b0b","Automatic speaker verification systems are vulnerable to several kinds of spoofing attacks. Some of them can be quite simple – for example, the playback of an eavesdropped recording does not require any specialized equipment nor knowledge, but still may pose a serious threat for a biometric identification module built into an e-banking application. In this paper we follow the recent approach and convert recordings to images, assuming that original voice can be distinguished from its played back version through the analysis of local texture patterns. We propose improvements to the state-of-the-art solution, but also show its severe limitations. This in turn leads to the fundamental question: is it possible to find one set of features which are characteristic for all playback recordings? We look for the answer by performing a series of optimization experiments, but in general the problem remains open. © Springer International Publishing AG 2018.","Antispoof algorithms; Biometrics; Playback detection","Biometrics; Automatic speaker verification; Biometric identifications; E-banking; Local Texture; Playback attack detection; Specialized equipment; Spoofing attacks; State of the art; Speech recognition",2-s2.0-85019208598
"Yeh C.-H., Lai J.-X., Chou Y.-C.","A web page watermarking method using hybrid watermark hiding strategy",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026789747&doi=10.1007%2f978-3-319-63856-0_5&partnerID=40&md5=4cabd3f63e5909f3f2fb5ffa7946b386","On the Internet, various communication channels are readily available for companies, communities, and individuals. As companies have increasingly made use of social websites and instant messaging technologies for marketing and public relations, additional effort has been put in place to create interactive web contents to attract online audience. It is easy for anyone to simply copy and modify existing web contents for their own use. A common approach to protecting the copyright of a companys web content is digital watermarking with copyright information. The watermarking technique is a good way to achieve the goal of copyright protection. This paper presents a web page copyright protection method by integrating Cartesian product combination, CSS and HTML tag capitalization method, HTML attribute combination method, HTML attribute quotation mark method, and CSS attribute value embedding method. The experimental results demonstrate that the proposed method success achieved the goal of copyright protection for web pages. © Springer International Publishing AG 2018.","CSS; Data hiding; Digital watermarking; HTML","Digital watermarking; HTML; Multimedia signal processing; Public relations; Signal processing; Websites; Cartesian Products; Combination method; Copyright informations; Copyright protections; Data hiding; Instant messaging technologies; Watermarking algorithms; Watermarking methods; Copyrights",2-s2.0-85026789747
"Alrehamy H.H., Walker C.","SemCluster: Unsupervised Automatic Keyphrase Extraction Using Affinity Propagation",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029591804&doi=10.1007%2f978-3-319-66939-7_19&partnerID=40&md5=c802981d36ff9080c7b46a1f0fdea520","Keyphrases provide important semantic metadata for organizing and managing free-text documents. As data grow exponentially, there is a pressing demand for automatic and efficient keyphrase extraction methods. We introduce in this paper SemCluster, a clustering-based unsupervised keyphrase extraction method. By integrating an internal ontology (i.e., WordNet) with external knowledge sources, SemCluster identifies and extracts semantically important terms from a given document, clusters the terms, and, using the clustering results as heuristics, identifies the most representative phrases and singles them out as keyphrases. SemCluster is evaluated against two baseline unsupervised methods, TextRank and KeyCluster, over the Inspec dataset under an F1-measure metric. The evaluation results clearly show that SemCluster outperforms both methods. © 2018, Springer International Publishing AG.","Clustering-based AKE; Keyphrase extraction; Unsupervised AKE","Artificial intelligence; Clustering algorithms; Ontology; Semantics; Affinity propagation; Clustering results; Clustering-based AKE; Evaluation results; External knowledge; Keyphrase extraction; Unsupervised AKE; Unsupervised method; Extraction",2-s2.0-85029591804
"Guda V., Sanampudi S.K.","A hybrid method for extraction of events from natural language text",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021236450&doi=10.1007%2f978-981-10-3223-3_28&partnerID=40&md5=8dea5587d7b83a08294c7699a580e8d2","Events extraction is a significant and interesting task in the field of Natural Language Processing (NLP). Basically events are the dynamic occurrences, specific happenings, causes or things. An event plays a vital role in narrative of text and also important for many NLP applications. This paper presents a Hybrid/Composite way of events extraction from natural language text. Earlier work of events extractions were developed with rule based approach or machine learning methods. The Proposed hybrid makes use of both machine learning approaches and hand coded rules to extract the events. Experiments were conducted on SemEval-2010 data set, the results obtained shown better precision and recall when compared with the existing methods. © Springer Nature Singapore Pte Ltd. 2018.","Events; Events extraction; Machine learning techniques; Natural⋅ Language Processing (NLP); Rules based approach","Artificial intelligence; Education; Extraction; Information analysis; Intelligent computing; Learning algorithms; Learning systems; Events; Events extractions; Language processing; Machine learning techniques; Rules based; Natural language processing systems",2-s2.0-85021236450
"López J.C.L., Carrillo P.A.Á., Valenzuela O.A.","A multicriteria group decision model for ranking technology packages in agriculture",2018,"Studies in Fuzziness and Soft Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024473336&doi=10.1007%2f978-3-319-62359-7_7&partnerID=40&md5=253573c44015fbe2975109f71c06ad2c","The problem of ranking a set of technology packages that are best suited for growing crops, is developed with a multicriteria group decision model. The group decision model is based on ELECTRE GD, a group decision method for multicriteria ranking problems, strongly based on ELECTRE III, developed to work on those cases where there is great divergence among the decision-makers. We use a practical case study to show our approach, where a group of decision-makers evaluates among the available technology packages to an agricultural company, in order to select the most appropriate alternative. The proposed model generates an agreed collective solution that aids those decision-makers with different interests, to reach (through an iterative process) an agreement on how to rank the technology packages. The proposed procedure is also based on a preference disaggregation approach for reaching agreement between individuals. To support the proposal of a temporary collective solution, individual inter-criteria parameters are inferred concerning individual and global preference for outranking methods in a feedback process. © 2018, Springer International Publishing AG.","Group decision-making; Multicriteria decision analysis; Multiobjective genetic algorithms; Outranking methods; Preference disaggregation analysis; Technology packages",,2-s2.0-85024473336
"Muggler M., Eshwarappav R., Cankaya E.C.","Cybersecurity management through logging analytics",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021645326&doi=10.1007%2f978-3-319-60585-2_1&partnerID=40&md5=6724cfb13880cf9c39ad46344e1bbf83","To make cybersecurity efforts proactive rather than solely reactive, this work proposes using machine learning to process large network related data: We collect various performance metrics in a network and use machine learning techniques to identify anomalous behavior. We introduce the novel idea of using weighted trust to prevent corruption of classifiers. Our design combines all aspects of a log management system into one distributed application for a data center to effectively offer logging, aggregation, monitoring and intelligence services. For this, we employ a three-component log management system: (1) to actively extract metrics from machines, (2) to aggregate and analyze extracted metrics to detect anomalous behavior, and (3) to allow reviewing collected metrics and to report on anomalous behavior observed. Our system runs at network and application layers and is concerned with risk mitigation and assessment. Several machine learning techniques are compared w.r.t. their classification, as well as detection performances. © Springer International Publishing AG 2018.","Anomaly detection; Cybersecurity; Log management system","Artificial intelligence; Education; Human engineering; Learning algorithms; Learning systems; Network layers; Risk assessment; Anomaly detection; Cyber security; Detection performance; Distributed applications; Intelligence services; Log managements; Machine learning techniques; Performance metrics; Information management",2-s2.0-85021645326
"Yovchev K., Chikurtev D., Chivarov N., Shivarov N.","Precise positioning of a robotic arm manipulator using stereo computer vision and iterative learning control",2018,"Mechanisms and Machine Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028352064&doi=10.1007%2f978-3-319-61276-8_32&partnerID=40&md5=b8952df0602fdb225eb9a2be4a64637c","Modern service robots are a combination of a mobile platform and a robotic manipulator. One of the main and most difficult tasks in front of these robots is the object transportation between two points. They should be able to detect any desired object. Then move the platform as close as possible to the desired object. Afterwards the manipulator arm should position the gripper near it. The last step is to grasp and transport the object. This paper presents a novel approach for solving the manipulator arm positioning problem. The presented method combines computer vision and Iterative Learning Control techniques in order to compensate any imprecisions of the robot kinematics and dynamics. This results in an efficient solution, which succeeds in precise positioning near the desired object even when there is a very little knowledge of those mathematics models. It is a robust method, which auto adapts to mechanical wear during normal operations, not severe damages or imprecise factory assembly. The method is then validated on a physical robotic manipulator. © 2018, Springer International Publishing AG.","Computer vision; Iterative Learning Control; Manipulator positioning; Service robots","Computer vision; Flexible manipulators; Iterative methods; Learning algorithms; Mobile robots; Object detection; Robotic arms; Robotics; Robots; Stereo image processing; Stereo vision; Two term control systems; Iterative learning control; Mathematics model; Normal operations; Object transportation; Precise positioning; Robot kinematics; Robotic manipulators; Service robots; Manipulators",2-s2.0-85028352064
"Mahapatra C.","Medical diagnosing of canine diseases using genetic programming and neural networks",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031424322&doi=10.1007%2f978-981-10-6747-1_22&partnerID=40&md5=bbe832ead97ed4f940d4506fb935d037","Neural networks and genetic programming have long since helped humans in diagnoses and treatment of human diseases. However, not much has been done for man’s best friend—the canine’s. This paper thus aims to explore and find the possibility of building software which is based on the use of neural network and Cartesian genetic programming to diagnose the various diseases of canine population. During the study, its outcomes were also compared and contrasted with the results of a neural network combined with simple genetic programming-based system, the results of which confirmed the high success rate of neural network training when it is modified with Cartesian genetic programming for the use of diagnosis of various categories of canine diseases. © 2018, Springer Nature Singapore Pte Ltd.","ANN; CGP; GA; Genetic programming; MATLAB; MLP; MLPGA; Neural networks; Perceptron; Software; Trainbr","Computer software; Diagnosis; Gallium; Genetic algorithms; MATLAB; Neural networks; Program diagnostics; Building softwares; Cartesian genetic programming; Human disease; MLPGA; Neural network training; Trainbr; Genetic programming",2-s2.0-85031424322
"Sakuma R., Kang H., Iwamura K., Echizen I.","Digital watermarking scheme based on machine learning for the IHC evaluation criteria",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026753578&doi=10.1007%2f978-3-319-63856-0_45&partnerID=40&md5=9dac28bff35b5510d45d7b326f2b6bf6","Digital watermarking is a technique used for embedding information in digital content and protecting its copyright. The important issues to be considered are robustness, quality and capacity. Our goal is to satisfy these requirements according to the Information Hiding and its Criteria for evaluation (IHC) criteria. In this study, we evaluate our watermarking scheme along the IHC criteria Ver. 3 as the primary step. Although image watermarking techniques based on machine learning already exist, their robustness against desynchronization attacks such as cropping, rotation, and scaling is still one of the most challenging issues. We propose a watermarking scheme based on machine learning which also has cropping tolerance. First, the luminance space of the image is decomposed by one level through wavelet transform. Then, a bit of the watermark and the marker for synchronization are embedded or extracted by adjusting or comparing the relation between the embedded coefficients value of the LL space and the output coefficients value of the trained machine learning model. This model can well memorize the relationship between its selected coefficients and the neighboring coefficients. The marker for synchronization is embedded in a latticed format in the LL space. Binarization processing is performed on the watermarked image to find the lattice-shaped marker and synchronize it against cropping. Our experimental results showed that there were no errors in 10HDTV-size areas after the second decompression. © Springer International Publishing AG 2018.","Binarization; Cropping; Digital watermarking; Lattice-shaped marker; Machine learning","Artificial intelligence; Bins; Digital watermarking; E-learning; Image processing; Image watermarking; Learning systems; Signal processing; Wavelet transforms; Binarization processing; Binarizations; Criteria for evaluations; Cropping; De-synchronization attacks; Lattice-shaped marker; Machine learning models; Watermarking algorithms; Multimedia signal processing",2-s2.0-85026753578
"Chen Y., Zhang L., Yi Z.","Subspace clustering using a low-rank constrained autoencoder",2018,"Information Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030531457&doi=10.1016%2fj.ins.2017.09.047&partnerID=40&md5=f216f36ea85f76e3a89a7ecf2464174a","The performance of subspace clustering is affected by data representation. Data representation for subspace clustering maps data from the original space into another space with the property of better separability. Many data representation methods have been developed in recent years. Typical among them are low-rank representation (LRR) and an autoencoder. LRR is a linear representation method that captures the global structure of data with low-rank constraint. Alternatively, an autoencoder nonlinearly maps data into a latent space using a neural network by minimizing the difference between the reconstruction and input. To combine the advantages of an LRR (globality) and autoencoder (self-supervision based locality), we propose a novel data representation method for subspace clustering. The proposed method, called low-rank constrained autoencoder (LRAE), forces the latent representation of the neural network to be of low rank, and the low-rank constraint is computed as a prior from the input space. One major advantage of the LRAE is that the learned data representation not only maintains the local features of the data, but also preserves the underlying low-rank global structure. Extensive experiments on several datasets for subspace clustering were conducted. They demonstrated that the proposed LRAE substantially outperformed state-of-the-art subspace clustering methods. © 2017 Elsevier Inc.","Autoencoder; Deep neural networks; Low-rank representation; Subspace clustering","Deep neural networks; Learning systems; Auto encoders; Data representations; Global structure; Linear representation; Low-rank representations; Rank constraints; State of the art; Sub-Space Clustering; Clustering algorithms",2-s2.0-85030531457
"Marcano J.L., Bell M.A., Beex A.A.L.","Classification of ADHD and non-ADHD subjects using a universal background model",2018,"Biomedical Signal Processing and Control",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026907165&doi=10.1016%2fj.bspc.2017.07.023&partnerID=40&md5=21a63e0aeb4804dc8152a95f0b938f9f","ADHD affects a major portion of our children, predominantly boys. Upon diagnosis treatment can be offered that is usually quite effective. Diagnosis is generally based on subjective observation and interview. As a result, an objective test for the detection or presence of ADHD is considered very desirable. Based on EEG, across multiple channels, using autoregressive model parameters as features, ADHD detection is approached here in analogy with the imposter problem known from speaker verification. Gaussian mixture models are used to define ADHD and universal background models so that a likelihood ratio detector can be designed. The efficacy of this approach is reflected in the traditional detector performance measures of the area-under-the-curve and equal-error-probability. The results – based on a limited database of males, approximately 6 years of age – indicate that high probability of detection and low equal error rate can be achieved simultaneously with the proposed approach, when using EEG collected during an attention network task. The effect of using contaminated data is investigated as well. © 2017 Elsevier Ltd","ADHD; AR models; EEG; Gaussian mixture models; Universal background model","Electroencephalography; Learning algorithms; ADHD; AR models; Area under the curves; Auto regressive models; Detector performance; Gaussian Mixture Model; Speaker verification; Universal background model; Speech recognition; Article; attention deficit disorder; child; clinical article; controlled study; disease classification; error; female; human; male; performance measurement system; priority journal; probability; receiver operating characteristic; task performance",2-s2.0-85026907165
"Marchetti Y., Nguyen H., Braverman A., Cressie N.","Spatial data compression via adaptive dispersion clustering",2018,"Computational Statistics and Data Analysis",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028854928&doi=10.1016%2fj.csda.2017.08.004&partnerID=40&md5=ccdb6875f8c35c261c3d24802657435c","Adaptive Spatial Dispersion Clustering (ASDC), a new method of spatial data compression, is specifically designed to reduce the size of a spatial dataset in order to facilitate subsequent spatial prediction. Unlike traditional data and image compression methods, the goal of ASDC is to create a new dataset that will be used as input into spatial-prediction methods, such as traditional kriging or Fixed Rank Kriging, where using the full dataset may be computationally infeasible. ASDC can be classified as a lossy compression method and is based on spectral clustering. It aims to produce contiguous spatial clusters and to preserve the spatial-correlation structure of the data so that the loss of predictive information is minimal. An extensive simulation study demonstrates the predictive performance of these adaptively compressed datasets for several scenarios. ASDC is compared to two other data-reduction schemes, one using local neighborhoods and one using simple binning. An application to remotely sensed sea-surface-temperature data is also presented, and computational costs are discussed. © 2017","Spatial clusters; Spatial data compression; Spatial dispersion function; Spectral clustering","Clustering algorithms; Data compression; Dispersions; Interpolation; Oceanography; Surface waters; Image compression methods; Lossy compression methods; Sea surface temperature (SST); Spatial cluster; Spatial correlation structures; Spatial data compression; Spatial dispersion; Spectral clustering; Image compression",2-s2.0-85028854928
"Piccini J., Robledo F., Romero P.","Complexity among combinatorial problems from epidemics",2018,"International Transactions in Operational Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030178170&doi=10.1111%2fitor.12444&partnerID=40&md5=96a5217dd1b48170e9f13bf9c852937e","A cornerstone in epidemic modeling is the classical susceptible–infected–removed model, or SIR. In this model, individuals are divided into three classes: susceptible (those who can be infected), infected, and removed (those who suffered the infection and recovered, gaining immunity from further contact with infected individuals). Transitions S→I→R occur at constant rates γS,γI. The SIR model is both simple and useful to understand cascading failures in a network. Nevertheless, a shortcoming is the unrealistic assumption of random contacts in a fully mixed large population. More realistic models are available from authoritative literature in the field. They consider a graph and an epidemic spread governed by probabilistic rules. In this paper, a combinatorial optimization problem is introduced using graph-theoretic terminology, inspired by an extremal analysis of epidemic modeling. The contributions are threefold. First, a general node immunization problem is defined for node immunization under budget requirements, using probabilistic networks. The goal is to minimize the expected number of deaths under a particular choice of nodes in the system to be immunized. In the second stage, a highly virulent environment leads to a purely combinatorial problem without probabilistic law, called the graph fragmentation problem (GFP). We prove the corresponding decision version for the GFP belongs to the class of NP-complete problems. As a corollary, SIR-based models also belong to this set. Third, a GRASP (greedy randomized adaptive search procedure) heuristic enriched with a path-relinking post-optimization phase is developed for the GFP. Finally, an experimental analysis is carried out under graphs taken from real-life applications. © 2017 The Authors. International Transactions in Operational Research © 2017 International Federation of Operational Research Societies","combinatorial optimization problem; computational complexity; graph fragmentation problem","Budget control; Combinatorial optimization; Complex networks; Computational complexity; Environmental regulations; Epidemiology; Graph theory; Heuristic algorithms; Immunization; Combinatorial optimization problems; Combinatorial problem; Experimental analysis; graph fragmentation problem; Greedy randomized adaptive search procedure; Probabilistic network; Probabilistic rules; Real-life applications; Optimization",2-s2.0-85030178170
"Jha S., Gupta G.P.","Energy balanced clustering protocol using particle swarm optimization for wireless sensor networks",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028397624&doi=10.1007%2f978-3-319-63645-0_4&partnerID=40&md5=5cb3a6f5e71638b650c0d89dc56b7fb8","In a large scale Wireless Sensor Networks (WSNs), designing an energy balanced clustering protocol has become a challenging research issues. This is due to fact that design of an energy-balanced clustering for maximizing the network lifetime of WSNs is a NP-hard problem. For solving this NP-hard problem, many meta-heuristic approach based clustering protocols are proposed in the recent years. However, these existing clustering protocols suffer from unbalanced energy consumption problem. In this problem, cluster heads are not uniformly distributed and overloaded cluster heads die out faster than under-loaded cluster heads. In order to solve this problem, we have proposed an energy balanced clustering protocol using particle swarm optimization called EBC-PSO. In the proposed protocol, we have used a novel multi-objective fitness function which contains three constraints such as average intra-cluster distance, residual energy and average cluster size. A detailed evaluation and performance comparison of the EBC-PSO with the three most popular protocols such as LEACH, PSO-ECHS, and E-OEERP are included. © Springer International Publishing AG 2018.","Clustering; PSO; Wireless sensor network","Computational complexity; Energy utilization; Evolutionary algorithms; Heuristic methods; Intelligent systems; Internet protocols; Network routing; Optimization; Particle swarm optimization (PSO); Problem solving; Routing protocols; Based clustering; Clustering; Clustering protocol; Large-scale wireless sensor networks; Meta-heuristic approach; Multi-objective fitness function; Performance comparison; Unbalanced energy; Wireless sensor networks",2-s2.0-85028397624
"Gonzalez-Cava J.M., Arnay R., Méndez Pérez J.A., León A., Martín M., Jove-Perez E., Calvo-Rolle J.L., Casteleiro-Roca J.L., de Cos Juez F.J.","A machine learning based system for analgesic drug delivery",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028679423&doi=10.1007%2f978-3-319-67180-2_45&partnerID=40&md5=288de6946ba75d4ba7df017e80725e1f","Monitoring pain and finding more efficient methods for analgesic administration during anaesthesia is a challenge that attracts the attention of both clinicians and engineers. This work focuses on the application of Machine Learning techniques to assist the clinicians in the administration of analgesic drug. The problem will consider patients undergoing general anaesthesia with intravenous drug infusion. The paper presents a preliminary study based on the use of the signal provided by an analgesia monitor, the Analgesia Nociception Index (ANI) signal. One aim of this research is studying the relation between ANI monitor and the changes in drug titration made by anaesthetist. Another aim is to propose an intelligent system that provides decisions on the drug infusion according to the ANI evolution. To do that, data from 15 patients undergoing cholecystectomy surgery were analysed. In order to establish the relationship between ANI and the analgesic, Machine Learning techniques have been introduced. After training different types of classifier and testing the results with cross validation method, it has been demonstrated that a relation between ANI and the administration of remifentanil can be found. © 2018, Springer International Publishing AG.","Anaesthesia; Analgesia; Analgesia nociception index; Intelligent system; Machine learning","Anesthesiology; Artificial intelligence; Drug infusion; Education; Intelligent systems; Learning algorithms; Soft computing; Anaesthesia; Analgesia; Analgesic drugs; Cross-validation methods; Machine learning techniques; Nociception indices; Remifentanil; Learning systems",2-s2.0-85028679423
"Holland-Letz T., Kopp-Schneider A.","Optimal experimental designs for estimating the drug combination index in toxicology",2018,"Computational Statistics and Data Analysis",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029545167&doi=10.1016%2fj.csda.2017.08.006&partnerID=40&md5=ae933ee051f5d4e820336ad69b93d2fb","When studying combination treatments made up of different substances, the interaction of these treatments is of primary research interest. One way to express the interaction is through a combination index τ based on Loewe additivity. Regarding the statistical optimal design of trials to estimate τ, the problem generally corresponds to a c-optimality design problem. Unfortunately, c-optimal designs have several practical problems, commonly including an inability to also estimate the underlying dose–response parameters in the same trial. It is demonstrated how optimal designs for combination indices can be generated as well as how these designs can be adapted to guarantee that at least a satisfactory degree of precision can be maintained for all parameter estimates. This is achieved by introducing secondary constraints on efficiency regarding the D-criterion, and optimizing within these constraints only. All of the proposals are demonstrated using a practical toxicological example. Furthermore, it is also investigated how the performance of the proposed designs is affected by misspecifications regarding the a priori parameter assumptions used to generate the designs. © 2017 Elsevier B.V.","c-optimal design; Combination index; Dose–response studies; Multiplicative algorithms; Nonlinear regression; Toxicology","Optimal systems; Combination index; Combination treatments; Non-linear regression; Optimal design; Optimal experimental designs; Response parameters; Satisfactory degree; Toxicology; Design of experiments",2-s2.0-85029545167
"Liu H., Li Y., Zhang Y., Chen Y., Song Z., Wang Z., Zhang S., Qian J.","Intelligent tuning method of PID parameters based on iterative learning control for atomic force microscopy",2018,"Micron",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031772104&doi=10.1016%2fj.micron.2017.09.009&partnerID=40&md5=fe6a6cc0d860df204aa6b2fac1cd6d33","Proportional-integral-derivative (PID) parameters play a vital role in the imaging process of an atomic force microscope (AFM). Traditional parameter tuning methods require a lot of manpower and it is difficult to set PID parameters in unattended working environments. In this manuscript, an intelligent tuning method of PID parameters based on iterative learning control is proposed to self-adjust PID parameters of the AFM according to the sample topography. This method gets enough information about the output signals of PID controller and tracking error, which will be used to calculate the proper PID parameters, by repeated line scanning until convergence before normal scanning to learn the topography. Subsequently, the appropriate PID parameters are obtained by fitting method and then applied to the normal scanning process. The feasibility of the method is demonstrated by the convergence analysis. Simulations and experimental results indicate that the proposed method can intelligently tune PID parameters of the AFM for imaging different topographies and thus achieve good tracking performance. © 2017 Elsevier Ltd","Atomic force microscopy; Intelligent tuning method; Iterative learning control; PID parameters","Atomic force microscopy; Iterative methods; Learning algorithms; Scanning; Three term control systems; Topography; Tuning; Two term control systems; Convergence analysis; Iterative learning control; Parameter-tuning; PID parameters; Proportional integral derivatives; Tracking performance; Tuning method; Working environment; Proportional control systems",2-s2.0-85031772104
"Aldà F., Simon H.U.","A lower bound on the release of differentially private integer partitions",2018,"Information Processing Letters",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029073064&doi=10.1016%2fj.ipl.2017.09.001&partnerID=40&md5=7945bf5711b35a1e623408d6d1fdcd1f","We consider the problem of privately releasing integer partitions. This problem is of high practical interest, being related to the publication of password frequency lists or the degree distribution of social networks. In this work, we show that any ε-differentially private mechanism releasing a partition of a sufficiently large non-negative integer N must incur a minimax risk of order Ω(N/ε). Moreover, for small values of N, we provide an optimal lower bound of order Ω(N). © 2017 Elsevier B.V.","Differential privacy; Integer partitions; Randomized algorithms","Computer applications; Degree distributions; Differential privacies; Integer partitions; Lower bounds; Minimax risk; Nonnegative integers; Optimal lower bound; Randomized Algorithms; Data processing",2-s2.0-85029073064
"Vijayaraghavan V., Garg A., Gao L.","Fracture mechanics modelling of lithium-ion batteries under pinch torsion test",2018,"Measurement: Journal of the International Measurement Confederation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030835295&doi=10.1016%2fj.measurement.2017.10.008&partnerID=40&md5=13e48b7afc8a27ea6119f2e077363d88","For the design of batteries to sustain the crash tests, the mechanical strength (force generated) on the battery can be evaluated to understand its fundamental effect on possible failure (such as breaking of separator and short-circuit) of batteries. In this perspective, this study proposed a holistic approach to evaluate the maximum force generated on the battery when subjected to the pinch-torsion test. The fundamentals of the test are understood by formation of Finite element analysis (FEA) model and validated based on experiments. The inputs in FEA such as the temperature, the displacement and the strain rate are varied and the maximum generated force is observed on the battery. The quantification of the finite element data is further performed by an optimization approach of GP. It was found that the GP model for an evaluation of mechanical force on the battery is accurate. The robustness in the model is validated by design of its simulation for 10,000 runs. 2-D and 3-D surface analysis suggests that the displacement due to indentation is the most dominant followed by the temperature and the strain rate. The findings from the analysis can pave the way for design of new battery that comprises of higher strength when subjected to the crash tests. © 2017 Elsevier Ltd","Energy storage system; Finite element analysis; Genetic programming; Lithium-ion battery failure; Short-circuit","Digital storage; Electric batteries; Finite element method; Fracture mechanics; Genetic algorithms; Genetic programming; Short circuit currents; Strain rate; Surface analysis; Torsion testing; Torsional stress; Crash tests; Energy storage systems; Finite element analysis modeling; Holistic approach; Lithium ions; Maximum forces; Mechanical force; Optimization approach; Lithium-ion batteries",2-s2.0-85030835295
"Domżał M., Jędrasiak K., Iwaneczko P., Jaskot K., Nawrat A.","UAV Swarm Management Using Prepar3D",2018,"Studies in Systems, Decision and Control",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029707622&doi=10.1007%2f978-3-319-64674-9_11&partnerID=40&md5=d4ab769cd210ad8b84bf39c26fa41b32","In the article a system for swarm management in the Prepar3D environment was presented. The system allow to simulate and control via graphical user interface swarm of UAVs. From the user’s perspective, the main advantages of such a system over a single machine would be: speed, no need to restock the UAV, elimination of the problem of transport spare batteries or fuel. Prepar3D is a simulation environment implemented by Lockheed Martin which provides a high degree of realism, and is capable of simulating flying, floating and ground-based objects. Therefore it is possible to research the behavior of various types of swarm. Increasing the number of vehicles in the swarm increases the number of turns on the route, however it allows for faster testing of the areas. As one of the advantages of the presented approach it can be mentioned the fact that for all studied situations, including parameter sets and the number of vehicles, in all cases swarm managed to examine the entire area. The selection of the appropriate parameters provides a better route for the coverage of area with photographs and allow to complete the mission faster. A system of this type could be used in reconnaissance missions or searching for people missing in uninhabited regions, or for example extensive research of infrastructure. The system could also generate a 3D map of the area. © 2018, Springer International Publishing AG.","Control algorithms; PSO; Swarm management; UAV",,2-s2.0-85029707622
"Chuang M.-T., Hu Y.-H., Lo C.-L.","Predicting the prolonged length of stay of general surgery patients: a supervised learning approach",2018,"International Transactions in Operational Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84971597321&doi=10.1111%2fitor.12298&partnerID=40&md5=fe02824d0042a5dec05dfe7fd8943a15","Determining the likelihood of a prolonged length of stay (LOS) for surgery patients can improve medical resource management. This study was aimed at developing predictive models for determining whether patient LOS is within the standard LOS after surgery. This study analyzed the complete historical medical records and lab data of 896 clinical cases involving surgeries performed by general surgery physicians. The cases were divided into urgent operation (UO) and non-UO groups to develop a prolonged LOS prediction model using several supervised learning techniques. Several critical factors for the two groups were identified using the gain ratio technique. The results indicated that the random forest method yielded the most accurate and stable prediction model. Additionally, comorbidity, body temperature, blood sugar, and creatinine were the most influential variables for prolonged LOS in the UO group, whereas blood transfusion, blood pressure, comorbidity, and the number of ICU admissions were the most influential variables in the non-UO group. This study shows that supervised learning techniques are suitable for analyzing patient medical records in accurately predicting a prolonged LOS; thus, the clinical decision support system developed based on the prediction models may serve as reference tools for communicating with patients before surgery. The system may also assist physicians when making decisions regarding whether patients require more clinical care, thereby improving patient safety. © 2016 The Authors. International Transactions in Operational Research © 2016 International Federation of Operational Research Societies","length of stay; physician patient communications; prediction; supervised learning; surgery; urgent surgery","Artificial intelligence; Blood pressure; Decision support systems; Decision trees; Epidemiology; Forecasting; Intensive care units; Learning algorithms; Learning systems; Supervised learning; Blood transfusion; Clinical decision support systems; Critical factors; Length of stay; Predictive models; Random forest methods; Resource management; Supervised learning approaches; Surgery",2-s2.0-84971597321
"Rajalakshmi S., Venkatesan R.","Exploring cepstral coefficient based sleep stage scoring method for single-channel EEG signal using machine learning technique",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030160492&doi=10.1007%2f978-3-319-67934-1_3&partnerID=40&md5=f19d3139fd1152cfa905f1b092110935","Sleep stage scoring is a critical task where conventionally large volume of data has to be analyzed visually which is troublesome, time-consuming and error prone. Eventually, machine learning technique is required for automatic sleep stage scoring. Therefore, a new feature extraction method for EEG analysis and classification is discussed based on the statistical properties of cepstral coefficients. The sleep EEG signal is segmented into 30 s epoch and each epoch is decomposed into different frequency bands: Gamma (γ), Beta (β), Alpha (α), Theta (θ) and Delta (δ) by employing the Discrete Wavelet Transform (DWT). The statistical properties of Mel Frequency Cepstral Coefficients (MFCCs), which represent the short term spectral characteristics of the wavelet coefficients, are extracted. The MFCC feature vectors are incorporated into the Gaussian Mixture Model with Expectation Maximization (GMM-EM) to classify various sleep stages: Wake, Rapid Eye Movement (REM) and Non-Rapid Eye Movement (N-REM) stage1 (S1), N-REM stage2 (S2), N-REM stage3 (S3), N-REM stage4 (S4). The proposed feature extraction for sleep stage scoring achieves 88.71% of average classification accuracy. © Springer International Publishing AG 2018.","Cognitive tasks; Discrete wavelet transform; Feature extraction; Gaussian mixture model-expectation maximization; Mel frequency cepstral coefficient; Statistical properties","Artificial intelligence; Biomedical signal processing; Data visualization; Discrete wavelet transforms; Extraction; Eye movements; Feature extraction; Frequency bands; Gaussian distribution; Image segmentation; Learning algorithms; Learning systems; Maximum principle; Signal reconstruction; Sleep research; Speech recognition; Speech transmission; Wavelet transforms; Cognitive task; Expectation - maximizations; Feature extraction methods; Machine learning techniques; Mel frequency cepstral co-efficient; Mel-frequency cepstral coefficients; Spectral characteristics; Statistical properties; Signal processing",2-s2.0-85030160492
"Shimada K., Noguchi S., Makino M., Naito T.","Exceptional association rule set mining from oral health assessment database",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030779640&doi=10.1007%2f978-3-319-67792-7_42&partnerID=40&md5=70e56f8995be80d14a1aca604a93f9c7","This paper proposes an extended method to discover exceptional association rule sets from incomplete databases. The proposed method calculates an odds ratio directly for the rule evaluation. The exceptional rule set is defined as each itemset X, Y has a weak or no statistical relation to class C, respectively; however, the join of X and Y has a strong relation to C. The exceptional rule set has potential to interpret long rules for the join of X and Y. The proposed method is applied to rule mining for oral health assessment databases. We obtained interesting exceptional rule sets and the results showed effectiveness of the method in the medical and health care fields. © 2018, Springer International Publishing AG.","Association analysis; Association rule; Evolutionary computation; Missing value","Association rules; Database systems; Evolutionary algorithms; Association analysis; Missing values; Odds ratios; Oral healths; Rule evaluation; Rule mining; Rule set; Statistical relations; C (programming language)",2-s2.0-85030779640
"García-Alvarado M., Paquet M., Chaabane A., Amodeo L.","Inventory management under joint product recovery and cap-and-trade constraints",2018,"Journal of Cleaner Production",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006041118&doi=10.1016%2fj.jclepro.2016.10.074&partnerID=40&md5=27761f25a0053967c029884cb85856cb","The influence of environmental legislation in inventory control policies is explored. Previous work on product recovery is extended using the introduction of a cap-and-trade mechanism in an infinite-horizon inventory system in which demand and returns are uncertain. Demand is met through two different sources namely manufacturing and remanufacturing, which differ in cost and greenhouse gas emissions. The main contributions of this paper are 1) comparison of system operation in terms of cost and environmental performance under conventional and green inventory policies, and 2) managerial insights into the structure of green inventory policies. To illustrate the impact of a cap-and-trade scheme, a numerical example is used. We solved the problem as a Markov decision process, and characterized the inventory policies based on the optimal replenishment strategy. We also conducted a sensitivity analysis to examine the effect of underlying environmental parameters such as the emission cap and the allowance price in the policy structures. The results indicate that decisions are sensitive to carbon prices. The inventory policy could play an important role in compliance with environmental legislation, although there is threshold carbon price beyond which the company must focus on strategic decisions rather than tactical decisions. © 2016 Elsevier Ltd","Cap-and-trade; Green supply chain management; Inventory control; Markov decision processes; Remanufacturing","Behavioral research; Commerce; Costs; Environmental management; Gas emissions; Greenhouse gases; Learning algorithms; Markov processes; Process control; Sensitivity analysis; Supply chain management; Cap and trade; Environmental legislations; Environmental performance; Green supply chain management; Inventory control policies; Markov Decision Processes; Optimal replenishment strategies; Remanufacturing; Inventory control",2-s2.0-85006041118
"Chaturvedi N.D., Manan Z.A., Wan Alwi S.R.","A mathematical model for energy targeting of a batch process with flexible schedule",2018,"Journal of Cleaner Production",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017566732&doi=10.1016%2fj.jclepro.2017.03.223&partnerID=40&md5=07a69e987f82c69a52653ee19256de6a","This paper presents a mathematical model to determine the minimum energy targets for a batch process with flexible schedule. Techniques developed for flexible-schedule batch processes typically result in nonlinear formulations. The proposed model was formulated as a mixed integer linear programming model (MILP). The model is developed based on the source-demand classification of process streams instead of the typical classification of hot and cold streams. In such classification, each stream is simultaneously treated as a source at its shifted supply temperature, and as a demand at its shifted target temperature. Such classification eliminates the model's non-linearity and reduces its complexity as well as the solution time. The mathematical model can be used to calculate the utility targets for a flexible-schedule batch process. Application of the proposed mathematical formulation demonstrates significant energy saving potential. The first illustrative example predicted a potential reduction of 11% cold utility and 14% hot utility. In the second illustrative example, up to 35% hot utility reduction and 62% cold utility reduction could be achieved. © 2017","Batch process; Energy targeting; Flexible-schedule; Heat integration; Mixed integer linear programming","Batch data processing; Energy conservation; Integer programming; Batch process; Energy saving potential; Energy targeting; Heat integration; Mathematical formulation; Mixed integer linear programming; Mixed integer linear programming model; Nonlinear formulation; Scheduling algorithms",2-s2.0-85017566732
"Pan C., Sun M., Yan Z.","The study on vehicle detection based on DPM in traffic scenes",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031403027&doi=10.1007%2f978-981-10-3187-8_3&partnerID=40&md5=d38ff2f60f76258225756d4631ca1e0c","After the HoG feature was proposed, a lot of detectors were developed based on the feature. But HoG feature has its defects, as high dimensional data leading to inefficiency, complex scenes leading to poor performances and so on. In this article, we proposed a vehicle detector based on DPM (Deformable Part Model). This detector uses a deformable part model to classify the front and the rear of the vehicles. © Springer Nature Singapore Pte Ltd. 2018.","DPM; Traffic scenes; Vehicle detection","Clustering algorithms; Computation theory; Complex scenes; Deformable part models; High dimensional data; Poor performance; Traffic scene; Vehicle detection; Vehicle detector; Vehicles",2-s2.0-85031403027
"Jia S., Wang L.","New methods for utilization of predictive information in neural network PID controller",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030839322&doi=10.1007%2f978-981-10-6496-8_67&partnerID=40&md5=59189ee7cf115268e043e76f213eebb9","In this paper, we analyze the utilization of predictive information in neural network PID controller (NN-PID). Based on the accuracy of predictive model, two novel methods are proposed to improve control performance. When predictive model is high-accuracy, two-step ahead predictive information is incorporated into loss function to adjust the weight of NN. When the predictive model is low-accuracy, only one-step ahead information is used and learning rate is adjusted based on the prediction error. Consequential simulation are conducted with each method. © 2018, Springer Nature Singapore Pte Ltd.","Loss function; Neural network PID control; Predictive information; Variable learning rate","Controllers; Electric control equipment; Intelligent systems; Learning algorithms; Proportional control systems; Control performance; Loss functions; Neural network PID; Neural network PID controller; Prediction errors; Predictive information; Predictive modeling; Variable learning rate; Three term control systems",2-s2.0-85030839322
"Korycki Ł., Krawczyk B.","Combining active learning and self-labeling for data stream mining",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019231123&doi=10.1007%2f978-3-319-59162-9_50&partnerID=40&md5=7668e5e6f072d4b4bcc05a2e78add71c","Data stream mining is among the most vital contemporary data science challenges. In this work we concentrate on the issue of actual availability of true class labels. Assumption that the ground truth for each instance becomes known right after processing it is far from being realistic, due to usually high costs connected with its acquisition. Active learning is an attractive solution to this problem, as it selects most valuable instances for labeling. In this paper, we propose to augment the active learning module with self-labeling approach. This allows classifier to automatically label instances for which it displays the highest certainty and use them for further training. Although in this preliminary work we use a static threshold for self-labeling, the obtained results are encouraging. Our experimental study shows that this approach complements the active learning strategy and allows to improve data stream classification, especially in scenarios with very small labeling budget. © Springer International Publishing AG 2018.","Active learning; Data stream mining; Machine learning; Self-labeling; Semi-supervised learning","Budget control; Data communication systems; Learning algorithms; Learning systems; Supervised learning; Active Learning; Active learning strategies; Attractive solutions; Data stream classifications; Data stream mining; Further trainings; Semi- supervised learning; Static thresholds; Artificial intelligence",2-s2.0-85019231123
"Scardapane S., Altilio R., Ciccarelli V., Uncini A., Panella M.","Privacy-preserving data mining for distributed medical scenarios",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029180413&doi=10.1007%2f978-3-319-56904-8_12&partnerID=40&md5=8ef124d43fffc427c3a5ae6873624712","In this paper, we consider the application of data mining methods in medical contexts, wherein the data to be analysed (e.g. records from different patients) is distributed among multiple clinical parties. Although inference procedures could provide meaningful medical information (such as optimal clustering of the subjects), each party is forbidden to disclose its local dataset to a centralized location, due to privacy concerns over sensible portions of the dataset. To this end, we propose a general framework enabling the parties involved to perform (in a decentralized fashion) any data mining procedure relying solely on the Euclidean distance among patterns, including kernel methods, spectral clustering, and so on. Specifically, the problem is recast as a decentralized matrix completion problem, whose proposed solution does not require the presence of a centralized coordinator, and full privacy of the original data can be ensured by the use of different strategies, including random multiplicative updates for secure computation of distances. Experimental results support our proposal as an efficient tool for performing clustering and classification in distributed medical contexts. As an example, on the known Pima Indians Diabetes dataset, we obtain a Rand-Index for clustering of 0.52 against 0.54 of the (unfeasible) centralized solution, while on the Parkinson speech database we increase from 0.45 to 0.50. © Springer International Publishing AG 2018.","Biomedicine; Distributed learning; Kernel methods; Privacy; Spectral clustering","Clustering algorithms; Data mining; Medical computing; Biomedicine; Distributed learning; Kernel methods; Matrix completion problems; Medical information; Multiplicative updates; Privacy preserving data mining; Spectral clustering; Data privacy",2-s2.0-85029180413
"Fimmel E., Gumbel M., Strüngmann L.","Exploring structure and evolution of the genetic code with the software tool GCAT",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028660994&doi=10.1007%2f978-3-319-67349-3_2&partnerID=40&md5=fd2a7dc513583f73cf7d5598617f975a","The genetic code can be seen as the major key to biological self-organisation. In fact, all living organisms regardless of whether they are plants, bacteria or mammals have the same molecular bases: Adenine, cytosine, guanine, and thymine. Unidimensional sequences of these bases contain the genetic information for the synthesis of proteins in all forms of life. Thus, one of the most fascinating questions is to explain why evolution has produced the current genetic code and why it exists in its present form. Motivated by these fundamental questions, a new software tool – Genetic Code Analysis Toolkit (GCAT) – was developed which can be used to investigate properties of the genetic code in order to develop hypotheses about its origin and evolution. The main focus of the tool has been put on the graphical visualisation of the data. In the present paper we will describe in short the tool GCAT and give a couple of applications presenting new results on circular codes and the structure of some ancient codes. © 2018, Springer International Publishing AG.","Binary dichotomic algorithms; Circular codes; GCAT; Genetic code analysis toolkit; Genetic information","Biology; Biomedical engineering; Biosynthesis; Computer software; Genes; Circular codes; GCAT; Genetic code; Genetic information; Living organisms; Molecular basis; New results; Self organisation; Codes (symbols)",2-s2.0-85028660994
"Pires J., Cota M.P., Rocha Á., Gonçalves R.","Towards a new approach of learning: Learn by thinking extending the paradigm through cognitive learning and artificial intelligence methods to improve special education needs",2018,"Studies in Computational Intelligence",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026297015&doi=10.1007%2f978-3-319-58965-7_18&partnerID=40&md5=50d308912cfd29d2f0a608bb1bcc1f7f","Cognitive theorists believe that the learning process involves the integration of events into actives organizational structures termed schemata. Schemata serve a number of functions in human cognition: schemata regulates attention, organizes searches of the environment and “fill the gaps” during information processing. Thus, the mind uses schemata to selectively organize and processes all the information individuals receive from the world. This perspective fits e.g. in teaching blind and deaf people alongside of children with special education needs. The aim of the research developed until the moment was to prove that the full integration of the concept of teaching and learning in the light of cognitive theories. © Springer International Publishing AG 2018.","Adaptive cognitive learning; Chi-square; ELearning; Genetic algorithms; Hypermedia system; Java; Knowledge-block; Pervasive computing; Ubiquitous computing; XML",,2-s2.0-85026297015
"Choi S.-G., Cho S.-B.","Adaptive database intrusion detection using evolutionary reinforcement learning",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028667927&doi=10.1007%2f978-3-319-67180-2_53&partnerID=40&md5=158e87ce80295227565d315edc45d2d9","This paper proposes an adaptive database intrusion detection model that can be resistant to potential insider misuse with a limited number of data. The intrusion detection model can be adapted online using evolutionary reinforcement learning (ERL) which combines reinforcement learning and evolutionary learning. The model consists of two feedforward neural networks, a behavior network and an evaluation network. The behavior network detects the intrusion, and the evaluation network provides feedback to the detection of the behavior network. To find the optimal model, we encode the weights of the networks as an individual and produce populations of better individuals over generations. TPC-E scenario-based virtual query data were used for verification of the proposed model. Experimental results show that the detection performance improves as the proposed model learns the intrusion adaptively. © 2018, Springer International Publishing AG.","Database intrusion detection; Evolutionary computation; Insider threat; Multi-layer perceptron; Online learning; Reinforcement learning","Database systems; Education; Evolutionary algorithms; Feedforward neural networks; Mercury (metal); Query processing; Reinforcement learning; Soft computing; Behavior network; Detection performance; Evolutionary Learning; Insider Threat; Intrusion detection models; Multi layer perceptron; Number of datum; Online learning; Intrusion detection",2-s2.0-85028667927
"Bidelman G.M.","Sonification of scalp-recorded frequency-following responses (FFRs) offers improved response detection over conventional statistical metrics",2018,"Journal of Neuroscience Methods",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029702680&doi=10.1016%2fj.jneumeth.2017.09.005&partnerID=40&md5=183d1701d8e49b594eb776e283b1af3d","Background The human frequency-following response (FFR) is a neurophonic potential used to examine the brain's encoding of complex sounds (e.g., speech) and monitor neuroplastic changes in auditory processing. Given the FFR's low amplitude (order of nanovolts), current conventions in literature recommend collecting several thousand trials to obtain a robust evoked response with adequate signal-to-noise ratio. New method By exploiting the spectrotemporal fidelity of the response, we examined whether auditory playbacks (i.e., “sonifications”) of the neural FFR could be used to assess the quality of running recordings and provide a stopping rule for signal averaging. Results and comparison with existing method In a listening task over headphones, naïve listeners detected speech-evoked FFRs within ∼500 sweeps based solely on their perception of the presence/absence of a tonal quality to the response. Moreover, response detection based on aural sonifications offered similar and in some cases a 2–3× improvement over objective statistical techniques proposed in the literature (i.e., MI, SNR, MSC, F-test, Corr). Conclusions Our findings suggest that simply listening to FFR responses (sonifications) might offer a rapid technique to monitor real-time EEG recordings and provide a stopping rule to terminate signal averaging that performs comparably or better than current approaches. © 2017 Elsevier B.V.","Data auralization; EEG detection algorithms; F-test; Mean-squared coherence (MSC); Objective audiometry","adult; Article; auditory stimulation; clinical article; electroencephalogram; evoked response; female; frequency analysis; frequency following response; human; male; perception; priority journal; response time; signal noise ratio; speech; statistical analysis; ultrasound; waveform",2-s2.0-85029702680
"Chen J., Zhang L., Dong X.","Clustering personalized 3D printing models with multiple modal CNN",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030843349&doi=10.1007%2f978-981-10-6496-8_64&partnerID=40&md5=f7105d2753d06f1379576fb25179357c","Clustering personalized 3D printing models is very useful for a cloud manufacturing management system, but it is difficult to cluster directly because of the complexity and abstraction of the 3D print model input. In this paper we use the convolution neural networks (CNNs) to learn the similarities of 3D print model pairs in different input modes and integrate these similarities by multi-channel spectral clustering. The three-dimensional CNN and the view-based CNN are used for different input modes. Our experiments show that the accuracy of the clustering can be improved by merging training results of different input modes. © 2018, Springer Nature Singapore Pte Ltd.","CNNs; Personalized 3D print model; Similarity classifier; Spectral cluster","Clustering algorithms; Intelligent systems; Printing; 3d prints; Cloud Manufacturing; CNNs; Convolution neural network; Multi channel; Similarity classifier; Spectral cluster; Spectral clustering; 3D printers",2-s2.0-85030843349
"Madankumar S., Rajendran C.","Mathematical models for green vehicle routing problems with pickup and delivery: A case of semiconductor supply chain",2018,"Computers and Operations Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964588019&doi=10.1016%2fj.cor.2016.03.013&partnerID=40&md5=15f0ed42f664f8eb3c03f30f7f4b0231","In this paper, we consider a special case of vehicle routing problem that addresses the routing problem in a semiconductor supply chain. This paper proposes two Mixed Integer Linear Programming (MILP) models for solving the Green Vehicle Routing Problems with Pickups and Deliveries in a Semiconductor Supply Chain (G-VRPPD-SSC). The first MILP model considers the basic G-VRPPD-SSC problem, and the objective is to find the set of minimum cost routes and schedules for the alternative fuel vehicles in order to satisfy a set of requests which comprise pickup and delivery operations, without violating the product and vehicle compatibility, vehicle capacity, request-priorities and request-types, and start/completion time constraints. The second model extends the first model in order to handle the scenario of having different fuel prices at different refueling stations, and the objective is to minimize the sum of costs of operating alternative fuel vehicles, which include both the routing cost and the refueling cost. To relatively evaluate the performance of the proposed MILP models, we consider the Pickup and Delivery Problem in a Semiconductor Supply Chain (PDP-SSC) without the presence of alternative fuel vehicles, and we present the corresponding MILP model. Our model is compared with an MILP model present in the literature. Our study indicates that the proposed model for the PDP-SSC gives better lower bounds than that by the existing work, apart from performing better than the existing work in terms of requiring less CPU time. In all cases, the proposed three MILP models preform quite good in terms of the execution time to solve the generated problem instances. © 2017 Elsevier Ltd","Alternative Fuel Vehicles; Green Vehicle Routing Problem with Pickup and Delivery; Request-priorities and Request-types; Time constraints; Vehicle Compatibility","Alternative fuels; Costs; Fuels; Integer programming; Network routing; Pickups; Routing algorithms; Supply chains; Vehicle routing; Vehicles; Alternative fuel vehicles; Mixed integer linear programming model; Pickup and delivery; Pickup and delivery problems; Request-priorities and Request-types; Semiconductor supply chain; Time constraints; Vehicle Routing Problems; Problem solving",2-s2.0-84964588019
"Mason G., Calinescu R., Kudenko D., Banks A.","Assurance in reinforcement learning using quantitative verification",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032362526&doi=10.1007%2f978-3-319-66790-4_5&partnerID=40&md5=3623788264b8e450723494f5c435a280","Reinforcement learning (RL) agents converge to optimal solutions for sequential decision making problems. Although increasingly successful, RL cannot be used in applications where unpredictable agent behaviour may have significant unintended negative consequences. We address this limitation by introducing an assured reinforcement learning (ARL) method which uses quantitative verification (QV) to restrict the agent behaviour to areas that satisfy safety, reliability and performance constraints specified in probabilistic temporal logic. To this end, ARL builds an abstract Markov decision process (AMDP) that models the problem to solve at a high level, and uses QV to identify a set of Pareto-optimal AMDP policies that satisfy the constraints. These formally verified abstract policies define areas of the agent behaviour space where RL can occur without constraint violations. We show the effectiveness of our ARL method through two case studies: a benchmark flag-collection navigation task and an assisted-living planning system. © 2018, Springer International Publishing AG.","Abstract markov decision processes; Quantitative verification; Reinforcement learning; Safety","Accident prevention; Behavioral research; Decision making; Learning algorithms; Markov processes; Pareto principle; Probabilistic logics; Constraint violation; Markov Decision Processes; Optimal solutions; Performance constraints; Probabilistic temporal logic; Quantitative verification; Reinforcement learning agent; Sequential decision making; Reinforcement learning",2-s2.0-85032362526
"Soleimani S., Rajaei S., Jiao P., Sabz A., Soheilinia S.","New prediction models for unconfined compressive strength of geopolymer stabilized soil using multi-gen genetic programming",2018,"Measurement: Journal of the International Measurement Confederation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028756979&doi=10.1016%2fj.measurement.2017.08.043&partnerID=40&md5=1261a6ae47c072e9716b547379d9cd08","This study presents new models for the prediction of unconfined compressive strength (UCS) of geopolymer stabilized clayey soils using a modified branch of genetic programming, called multi-gen genetic programming (MGGP). The proposed MGGP models incorporate several parameters affecting the behavior of the UCS of the clayey stabilized soil. UCS is formulated in terms of percentages of fly ash, ground granulated blast furnace slag, liquid limit, plastic limit, plasticity index, molar concentration, alkali to binder ratio, and ratios of sodium and silicon to aluminum. The importance of each predictor variable is measured through a sensitivity analysis. The validity of the models and the trend of the results are verified by performing parametric study. The parametric study results are also in good agreement with previous studies. The results indicate that the proposed equations are capable of evaluating UCS accurately. © 2017 Elsevier Ltd","Genetic programming; Geopolymer; Prediction; Soil stabilization","Blast furnaces; Compressive strength; Fly ash; Forecasting; Genetic algorithms; Geopolymers; Inorganic polymers; Sensitivity analysis; Slags; Soil mechanics; Soils; Stability; Stabilization; Geopolymer; Ground granulated blast furnace slag; Molar concentration; Plasticity indices; Predictor variables; Sodium and silicons; Soil stabilization; Unconfined compressive strength; Genetic programming",2-s2.0-85028756979
"Rabbi K., Mamun Q., Islam M.R.","A novel swarm intelligence based strategy to generate optimum test data in T-Way testing",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032706236&doi=10.1007%2f978-3-319-67071-3_31&partnerID=40&md5=71f96a19150165258e9e13f2897e5f68","The limitation of resources and the deadline of software and hardware projects inhibits the exhaustive testing of a system. The most effective way to overcome this problem is to generation of optimal test suite. Heuristic searches are used to optimize the test suite since 1992. Recently, the interest and activities is increasing in this area. In theory, the changes to the parameter interaction (the t) can significantly reduce the number data in the test suite. Using this principle many scientists and practitioners created some effective test suite generation strategies. The implementation of heuristic search in the generation of optimum and minimum test suite is the most effective. However, producing the optimum test data is a NP-hard problem (Non-deterministic polynomial). Thus, it is impossible for any strategy that can produce the optimum test suite in any circumstance. This paper represents a novel swarm intelligent based searching strategy (mSITG) to generate optimum test suite. The performances of the mSITG are analyzed and compared with other well-known strategies. Empirical result shows that the proposed strategy is highly acceptable in terms of the test data size. © 2018, Springer International Publishing AG.","Combinatorial interaction testing; Interaction testing; Software testing; Swarm intelligence; T-way testing; Test case generation","Artificial intelligence; Computational complexity; Heuristic algorithms; Optimization; Swarm intelligence; Testing; Combinatorial interaction testing; Exhaustive testing; Interaction testing; Parameter interactions; Searching strategy; Software and hardwares; T-way testing; Test case generation; Software testing",2-s2.0-85032706236
"Ito R., Yoshidome T.","An accurate computational method for an order parameter with a Markov state model constructed using a manifold-learning technique",2018,"Chemical Physics Letters",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032711743&doi=10.1016%2fj.cplett.2017.10.057&partnerID=40&md5=b1135476107249d203c6b4ee879a2101","Markov state models (MSMs) are a powerful approach for analyzing the long-time behaviors of protein motion using molecular dynamics simulation data. However, their quantitative performance with respect to the physical quantities is poor. We believe that this poor performance is caused by the failure to appropriately classify protein conformations into states when constructing MSMs. Herein, we show that the quantitative performance of an order parameter is improved when a manifold-learning technique is employed for the classification in the MSM. The MSM construction using the K-center method, which has been previously used for classification, has a poor quantitative performance. © 2017 Elsevier B.V.",,"Learning systems; Molecular dynamics; Proteins; Long time behavior; Manifold learning; Markov State models; Molecular dynamics simulations; Order parameter; Physical quantities; Poor performance; Protein conformation; Learning algorithms",2-s2.0-85032711743
"Caruso G., Gattone S.A., Fortuna F., Di Battista T.","Cluster analysis as a decision-making tool: A methodological review",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021763192&doi=10.1007%2f978-3-319-60882-2_6&partnerID=40&md5=c828c0c5a19accb0fd3ed396fb6b0bd5","Cluster analysis has long played an important role in a broad variety of areas, such as psychology, biology, computer sciences. It has established as a precious tool for marketing and business areas, thanks to its capability to help in decision-making processes. Traditionally, clustering approaches concentrate on purely numerical or categorical data only. An important area of cluster analysis deals with mixed data, composed by both numerical and categorical attributes. Clustering mixed data is not simple, because there is a strong gap between the similarity metrics for these two kind of data. In this review we provide some technical details about the kind of distances that could be used with mixed-data types. Finally, we emphasize as in most applications of cluster analysis practitioners focus either on numeric or categorical variables, lessening the effectiveness of the method as a tool of decision-making. © Springer International Publishing AG 2018.","Clusters analysis; Decision-making; Mixed data","Artificial intelligence; Clustering algorithms; Decision making; Distributed computer systems; Categorical attributes; Categorical variables; Clustering approach; Clusters analysis; Decision making process; Decision making tool; Mixed data; Similarity metrics; Cluster analysis",2-s2.0-85021763192
"Lin Y., Wang B., Zhao Y.","Moving shadow detection using fusion of multiple features",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031426863&doi=10.1007%2f978-981-10-3773-3_47&partnerID=40&md5=957a98312b52458c59ebcf2a13429c58","Moving shadow detection is an important technique for the integrity of object detection. This paper is based on the assumption that the shadow area is darker than the corresponding background area but keeps color constancy and texture consistency. The main contributions of this paper include two parts. First, an adaptive mechanism for shadow detection is proposed using texture of improved local ternary pattern. The main idea is to detect partial real shadows to estimate relative accurate threshold parameters for shadow detector. Second, we utilize a model of genetic programming model to fuse multiple features: texture, color, and gradient information. Experimental results on indoor and outdoor sequences demonstrated that the proposed method outperforms some state-of-the-art methods. © Springer Nature Singapore Pte Ltd. 2018.","Genetic programming model; Improved local ternary pattern; Moving shadow; Multiple features","Genetic algorithms; Object detection; Genetic programming modeling; Gradient informations; Local ternary patterns; Moving shadow; Moving shadow detection; Multiple features; State-of-the-art methods; Threshold parameters; Genetic programming",2-s2.0-85031426863
"Srivastava D.K., Nair P.","Employee attrition analysis using predictive techniques",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028428954&doi=10.1007%2f978-3-319-63673-3_35&partnerID=40&md5=d4363b592d85e8869b4c9778510afe86","Employee churn is an unsolicited aftermath of our blooming economy. Attrition may be defined as voluntary or involuntary resignation of a serving employee from an organization. Employee churn can incur a colossal cost to the firm. However, furtherance to prediction and control over attrition can give quality results. Earmarking the risk of attrition, the management can take required steps to retain the high valued talent. Workforce Analytics can be applied to reduce the overall business risk by predicting the employee churn. Predictive Analytics is the field of study that employs statistical analysis, data mining techniques and machine learning to predict the future events with accuracy based on past and current situation. The paper presents a framework for predicting the employee attrition with respect to voluntary termination employing predictive analytics. © 2018, Springer International Publishing AG.","Data mining; Employee attrition; Predictive algorithms; Predictive analytics; Turnover prediction","Data mining; Forecasting; Intelligent systems; Learning systems; Quality control; Business risks; Current situation; Prediction and control; Predictive algorithms; Predictive techniques; Risk of attritions; Predictive analytics",2-s2.0-85028428954
"Hadjiantoni S., Kontoghiorghes E.J.","A recursive three-stage least squares method for large-scale systems of simultaneous equations",2018,"Linear Algebra and Its Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029814769&doi=10.1016%2fj.laa.2017.08.019&partnerID=40&md5=d18d70fb16f7bbf43f353cf9ea592fef","A new numerical method is proposed that uses the QR decomposition (and its variants) to derive recursively the three-stage least squares (3SLS) estimator of large-scale simultaneous equations models (SEM). The 3SLS estimator is obtained sequentially, once the underlying model is modified, by adding or deleting rows of data. A new theoretical pseudo SEM is developed which has a non positive definite dispersion matrix and is proved to yield the 3SLS estimator that would be derived if the modified SEM was estimated afresh. In addition, the computation of the iterative 3SLS estimator of the updated observations SEM is considered. The new recursive method utilizes efficiently previous computations, exploits sparsity in the pseudo SEM and uses as main computational tool orthogonal and hyperbolic matrix factorizations. This allows the estimation of large-scale SEMs which previously could have been considered computationally infeasible to tackle. Numerical trials have confirmed the effectiveness of the new estimation procedures. The new method is illustrated through a macroeconomic application.1 © 2017 Elsevier Inc.","High dimensional data; Matrix algebra; QR decomposition; Updating","Clustering algorithms; Iterative methods; Large scale systems; Least squares approximations; Numerical methods; Estimation procedures; High dimensional data; Matrix factorizations; Q R decomposition; Simultaneous equations; Simultaneous equations model; Three-stage least squares; Updating; Matrix algebra",2-s2.0-85029814769
"Pérez-Basante A., Ceballos S., Konstantinou G., Pou J., Andreu J., De Alegría I.M.","(2N+1) Selective Harmonic Elimination-PWM for Modular Multilevel Converters: A Generalized Formulation and A Circulating Current Control Method",2018,"IEEE Transactions on Power Electronics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032205693&doi=10.1109%2fTPEL.2017.2666847&partnerID=40&md5=ad3489d208d66d2a20122447f2c01411","The performance of modular multilevel converters (MMCs) in medium-voltage applications, where the number of required submodules is not high, can be improved utilizing low switching frequency modulations such as (2N+1) selective harmonic elimination-pulse width modulation (SHE-PWM), which provides tight control of lower order harmonics and low switching losses. This paper proposes a calculation method, which is based on a novel formulation, to solve the SHE-PWM problem. In particular, MMCs with (2N+1) phase output voltage levels are considered, obtaining a (2N+1) SHE-PWM waveform. This method utilizes a unique system of equations that is valid for any possible waveform. Therefore, it is able to calculate simultaneously, without predefined waveforms, both the switching patterns and the associated firing angles that solve the (2N+1) SHE-PWM problem. Consequently, the search process is simplified and optimized. Furthermore, this paper also proposes a circulating current control technique, which can be applied along with (2N+1) SHE-PWM without disturbing the phase output voltage. Simulation results and experimental tests obtained with a single-phase laboratory prototype prove the validity of the novel (2N+1) SHE-PWM implementation method and the proposed circulating current control technique. © 1986-2012 IEEE.","Circulating current; modular multilevel converter (MMC); optimization algorithms; selective harmonic elimination (SHE)","Electric current control; Electric rectifiers; Harmonic analysis; Modulation; Optimization; Pulse width modulation; Voltage control; Circulating current; Low switching frequency; Lower order harmonics; Modular multi-level converters; Optimization algorithms; Selective harmonic elimination; Selective harmonic elimination PWM; System of equations; Power converters",2-s2.0-85032205693
"Dhawan A., Deepika M.G.","Crime against women: A state level analysis using a hierarchical and k-means clustering techniques",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032672494&doi=10.1007%2f978-3-319-68385-0_21&partnerID=40&md5=55eb21dcd315f0581caed68829989e12","Despite the constitutional and legal provisions, crime against women in India has been continuously on the rise. While the incidence of crime against women is sharply on the rise, different dimensions of crime have varied across the states. Given the NCRB data on crime against women in India at the state level, the current study examines the dimensions and changing trends on crime against women and its association with important socio economic variables. Cluster analysis using agglomerative hierarchical method suggests for three clusters. We then use the widely used K-Means clustering method to arrive at the final clusters. The analysis reveals strong association of the rate of crime with that of socio economic variables like poverty rate, per capita state domestic product, literacy rate and the human development ranking of the state. The study reveals the importance of development indicators as much as the legal provisions in bringing down the rate of crime against women in India. © Springer International Publishing AG 2018.","Cluster analysis; Crime; Development; India; Women","Cluster analysis; Clustering algorithms; Economic analysis; Intelligent systems; Agglomerative hierarchical; Development; Human development; India; K-means clustering method; K-means clustering techniques; Legal provisions; Women; Crime",2-s2.0-85032672494
"Shin D.-W., Kang Y., Park E.-J.","C0-discontinuous Galerkin methods for a wind-driven ocean circulation model: Two-grid algorithm",2018,"Computer Methods in Applied Mechanics and Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030559789&doi=10.1016%2fj.cma.2017.08.034&partnerID=40&md5=c789dc9d14cba0a682466c2666134fce","This paper presents a nonconforming finite element method for a streamfunction formulation of the stationary quasi-geostrophic equations, which describe the large scale wind-driven ocean circulation. The streamfunction formulation is a fourth order nonlinear PDE and the nonconforming method is based on C0-elements instead of C1-elements. Existence and uniqueness of the approximation are proved and optimal error estimates in several norms of interest are demonstrated under a small data assumption. Two-grid algorithms based on Picard and Newton type linearizations are then presented to efficiently resolve nonlinearities and computational results are given to demonstrate the efficiency of the algorithm. The Mediterranean sea example is tested with real world coastline data, which illustrates the effectiveness of the two-grid approach in the wind-driven ocean circulation simulation. © 2017 Elsevier B.V.","Fourth-order partial-differential equation; Geophysical fluid dynamics; Nitsche's method; Nonconforming finite-element method","Computational efficiency; Control nonlinearities; Galerkin methods; Oceanography; Partial differential equations; Existence and uniqueness; Fourth order partial differential equations; Geophysical fluid dynamics; Nitsche's methods; Nonconforming finite element method; Ocean circulation models; Optimal error estimate; Streamfunction formulation; Finite element method",2-s2.0-85030559789
"Nguyen L.T.T., Nguyen L.T.T., Vo B.","An improved algorithm for mining top-k association rules",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025160120&doi=10.1007%2f978-3-319-61911-8_11&partnerID=40&md5=279c05637f2171a2b5973cda0b94a367","This paper proposes an improved algorithm of TopKRules algorithm which was proposed by Philippe et al. in 2012 to mine top-k association rules (ARs). To impove the perfomance of TopKRules, we develop two propositions to reduce search space and runtime in the mining process. Experimental results on standard databases show that our algorithm need less time than TopKRules algorithm to generate usefull rules. © Springer International Publishing AG 2018.","Association rule mining; Data mining; Rule expansion; Top-k association rules","Aluminum alloys; Data mining; Mining process; Perfomance; Rule expansions; Runtimes; Search spaces; Association rules",2-s2.0-85025160120
"Azad M., Bozorg-Haddad O., Chu X.","Flower pollination algorithm (FPA)",2018,"Studies in Computational Intelligence",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021654851&doi=10.1007%2f978-981-10-5221-7_7&partnerID=40&md5=babe5702f96c2f772c959057d2f79ded","This chapter is designed to describe the flower pollination algorithm (FPA) which is a new metaheuristic algorithm. First, the FPA applications in different problems are summarized. Then, the natural pollination process and the flower pollination algorithm are described. Finally, a pseudocode of the FPA is presented. © 2018, Springer Nature Singapore Pte Ltd.",,,2-s2.0-85021654851
"Bahrami M., Bozorg-Haddad O., Chu X.","Moth-flame optimization (MFO) algorithm",2018,"Studies in Computational Intelligence",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021629280&doi=10.1007%2f978-981-10-5221-7_13&partnerID=40&md5=267909aa1704229c275f9518f7c6176f","This chapter introduces the Moth-Flame Optimization (MFO) algorithm, along with its applications and variations. The basic steps of the algorithm are explained in detail and a flowchart is represented. In order to better understand the algorithm, a pseudocode of the MFO is also included. © 2018, Springer Nature Singapore Pte Ltd.",,,2-s2.0-85021629280
"Zolghadr-Asli B., Bozorg-Haddad O., Chu X.","Crow search algorithm (CSA)",2018,"Studies in Computational Intelligence",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021693355&doi=10.1007%2f978-981-10-5221-7_14&partnerID=40&md5=7598472440603d521532b85264dcf0e4","The crow search algorithm (CSA) is novel metaheuristic optimization algorithm, which is based on simulating the intelligent behavior of crow flocks. This algorithm was introduced by Askarzadeh (2016) and the preliminary results illustrated its potential to solve numerous complex engineering-related optimization problems. In this chapter, the natural process behind a standard CSA is described at length. © 2018, Springer Nature Singapore Pte Ltd.",,,2-s2.0-85021693355
"Flores-Garrido M., Carrasco-Ochoa J.A., Martínez-Trinidad J.F.","Extensions to AGraP Algorithm for Finding a Reduced Set of Inexact Graph Patterns",2018,"International Journal of Pattern Recognition and Artificial Intelligence",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029180990&doi=10.1142%2fS0218001418600121&partnerID=40&md5=11d927c35fb6fa4a5b45074cc99f1e8e","Most algorithms to mine graph patterns, during the searching process, require a pattern to be identical to its occurrences, relying on the graph isomorphism problem. However, in recent years, there has been interest in the case in which it is acceptable to have some differences between a pattern and its occurrences, whether these differences are in labels or in structure. Allowing some differences and using inexact matching to measure the similarity between graphs lead to the discovery of new patterns, but some important challenges, such as the increment on the number of found patterns, make the post-mining analysis harder. In this work we focus on two extensions of the AGraP algorithm, which mines inexact patterns, addressing the issue of reducing the output pattern set while trying to retain the useful information gained through the use of inexact matching. First, exploring a traditional approach, we propose the CloseAFG algorithm that focuses on closed patterns. Then, we propose the IntAFG algorithm to find a subset of patterns covering the original pattern set, while lessening redundancy among selected patterns. We show the performance of our approaches through some experiments on synthetic databases; additionally, we also show the usefulness of the reduced pattern sets for image classification. © 2018 World Scientific Publishing Company.","approximate patterns; Closed frequent pattern; frequent patterns in a single graph; inexact matching; interesting patterns","Pattern recognition; Software engineering; approximate patterns; Closed frequent pattern; inexact matching; interesting patterns; Single graph; Classification (of information)",2-s2.0-85029180990
"Zolghadr-Asli B., Bozorg-Haddad O., Chu X.","Krill herd algorithm (KHA)",2018,"Studies in Computational Intelligence",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021659449&doi=10.1007%2f978-981-10-5221-7_8&partnerID=40&md5=e5dbad5c2396b73ea43286d42e003d8d","The krill herd algorithm (KHA) is a new metaheuristic search algorithm based on simulating the herding behavior of krill individuals using a Lagrangian model. This algorithm was developed by Gandomi and Alavi (2012) and the preliminary studies illustrated its potential in solving numerous complex engineering optimization problems. In this chapter, the natural process behind a standard KHA is described. © 2018, Springer Nature Singapore Pte Ltd.",,,2-s2.0-85021659449
"Zolghadr-Asli B., Bozorg-Haddad O., Chu X.","Dragonfly algorithm (DA)",2018,"Studies in Computational Intelligence",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021683082&doi=10.1007%2f978-981-10-5221-7_15&partnerID=40&md5=34d2268f63139f7461f3e4a1dd3061a8","The dragonfly algorithm (DA) is a new metaheuristic optimization algorithm, which is based on simulating the swarming behavior of dragonfly individuals. This algorithm was developed by Mirjalili (2016) and the preliminary studies illustrated its potential in solving numerous benchmark optimization problems and complex computational fluid dynamics (CFD) optimization problems. In this chapter, the natural process behind a standard DA is described at length. © 2018, Springer Nature Singapore Pte Ltd.",,,2-s2.0-85021683082
"Li L., Li P., Xu H., Chen F.","A bayes classifier-based OVFDT algorithm for massive stream data mining on big data platform",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026310606&doi=10.1007%2f978-3-319-61566-0_49&partnerID=40&md5=28672531ac07e89be38f8776a751079b","Recently, online incremental data mining has become an immensely growing area of research for stream data mining. VFDT algorithm, as an excellent incremental decision tree classification algorithm, is widely used in online data mining. To optimize VFDT algorithm, a dynamic tie-breaking threshold strategy and a pre-pruning mechanism strategy are utilized to achieve the reduction of the scale of decision tree. Furthermore, Bayes classifier is applied to leaf nodes of Hoeffding decision tree, which promotes the improvement of classification accuracy. In this paper, this improved algorithm is called OVFDT (Optimized VFDT) algorithm. To improve the performance of OVFDT for massive streaming data processing, an implementation scheme of OVFDT Algorithm on MapReduce Platform is proposed in our paper. Considering the need for real-time computing, the implementation scheme on Storm Platform is designed. Three comparison experiments are designed to compare the scale, the classification accuracy and the execution time of decision tree of three algorithm generate. The simulation results reveal that compared with C4.5 and VFDT algorithm, OVFDT algorithm can effectively reduce the scale of the decision tree, achieves the improvement of classification accuracy as well. © Springer International Publishing AG 2018.",,"Big data; Data handling; Decision trees; Trees (mathematics); Classification accuracy; Decision tree classification; Implementation scheme; Incremental data; Real time computing; Stream data mining; Streaming data processing; Threshold strategy; Data mining",2-s2.0-85026310606
"Shi Q., Li F., Hu Q., Wang Z.","Dynamic demand control for system frequency regulation: Concept review, algorithm comparison, and future vision",2018,"Electric Power Systems Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028077697&doi=10.1016%2fj.epsr.2017.07.021&partnerID=40&md5=9a90ed0c3df53673871b918f2f15bff2","The increasing penetration of renewable energy resources brings a number of uncertainties to modern power system operation. In particular, the frequent variation of wind power output causes a short-term mismatch between generation and demand, which causes system frequency fluctuation. The traditional approach to deal with this problem is to increase the amount of system spinning reserve. In recent years, researchers are actively exploring the utilization of residential and commercial loads in frequency regulation without affecting customers’ life quality. This paper first reviews the theoretical basis and application background of the dynamic demand control. Then, the paper summarizes the technical features and advantage/disadvantages of three types of dynamic demand control algorithms, namely centralized control, decentralized control and hybrid control. The technical and economic concerns of this research field are also discussed, which can be future research directions. © 2017 Elsevier B.V.","Demand response; Dynamic demand control; Frequency regulation; Renewable energy penetration; Responsive load; Spinning reserve","Energy resources; Renewable energy resources; Wind power; Demand response; Dynamic demand controls; Frequency regulations; Renewable energy penetrations; Responsive load; Spinning reserves; Decentralized control",2-s2.0-85028077697
"Abdi-Dehkordi M., Bozorg-Haddad O., Chu X.","Gradient evolution (GE) algorithm",2018,"Studies in Computational Intelligence",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021652096&doi=10.1007%2f978-981-10-5221-7_12&partnerID=40&md5=6706167891297114432e4d219d09237e","In this chapter, a meta-heuristic optimization algorithm named gradient evolution (GE) is discussed, which is based on a gradient search method. First, the GE algorithm and the underlying idea are introduced and its applications in some studies are reviewed. Then, the mathematical formulation and a pseudo-code of GE are discussed. Finally, the conclusion is presented. © 2018, Springer Nature Singapore Pte Ltd.",,,2-s2.0-85021652096
"Patwal R.S., Narang N., Garg H.","A novel TVAC-PSO based mutation strategies algorithm for generation scheduling of pumped storage hydrothermal system incorporating solar units",2018,"Energy",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032268947&doi=10.1016%2fj.energy.2017.10.052&partnerID=40&md5=157d5c02e96a3bd0a344b8908c1c52e0","With increasing penetration of renewable energy sources, it is necessary to analyze its impact on the allocation of optimal power generation schedule. In this work, the pumped storage hydrothermal (PSHT) system incorporating solar units has been undertaken. The novel integrated heuristic approach named as time varying acceleration coefficient particle swarm optimization with mutation strategies (TVAC-PSO-MS) has been proposed. In this approach, an initial solution has been updated by the TVAC-PSO approach and then local best solutions are updated by using the successive mutation strategies namely Cauchy, Gaussian, and opposition based mutations. The Cauchy mutation strategy is applied to enhance the search capability and the Gaussian, as well as the opposition based mutation strategies are used to improve the exploitation capability of the algorithm. In order to validate the proposed approach, a standard test system of hydrothermal generation scheduling has been undertaken and the results have been compared with other state of art algorithms. Further, the proposed approach has been applied to optimize the cost of the PSHT system incorporating solar units and validate it through statistical test. © 2017 Elsevier Ltd","Mutation strategies; Pumped storage hydrothermal system; Solar units; Time varying acceleration coefficient particle swarm optimization",,2-s2.0-85032268947
"Kakulapati V., Pentapati V.","A setpitextOFF algorithm-based fast image projection analysis",2018,"Studies in Computational Intelligence",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031996915&doi=10.1007%2f978-3-319-63754-9_23&partnerID=40&md5=85d4ffa64544fc69c82d0c5e8b9c28f1","This paper proposes a novel image analysis algorithm called setpitextOFF algorithm for image texture interspacing, retrieving the OFF image pixels, run-length pixels block mapping and image fast projection. To explore the Implementation of Image Analysis, we combine the pixels at different space locations with similar retrieving dependencies as a space vector and mapped the space vectors to form interdependency setpi clusters by context building, these setpi clusters were analysed for the proposed setpitextOFF algorithm. Thereafter, we have formulated a double-setpi cluster to regularize the proposed algorithm implementation in a communication channel. Our proposed algorithm used less time to compute with more accuracy in quality performance metrics comparatively. Our proposed research work can be implemented in any digital communication link, for Video, Image and Data analysis. © Springer International Publishing AG 2018.","Communication link; Compute; Image analysis; Mapping; Texture",,2-s2.0-85031996915
"Wang C.-Y., He L., Li Y., Shuai C.-G.","A multi-reference filtered-x-Newton narrowband algorithm for active isolation of vibration and experimental investigations",2018,"Mechanical Systems and Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022203780&doi=10.1016%2fj.ymssp.2017.04.044&partnerID=40&md5=93aa621249e015e6e8dd64dba528cf23","In engineering applications, ship machinery vibration may be induced by multiple rotational machines sharing a common vibration isolation platform and operating at the same time, and multiple sinusoidal components may be excited. These components may be located at frequencies with large differences or at very close frequencies. A multi-reference filtered-x Newton narrowband (MRFx-Newton) algorithm is proposed to control these multiple sinusoidal components in an MIMO (multiple input and multiple output) system, especially for those located at very close frequencies. The proposed MRFx-Newton algorithm can decouple and suppress multiple sinusoidal components located in the same narrow frequency band even though such components cannot be separated from each other by a narrowband-pass filter. Like the Fx-Newton algorithm, good real-time performance is also achieved by the faster convergence speed brought by the 2nd-order inverse secondary-path filter in the time domain. Experiments are also conducted to verify the feasibility and test the performance of the proposed algorithm installed in an active-passive vibration isolation system in suppressing the vibration excited by an artificial source and air compressor/s. The results show that the proposed algorithm not only has comparable convergence rate as the Fx-Newton algorithm but also has better real-time performance and robustness than the Fx-Newton algorithm in active control of the vibration induced by multiple sound sources/rotational machines working on a shared platform. © 2017 Elsevier Ltd","Active control; MRFx-Newton; Multiple references; Narrowband; Ship machinery; Vibration isolation",,2-s2.0-85022203780
"Srividya B.V., Akhila S.","Implementing a hybrid crypto-coding algorithm for an image on FPGA",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028369547&doi=10.1007%2f978-3-319-63645-0_8&partnerID=40&md5=8c412d833dbc7e54903969c14f109591","This paper proposes a hardware design, implemented on an FPGA, for a hybrid selective encryption and selective error correction coding scheme. FPGA’s are used as implementation platforms in image processing, as its structure exploits the temporal and spatial parallelism. The algorithm aims at implementing security and reliability in which encryption and encoding are performed in a single step using Bezier curve and Galois field GF (2m). The system aims at speeding up the encryption and encoding operations without compromising either on security or on error correcting capability by using selective encryption and selective encoding. The coding for hybrid crypto-coding algorithm is carried out using VHDL. The algorithm is simulated and synthesized using Xilinx ISE 10.1 software. The algorithm is implemented on Spartan 3 FPGA device 3s1000fg676-5. The proposed scheme reduces the hardware as modular arithmetic operations are involved. © Springer International Publishing AG 2018.","Bezier curve; Encryption; Error correction; FPGA; Galois field; Image","Codes (symbols); Encoding (symbols); Error correction; Errors; Field programmable gate arrays (FPGA); Hardware; Image coding; Image processing; Intelligent systems; Interpolation; Signal encoding; Bezier curve; Error correction coding; Galois fields; Image; Implementation platforms; Security and reliabilities; Selective encryption; Temporal and spatial; Cryptography",2-s2.0-85028369547
"Ahlawat R.K., Malik A., Sadhu A.","Sybil attack prevention algorithm for body area networks",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031430127&doi=10.1007%2f978-981-10-6747-1_15&partnerID=40&md5=bf49d3b290d1ab7b8e8f5822387f644c","Advancement in wireless network technologies, such as wearable and implantable biosensors, along with present developments in the embedded computing area is enabling the design, progress and implementation of body area networks. Security in BANs is a big issue. In this paper, a new security algorithm for body area networks named Sybil attack prevention algorithm for body area networks (SAPA-BAN) is proposed. This algorithm protects the BANs from Sybil attack. It provides the confidentiality and integrity to the data or critical information about the patient’s health sent by a BAN to the coordinating centre/emergency services. This algorithm is energy efficient and reliable also because it operates on less energy. SAPA-BAN performs better in terms of throughput, packet delivery ratio, end-to-end delay, hops count and overhead. A comparative analysis of SAPA-BAN with respect to LSA is performed on the basis of above said parameters. © 2018, Springer Nature Singapore Pte Ltd.","Body area networks; Cluster head; Non-key; Security; Sybil attack","Computer crime; Energy efficiency; Wearable technology; Body Area Network; Cluster head; Non-key; Security; Sybil attack; Network security",2-s2.0-85031430127
"Mohammad-Azari S., Bozorg-Haddad O., Chu X.","Shark smell optimization (SSO) algorithm",2018,"Studies in Computational Intelligence",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021649975&doi=10.1007%2f978-981-10-5221-7_10&partnerID=40&md5=0c08b1c1c682355699c1b44258b63135","In this chapter, the shark smell optimization (SSO) algorithm is presented, which is inspired by the shark’s ability to hunt based on its strong smell sense. In Sect.Â 10.1, an overview of the implementations of SSO is presented. The underlying idea of the algorithm is discussed in Sect.Â 10.2. The mathematical formulation and a pseudo-code are presented in Sects.Â 10.3 and 10.4, respectively. SectionÂ 10.5 is devoted to conclusion. © 2018, Springer Nature Singapore Pte Ltd.",,,2-s2.0-85021649975
"Zhang R., Liu J., Zhu F.","A steganography algorithm based on MP3 linbits bit of huffman codeword",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026669712&doi=10.1007%2f978-3-319-63859-1_22&partnerID=40&md5=d81d3180d575601caf5629c14c98d7cf","This paper proposes a steganography algorithm based on MP3 linbits bit of Huffman codeword by analyzing the structure of MP3 bitstream and the characteristics of the linbits of MP3 encoding. Experimental results show that the proposed algorithm not only has very high embedding capacity and keeps transparency, but also has low computational complexity and has good real-time performance for embedding and extraction. © Springer International Publishing AG 2018.","Compressed-domain; Linbits; MP3; Steganography","Signal processing; Steganography; Bit stream; Compressed domain; Embedding capacity; Huffman codeword; Linbits; Low computational complexity; MP3 encoding; Real time performance; Multimedia signal processing",2-s2.0-85026669712
"Sarzaeim P., Bozorg-Haddad O., Chu X.","Teaching-learning-based optimization (TLBO) algorithm",2018,"Studies in Computational Intelligence",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021627782&doi=10.1007%2f978-981-10-5221-7_6&partnerID=40&md5=b85b925f1e4bae2dd582d8c410d2f6ff","This chapter is prepared to describe the Teaching-Learning-Based Optimization (TLBO) algorithm, a novel metaheuristic optimization method inspired by an educational classroom environment. It has an interesting exclusivity which may facilitate the solution process of optimization problems. In this chapter, a brief literature review of the TLBO algorithm is first presented. Then, the working process and two phases of TLBO (teacher phase and learner phase) are depicted. Eventually, a pseudocode of TLBO is presented. © 2018, Springer Nature Singapore Pte Ltd.",,,2-s2.0-85021627782
"Samolej S., Orkisz M., Rogalski T.","The Airspeed Automatic Control Algorithm for Small Aircraft",2018,"Studies in Systems, Decision and Control",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029692694&doi=10.1007%2f978-3-319-64674-9_10&partnerID=40&md5=d6ff4d5151e5a402b1133e7e6560a572","This paper presents selected results authors have reached during research of airspeed control algorithm developed for Single Engine Piston Light (SEPL) aircraft powered by piston engine with constant-pitch propeller in tractor configuration. There are some theoretical discussions about control law’s structure and methods of adjusting them to control plant’s operational features in this paper. Moreover, practical implementation of developed algorithm is described. Finally, results achieved both during computer simulations and flight tests are presented and discussed. © 2018, Springer International Publishing AG.","Flight control systems; General aviation; UAV and RPAS",,2-s2.0-85029692694
"Margun A., Furtat I., Bazylev D., Kremlev A.","Disturbance compensation and control algorithm with application for non-linear twin rotor MIMO system",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029216175&doi=10.1007%2f978-3-319-65960-2_53&partnerID=40&md5=609ddbf1b0729a5cd1f89a739df87212","The disturbance compensation algorithm for continuous-time multi input multi output (MIMO) nonlinear plants under parametric uncertainties and external disturbances with quantized output signal is proposed. The auxiliary loop approach is used for estimation disturbance function. The proposed algorithm guarantees that the output of the plant tracks the reference output with the required accuracy. The experimental results on non-linear twin rotor MIMO system illustrate the efficiency and robustness of the suggested control system. © 2018, Springer International Publishing AG.","Disturbances compensation; MIMO systems; Quantized measurement; Robust control","Continuous time systems; Robust control; Continuous-time; Disturbance compensation; Disturbance functions; External disturbances; Multi input multi output; Parametric uncertainties; Quantized measurements; Twin Rotor MIMO System; MIMO systems",2-s2.0-85029216175
"Saad H., Soliman T.H.A., Rady S.","Developing an efficient clique-based algorithm for community detection in large graphs",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029502635&doi=10.1007%2f978-3-319-64861-3_18&partnerID=40&md5=5d75a60460dd43232d18f93e8ddd866c","Many computer science problems are structured as a network. Mobile, e-mail, social networks (MySpace, Friendster, Facebook, etc.), collaboration networks, and Protein-Protein Interaction (PPI), Gene Regulatory Networks (GRN) and Metabolic Networks (MN) in bioinformatics, are among several applications. Discovering communities in Networks is a recent and critical task in order to understand and model network structures. Several methods exist for community detection, such as modularity, clique, and random walk methods. These methods are somewhat limited because of the time needed to detect communities and their modularity. In this work, a Clique-based Community Detection Algorithm (CCDA) is proposed to overcome time and modularity limitations. The clique method is suitable since it arises in many real-world problems, as in bioinformatics, computational chemistry, and social networks. In definition, clique is a group of individuals who interact with one another and share similar interests. Based on this definition, if one vertex of a clique is assigned to a specific community, all other vertices in this clique often belong to the same community. CCDA develops a simple and fast method to detect maximum clique for specific vertex. In addition, testing is done for the closest neighbor node instead of testing all nodes in the graph. Since neighbor nodes are also sorted in descending order, it contributes to save more execution time. Furthermore, each node will be visited exactly once. To test the performance of CCDA, it is compared with previously proposed community detection algorithms (Louvain, and MACH with DDA-M2), using various datasets: Amazon (262111 nodes/1234877 vertices), DBLP (317080 nodes/1049866 vertices), and LiveJournal (4847571 nodes, 68993773 vertices). Results have proven the efficiency of the proposed method in terms of time performance and modularity. © 2018, Springer International Publishing AG.","Clique; Community detection; Graph clustering; Graph mining; Network analysis",,2-s2.0-85029502635
"Han D., Sun W., Fan X.","Dynamic energy management in smart grid: A fast randomized first-order optimization algorithm",2018,"International Journal of Electrical Power and Energy Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025103478&doi=10.1016%2fj.ijepes.2017.07.003&partnerID=40&md5=92f5170e996cb53a5827a399a1a1ee57","A crucial issue in the smart grid is how to manage the controllable load resources of end-users, in order to reduce the economic costs of system operation and facilitate to utilize renewable energies. This paper investigates a fast randomized first-order optimization method to explore the solution of dynamic energy management (DEM) for the smart grid integrated large-scale distributed energy resources. A complicated time-coupling and multi-variable optimal problem is presented to determine the load scheduling for the electricity customers. The main challenge of the proposed problem is to enable the efficient processing of the large data volumes and optimization of aggregated data involved in DEM. The first-order method as one of big data optimization algorithms is able to exhibit significant performance for computing globally optimal solutions based on randomization techniques. Using such solution approach, we can reformulate the original problem into an unconstrained augmented Lagrangian function. The optimal results can be obtained from computing the gradient based on the information of the first-order derivative. To speed up the calculations of obtaining the feasible solutions, the optimization variable matrix used to update the Lagrangian multiplier can be replaced with the corresponding low-rank representation in the iteration process. Both theoretical analysis and simulation results suggest that the proposed approach may effectively solve the optimal scheduling problem of DEM considering users’ participation. © 2017 Elsevier Ltd","Augmented Lagrangian function; Distributed energy resources; Dynamic energy management; First-order optimization method; Low-rank matrix approximation","Big data; Constrained optimization; Electric power transmission networks; Energy management; Energy resources; Iterative methods; Lagrange multipliers; Matrix algebra; Numerical analysis; Optimization; Scheduling; Augmented Lagrangian functions; Distributed Energy Resources; Dynamic energy managements; First order optimization method; Low-rank matrix approximations; Smart power grids",2-s2.0-85025103478
"Chiroiu V., Brişan C., Dumitriu D., Munteanu L.","A sonification algorithm for developing the off-roads models for driving simulators",2018,"Mechanical Systems and Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022202861&doi=10.1016%2fj.ymssp.2017.05.002&partnerID=40&md5=50668e110186848a14ae1c9c65faef81","In this paper, a sonification algorithm for developing the off-road models for driving simulators, is proposed. The aim of this algorithm is to overcome difficulties of heuristics identification which are best suited to a particular off-road profile built by measurements. The sonification algorithm is based on the stochastic polynomial chaos analysis suitable in solving equations with random input data. The fluctuations are generated by incomplete measurements leading to inhomogeneities of the cross-sectional curves of off-roads before and after deformation, the unstable contact between the tire and the road and the unreal distribution of contact and friction forces in the unknown contact domains. The approach is exercised on two particular problems and results compare favorably to existing analytical and numerical solutions. The sonification technique represents a useful multiscale analysis able to build a low-cost virtual reality environment with increased degrees of realism for driving simulators and higher user flexibility. © 2017 Elsevier Ltd","Driving simulators; Off-road models; Polynomial chaos expansion; Sonification",,2-s2.0-85022202861
"Novelli A., Aguilar M.A., Tarantino E.","A new threshold relative radiometric correction algorithm (TRRCA) of multiband satellite data",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020465693&doi=10.1007%2f978-3-319-59480-4_5&partnerID=40&md5=be9feb7446a02e50dcd6e18504d2ee8a","It is well known that remote sensed scenes could be affected by many factors and, for optimum change detection, these unwanted effects must be removed. In this study a new algorithm is proposed for PIF (Pseudo Invariant Features) extraction and relative radiometric normalization. The new algorithm can be labeled as a supervised one and combines three methods for the detection of PIFs: Moment distance index (MDI), Normalized Difference Vegetation Index (NDVI) masks morphological erosion and dilate operators. In order to prove its effectiveness, the algorithm was tested by using Landsat 8 scenes of the “Mar de Plstico” landscape of the Andalusian Almería. Many tests were performed in order to provide a set of valid input parameters for the chosen environments. Lastly, the results were statistically assessed with parametric and non-parametric tests showing very good and stable results in the four different study areas. © Springer International Publishing AG 2018.","Change detection; Landsat 8; Multispectral imagery; PIF; Relative radiometric normalization","Interactive computer systems; Multimedia services; Multimedia systems; Remote sensing; Change detection; LANDSAT; Morphological erosion; Multi-spectral imagery; Normalized difference vegetation index; Pseudo-invariant features; Relative radiometric correction; Relative radiometric normalization; Radiometry",2-s2.0-85020465693
"Said S.A., Salem S.A., Sayed S.G.","Energy aware mobile cloud computing algorithm for android smartphones",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029475327&doi=10.1007%2f978-3-319-64861-3_58&partnerID=40&md5=e86b664b6f7794ec8c83a1d368f97424","Nowadays, smartphones and tablet computers have become progressively essential parts of our life. However, these devices are limited in their computational resources compared to other processing devices such as personal computers and laptops. To mitigate this problem, cloud computing can be a promising candidate to help resource-constrained devices by offloading the heavy applications onto the Cloud. In this paper, a novel energy aware mobile cloud computing algorithm is proposed. The proposed algorithm estimates the application computational time and uses weighted parameters to obtain a reliable offloading decision. This actually saves the energy and reduces applications’ execution time. Experimental results on different applications show that the proposed algorithm improves applications’ performance and effectively reduces the energy consumption through a robust estimation of applications’ execution time. © 2018, Springer International Publishing AG.","Computation offloading; Energy saving; Mobile cloud computing",,2-s2.0-85029475327
"Hao Y., Wang Q., Li Y., Song W.","An intelligent algorithm for fault location on VSC-HVDC system",2018,"International Journal of Electrical Power and Energy Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021887220&doi=10.1016%2fj.ijepes.2017.06.030&partnerID=40&md5=8e88ff503c8316dd3ca495a3ceccc87e","This paper proposes a novel intelligent algorithm for fault location on the voltage sourced converter-high voltage direct current (VSC-HVDC) system. This method with single-ended measurement makes full use of frequency, time and energy to capture the fault features via Hilbert-Huang Transform (HHT). The time delay, characteristic frequency, energy attenuation and high-frequency energy are used as the input of ε-support vector regression (SVR) to get fault distance. Then bat algorithm (BA) optimizes the parameters of the model with cross validation comparing with other optimization algorithm. Furthermore, high-frequency variance contribution rate (HVCR) is adopted to identify the fault area. The VSC-HVDC simulation system is constructed to verify the reliability and accuracy of the method and the expected accuracy of the proposed method is ±500 m. The results demonstrated that the proposed method still has reliability and accuracy for hybrid transmission line with a small amount of data. © 2017 Elsevier Ltd","BA-SVR; Fault location; HHT; HVCR; VSC-HVDC system","DC power transmission; Electric fault location; Location; Mathematical transformations; Optimization; Characteristic frequencies; High voltage direct current; Hilbert Huang transforms; HVCR; Hybrid transmission lines; Support vector regression (SVR); Voltage sourced converters; VSC-HVDC; HVDC power transmission",2-s2.0-85021887220
"Zhang J., Niu S., Li Y., Liu Y.","An algorithm for asymmetric clipping detection based on parameter optimization",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026673526&doi=10.1007%2f978-3-319-63859-1_2&partnerID=40&md5=9a58144d0964aca51851c25f1c81258e","Asymmetric clipping of digital images is a common method of image tampering, and the existing identification techniques of which are relatively meager. Camera calibration technology is an important method to determine the tampering of asymmetric cutting, but the proposed algorithm has made too many assumptions on the internal parameters matrix of the camera, resulting in some error. This paper presents a parameter optimization algorithm based on camera calibration: by keeping the four parameters in the original camera’s five internal parameters, after approximate processing, to achieve that a single picture contains no coplanar of the two regular geometric figures can calculate the coordinates of the principal point, and as a basis for the image forensics of the asymmetric cutting tampering. The experimental results show that the proposed algorithm can effectively estimate the camera parameters, the application scope and accuracy can be improved greatly, and can accurately detect the image tampering behavior of asymmetric clipping. © Springer International Publishing AG 2018.","Asymmetric clipping; Blind forensics; Camera calibration; Parameter optimization; Regular geometric figures","Calibration; Cameras; Cutting; Image processing; Multimedia signal processing; Optimization; Signal processing; Asymmetric clipping; Blind forensics; Camera calibration; Parameter optimization; Regular geometric figures; Parameter estimation",2-s2.0-85026673526
"Kim K.-W., Lee H.-H., Kim S.-H.","Efficient Combined Algorithm for Multiplication and Squaring for Fast Exponentiation over Finite Fields GF(2m)",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032487293&doi=10.1007%2f978-981-10-6520-0_6&partnerID=40&md5=71e00027d9199b5eade68f47296372b3","For big data security, high-speed arithmetic units are needed. Finite field arithmetic has received much attention in error-control codes, cryptography, etc. The modular exponentiation over finite fields is an important and essential cryptographic operation. The modular exponentiation can be performed by a sequence of modular squaring and multiplication based on the binary method. In this paper, we propose a combined algorithm to concurrently perform multiplication and squaring over GF(2m) using the bipartite method and common operations. We expect that the architecture based on the proposed algorithm can reduce almost a half of latency compared to the existing architecture. Therefore, we expect that our algorithm can be efficiently used for various applications including big data security which demands high-speed computation. © 2018, Springer Nature Singapore Pte Ltd.","Cryptography; Exponentiation; Finite fields; Multiplication; Squaring","Big data; Computation theory; Cryptography; Cryptographic operations; Existing architectures; Exponentiations; Finite field arithmetic; Finite fields; High-speed computation; Multiplication; Squaring; Computational efficiency",2-s2.0-85032487293
"Suganthi S.T., Devaraj D., Ramar K., Hosimin Thilagar S.","An Improved Differential Evolution algorithm for congestion management in the presence of wind turbine generators",2018,"Renewable and Sustainable Energy Reviews",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027556079&doi=10.1016%2fj.rser.2017.08.014&partnerID=40&md5=016cb197f960136b6fe58c03a02fb654","Congestion management is imperative for reliable and secure system operation in restructured power systems. Since the installation of wind farms at proper locations offers the possibility of congestion relief, this paper investigates congestion management in power systems with specific consideration of wind energy sources. The optimal location of a wind farm is determined by the Bus Sensitivity Factor and the Wind Availability Factor. Differential Evolution is a population-based heuristics algorithm used for solving non-linear optimization problems. We propose an Improved Differential Evolution based approach to ease congestion in transmission lines by generator rescheduling and installation of new wind farms. In this approach, an enhanced mutation operator is introduced to improve the performance of the Differential Evolution algorithm. A standard IEEE-30 bus system is used to evaluate the proposed algorithm under critical line outages. The simulation results show that the proposed approach is more effective than other approaches. © 2017 Elsevier Ltd","Bus Sensitivity Factor; Congestion management; Generation rescheduling; Improved Differential Evolution; Wind Availability Factor",,2-s2.0-85027556079
"Abdmouleh M.K., Amri H., Khalfallah A., Bouhlel M.S.","A fast JPEG2000 based crypto-compression algorithm: Application to the security for transmission of medical images",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029527775&doi=10.1007%2f978-3-319-62521-8_14&partnerID=40&md5=cff95ace8796267c5a7255eb1b790d5b","Over the past years, the use of telecommunications and information technologies in medicine is evolving. This involves the development of the applications bound to the telemedicine and based on a network medical image transmission. Therefore, the optimization of medical application performances remains a necessity. In this paper, we propose a novel and efficient crypto-compression algorithm. This novel scheme concerning the application of a partial encryption to the JPEG2000 file format. Our algorithm is rapid, efficient, secure and it perfectly preserves the performances of the JPEG2000 compression algorithm. In addition, the proposed transmission scheme is adapted to the Telediagnostic sector and can be easily integrated in JPEG2000 coder. © 2018, Springer International Publishing AG.","Crypto-compression; JPEG2000; Medical images; RSA; Telemedicine; Transmission",,2-s2.0-85029527775
"Jafari S., Bozorg-Haddad O., Chu X.","Cuckoo optimization algorithm (COA)",2018,"Studies in Computational Intelligence",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021638750&doi=10.1007%2f978-981-10-5221-7_5&partnerID=40&md5=7f4820e2a1952061961eb97acbf4b977","The cuckoo optimization algorithm (COA) is used for continuous non-linear optimization. COA is inspired by the life style of a family of birds called cuckoo. These birds’ life style, egg laying features, and breeding are the basis of the development of this optimization algorithm. Like other evolutionary approaches, COA is started by an initial population. There are two types of the population of cuckoos in different societies: mature cuckoos and eggs. The basis of the algorithm is made by the attempt to survive. While competing for being survived, some of them are demised. The survived cuckoos immigrate to better areas and start reproducing and laying eggs. Finally, the survived cuckoos are converged in a way that there is a cuckoo society with the same profit rate. © 2018, Springer Nature Singapore Pte Ltd.",,,2-s2.0-85021638750
"You X., Zhao D., Hu C.","A general iterative algorithm for solving a class of variational inequalities over the common fixed points set of a finite family of nonexpansive mappings in Banach spaces",2018,"Journal of Computational Analysis and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027374950&partnerID=40&md5=53f702b1bade9f172e9bad9393e629fe","In this paper, we introduce a general iterative algorithm for finding a common element of the set of common fixed points of an finite family of nonexpansive mappings and the set of solutions of class of variational inequalities in uniformly convex and q-uniformly smooth Banach space. We prove that the sequence generated by the iterative algorithm converges strongly to the unique solution of the variational inequality under suitable conditions. Our result improves and extends the recent results announced by many others. © 2018 by Eudoxus Press, LLC. All rights reserved.","Banach space; Fixed point; Nonexpansive mapping; Strong convergence; Variational inequality",,2-s2.0-85027374950
"Bala Y., Malik A.","Biometric inspired homomorphic encryption algorithm for secured cloud computing",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031418114&doi=10.1007%2f978-981-10-6747-1_2&partnerID=40&md5=9505842898b316f2203f8a09abf93637","Cloud computing widely uses resource sharing and computing framework over the Internet. Data security is the key objective while sharing data over untrusted environment. This paper presents a novel biometric inspired homomorphic encryption algorithm (BIHEA) for secured data/files transmission over hybrid cloud environment. The proposed algorithm encrypts the user data at run-time by providing the authorized user biometric-feature-based one time password. Every time a user is authenticated by a totally different one time password. The BIHEA provides a good solution to commonly identified theft seen in cloud environment like phishing, shoulder surfing. © 2018, Springer Nature Singapore Pte Ltd.","Biometric; Cloud computing; Homomorphic encryption; One time password","Authentication; Biometrics; Cloud computing; Network function virtualization; Authorized users; Biometric features; Cloud environments; Computing frameworks; Ho-momorphic encryptions; One time passwords; Resource sharing; Shoulder surfing; Cryptography",2-s2.0-85031418114
"Fang B., Wang C.","A 3D reconstruction method based on the combination of the ICP and artificial potential field algorithm",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030836830&doi=10.1007%2f978-981-10-6496-8_45&partnerID=40&md5=eb309318a0b60248df57e19504ade535","For real-time and accurate three-dimensional (3D) reconstruction during autonomous mobile robot navigation, a method based on the combination of iterative closest points (ICP) and artificial potential field algorithm (APF) is proposed. In real-time path planning, the mobile robot uses the artificial potential field method to obtain the environment point-cloud image by Kinect. Then, the combination of the improved ICP method and the initial transformation matrix is applied to complete the 3D reconstruction. The experimental results show that the proposed algorithm is more efficient than normal distributions transform (NDT) and the traditional three-dimensional ICP method. © 2018, Springer Nature Singapore Pte Ltd.","Artificial potential field (APF); Iterative closest points (ICP); Mobile robot; Three-dimensional (3D) reconstruction","Intelligent systems; Iterative methods; Linear transformations; Mobile robots; Motion planning; Normal distribution; Robot programming; Robots; 3D reconstruction; Artificial potential field method; Artificial potential fields; Autonomous Mobile Robot; Iterative closest point; Real time path planning; Three-dimensional (3-D) reconstruction; Transformation matrices; Image reconstruction",2-s2.0-85030836830
"Lu C.-T., Chen Y.-Y., Shen J.-H., Wang L.-L., Lei C.-L.","Improvement of power-spectral-subtraction algorithm using cross-term compensation for speech enhancement",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031407429&doi=10.1007%2f978-981-10-3187-8_55&partnerID=40&md5=65e7d1fc8502e7bea16e3d55f60250b3","Although the power-spectral-subtraction (PSS) algorithm is widely used in speech enhancement, this method suffers from musical residual noise. So the enhanced speech sounds annoying to the human ear. This study proposes using the cross term between the spectrum of speech and noise signals to be additionally subtracted from the power spectrum of noisy speech, enabling background noise to be efficiently removed. Experimental results show that the proposed method can significantly improve the performance of the PSS algorithm by the consideration on the cross term. The quantity of musical residual noise can be efficiently removed, while speech components are well preserved in the enhanced speech. © Springer Nature Singapore Pte Ltd. 2018.","Cross-term; Harmonic adaptation; Power-spectral-subtraction; Speech enhancement","Computation theory; Speech enhancement; Background noise; Cross-terms; Harmonic adaptation; Musical residual noise; Noise signals; Noisy speech; Power spectral; Speech sounds; Speech",2-s2.0-85031407429
"Hung Y.-M., Wang Y.-C.","A general auto-alignment algorithm for three-degree freedom stage by local inverse information with regression method",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026744633&doi=10.1007%2f978-3-319-63856-0_22&partnerID=40&md5=0ef41b373c37e265b51d202bd0084cd4","This paper demonstrated a general algorithm to carry out precision alignment with UVW or XXY and XYθ stages using two cameras without rotation center information. Image processing with template match was implemented to search for fiducial mark under the field of view of a camera as the positioning tool. We established the relationship between cameras and motion stage by calibration procedure with inverse regression method. We finished the substrate’s alignment parallel to the mechanical axis in 2–4 times iterations and applied this algorithm in sixth-generation LCD prober system successfully. © Springer International Publishing AG 2018.","Auto alignment; Precision positioning; UVW axis","Alignment; Cameras; Image processing; Inverse problems; Regression analysis; Signal processing; Auto alignment; Calibration procedure; Inverse regression; Positioning tools; Precision alignment; Precision positioning; Regression method; UVW axis; Multimedia signal processing",2-s2.0-85026744633
"Chowdhury K., Chaudhuri D., Pal A.K.","Seed point selection algorithm in clustering of image data",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032618235&doi=10.1007%2f978-981-10-3376-6_13&partnerID=40&md5=978cca64957ca892951c68c2e852123c","Massive amount of data are being collected in almost all sectors of life due to recent technological advancements. Various data mining tools including clustering is often applied on huge data sets in order to extract hidden and previously unknown information which can be helpful in future decision-making processes. Clustering is an unsupervised technique of data points which is separated into homogeneous groups. Seed point is an important feature of a clustering technique, which is called the core of the cluster and the performance of seed-based clustering technique depends on the choice of initial cluster center. The initial seed point selection is a challenging job due to formation of better cluster partition with rapidly convergence criteria. In the present research we have proposed the seed point selection algorithm applied on image data by taking the RGB features of color image as well as 2D data based on the maximization of Shannon’s entropy with distance restriction criteria. Our seed point selection algorithm converges in a minimum number of steps for the formation of better clusters. We have applied our algorithm in different image data as well as discrete data and the results appear to be satisfactory. Also we have compared the result with other seed selection methods applied through K-Means algorithm for the comparative study of number of iterations and CPU time with the other clustering technique. © Springer Nature Singapore Pte Ltd. 2018.","Clustering; Data mining; K-means; Seed point; Shannon’s entropy",,2-s2.0-85032618235
"Mani M., Bozorg-Haddad O., Chu X.","Ant lion optimizer (ALO) algorithm",2018,"Studies in Computational Intelligence",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021624124&doi=10.1007%2f978-981-10-5221-7_11&partnerID=40&md5=44e4d5529a5bbb39f17119d7b9a76c9e","This chapter introduces the ant lion optimizer (ALO), which mimics the hunting behavior of antlions in the larvae stage. Specifically, this chapter includes literature review, details of the ALO algorithm, and a pseudo-code for its implementation. © 2018, Springer Nature Singapore Pte Ltd.",,,2-s2.0-85021624124
"Wei Q., Song R., Li B., Lin X.","Nonlinear neuro-optimal tracking control via stable iterative Q-learning algorithm",2018,"Studies in Systems, Decision and Control",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028967499&doi=10.1007%2f978-981-10-4080-1_5&partnerID=40&md5=b2083d7f824a46b723d624b7aa484007","This chapter discusses a new policy iteration Q-learning algorithm to solve the infinite horizon optimal tracking problems for a class of discrete-time nonlinear systems. The idea is to use an iterative adaptive dynamic programming (ADP) technique to construct the iterative tracking control law which makes the system state track the desired state trajectory and simultaneously minimizes the iterative Q function. Via system transformation, the optimal tracking problem is transformed into an optimal regulation problem. The policy iteration Q-learning algorithm is then developed to obtain the optimal control law for the regulation system. Initialized by an arbitrary admissible control law, the convergence property is analyzed. It is shown that the iterative Q function is monotonically nonincreasing and converges to the optimal Q function. It is proven that any of the iterative control laws can stabilize the transformed nonlinear system. Two neural networks are used to approximate the iterative Q function and compute the iterative control law, respectively, for facilitating the implementation of policy iteration Q-learning algorithm. Finally, two simulation examples are presented to illustrate the performance of the developed algorithm. © Science Press, Beijing and Springer Nature Singapore Pte Ltd. 2018.",,,2-s2.0-85028967499
"Kosheleva O., Villaverde K.","How to enhance student motivations by borrowing from ancient tradition: Russian peasant multiplication algorithm",2018,"Studies in Computational Intelligence",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032340166&doi=10.1007%2f978-3-662-55993-2_9&partnerID=40&md5=19792024573ca1fde5318f240191700c","In the previous chapter, we showed how to use ideas from ancient Egyptian, Mayan and Babylonian mathematics when teaching math. In this chapter, we consider the use of a more recent computational tradition, namely, of a Russian peasant multiplication algorithm. © Springer-Verlag GmbH Germany 2018.",,,2-s2.0-85032340166
"Santa Chávez J.J., Escobar J.W., Echeverri M.G., Meneses C.A.P.","A heuristic algorithm based on tabu search for vehicle routing problems with backhauls",2018,"Decision Science Letters",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025123130&doi=10.5267%2fj.dsl.2017.6.001&partnerID=40&md5=08da72374e1f3253384d64464c44f30f","In this paper, a heuristic algorithm based on Tabu Search Approach for solving the Vehicle Routing Problem with Backhauls (VRPB) is proposed. The problem considers a set of customers divided in two subsets: Linehaul and Backhaul customers. Each Linehaul customer requires the delivery of a given quantity of product from the depot, whereas a given quantity of product must be picked up from each Backhaul customer and transported to the depot. In the proposed algorithm, each route consists of one sub-route in which only the delivery task is done, and one sub-route in which only the collection process is performed. The search process allows obtaining a correct order to visit all the customers on each sub-route. In addition, the proposed algorithm determines the best connections among the sub-routes in order to obtain a global solution with the minimum traveling cost. The efficiency of the algorithm is evaluated on a set of benchmark instances taken from the literature. The results show that the computing times are greatly reduced with a high quality of solutions. Finally, conclusions and suggestions for future works are presented. © 2018 Growing Science Ltd. All rights reserved.","Backhauling; Combinatorial optimization; Computational simulation; Exact model; Freight transportation; Mathematical modeling; Tabu search; Vehicle routing problem",,2-s2.0-85025123130
"Koprowski R.","Examples of tailoring the algorithm",2018,"Studies in Computational Intelligence",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024109359&doi=10.1007%2f978-3-319-61340-6_5&partnerID=40&md5=a8da283b365c8b6a31c9167790958fc0","Currently, no algorithm is versatile enough to allow for automated and repeatable measurement of all parameters for any images. There are two possible directions of designing applications intended for automated image analysis. The first involves implementation of all known and new methods of image analysis and processing. The second direction involves tailoring applications to measurement automation for a single type of task/analysis. Tailoring an algorithm to a particular application has great advantages such as full automation of measurements of hundreds of thousands of images without operator intervention. They provide quantitative and reproducible diagnostic information. Their drawback is, in addition to the need to tailor them, the possibility of over-fitting of the device and operator to the data. © 2018, Springer International Publishing AG.",,,2-s2.0-85024109359
"Wojciechowski S., Wilk S., Stefanowski J.","An algorithm for selective preprocessing of multi-class imbalanced data",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019201836&doi=10.1007%2f978-3-319-59162-9_25&partnerID=40&md5=e340f66620a4d7e77e2c3339f6529ce7","In this paper we propose a new algorithm called SPIDER3 for selective preprocessing of multi-class imbalanced data sets. While it borrows selected ideas (i.e., combination of relabeling and local resampling) from its predecessor – SPIDER2, it introduces several important extensions. Unlike SPIDER2, it is able to handle directly multi-class problems. Moreover, it considers the relevance of specific decision classes to control the order of their processing. Finally, it uses information about relations between specific classes (modeled with misclassification costs) to better control the extent of changes introduced locally to preprocessed data. We performed a computational experiment on artificial 3-class data sets to evaluate and compare SPIDER3 to SPIDER2 with temporarily aggregated classes and the results confirmed advantages of the new algorithm. © Springer International Publishing AG 2018.",,"Computer programming; Computational experiment; Decision class; Misclassification costs; Multi-class imbalanced datum; Multi-class problems; Pre-processed data; Resampling; Specific class; Computer science",2-s2.0-85019201836
"Cho B., Kim K.J., Kim H.","The isolation algorithm of problem location with multi-agent approach for end-to-end network performance management",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022223730&doi=10.1007%2f978-981-10-5281-1_44&partnerID=40&md5=1c13f0046ff2951e7803b16eef74d870","With the dramatic increase in demands for high-performance network service, practically in advanced scientific research, as well as commercial internet service, the performance of data transfer for the huge amount of scientific experimental data and medical data, genome data is the key element that enables advanced global collaborative research. These activities require a guaranteed end-to-end (ETE) network performance and sophisticated network management framework for the ETE network. This paper suggests an isolation algorithm of problem location with multi-agent approach isolation algorithm of problem location with multi-agent approach ETE network performance management framework with Case-Base Reasoning (CBR) approach and multi-agent approach. It will enable a preliminary and proactive performance management for ETE network. © Springer Science+Business Media Singapore 2018.","Case-based reasoning; Flow monitoring; Multi-agent approach; Network performance","Case based reasoning; Data transfer; Location; Multi agent systems; Network performance; Wireless telecommunication systems; Collaborative research; End-to-end network performance; Flow monitoring; High performance networks; Multi-agent approach; Network management frameworks; Network performance management; Performance management; Software agents",2-s2.0-85022223730
"Castejón-Limas M., Alaiz-Moreton H., Fernández-Robles L., Alfonso-Cendón J., Fernández-Llamas C., Sánchez-González L., Pérez H.","Coupling the PAELLA algorithm to predictive models",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028637900&doi=10.1007%2f978-3-319-67180-2_49&partnerID=40&md5=b6623cf84312f94400bb3eb4993d6cda","This paper explores the benefit of using the PAELLA algorithm in an innovative way. The PAELLA algorithm was originally developed in the context of outlier detection and data cleaning. As a consequence, it is usually seen as a discriminant tool that categorizes observations into two groups: core observations and outliers. A new look at the information contained in its output provides ample opportunity in the context of data driven predictive models. The information contained in the occurrence vector is used through the experiments reported in a quest for finding how to take advantage of that information. The results obtained in each successive experiment guide the researcher to a sensible use case in which this information proves extremely useful: probabilistic sampling regression. © 2018, Springer International Publishing AG.","Outlier detection; Probabilistic sampling","Data handling; Soft computing; Data cleaning; Data driven; Outlier Detection; Predictive models; Probabilistic sampling; Statistics",2-s2.0-85028637900
"Zhao H., Huang J., Liang X., Hua Y.","New algorithm for guidance instrument error separation",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028298358&doi=10.1007%2f978-981-10-4837-1_36&partnerID=40&md5=f83553009b9853b0d94ecef28adab081","Environmental matrix S in the guidance instrument systematic error model is usually seriously ill-conditioned, which has a strong impact on the accuracy of the result of error separation. In this paper, new algorithm for guidance instrument error separation is presented. Based on some numerical iterative method, the new algorithm firstly converts the ill-conditioned algebraic equations to the corresponding stiff dynamic system, and stiff stable numerical method is applied to solve the stiff dynamic system. The convergence of the new method is proved. The method which used to solve the stiff dynamic system is given in the paper. Compared with the PB method (primary Bayesian), the numerical experiments illustrate that the new method is more effective for the Guidance Instrument Error separation. © Tsinghua University Press, Beijing and Springer Nature Singapore Pte Ltd. 2018.","Error separation; Guidance error; Ill-conditioned; Stiff dynamic system","Algebra; Errors; Numerical methods; Separation; Algebraic equations; Environmental matrixes; Error separation; Guidance error; Ill-conditioned; Instrument systematic error; Numerical experiments; Numerical iterative methods; Iterative methods",2-s2.0-85028298358
"Wei Q., Song R., Li B., Lin X.","A new approach for a class of continuous-time chaotic systems optimal control by online ADP algorithm",2018,"Studies in Systems, Decision and Control",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028969898&doi=10.1007%2f978-981-10-4080-1_8&partnerID=40&md5=395b65a970aeb6eaf357597896a3e4d5","In this chapter, an online adaptive dynamic programming (ADP) based optimal control scheme is developed for continuous-time chaotic systems. The idea is to use ADP algorithm to obtain the optimal control input which makes the performance index function reach the optimum. The expression of the performance index function for the chaotic system is first presented. The online ADP algorithm is presented to get the optimal control law. In the ADP structure, the neural networks are used to construct the critic network and action network, which can obtain the approximate performance index function and the control input, respectively. It is proven that the critic parameter error dynamics and the closed-loop chaotic systems are uniformly ultimately bounded exponentially. Simulation results are given to illustrate the performance of the established optimal control method. © Science Press, Beijing and Springer Nature Singapore Pte Ltd. 2018.",,,2-s2.0-85028969898
"Ömür C., Uygur A.B., Horuz İ., Işık H.G., Ayan S., Konar M.","Incorporation of manufacturing constraints into an algorithm for the determination of maximum heat transport capacity of extruded axially grooved heat pipes",2018,"International Journal of Thermal Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030767407&doi=10.1016%2fj.ijthermalsci.2017.09.016&partnerID=40&md5=7cd2edc9418e6dbaf378db5e88319a73","In this study, an algorithm is proposed which takes into account the manufacturing (EDM and extrusion) constraints as well as container design, temperature drop criterion between the evaporator and condenser together the with the vapor and liquid pressure losses for axially grooved heat pipes. The algorithm was executed for rectangular, triangular, trapezoidal and reentrant grooved heat pipes for a fixed outer diameter with and without manufacturing constraints. It was seen that for all groove types, the maximum heat transport capacity was found to be higher for the case in which manufacturing constraints are neglected. Results also show that for trapezoidal and reentrant grooves, the width and depth combinations yielding the maximum heat transport cannot be actually manufactured. On the other hand, the maximum heat transport occurs in the range where the heat pipe can actually be manufactured for rectangular and triangular grooves. © 2017 Elsevier Masson SAS","Electro discharge machining (EDM); Extrusion; Grooved heat pipe; Manufacturing constraints; Maximum heat transport",,2-s2.0-85030767407
"Karoum B., Elbenani B., El Khattabi N., El Imrani A.A.","Manufacturing Cell formation problem using hybrid cuckoo search algorithm",2018,"Operations Research/ Computer Science Interfaces Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032627281&doi=10.1007%2f978-3-319-58253-5_10&partnerID=40&md5=05b354664fb878eeea7c261ae75222f2","Cellular manufacturing, as one of the most important applications of Group Technology, has gained popularity in both academic research and industrial applications. The cell formation problem is considered the first and the foremost issue faced in the designing of cellular manufacturing systems that attempts to minimize the inter-cell movement of the products while maximize the machines utilization. This paper presents an adapted optimization algorithm entitled the cuckoo search algorithm for solving this kind of problems. The proposed method is tested on different benchmark problems; the obtained results are then compared to others available in the literature. The comparison result reveals that on 31 out of 35 problems (88.57%) the results of the introduced method are among the best results. © Springer International Publishing AG 2018.","Cell formation problem; Cellular manufacturing; Cuckoo search; Lévy flight; Metaheuristic",,2-s2.0-85032627281
"Sayed G.I., Hassanien A.E., Shaalan M.I.","Particle swarm optimization and k-means algorithm for chromosomes extraction from metaphase images",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029495078&doi=10.1007%2f978-3-319-64861-3_31&partnerID=40&md5=dafca1821b5f8cd903dfb1fe60c7d1a7","This paper presents a novel approach based on hybrid particle swarm optimization and K-Means algorithm. The proposed approach is to remove residual stains and interphase cells from metaphase chromosome images to focus only on the chromosomes. Interphase cells can highly interrupt the automatic karyotyping. Karyotyping is the process that geneticist used for identifying chromosomal abnormalities to diagnose genetic diseases. The proposed approach comprised of three fundamental phases: (1) Preprocessing, (2) Image clustering based on hybrid particle swarm optimization and K-Means algorithm and (3) Interphase cells removal and chromosomes extraction phase. 40 chromosomal images from albino rat bone marrow are used in this experiment. The experimental results showed the efficiency of the proposed segmentation approach. It achieved overall almost 95% segmentation accuracy. Moreover, it compared with well-known approaches and gives better results. © 2018, Springer International Publishing AG.","Chromosome image; Genetic diseases; Interphase cells; K-Means; Karyotype; Particle swarm optimization",,2-s2.0-85029495078
"Drabowski M., Kiełkowicz K.","A Hybrid Genetic Algorithm for Hardware–Software Synthesis of Heterogeneous Parallel Embedded Systems",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029537778&doi=10.1007%2f978-3-319-67229-8_30&partnerID=40&md5=018b22a0e25df1d538e34e2e998d497c","The paper includes a proposal of a new algorithm for hardware–software synthesis of heterogeneous parallel embedded systems. Optimal scheduling of tasks, optimal partition of resources and allocation tasks and resources are fundamental problems in this algorithm. In the former synthesis methods, software and hardware parts have been developed separately and then connected in the process of so-called concurrent synthesis. The objective of this research is to present the concept of coherent approach to the problem of system synthesis, i.e. a combined solution to task scheduling and resource partition problems. The approach is new and original and allowing synergic design of hardware and also software controlling the performance of a computer system. This is an approach which we call a coherent parallel synthesis. This paper shows the algorithm, based on genetic method assisted with simulated annealing strategy and shows the results of selected representative computational experiments into different instances of system synthesis problems which prove the correctness of the coherent synthesis concept and indicate methods solving these problems. © 2018, Springer International Publishing AG.","Allocation; Boltzmann tournament; Genetic; Optimization; Partition; Scheduling; Simulated annealing; Synergic; Synthesis",,2-s2.0-85029537778
"Diaz M.A., Gibbons M.W., Song J., Hillstrom H.J., Choe K.H., Pasquale M.R.","Concurrent validity of an automated algorithm for computing the center of pressure excursion index (CPEI)",2018,"Gait and Posture",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030117619&doi=10.1016%2fj.gaitpost.2017.09.022&partnerID=40&md5=0e545e98f84bff2d889a0311d63655ee","Center of Pressure Excursion Index (CPEI), a parameter computed from the distribution of plantar pressures during stance phase of barefoot walking, has been used to assess dynamic foot function. The original custom program developed to calculate CPEI required the oversight of a user who could manually correct for certain exceptions to the computational rules. A new fully automatic program has been developed to calculate CPEI with an algorithm that accounts for these exceptions. The purpose of this paper is to compare resulting CPEI values computed by these two programs on plantar pressure data from both asymptomatic and pathologic subjects. If comparable, the new program offers significant benefits—reduced potential for variability due to rater discretion and faster CPEI calculation. CPEI values were calculated from barefoot plantar pressure distributions during comfortable paced walking on 61 healthy asymptomatic adults, 19 diabetic adults with moderate hallux valgus, and 13 adults with mild hallux valgus. Right foot data for each subject was analyzed with linear regression and a Bland-Altman plot. The automated algorithm yielded CPEI values that were linearly related to the original program (R2 = 0.99; P &lt; 0.001). Bland-Altman analysis demonstrated a difference of 0.55% between CPEI computation methods. Results of this analysis suggest that the new automated algorithm may be used to calculate CPEI on both healthy and pathologic feet. © 2017 Elsevier B.V.","Center of pressure excursion index; CPEI; Foot function; Gait analysis; Plantar pressures",,2-s2.0-85030117619
"Zhongming X., Qinghua W., Yansong H., Zhifei Z., Shu L., Mengran L.","A monotonic two-step iterative shrinkage/thresholding algorithm for sound source identification based on equivalent source method",2018,"Applied Acoustics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028594898&doi=10.1016%2fj.apacoust.2017.07.012&partnerID=40&md5=36f38cca3605adfe125ae7e865fd33c4","Near-field acoustical holography (NAH) based on equivalent source method (ESM) is an efficient technique applied for sound source identification. However, the conventional ESM with ℓ2 norm regularization cannot produce a satisfactory solution in high frequency, where the average array inter-element spacing is larger than half a wavelength. Therefore, conventional ESM with Tikhonov regularization is restricted to relatively low frequency. To overcome the issue, an alternative method called monotonic two-step iterative shrinkage/thresholding algorithm for near-field acoustical holography is proposed. In the algorithm, another existing algorithm called Wideband Acoustical Holography (WBH) is used to generate the threshold, and also be used as a benchmark for comparison. Simulated measurements based on an irregular microphone array are performed to compare the performances of the Tikhonov regularization, WBH and MTwIST. The results suggested that the proposed method can identify the sound sources more accurately than Tikhonov regularization in full frequency range, and it performs better than WBH in the case of identifying coherent sources at relatively low frequency. The experiments demonstrated the validity and the practicability of the proposed method. © 2017 Elsevier Ltd","Acoustical holography; Equivalent source method; Inverse problem; Sound source identification","Acoustic generators; Acoustic holography; Acoustic variables measurement; Acoustics; Holography; Inverse problems; Shrinkage; Acoustical holography; Equivalent source method; Inter-element spacing; Near-field acoustical holography; Satisfactory solutions; Sound source identification; Tikhonov regularization; Two-step iterative shrinkages; Iterative methods",2-s2.0-85028594898
"Maes K., Gillijns S., Lombaert G.","A smoothing algorithm for joint input-state estimation in structural dynamics",2018,"Mechanical Systems and Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022194595&doi=10.1016%2fj.ymssp.2017.04.047&partnerID=40&md5=c9bfd15b3d8fb477b0bbdb31acdd399f","This paper presents a recursive algorithm where a time delay is considered in the estimation of the forces applied to a structure and the corresponding system states. In particular when the measured response is not collocated with the estimated forces, essential information on the estimated forces and/or system states is contained in the response at L consecutive time steps following the time step where the estimation is performed. The main focus in this paper is on the reduction in estimation uncertainty that can be achieved by so-called smoothing, i.e. by considering a time delay in the estimation. When the calculation of the gain matrices is included in the recursive estimation, the calculation time of the algorithm largely increases with the time delay. It is shown that a prior calculation of the steady-state gain matrices allows for a significant reduction of the calculation time. The presented algorithm is first verified using numerical simulations. Next, a validation is performed using data obtained from a field test on a footbridge. © 2017 Elsevier Ltd","Data fusion; Force identification; Joint input-state estimation; Response estimation; Smoothing; Time delay",,2-s2.0-85022194595
"Panahandeh G., Åkerblom N.","Clustering driving destinations using a modified DBSCAN algorithm with locally-defined map-based thresholds",2018,"Computational Methods in Applied Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021846168&doi=10.1007%2f978-3-319-54490-8_7&partnerID=40&md5=a3bd2bc1bc10afaaa6d887c0d0607515","The aim of this paper is to propose a method to cluster GPS data corresponding to driving destinations. A new DBSCAN-based algorithm is proposed to group stationary GPS traces, collected prior to end of trips, into destination clusters. While the original DBSCAN clustering algorithm uses a global threshold as a closeness measure in data space, we develop a method to set local thresholds values for data points; this is important because the GPS data proximity strongly depends on the density of the street grid around each point. Specifically, the spread of GPS coordinates in parking lots can vary substantially between narrow (personal parking lot) and wide (parking lot of a shopping mall) depending on the destinations. To characterize the parking lot diversities at each destination, we introduce the concept of using a local threshold value for each data point. The local threshold values are inferred from road graph density using a map database. Moreover, we propose a mutual reachability constraint to preserve the insensitivity of DBSCAN with respect to the ordering of the points. The performance of the proposed clustering algorithm has been evaluated extensively using trips of actual cars in Sweden, and some of the results are presented here. © 2018, Springer International Publishing AG.",,,2-s2.0-85021846168
"Wei Q., Song R., Li B., Lin X.","Multiobjective optimal control for a class of unknown nonlinear systems based on finite-approximation-error ADP algorithm",2018,"Studies in Systems, Decision and Control",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028991896&doi=10.1007%2f978-981-10-4080-1_7&partnerID=40&md5=164c25072f9ba289645032c0bc3e03d3","In this chapter, an optimal control method for a class of unknown discrete-time nonlinear systems with general multiobjective performance index function is developed. In the design of the optimal controller, only available input–output data are required instead of knowing system dynamics, and the data-based identifier is established with stability proof. By the weighted sum technology, the multiobjective optimal control problem is transformed into the single objective optimization. To obtain the solution of the HJB equation, a novel finite-approximation-error adaptive dynamic programming (ADP) algorithm is presented with convergence proof. The detailed theoretic analyses for the relationship of the approximation accuracy and the algorithm convergence are given. It is shown that, as convergence conditions are satisfied, the iterative value functions can converge to a finite neighborhood of the greatest lower bound of all performance index functions. Neural networks are used to approximate the performance index function and compute the optimal control law, respectively, for facilitating the implementation of the iterative ADP algorithm. Finally, two simulation examples are given to illustrate the performance of the present method. © Science Press, Beijing and Springer Nature Singapore Pte Ltd. 2018.",,,2-s2.0-85028991896
"Tian S., Li S., Zhang Z.","Research on cable fault location algorithm based on improved HHT",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031418305&doi=10.1007%2f978-981-10-6499-9_8&partnerID=40&md5=29307028558354a057c778e0434a273d","The accurate calibration of the fault traveling wave head is the key to realize the cable fault traveling wave ranging. Modal aliasing will appear when the traveling wave ranging method based on HHT carries on empirical mode decomposition, so that the ranging accuracy is low. In order to solve this problem, an improved HHT algorithm based on ensemble empirical mode decomposition (EEMD) is put forward. At first, the EEMD algorithm is used to extract the inherent modal function of the fault traveling wave head. Secondly, the instantaneous frequency is calculated by the Hilbert transform. Thirdly, the traveling wave head is accurately calibrated by the abrupt change point of the instantaneous frequency. Then use the double-terminal fault ranging algorithm to achieve more accurate fault location. Finally, the 10 kV distribution network model based on the cable line is built in PSCAD/EMTDC software. A large number of simulation results show that the proposed method is feasible, and it is more precise than traditional methods. © 2018, Springer Nature Singapore Pte Ltd.","Band aliasing; Ensemble empirical mode decomposition (EEMD); PSCAD software simulation; Traveling-wave fault location","Cables; Calibration; Computer software; Intelligent systems; Mathematical transformations; Aliasing; Cable fault locations; Empirical Mode Decomposition; Ensemble empirical mode decompositions (EEMD); Hilbert transform; Instantaneous frequency; Software simulation; Traveling wave fault locations; Location",2-s2.0-85031418305
"Slavov S.","An algorithm for generating optimal toolpaths for CNC based ball-burnishing process of planar surfaces",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031296205&doi=10.1007%2f978-3-319-68324-9_40&partnerID=40&md5=87561289e83a46f7ea2ede0794c15f47","This paper presents an algorithm for generating optimal toolpaths for CNC based ball-burnishing process of planar workpieces having burnished areas with rectangular or circular shape. The proposed algorithm firstly calculates the 2D coordinates of the points from a polyline, which describes the needed complex toolpath of the ball-tool to obtain a regular shaped roughness on burnished areas. Then Boolean constraints conditions are used to restrict the generated sub-toolpaths only within ball-burnishing area of the workpiece. Finally, all trajectories are connected in one single continuous curve (i.e. polyline in DXF file format) which represents the optimal toolpath, depending on the shape and the dimensions of the burnishing area. The obtained toolpath from proposed generation strategy most resembles the toolpath, obtained from the classical setup for planar vibrations-assisted ball-burnishing method, using milling machines without CNC control. The purposed algorithm has comparatively simple implementation, minimizes the blank movements of the ball tool, and provides high accuracy of the burnished planar surfaces. © 2018, Springer International Publishing AG.","Ball-burnishing process; CAD-CAM; CNC; Generation; Manufacturing; Milling machines; Toolpath","Burnishing; Computer aided design; Manufacture; Milling (machining); Milling machines; 2D coordinates; Ball burnishing; Boolean constraint; Circular shape; Generation; Planar surface; Planar vibration; Toolpaths; Ball milling",2-s2.0-85031296205
"Muniyasamy K., Srinivasan S., Parthasarathy S., Subathra B., Dzitac S.","Epidemic algorithm based optimal power flow in electric grids",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029515343&doi=10.1007%2f978-3-319-62521-8_6&partnerID=40&md5=355482a640a575a56baf2e4efebc1849","Time-triggering and distributed nature of the grid are emerging as the major challenge in managing energy in distribution grids. This investigation presents an event triggered distributed optimal power flow (OPF) algorithm for energy grids. To generate the event triggers, we use the epidemic algorithm. The buses are classified into three: infected, susceptible, and dead. The network works in two modes: normal and optimization mode. In the normal mode, only event detection happens and when there are no event triggers, the system is said to be in normal mode. In optimization mode, event triggers that can be a change in generation or demand beyond a threshold value that necessitates the re-optimization of the network, the optimization mode begins. In this mode, the infected node which is infected by change in bus variable intimates it to the energy management application. The energy management application on sensing this change, will initiate the graph grammars which are a set of rules to change the bus nature by detecting the effect of the change on the particular bus. The network is re-optimized using a DC OPF formulation as it is convex and can be solved using simple matrix inversion on the stationary conditions. As a result, the solution of DCOPF problem becomes that of solving a system of linear equations of the form $$Ax=b$$, which is solved using Krylov’s method or the Arnoldi algorithm in a distributed fashion. Each node solves the problem of its one-hop neighbours in parallel and this leads to a distributed implementation resulting significant reduction in complexity. The propossed approach is illustrated on a simple 3 bus network. © 2018, Springer International Publishing AG.",,,2-s2.0-85029515343
"Khorsandi A., Liu X.-C., Cao B.-Y.","A new algorithm to shortest path problem with fuzzy arc lengths",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030781006&doi=10.1007%2f978-3-319-66514-6_25&partnerID=40&md5=2b0cc383a45a3c65244339a158cdad4d","Network flow problem is prevalent in engineering and management. In real life the parameters between nodes are not certain. Many authors try to proposed the solution method in different types of this problem. This paper proposes the simple method to compute the fuzzy shortest path (fuzzy shortest distance) between source node and destination node in network flow problem. This algorithm only considered the nodes that need to reach destination node and doesn’t involve all nodes, so it has expended less time. The goal is to reach destination node and find the shortest path, so it’s not important which nodes will be past through. © Springer International Publishing AG 2018.","Fuzzy shortest path; Ranking function; Trapezoidal fuzzy numbers","Fuzzy sets; Destination nodes; Network flow problems; Ranking functions; Shortest path; Shortest path problem; SIMPLE method; Solution methods; Trapezoidal fuzzy numbers; Graph theory",2-s2.0-85030781006
"Yaeger D., Bubeck C.","Efficient language model generation algorithm for mobile voice commands",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026267170&doi=10.1007%2f978-3-319-60011-6_11&partnerID=40&md5=7f633533212ff4b36afbcdc6aba14535","The Single Multimodal Android Service for HCI (SMASH) framework implements an automated language data generation algorithm to support high-accuracy, efficient, always-listening voice command recognition using the Carnegie Mellon University (CMU) PocketSphinx n-gram speech recognizer. SMASH injects additional language data into the language model generation process to augment the orthographies extracted from the input voice command grammar. This additional data allows for a larger variety of potential outcomes, and greater phonetic distance between outcomes, within the generated language model, resulting in more consistent probability scores for in-grammar utterances, and fewer false positives from out-of-grammar (OOG) utterances. © Springer International Publishing AG 2018.","ASR; Automatic speech recognition; HCI; Human computer interaction; Mobile computing","Computational linguistics; Human computer interaction; Human engineering; Mobile computing; Systems engineering; Additional datum; Automatic speech recognition; Carnegie Mellon University; Data generation; Language model; Potential outcomes; Speech recognizer; Voice command recognition; Speech recognition",2-s2.0-85026267170
"Xu G., Sun Z., Yan C., Gan Y.","A rapid detection algorithm of corrupted data in cloud storage",2018,"Journal of Parallel and Distributed Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028894452&doi=10.1016%2fj.jpdc.2017.08.004&partnerID=40&md5=03f2040aac74832ecd7fbaf02cd55999","The cloud computing provides dynamically scalable and virtualized resource service for users to access the storage data. Although having been bringing enormous convenience, it also incurs the threat of users’ data loss or corruption, such as data intentionally deleted or corrupted, the service providers’ hardware error and careless operation. Most of the data verification schemes based POR or PDP are proposed to verify the integrity of a data block or even a batch of data blocks. However, once the batch verification fails, it results in that all the blocks in the batch of data cannot be judged to be intact or corrupted since the corrupted blocks are not accurately identified. To improve the efficiency of corrupted data identified, we propose a rapid detection algorithm of corrupted data based on three-dimensional data locating, which is called cube-based detection. Furthermore, the consistent hash is utilized to balance the computation cost, and the cube splitting is applied to locate the corrupted blocks by narrowing the range of suspicious blocks step by step. Finally, both data hierarchically concatenated and data blind technology are utilized to improve the verification efficiency and preserve users’ data privacy in the detection process. Theoretic analysis and simulation results demonstrate that our algorithm has strong detection capability and identification capability for all the corrupted blocks, and greatly decreases the cost of verification data transmission and computation. © 2017 Elsevier Inc.","Cloud storage; Corrupted data detecting; Cube-based hierarchical verification; Data integrity verification","Cost benefit analysis; Data privacy; Efficiency; Geometry; Signal detection; Batch verification; Cloud storages; Corrupted data; Data integrity; Detection capability; Hierarchical verification; Three-dimensional data; Virtualized resources; Digital storage",2-s2.0-85028894452
"Douik A., Aly S.A., Al-Naffouri T.Y., Alouini M.-S.","Cardinality estimation algorithm in large-scale anonymous wireless sensor networks",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029476969&doi=10.1007%2f978-3-319-64861-3_53&partnerID=40&md5=99fb8abb365f47718ced18a6799bc5e1","Consider a large-scale anonymous wireless sensor network with unknown cardinality. In such graphs, each node has no information about the network topology and only possesses a unique identifier. This paper introduces a novel distributed algorithm for cardinality estimation and topology discovery, i.e., estimating the number of node and structure of the graph, by querying a small number of nodes and performing statistical inference methods. While the cardinality estimation allows the design of more efficient coding schemes for the network, the topology discovery provides a reliable way for routing packets. The proposed algorithm is shown to produce a cardinality estimate proportional to the best linear unbiased estimator for dense graphs and specific running times. Simulation results attest the theoretical results and reveal that, for a reasonable running time, querying a small group of nodes is sufficient to perform an estimation of $$95\%$$ of the whole network. Applications of this work include estimating the number of Internet of Things (IoT) sensor devices, online social users, active protein cells, etc. © 2018, Springer International Publishing AG.","Anonymous networks; BigData; Cardinality estimation; IoT; Sensor networks",,2-s2.0-85029476969
"Domínguez J.S., Hoff G., de Assis J.T.","Using the FDK algorithm to reconstruct low contrast images generated by Monte Carlo, simulation of sediment imaging",2018,"Lecture Notes in Computational Vision and Biomechanics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032360797&doi=10.1007%2f978-3-319-68195-5_34&partnerID=40&md5=f25e902bb0d43f0bd3f6a89a4c6d82db","In geology field, the experimental or computational simulation of the sediment deposition process is widely used to characterize regions and possible findings. Noninvasive methods are the best way to evaluate sediments; in order of not to destroy the information of the sediment deposition structure. The use of computed tomography (CT) techniques to get images of sediments will be evaluated. A CT will be analyzed has a two stage process, the scan of body test to produce a set of X-ray images and the reconstruction step where the set of X-ray images is processed by computational algorithm to generate cross-sectional images of the scanned object. To test the method the X-ray images are generated using the Monte Carlo method with a XRMC tool, and the simulated images are 3D reconstructed using the Feldkamp, David e Kress algorithm. The reconstruction planes and the volume generated in the simulation showed very similar after a visual comparison for all of tested volumes. However a statistical analysis showed that there was no statistical coincidence of the simulated dimensions and reconstruction. The results presented showed the possibility to use CT to study the sediments in tanks or rivers. © 2018, Springer International Publishing AG.",,,2-s2.0-85032360797
"Naveen Naik S., Malarkodi B.","An experimental setup of DSA algorithm suitable for high bandwidth data transfer using USRP and GNU radio companion",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030160477&doi=10.1007%2f978-3-319-67934-1_8&partnerID=40&md5=e8a699e38aa68948c2db96f3630d69fc","In this paper we present the experimental implementation of dynamic spectrum access (DSA) algorithm using universal software radio peripheral (USRP) and GNU Radio. The setup contains two primary users and two cognitive radios or secondary users. One primary user is fixed and the other is allowed to change its position randomly. Depending upon the position of the primary user the cognitive user will use the spectrum band where the detected energy is below certain predefined threshold level. The cognitive radio users are also programmed to operate independently without interfering with each other using energy detection algorithm for spectrum sensing. The modulation scheme is set to GMSK for secondary user performing data transmission. This experimental setup is used to analyze the quality of video transmission using DSA which provides the insight regarding the possibility of using free spectrum space to improve the performance of the system and its advantage over a non-DSA system. From the experiment it is shown that under congestion and interference DSA perform better than a non- DSA system. © Springer International Publishing AG 2018.","Cognitive radio; Dynamic spectrum access; Energy detection; GNU radio; IEEE 802.22; USRP","Cryptography; Data transfer; Image communication systems; Open source software; Radio communication; Radio systems; Signal processing; Software radio; Spectroscopy; Dynamic spectrum access; Energy detection; GNU radio; IEEE 802.22; USRP; Cognitive radio",2-s2.0-85030160477
"Faybusovich L.","Primal-dual potential reduction algorithm for symmetric programming problems with nonlinear objective functions",2018,"Linear Algebra and Its Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030089978&doi=10.1016%2fj.laa.2017.09.017&partnerID=40&md5=ad3bd19dd26a50ed5e49b7270f9c99bb","We consider a primal-dual potential reduction algorithm for nonlinear convex optimization problems over symmetric cones. The same complexity estimates as in the case of the linear objective function are obtained provided a certain nonlinear system of equations can be solved with a given accuracy. This generalizes the result of K. Kortanek, F. Potra and Y. Ye [7]. We further introduce a generalized Nesterov–Todd direction and show how it can be used to achieve a required accuracy (by solving the linearization of above mentioned nonlinear system) for a class of nonlinear convex functions satisfying scaling Lipschitz condition. This result is a far-reaching generalization of results of F. Potra, Y. Ye and J. Zhu [8], [9]. Finally, we show that a class of functions (which contains quantum entropy function) satisfies scaling Lipschitz condition. © 2017 Elsevier Inc.","Convex objective functions; Optimization over symmetric cones; Quantum entropy","Convex optimization; Entropy; Functions; Nonlinear systems; Optimization; Quantum theory; Convex objectives; Convex optimization problems; Linear objective functions; Lipschitz conditions; Nonlinear objective functions; Nonlinear system of equations; Quantum entropy; Symmetric cone; Nonlinear equations",2-s2.0-85030089978
"Feng X., Liu P., Jia K.","Fast intra mode decision algorithm for 3D-HEVC transcoding",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026649752&doi=10.1007%2f978-3-319-63859-1_8&partnerID=40&md5=02d9294fa8d2c61728e65c5563753688","To satisfy the popularity of 3D application, 3D-HEVC has been developed as a new video encoding standard for multiviews. What’s more, as the development of internet and mobile services, the use of 3D video application from the big screen to mobile devices become an inevitable trend. So an efficient transcoding for 3D videos is necessary. In 3D-HEVC, 3D video is comprised by multiview video and corresponding depth maps. The computational complexity is further increased caused by depth maps. In order to reduce the computational complexity caused by the mode decision for depth maps, an efficient fast intra mode decision for 3D-HEVC depth maps down-sizing video transcoding based on SVM (support vector machines, SVM) is proposed in this paper. Compared with the HTM16.0 which employs the original intra mode decision, the proposed algorithm can save about 16% of transcoding time without distortion of synthesized intermediate views. © Springer International Publishing AG 2018.","3D-HEVC; Depth Modeling Mode (DMM); Down-sizing; SVM; Transcoding","Computational complexity; Multimedia signal processing; Signal processing; Support vector machines; 3D-HEVC; Depth models; Down-sizing; Fast intra mode decisions; Inevitable trends; Intra mode decision; Transcoding; Video-transcoding; Three dimensional computer graphics",2-s2.0-85026649752
"Murinová P., Burda M., Pavliska V.","An algorithm for intermediate quantifiers and the graded square of opposition towards linguistic description of data",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029444687&doi=10.1007%2f978-3-319-66824-6_52&partnerID=40&md5=169f16313e6b04a604c3e50ceff333d8","The aim of this paper is to apply main theories of fuzzy natural logic together with fuzzy GUHA method for a linguistic characterization of relationships in data. Namely, we utilize the theory of intermediate quantifiers, which provides mathematical interpretation of natural language expressions describing quantity such as “Almost all”, “Few” etc., to describe relationships in data using vague terms that are natural in human expression. We provide an algorithm for computation of truth degrees of expressions containing such quantifiers. Moreover, we discuss some basic properties of intermediate quantifiers (contraries, contradictories, sub-contraries and sub-alterns), which formulate the graded Peterson’s square of opposition, and which can be used to infer new expressions from existing ones. © 2018, Springer International Publishing AG.","Fuzzy GUHA; Fuzzy natural logic; Generalized square of opposition; Intermediate quantifiers; Linguistic associations mining","Computation theory; Computer circuits; Fuzzy sets; Linguistics; Pattern matching; Fuzzy GUHA; Intermediate quantifiers; Linguistic associations; Natural logic; Square-of-opposition; Fuzzy logic",2-s2.0-85029444687
"Nishimura R., Sakamoto S., Suzuki Y.","A wind noise detection algorithm for monitoring infrasound using smartphone as a sensor device",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026639233&doi=10.1007%2f978-3-319-63859-1_19&partnerID=40&md5=4d05a7ade86fcdce107ee30a1603d401","Infrasound monitoring is promising for early warning systems to mitigate damage of disaster. However, wind noise contains the same frequency components as infrasound does, and they need to be separated. To achieve this purpose, a wind noise detection algorithm is proposed. Unlike conventional methods that typically use two microphones, the proposed method assumes that one pressure and one acoustic sensor is available. This assumption comes from a requirement that a smartphone is used as a sensor device. Wind noise is detected as anomaly detection of the microphone signal, using extreme value distribution. Comparing with the data obtained by an anemometer, it is shown that the proposed method successfully determines time periods where wind noise exists under a practical environment, depending on the condition of wind. © Springer International Publishing AG 2018.",,"Microphones; Signal detection; Signal processing; Smartphones; Acoustic Sensors; Anomaly detection; Conventional methods; Early Warning System; Extreme value distributions; Frequency components; Infrasound monitoring; Microphone signals; Multimedia signal processing",2-s2.0-85026639233
"Watada J., Zhang H., Melo H., Wang J., Vasant P.","SURF algorithm-based panoramic image mosaic application",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026725131&doi=10.1007%2f978-3-319-63856-0_43&partnerID=40&md5=f0183426e0a728260efff6d1f7a638ae","Panoramic image mosaic is a technology to match a series of images which are overlapped with each other. Panoramic image mosaics can be used for different applications. Image mosaic has important values in various applications such as computer vision, remote sensing image processing, medical image analysis and computer graphics. Image mosaics also can be used in moving object detection with a dynamic camera. After getting the panoramic background of the video for detection, we can compare every frame in the video with the panoramic background, and finally detect the moving object. To build the image mosaic, SURF (Speeded Up Robust Feature) algorithm is used in feature detection and OpenCV is used in the programming. Because of special optimization in image fusion, the result becomes stable and smooth. © Springer International Publishing AG 2018.","Feature point; Panorama; Stitching; SURF; Video frame","Computer graphics; Image fusion; Image processing; Image reconstruction; Medical imaging; Object detection; Optimization; Remote sensing; Signal processing; Stitching (metal joining); Feature detection; Feature point; Moving-object detection; Panorama; Remote sensing image processing; Speeded up robust features; SURF; Video frame; Multimedia signal processing",2-s2.0-85026725131
"Zaslavskyi V., Pasichna M.","Type variety principle and the algorithm of strategic planning of diversified portfolio of electricity generation sources",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020786663&doi=10.1007%2f978-3-319-59415-6_45&partnerID=40&md5=e6d9300be28e02670c6c989d229e8992","The article provides an approach for the electricity generation companies and their electricity generation portfolios (mix), mainly focusing on the European Union (EU). The model, looking at the management and optimization to structure the electricity generation portfolio for electricity providers, is aimed at defining a system to mix different electricity generation technologies, to maximize the value of the portfolio e.g. ensure energy security and minimize its environmental footprint. Given the limitations of resources and unstable energy market, this would help to understand to what degree electricity generating companies are able to achieve their goals and also how external regulators could achieve their goals. Type variety principle lies at the basis of a developed algorithm. © Springer International Publishing AG 2018.","Energy portfolio; Energy security; Optimization; Risk management","Energy security; Environmental technology; Optimization; Risk management; Structural optimization; Electricity generation; Electricity-generation technology; Energy markets; Energy portfolio; Environmental footprints; European union; Generating companies; Electric power generation",2-s2.0-85020786663
"Jardzioch A., Skobiej B.","Job scheduling problem in a flow shop system with simulated hardening algorithm",2018,"Lecture Notes in Mechanical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032670692&doi=10.1007%2f978-3-319-68619-6_10&partnerID=40&md5=f6c082756c798da136b8a1e420da623b","A solution to the problem of job scheduling in a flow shop system is proposed in this paper. A three-machine flow shop system is presented with 10 sets of 10 random jobs to be processed. A new approach, called Simulated Hardening (SH), is used to schedule the jobs by taking into consideration two criteria: minimal makespan and maximal profit. The results obtained are compared with First In First Out (FIFO), Earliest Due Date (EDD), Shortest Processing Time (SPT), Longest Processing Time (LPT), Time Reserve (TR), and Descending Delay Penalty (DDP) sorting methods and confronted with the results of exhaustive search. The usefulness of the new SH algorithm is estimated in terms of the quality of the results obtained. © Springer International Publishing AG 2018.","Flow shop; Makespan; Profit; Scheduling; Simulated hardening",,2-s2.0-85032670692
"Pan Z., Yao H., Zhang H.","Research on data storage algorithm based on metallurgy control system",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028370422&doi=10.1007%2f978-3-319-60744-3_52&partnerID=40&md5=839819c93be8b9ecb952334c5b9f0b48","In the traditional method, the data structure of the embedded system is optimized by using K-L method. With the increase of the high load of the metallurgical control data, the cost of data storage is high, and the metallurgical control performance is not good. In order to improve control property and storage property of an embedded metallurgy system, this paper raises a kind of data structure optimum storage algorithm based on an embedded metallurgy system of optimum basic function adaptive matching on metallurgy control system data storage. It’s proved by the stimulation outcome that it efficiently reduces data storage expense and enlarges data storage space by using method raised in this paper, which further improves control ability and storage ability of data interaction in the embedded metallurgy system. © 2018, Springer International Publishing AG.","Data storage; Embedded system; Metallurgy control","Adaptive control systems; Control systems; Data storage equipment; Data structures; Embedded systems; Intelligent systems; Metallurgy; Metals; Real time systems; Structural optimization; Adaptive matching; Basic functions; Control properties; Data interactions; Data storage; Metallurgical control; Storage abilities; Storage properties; Digital storage",2-s2.0-85028370422
"Syu J.-L., Li H.-T., Chiang J.-S., Hsia C.-H., Wu P.-H., Hsieh C.-F.","An assisted forklift pallet detection with adaptive structure feature algorithm for automated storage and retrieval systems",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031401657&doi=10.1007%2f978-981-10-3187-8_26&partnerID=40&md5=3e2f8bbb85f5632db74b43c08b426172","This paper is about automatically guided vehicle (AGV) system in the automated-storage-and-retrieval-system (ASRS). In ASRS, it usually uses AGV system to transport materials, because it not only efficient but can cost down logistic cost. However, the major problem of the application about AGV is how to find the position of the pallets due to the difficulties to locating the pallet position on a complicated factory environment. In this work, Haar like-based Adaboost scheme with adaptive structure feature of pallets algorithm to detect pallets is presented, and by combining direction weighted overlapping (DWO) ratio, it can avoid those non-optimal candidates in object tracking. The experimental result shows this method can remove most of the non-stationary background and can increase the average pallet detection rate by 95%. © Springer Nature Singapore Pte Ltd. 2018.","Adaboost; Automated storage and retrieval systems; Forklift; Industry 4.0; Pallet detection","Adaptive boosting; Automation; Computation theory; Computer control systems; Feature extraction; Information retrieval; Materials handling equipment; Pallets; Storage (materials); Transportation; Adaptive structure; Automated storage and retrieval system; Automatically guided vehicles; Detection rates; Forklift; Non-stationary backgrounds; Object Tracking; Transport materials; Automatic guided vehicles",2-s2.0-85031401657
"Jayanth J., Ashok Kumar T., Koliwad S., Shalini V.S.","Artificial bee colony algorithm for classification of semi-urban LU/LC features using high-resolution satellite data",2018,"Lecture Notes in Computational Vision and Biomechanics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028077930&doi=10.1007%2f978-3-319-61316-1_1&partnerID=40&md5=ccec79a6fcf3cc583d9bd088eb573efa","Attempts to classify high-resolution satellite data with conventional classifier show limited success since the traditional-per-pixel classifiers examine only the spectral variance ignoring the spatial distribution of the pixels corresponding to the land use/land cover classes. The work is carried out in two stages on panchromatic sharpened IRS P-6 LISS-IV (2.5 m) multispectral (MS) imagery of the year 2014 of Mangalore coastal zone along the west coast of Karnataka state of India. In the first stage, in order to overcome the limitations experienced in the parametric and nonparametric classifications, the swarm intelligence optimisation technique based on Artificial Bee Colony (ABC) algorithm has been studied for twelve land cover classes that are mapped. In the second stage, to bring out a greater separability between the spectrally overlapping classes, a texture-based image classification approach has been introduced and a methodology is developed to determine the optimal window size, interpixel distance and the best combinations of texture bands in multispectral data. The five texture measures, viz. entropy (ENT), angular second moment (ASM), contrast (CON), MEAN and homogeneity (Hmg) derived from the grey-level co-occurrence matrix (GLCM), are investigated in the study. The major observations and contributions of this work are as follows: in the first stage, the image classifier employing the ABC algorithm exhibits higher classification accuracy when compared with maximum likelihood classifier. In the second stage, the results show that combining textural features and spectral bands in classification approach has proven very useful in delineating the spectrally overlapping classes, particularly at higher class hierarchy level. © 2018, Springer International Publishing AG.","Artificial bee colony; GLCM; MLC; Texture",,2-s2.0-85028077930
"Karaca E., Tunga M.A.","An interpolation-based texture and pattern preserving algorithm for inpainting color images",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029055503&doi=10.1016%2fj.eswa.2017.09.001&partnerID=40&md5=bdfe565e6c8ac555fca9871c16326afd","Image inpainting can be defined as the process of filling missing regions in a given image with appropriate intensities. Intensity values of pixels in a missing area are expected to be associated with the pixels in the surrounding area. Interpolation-based methods that can solve the problem with a high accuracy may become inefficient when the dimension of the data increases. Also, they suffer from finding the underlying texture and pattern in the missing region. In this study, we propose a texture and pattern preserving interpolation-based algorithm for inpainting missing regions in color images. First, the proposed approach produces candidate inpainting results by interpolating to the observed data at the different neighborhoods of the missing region using High Dimensional Model Representation with Lagrange interpolation. Later, a final inpainting decision is given among the candidates for each pixel in the missing region for a texture and pattern preserving inpainting. This is achieved by combining the information obtained from co-occurrence matrix and from a patch found in the image that fits best to the missing region. We evaluate the performance of the proposed approach on various color images that include different texture and pattern. We also compare the proposed approach with the state-of-the-art inpainting methods in the literature. Experimental results demonstrate the potential of the proposed approach. © 2017 Elsevier Ltd","Digital image inpainting; High dimensional model representation method; Lagrange interpolation; Texture and pattern preserving inpainting","Color; Image processing; Interpolation; Lagrange multipliers; Pixels; Co-occurrence-matrix; Digital image inpainting; High dimensional model representation; Inpainting; Inpainting method; Intensity values; Lagrange interpolations; State of the art; Image texture",2-s2.0-85029055503
"Wanyuan J., Peng L., He X., Huqing N.","Energy optimization algorithm based on data density correlation in wireless sensor network",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026321699&doi=10.1007%2f978-3-319-61566-0_54&partnerID=40&md5=35cb9373053b37a42b47fedc92b47652","It’s importance to send the typical data from sampled data to the sink node in wireless sensor network. Compared with actual data, the representative data are always imprecise. Moreover, the energy consumption is huge. In order to minimize the energy consumption and improve the data accuracy, this paper presents the data fusion model PCCDNCD (correlation degree base on the Pearson correlation coefficient, the distance factor and the number of neighbor nodes, PCCDNCD). The correlation degree formula which can characterize the node from three aspects and classify nodes into three types precisely, is based on the Pearson correlation coefficient, the distance of nodes and the number of neighboring nodes. Nodes are classified into typical、ordinary and isolated nodes. In addition, the typical and isolated nodes are responsible for transferring data, while ordinary nodes are not required. The results show that the typical data achieved by the PCCDNCD method have higher degree of accuracy than the data from PCC (the Pearson correlation coefficient, PCC) and DDCD (the data density correlation degree, DDCD) methods. Meanwhile PCCDNCD algorithm has a low energy consumption. © Springer International Publishing AG 2018.","Data density; Data fusion; Energy optimization; Wireless sensor networks","Complex networks; Correlation methods; Data fusion; Energy utilization; Optimization; Sensor data fusion; Wireless sensor networks; Correlation degree; Data density; Degree of accuracy; Energy optimization; Isolated nodes; Low energy consumption; Neighboring nodes; Pearson correlation coefficients; Sensor nodes",2-s2.0-85026321699
"Li W., Xie J., Xin M., Mo J.","An overlapping network community partition algorithm based on semi-supervised matrix factorization and random walk",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029373327&doi=10.1016%2fj.eswa.2017.09.007&partnerID=40&md5=9834f8fa47655eb5bc022b285b17e969","The discovery of community structure is the basis of understanding the topology structure and social function of the network. It is also an important factor for recommendation technology, information dissemination, event prediction, and more. In this paper, we consider the structure and characteristics of the social network and propose an algorithm based on semi-supervised matrix factorization and random walk. The proposed method first calculates the transition probability between nodes through the topology of the network. The random walk model is then used to obtain the final walk probability, and the feature matrix is constructed. At the same time, we combine a priori content information in the network to build a must-link matrix and a cannot-link matrix. We then merge them into the feature matrix of the random walk to form a new feature matrix. Finally, the expectation of the number of edges is defined according to the factorized membership matrix. Results demonstrate the effectiveness and better performance of our method. © 2017 Elsevier Ltd","Matrix factorization; Node convergence degree; Node influence; Random walk","Factorization; Information dissemination; Random processes; Topology; Community structures; Matrix factorizations; Node convergence degree; Node influence; Random Walk; Random walk modeling; Recommendation technologies; Transition probabilities; Matrix algebra",2-s2.0-85029373327
"Jatsun S., Savin S., Yatsun A.","Motion control algorithm for a lower limb exoskeleton based on iterative LQR and ZMP method for trajectory generation",2018,"Mechanisms and Machine Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028080156&doi=10.1007%2f978-3-319-59972-4_22&partnerID=40&md5=2acd04de26bbc73fd50cf7dc23af7d33","In this paper a problem of controlling a lower limb exoskeleton during sit-to-stand motion (verticalization) in sagittal plane is studied. It is assumed that left and right sides of the exoskeleton are moving symmetrically. The main challenge in performing this motion is to maintain balance of the system. In this paper we use the zero-moment point (ZMP) methodology to produce desired trajectories for the generalized coordinates that would allow the system to remain vertically balanced. The limitations of this approach is that, it requires relatively accurate work of the feedback controller that ensures that the exoskeleton follows generated trajectories. In this work we use Iterative Linear Quadratic Regulator (ILQR) as a feedback controller in order to obtained the required accuracy. In the paper a way of trajectory generation that uses ZMP methodology is discussed, the results of the numerical simulation of the exoskeleton motion are presented and analyzed. A comparison between a natural human motion (for a human not wearing an exoskeleton) and the simulated motion of an exoskeleton using the proposed algorithm is presented. © Springer International Publishing AG 2018.","Control system design; Iterative linear quadratic regulator; Lower limb exoskeleton; Sit-to-stand motion; ZMP trajectory generation","Control systems; Controllers; Feedback; Feedback control; Flight control systems; Iterative methods; Machine design; Mobile robots; Trajectories; Generalized coordinates; Generated trajectories; Iterative linear quadratic regulator (ILQR); Linear quadratic regulator; Lower limb; Sit-to-stand; Trajectory generation; ZMP trajectory; Exoskeleton (Robotics)",2-s2.0-85028080156
"Mester D., Bräysy O., Dullaert W.","Why to climb if one can jump: a hill jumping algorithm for the vehicle routing problem with time windows",2018,"Computational Methods in Applied Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021839023&doi=10.1007%2f978-3-319-54490-8_6&partnerID=40&md5=92e429d419a7ff1a279de663b5dccabc","The most common approaches to solve the variants of the well-known vehicle routing problem are based on metaheuristic hill-climbing search. The deficiency of these methods is slow local search based hill climbing that often is restricted to limited local neighborhood. In this paper we suggest a novel new two-phase metaheuristic that escapes the local minima with jumps of varying size, instead of step by step local hill climbing. The initial solution is first generated with a powerful ejection pool heuristic. The key idea of the improvement phase is to combine large neighborhood search with standard guided local search metaheuristic in a novel way, allowing improved search diversification and escape from local minima in more efficient way through jumps. The algorithm has been tested on the standard Gehring and Homberger benchmarks for the vehicle routing problem with time windows and the results indicate very competitive performance. We found 12 new and 43 matched best-known solutions and the best overall results for all problem sizes at comparable computation times. © 2018, Springer International Publishing AG.","Heuristics; Metaheuristic; Time windows; Vehicle routing",,2-s2.0-85021839023
"Tang L., Gao X., Zhai P., Luo X.","Real-time density-based on-ramp metering algorithm considering multi-lane of mainstream",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026775198&doi=10.1007%2f978-981-10-3551-7_37&partnerID=40&md5=3677fbcca3376e3ecee297c5f40a0581","On-ramp metering is regarded as one of most effective control methods of balancing mainstream traffic flow and releasing congestion on expressway in recent years. The current control methods suffer from several shortcomings, such as lack of consideration of on-ramp queue or lane-change behavior on multi-lane mainstream. This paper optimizes the real-time density-based on-ramp metering algorithm by taking multi-lane traffic flow character into consideration. The error function representing lane difference is defined as the objective, and real-time density considering lane change is used as the control parameter of calculating the metering rate. The micro-simulation is used for testing the performance of the multi-lane real-time density-based on-ramp metering (MRD-RM) model using the field data collected in Chengdu. The simulation result shows that MRD-RM model outperforms ALINEA and non-control in terms of reducing average queue length as well as keeping traffic flow on mainstream close to capacity. © Springer Science+Business Media Singapore 2018.","Intelligent transportation systems (ITSs); Lane-changing rate; Multi-lane; On-ramp metering; Real-time density","Highway traffic control; Intelligent systems; Intelligent vehicle highway systems; Traffic congestion; Traffic control; Transportation; Intelligent transportation systems; Lane changing; Multi-lane; On-ramp metering; Real-time density; Real time systems",2-s2.0-85026775198
"Vasuki A.","Certain applications and case studies of evolutionary computing techniques for image processing",2018,"Lecture Notes in Computational Vision and Biomechanics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028049164&doi=10.1007%2f978-3-319-61316-1_12&partnerID=40&md5=68839cea7f0225302437c3fea89116d7","The chapter gives an introduction to optimization based on evolutionary computational techniques and swarm intelligence. Evolutionary computational algorithms adopt the principles of biological evolution and use a population of solutions that evolves with every generation. The bio-inspired computing algorithms that mimic the behavior of swarms of birds and insects, referred collectively as swarm intelligence, are a subset of evolutionary algorithms. The behavior of swarms individually as well as collective behavior in a flock has been extensively studied and an insight into their integration with the optimization algorithm is given. The evolutionary optimization algorithms such as genetic algorithm, particle swarm optimization, ant colony optimization, bee colony optimization, cuckoo search, fish school search, firefly algorithm have been reviewed. The application of these algorithms to image processing has been outlined, and few case studies have been presented. © 2018, Springer International Publishing AG.","Ant colony optimization; Bee colony optimization; Bio-inspired computing; Cuckoo search; Evolutionary computation; Firefly algorithm; Fish school; Genetic algorithm; Image processing; Particle swarm optimization",,2-s2.0-85028049164
"Basegio T.L., Bordini R.H.","An algorithm for allocating structured tasks in multi-robot scenarios",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020473931&doi=10.1007%2f978-3-319-59394-4_10&partnerID=40&md5=999987fcd65999784aac96fe69b418ae","Task allocation is an important aspect in dealing with coordination problems. However, there are challenges in developing appropriate strategies for multi-robot teams in such a way that robots perform their operations efficiently. Real-world scenarios usually require the use of heterogeneous robots and execution of tasks with different structures and constraints. In this paper we propose a dynamic, decentralised task allocation mechanism considering different types of tasks for heterogeneous robot teams playing different roles and carrying out tasks according to their own capabilities. We have run several simulations in order to evaluate the proposed mechanism. The results indicate that the proposed mechanism scales well and provides near-optimal allocations. © Springer International Publishing AG 2018.","Multi-agent systems; Multi-robot systems; Task allocation","Industrial robots; Multipurpose robots; Programmable robots; Robots; Coordination problems; Different structure; Heterogeneous robot teams; Heterogeneous robots; Multi-robot systems; Near-optimal allocation; Real-world scenario; Task allocation; Multi agent systems",2-s2.0-85020473931
"Zwolińska B.","Algorithm of autonomic shaping of workflow",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028615133&doi=10.1007%2f978-3-319-64465-3_12&partnerID=40&md5=2ff933f1d365721d66986794c590e6c7","In the article there is a presentation of the model of shaping level of workflow which is possible to use in formulation of autonomic software of production system. Application with model in intelligent production system is on the second level – level of gathering and processing data. Assumptions of presented models assume customization (personalization) of created product in elastic production system. Flexibility of production system achieved by flexible production sockets with use of economic robots with full cooperation with operator. Exemplary production system have been shaped due to the level of workflow of m input streams and n processing phases. In consideration there is a single production where number of orders kp in time ∆t is deterministic value smaller than 30. The rest of parameters as realization time in consecutive processes are random variables with characteristic designation of probability thickness. Presented model of the whole production system can be used as a system of early warnings before anomaly situations of overstretching or under-stretching single sub-systems of the whole system. © Springer International Publishing AG 2018.","Balancing of the production line; Shaping of the level of workflow","Data handling; Intelligent systems; Maintenance; Early warning; Flexible production; Input streams; Personalizations; Production line; Production system; Second level; Shaping of the level of workflow; Production",2-s2.0-85028615133
"Askari E., Flores P., Silva F.","A particle swarm-based algorithm for optimization of multi-layered and graded dental ceramics",2018,"Journal of the Mechanical Behavior of Biomedical Materials",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030856406&doi=10.1016%2fj.jmbbm.2017.10.005&partnerID=40&md5=182fb43f5e928f39ab7c10c518159b99","The thermal residual stresses (TRSs) generated owing to the cooling down from the processing temperature in layered ceramic systems can lead to crack formation as well as influence the bending stress distribution and the strength of the structure. The purpose of this study is to minimize the thermal residual and bending stresses in dental ceramics to enhance their strength as well as to prevent the structure failure. Analytical parametric models are developed to evaluate thermal residual stresses in zirconia-porcelain multi-layered and graded discs and to simulate the piston-on-ring test. To identify optimal designs of zirconia-based dental restorations, a particle swarm optimizer is also developed. The thickness of each interlayer and compositional distribution are referred to as design variables. The effect of layers number constituting the interlayer between two based materials on the performance of graded prosthetic systems is also investigated. The developed methodology is validated against results available in literature and a finite element model constructed in the present study. Three different cases are considered to determine the optimal design of graded prosthesis based on minimizing (a) TRSs; (b) bending stresses; and (c) both TRS and bending stresses. It is demonstrated that each layer thickness and composition profile have important contributions into the resulting stress field and magnitude. © 2017 Elsevier Ltd","Ceramic; Dental restoration; Multi-layered and graded material; Particle swarm optimization; Porcelain; Thermal and bending stresses","Ceramic materials; Cooling systems; Dental materials; Filling; Finite element method; Optimal systems; Particle swarm optimization (PSO); Porcelain; Processing; Prosthetics; Residual stresses; Restoration; Zirconia; Bending stress; Bending stress distribution; Ceramic; Compositional distribution; Dental restorations; Graded materials; Processing temperature; Thermal residual stress; Structural design",2-s2.0-85030856406
"Cheriguene S., Azizi N., Dey N., Ashour A.S., Mnerie C.A., Olariu T., Shi F.","Classifier ensemble selection based on mRMR algorithm and diversity measures: An application of medical data classification",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029528458&doi=10.1007%2f978-3-319-62521-8_32&partnerID=40&md5=de8667d9b8c66a8a57a1c7c46efec469","Classifier selection is a significant problem in machine learning to reduce the computational time and the number of ensemble members. Over the past decade, multiple classifier systems (MCS) have been actively exploited to enhance the classification accuracy. Finding a pertinent objective function for measuring the competence of base classifier is a critical issue to select the appropriate subset from a pool of classifiers. Along with the accuracy, diversity measures are designed as objective functions for ensemble selection. This current work proposed a new selection method based on accuracy and diversity in order to achieve better medical data classification performance. The classifiers correlation was calculated using Minimum Redundancy Maximum Relevance (mRMR) method based on relevance and diversity measures. Experiments were carried out on five data sets from UCI Machine Learning Repository and LudmilaKuncheva Collection. The experimental results proved the superiority of the proposed classifiers selection method. © 2018, Springer International Publishing AG.","Classifiers selection; Diversity measures; Medical data classification; Minimum Redundancy Maximum Relevance Method; Relevance",,2-s2.0-85029528458
"Barati R., Badfar M., Azizyan G., Akbari G.H.","Discussion of ""Parameter estimation of extended nonlinear muskingum models with the weed optimization algorithm"" by Farzan Hamedi, Omid Bozorg-Haddad, Maryam Pazoki, Hamid-Reza Asgari, Mehran Parsa, and Hugo A. Loáiciga",2018,"Journal of Irrigation and Drainage Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032733289&doi=10.1061%2f%28ASCE%29IR.1943-4774.0001095&partnerID=40&md5=b32d7d0c693668b15d53b0fd4860a8fc",[No abstract available],,,2-s2.0-85032733289
"Ghasemzade R.","Discussion of ""application of the firefly algorithm to optimal operation of reservoirs with the purpose of irrigation supply and hydropower production"" by Irene Garousi-Nejad, Omid Bozorg-Haddad, Hugo A. Loáiciga, and Miguel A. Mari ño",2018,"Journal of Irrigation and Drainage Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032721329&doi=10.1061%2f%28ASCE%29IR.1943-4774.0001064&partnerID=40&md5=7dd00aabfb7f26d06fe872629a57bfb6",[No abstract available],,,2-s2.0-85032721329
"Zheng Y.-H., Li J.-L., Cheng D.-X., Lv L.-L.","The incomplete global GMERR algorithm to solve AX = B*",2018,"Journal of Computational Analysis and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027333478&partnerID=40&md5=4cadaa583ba0e0af8ca441cd03049c90","To reduce the computational cost and storage requirement of global generalized minimal error (GLGMERR) method, in this paper, we propose a truncated version of GLGMERR method, which is termed as incomplete global generalized minimal error method. The proposed approach uses only a few rather than all of the prior computed matrices in recurrences to generate the next matrix. Moreover a quasi-minimum error solution is obtained as well. Finally, we present the numerical results by comparing with the traditional global GMERR method in CPU time and storage requirements to show the effectiveness and advantages of our method. © 2018 by Eudoxus Press, LLC. All rights reserved.","Incomplete global generalized minimal error; Matrix equation",,2-s2.0-85027333478
"Patel H.A., Divecha N.H.","A feature-based semi-fragile watermarking algorithm for digital color image authentication using hybrid transform",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031418604&doi=10.1007%2f978-981-10-3773-3_44&partnerID=40&md5=40503fe6442e688f7eab2d51607335ae","Digital watermarking plays vital role to preserve content of digital color image authentication. This paper proposed semi-fragile watermarking technique using feature extraction. The features of original image are extracted through canny edge detection and utilize it as watermark. Watermark is scrambled for providing more security. To achieve higher level of imperceptibility and robustness against attacks, amalgamation of DCT, DWT, and SVD are applied. Experimental results prove that, proposed technique is robust against group of attacks with adequate hiding capacity and imperceptibility as compare to existing systems. © Springer Nature Singapore Pte Ltd. 2018.","DCT-DWT-SVD; Digital watermarking; Image authentication; Scrambling; Semi-fragile watermarking","Authentication; Color image processing; Digital watermarking; Discrete wavelet transforms; Edge detection; Feature extraction; Metals; Signal reconstruction; Canny edge detection; Digital color images; Existing systems; Hiding capacity; Hybrid transforms; Image authentication; Scrambling; Semi-fragile watermarking; Image watermarking",2-s2.0-85031418604
"Asgari H.-R., Bozorg-Haddad O., Loáiciga H.A.","Closure to ""Parameter estimation of extended nonlinear muskingum models with the weed optimization algorithm"" by Farzan Hamedi, Omid Bozorg-Haddad, Maryam Pazoki, Hamid-Reza Asgari, Mehran Parsa, and Hugo A. Loáiciga",2018,"Journal of Irrigation and Drainage Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032726037&doi=10.1061%2f%28ASCE%29IR.1943-4774.0001095&partnerID=40&md5=ccab0bfbc901d3e7f261b3e3692b83b9",[No abstract available],,,2-s2.0-85032726037
"Gonzalez-Donquiles C., Sanchez-Lasheras F., Alonso-Molero J., Vilorio-Marqués L., Fernandez-Villa T., Tardón G.G., Molina A.J., Martin V.","PoDA algorithm: Predictive pathways in colorectal cancer",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028680310&doi=10.1007%2f978-3-319-67180-2_41&partnerID=40&md5=49f68ad7ec86ae31070f825301291494","Colorectal cancer (CRC) has the third highest incidence in men, and the second highest in women worldwide. As it is known, both genetic and environmental factors play a role in colorectal cancer. So far, the most common way of studying genetic factors affecting CRC has been the SNP-SNP analysis. However, since these rarely act in an individualized way, it would be interesting to study them together. For that reasons, it is important to detect pathways or SNPs with a known relation which plays a role in this disease. In this study, we use Pathway of Distinction Analysis methodology (PoDA) in order to do it. PoDA is a novel bioinformatics tool that identifies significant pathways that could play an essential role in a specific disease based on genetics distance. Based on this method, we state that mitochondrial biogenesis pathway could be a good predictor pathway on colorectal cancer. © 2018, Springer International Publishing AG.","Colorectal cancer; Pathways; PoDA; Single nucleotide polymorphism","Soft computing; Bioinformatics tools; Colorectal cancer; Colorectal cancers (CRC); Environmental factors; Mitochondrial biogenesis; Pathways; PoDA; Single nucleotide polymorphisms; Diseases",2-s2.0-85028680310
"Masrani M., Gou P.","Twitter sentiment analysis using a modified naïve bayes algorithm",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029521435&doi=10.1007%2f978-3-319-67220-5_16&partnerID=40&md5=f32949e93459776fabc4f083afd1c721","Microblogging has emerged as a popular platform and a powerful communication tool among people nowadays. A clear majority of people share their opinions about various aspects of their lives online every day. Thus, microblogging websites offer rich sources of data in order to perform sentiment analysis and opinion mining. Because microblogging has emerged relatively recently there are only some research works which are devoted to this field. In this paper, the focus is on performing the task of sentiment analysis using Twitter which is one of the most popular microblogging platforms. Twitter is a very popular microblogging site where its users write status messages called tweets to express themselves. These status updates mostly express their opinions about various topics. The objective of this paper is to build a system that can classify these Twitter status updates as positive, negative, or neutral with respect to any query term thereby giving an idea about the overall sentiment of the people towards that topic. This type of sentiment analysis is useful for advertisers, consumers researching a service or product, companies, governments, marketers, or any organization who are researching public opinion. © 2018, Springer International Publishing AG.","Data mining; Sentiment analysis; Twitter",,2-s2.0-85029521435
"Fang Y., Feng H., Chen Y.","A robust interaural time differences estimation and dereverberation algorithm based on the coherence function",2018,"Applied Acoustics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026409709&doi=10.1016%2fj.apacoust.2017.07.019&partnerID=40&md5=d01b54ec4346c879d601b77c297642a4","A novel scheme of binaural sound localization and dereverberation in reverberation environment is present in this paper. The performance of cross-correlation based traditional time-delay estimation method is degraded sharply in a reverberation environment. Some precedence effect models have been proposed to apply in cross-correlation functions, but these models are parameter-sensitive and the front-end processes are very complex. This paper firstly proposes a simple and effective time-delay estimation method based on a coherence function in which the absolute values of coherence function is used to judge the reliability of the frequency-domain signal. And then the estimated time-delay values were applied to the coherent-to-diffuse power ratio (CDR) estimator, which can be used for reverberation suppression. Experimental results showed that the proposed scheme has higher localization accuracy than traditional methods and achieve a higher PESQ scores than other CDR estimators. © 2017 Elsevier Ltd","Coherence; Dereverberation; Precedence effect; Sound localization","Clock and data recovery circuits (CDR circuits); Coherent light; Estimation; Reverberation; Time delay; Binaural sound localizations; Cross-correlation function; Dereverberation; Interaural time differences; Precedence effect; Reverberation suppressions; Sound localization; Time delay estimation method; Frequency estimation",2-s2.0-85026409709
"Arya M.S., Jain P.","Fifth-level second-generation wavelet-based image fusion algorithm for visual quality enhancement of digital image data",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031747476&doi=10.1007%2f978-981-10-5508-9_13&partnerID=40&md5=f0357c5c3634c3ab20fbe1d57aa54694","Image fusion is a technique that combines the complementary information from multiple images such that the fused image contains possibly the maximum information pertaining to both the constituent images. The objective of the proposed work is to review the existing techniques presented by various researchers for image fusion and devise a more efficient solution. The proposed technique involves the use of lifting wavelet transform technique at fifth level of decomposition and 9 different max–min–mean fusion rule combinations to achieve image fusion. The performance evaluation has been done on the basis of performance parameters considering PSNR, entropy, E-RMS, correlation coefficient, and structural similarity index. The fused images obtained were nearly identical to the ideal images since the correlation coefficient is 0.9947 which is quite close to 1. The observed values of the evaluation parameters show that the proposed scheme shows better performance as compared to others. © Springer Nature Singapore Pte Ltd. 2018.","CR; Image fusion; Lifting wavelet transform; SSIM","Chromium; Data fusion; Image enhancement; Parameter estimation; Wavelet decomposition; Wavelet transforms; Correlation coefficient; Digital image data; Evaluation parameters; Lifting wavelet transforms; Performance parameters; Second generation wavelet; SSIM; Structural similarity indices; Image fusion",2-s2.0-85031747476
"Więcek-Janka E., Sławińska M.","Improvement of interactive products based on an algorithm minimizing information gap",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021764130&doi=10.1007%2f978-3-319-60828-0_11&partnerID=40&md5=f7f5b1f2cd28d833c30f306d660a81d0","This paper feature results of scientific research that is associated with the improvement of interaction conditions of interactive products. Efficiency of use of these products remains in close correlation with efficient performance of decision making processes. Available information resources assist the user in the effective use of electronic devices only when, at the same time, mechanisms of adaptation of information to the real needs and learning capabilities of the individual user in the information environment are being designed. This multi-dimensional space in which cognitive processes are carried out, in regard to processing and transferring information, is nowadays characterized by excessive amounts of information, also called information noise. However, in the use of interactive products, the common phenomenon of the so-called information gap, which is the difference between relevant information and the collection of information became available in the system. The result of designing interactive products targeted at eliminating this discrepancy is that the user achieve goals with satisfaction, in less time and without frustration and anxiety, which would otherwise occur as a result of emotional and cognitive dissonance. © Springer International Publishing AG 2018.","Cognitive processes; Decision making processes","Cognitive systems; Decision making; Ergonomics; Cognitive dissonance; Cognitive process; Decision making process; Information environment; Information resource; Learning capabilities; Multi-dimensional space; Scientific researches; Product design",2-s2.0-85021764130
"Puchala E., Krysmann M.","An algorithm for detecting the instant of olfactory stimulus perception, using the EEG signal and the Hilbert-Huang transform",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019220677&doi=10.1007%2f978-3-319-59162-9_52&partnerID=40&md5=3143119ba3cc788f2f66aef83214cac4","The paper describes approach to instant of olfactory stimulus perception detection. Classification of olfactory stimuli in EEG is complex, but very important task. It allows to describe cognitive process and help in medical diagnosis process. Due to chemical - electrical nature of olfactory perception, there is need of solution which provide detection of beginning stimuli in EEG signal. Other way classification of olfactory stimuli would be more complex, due to not accurate in objects localization in learning set. Therefore the paper proposes utilization of Hilbert-Huang transformation in pre-processing. Proposed approach is evaluated and it have proven it’s usability. © Springer International Publishing AG 2018.","Hilbert-Huang transform; Instant detection; Olfactory stimulus","Chemical detection; Diagnosis; Cognitive process; EEG signals; Electrical nature; Hilbert Huang Transformation; Hilbert Huang transforms; Olfactory stimulus; Pre-processing; Mathematical transformations",2-s2.0-85019220677
"Poczeta K., Kubuś Ł., Yastrebov A., Papageorgiou E.I.","Application of fuzzy cognitive maps with evolutionary learning algorithm to model decision support systems based on real-life and historical data",2018,"Studies in Computational Intelligence",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022336363&doi=10.1007%2f978-3-319-59861-1_10&partnerID=40&md5=65998903ff20e3b586c605dd08da5476","Fuzzy cognitive map (FCM) is a universal tool for modeling dynamic decision support systems. It can be constructed by the experts or learned based on historical data. FCM models learned from data are denser than those created by humans. We developed an evolutionary learning approach for fuzzy cognitive maps based on density and system performance indicators. It allows to select only the most significant connections between concepts and receive the structure more similar to the FCMs initialized by experts. This paper is devoted to the application of the developed approach to model decision support systems with the use of real-life and historical data. © Springer International Publishing AG 2018.",,,2-s2.0-85022336363
"Chen C.-H., Yu C.-H.","A PIP-based approach for optimizing a group stock portfolio by grouping genetic algorithm",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032630489&doi=10.1007%2f978-981-10-6487-6_3&partnerID=40&md5=1d8c9d027087c054d764e2f83d093d04","Recently, some approaches have been proposed for finding a group stock portfolio (GSP). However, stock price series of stocks which are useful information may not be considered in those approaches. Hence, this study takes stock price series into consideration and presents a perceptually important point (PIP)-based approach for obtaining a GSP. Since the PIP is used, the proposed approach can handle stock price series with different lengths, which means that a more useful GSP could be found and provided to investors. Each chromosome is encoded by grouping, stock, and stock portfolio parts. To measure the similarity of series in groups, the series distance is designed and used as a part of fitness function. At last, experiments were conducted on a real dataset to show the advantages of the proposed approach. © Springer Nature Singapore Pte Ltd. 2018.",,,2-s2.0-85032630489
"Kedia A., Pandel A., Mohata A., Sowmya Kamath S.","An intelligent algorithm for automatic candidate selection for web service composition",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032645914&doi=10.1007%2f978-981-10-3376-6_41&partnerID=40&md5=3880bdf471d26b031d373d4f053924ad","Web services have become an important enabling paradigm for distributed computing. Some deterrents to the continued popularity of the web service technology currently are the nonavailability of large-scale, semantically enhanced service descriptions and limited use of semantics in service life cycle tasks like discovery, selection, and composition. In this paper, we outline an intelligent semantics-based web service discovery and selection technique that uses interfaces and text description of services to capture their functional semantics. We also propose a service composition mechanism that automatically performs candidate selection using the service functional semantics, when one web service does not suffice. These techniques can aid application designers in the process of service-based application development that uses multiple web services for its intended functionality. We present experimental and theoretical evaluation of the proposed method. © Springer Nature Singapore Pte Ltd. 2018.","NLP; Semantic search; Web services composition",,2-s2.0-85032645914
"Garousi-Nejad I., Bozorg-Haddad O., Loáiciga H.A.","Closure to ""application of the firefly algorithm to optimal operation of reservoirs with the purpose of irrigation supply and hydropower production"" by Irene Garousi-Nejad, Omid Bozorg-Haddad, Hugo A. Loáiciga, and Miguel A. Mari ño",2018,"Journal of Irrigation and Drainage Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032724459&doi=10.1061%2f%28ASCE%29IR.1943-4774.0001064&partnerID=40&md5=b81b6bfd419dcd4310c1478e34ca71c5",[No abstract available],,,2-s2.0-85032724459
"Rathod D., Khanna S., Singh M.","Smart two level K-means algorithm to generate dynamic user pattern cluster",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028368807&doi=10.1007%2f978-3-319-63645-0_19&partnerID=40&md5=0774a4bc92661625b2b8a02387b1bc53","Data cleaning perform in the Data Preprocessing and Mining. The clean data work of web server logs irrelevant items and useless data can not completely removed and Overlapped data causes difficulty during retrieving data from datasource. Previous paper had given 30% performance of datasource. So We have Implemented Smart Two-level clustering method to get pattern data for mining. This paper presents WebLogCleaner can filter out much irrelevant, inconsistent data based on the common of their URLs and it is going to improving 8% of the data quality, performance, Accuracy and efficiency of any Datasource. © Springer International Publishing AG 2018.","Data cleaning; Pattern cluster; Preprocessing; Web log mining; Web page mining; Web usage mining (WUM)","Intelligent systems; Websites; Data cleaning; Pattern cluster; Preprocessing; Web log mining; Web usage mining; Filtration",2-s2.0-85028368807
"Kartiev S.B., Kureychick V.M.","Algorithm for building recommendations for intelligent systems",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031314033&doi=10.1007%2f978-3-319-68324-9_9&partnerID=40&md5=8896f97e3446d28d128c21744dcafb97","At present, when developing intellectual systems, one of the most important questions is the construction of a formal description of the data domain. This allows to improve the quality of development. The ontological models are currently used for these purposes. The paper describes the development of a model of the recommendation system based on the ontological approach. When developing recommendatory systems, the usual methods of describing objects are applied, which leads to the impossibility of configuring the system being developed. The purpose of this study was to develop an ontological model for configurable recommender systems. An introduction is given to the topic of ontological modeling, sufficient for understanding the main material of the article. The formal ontology model is presented, the main ontology classes, ontology levels, ontology usage objectives are described. The main principle of modeling the domain object-oriented design is described. Next, the application of ontologies in the recommendation system is described. It describes the conceptual model of the system with UML. A model of the ontology of the data domain description for the development of the recommendatory system was developed. The principal difference of this model from existing models is its customization on the data domain. Using the developed model, it is possible to develop configurable advisory systems. A recommendatory system has been developed using the Python programming language to solve the problem of making recommendations using the developed ontological model of the domain model presentation. Studies were conducted on the effectiveness of modeling the subject area with regard to the compilation of requirements for the recommendation system. © 2018, Springer International Publishing AG.","Ontological modeling; Recommended system; Semantic web","Intelligent systems; Object oriented programming; Ontology; Semantic Web; Application of ontologies; Data domain description; Formal ontology model; Intellectual systems; Object oriented design; Ontological modeling; Python programming language; Recommended systems; Recommender systems",2-s2.0-85031314033
"Farnsworth M., Tiwari A., Zhu M., Benkhelifa E.","A multi-objective and multidisciplinary optimisation algorithm for microelectromechanical systems",2018,"Studies in Computational Intelligence",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030108123&doi=10.1007%2f978-3-319-64063-1_9&partnerID=40&md5=97332f6873ecea5d3bcde0babf646ca0","Microelectromechanical systems (MEMS) are a highly multidisciplinary field and this has large implications on their applications and design. Designers are often faced with the task of balancing the modelling, simulation and optimisation that each discipline brings in order to bring about a complete whole system. In order to aid designers, strategies for navigating this multidisciplinary environment are essential, particularly when it comes to automating design synthesis and optimisation. This paper outlines a new multi-objective and multidisciplinary strategy for the application of engineering design problems. It employs a population-based evolutionary approach that looks to overcome the limitations of past work by using a non-hierarchical architecture that allows for interaction across all disciplines during optimisation. Two case studies are presented, the first focusing on a common speed reducer design problem found throughout the literature used to validate the methodology and a more complex example of design optimisation, that of a MEMS bandpass filter. Results show good agreement in terms of performance with past multi-objective multidisciplinary design optimisation methods with respect to the first speed reducer case study, and improved performance for the design of the MEMS bandpass filter case study. © Springer International Publishing AG 2018.","Evolutionary computation; MEMS and multidisciplinary; Microelectromechanical systems; Multi-objective optimisation",,2-s2.0-85030108123
"Studniarski M., Al-Jawadi R., Younus A.","An evolutionary optimization method based on scalarization for multi-objective problems",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029534234&doi=10.1007%2f978-3-319-67220-5_5&partnerID=40&md5=5d8f4121a3cfddfd951bcf996b617d8d","In this paper, we perform some computational experiments on the new global scalarization method for multi-objective optimization problems. Its main idea is to construct, for a given multi-objective optimization problem, a global scalarization function whose values are non-negative real numbers. The points where the scalarization function attains the zero value are exactly weak Pareto stationary points for the original multi-objective problem. We apply two different evolutionary algorithms to minimize the scalarization function; both of them are designed for solving scalar optimization problems. The first one is the classical Genetic Algorithm (GA). The second one is a new algorithm called Dissimilarity and Similarity of Chromosomes (DSC), which has been designed by the authors. The computational results presented in this paper show that the DSC algorithm can find more minimizers of the scalarization function than the classical GA. © 2018, Springer International Publishing AG.","Dissimilarity and similarity of chromosomes algorithm; Genetic algorithm; Multi-objective optimization; Scalarization",,2-s2.0-85029534234
"Krasheninnikov V., Vasil’ev K.","Multidimensional image models and processing",2018,"Intelligent Systems Reference Library",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032576839&doi=10.1007%2f978-3-319-67516-9_2&partnerID=40&md5=a83c86e3ed8f8414f4fd8dfb45f83bec","The problems of developing mathematical models and statistical algorithms for processing of multidimensional images and their sequences are presented in this chapter. Different types of random fields are taken for the basic mathematical image model. This implies two main problems associated with image modeling, namely, model analysis and synthesis. The main attention is paid to the correlation aspect, i.e. evaluation of the correlation function of a random field generated by a given model and, vice versa, development of a model generating a random field with a predetermined correlation function. For this purpose, new models (tensor and wave) and new versions of autoregressive models (with multiple roots) are suggested. The problems of image simulation on the curved surfaces are considered. The suggested models are used to synthesize the algorithms of multidimensional image processing and their sequences. The tensor filtration of imaging sequences and recursive filtration of multidimensional images, as well as the asymptotic characteristics of efficiency of random field filtration on grids of arbitrary dimension are suggested. The problem of object and anomaly detection on the background of interfering images is considered for the images of any dimension, e.g. for multi-zone data. It is shown that four equivalent forms of the optimal decision rule, which reflect various aspects of detection procedure, exist. Potential efficiency of anomaly detection is analyzed. The problems of alignment and estimation of parameters for interframe geometric image transformations are considered for multidimensional image sequences. A tensor procedure of simultaneous filtration of multidimensional image sequence and their interframe displacements are suggested. A method based on a fixed point of a complex geometric image transformation was investigated in order to evaluate large interframe displacements. Options for adaptive image processing algorithms are also discussed in this chapter. In this context, pseudo-gradient procedures are taken as a basis, as they do not require preliminary evaluation of any characteristics of the processed data. This allows to develop the high-performance algorithms that can be implemented in real-time systems. © 2018, Springer International Publishing AG.","Adaptive algorithm; Anomaly detection; Autoregressive model; Curved surface; Filtration; Multidimensional image model; Potential efficiency; Prediction; Processing; Pseudo-gradient algorithm; Recognition; Tensor model; Wave model",,2-s2.0-85032576839
"Wang L., Shi X., Han S., Jinchi","Robust object tracking via improved mean-shift model",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022190301&doi=10.1007%2f978-981-10-5281-1_10&partnerID=40&md5=96152c003f5c9dcba079c49e332cd21d","In this paper we propose a robust object tracking algorithm using a improved Mean-Shift model. As the traditional Mean-Shift algorithm for object tracking uses a single histogram. Because the traditional Mean-Shift lacks spatial distribution information, so it is difficult to track non-rigid object especially. With a focus on this problem, an improved Mean-Shift algorithm based on the shape feature and color of the target is presented. The results show that the algorithm can track the moving vehicles in real time, and it has a preferable adaptability and robustness to the irregular motion and deformation of the target. © Springer Science+Business Media Singapore 2018.","Color feature; Machine vision; Mean shift; Object tracking","Computer vision; Wireless telecommunication systems; Color features; Mean shift; Mean shift algorithm; Mean shift model; Motion and deformations; Non-rigid objects; Object Tracking; Object tracking algorithm; Tracking (position)",2-s2.0-85022190301
"Chi Z.","Research on image fingerprint technology based on watson visual model multimedia technology",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028446197&doi=10.1007%2f978-3-319-60744-3_14&partnerID=40&md5=f577b2db46958ea13a433779c37cbf15","Computer network has greatly changed the life and work of people, the demand of people for information has been developed from the single text message to the current graphics, images, audio, video and other digital multimedia forms. With the development of a large number of multimedia applications, the digital image is easy to be operated and tampered, this paper aims to study an image fingerprint algorithm based on the masking characteristics of the human eye. An image sensing Hash algorithm based on human visual model is proposed to effectively eliminate the influence of geometric attacks. Watson visual model is used to deal with the DCT coefficients to produce the image fingerprint sequences, which has excellent robustness and security. The experiment proves that the algorithm can certify the copyright of the image, reduce geometric attacks, JPEG compression and other attacks, it can also use the key to generate the pseudo-random matrix, so as to encrypt the image, and effectively realize the security of the algorithm. © 2018, Springer International Publishing AG.","Image fingerprint algorithm; Regularization; Watson visual model","Hash functions; Intelligent systems; Multimedia systems; Real time systems; Digital multimedia; Fingerprint algorithm; Fingerprint technologies; Masking characteristic; Multimedia applications; Multimedia technologies; Regularization; Visual model; Image compression",2-s2.0-85028446197
"Zhang M., Benítez J.M., Montáns F.J.","Cyclic plasticity using Prager's translation rule and both nonlinear kinematic and isotropic hardening: Theory, validation and algorithmic implementation",2018,"Computer Methods in Applied Mechanics and Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031759946&doi=10.1016%2fj.cma.2017.09.028&partnerID=40&md5=a9941ccf5a8a048a5a5c78b536169398","Finite element analysis of structures under elasto-plastic nonproportional cyclic loadings is useful in seismic engineering, fatigue analysis and ductile fracture. Usual models with nonlinear stress–strain curves in cyclic behavior are based on Mróz multisurface plasticity, bounding surface models or models derived from the Armstrong–Frederick rule. These models depart from the associative Prager's rule with the main purpose of modeling aspects of cyclic nonlinear hardening. In this paper we develop a model for cyclic plasticity within the framework of the associative classical plasticity theory using Prager's rule accounting for anisotropic nonlinear kinematic hardening coupled with nonlinear isotropic hardening. We include the validation of the theory against several uniaxial and multiaxial cyclic experiments and an efficient fully implicit radial return algorithm. The parameters of the model are obtained directly by a discretization of the uniaxial stress–strain behavior. Remarkably, both the presented theory and the computational algorithm automatically recover classical bi-linear plasticity and the Krieg and Key algorithm if the user-prescribed stress–strain curve is bilinear. © 2017 Elsevier B.V.","Associative plasticity; Cyclic plasticity; Multisurface model; Nonlinear kinematic hardening; Radial return algorithm","Computation theory; Ductile fracture; Earthquake engineering; Hardening; Kinematics; Plasticity; Associative plasticity; Computational algorithm; Cyclic plasticity; Multi-surface plasticity; Multisurface model; Nonlinear isotropic hardening; Nonlinear kinematic hardening; Nonproportional cyclic loading; Finite element method",2-s2.0-85031759946
"Sun Y., Xiao H., Tu S., Sun K., Pan L., Tu K.","Detecting decayed peach using a rotating hyperspectral imaging testbed",2018,"LWT - Food Science and Technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029316758&doi=10.1016%2fj.lwt.2017.08.086&partnerID=40&md5=387f6d31f550b3511e7195e2ee64abbe","A hyperspectral imaging system with a moving testbed has been developed for detection of the disease caused by Rhizopus stolonifera in peaches. The all-around hyperspectral imaging of the whole peach was obtained, which can identify the decayed area fully and is suitable for online monitoring. Three single-band images (709, 807, and 874 nm) which were selected by statistical methods and an image segmentation algorithm were applied to locate the decayed area of peaches was developed based on band ratio image coupled with a simple thresholding method. The performance of image segmentation algorithm of the single-band images was evaluated. The detection accuracy of peaches classified as ‘sound’, ‘slight-decayed’, ‘moderate-decayed’ and ‘severe-decayed’ were 95%, 66.29%, 100% and 100%, respectively. The spectral information was extracted from the decayed area to improve the detection accuracy. The six optical wavelengths were selected by SPA (successive projections algorithm) from the full spectral range. The classification accuracy of sound and rotten peaches was 100% if only these two categories were applied. Our results demonstrated that the hyperspectral imaging method offers the potential to be used to automatically detect fungal infection in peaches. © 2017 Elsevier Ltd","Band ratio; Image segmentation algorithm; PLS-DA; Rhizopus stolonifera","Decay (organic); Fruits; Hyperspectral imaging; Spectroscopy; Testbeds; Band ratios; Classification accuracy; Image segmentation algorithm; PLS-DA; Rhizopus stolonifera; Spectral information; Successive projections algorithm; Thresholding methods; Image segmentation",2-s2.0-85029316758
"Xu H., Yu L., Zhang L., Liu J.","A wall interactive system based on infrared electronic pen",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030859704&doi=10.1007%2f978-981-10-6496-8_17&partnerID=40&md5=fd4943461e256a828d38b7cd43024e12","In this paper, a new method of interactive system based on infrared electronic pen is proposed to achieve accurate tracking of the target trajectory with anti-jamming ability. Projection technology, infrared sensor, dynamic capture, image processing and other technologies are synthesized in this system. The interactive area is created intelligently and the touch event is determined, and the Improved Mean Shift algorithm is utilized for image information tracking. The simulation of the mouse function can make any wall into a touch screen. With the integration of whiteboard technology, a good human-computer interaction effect can be achieved. © 2018, Springer Nature Singapore Pte Ltd.","Improved Mean Shift algorithm; Infrared sensor; Interactive system; Projection technology; Target trajectory","Image enhancement; Image processing; Infrared detectors; Infrared devices; Intelligent systems; Touch screens; Infra-red sensor; Interactive system; Mean shift algorithm; Projection technology; Target trajectory; Human computer interaction",2-s2.0-85030859704
"Li J., He Q., Yang L., Shao C.","Pedestrian detection and counting in crowded scenes",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026774443&doi=10.1007%2f978-981-10-3551-7_39&partnerID=40&md5=28dd4851662517e766756dd52bacdb20","Pedestrians are the most essential and important component of traffic systems. The pedestrian injury and fatality rates are at a high level due to the severe traffic crashes. Therefore, effective strategies should be implemented to enhance pedestrian safety. However, there is a lack of feasible methods to collect pedestrian data for pedestrian safety study. And the effectiveness of the existing methods may decrease along with the increasing complexity of the traffic system. To ensure pedestrian safety even in crowded scenes, a head-based pedestrian detection and counting method is proposed in this paper to capture the data of pedestrians. From the test results, several important attributes such as crowd density, location, and speed can be obtained. Instead of collecting the full bodies of pedestrians, human heads are used in our study to avoid the occlusion problem happened in crowded scenes. After setting the detection region, head detection is started by applying mixed color algorithm to locate candidate head area and then using Canny algorithm and Hough transform to extract target contour and locate head precisely. Finally, the minimum distance method is utilized to match and count the effective heads. The detection results compared with manual count indicate its extremely accurate performance. This method demonstrates the proposed approach which is useful and effective for crowded pedestrian detection and counting, and can be applied in real-world traffic system to detect pedestrians and prevent pedestrian accidents. © Springer Science+Business Media Singapore 2018.","Canny algorithm; Crowded scenes; Hough transform; Mixed color algorithm; Pedestrian detection","Hough transforms; Intelligent systems; Intelligent vehicle highway systems; Transportation; Accurate performance; Canny algorithm; Crowded scenes; Minimum distance; Occlusion problems; Pedestrian accidents; Pedestrian detection; Pedestrian injuries; Pedestrian safety",2-s2.0-85026774443
"Oveisi E., Letouzey A., De Zanet S., Lucas G., Cantoni M., Fua P., Hébert C.","Stereo-vision three-dimensional reconstruction of curvilinear structures imaged with a TEM",2018,"Ultramicroscopy",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028920642&doi=10.1016%2fj.ultramic.2017.08.010&partnerID=40&md5=4cbc3d8e1cc5f6134cb29b4a1de41923","Deriving accurate three-dimensional (3-D) structural information of materials at the nanometre level is often crucial for understanding their properties. Tomography in transmission electron microscopy (TEM) is a powerful technique that provides such information. It is however demanding and sometimes inapplicable, as it requires the acquisition of multiple images within a large tilt arc and hence prolonged exposure to electrons. In some cases, prior knowledge about the structure can tremendously simplify the 3-D reconstruction if incorporated adequately. Here, a novel algorithm is presented that is able to produce a full 3-D reconstruction of curvilinear structures from stereo pair of TEM images acquired within a small tilt range that spans from only a few to tens of degrees. Reliability of the algorithm is demonstrated through reconstruction of a model 3-D object from its simulated projections, and is compared with that of conventional tomography. This method is experimentally demonstrated for the 3-D visualization of dislocation arrangements in a deformed metallic micro-pillar. © 2017","3-D reconstruction; Curvilinear structures; Dislocations; Stereo-vision; TEM","Dislocations (crystals); High resolution transmission electron microscopy; Image acquisition; Image reconstruction; Stereo image processing; Stereo vision; Tomography; Transmission electron microscopy; 3D reconstruction; 3D Visualization; Curvilinear structures; Dislocation arrangement; Novel algorithm; Structural information; Three-dimensional reconstruction; Threedimensional (3-d); Three dimensional computer graphics; algorithm; Article; image analysis; image display; image processing; image reconstruction; reliability; three dimensional imaging; transmission electron microscopy",2-s2.0-85028920642
"Ding T., Yao L., Li F.","A multi-uncertainty-set based two-stage robust optimization to defender–attacker–defender model for power system protection",2018,"Reliability Engineering and System Safety",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029149053&doi=10.1016%2fj.ress.2017.08.020&partnerID=40&md5=3562c99c827cb2fd4dc784c3dd603661","To handle rapidly growing threats from deliberate attacks, the critical components in power grid should be identified and protected. This paper proposed a defender–attacker–defender model to deal with power grid protection problem, in which the uncertain attacks and load types are considered. Furthermore, multiple uncertainty sets are introduced to characterize the possible realizations of disruptions caused by attackers, and the probabilities of the multiple uncertainty sets are estimated using analytic hierarchy process. Then, the problem is formulated as a multi-uncertainty-set based two-stage robust optimization model which can be termed as a mixed-integer tri-level programming and solved by column-and-constrains generation algorithm with a master-subproblem framework. The test results on a standard IEEE RTS 24-bus system show the effectiveness of the proposed model by considering multiple uncertainty sets and load types. © 2017","Analytic hierarchy process; Column-and-constrains generation algorithm; Defender–attacker–defender; Multi-uncertainty-set; Power grid protection; Robust optimization","Analytic hierarchy process; Electric power transmission networks; Integer programming; Optimization; Uncertainty analysis; Critical component; Generation algorithm; Mixed integer; Multi-uncertainties; Power grids; Power system protection; Robust optimization; Robust optimization models; Electric power system protection",2-s2.0-85029149053
"Kallel F., Mezghani A., Kanoun S., Kherallah M.","A novel arabic writer identification system using texture feature on multi-resolution levels",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028635673&doi=10.1007%2f978-3-319-60834-1_35&partnerID=40&md5=5a4f1f5727dc0702cd38d93a5cac2afe","Recognizing an Arabic text with OCR is a complex task caused by the cursive nature of Arabic script. The Arabic letters change forms not only according to their position in the word, but also according to their font in printed text and to their writer in handwritten text. In fact developing a font recognition system or a writer identification system as a pre-recognition step has become a necessity for Arabic text recognition. In this paper, we present an Arabic script recognition system using Curvelet transform for feature extraction in multi-resolution levels. Also, we used a best feature selection algorithm to increase the feature vector size. To validate our proposed system, we tested our system on Arabic handwriting text database ‘KHATT’ using SVM classification. This experiment show a very interesting results. © 2018, Springer International Publishing AG.","Arabic writer identification; Best feature selection algorithm; Curvelet transform; KHATT database; Steerable pyramid; SVM","Classification (of information); Feature extraction; Image retrieval; Optical character recognition; Text processing; Arabic handwriting; Arabic text recognition; Curvelet transforms; Feature selection algorithm; Recognition systems; Steerable pyramids; SVM classification; Writer identification; Character recognition",2-s2.0-85028635673
"Deng L., Ding J., Liu Y., Wei C.","Regression analysis for the proportional hazards model with parameter constraints under case-cohort design",2018,"Computational Statistics and Data Analysis",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029664061&doi=10.1016%2fj.csda.2017.08.013&partnerID=40&md5=c5a3e65e03d35a7ffb96171c8561a8a6","To reduce the cost and improve the efficiency of cohort studies, case-cohort design is a widely used biased-sampling scheme for time-to-event data. In modeling process, case-cohort studies can benefit further from taking parameters’ prior information, such as the histological type and disease stage of the cancer in medical, the liquidity and market demand of the enterprise in finance. Regression analysis of the proportional hazards model with parameter constraints under case-cohort design is studied. Asymptotic properties are derived by applying the Lagrangian method based on Karush–Kuhn–Tucker conditions. The consistency and asymptotic normality of the constrained estimator are established. A modified minorization–maximization algorithm is developed for the calculation of the constrained estimator. Simulation studies are conducted to assess the finite-sample performance of the proposed method. An application to a Wilms tumor study demonstrates the utility of the proposed method in practice. © 2017","Case-cohort design; Constrained estimation; Karush–Kuhn–Tucker conditions; Minorization–maximization algorithm; Proportional hazards model","Lagrange multipliers; Regression analysis; Sampling; Asymptotic properties; COHORT design; Constrained estimation; Constrained estimators; Finite sample performance; Maximization algorithm; Parameter constraints; Proportional hazards model; Hazards",2-s2.0-85029664061
"Dan D.-H., Xia Y., Xu B., Han F., Yan X.-F.","Multistep and Multiparameter Identification Method for Bridge Cable Systems",2018,"Journal of Bridge Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032393560&doi=10.1061%2f%28ASCE%29BE.1943-5592.0001145&partnerID=40&md5=8c60b04a0d0da07b7c45194918e6669b","Because complex cable systems are widely used in engineering practice, the issues related to parameter identification of complex cable systems are becoming increasingly important. In this study, a universal characteristic frequency equation, considering boundary conditions, various lateral forces, and multiple factors pertaining to cables simultaneously, was established for a class of cable systems installed with intermediate lateral components. The optimization model corresponding to the equation was established to transform the root-finding problem of the complicated transcendental equation into a relatively simple parameter identification and optimization problem. Thereafter, a parameter identification scheme for complicated cable systems was proposed using the particle swarm optimization algorithm. Through experimental tests using a full-scale cable-damper system, a detailed multistep, multiparameter identification program was presented for complex cable systems. The experimental results, achieved effectively using the proposed method, indicate a significant reduction in parameter identification errors and improvement in identification quality. © 2017 American Society of Civil Engineers.","Characteristics frequency equation; Complex cable system; Parameter identification; Particle swarm optimization (PSO) algorithm","Cables; Identification (control systems); Optimization; Particle swarm optimization (PSO); Software testing; Cable systems; Characteristic frequencies; Frequency equation; Identification method; Optimization modeling; Optimization problems; Particle swarm optimization algorithm; Transcendental equations; Parameter estimation",2-s2.0-85032393560
"Cabrera G. G., Ehrgott M., Mason A.J., Raith A.","A matheuristic approach to solve the multiobjective beam angle optimization problem in intensity-modulated radiation therapy",2018,"International Transactions in Operational Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954305328&doi=10.1111%2fitor.12241&partnerID=40&md5=8d2cd8d4653e88c7e16e24ed29f21572","Selecting a suitable set of beam angles is an important but difficult task in intensity-modulated radiation therapy (IMRT) for cancer treatment. From a single objective point of view, this problem, known as the beam angle optimization (BAO) problem, is solved by finding a beam angle configuration (BAC) that leads to the best dose distribution, according to some objective function. As there exists a trade-off between the main goals in IMRT (to irradiate the tumor according to some prescription and to avoid surrounding healthy tissue), it makes sense to solve this problem from a multiobjective (MO) point of view. When doing so, a solution of the BAO problem is no longer a single BAC, but instead a set of BACs that lead to a set of dose distributions that, depending on both dose prescription and physician preferences, can be selected as the preferred treatment. We solve this MO problem using a two-phase strategy. During the first phase, a deterministic local search algorithm is used for selecting a set of locally optimal BACs, according to a single-objective function. During this search, an optimal dose distribution for each BAC, with respect to the single-objective function, is calculated using an exact nonlinear programming algorithm. During the second phase, a set of nondominated points is generated for each promising locally optimal BAC and a dominance analysis among them is performed. The output of the procedure is a set of (approximately) efficient BACs that lead to good dose distributions. To demonstrate the viability of the method, the two-phase strategy is applied to a prostate case. © 2016 The Authors. International Transactions in Operational Research © 2016 International Federation of Operational Research Societies","deterministic local search; intensity-modulated radiation therapy; mathematical programming; multiobjective beam angle optimization","Economic and social effects; Local search (optimization); Mathematical programming; Multiobjective optimization; Nonlinear programming; Optimization; Problem solving; Beam angle optimization; Intensity modulated radiation therapy; Local search; Local search algorithm; Non-dominated points; Nonlinear programming algorithm; Objective functions; Physician preferences; Radiotherapy",2-s2.0-84954305328
"Xiao Y., Wu J., Lin Z., Zhao X.","A deep learning-based multi-model ensemble method for cancer prediction",2018,"Computer Methods and Programs in Biomedicine",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030330677&doi=10.1016%2fj.cmpb.2017.09.005&partnerID=40&md5=8db9734a18127c7d7bde0c5008d9136e","Background and Objective: Cancer is a complex worldwide health problem associated with high mortality. With the rapid development of the high-throughput sequencing technology and the application of various machine learning methods that have emerged in recent years, progress in cancer prediction has been increasingly made based on gene expression, providing insight into effective and accurate treatment decision making. Thus, developing machine learning methods, which can successfully distinguish cancer patients from healthy persons, is of great current interest. However, among the classification methods applied to cancer prediction so far, no one method outperforms all the others. Methods: In this paper, we demonstrate a new strategy, which applies deep learning to an ensemble approach that incorporates multiple different machine learning models. We supply informative gene data selected by differential gene expression analysis to five different classification models. Then, a deep learning method is employed to ensemble the outputs of the five classifiers. Results: The proposed deep learning-based multi-model ensemble method was tested on three public RNA-seq data sets of three kinds of cancers, Lung Adenocarcinoma, Stomach Adenocarcinoma and Breast Invasive Carcinoma. The test results indicate that it increases the prediction accuracy of cancer for all the tested RNA-seq data sets as compared to using a single classifier or the majority voting algorithm. Conclusions: By taking full advantage of different classifiers, the proposed deep learning-based multi-model ensemble method is shown to be accurate and effective for cancer prediction. © 2017 Elsevier B.V.","Cancer prediction; Deep learning; Feature selection; Gene expression; Multi-model ensemble","Artificial intelligence; Bioinformatics; Classification (of information); Decision making; Deep learning; Diseases; Feature extraction; Forecasting; Genes; Learning systems; RNA; Cancer prediction; Differential gene expressions; High-throughput sequencing; Machine learning methods; Machine learning models; Majority voting algorithm; Multi-model ensemble; Treatment decision makings; Gene expression; Article; breast carcinoma; cancer staging; classification algorithm; classifier; computer model; computer prediction; decision tree; gene expression; human; k nearest neighbor; lung adenocarcinoma; machine learning; malignant neoplasm; random forest; RNA sequence; stomach adenocarcinoma; support vector machine",2-s2.0-85030330677
"Serrano González J., Burgos Payán M., Riquelme Santos J.M.","Optimal design of neighbouring offshore wind farms: A co-evolutionary approach",2018,"Applied Energy",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032784690&doi=10.1016%2fj.apenergy.2017.10.120&partnerID=40&md5=2cbb19532432119214ccfc3138b12939","This paper presents a new approach for the optimization of neighbouring offshore wind farms. Offshore wind energy is one of the most promising and developed low-carbon generation technologies. However, the high capital costs, which are strongly dependent on seabed depth, currently limit the geographical expansion of this technology to areas with relatively shallow waters and appropriate wind resource. This, along with the advantages of sharing a submarine transmission system among several projects, leads to a high concentration of offshore wind farms in certain zones, as happens, for example, in the North Sea. The presence of other neighbouring offshore wind farms has to be taken into account when a developer plans a new project, since the wake effect of wind turbines belonging to other neighbouring wind farms will affect the annual energy production and, consequently, the profitability of the project under study. However, not only already operating or installed neighbouring projects have to be borne in mind, but also the possible design of future neighbouring wind farms yet to be developed. In order to tackle this issue, an innovative co-evolutionary algorithm is proposed in this paper with the objective of determining a Nash equilibrium solution that would provide the best possible configuration of the wind farm under study by taking into account and limiting the disturbance introduced by other neighbouring projects. The performance of the proposed methodology has been successfully tested through the analysis of a realistic case and compared with other collaborative approaches and the classic single-project optimization methods already existing in the literature. © 2017 Elsevier Ltd","Co-evolutionary algorithm; Games theory; Genetic algorithm; Micro-siting; Neighbouring offshore wind farm",,2-s2.0-85032784690
"Lv L., Han C., Zhang L.","Solutions to periodic sylvester matrix equations based on matrices splitting",2018,"Journal of Computational Analysis and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027311879&partnerID=40&md5=0635e1aff0ff88c2b52824522a308966","New iterative algorithms are introduced to solve periodic Sylvester matrix equations in this paper. The iterative algorithms are based on the principle of matrix splitting and gradient iteration method. Detailed iterative steps for solving equations are presented and their convergence property are strictly verified. A numerical test is employed to prove the correctness and effectiveness of the iterative algorithms. © 2018 by Eudoxus Press, LLC. All rights reserved.","Iterative algorithm; Matrix splitting; Periodic Sylvester matrix equations",,2-s2.0-85027311879
"Gashkov S., Frolov A.","Comparative analysis of calculations in cryptographic protocols using a combination of different bases of finite fields",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020783109&doi=10.1007%2f978-3-319-59415-6_16&partnerID=40&md5=7aa23d71003897081ecf5d8f8f58a5b6","The chapter introduces a comparative analysis of the complexity of the Tate pairing operation on a supersingular elliptic curve and the complexity of the final exponentiation in the tripartite key agreement cryptographic protocol. The analysis takes into account a possibility of using different bases of finite fields in combination. Operations of multiplication and multiple squaring in the field GF(2n) and its 4-degree extension, of Tate pairing on supersingular elliptic curve and of final exponentiation are considered separately and in combination. We conclude that the best complexity bound for the pairing and the final exponentiation in the cryptographically significant field GF(2191) is provided by the combination of the polynomial basis of this field and 1-type optimal basis of the field expansion. © Springer International Publishing AG 2018.","Algorithm with square root extraction; Algorithm without square root extraction; Combination of bases; Extension of finite field; Final exponentiation; Finite field; Optimal normal basis; Supersingular elliptic curve; Tate pairing","Cryptography; Extraction; Geometry; Public key cryptography; Combination of bases; Exponentiations; Finite fields; Optimal normal basis; Square root extractions; Supersingular elliptic curve; Tate pairing; Program processors",2-s2.0-85020783109
"Yuan S., Yang Y., Liu X., Zhou X., Wei Z.","Optical image transformation and encryption by phase-retrieval-based double random-phase encoding and compressive ghost imaging",2018,"Optics and Lasers in Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026916624&doi=10.1016%2fj.optlaseng.2017.07.015&partnerID=40&md5=5ac370b9bbc1713b597b8d1c979f5cbf","An optical image transformation and encryption scheme is proposed based on double random-phase encoding (DRPE) and compressive ghost imaging (CGI) techniques. In this scheme, a secret image is first transformed into a binary image with the phase-retrieval-based DRPE technique, and then encoded by a series of random amplitude patterns according to the ghost imaging (GI) principle. Compressive sensing, corrosion and expansion operations are implemented to retrieve the secret image in the decryption process. This encryption scheme takes the advantage of complementary capabilities offered by the phase-retrieval-based DRPE and GI-based encryption techniques. That is the phase-retrieval-based DRPE is used to overcome the blurring defect of the decrypted image in the GI-based encryption, and the CGI not only reduces the data amount of the ciphertext, but also enhances the security of DRPE. Computer simulation results are presented to verify the performance of the proposed encryption scheme. © 2017 Elsevier Ltd","Double random-phase encoding; Ghost imaging; Phase-retrieval algorithm","Binary images; Encoding (symbols); Geometrical optics; Imaging techniques; Signal encoding; Compressive sensing; Decryption process; Double random-phase encoding; Encryption schemes; Encryption technique; Ghost imaging; Phase retrieval; Phase retrieval algorithm; Cryptography",2-s2.0-85026916624
"Douzas G., Bacao F.","Effective data generation for imbalanced learning using conditional generative adversarial networks",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029534844&doi=10.1016%2fj.eswa.2017.09.030&partnerID=40&md5=a3f6a29e46545d1b4f41bece0ca36e08","Learning from imbalanced datasets is a frequent but challenging task for standard classification algorithms. Although there are different strategies to address this problem, methods that generate artificial data for the minority class constitute a more general approach compared to algorithmic modifications. Standard oversampling methods are variations of the SMOTE algorithm, which generates synthetic samples along the line segment that joins minority class samples. Therefore, these approaches are based on local information, rather on the overall minority class distribution. Contrary to these algorithms, in this paper the conditional version of Generative Adversarial Networks (cGAN) is used to approximate the true data distribution and generate data for the minority class of various imbalanced datasets. The performance of cGAN is compared against multiple standard oversampling algorithms. We present empirical results that show a significant improvement in the quality of the generated data when cGAN is used as an oversampling algorithm. © 2017","Artificial data; GAN; Imbalanced learning; Minority class","Information systems; Mathematical models; Adversarial networks; Artificial data; Class distributions; Classification algorithm; Imbalanced Data-sets; Imbalanced Learning; Minority class; Multiple standards; Classification (of information)",2-s2.0-85029534844
"Veneti A., Konstantopoulos C., Pantziou G.","Evolutionary computation for the ship routing problem",2018,"Intelligent Systems Reference Library",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029432224&doi=10.1007%2f978-3-319-61801-2_4&partnerID=40&md5=fb746d0aa3e4a5df10c9ba118e1f133d","In this chapter, we present evolutionary algorithms for solving the real time ship weather routing problem. The objectives to be minimized are the mean total risk and fuel cost incurred along the obtained route while considering the time-varying sea and weather conditions and also a constraint on the total passage time of the route. In addition, for achieving a high safety level the proposed approaches should return only solutions compliant with the guidelines of the International Maritime Organization (IMO). Two different well-known genetic algorithms, namely SPEA2 and NSGA-II are applied to the ship routing problem and a comparative performance evaluation of the two algorithms is performed. The proposed approaches are tested on real data and compared with an exact algorithm which solves the same problem. © Springer International Publishing AG 2018.","Label setting algorithm; Multi-criteria optimization; Resource-constrained shortest path; Time dependent networks",,2-s2.0-85029432224
"Hajjem M., Bouziri H., Talbi E.-G.","A metaheuristic framework for dynamic network flow problems",2018,"Operations Research/ Computer Science Interfaces Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032630195&doi=10.1007%2f978-3-319-58253-5_16&partnerID=40&md5=73103c705cda30d6379c0c2878eaeb73","Dynamic network problems is a very interesting topic in modeling real life situations where we aim to send some flow to a given destination within time dependent parameters. This can occur in many applications such in evacuation of people or vehicules in emergency time. The majority of existing algorithms are based on mathematical approximations. However, this work proposes another technique based on metaheuristics. A general framework is provided in both single and population based algorithms. Therefore, basic search techniques are proposed such as the crossover or the mutation. Moreover, solution representations are given within a general metaheuristical scheme. In addition, we assess a genetic algorithm by an experimental study is conducted on a case study of a building evacuation. © Springer International Publishing AG 2018.","Dynamic flow problem; Evacuation; Genetic algorithm; Metaheuristic",,2-s2.0-85032630195
"Fakhfakh F., Tounsi M., Mosbah M., Méry D., Kacem A.H.","A formal approach for maintaining forest topologies in dynamic networks",2018,"Studies in Computational Intelligence",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020440516&doi=10.1007%2f978-3-319-60170-0_9&partnerID=40&md5=a8016ce848670f8ae83c8be723b4dec7","In this paper, we focus on maintaining a forest of spanning trees in dynamic networks. In fact, we propose an approach based on two levels for specifying and proving distributed algorithms in a forest. The first level allows us to control the dynamic structure of the network by triggering a maintenance operation when the forest is altered. To do so, we develop a formal pattern using the Event- B method, based on the refinement technique. The proposed pattern relies on the dynamicity aware-graph relabeling systems (DA-GRS) which is an existing model for building and maintaining a spanning forest in dynamic networks. It is based on evolving graphs as a powerful model to record the evolution of a network topology. The second level of our approach deals with distributed algorithms which can be applied to spanning trees of the forest. Through an example of a leader election algorithm, we illustrate our pattern. The proof statistics show that our solution can save efforts on specifying as well as proving the correctness of distributed algorithms in a forest topology. © Springer International Publishing AG 2018.",,"Network architecture; Dynamic structure; Event-b methods; Evolving graphs; Graph relabeling systems; Leader election algorithm; Maintenance operations; Network topology; Refinement techniques; Topology",2-s2.0-85020440516
"Chen Y., Marek G.W., Marek T.H., Brauer D.K., Srinivasan R.","Improving SWAT auto-irrigation functions for simulating agricultural irrigation management using long-term lysimeter field data",2018,"Environmental Modelling and Software",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031713081&doi=10.1016%2fj.envsoft.2017.09.013&partnerID=40&md5=987c1c84944a747362b647759225209d","Decreasing groundwater availability in the Texas High Plains has resulted in the widespread adoption of management allowed depletion (MAD) irrigation scheduling. Modeling of such practices and their effects on water balance components can be a cost-effective and time-saving alternative to field-based research. However, studies have identified deficiencies in the auto-irrigation algorithms in the Soil and Water Assessment Tool (SWAT) including the continuation of irrigation during the non-growing season and an inability to simulate growth stage-specific irrigation. Consequently, new and representative auto-irrigation algorithms were developed using 1) a uniform, single season MAD and 2) a growth stage-specific MAD with options for seasonal growth stage partitioning based on scheduled date and accumulated heat units. Comparisons with observed data from an irrigated lysimeter field showed improved model performance for simulations of irrigation amount and frequency and actual evapotranspiration. Minimal differences in leaf area index and yield were observed with the non-water stressed management. © 2017 Elsevier Ltd","Actual evapotranspiration (ET); Auto-irrigation; Crop leaf area index (LAI); Heat units; Management allowed depletion (MAD); Soil water deficit","Cost effectiveness; Evapotranspiration; Groundwater; Lysimeters; Plants (botany); Rain; Scheduling; Soil moisture; Soil surveys; Actual evapotranspiration; Agricultural irrigation; Heat units; Irrigation scheduling; Leaf Area Index; Soil and water assessment tool; Soil water deficit; Water balance components; Irrigation; agricultural management; algorithm; data set; evapotranspiration; groundwater; leaf area index; lysimeter; soil and water assessment tool; soil water; water availability; water budget; Great Plains; Texas; United States",2-s2.0-85031713081
"Gulde P., Hermsdörfer J.","A Comparison of Smoothing and Filtering Approaches Using Simulated Kinematic Data of Human Movements",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029592772&doi=10.1007%2f978-3-319-67846-7_10&partnerID=40&md5=98490efd7937b93e9b54ab76797bea31","Gathered kinematic data usually requires post-processing in order to handle noise. There a three different approaches frequently used: local regression & moving average algorithms, and Butterworth filters. In order to examine the most appropriate post-processing approach and its optimal settings to human upper limb movements, we examined how far the approaches were able to reproduce a simulated movement signal with overlaid noise. We overlaid a simulated movement signal (movement amplitude 80 cm) with normal distributed noise (standard deviation of 0.5 cm). The resulting signal was post-processed with local regression and moving average algorithms as well as Butterworth filters with different settings (spans/orders). The deviation from the original simulated signal in four kinematic parameters (path length, maximum velocity, relative activity, and spectral arc length) was calculated and checked for a minimum. The unprocessed noisy signal showed absolute mean deviations of 54.78% ± 12.16% in the four kinematic parameters. The local regression algorithm revealed the best performance at a span of 420 ms with an absolute mean deviation of 2.00% ± 0.86%. For spans between 280–690 ms the local regression algorithm still revealed deviations below 5%. Based on our results we suggest a local regression algorithm with a span of 420 ms for smoothing noisy kinematic data in upper limb performance, e.g., activities of daily living. This suggestion applies to kinematic data of human movements. © 2018, Springer International Publishing AG.","Filtering; Human movement; Kinematics; Simulation; Smoothing","Butterworth filters; Filtration; Regression analysis; Sports; Activities of Daily Living; Human movements; Kinematic parameters; Moving-average algorithm; Relative activities; Simulation; Smoothing; Standard deviation; Kinematics",2-s2.0-85029592772
"Kotenko I., Saenko I., Ageev S.","Fuzzy adaptive routing in multi-service computer networks under cyber attack implementation",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031401801&doi=10.1007%2f978-3-319-68321-8_22&partnerID=40&md5=6a43fbc39de50258edba2f23490c704b","Multi-service computer networks (MSCN) play an important role in the modern society life. However, design of MSCN is a rather complex challenge. Development of adaptive routing algorithms, which consider the failures of nodes and communication lines because of the impact of the computer attacks, holds a specific place in MSCN design. The paper offers a new approach to adaptive routing in MSCN based on a combined use of the multi-path routing of data streams and the integral criterion, which is based on fuzzy assessment of network states. The algorithm based on this approach considers additional routing metrics, i.e. the level of information security, the technical state of network elements and the packet loss probability. The experimental assessment of the offered algorithm of fuzzy adaptive routing showed that in the conditions of high level impact of computer attacks the gain in the time of message delay is improved by 2–4 times. It testifies about higher performance of the proposed algorithm in comparison with known algorithms. © Springer International Publishing AG 2018.","Adaptive routing; Cyber attacks; Fuzzy logical inference; Multi-service computer network","Computer networks; Crime; Network routing; Network security; Security of data; Adaptive routing; Adaptive routing algorithm; Communication lines; Cyber-attacks; Experimental assessment; Fuzzy logical; Multi-services; Packet loss probability; Computer crime",2-s2.0-85031401801
"Tayanov V., Krzyżak A., Suen C.","Some properties of consensus-based classification",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019243805&doi=10.1007%2f978-3-319-59162-9_29&partnerID=40&md5=cd6cfc685849f050383d197da0a7a634","The objective of this paper is to consider some properties of decisions produced by classifiers that are in consensus. Consensus allows strong classifiers to obtain very reliable classification on the objects on which consensus has been reached. For those ones where consensus is not reached the reclassification procedure should be applied based on other classification algorithms. Properties of different consensuses are described using algebraic approach and performance evaluation routine. © Springer International Publishing AG 2018.",,"Computer programming; Algebraic approaches; Classification algorithm; Strong classifiers; Computer science",2-s2.0-85019243805
"Carboni A.P., Simas H., Martins D.","Analysis of self-aligning mechanisms by means of matroid theory",2018,"Mechanisms and Machine Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031284465&doi=10.1007%2f978-3-319-67567-1_6&partnerID=40&md5=9a7f3d11fac2e18831a837c363b72f9d","This papers deals with the investigation of the linear dependence and independence of freedoms and constraints in a given mechanism by the application of matroid theory. A new and original approach, based on matroid theory, is proposed and applied for solving two different problems of mechanism: enumeration and selection of self-aligning mechanism kinematically equivalent to a given mechanism. Two novel algorithms are presented and examples of application are provided. © 2018, Springer International Publishing AG.","Matroid; Mechanism; Overconstraint; Self-aligning","Matrix algebra; Mechanisms; Linear dependence; Matroid theory; Novel algorithm; Over-constraint; Self-aligning; Combinatorial mathematics",2-s2.0-85031284465
"Raza M.S., Qamar U.","Feature selection using rough set-based direct dependency calculation by avoiding the positive region",2018,"International Journal of Approximate Reasoning",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031769533&doi=10.1016%2fj.ijar.2017.10.012&partnerID=40&md5=79971d704482683de442bdad55c1bdcd","Feature selection is the process of selecting a subset of features from the entire dataset such that the selected subset can be used on behalf of the entire dataset to reduce further processing. There are many approaches proposed for feature selection, and recently, rough set-based feature selection approaches have become dominant. The majority of such approaches use attribute dependency as criteria to determine the feature subsets. However, this measure uses the positive region to calculate dependency, which is a computationally expensive job, consequently effecting the performance of feature selection algorithms using this measure. In this paper, we have proposed a new heuristic-based dependency calculation method. The proposed method comprises a set of two rules called Direct Dependency Calculation (DDC) to calculate attribute dependency. Direct dependency calculates the number of unique/non-unique classes directly by using attribute values. Unique classes define accurate predictors of class, while non-unique classes are not accurate predictors. Calculating unique/non-unique classes in this manner lets us avoid the time-consuming calculation of the positive region, which helps increase the performance of subsequent algorithms. A two-dimensional grid was used as an intermediate data structure to calculate dependency. We have used the proposed method with a number of feature selection algorithms using various publically available datasets to justify the proposed method. A comparison framework was used for analysis purposes. Experimental results have shown the efficiency and effectiveness of the proposed method. It was determined that execution time was reduced by 63% for calculation of the dependency using DDCs, and a 65% decrease was observed in the case of feature selection algorithms based on DDCs. The required runtime memory was decreased by 95%. © 2017 Elsevier Inc.","Dependency rules; Feature selection; Positive region; Reducts; Rough set theory","Feature extraction; Heuristic methods; Attribute values; Dependency rules; Feature selection algorithm; Feature subset; Positive region; Reducts; Rough-set based; Two-dimensional grids; Rough set theory",2-s2.0-85031769533
"Sarhani M., El Afia A., Faizi R.","Facing the feature selection problem with a binary PSO-GSA approach",2018,"Operations Research/ Computer Science Interfaces Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032615163&doi=10.1007%2f978-3-319-58253-5_26&partnerID=40&md5=45163b8637f55b8af04f902f4f33afc2","Feature selection has become the focus of much research in many areas where we can face the problem of big data or complex relationship among features. Metaheuristics have gained much attention in solving many practical problems, including feature selection. Our contribution in this paper is to propose a binary hybrid metaheuristic to minimize a fitness function representing a trade-off between the classification error of selecting the feature subset and the corresponding number of features. This algorithm combines particle swarm optimization (PSO) and gravitational search algorithm (GSA). Also, a mutation operator is integrated to enhance population diversity. Experimental results on ten benchmark dataset show that our proposed hybrid method for feature selection can achieve high performance when comparing with other metaheuristic algorithms and well-known feature selection approaches. © Springer International Publishing AG 2018.","Feature selection; Gravitational search algorithm; Machine learning; Metaheuristics; Particle swarm optimization",,2-s2.0-85032615163
"García F., Prioletti A., Cerri P., Broggi A.","PHD filter for vehicle tracking based on a monocular camera",2018,"Expert Systems with Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029532206&doi=10.1016%2fj.eswa.2017.09.018&partnerID=40&md5=c87f6f58e9622bf451dabab24e957be1","Novel advance driver assistance systems, such as emergency braking and adaptive cruise control require the most reliable detection algorithms. Furthermore, in the recent years, the use of computer vision approaches in these type of applications is becoming more frequent. However, when dealing with these technologies, reliability is a very important factor that still requires improvement. On this paper, it is presented a tracking algorithm which aims in improving the accuracy of these applications, based on computer vision and modern Probability Hypothesis Density (PHD) Filter technique. The tracking is performed on the features detected within the bounding box provided by a computer video based vehicle detection algorithm. The features tracked are combined in a last stage, providing accurate monocular camera tracking. Test provided, allowed to identify the best method for feature combination. Furthermore, it was proved that under the proper visibility conditions, the PHD filter design is able to improve current methods such as Unscented Kalman Filter. © 2017 Elsevier Ltd","Computer vision; PHD filter; Vehicle detection; Vehicle tracking","Adaptive control systems; Adaptive cruise control; Automobile drivers; Bandpass filters; Cameras; Kalman filters; Signal detection; Stereo vision; Tracking (position); Vehicles; Driver assistance system; Feature combination; PHD filters; Probability hypothesis density filter; Tracking algorithm; Unscented Kalman Filter; Vehicle detection; Visibility conditions; Computer vision",2-s2.0-85029532206
"Li K., Ran R., Song S., Wang J., Wang L.","Spacecraft electrical signal classification method of reliability test based on random forest",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028715162&doi=10.1007%2f978-981-10-6232-2_53&partnerID=40&md5=8dca3a2817ab93cc7a185a7e0a366b00","The spacecraft electrical signal characteristic data exist a large amount of data, high dimension features, computational complexity degree and low rate of identification problems. This paper proposes the feature extraction method based on wavelet de-noising and the classification method based on random forest (RF) algorithm. Considering the time complexity, the method of wavelet de-noising is used to compress the data and reduce the dimension and then applied to classification. The random forest algorithm has superior performance in dealing with the large amount of data. The experimental results show that compared with other algorithms, the proposed method shows excellent performance in accuracy, computational efficiency, stability in dealing with spacecraft electrical signal data. © Springer Nature Singapore Pte Ltd. 2018.","Electrical signal classification; RF; Spacecraft fault diagnosis","Computer aided diagnosis; Decision trees; Fault detection; Spacecraft; Systems engineering; Classification methods; Electrical signal; Feature extraction methods; High dimensions; Identification problem; Random forest algorithm; Reliability test; Wavelet denoising; Computational efficiency",2-s2.0-85028715162
"Yuan G., Sheng Z., Wang B., Hu W., Li C.","The global convergence of a modified BFGS method for nonconvex functions",2018,"Journal of Computational and Applied Mathematics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022335122&doi=10.1016%2fj.cam.2017.05.030&partnerID=40&md5=ba1b23893bbd1c7a2b862ab30d14f4bc","The standard BFGS method plays an important role among the quasi-Newton algorithms for constrained/un-constrained optimization problems. However, Dai (2003) constructed a counterexample to demonstrate that this method may fail for non-convex functions with inexact Wolfe line searches, and Mascarenhas (2004) showed the nonconvergence of this method and other methods in the Broyden family, even with exact line search techniques. These works motivate us to try to find another way to obtain another quasi-Newton method with better convergence based on the standard BFGS formula. In this paper, four approaches are used in the designed algorithm: (1) a modified weak Wolfe–Powell line search technique is introduced; (2) if one defined condition is satisfied, then the search direction and its associated step length are accepted, and the next point is designed; (3) otherwise, a parabolic will be presented, and it is regarded as the projection surface to avoid using the failed direction, and the next point xk+1 is generated by a projection technique; and (4) to easily obtain the global convergence of the proposed algorithm, the projection point is not used in the current BFGS update but rather for all the next iterations. The new algorithm possesses global convergence for general functions under the inexact modified weak Wolfe–Powell line search technique, and it is shown that other methods in the Broyden class also have this property. Numerical results are reported to show the performance of the given algorithm and other similar methods. © 2017 Elsevier B.V.","BFGS method; Global convergence; Optimization; Wolfe line search","Constrained optimization; Functions; Information analysis; Newton-Raphson method; Numerical methods; BFGS method; Global conver-gence; Line search technique; Optimization problems; Projection techniques; Quasi-newton algorithm; Quasi-Newton methods; Wolfe line searches; Optimization",2-s2.0-85022335122
"Cui J., Li P., Yue D., Jin Y., Liu Y., Liu Q.","Hybrid roadside devices placement for advertisement disseminations in vehicular CPS",2018,"Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031294740&doi=10.1007%2f978-3-319-66628-0_46&partnerID=40&md5=b5f4ddb7d3bf88c1cf1fe9c12ce729ac","There are two types of roadside devices for advertisement dissemination in the Vehicular Cyber-Physical Systems (VCPS), one is roadside units (RSUs) and the other is roadside access points (RAPs). The placement cost of RSUs is lower than RAPs. However, the coverage of RSUs is limited. In this paper, we investigate the hybrid roadside device placement problem in the Vehicular Cyber-Physical Systems (VCPS). Given the budget constraint and the distribution of traffic conditions, our goal is to optimize the deployment of the hybrid roadside device for the merchants to maximize their benefits from advertisement dissemination. With the purpose of all advertisement can be effectively served, we propose a corresponding hybrid greedy placement algorithm. Our algorithm not only obtains the more benefits, but also consider the placement cost. Finally, we evaluate the performance of our proposed algorithm. Extensive simulations show that the performance of our proposed algorithm is superior to the other algorithms. © 2018, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.","Advertisement dissemination; Roadside device placement; Vehicular Cyber-Physical Systems","Budget control; Cyber Physical System; Embedded systems; Access points; Advertisement dissemination; Budget constraint; Extensive simulations; Placement algorithm; Placement problems; Roadside units; Traffic conditions; Roadsides",2-s2.0-85031294740
"Rice I.","Improved data visualisation through nonlinear dissimilarity modelling",2018,"Pattern Recognition",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028072053&doi=10.1016%2fj.patcog.2017.07.016&partnerID=40&md5=ca719959e88cdfa26e0e807b5ad84bb8","Inherent to state-of-the-art dimension reduction algorithms is the assumption that global distances between observations are Euclidean, despite the potential for altogether non-Euclidean data manifolds. We demonstrate that a non-Euclidean manifold chart can be approximated by implementing a universal approximator over a dictionary of dissimilarity measures, building on recent developments in the field. This approach is transferable across domains such that observations can be vectors, distributions, graphs and time series for instance. Our novel dissimilarity learning method is illustrated with four standard visualisation datasets showing the benefits over the linear dissimilarity learning approach. © 2017","Dissimilarity; Multidimensional scaling; RBF network; Visualisation","Data visualization; Radial basis function networks; Dimension reduction algorithm; Dissimilarity; Dissimilarity measures; Learning approach; Learning methods; Multi-dimensional scaling; State of the art; Universal approximators; Visualization",2-s2.0-85028072053
"Lopez-Molina C., Montero J., Bustince H., De Baets B.","Gradient fusion operators for vector-valued image processing",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029408231&doi=10.1007%2f978-3-319-66824-6_38&partnerID=40&md5=00eb697a23790c27d97708d3db715f6a","While classical image processing algorithms were designed for scalar-valued (binary or grayscale) images, new technologies have made it commonplace to work with vector-valued ones. These technologies can involve new types of sensors, as in remote sensing, but also mathematical models leading to an increased cardinality at each pixel. This work analyzes the role of first-order differentiation in vector-valued images; specifically, we explore a novel operator to produce a 2D vector from a Jacobian matrix, in order to represent the variation in a vector-valued image as a planar feature. © 2018, Springer International Publishing AG.","Differentiation; Information fusion; Jacobian matrix; Vector-valued images","Differentiation (calculus); Fuzzy logic; Fuzzy sets; Image fusion; Information fusion; Jacobian matrices; Pattern matching; Remote sensing; Vectors; Cardinalities; First order; Fusion operator; Gray scale; Image processing algorithm; Vector valued; Vector-valued images; Image processing",2-s2.0-85029408231
"Popescu D.A., Domșa O., Bold N.","About the applications of the similarity of websites regarding HTML-based webpages",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029480307&doi=10.1007%2f978-3-319-62521-8_12&partnerID=40&md5=364eab001979b85ed5e68187a409b470","The study of the similarity between web applications has extended alongside with the informational explosion resulted from the fast communication means through Internet. The copyright of web applications is difficult to be appreciated in this domain and this is the reason for the development of novel web technologies and mechanisms of measuring the similarity between two webpages. In this paper, we will present a modality of measurement of the similarity degree between two webpages regarding the HTML tag-based webpages. The degree of similarity will be determined approximately, being dependent of the webpages used from the both websites and the tags set used in the comparison of the webpages. The selection of webpages in order to determine the degree of similarity between two webpages will be made using genetic algorithms. In the final part of the paper there are presented the results obtained with the implementation of the algorithm presented in the paper. © 2018, Springer International Publishing AG.","Algorithm; Chromosome; Gene; Similarity; Tag; Webpage",,2-s2.0-85029480307
"Guada C., Gómez D., Rodríguez J.T., Yáñez J., Montero J.","Graph approach in image segmentation",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029437975&doi=10.1007%2f978-3-319-66824-6_18&partnerID=40&md5=f391e97e5bc8f0e19730e88efc6e1262","In this paper we discuss about graph approach in image segmentation. In first place, some main image processing techniques are classified based upon the output these methods provide. Then, a fuzzy image segmentation definition is presented because in the literature review was found that it was not clearly defined. This definition of fuzzy image segmentation is then related to a hierarchical image segmentation procedure, so this concept is also formally defined in this work. As every output of an image processing algorithm has to be evaluated, then a method to evaluate a hierarchical segmentation output is proposed in order to later propose a method to evaluate a fuzzy image segmentation output. Computational experiences point to some advantages of the proposed hierarchical image segmentation procedure over other algorithms. © 2018, Springer International Publishing AG.","Benchmarking; Edge detection; Fuzzy sets; Graph approach; Hierarchical segmentation","Benchmarking; Computation theory; Edge detection; Fuzzy logic; Fuzzy sets; Image processing; Pattern matching; Fuzzy image segmentation; Graph approach; Hierarchical segmentation; Image processing algorithm; Image processing technique; Literature reviews; Segmentation procedure; Image segmentation",2-s2.0-85029437975
"Stasiak M.D.","Modelling of currency exchange rates using a binary-wave representation",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029542392&doi=10.1007%2f978-3-319-67223-6_3&partnerID=40&md5=fe29cba28b4c431f96a8b8c062042b44","Exchange rate of a currency pair can be visualized in a binary representation. Binarization algorithm transforms the course trajectory represented by tick data into an appropriate binary string. This kind of representation allows for a far more precise analysis and can be applied in HFT systems. In the following article a state model for exchange rate in binary representation with use of wave relations is proposed. In the model, states corresponding to particular price change patterns and wave types were defined. The wave detection process uses respective algorithms of wave detection in binary representation. In the article, research was performed for EUR/SEK currency pair with main focus on the possible application of abovementioned model in creating a HFT system with a positive rate of return. © 2018, Springer International Publishing AG.","Currency market investment decision support; Exchange rate modeling; Foreign exchange market; High frequency econometric; Technical analysis","Commerce; Decision support systems; Earnings; Economics; Electronic trading; Finance; Financial markets; Information systems; Investments; Signal detection; Binarization algorithm; Binary representations; Currency exchange rates; Exchange rates; High frequency HF; Investment decisions; Precise analysis; Technical analysis; Bins",2-s2.0-85029542392
"Cao X.-L., Xi X.-Q.","A Method to Evaluate the Research Direction of University",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030848321&doi=10.1007%2f978-3-319-68527-4_17&partnerID=40&md5=5a00511b062cc4aa54f9ed57dc97bd2e","The era is changing from information technology to data technology, big data is used very well in the field of financial, medical, e-commerce and so on, but not very well in the field of education. The idea of “Data - driven schools, analysis of change education” make the need for the educational data mining more and more prominent. Data mining in education can help us to connect the relevant areas of education and find the key educational variables, which can make the education and teaching decision simple and accurate. In this paper, by using the Chinese word segmentation algorithm, association rule and RStudio tool, we analyse the title of master’s thesis in four universities that have same discipline structure. The title data is obtained from http://www.cnki.net, which is an authority database in China. The results show that the research directions of the four university tend to be wireless network, mobile communication and algorithms. © 2018, Springer International Publishing AG.","Association rules; Chinese word segmentation algorithm; Education data mining; RStudio","Association rules; Computational linguistics; Data handling; Data mining; Education; Engineering education; Information analysis; Teaching; Chinese word segmentation; Data driven; Data technologies; Educational data mining; Mobile communications; RStudio; Big data",2-s2.0-85030848321
"Jin Z., Li N., Xu Q., Bian Z.","Modern Heuristics of MCDM for the Operation Optimization in Container Terminals",2018,"International Series in Operations Research and Management Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032439851&doi=10.1007%2f978-3-319-62338-2_11&partnerID=40&md5=ff8ba22b8fcbb173712689bad44f4af1","This chapter systematically applies modern heuristics to solve multi-criteria decision making problems in the fields of container terminal, which consists of three geographically interrelated core areas: container terminal, anchorage ground on its sea side, and gateway on its land side. For the container terminal, the container loading sequence problem is considered and a hybrid dynamic programming approach is proposed. The considered problem aims at obtaining an optimized container loading sequence for a crane to retrieve all the containers from the yard to the ship. The proposed dynamic algorithms consist of two phases. A heuristic algorithm is developed to retrieve the containers subset which needs no relocation and may be loaded directly onto the ship at the first phase, and a dynamic programming with heuristic rules is applied to solve the loading sequence problem for the rest of the containers at the second phase. For the anchorage ground on the sea side of a container terminal, the tugboat scheduling problem is formulated as a multiprocessor tasks scheduling problem after analyzing the characteristics of tugboat operation. The model considers factors of multi-anchorage bases and three stages of operations (berthing/shifting-berth/unberthing). The objective is to minimize the total operation times for all tugboats and the waste of the tugboats horsepower in use at the same time. A hybrid simulated annealing algorithm is proposed to solve the addressed problem. For the gateway on the land side of a container terminal, resource deployment for truck appointment system on container terminals is solved as an optimization problem. A bi-objective model is set up to minimize resource input and balance workloads. Modern heuristics method based on non-dominated genetic algorithmII is proposed to solve difficulties of simultaneous optimization of resource input and appointment quotas. Three chromosomes representing quotas, yard cranes and gate lanes are set up, some of which are two dimensional. Numerical experiments are untaken to evaluate the effectiveness of the proposed algorithms and show the efficiency of the proposed algorithm. The three parts analyzed above cover all the core elements of modern heuristics of MCDM for the operation optimization in a container terminal from a container terminal to both its land side and its sea side. © 2018, Springer International Publishing AG.","Container loading sequence problem; Dynamic programming; Non-dominated genetic algorithm; Operation optimization; Resource deployment; Simulated annealing; Tugboat scheduling problem",,2-s2.0-85032439851
"Jiang Y., Zhang X., Zhou Q., Cheng Z.","An entropy-based ddos defense mechanism in software defined networks",2018,"Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031293252&doi=10.1007%2f978-3-319-66625-9_17&partnerID=40&md5=bea554f12a5e258e2017352c524784f2","The issue on defensing against Distributed Denial of Service (DDoS) attacks in Software Defined Networks (SDN) has been highly concerned by academe and industry. The existing studies cannot eliminate the false positives by using the simple classification algorithms. In this paper, we analyze the essential difference between DDoS attacks and flash crowds which causes some similar consequences to DDoS. Accordingly we design a novel effective Entropy-based DDoS Defense Mechanism (EDDM) running on the SDN controller, which including a two-stage DDoS detection method. Compared with the existing works, the EDDM avoids the dropping of legitimate packets and minimizes the losses of legitimate users. Simulations demonstrate that the EDDM can distinguish the DDoS attacks from flash crowds, find the locations of bots, and block attack packets at source effectively. © 2018, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.","DDoS defense; Entropy; Flash crowd; SDN","Entropy; Network security; Software defined networking; Classification algorithm; DDoS defense; Defense mechanism; Distributed denial of service attack; Effective entropies; False positive; Flash crowd; Legitimate users; Denial-of-service attack",2-s2.0-85031293252
"Lee R.-K., Yang Y.-C., Chen J.-H., Chen Y.-C.","Freeway travel time prediction by using the GA-based hammerstein recurrent neural network",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032623477&doi=10.1007%2f978-981-10-6487-6_2&partnerID=40&md5=e8873bffb6bcd398ab2f2acf9e7c838e","Freeway travel time prediction has become a focus of research in recent years. However, we must understand that most conventional methods are very instinctive. They rely on the small amount of real-time data from the day of travel to look for historical data with similar characteristics and then use the similar data to make predictions. This approach is only applicable for a single day and cannot be used to predict the travel time on a day in the future (such as looking up the travel time for the coming Sunday on a Monday). This study therefore developed a Hammerstein recurrent neural network based on genetic algorithms that learns the freeway travel time for different dates. The trained model can then be used to predict freeway travel time for a future date. The experiment results demonstrated the validity of the proposed approach. © Springer Nature Singapore Pte Ltd. 2018.","Freeway travel time prediction; Genetic algorithm; Recurrent neural network",,2-s2.0-85032623477
"Patil P., Aghav J.V., Sareen V.","Two-level diversified classifier ensemble for classification of credit entries",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031423936&doi=10.1007%2f978-981-10-3773-3_61&partnerID=40&md5=85ce5602e786fc15cb6bfc23456b7fce","Classification of creditable customers from the customers which have applied for the loan is the first step for assessing the potential losses and credit exposure faced by financial institutions. So in the present scenario, it is very important for the banks and the financial institutes to minimize the loan defaults. One of the important strategies is to predict the likely defaulters so that such loans are either not issued or monitored closely after the issuance. In this paper, we have surveyed various classification algorithms used in financial domain and various ensemble techniques like bagging, boosting and stacking. The experimental results and statistical tests show that this new proposed classifier ensemble constitutes a proper solution for classification problem of credit entries, performing better than the traditional single ensembles like bagging, boosting and more significant than individual classifiers. © Springer Nature Singapore Pte Ltd. 2018.",,"Computer programming; Computer science; Classification algorithm; Classifier ensembles; Ensemble techniques; Financial domains; Financial institutes; Financial institution; Individual classifiers; Proper solutions; Finance",2-s2.0-85031423936
"Colombo F.T., da Silva M.M.","Towards a servovision based control for a planar parallel manipulator",2018,"Mechanisms and Machine Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031306905&doi=10.1007%2f978-3-319-67567-1_23&partnerID=40&md5=1fbc5ff9ac4200537328a0b367843e8e","The control of parallel kinematic machines requires the use of complex strategies due to the coupling of the kinematic chains. The usual strategies for controlling serial manipulators should be reassessed for successfully controlling parallel manipulators. For instance, the usual joint space computed torque control strategy requires the calculation of the manipulator’s inverse kinematics. The inverse kinematics of a parallel manipulator can be cumbersome. This issue may yield unsatisfactory performance and/or stability. The usual Cartesian space computed torque control strategy demands the measurement of the end-effector’s pose. This measurement can be a challenging task. In this work, the pose of the end-effector of a 3RRR parallel manipulator is estimated using a fixed camera and image processing algorithms during the execution of a predefined task. This is the first step for implementing the Cartesian space computed torque control for the manipulator under study. © 2018, Springer International Publishing AG.","Camera calibration; Image processing; Parallel kinematic manipulator; Servovision","Cameras; End effectors; Flexible manipulators; Image processing; Inverse kinematics; Kinematics; Torque control; Camera calibration; Computed torque control; Image processing algorithm; Parallel kinematic machines; Parallel kinematic manipulators; Parallel manipulators; Planar parallel manipulators; Servovision; Manipulators",2-s2.0-85031306905
"Kopczynski B., Strumillo P., Niebudek-Bogusz E.","Glottocorrelographic visualization of normal and pathological vocal folds oscillations from videolaryngostroboscopic images",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028724154&doi=10.1007%2f978-3-319-66905-2_17&partnerID=40&md5=5e64831bc479ef1da19135a743e137f7","Videostroboscopy is a common technique used by phoniatricians for diagnosing vocal folds status by imaging their oscillations. Implementation of image processing methods allows to extract qualitative description and quantitative indices. Such an analysis approach allows to detect glottal pathological changes and monitor the voice quality. Presented analysis of the videostroboscopic sequences were carried for 12 individuals i.e. 6 patients with diagnosed vocal nodules and 6 normophonic individuals classified as a control group. Image pre-processing and image segmentation algorithms were applied to compute the glottal area waveform (GAW) and the glottovibragram during phonation and to build a novel representation of vocal folds oscillations which we called the glottocorrelogram. The obtained results confirm that computer analysis and new representations of the phonation process of the glottis can aid the phoniatricians in diagnosis of voice disorders. © 2018, Springer International Publishing AG.","Image processing; Laryngology; Medical imaging; Vocal folds","Biocybernetics; Biomedical engineering; Biophysics; Diagnosis; Image segmentation; Medical imaging; Processing; Quality control; Speech; Diagnosis of voice disorders; Glottal area waveform; Image processing - methods; Image segmentation algorithm; Laryngology; Pathological changes; Quantitative indices; Vocal folds; Image processing",2-s2.0-85028724154
"López-Tapia S., Molina R., Pérez de la Blanca N.","Using machine learning to detect and localize concealed objects in passive millimeter-wave images",2018,"Engineering Applications of Artificial Intelligence",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030873583&doi=10.1016%2fj.engappai.2017.09.005&partnerID=40&md5=52d5580fd35dd1915c6d2e839ed0b880","The detection and location of objects concealed under clothing is a very challenging task that has crucial applications in security. In this domain, passive millimeter-wave images (PMMWIs) can be used. However, the quality of the acquired images, and the unknown position, shape, and size of hidden objects render this task difficult. In this paper, we propose a machine learning-based solution to this detection/localization problem. Our method outperforms currently used approaches. The effect of non-stationary noise on different classification algorithms is analyzed and discussed, and a detailed experimental comparative study of classification techniques is presented using a new and comprehensive PMMWI database. The low computational testing cost of this solution allows for its use in real-time applications. © 2017 Elsevier Ltd","Machine learning; Passive millimeter-wave imaging; Threat detection","Artificial intelligence; Classification (of information); Learning systems; Millimeter waves; Classification algorithm; Classification technique; Comparative studies; Computational testing; Passive millimeter wave; Passive millimeter wave imaging; Real-time application; Threat detection; Object detection",2-s2.0-85030873583
"Rahali M., Loukil H., Bouhlel M.S.","Analysis of image compression approaches using wavelet transform and Kohonen’s network",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029503732&doi=10.1007%2f978-3-319-62521-8_41&partnerID=40&md5=bcd645cb6e15b44ef9603e6672bc6a25","Since digital images require a large space on the storage devices and the network bandwidth, many compression methods have been used to solve this problem. Actually, these methods have, more or less, good results in terms of compression ratio and the quality of the reconstructed images. There are two main types of compression: the lossless compression which is based on the scalar quantization and the lossy compression which rests on the vector quantization. Among the vector quantization algorithms, we can cite the Kohonen’s network. To improve the compression result, we add a pre-processing phase. This phase is performed on the image before applying the Kohonen’s network of compression. Such a phase is the wavelet transform. Indeed, this paper is meant to study and model an approach to image compression by using the wavelet transform and Kohonen’s network. The compression settings for the approach to the model are based on the quality metrics rwPSNR and MSSIM. © 2018, Springer International Publishing AG.","Image compression; Kohonen’s networks; Learning algorithm; Wavelet transform",,2-s2.0-85029503732
"Rabbani M., Zhalechian M., Farshbaf-Geranmayeh A.","A robust possibilistic programming approach to multiperiod hospital evacuation planning problem under uncertainty",2018,"International Transactions in Operational Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982914640&doi=10.1111%2fitor.12331&partnerID=40&md5=604934eec8fe845a67947b21e8964956","In this paper, a biobjective programming model is developed to address the hospital evacuation problem under uncertainty. It aims to concurrently minimize the total evacuation time and the total weighted number of unevacuated patients in each period. The presented model considers two types of patients and three transportation modes. Moreover, the evacuating hospitals are divided into two groups. In the first group, it is not possible to send vehicles to the evacuating hospitals due to the poor road condition or congestion, whereas there is no such limitation in the second group. A robust possibilistic programming approach is adopted to deal with the inherent uncertainty in the input data. To cope with the computational complexity of the problem, two well-known metaheuristic algorithms are developed to solve the large-sized problems. Finally, several computational experiments and sensitivity analyses are conducted and the results are analyzed. © 2016 The Authors. International Transactions in Operational Research © 2016 International Federation of Operational Research Societies","disaster; hospital evacuation planning; metaheuristics; robust possibilistic programming","Disasters; Sensitivity analysis; Traffic congestion; Bi-objective programming; Computational experiment; Hospital evacuation; Meta heuristic algorithm; Meta heuristics; Possibilistic programming; Transportation mode; Weighted number; Hospitals",2-s2.0-84982914640
"Surya Prasanthi L., Kiran Kumar R., Srinivas K.","A novel random forest approach using specific under sampling strategy",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021206181&doi=10.1007%2f978-981-10-3223-3_24&partnerID=40&md5=55aa7a09bcf736c081b7a82227278b70","In Data Mining the knowledge is discovered from the existing real world data sets. In real time scenario, the category of datasets varies dynamically. One of the emerging categories of dataset is class imbalance data. In Class Imbalance data, the percentages of instances in one class are far greater than the other class. The traditional data mining algorithms are well applicable for knowledge discovery from balance datasets. Efficient knowledge discovery is hampered in the case of class imbalance datasets. In this paper, we propose a novel approach dubbed as Under Sampling using Random Forest (USRF) for efficient knowledge discovery from imbalance datasets. The proposed USRF approach is verified on the 11 benchmark datasets from UCI repository. The experimental observations show that an improved accuracy and AUC is achieved with the proposed USRF approach with a good reduction in RMS error. © Springer Nature Singapore Pte Ltd. 2018.","Data mining; Imbalance data; Knowledge discovery; Random forest","Decision trees; Intelligent computing; Benchmark datasets; Class imbalance; Data mining algorithm; Imbalance datum; Random forests; RMS errors; UCI repository; Under-sampling; Data mining",2-s2.0-85021206181
"Sakouhi T., Akaichi J., Ahmed U.","Computing semantic trajectories: Methods and used techniques",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020422740&doi=10.1007%2f978-3-319-59480-4_39&partnerID=40&md5=3d7b2f68b40155cfad87f658e69b94b9","The widespread use of mobile devices generates huge amount of location data. The generated data is useful for many applications, including location-based services such as outdoor sports forums, routine prediction, location-based activity recognition and location-based social networking. Sharing individuals’ trajectories and annotating them with activities, for example a tourist transportation mode during his trip, helps bringing more semantics to the GPS data. Indeed, this provides a better understanding of the user trajectories, and then more interesting location-based services. To address this issue, diverse range of novel techniques in the literature are explored to enrich this data with semantic information, notably, machine learning and statistical algorithms. In this work, we focused, at a first level, on exploring and classifying the literature works related to semantic trajectory computation. Secondly, we capitalized and discussed the benefits and limitations of each approach. © Springer International Publishing AG 2018.","Activity recognition; Data mining; Machine learning; Mobility data; Ontology; Semantic modeling; Trajectory","Artificial intelligence; Data mining; Interactive computer systems; Learning systems; Location; Mobile devices; Mobile telecommunication systems; Multimedia services; Multimedia systems; Ontology; Pattern recognition; Semantics; Telecommunication services; Trajectories; Activity recognition; Mobility datum; Routine prediction; Semantic information; Semantic Model; Semantic trajectories; Statistical algorithm; Transportation mode; Location based services",2-s2.0-85020422740
"Li L., Zhang J., Zheng Y., Ran B.","Real-time traffic incident detection with classification methods",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026736139&doi=10.1007%2f978-981-10-3551-7_62&partnerID=40&md5=b53cc395914df39e212ac8a87b65dbf9","It is well known that traffic incident detection is essential to intelligent transportation system (ITS) and modern traffic management. Compared to traditional models based on traffic theory, some data mining computational algorithms are believed more appropriate and flexibility for automatic incident detection. In this paper, four classification models were introduced and their parameters were selected by tenfold cross-validation. Using an open dataset their predictive performance was compared based on five criteria. The results show that the classification models perform well to detect traffic incidents and no over-fitting problem. What’s more, AdaBoost-Cart and Naïve Bayes models seem to outperform support vector machine and Cart models since they provide superior detection rate. However, they cost long time to train. © Springer Science+Business Media Singapore 2018.","Classification method; Data mining; Traffic incident detection","Adaptive boosting; Advanced traffic management systems; Bayesian networks; Computation theory; Data mining; Highway traffic control; Intelligent systems; Transportation; Automatic incident detection; Classification methods; Classification models; Computational algorithm; Intelligent transportation systems; Over fitting problem; Predictive performance; Traffic incident detections; Intelligent vehicle highway systems",2-s2.0-85026736139
"Nazeer W., Kang S.M., Munir M., Kausar S.","Strong convergence theorems for a non-convex hybrid method for quasi-Lipschitz mappings and applications",2018,"Journal of Computational Analysis and Applications",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027325540&partnerID=40&md5=75ace2598fcbf7e4b903b1421ee488ac","In this note, the strong convergence theorems of a non-convex hybrid iteration algorithm corresponding to Noor iterative scheme about common fixed points for a uniformly closed asymptotically family of countable quasi-Lipschitz mappings in a Hilbert space has been proved. Moreover some applications of developed algorithm is presented. © 2018 by Eudoxus Press, LLC. All rights reserved.","Asmptotically quasi-nonexpansive mapping; Hybrid algorithm; Nonexpansive mapping; Quasi-Lipschitz mapping; Quasi-nonexpansive mapping",,2-s2.0-85027325540
"Ahmed A., Arif M., Rizwan A.R., Jabbar M., Ahmed Z.","A smart way to improve the printing capability of operating system",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029469793&doi=10.1007%2f978-3-319-62521-8_18&partnerID=40&md5=fa74857c810ee2b0468b7ec990a41594","Operating system is the core of computer science and task scheduling is the major topic in this domain. Priority base scheduling is always remains hot topic in the domain of operating systems. In Priority base printing always higher priority given to those printings jobs which are processed more quickly rather than the lower priority base printings jobs. In this way low priority jobs are delayed again and again. In this research detail study is conducted regarding the scheduling algorithms in operating system. Priority base printings become bottlenecks who are assigned lowest priority. They may have to wait till their turn may be up to mid night in large departments. Now we are going to discuss a specific algorithm which can solve above issues in a smart way. A new method is proposed to solve the priority scheduling problems. This method is very handy for those users who are assigned a higher priority authority in printing mechanism. It also allows the lowest priority base printing to print data. In this solution we are not going to ignore the highest printing jobs. The highest priority base printing jobs will be continued in the same way. Our main objective is to maintain a balance between the high priority and low priority printing jobs without suffering from continues delay. © 2018, Springer International Publishing AG.","Algorithm; Printer; Printing capability; Priority printing; Smart scheduling; Spooler",,2-s2.0-85029469793
"Tang X., Zeng W., Shi Y., Zhao L.","Brain activation detection by modified neighborhood one-class SVM on fMRI data",2018,"Biomedical Signal Processing and Control",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028690849&doi=10.1016%2fj.bspc.2017.08.021&partnerID=40&md5=8ec67bc3c8a05a644b69f25bc3579626","The one-class support vector machine (OC-SVM) is a data-driven machine learning method that has been applied as a novel technique for brain activation detection. Several researchers have obtained positive preliminary results using OC-SVMs. Nevertheless, existing algorithms are either too complicated or oversimplified and their performance needs to be further improved. In this study, a modified neighborhood one-class support vector machine (MNOC-SVM) algorithm is proposed to detect brain functional activation on functional magnetic resonance imaging (fMRI) data. This method is based on two basic assumptions: (a) For task-related fMRI data, time series of only a few voxels are related to a particular functional activity or functional area, and these voxels should be identified as activated voxels, i.e., the outliers. In contrast, for resting-state fMRI data, only a small number of voxels are unrelated to any resting-state functional networks. These voxels should instead be taken as non-activated voxels, i.e., the outliers. (b) Close voxels have similarly activated or non-activated states. To improve detection accuracy, we apply the following features to each voxel: the RV coefficient between each voxel and its 26 neighborhood voxels (or fewer than 26 for voxels on the edge of the brain), a flag for isolated voxels and a flag for isolated areas. For both task-related and resting-state fMRI data, our MNOC-SVM method effectively detects activated functional areas in the whole brain. © 2017","Brain activation detection; fMRI data; OC-SVM; Regional homogeneity","Chemical activation; Learning systems; Magnetic resonance imaging; Statistics; Support vector machines; Brain activation; fMRI data; Functional activation; Functional magnetic resonance imaging; Machine learning methods; OC-SVM; One-class support vector machine; Regional homogeneity; Functional neuroimaging; algorithm; Article; clinical assessment; clinical effectiveness; comparative study; controlled study; electroencephalogram; female; functional connectivity; functional magnetic resonance imaging; human; male; neighborhood; neuroimaging; nuclear magnetic resonance scanner; priority journal; resting state network; support vector machine; time series analysis; visual stimulation",2-s2.0-85028690849
"Abdelhade N., Soliman T.H.A., Ibrahim H.M.","Detecting twitter users’ opinions of arabic comments during various time episodes via deep neural network",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029504404&doi=10.1007%2f978-3-319-64861-3_22&partnerID=40&md5=201694403c2e79ed7878370334f2ec43","Due to the revolution of web 2.0, the amount of opinionated data has been extremely increased, produced by online users through sharing comments, videos, pictures, reviews, news and opinions. Although Twitter is one of the most prevalent social networking, the gathered data from Twitter is highly disorganized. However, extracting useful information from tweets is considered a challenging task. Twitter has a huge number of Arabic users who mostly post and write their tweets using the Arabic language. There has been a lot of work on sentiment analysis in English texts. However, the datasets and the publications of Arabic tweets analysis are still somewhat limited. In addition, one of the main important issues is that users can change their opinions on different subjects over time. In this work, two main points are discussed. First, a deep neural network (DNN) approach (back propagation algorithm) is applied to Arabic tweets to two different domains: Egyptian stock exchange and sports’ tweets. Second, DNN is implemented to detect users’ attitude in a time period of two years for each dataset (2014 and 2015) and (2012 and 2013). The datasets are manually annotated via constructing a lexicon from the two already existing ones. When DNN performance is evaluated an average value of accuracy 90.22%, precision 90.56%, recall 90.90%, and F-measure of 90.68%, when compared to other three machine learning algorithms Naïve Bayes (NB), Decision Tree, and K-Nearest. © 2018, Springer International Publishing AG.","Arabic tweets; Back propagation algorithm; Deep neural network; Opinion mining and time episodes; Sentiment analysis",,2-s2.0-85029504404
"Tharwat A., Gabel T., Hassanien A.E.","Classification of toxicity effects of biotransformed hepatic drugs using optimized support vector machine",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029488209&doi=10.1007%2f978-3-319-64861-3_15&partnerID=40&md5=bd049981cf991753c64ea6e53aaf2974","Measuring toxicity is an important step in drug development, and there is a high demand to develop computational models that can predict the drug toxicity risks. In this study, we used a dataset that consists of 553 drug samples that biotransformed in liver. The toxic effects were calculated for the current data are mutagenic, tumorigenic, irritant, and reproductive effects. The proposed model has two phases, in the first phase; sampling algorithms were utilized to solve the problem of imbalanced dataset, in the second phase, the Support Vector Machines (SVM) classifier was used to classify an unknown drug sample into toxic or non-toxic. Moreover, in our model, Dragonfly Algorithm (DA) was used to optimize SVM parameters such as the penalty parameter and kernel parameters. The experimental results demonstrated that the proposed model obtained high sensitivity to all toxic effects, which indicates that it could be used for the prediction of drug toxicity in the early stage of drug development. © 2018, Springer International Publishing AG.","Classification; Computational model; Dragonfly algorithm; Drug design; Optimization; Toxicity",,2-s2.0-85029488209
"Chen K., Zhou F., Yin L., Wang S., Wang Y., Wan F.","A hybrid particle swarm optimizer with sine cosine acceleration coefficients",2018,"Information Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028957463&doi=10.1016%2fj.ins.2017.09.015&partnerID=40&md5=7f2c773a24a3f8508b8b279e357c6023","Particle swarm optimization (PSO) has been widely used to solve complex global optimization tasks due to its implementation simplicity and inexpensive computational overhead. However, PSO has premature convergence, is easily trapped in the local optimum solution and is ineffective in balancing exploration and exploitation, especially in complex multi-peak search functions. To overcome the shortcomings of PSO, a hybrid particle swarm optimizer with sine cosine acceleration coefficients (H-PSO-SCAC) is proposed to solve these problems. It is verified by the application of twelve numerical optimization problems. In H-PSO-SCAC, we make the following improvements: First, we introduce sine cosine acceleration coefficients (SCAC) to efficiently control the local search and convergence to the global optimum solution. Second, opposition-based learning (OBL) is adopted to initialize the population. Additionally, we utilize a sine map to adjust the inertia weight ω. Finally, we propose a modified position update formula. Experimental results show that, in the majority of cases, the H-PSO-SCAC approach is capable of efficiently solving numerical optimization tasks and outperforms the existing similar population-based algorithms and PSO variants proposed in recent years. Therefore, the H-PSO-SCAC algorithm is successfully employed as a novel optimization strategy. © 2017 Elsevier Inc.","Opposition-based learning; Particle swarm optimizer; Sine cosine acceleration coefficients; Sine map","Global optimization; Optimization; Pattern matching; Population statistics; Acceleration coefficients; Balancing exploration and exploitations; Computational overheads; Global optimum solutions; Numerical optimizations; Opposition-based learning; Particle swarm optimizers; Population-based algorithm; Particle swarm optimization (PSO)",2-s2.0-85028957463
"Cortijo S., Gonzales C.","On conditional truncated densities Bayesian networks",2018,"International Journal of Approximate Reasoning",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031795544&doi=10.1016%2fj.ijar.2017.10.007&partnerID=40&md5=e975eed738ce37c01d822c4693ac702e","The majority of Bayesian networks learning and inference algorithms rely on the assumption that all random variables are discrete, which is not necessarily the case in real-world problems. In situations where some variables are continuous, a trade-off between the expressive power of the model and the computational complexity of inference has to be done: on one hand, conditional Gaussian models are computationally efficient but they lack expressive power; on the other hand, mixtures of exponentials (MTE), basis functions (MTBF) or polynomials (MOP) are expressive but this comes at the expense of tractability. In this paper, we introduce an alternative model called a ctdBN that lies in between. It is composed of a “discrete” Bayesian network (BN) combined with a set of univariate conditional truncated densities modeling the uncertainty over the continuous random variables given their discrete counterpart resulting from a discretization process. We prove that ctdBNs can approximate (arbitrarily well) any Lipschitz mixed probability distribution. They can therefore be exploited in many practical situations. An efficient inference algorithm is also provided and its computational complexity justifies theoretically why inference computation times in ctdBNs are very close to those in discrete BNs. Experiments confirm the tractability of the model and highlight its expressive power, notably by comparing it with BNs on classification problems and with MTEs and MOPs on marginal distributions estimations. © 2017 Elsevier Inc.","Bayesian network; Continuous random variable; Inference; Mixed probability distribution","Barium compounds; Complex networks; Computational complexity; Computational efficiency; Economic and social effects; Inference engines; Knowledge based systems; Probability distributions; Random variables; Uncertainty analysis; Computation time; Computationally efficient; Discretization process; Expressive power; Inference; Inference algorithm; Marginal distribution; Real-world problem; Bayesian networks",2-s2.0-85031795544
"Ortiz J.S., Zapata C.F., Vega A.D., Andaluz V.H.","Path planning based on visual feedback between terrestrial and aerial robots cooperation",2018,"Mechanisms and Machine Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026285660&doi=10.1007%2f978-3-319-60867-9_12&partnerID=40&md5=5f494e8809c79bf456701c67dbf2c3eb","This paper presents an algorithm for path planning in which the evasion of fixed and mobile obstacles is considered in order to be followed by an unmanned land vehicle; path planning is based on visual feedback through an unmanned aerial vehicle. In addition, a path planning algorithm is proposed for the ground vehicle in which a non-constant velocity is considered that is a function of the control error, of the curvature of the road to be followed. The stability of the control algorithm is tested through the Lyapunov method. Finally the experimental results are presented and discussed in which the proposal is validated. © Springer International Publishing AG 2018.","Path planning; Robots cooperation; UAV; UGV","Feedback; Ground vehicles; Intelligent vehicle highway systems; Kinematics; Lyapunov methods; Motion planning; Robot programming; Unmanned aerial vehicles (UAV); Vehicles; Visual communication; Aerial robots; Control errors; Land vehicles; Mobile obstacles; Non-constant velocities; Path-planning algorithm; Visual feedback; Visual servoing",2-s2.0-85026285660
"Babshet K., Honegger C., Gritzman A., Aharonson V.","Visual pattern complexity determination for enhanced usability in cognitive testing",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021792316&doi=10.1007%2f978-3-319-60642-2_18&partnerID=40&md5=b56d012931ab3d00c051a7f8f80d2531","Computerized cognitive tests often entail tasks related to visual stimuli. An efficient complexity measure for these tasks can enhance their cognitive evaluation accuracy, specifically for elderly and cognitively impaired subjects. This paper details the design, implementation, and testing of a visual pattern complexity determination algorithm. The patterns used for the study are sixteen-bit binary patterns taken from computerized cognitive assessments. Three complexity levels were defined based on the visual perception of human subjects: easy, medium, and hard. The algorithm was tested on three hundred patterns and the results were compared to the parallel complexities perceived by human judges. Correlations of 72%, 74%, and 61% between human perception and the algorithm’s predictions were obtained for the easy, medium, and hard patterns, respectively. The algorithm has potential to become an accurate measure of visual pattern complexity in computerized assessment, and could improve the usability of these tests for psychometric and cognitive evaluations. © Springer International Publishing AG 2018.","Binary images; Cognitive assessments usability; Human perceived complexity; Visual pattern complexity","Binary images; Bins; Cognitive assessments; Cognitively impaired; Computerized assessments; Determination algorithm; Evaluation accuracy; Human perceived complexity; Parallel complexity; Visual pattern; Computational complexity",2-s2.0-85021792316
"Mauro S., Scimmi L.S., Pastorelli S.","Collision avoidance system for collaborative robotics",2018,"Mechanisms and Machine Science",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028351882&doi=10.1007%2f978-3-319-61276-8_38&partnerID=40&md5=1ea5560f3719fdf20659b7f5194c32a2","In this paper a real-time collision avoidance algorithm, based on the method of artificial potentials an intended for collaborative robotics applications was studied. Within this work, the movements of a person are detected and acquired by a vision system and a dummy, developed to interact with a robot in a simulated workspace, replicates these actions. Ellipsoids are then defined to entirely include several parts of the dummy and the end-effector of the robot. The minimum distance between the ellipsoids of the dummy and the one of the end-effector is the input of the collision avoidance algorithm. The results of tests are presented to show the effectiveness of the algorithm. Finally, the influence of the velocity of the obstacle on the capability of the algorithm of ensuring safe collision avoidance is analyzed. © 2018, Springer International Publishing AG.","Artificial potentials; Collaborative robotics; Collision avoidance algorithm; Vision system","Collision avoidance; Robotics; Artificial potentials; Collision avoidance systems; Minimum distance; Real time; Robotics applications; Vision systems; End effectors",2-s2.0-85028351882
"Kazakis N.A.","Comment on the paper “Thermoluminescence glow-curve deconvolution functions for mixed order of kinetics and continuous trap distribution by G. Kitis, J.M. Gomez-Ros, Nuclear Instruments and Methods in Physics Research A 440, 2000, pp 224–231”",2018,"Nuclear Instruments and Methods in Physics Research, Section A: Accelerators, Spectrometers, Detectors and Associated Equipment",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032037859&doi=10.1016%2fj.nima.2017.09.062&partnerID=40&md5=43a2fccfb9513e1dfcdad00a4a747dee","The present comment concerns the correct presentation of an algorithm proposed in the above paper for the glow-curve deconvolution in the case of continuous distribution of trapping states. Since most researchers would use directly the proposed algorithm as published, they should be notified of its correct formulation during the fitting of TL glow curves of materials with continuous trap distribution using this Equation. © 2017 Elsevier B.V.","Algorithm; Continuous trap distribution; Deconvolution; Fitting; FOM; Thermoluminescence",,2-s2.0-85032037859
"Zielosko B.","Optimization of exact decision rules relative to length",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020405223&doi=10.1007%2f978-3-319-59421-7_14&partnerID=40&md5=6f82f71eb84ba9651de26157e9659167","In the paper, an idea of modified dynamic programming algorithm is used for optimization of exact decision rules relative to length. The aims of the paper are: (i) study a length of decision rules, and (ii) study a size of a directed acyclic graph (the number of nodes and edges). The paper contains experimental results with decision tables from UCI Machine Learning Repository and comparison with results for dynamic programming algorithm. © Springer International Publishing AG 2018.","Decision rules; Dynamic programming; Length; Optimization","Decision tables; Directed graphs; Graph theory; Learning systems; Optimization; Decision rules; Directed acyclic graph (DAG); Dynamic programming algorithm; Length; UCI machine learning repository; Dynamic programming",2-s2.0-85020405223
"Schreiber L.-T., Gosselin C.","Kinematically redundant planar parallel mechanisms: Kinematics, workspace and trajectory planning",2018,"Mechanism and Machine Theory",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029119310&doi=10.1016%2fj.mechmachtheory.2017.08.022&partnerID=40&md5=f1013fb7e093b00a940c35596f6d0187","This paper introduces two general architectures of kinematically redundant planar parallel mechanisms. Their kinematic models are analyzed, an analytic workspace determination method is presented and a simple algorithm for their trajectory planning is provided for prescribed Cartesian trajectories. The trajectory planning algorithm uses the redundant degree of freedom to avoid singularities and optimize the actuator forces while taking into account the mechanical limits of the mechanism. The trajectory planning is computed globally in order to avoid local minima/maxima and to predict and take into account large variations in optimal values of the redundant degree of freedom. The algorithm guarantees that a solution will be found, if the Cartesian trajectory is feasible. Two planar parallel mechanisms with kinematic redundancy are used to demonstrate the algorithm. The kinematics of the mechanisms are derived, and the Jacobian matrices are obtained. The singularities and the mechanical limits of this type of mechanism are presented in order to establish the framework for the planning algorithm. Finally, example trajectories and results are shown to illustrate the algorithm and demonstrate its effectiveness. © 2017 Elsevier Ltd","Kinematic redundancy; Parallel robot; Planar mechanism; Workspace","Degrees of freedom (mechanics); Jacobian matrices; Kinematics; Mechanical actuators; Optimal systems; Redundancy; Redundant manipulators; Trajectories; Determination methods; General architectures; Kinematic redundancy; Parallel robots; Planar mechanism; Planar parallel mechanisms; Trajectory planning algorithm; Workspace; Mechanisms",2-s2.0-85029119310
"Boiroux D., Duun-Henriksen A.K., Schmidt S., Nørgaard K., Madsbad S., Poulsen N.K., Madsen H., Jørgensen J.B.","Overnight glucose control in people with type 1 diabetes",2018,"Biomedical Signal Processing and Control",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029001470&doi=10.1016%2fj.bspc.2017.08.005&partnerID=40&md5=1cdaac8b743f3400ffed88ae56e9b1b0","This paper presents an individualized model predictive control (MPC) algorithm for overnight blood glucose stabilization in people with type 1 diabetes (T1D). The MPC formulation uses an asymmetric objective function that penalizes low glucose levels more heavily. We compute the model parameters in the MPC in a systematic way based on a priori available patient information. The model used by the MPC algorithm for filtering and prediction is an autoregressive integrated moving average with exogenous input (ARIMAX) model implemented as a linear state space model in innovation form. The control algorithm uses frequent glucose measurements from a continuous glucose monitor (CGM) and its decisions are implemented by a continuous subcutaneous insulin infusion (CSII) pump. We provide guidelines for tuning the control algorithm and computing the Kalman gain in the linear state space model in innovation form. We test the controller on a cohort of 100 randomly generated virtual patients with a representative inter-subject variability. We use the same control algorithm for a feasibility overnight study using 5 real patients. In this study, we compare the performance of this control algorithm with the patient's usual pump setting. We discuss the results of the numerical simulations and the in vivo clinical study from a control engineering perspective. The results demonstrate that the proposed control strategy increases the time spent in euglycemia. © 2017 Elsevier Ltd","Artificial pancreas; Closed-loop control; Glucose control; Model predictive control; Type 1 diabetes","Artificial organs; Glucose; Predictive control systems; State space methods; Artificial pancreas; Auto-regressive integrated moving average; Closed-loop control; Glucose control; Glucose measurements; Linear state space model; Patient information; Type 1 diabetes; Model predictive control; glucose; insulin; adult; algorithm; Article; blood glucose monitoring; clinical article; control strategy; control system; glucose blood level; human; hypoglycemia; insulin dependent diabetes mellitus; insulin pump; insulin sensitivity; model; practice guideline; prediction; priority journal; simulation",2-s2.0-85029001470
"Chauhan N., Rakesh N., Matam R.","Assessment on vm placement and vm selection strategies",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031407265&doi=10.1007%2f978-981-10-6747-1_18&partnerID=40&md5=04ac00beefa76031afc563c26188f0d6","Cloud Computing is captivating many organizations and individuals because it provides a framework where the user can access diverse resources such as applications, storage capacity, network bandwidth, and many resources. Cloud users rent the resources that they need from the cloud provider. The optimum allocation of resources to the users in a dynamic environment is a major challenge for the cloud providers. Virtualization technology in Cloud enables allocation of resources to the end user applications in Cloud by hosting numerous Virtual Machines on a single host. There are number of approaches to decide the placement of Virtual Machines to the various hosts. As numbers of applications are submitted by the users, some of the hosts become overloaded and some become under loaded. As a result, some of the user applications hosted on a Virtual Machine of one host needs to be transferred to another Virtual Machine of another host. The migration of Virtual Machines from one host to another needs to be minimized to improve the response time, turnaround time for an end user application. This paper addresses the various VM placement and VM selection algorithms and their scope of improvement. © 2018, Springer Nature Singapore Pte Ltd.","Resource allocation; VM migration; VM placement; VM selection","Cloud computing; Network security; Resource allocation; Virtual machine; Dynamic environments; End-user applications; Optimum allocation; Selection algorithm; Virtualization technologies; Vm migrations; VM placements; VM selection; Distributed computer systems",2-s2.0-85031407265
"Li Z., Zhang X., Müller H., Zhang S.","Large-scale retrieval for medical image analytics: A comprehensive review",2018,"Medical Image Analysis",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031765308&doi=10.1016%2fj.media.2017.09.007&partnerID=40&md5=335200bd8a11a7e0497b257b7a098d85","Over the past decades, medical image analytics was greatly facilitated by the explosion of digital imaging techniques, where huge amounts of medical images were produced with ever-increasing quality and diversity. However, conventional methods for analyzing medical images have achieved limited success, as they are not capable to tackle the huge amount of image data. In this paper, we review state-of-the-art approaches for large-scale medical image analysis, which are mainly based on recent advances in computer vision, machine learning and information retrieval. Specifically, we first present the general pipeline of large-scale retrieval, summarize the challenges/opportunities of medical image analytics on a large-scale. Then, we provide a comprehensive review of algorithms and techniques relevant to major processes in the pipeline, including feature representation, feature indexing, searching, etc. On the basis of existing work, we introduce the evaluation protocols and multiple applications of large-scale medical image retrieval, with a variety of exploratory and diagnostic scenarios. Finally, we discuss future directions of large-scale retrieval, which can further improve the performance of medical image analysis. © 2017 Elsevier B.V.","Computer aided diagnosis; Information retrieval; Large scale; Medical image analysis","Computer aided analysis; Computer aided diagnosis; Computer vision; Diagnosis; Image analysis; Image enhancement; Image retrieval; Imaging techniques; Information retrieval; Learning systems; Pipelines; Conventional methods; Digital imaging techniques; Evaluation protocol; Feature representation; Image data; Large scale; Multiple applications; State-of-the-art approach; Medical imaging; algorithm; compression; data extraction; hashing; histopathology; human; image analysis; image processing; image retrieval; image segmentation; machine learning; mammography; methodology; nerve cell; priority journal; Review",2-s2.0-85031765308
"van der Meer F., Kopačková V., Koucká L., van der Werff H.M.A., van Ruitenbeek F.J.A., Bakker W.H.","Wavelength feature mapping as a proxy to mineral chemistry for investigating geologic systems: An example from the Rodalquilar epithermal system",2018,"International Journal of Applied Earth Observation and Geoinformation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032209040&doi=10.1016%2fj.jag.2017.09.008&partnerID=40&md5=8755ce2d15513c0a58265b577ec2e461","The final product of a geologic remote sensing data analysis using multi spectral and hyperspectral images is a mineral (abundance) map. Multispectral data, such as ASTER, Landsat, SPOT, Sentinel-2, typically allow to determine qualitative estimates of what minerals are in a pixel, while hyperspectral data allow to quantify this. As input to most image classification or spectral processing approach, endmembers are required. An alternative approach to classification is to derive absorption feature characteristics such as the wavelength position of the deepest absorption, depth of the absorption and symmetry of the absorption feature from hyperspectral data. Two approaches are presented, tested and compared in this paper: the ‘Wavelength Mapper’ and the ‘QuanTools’. Although these algorithms use a different mathematical solution to derive absorption feature wavelength and depth, and use different image post-processing, the results are consistent, comparable and reproducible. The wavelength images can be directly linked to mineral type and abundance, but more importantly also to mineral chemical composition and subtle changes thereof. This in turn allows to interpret hyperspectral data in terms of mineral chemistry changes which is a proxy to pressure-temperature of formation of minerals. We show the case of the Rodalquilar epithermal system of the southern Spanish Gabo de Gata volcanic area using HyMAP airborne hyperspectral images. © 2017 Elsevier B.V.","Absorption features; Geology; HyMAP; Hyperspectral imaging; Rodalquilar; SE Spain; Wavelength mapping","algorithm; chemical composition; epithermal deposit; geological mapping; image classification; mineralogy; multispectral image; pixel; remote sensing; wavelength; Almeria [Andalucia]; Andalucia; Rodalquilar; Spain",2-s2.0-85032209040
"Artetxe A., Larburu N., Murga N., Escolar V., Graña M.","Heart failure readmission or early death risk factor analysis: A case study in a telemonitoring program",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019762550&doi=10.1007%2f978-3-319-59397-5_26&partnerID=40&md5=b5c30b8bf9091975e0ebb19b6e06662d","Heart Failure (HF) is a clinical syndrome caused by a structural and/or functional cardiac abnormality that imposes tremendous burden on patients and on the healthcare systems worldwide. In this context, predictive models may facilitate the identification of patients at high risk of death or unplanned hospital readmissions and potentially enable direct specific interventions. Currently a plethora of studies in this field is discussing whether hospital readmission and mortality can be effectively predicted in patients with HF. In this work, we present a preliminary study for identifying risk factors for unplanned readmission or death, using a clinical dataset with 119 patients and 60 features. Different classification algorithms and feature selection approaches were employed in order to increase the prediction ability of the models and reduce their complexity in terms of number of features. Results show that sequential feature selection methods along with SVM achieve the best scores in terms of accuracy for predicting 30-day readmission or death risk. © Springer International Publishing AG 2018.","Feature selection; Heart failure; Predictive models; Readmission risk","Cardiology; Classification (of information); Feature extraction; Health care; Heart; Hospitals; Patient treatment; Risk analysis; Telemedicine; Classification algorithm; Clinical syndromes; Health-care system; Heart failure; Predictive models; Risk factors; Sequential feature selections; Tele-monitoring; Risk assessment",2-s2.0-85019762550
"González-Calderón A., Vivas-Cruz L.X., Herrera-Hernández E.C.","Application of the θ-method to a telegraphic model of fluid flow in a dual-porosity medium",2018,"Journal of Computational Physics",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031093102&doi=10.1016%2fj.jcp.2017.09.014&partnerID=40&md5=727aad419d0f84ddc2d7d251b8ffa479","This work focuses mainly on the study of numerical solutions, which are obtained using the θ-method, of a generalized Warren and Root model that includes a second-order wave-like equation in its formulation. The solutions approximately describe the single-phase hydraulic head in fractures by considering the finite velocity of propagation by means of a Cattaneo-like equation. The corresponding discretized model is obtained by utilizing a non-uniform grid and a non-uniform time step. A simple relationship is proposed to give the time-step distribution. Convergence is analyzed by comparing results from explicit, fully implicit, and Crank–Nicolson schemes with exact solutions: a telegraphic model of fluid flow in a single-porosity reservoir with relaxation dynamics, the Warren and Root model, and our studied model, which is solved with the inverse Laplace transform. We find that the flux and the hydraulic head have spurious oscillations that most often appear in small-time solutions but are attenuated as the solution time progresses. Furthermore, we show that the finite difference method is unable to reproduce the exact flux at time zero. Obtaining results for oilfield production times, which are in the order of months in real units, is only feasible using parallel implicit schemes. In addition, we propose simple parallel algorithms for the memory flux and for the explicit scheme. © 2017 Elsevier Inc.","Dual-porosity reservoir; Nonuniform grid and time step; Parallel algorithm; Telegraphic fluid flow; θ-method",,2-s2.0-85031093102
"Desai M.N., Dahiya V., Singh A.K.","Proposed model for an expert system for diagnosing degenerative diseases – using digital image processing with neural network",2018,"Smart Innovation, Systems and Technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028442519&doi=10.1007%2f978-3-319-63673-3_8&partnerID=40&md5=ad7f0056bf3c126fd781e1a378b45d08","In the era of any information on fingertip or on one click, medical diagnosis is context in which wrong diagnosis should be avoided using extensive information related to patients and symptoms. There should be an efficient system in diagnosis in terms of expert diagnostic opinion within short span of time, so that disease should be prevented to become chronic. To streamline this expert diagnostic opinion process to the patients, in daily routine, Expert System (ES) using artificial neural network can be employed. It is the method which can simulate two very important characteristics of humans, learning and generalization. Using ANN algorithms various types of medical data are handled and output is achieved with defining various relations between that data. Radiology is one of the branches of medical science in which various medical imaging techniques are used to diagnose difference internal medical problems. Digital Image Processing is the science of processing various digital images: such that important information will be generated. An Expert System is also an efficient tool from which diagnosis can be made. Integrating outcomes of neural network from diseased X-ray, to the knowledge based expert system; an expert opinion of diagnosing disease can be generated. In this paper a model is proposed for diagnosing, seven lower lumbar problems as degenerative diseases. © 2018, Springer International Publishing AG.","Artificial neural network; Expert system; Lower lumbar diagnosis; Medical imaging techniques; Radiology","Expert systems; Image processing; Imaging techniques; Intelligent systems; Knowledge based systems; Medical imaging; Medical problems; Neural networks; Radiation; Radiology; ANN algorithm; Daily routines; Degenerative disease; Digital image; Expert opinion; Knowledge-based expert systems; Medical data; Medical science; Diagnosis",2-s2.0-85028442519
"Kalcheva N., Zagorska A., Dukov N., Bliznakova K.","Analysis of suitability of five statistical methods applied for the validation of a monte carlo X-ray based software packages",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031422632&doi=10.1007%2f978-3-319-68321-8_46&partnerID=40&md5=9c96eaa1a8bdcfbf1849b6c83952eb27","Goal of this study is to compare five statistical algorithms used for evaluation of software packages based on Monte Carlo techniques. These methods are the following analysis: regression, correlation and Bland Altman as well as Wilcoxon rank sum and Kolmogorov-Smirnov tests. The methods were applied for the case study of validating a dedicated computer code for calculation of scattered radiation reaching the eyes of the operator during interventional procedures. The transport of x-rays and their interactions with the matter have been accomplished by the use of Monte Carlo techniques. Results were presented in the form of number of registered photons as a function of their energy and further compared to data from literature. From the five statistical methods for comparison, the most suitable for our application turns out to be the Bland-Altman method. Further effort is related to the development of a specific software application for evaluation of data generated from general purpose x-ray simulations, as well as with analysis of more data obtained from different incident x-ray spectra. © Springer International Publishing AG 2018.","Monte carlo; Statistical methods; X-ray imaging","Application programs; Monte Carlo methods; Software packages; X ray analysis; Dedicated computers; Interventional procedures; Kolmogorov-Smirnov test; Monte Carlo techniques; Scattered radiations; Software applications; Statistical algorithm; Xray imaging; Statistical methods",2-s2.0-85031422632
"Gahlot G., Patil N.","A pragmatics-oriented high utility mining for itemsets of size two for boosting business yields",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032646581&doi=10.1007%2f978-981-10-3376-6_9&partnerID=40&md5=f6e17f8a858f79407b8b35f43b771eb9","Retail market has paced with an enormous rate, sprawling its effect over the nations. The B2C companies have been putting lucrative offers and schemes to fetch the customers’ attractions in the awe of upbringing the business profits, but with the mindless notion of the same. Knowledge discovery in the field of data mining can be well harnessed to achieve the profit benefits. This article proposes the novel way for determining the items to be given on sale, with the logical clubs, thus extending the Apriori algorithm. The dissertation proposes the high-utility mining for itemsets of size two (HUM-IS2) Algorithm using the transactional logs of the superstores. The pruning strategies have been introduced to remove unnecessary formations of the clubs. The essence of the algorithm has been proved by experimenting with various datasets. © Springer Nature Singapore Pte Ltd. 2018.","Apriori algorithm; B2C companies; Business yields; High-utility itemsets; Knowledge discovery; Log mining; Offers; Pragmatics; Retail",,2-s2.0-85032646581
"Zhu H., Zhang S.","Extraction method of micro-blog new login word based on improved position-word probability",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032665623&doi=10.1007%2f978-3-319-67071-3_45&partnerID=40&md5=6774d32a7db55cc0063f4f99ca989799","In the traditional discovery methods of micro-blog new login word, compound words are difficult to be extracted effectively. Aiming to solve this problem, this paper proposes an extraction method of micro-blog new login word based on improved Position-Word Probability (PWP) and N-increment algorithm. First, the micro-blog long text is composed of all micro-blog within a single topic in period of a given time and then pre-treated. Then, the extension direction of frequent strings is judged by improved the probability of word location in the query process of N-increment algorithm. Finally, the redundant strings are reduced by pruning frequent strings set. The experimental results show that the algorithm proposed in this paper can effectively extract the compound words in micro-blog new login word. © 2018, Springer International Publishing AG.","Compound words; Improved PWP; Micro-blog new login word; N-increment algorithm","Extraction; Probability; Compound words; Extraction method; Improved PWP; Micro-blog; Blogs",2-s2.0-85032665623
"Zeng X., Xu L., Ma L., Zhao R., Cen Y.","Visual tracking using global sparse coding and local convolutional features",2018,"Digital Signal Processing: A Review Journal",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032202564&doi=10.1016%2fj.dsp.2017.10.007&partnerID=40&md5=caea6f6ba0cbf8f9133928bbace8c425","Visual tracking is a challenging task in many computer vision applications due to factors such as occlusion, scale variations, background clutter, and so on. In this paper, we present a robust tracking algorithm by representing the target at two levels: global and local levels. Accordingly, the tracking algorithm is composed of two parts: global and local parts. The global part is a discriminative model which separates the foreground object from the background based on holistic features. In the local part, we explore the target's local representation by a set of filters convolving the target region at each position. Then, the global part and local part are integrated into a collaborative model to construct the final tracker. Experiments on the tracking benchmark dataset with 50 challenging videos demonstrate the robustness and effectiveness of the proposed algorithm, outperforming several state-of-the-art models. © 2017 Elsevier Inc.","Collaborative model; Local convolutional feature; Sparse representation; Visual tracking","Tracking (position); Background clutter; Collaborative model; Computer vision applications; Discriminative models; Local convolutional feature; Sparse representation; Tracking algorithm; Visual Tracking; Convolution",2-s2.0-85032202564
"Sharma S., Jain R.","Outlier detection in agriculture domain: Application and techniques",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031419840&doi=10.1007%2f978-981-10-6620-7_28&partnerID=40&md5=df602911f447140707fae1fbc1ab38ab","Outliers are those values that do not comply with the general behavior of the existing data. Outliers vary quantitatively from rest of the data, according to any outlier-selection algorithm. Normal data values or objects follow a common generating mechanism, whereas the abnormal objects deviated from that mechanism and it seems that they have been generated from some different mechanisms. These abnormal data objects are referred as “Outliers”. In this paper, authors have tried to explore various applications and techniques of outlier detection. Further, an algorithm for detecting the outliers in agriculture domain has been proposed and its implementation through hand-coded ETL tool, AGRETL, has been discussed. The results show the significant improvement, when the algorithm was validated on the real-time dataset. © 2018, Springer Nature Singapore Pte Ltd.","Agriculture; ETL process; Outlier detection","Agriculture; Data handling; Statistics; Abnormal data; Data values; Different mechanisms; ETL process; Generating mechanism; Outlier Detection; Real-time dataset; Selection algorithm; Big data",2-s2.0-85031419840
"Pei S., Hu Q.","Partially monotonic decision trees",2018,"Information Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030725250&doi=10.1016%2fj.ins.2017.10.006&partnerID=40&md5=1c69c210003bba7b32c2f6f5bbb6fe0b","In multicriteria decision tasks, certain features are linearly ordered according to the decision and are called criteria, whereas others, called regular attributes, are not. In practice, regular attributes and criteria coexist in most classification tasks. In this paper, we propose a rank-inconsistent rate that distinguishes attributes from criteria. Furthermore, it represents the directions of the monotonic relationships between criteria and decisions. We design a partially monotonic decision tree algorithm to extract decision rules for partially monotonic classification tasks. Experimental results show that the proposed algorithm is effective and efficient. © 2017","Decision tree; Monotonic directions; Partially monotonic; Rank inconsistency","Decision trees; Trees (mathematics); Classification tasks; Decision rules; Decision-tree algorithm; Monotonic classifications; Monotonic directions; Multicriteria decision; Partially monotonic; Rank inconsistency; Data mining",2-s2.0-85030725250
"Kuzmanić I., Vujović I., Šoda J.","Dielectric material selection optimization based on relative dielectric constant dependencies in operating environment",2018,"Advanced Structured Materials",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024490136&doi=10.1007%2f978-3-319-59590-0_5&partnerID=40&md5=347b8f8f9a2b6c5ced4c7db31eb5a2b5","Selecting suitable material is an important issue in applied engineering. In this paper, an algorithm for optimum dielectric material identification is developed. Its scope covers general and specific requirements for the marine environment, using the parameters of influence to test whether the chosen material is suitable for use in the range of the parameters. The design of a parameter’s range is determined by the designer, and should be suited to the exact field of the specific application. The proposed algorithm is also location/application-dependent. It provides a framework for further development of self-turning devices, correcting itself by calculating the influence of environmental conditions. © 2018, Springer International Publishing AG.","Dielectric materials; Operating conditions; Relative dielectric constant (permittivity); Selection algorithm; Structural characterization",,2-s2.0-85024490136
"Soltesz K.","Robust computation of pulse pressure variations",2018,"Biomedical Signal Processing and Control",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026901068&doi=10.1016%2fj.bspc.2017.07.021&partnerID=40&md5=26913f8577d06581f7a1926aecc64c6c","Evidence of arterial pulse pressure variations caused by cardio-pulmonary interactions, and their connection to volume status via the Frank–Starling relationship, are well documented in the literature. Computation of pulse pressure variations from arterial pressure measurements is complicated by the fact that systolic and diastolic peaks are not evenly spaced in time. A robust, structurally uncomplicated, and computationally cheap algorithm, specifically addressing this fact, is presented. The algorithm is based on the Lomb–Scargle spectral density estimator, and ordinary least squares fitting. It is introduced using illustrative examples, and successfully demonstrated on a challenging porcine data set. © 2017 Elsevier Ltd","Arterial blood pressure; Frequency estimation; Nonuniform sampling; Pulse pressure variation","Frequency estimation; Spectral density; Arterial blood pressure; Arterial pulse pressure variations; Nonuniform sampling; Ordinary least squares; Pulse-pressure variations; Robust computation; Spectral density estimator; Volume status; Blood pressure; algorithm; arterial pressure; Article; artificial ventilation; breathing pattern; cardiopulmonary hemodynamics; comparative study; controlled study; Fourier transformation; nonhuman; positive end expiratory pressure; priority journal; pulse pressure",2-s2.0-85026901068
"Wardlaw J., Sprinks J., Houghton R., Muller J.-P., Sidiropoulos P., Bamford S., Marsh S.","Comparing experts and novices in Martian surface feature change detection and identification",2018,"International Journal of Applied Earth Observation and Geoinformation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032178163&doi=10.1016%2fj.jag.2017.05.014&partnerID=40&md5=4592541bcdc0d8a8943afc20fcf244e5","Change detection in satellite images is a key concern of the Earth Observation field for environmental and climate change monitoring. Satellite images also provide important clues to both the past and present surface conditions of other planets, which cannot be validated on the ground. With the volume of satellite imagery continuing to grow, the inadequacy of computerised solutions to manage and process imagery to the required professional standard is of critical concern. Whilst studies find the crowd sourcing approach suitable for the counting of impact craters in single images, images of higher resolution contain a much wider range of features, and the performance of novices in identifying more complex features and detecting change, remains unknown. This paper presents a first step towards understanding whether novices can identify and annotate changes in different geomorphological features. A website was developed to enable visitors to flick between two images of the same location on Mars taken at different times and classify 1) if a surface feature changed and if so, 2) what feature had changed from a pre-defined list of six. Planetary scientists provided “expert” data against which classifications made by novices could be compared when the project subsequently went public. Whilst no significant difference was found in images identified with surface changes by expert and novices, results exhibited differences in consensus within and between experts and novices when asked to classify the type of change. Experts demonstrated higher levels of agreement in classification of changes as dust devil tracks, slope streaks and impact craters than other features, whilst the consensus of novices was consistent across feature types; furthermore, the level of consensus amongst regardless of feature type. These trends are secondary to the low levels of consensus found, regardless of feature type or classifier expertise. These findings demand the attention of researchers who want to use crowd-sourcing for similar scientific purposes, particularly for the supervised training of computer algorithms, and inform the scope and design of future projects. © 2017 Elsevier B.V.","Change detection; Citizen science; Crowd sourcing; Image analysis; Planetary science; Volunteered geographic information","algorithm; crater; detection method; image analysis; Internet; Mars; planetary surface; satellite imagery; supervised learning",2-s2.0-85032178163
"Dande P., Samant P.","Acquaintance to Artificial Neural Networks and use of artificial intelligence as a diagnostic tool for tuberculosis: A review",2018,"Tuberculosis",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030831972&doi=10.1016%2fj.tube.2017.09.006&partnerID=40&md5=a8f64a966327a09f072ee8a5e776dabb","Tuberculosis [TB] has afflicted numerous nations in the world. As per a report by the World Health Organization [WHO], an estimated 1.4 million TB deaths in 2015 and an additional 0.4 million deaths resulting from TB disease among people living with HIV, were observed. Most of the TB deaths can be prevented if it is detected at an early stage. The existing processes of diagnosis like blood tests or sputum tests are not only tedious but also take a long time for analysis and cannot differentiate between different drug resistant stages of TB. The need to find newer prompt methods for disease detection has been aided by the latest Artificial Intelligence [AI] tools. Artificial Neural Network [ANN] is one of the important tools that is being used widely in diagnosis and evaluation of medical conditions. This review aims at providing brief introduction to various AI tools that are used in TB detection and gives a detailed description about the utilization of ANN as an efficient diagnostic technique. The paper also provides a critical assessment of ANN and the existing techniques for their diagnosis of TB. Researchers and Practitioners in the field are looking forward to use ANN and other upcoming AI tools such as Fuzzy-logic, genetic algorithms and artificial intelligence simulation as a promising current and future technology tools towards tackling the global menace of Tuberculosis. Latest advancements in the diagnostic field include the combined use of ANN with various other AI tools like the Fuzzy-logic, which has led to an increase in the efficacy and specificity of the diagnostic techniques. © 2017 Elsevier Ltd","Artificial intelligence; Artificial Neural Networks; Diagnosis; Neuro fuzzy logic; Tuberculosis","artificial intelligence; artificial neural network; computer assisted diagnosis; diagnostic procedure; fuzzy logic; genetic algorithm; human; multilayered feed forward neural network; nomenclature; priority journal; recurrent neural network; Review; tuberculosis",2-s2.0-85030831972
"Huynh Q.T.B., Bui P.N., Le T.Q.","Localized comparison of sleep stage scoring between psg and wearable devices",2018,"IFMBE Proceedings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030850905&doi=10.1007%2f978-981-10-4361-1_139&partnerID=40&md5=868351ce510cd277b71f3c060657d615","Wearable devices have been recently proposed as an alternative to the gold standard—polysomnography system (PSG)—in several particular circumstances. The past decade has seen a renewed importance in this area, resulting in various researches attempted to evaluate the validity and reliability of this kind of surrogate devices.​ This paper seeks to address the issue of consensus in results reached by both wearable devices and PSG system. Specifically, we propose an algorithm to locally detect and quantify the discrepancies among the wearable devices and PSG sy﻿stem in scoring sleep stages. Within this study, the developed validation algorithm was performed using the data collect﻿ed from 14 human subjects, ​each of whom wears 4 wearable devices simultaneously to retrieve the signals of intere﻿st associated​ ﻿with PSG system as a benchmark overnight at our sleep lab ​for sleep monitoring and record. The gist of the algorithm is to﻿ compute the differences between two consecutive points in the hypnogram—a graph that represents the stages of sleep over the time—to estimate the monotone correlation of the sleep stages between wearable device and PSG. Our main goals are to determine sleep periods where the most considerable discriminants happen, and to quantify the levels of disagreement between two sorts of the instrument. Preliminary results show that the localized correlation algorithm can detect the points of the most significant agreement and disagreement of wearable devices benchmarked to PSG. The validation method for this algorithm will soon be an inevitably critical issue to be verified and developed for the robustness and reliability of wearable devices in comparison with gold standard PSG system. © Springer Nature Singapore Pte Ltd. 2018.","Localized correlation; Polysomnography system; Wearable device; Wearable device validation","Biomedical engineering; Gold; Patient monitoring; Sleep research; Correlation algorithm; Critical issues; Data collect; Gold standards; Human subjects; Polysomnography; Sleep monitoring; Wearable devices; Wearable technology",2-s2.0-85030850905
"Shah N.F., Kumar P.","A comparative analysis of various spam classifications",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032635243&doi=10.1007%2f978-981-10-3376-6_29&partnerID=40&md5=6838a34d89b5d00afa1f5080a08db150","Bandwidth, time, and storage space are the major three assets in computational world. Spam emails affect all the three, thus degrade the overall efficiency of the system. Spammers are using new tricks and traps to land these frivolous mails into our inbox. To make mailboxes more intelligent, our effort will be to devise a new algorithm that will help to classify emails in much smarter and efficient way. This paper analyzes various spam classification techniques and thereby put forward a new way of classifying spam emails. This paper thoroughly compares the results that various authors have got while simulating their architectures. Our approach of classification works efficiently and more accurately on varied length and type of datasets during training and testing phases. We tried to minimize the error ratio and increase classifier efficiency by implementing Genetic Algorithm concept. © Springer Nature Singapore Pte Ltd. 2018.","Feature set; Genetic algorithm; Logistic regression; Machine learning; Spam classification; Spam email; Unsolicited",,2-s2.0-85032635243
"Pourbagher R., Derakhshandeh S.Y.","A powerful method for solving the power flow problem in the ill-conditioned systems",2018,"International Journal of Electrical Power and Energy Systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021697462&doi=10.1016%2fj.ijepes.2017.06.032&partnerID=40&md5=bb950dcf081a1f75e700dd19fc84c620","In most cases, the power systems are well-conditioned and the power flow problem (PFP) can be solved by using the famous Newton or Newton-based methods. However, in some cases, the conditions of the power systems are ill and the above-mentioned methods are poorly converged or even diverged. This paper presents application of corrected Levenberg-Marquardt algorithm with a non-monotone line search for solving the PFP in the ill-conditioned power systems. The presented algorithm is evaluated on the case studies ranging from small to large (30-bus, 57-bus, 118-bus and 2383-bus). Simulation results show the proposed approach converges in all of the case studies. Moreover, application of the proposed method for solving the PFP in ill-conditioned power systems can significantly reduce the CPU time and number of iterations in comparison with the benchmark methods. © 2017 Elsevier Ltd",,"Benchmarking; Buses; Case-studies; CPU time; Ill-conditioned; Ill-conditioned systems; Levenberg-Marquardt algorithm; Line searches; Number of iterations; Power flow problem; Electric load flow",2-s2.0-85021697462
"Lin C.-S., Chen Y.-H., Chiang T.-F., Lee J.-W., Lin W.-C., Lin Y.-D.","An automatic inspection system for the coating quality of the edge of mirror elements",2018,"Optik",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030707601&doi=10.1016%2fj.ijleo.2017.09.108&partnerID=40&md5=03fb4ec89ae6428c9789140c8c076bac","This study aims to inspect the common defects of the edge of the mirror elements, including scratches, impurities, and edge serration, which occur in the production of mirror elements, where a mirror surface was illuminated in different directions in the experiment. The imaging system was used to inspect the defect position, enhance image contrast, and judge whether the defect exceeds the permissible range. With a novel algorithm, the image contour was analyzed by edge detection, and combined with edge evaluating parameters to improve the quality of the coating edge. According to the experimental results, the proposed algorithm has an average recognition rate of 96% and the recognition speed on a mirror element sized 10 × 7 cm is only 0.1 s. © 2017 Elsevier GmbH","Coating; Edge serration; Mirror elements","Coatings; Image enhancement; Inspection; Mirrors; Surface defects; Automatic inspection system; Coating quality; Edge serration; Image contour; Image contrasts; Mirror surfaces; Novel algorithm; Recognition speed; Edge detection",2-s2.0-85030707601
"Fang H., Zhang J.","Representations of Face Images and Collaborative Representation Classification for Face Recognition",2018,"Journal of Circuits, Systems and Computers",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027832286&doi=10.1142%2fS0218126618500172&partnerID=40&md5=1a2f376ec7c9dbbe7dc83ed982f63e5b","Collaborative representation classification (CRC) was firstly proposed by Zhang et al. [L. Zhang, M. Yang, X. Feng, Y. Ma and D. Zhang, Collaborative Representation based Classification for Face Recognition, Computer Science, 2014]. It was an excellent algorithm for solving face recognition problems. The method suggests that the combination of all original training samples can approach the test samples accurately. But in fact, this does not mean it can well solve complex face recognition problems in some special situation, such as face recognition with varying illuminations and facial expressions. In the paper, we proposed an improvement to previous CRC method. By using a dedicated algorithm to combine the linear combinations of the original and their mirror training samples to represent the test samples, we can get more accurate recognition of test samples. The experimental results show that the proposed method does obtain notable accuracy improvement in comparison with the previous method. © 2018 World Scientific Publishing Company.","collaborative representation classification; Face recognition; mirror training samples","Image classification; Mirrors; Optical testing; Sampling; Accuracy Improvement; Algorithm for solving; Collaborative representations; Face images; Facial Expressions; Linear combinations; Test samples; Training sample; Face recognition",2-s2.0-85027832286
"Baati K., Hamdani T.M., Alimi A.M., Abraham A.","Decision quality enhancement in minimum-based possibilistic classification for numerical data",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028611975&doi=10.1007%2f978-3-319-60618-7_62&partnerID=40&md5=b029e6f3375a1d24f6195e2d654e40c3","Two Bayesian-like possibilistic classifiers based on the transformation of Dubois et al. in the continuous case have been proposed to deal with numerical data. For these two classifiers, namely Naïve Possibilistic Classifier (NPC) and Flexible Naïve Possibilistic Classifier (FNPC), the minimum operator has led to less accurate classification when compared to the one produced by the product rule. In this paper, we investigate the use of the Generalized Minimum-based (G-Min) algorithm that has been recently suggested as an alternative to the minimum operator for combining possibilistic estimates. The main objective is to enhance the quality of decision within minimum-based possibilistic classifiers for numerical data. Experimental evaluations are conducted on 15 numerical datasets taken from University of California Irvine (UCI) and show that using the G-Min algorithm largely improves the classification accuracy within minimum-based NPC as well as minimum-based FNPC. © Springer International Publishing AG 2018.","Flexible naïve possibilistic classifier; G-min algorithm; Minimum operator; Naïve possibilistic classifier; Numerical data","Pattern recognition; Sodium; Soft computing; Classification accuracy; Experimental evaluation; Minimum operator; Numerical data; Numerical datasets; Possibilistic; Possibilistic classifications; University of California; Classification (of information)",2-s2.0-85028611975
"Pugin E., Zhiznyakov A., Zakharov A.","Pipes localization method based on fuzzy hough transform",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031410930&doi=10.1007%2f978-3-319-68321-8_56&partnerID=40&md5=9125aaeaa2904b656f719db2d6b5fe19","In this paper a novel method of pipes detection in images on an industrial enterprise is proposed. Detailed description of preprocessing procedures is given. Method is supposed to work with grayscale images. First, contrast of the source image is increased. Then smoothing procedure is applied to reduce noise influence. Estimation of filtering quality is performed with PSNR and MSE methods. Different edge detection operators were tested, Canny operator shows the best results. Hough transform and its fuzzy form are considered. Fuzzy Hough transform is a modification of the original method that uses fuzzy features based on fuzzy sets theory. Extracted lines are filtered or fused to decreased features number. Algorithm parameters are shown in the table with their optimal values for current task. Proposed method is implemented in C++ with the use of OpenCV library. The results of this algorithm, number of errors and executing time on test and real image are described. © Springer International Publishing AG 2018.","Edge detection; Fuzzy features; Fuzzy hough transform; Lines fusion","Edge detection; Hough transforms; Algorithm parameters; Edge-detection operators; Filtering qualities; Fuzzy features; Fuzzy Hough transforms; Fuzzy sets theory; Industrial enterprise; Localization method; Feature extraction",2-s2.0-85031410930
"Zhu H., Cai J., Li Z., Xiang Z.","Telemetry communication in complex attitude conditions based on space-time coding",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028322919&doi=10.1007%2f978-981-10-4837-1_17&partnerID=40&md5=e4fc3f5d6c5dd311ca2e4576f5095594","In order to improve the reliability of the aircraft telemetry communication in complex attitude conditions, a system model with concatenated LPDC space-time codes and a 2 × 1 antenna system is established. A channel parameter estimation method is introduced, and then a soft space-time decoding algorithm based on channel parameter estimation is proposed. The decoding algorithm gives soft output information to the LDPC decoder which can take full advantage of LDPC coding gain. Simulation result shows that there would be a poor error performance without space-time coding while the phase difference of signal from two antennas is in the vicinity of π. But with space-time coding, the reliability of communication in any phase difference could be guaranteed. © Tsinghua University Press, Beijing and Springer Nature Singapore Pte Ltd. 2018.","Complex attitude; Space-time coding; Telemetry communication","Aircraft communication; Antennas; Codes (symbols); Concatenated codes; Decoding; Parameter estimation; Space time adaptive processing; Telemetering equipment; Channel parameter estimation; Complex attitude; Decoding algorithm; Error performance; Phase difference; Space time coding; Space-time decoding; System modeling; Space time codes",2-s2.0-85028322919
"Yu B., Zhao J., Pan Y.","Design an induction motor rotor fux ob-server based on orthogonal compensation of the stator flux and back EMF",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031404348&doi=10.1007%2f978-981-10-6499-9_37&partnerID=40&md5=483a67c10a0cce2d0e60b5933fa80fde","To address the problems of error accumulation and drift caused by pure integral part in the traditional voltage model flux observer and amplitude and phase error when the first-order low-pass filter is introduced into the traditional voltage model flux observe and saturation threshold selection in the first-order low-pass filter saturated feedback link, this paper applied a compensation method based on orthogonal principle of the stator flux and back EMF in observing Induction motor rotor flux. We analyzed the principle of this new voltage model and derived the compensation algorithm due to the introduction of the amplitude and phase error with the low-pass filter. Simulation experiments verified the correction of the compensation algorithm, the application of this method in observing Induction motor rotor flux is right and effective. The induction motor vector control system had a good dynamic and steady state performance. © 2018, Springer Nature Singapore Pte Ltd.","Rotor flux; Vector control system; Voltage model","Control systems; Error compensation; Errors; Intelligent systems; Low pass filters; Stators; Vector control (Electric machinery); Amplitude and phase error; Compensation algorithm; Compensation method; Rotor fluxes; Steady state performance; Threshold selection; Voltage model; Voltage model flux observer; Induction motors",2-s2.0-85031404348
"Quan H., Ciocan S., Qian W., Bin S.","Low-complexity MMSE signal detection based on WSSOR method for massive MIMO systems",2018,"Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031304792&doi=10.1007%2f978-3-319-66628-0_19&partnerID=40&md5=11a959c5fb369b1f7e81c7766c8f45b0","Signal detection algorithm based on the linear minimum mean square error (LMMSE) criteria can achieve quasi-optimal performance in uplink of massive MIMO systems where the base stations are equipped with hundreds of antennas. However, it introduces complicated matrix inversion operations, thus making it prohibitively difficult to implement rapidly and effectively. In this paper, we first propose a low complexity signal detection approach by exploiting the weighting symmetric successive over-relaxation (WSSOR) iterative method to circumvent the computations in the matrix inversion. We then present a proper initial solution, relaxation parameter, and scope of the weighting factor to accelerate the convergence speed. Simulation results prove that the proposed simplified method can reach its performance quite close to that of the LMMSE algorithm with no more than three iterations. © 2018, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.","Massive MIMO detection; Minimum mean square error; Weighting symmetric successive over-relaxation","Error detection; Iterative methods; Matrix algebra; Mean square error; MIMO systems; Signal receivers; Detection approach; Linear minimum mean square error(LMMSE); Matrix inversions; MIMO detection; Minimum mean square errors; Relaxation parameter; Signal detection algorithm; Symmetric successive over relaxations; Signal detection",2-s2.0-85031304792
"Charalampidis E.G., Kevrekidis P.G., Farrell P.E.","Computing stationary solutions of the two-dimensional Gross–Pitaevskii equation with deflated continuation",2018,"Communications in Nonlinear Science and Numerical Simulation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021674164&doi=10.1016%2fj.cnsns.2017.05.024&partnerID=40&md5=5a991c3bad234c569e4ecb7bd9b24531","In this work we employ a recently proposed bifurcation analysis technique, the deflated continuation algorithm, to compute steady-state solitary waveforms in a one-component, two-dimensional nonlinear Schrödinger equation with a parabolic trap and repulsive interactions. Despite the fact that this system has been studied extensively, we discover a wide variety of previously unknown branches of solutions. We analyze the stability of the newly discovered branches and discuss the bifurcations that relate them to known solutions both in the near linear (Cartesian, as well as polar) and in the highly nonlinear regimes. While deflated continuation is not guaranteed to compute the full bifurcation diagram, this analysis is a potent demonstration that the algorithm can discover new nonlinear states and provide insights into the energy landscape of complex high-dimensional Hamiltonian dynamical systems. © 2017 The Authors","Bose–Einstein condensation; Deflated continuation; Gross–Pitaevskii equation; Stability and bifurcation analysis","Bifurcation (mathematics); Bose-Einstein condensation; Dynamical systems; Hamiltonians; Nonlinear equations; Bifurcation analysis; Bifurcation diagram; Continuation algorithm; Deflated continuation; Hamiltonian dynamical systems; Repulsive interactions; Stability and bifurcation analysis; Stationary solutions; Nonlinear analysis",2-s2.0-85021674164
"Hemmecke R.","Dancing samba with Ramanujan partition congruences",2018,"Journal of Symbolic Computation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013469491&doi=10.1016%2fj.jsc.2017.02.001&partnerID=40&md5=85a796c308e083ea67b4b372458da363","The article presents an algorithm to compute a C[t]-module basis G for a given subalgebra A over a polynomial ring R=C[x] with a Euclidean domain C as the domain of coefficients and t a given element of A. The reduction modulo G allows a subalgebra membership test. The algorithm also works for more general rings R, in particular for a ring R⊂C((q)) with the property that f∈R is zero if and only if the order of f is positive. As an application, we algorithmically derive an explicit identity (in terms of quotients of Dedekind η-functions and Klein's j-invariant) that shows that p(11n+6) is divisible by 11 for every natural number n where p(n) denotes the number of partitions of n. © 2017 Elsevier Ltd","Number theoretic algorithm; Partition identities; Subalgebra basis",,2-s2.0-85013469491
"Xu Z., Xuan J., Zhu Y., Wei X.","Building the profile of web events based on website measurement",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031401873&doi=10.1007%2f978-981-10-3187-8_1&partnerID=40&md5=86f592a330534fbfacdb9ae1fb07c959","Nowadays, Web makes it possible to study emergencies from web information due to its real-time, open, and dynamic features. After the emergence of a web event, there will be numerous websites publishing webpages to cover this web event. Measuring temporal features in evolution course of web events can help people timely know and understand which events are emergencies, so harms to the society caused by emergencies can be reduced. In this paper, website preference is formally defined and mined by three proposed strategies which are all explicitly or implicitly based on the three-level networks: website-level, webpage-level and keyword-level. An iterative algorithm is firstly introduced to calculate outbreak power of web events, and increased web pages of events, increased attributes of events, distribution of attributes in web pages and the relationships of attributes are embedded into this iterative algorithm as the variables. By means of prior knowledge, membership grade of web events belong to each type can be calculated, and then the type of web events can be discriminated. Experiments on real data set demonstrate the proposed algorithm is both efficient and effective, and it is capable of providing accurate results of discrimination. © Springer Nature Singapore Pte Ltd. 2018.","Web events; Web mining; Website preference","Computation theory; Iterative methods; Dynamic features; Iterative algorithm; Membership grade; Temporal features; Three-level networks; Web events; Web information; Web Mining; Websites",2-s2.0-85031401873
"Liu J., Heiskanen J., Maeda E.E., Pellikka P.K.E.","Burned area detection based on Landsat time series in savannas of southern Burkina Faso",2018,"International Journal of Applied Earth Observation and Geoinformation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032229011&doi=10.1016%2fj.jag.2017.09.011&partnerID=40&md5=f30b3f662cc8d43656e77cefc8d59ca1","West African savannas are subject to regular fires, which have impacts on vegetation structure, biodiversity and carbon balance. An efficient and accurate mapping of burned area associated with seasonal fires can greatly benefit decision making in land management. Since coarse resolution burned area products cannot meet the accuracy needed for fire management and climate modelling at local scales, the medium resolution Landsat data is a promising alternative for local scale studies. In this study, we developed an algorithm for continuous monitoring of annual burned areas using Landsat time series. The algorithm is based on burned pixel detection using harmonic model fitting with Landsat time series and breakpoint identification in the time series data. This approach was tested in a savanna area in southern Burkina Faso using 281 images acquired between October 2000 and April 2016. An overall accuracy of 79.2% was obtained with balanced omission and commission errors. This represents a significant improvement in comparison with MODIS burned area product (67.6%), which had more omission errors than commission errors, indicating underestimation of the total burned area. By observing the spatial distribution of burned areas, we found that the Landsat based method misclassified cropland and cloud shadows as burned areas due to the similar spectral response, and MODIS burned area product omitted small and fragmented burned areas. The proposed algorithm is flexible and robust against decreased data availability caused by clouds and Landsat 7 missing lines, therefore having a high potential for being applied in other landscapes in future studies. © 2017 Elsevier B.V.","Breakpoint identification; Burned area; Harmonic model; Landsat time series; MODIS","algorithm; biodiversity; burning; carbon balance; decision making; detection method; harmonic analysis; land management; Landsat; mapping; MODIS; savanna; time series analysis; vegetation structure; Burkina Faso",2-s2.0-85032229011
"Jayashree P., Ramakrishnan K.","Design and evaluation of reinforcement learning based AI agent: A case study in gaming",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028624425&doi=10.1007%2f978-3-319-60618-7_33&partnerID=40&md5=2756779a2b70664494c1e978eb3bc3e5","Soft computing is extensively used in the field of computer games to create AI agents for computers. A case study of reinforcement learning is presented, by designing an AI agent for chopsticks game, with a probabilistic algorithm devised to make use of past game experience as its only tool to guide itself to victory. It has been experimentally verified that the AI agent’s performance increases with learning and nears saturation beyond a point of learning. Constant order space and time complexity is achieved with proper design of knowledge base. © Springer International Publishing AG 2018.","AI agent; Chopsticks; Probabilistic model; Reinforcement learning; Soft computing","Computer games; Knowledge based systems; Pattern recognition; Soft computing; Chopsticks; Constant orders; Design and evaluations; Game experience; Knowledge base; Probabilistic algorithm; Probabilistic modeling; Space and time complexity; Reinforcement learning",2-s2.0-85028624425
"Strug B., Ślusarczyk G., Grabska E.","Design classification based on matching graph kernels",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030762198&doi=10.1007%2f978-3-319-67792-7_44&partnerID=40&md5=598be59e77b6ac3d66bc9c949b260759","The paper deals with the problem of classification of designs according to their styles. The designs are represented by means of labelled, attributed graphs. The similarity between designs is calculated with the use of a new graph kernel and then used to predict if a given design belongs to a certain style of designs. The prediction process is performed by a classification algorithm. Examples of garden designs are used to present experimental results obtained by means of the presented method. © 2018, Springer International Publishing AG.","Design patterns; Graph classification; Graph kernels; Machine learning","Computer programming; Computer science; Attributed graphs; Classification algorithm; Design Patterns; Graph classification; Graph kernels; Matching graph; Prediction process; Learning systems",2-s2.0-85030762198
"Correia P., Paquete L., Figueira J.R.","Compressed data structures for bi-objective {0,1}-knapsack problems",2018,"Computers and Operations Research",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027973695&doi=10.1016%2fj.cor.2017.08.008&partnerID=40&md5=0332df4e1b2f24559e775b25b0958d2b","Solving multi-objective combinatorial optimization problems to optimality is a computationally expensive task. The development of implicit enumeration approaches that efficiently explore certain properties of these problems has been the main focus of recent research. This article proposes algorithmic techniques that extend and empirically improve the memory usage of a dynamic programming algorithm for computing the set of efficient solutions both in the objective space and in the decision space for the bi-objective knapsack problem. An in-depth experimental analysis provides further information about the performance of these techniques with respect to the trade-off between CPU time and memory usage. © 2017 Elsevier Ltd","Implicit enumeration techniques; Multi-objective optimization","Combinatorial optimization; Economic and social effects; Multiobjective optimization; Optimization; Algorithmic techniques; Bi-objective knapsack problems; Compressed data structures; Dynamic programming algorithm; Experimental analysis; Implicit enumeration; Knapsack problems; Multiobjective combinatorial optimization; Dynamic programming",2-s2.0-85027973695
"Kowalczuk Z., Tatara M., Stefański T.","Reduction of computational complexity in simulations of the flow process in transmission pipelines",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028350914&doi=10.1007%2f978-3-319-64474-5_20&partnerID=40&md5=668d71debc169ab8383c83626a151993","The paper addresses the problem of computational efficiency of the pipe-flow model used in leak detection and identification systems. Analysis of the model brings attention to its specific structure, where all matrices are sparse. With certain rearrangements, the model can be reduced to a set of equations with tridiagonal matrices. Such equations can be solved using the Thomas algorithm. This method provides almost the same values of the state vector and maintains stability for the same discretization grid, while the computational overhead is vastly reduced. © Springer International Publishing AG 2018.","Flow process; Flow simulation; Leak detection and identification; Numerical analysis","Fault tolerance; Flow simulation; Leak detection; Matrix algebra; Numerical analysis; Pipe flow; Computational overheads; Detection and identifications; Discretizations; Flow process; Pipe flow models; Thomas algorithm; Transmission pipelines; Tridiagonal matrices; Computational efficiency",2-s2.0-85028350914
"Guo F., Pan J.-S.","Nearest Neighbor Search Techniques Applied in the Nearest Feature Line Classifier",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030848810&doi=10.1007%2f978-3-319-68527-4_38&partnerID=40&md5=b9e1b8af69e7d4e36a66ba622ee0f3f4","Pointing to the computational complexity to find the minimum distance in the nearest feature line (NFL) classification algorithm, the nearest neighbor search methods with Full Search (FS), Partial Distortion Search (PDS), Absolute Error Inequality (AEI) and Equal-average Nearest Neighbor Search (ENNS) is used to evaluate the calculated performance on NFL. The experimental results demonstrate that the computational complexity on NFL using these search techniques is different and some of the nearest neighbor search methods could improve the calculated performance on finding out the minimum distance applied in the NFL classification. © 2018, Springer International Publishing AG.","AEI; ENNS; FS; Minimum distance; Nearest neighbor search; NFL; PDS","Classification (of information); Computational complexity; Data handling; Fluorine; Information analysis; Palladium; Absolute error; Classification algorithm; ENNS; Minimum distance; Nearest feature lines; Nearest neighbors; Partial distortion searches; Search technique; Nearest neighbor search",2-s2.0-85030848810
"Liu H., Lv H., Wang H., Zhang Y.","Study on the influence on liquid sloshing caused by baffle’s parameter changes in tank",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026740706&doi=10.1007%2f978-981-10-3551-7_4&partnerID=40&md5=ee5fe8a35d80f1fcc8bb67fa595bc99e","Liquid sloshing in the tank is simulated by numerical method in this thesis. The Volume of Fluid (VOF) method and the standard k-e turbulent model, and the PISO algorithm is determined for the solution. The thesis investigates numerical simulation of different numbers of the baffles and the baffle location in circle cross-sectional tank with the FLUENT software. The results show that (1) In the circle cross-sectional tank, the effect of defending waves will be better with the increasing number of baffles. (2) The larger the baffle area below the liquid free surface, the better the effect of defending waves. © Springer Science+Business Media Singapore 2018.","Baffle; Impact force; Liquid free surface; Liquid sloshing; Tank","Computer software; Intelligent systems; Intelligent vehicle highway systems; Liquids; Numerical methods; Scattering parameters; Tanks (containers); Transportation; Baffle; FLUENT software; Impact force; Liquid free surfaces; PISO algorithm; Tank; Turbulent models; Volume of fluid method; Liquid sloshing",2-s2.0-85026740706
"Nasseri S.H., Chitgar S.","A new approach for solving fuzzy supplier selection problems under volume discount",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030783684&doi=10.1007%2f978-3-319-66514-6_2&partnerID=40&md5=bf6b5eebd6763be3f134ea07e16016dc","In order to achieve a compromised solution for a multi-objective linear programming with fuzzy right hand sides, Tchebycheff norm and a new approach based on α-cut is suggested to minimize the distance from the current estimate of the objective values from the ideal point. Since the obtained solutions by the Tchebycheff approach are weakly efficient for multi-objective problems. Hence, an augmented weighted Tchebycheff norm has been proposed. Here, the satisficing tradeoff algorithm is used to solve the augmented weighted Tchebycheff problems. Since the supplier selection problem is usually a multi-objective problem, the augmented weighted Tchebycheff method is applied for obtaining its solutions. © Springer International Publishing AG 2018.","Augmented weighted tchebycheff norm; Fuzzy multi-objective linear programming; Satisficing tradeoff algorithm; α-cut approach","Computer programming; Computer science; Augmented weighted tchebycheff norm; Compromised solution; Fuzzy multi-objective linear programming; Multi-objective linear programming; Multi-objective problem; Satisficing; Tchebycheff approach; Weighted Tchebycheff method; Linear programming",2-s2.0-85030783684
"Zhou C., Wang L., Zhengqiu L.","The study of WSN node localization method based on back propagation neural network",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032688980&doi=10.1007%2f978-3-319-67071-3_54&partnerID=40&md5=f86c756fd9fb084f14afb504c97ce325","In order to cut down the localization accuracy problem of wireless sensor network (WSN), a novel node localization method is proposed with back propagation neural network (BPNN). At first, the calculation of node localization is presented by ranging interval and signal strength, and the parameters are rapid solving base on BPNN. Finally, a simulation experiment is conducted to study the influence key factor with NS2 and MATLAB. The results show that, compared other localization algorithm, this method has good suitability, and it could effectively reduce the localization error. © 2018, Springer International Publishing AG.","Back propagation neural network; Localization; Wireless sensor network","Backpropagation; MATLAB; Neural networks; Sensor nodes; Torsional stress; Back propagation neural networks; Key factors; Localization; Localization accuracy; Localization algorithm; Localization errors; Node localization; Signal strengths; Wireless sensor networks",2-s2.0-85032688980
"Zhou B., Singh M.S., Yildirim M., Prifti I., Zurian H.C., Yuncosa Y.M., Lukowicz P.","Smart blanket: A real-time user posture sensing approach for ergonomic designs",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022333656&doi=10.1007%2f978-3-319-60492-3_19&partnerID=40&md5=acc7bf81ab1332596382b5d3cce32ab1","We present a pervasive sensing system in the form of a wireless smart blanket that unobtrusively monitors people’s posture on ergonomic design chairs by covering the back piece of the chair and measuring the pressure profile of the user’s back. The sensor system has 1024 sensitive points, covering 48-by-48 cm2 area. With simple and efficient classification algorithm, we reach around 80% among 10 postures, including lordotic and kyphotic lumber spine on different degrees, and lean to the sides on different degrees. The web browser based user interface offers timely and reprogrammable intervention from the user’s posture history. © Springer International Publishing AG 2018.","Ergonomic design; Pressure mapping; Sitting posture; Smart fabric; User activity recognition","Smart textiles; User interfaces; Classification algorithm; Ergonomic design; Pervasive sensing; Pressure mapping; Pressure profiles; Reprogrammable; Sitting posture; User activity; Ergonomics",2-s2.0-85022333656
"Ning S., Fujita T., Nie A., Wang Z., Xu X., Chen J., Chen M., Yao S., Zhang T.-Y.","Scanning distortion correction in STEM images",2018,"Ultramicroscopy",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031724873&doi=10.1016%2fj.ultramic.2017.09.003&partnerID=40&md5=8a793a0d69042262f84d838cbc9bd31e","Various disturbances do exist in the image taking process of scanning transmission electron microscopes (STEM), which seriously reduces the resolution and accuracy of STEM images. In this paper, a deep understanding of the scanning distortion influence on the real and reciprocal spaces of STEM images is achieved via theoretical modeling and simulation. A scanning distortion correction algorithm is further developed based on two images scanned along perpendicular directions, which is able to effectively correct scanning distortion induced deviations and significantly increase the signal to noise ratio of STEM images. © 2017 Elsevier B.V.","Delaunay triangulation; Finite element method; Image registration; Scanning distortion; STEM","Finite element method; Image registration; Signal to noise ratio; STEM (science, technology, engineering and mathematics); Transmission electron microscopy; Delau-nay triangulations; Distortion correction; Reciprocal space; Scanning transmission electron microscopes; STEM images; Theoretical modeling; Scanning; algorithm; Article; controlled study; derivatization; image analysis; image intensity; mathematical analysis; scanning distortion correction; scanning transmission electron microscopy; scintiscanning; signal noise ratio; simulation; theoretical model",2-s2.0-85031724873
"Bhaskaran R., Chandavarkar B.R.","An unsupervised method for attribute identification from a natural language query",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026737532&doi=10.1007%2f978-981-10-3373-5_54&partnerID=40&md5=47752bcce47c119bd370c4dff143a420","Identifying which attributes the user querying is an important step in providing a Natural language (NL) search interface to a relational database. In this paper, we discuss an unsupervised approach for identifying the target database attributes from natural language (NL) query. This is a knowledge base-driven method which can be adopted into any domain with very little effort. Initially, we created a knowledge base using background information about the database domain. Then used a probabilistic algorithm to calculate the semantic dependency between different nodes in the knowledge base. When processing the query, this dependency score will be used to resolve the target attribute. © Springer Nature Singapore Pte Ltd. 2018.","Database and query processing; Database natural language interface","Computation theory; Intelligent computing; Knowledge based systems; Natural language processing systems; Semantics; Background information; Natural language interfaces; Natural language queries; Probabilistic algorithm; Relational Database; Semantic dependency; Unsupervised approaches; Unsupervised method; Query processing",2-s2.0-85026737532
"Li K., Hong N.","Dynamic heat load calculation of a bridge anti-icing system",2018,"Applied Thermal Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028998198&doi=10.1016%2fj.applthermaleng.2017.09.024&partnerID=40&md5=39fe76f03606499a19d5a1a46067e471","Road icing poses a serious threat to traffic safety in winter. Active anti-icing is one of effective methods to solve this problem. An inverse heat conduction method was developed to identify the dynamic heat load of the bridge cable heating system. One regularized functional was established based on Tikhonov regularization theory and solved by an iterative method. The results showed that the heat load calculated was not just the sum of heat loss at the top surface and bottom surface of a bridge. There are time lag and amplitude attenuation between the heat load and heat loss of the bridge. The inverse heat conduction method was validated by the direct heat transfer numerical simulation. Based on the maximum heat load results, ON-OFF algorithm and proportional-integral-derivative (PID) control algorithm were implemented. The simulation results showed that the temperature of bridge surface was greater than 0 °C and indicated that the theoretical derivation of heating load and control logic is suitable for bridge anti-icing system. © 2017 Elsevier Ltd","Bridge anti-icing; Control logic; Heat transfer; Heating load","Computer circuits; Heat conduction; Heat losses; Heat transfer; Heat transfer coefficients; Heating; Inverse problems; Numerical methods; Proportional control systems; Thermal load; Two term control systems; Anti-icing; Anti-icing systems; Control logic; Heating load; Inverse heat conduction methods; Proportional integral derivative control algorithm (PID); Theoretical derivations; Tikhonov regularization; Iterative methods",2-s2.0-85028998198
"Qi G., Huang B.","Walking detection using the gyroscope of an unconstrained smartphone",2018,"Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031301322&doi=10.1007%2f978-3-319-66628-0_51&partnerID=40&md5=e33f78997915316332366c0b57b46edd","In recent years, mobile devices (e.g., smartphones, tablets and etc.) equipped with various inertial sensors have been increasingly popular in daily life, and a large number of mobile applications have been developed based on such built-in inertial sensors. In particular, many of these applications, such as healthcare, navigation, and etc., rely on the knowledge of whether a user is walking or not, so that walking detection thus has attained much attention. This paper deals with walking detection by using the gyroscope of any commercial off-the-shelf (COTS) smartphone, which can be placed at different positions of the user. Inspired by the fact that the walking activity often results in notable features in the frequency domain, we propose a novel algorithm based on fast Fourier transformation (FFT) to identify the walking activity of a user who may perform various activities and may hold the smartphone in different manners. A thorough experiment involving three testers and multiple activities is carried out and confirms that the proposed algorithm is superior to the existing well-known counterparts. © 2018, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.","Angular velocities; Fast Fourier transformation(FFT); Smartphone; Unconstrained; Walking detection","Angular velocity; Fast Fourier transforms; Frequency domain analysis; Gyroscopes; Inertial navigation systems; Smartphones; Commercial off-the shelves; Fast fourier transformation (FFT); Frequency domains; Inertial sensor; Mobile applications; Novel algorithm; Unconstrained; Walking activity; mHealth",2-s2.0-85031301322
"Taha A., Darwish A., Hassanien A.E.","Arabian horse identification system based on live captured muzzle print images",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029517764&doi=10.1007%2f978-3-319-64861-3_73&partnerID=40&md5=aae5232f76bb056200a483f5cc5cd4cb","The Arabian horse is one of the oldest and purebred breeds of horses in the entire world. The Arabian horse is characterized by speed, strength, and great beauty, full of quality, elegance, and dignity compared to other breeds. The Arabian horse identification is critical to controlling the disease outbreak, vaccination management, production management, and assigning ownership. In this paper, we represented Arabian horse identification system by using muzzle print images. The system has three processes; the first is the enrolment process which use Scale Invariant Feature Transform (SIFT) algorithm to extract the features of muzzle print images then store it in the database. The second process is matching process which matching the input muzzle print image with stored images in the database Random Sample Consensus (RANSAC) algorithm comes at the end of the matching process to remove any outlier, mismatched SIFT keypoints, and ensure the robustness of the similarity score. Finally, the Arabian horse identity is then assigned according to the highest estimated similarity score between the input image and the template one. © 2018, Springer International Publishing AG.","Animal biometric; Arabian horse identification; RANSAC; SIFT algorithm",,2-s2.0-85029517764
"Guendouzi W., Boukra A.","An enhanced bat echolocation approach for security audit trails analysis using manhattan distance",2018,"Operations Research/ Computer Science Interfaces Series",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032635933&doi=10.1007%2f978-3-319-58253-5_28&partnerID=40&md5=bc0fb11bc75b661df1ea4d9ffa9f8b1e","Security Audit Trail Analysis problem consists in detecting predefined attack scenarios in the audit trails. Each attack scenario is defined by a number of occurrences of auditable events. This problem is classified as an NP-Hard combinatorial optimization problem. In this paper, we propose to use the Bat echolocation approach to solve such problem. The proposed approach named an Enhanced Binary Bat Algorithm (EBBA) is an improvement of Bat Algorithm (BA). The fitness function is defined as the global attacks risks. In order to improve, the fitness function is combined with the Manhattan distance measure. Thus, intrusion detection process is guided, on one hand, by the fitness function that aims to maximize the global attacks risks and, on the other hand, by the Manhattan distance that attempts to reduce false Positives and false negatives. The best solution retained has the smallest Manhattan distance. Experiments show that the use of the Manhattan distance improves substantially the intrusion detection quality. The comparative study proves the effectiveness of the proposed approach to make correct prediction. © Springer International Publishing AG 2018.","Bat algorithm; Combinatorial optimization problem; Intrusion detection; Manhattan distance; Metaheuristics; NP-hard; Security audit trail analysis",,2-s2.0-85032635933
"Lebel K., Hamel M., Duval C., Nguyen H., Boissy P.","Camera pose estimation to improve accuracy and reliability of joint angles assessed with attitude and heading reference systems",2018,"Gait and Posture",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031999309&doi=10.1016%2fj.gaitpost.2017.10.016&partnerID=40&md5=c82ffa0ca0ee45259a540ae3a964b9a7","Joint kinematics can be assessed using orientation estimates from Attitude and Heading Reference Systems (AHRS). However, magnetically-perturbed environments affect the accuracy of the estimated orientations. This study investigates, both in controlled and human mobility conditions, a trial calibration technic based on a 2D photograph with a pose estimation algorithm to correct initial difference in AHRS Inertial reference frames and improve joint angle accuracy. In controlled conditions, two AHRS were solidly affixed onto a wooden stick and a series of static and dynamic trials were performed in varying environments. Mean accuracy of relative orientation between the two AHRS was improved from 24.4° to 2.9° using the proposed correction method. In human conditions, AHRS were placed on the shank and the foot of a participant who performed repeated trials of straight walking and walking while turning, varying the level of magnetic perturbation in the starting environment and the walking speed. Mean joint orientation accuracy went from 6.7° to 2.8° using the correction algorithm. The impact of starting environment was also greatly reduced, up to a point where one could consider it as non-significant from a clinical point of view (maximum mean difference went from 8° to 0.6°). The results obtained demonstrate that the proposed method improves significantly the mean accuracy of AHRS joint orientation estimations in magnetically-perturbed environments and can be implemented in post processing of AHRS data collected during biomechanical evaluation of motion. © 2017 Elsevier B.V.","3D orientation tracking; AHRS; IMU; Inertial sensors; Joint orientation; Pose estimation","accuracy; adult; algorithm; Article; attitude; calibration; camera pose estimation; environment; female; human; joint; kinematics; orientation; photography; priority journal; reliability; walking speed",2-s2.0-85031999309
"Rabbani M., Mohammadi S., Mobini M.","Optimum design of a CCHP system based on economical, energy and environmental considerations using GA and PSO",2018,"International Journal of Industrial Engineering Computations",1,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020127937&doi=10.5267%2fj.ijiec.2017.4.002&partnerID=40&md5=88ec90d2d60b493198af95ef0482abc2","Optimum design and control of a Combined Cooling, Heating and Power generation (CCHP) system, in addition to the economic benefits, could be profitable in environmental and energy consumption aspects. The aim of this study is to determine the optimal capacity of equipment and define the best control strategy of a CCHP system. Since determination of optimal system control strategy has a huge impact on improving the objective functions, the system’s performance under five different strategies (developed based on well-known Following Electrical Load (FEL) and Following Thermal Load (FTL) strategies) is evaluated. In a real case study, a CCHP system is designed for an educational complex located in Mahmoudabad, Mazandaran, Iran. The objective is to minimize capital and operational costs, energy consumption, and CO2 emissions of the system. Due to the complexities of the model, genetic algorithm (GA) and particle swarm optimisation (PSO) algorithm are used to find the optimal values of the decision variables. The results show that using FEL strategy CO2 emissions reduces in compression to FTL strategy. Furthermore, using multiple power generation units under FTL strategy eventuates the least cost but increases CO2 emissions and energy consumption in compression to FEL strategy. © 2018 Growing Science Ltd. All rights reserved","Combined cooling heating power generation; Control strategy; Genetic algorithm; Optimised design; Particle Swarm Optimisation",,2-s2.0-85020127937
"Yan F.-G., Cao B., Liu S., Jin M., Shen Y.","Reduced-complexity direction of arrival estimation with centro-symmetrical arrays and its performance analysis",2018,"Signal Processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026857621&doi=10.1016%2fj.sigpro.2017.07.033&partnerID=40&md5=e0c23461183f80abd399635bcdfc9743","A fast algorithm is proposed to dramatically reduce the computational complexity of the multiple signal classification (MUSIC) algorithm for direction-of-arrival (DOA) estimate using a centro-symmetrical array (CSA). The CSA is divided into two sub-arrays and a real matrix is constructed with the covariance matrices of the two sub-arrays and their cross-correlation ones. This real matrix is further regarded as the data covariance one observed by a virtual array which has a real array response, and a novel MUSIC-like cost function is derived accordingly. In the developed method, only real-valued computation is required and the spectral search is compressed into half of the total angular field-of-view. Furthermore, the dimensions of noise subspace and those of search vector are both reduced, leading to about 97% complexity reduction as compare to MUSIC. The non-asymptotic statistical performance of the new DOA estimator is analyzed and a closed-form expression is given to predict the mean square error (MSE) of DOA estimation by the new technique. The effectiveness of the presented approach as well as the theoretical analysis is verified through numerical computer simulations, and it is shown that the proposed method is able to provide good accuracy with low signal-to-noise ratio (SNR) and small numbers of snapshots. © 2017","Centro-symmetrical array (CSA); Direction-of-arrival (DOA) estimation; Real-valued computation; Reduced dimension; Statistical performance analysis","Computer music; Cost functions; Covariance matrix; Matrix algebra; Mean square error; Numerical methods; Signal to noise ratio; Wavelet analysis; Centro-symmetrical array (CSA); Direction of arrival estimation; Direction of arrivalestimation(DOA); Low signal-to-noise ratio; Multiple signal classification algorithm; Reduced dimension; Statistical performance; Statistical performance analysis; Direction of arrival",2-s2.0-85026857621
"Zhu X., Skidmore A.K., Darvishzadeh R., Niemann K.O., Liu J., Shi Y., Wang T.","Foliar and woody materials discriminated using terrestrial LiDAR in a mixed natural forest",2018,"International Journal of Applied Earth Observation and Geoinformation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032197039&doi=10.1016%2fj.jag.2017.09.004&partnerID=40&md5=5325722a631b8fd03586bdd4be971f7a","Separation of foliar and woody materials using remotely sensed data is crucial for the accurate estimation of leaf area index (LAI) and woody biomass across forest stands. In this paper, we present a new method to accurately separate foliar and woody materials using terrestrial LiDAR point clouds obtained from ten test sites in a mixed forest in Bavarian Forest National Park, Germany. Firstly, we applied and compared an adaptive radius near-neighbor search algorithm with a fixed radius near-neighbor search method in order to obtain both radiometric and geometric features derived from terrestrial LiDAR point clouds. Secondly, we used a random forest machine learning algorithm to classify foliar and woody materials and examined the impact of understory and slope on the classification accuracy. An average overall accuracy of 84.4% (Kappa = 0.75) was achieved across all experimental plots. The adaptive radius near-neighbor search method outperformed the fixed radius near-neighbor search method. The classification accuracy was significantly higher when the combination of both radiometric and geometric features was utilized. The analysis showed that increasing slope and understory coverage had a significant negative effect on the overall classification accuracy. Our results suggest that the utilization of the adaptive radius near-neighbor search method coupling both radiometric and geometric features has the potential to accurately discriminate foliar and woody materials from terrestrial LiDAR data in a mixed natural forest. © 2017 Elsevier B.V.","Classification; Geometric feature; Radiometric feature; Radius search; Terrestrial laser scanning","algorithm; biomass; image classification; leaf area index; lidar; machine learning; national park; radiometer; scanner; Bavaria; Bavarian Forest National Park; Germany",2-s2.0-85032197039
"Larmier C., Lam A., Brantley P., Malvagi F., Palmer T., Zoia A.","Monte Carlo chord length sampling for d-dimensional Markov binary mixtures",2018,"Journal of Quantitative Spectroscopy and Radiative Transfer",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032487842&doi=10.1016%2fj.jqsrt.2017.09.014&partnerID=40&md5=4f4424910305c8c52e57b67d2a419e1c","The Chord Length Sampling (CLS) algorithm is a powerful Monte Carlo method that models the effects of stochastic media on particle transport by generating on-the-fly the material interfaces seen by the random walkers during their trajectories. This annealed disorder approach, which formally consists of solving the approximate Levermore–Pomraning equations for linear particle transport, enables a considerable speed-up with respect to transport in quenched disorder, where ensemble-averaging of the Boltzmann equation with respect to all possible realizations is needed. However, CLS intrinsically neglects the correlations induced by the spatial disorder, so that the accuracy of the solutions obtained by using this algorithm must be carefully verified with respect to reference solutions based on quenched disorder realizations. When the disorder is described by Markov mixing statistics, such comparisons have been attempted so far only for one-dimensional geometries, of the rod or slab type. In this work we extend these results to Markov media in two-dimensional (extruded) and three-dimensional geometries, by revisiting the classical set of benchmark configurations originally proposed by Adams, Larsen and Pomraning [1] and extended by Brantley [2]. In particular, we examine the discrepancies between CLS and reference solutions for scalar particle flux and transmission/reflection coefficients as a function of the material properties of the benchmark specifications and of the system dimensionality. © 2017 Elsevier Ltd","Benchmark; Chord Length Sampling; Markov geometries; Mercury; Monte Carlo; TRIPOLI-4®","Benchmarking; Binary mixtures; Boltzmann equation; Geometry; Interfaces (materials); Mercury (metal); Particle separators; Stochastic models; Stochastic systems; Chord lengths; Material interfaces; One-dimensional geometry; Particle transport; Reference solution; Three dimensional geometry; Transmission/reflection coefficients; TRIPOLI-4; Monte Carlo methods; algorithm; benchmarking; Markov chain; Monte Carlo analysis; particle motion; sampling; simulated annealing; three-dimensional modeling; two-dimensional modeling",2-s2.0-85032487842
"Hu Q., Wei L., Lim A.","The two-dimensional vector packing problem with general costs",2018,"Omega (United Kingdom)",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011031844&doi=10.1016%2fj.omega.2017.01.006&partnerID=40&md5=09b03f85a484ece1756f6a2193538089","The two-dimensional vector packing problem with general costs (2DVPP-GC) arises in logistics where shipping items of different weight and volume are packed into cartons before being transported by a courier company. In practice, the delivery cost of a carton of items is usually retrieved from a cost table. The costs may not preserve any known mathematical function since it could specify arbitrary price at any possible weight. Such a general pricing scheme meets a majority of real-world bin packing applications, where the price of delivery service is determined by many complicated and correlated factors. Compared to the classical bin packing problem and its variants, the 2DVPP-GC is more complex and challenging. To solve the 2DVPP-GC with minimizing the total cost, we propose a memetic algorithm to compute solutions of high quality. Fitness functions and improved operators are proposed to achieve effectiveness. Computational experiments on a variety of test instances show that the algorithm is competent to solve the 2DVPP-GC. In particular, optimal solutions are found in a second for all the test instances that have a known optimal solution. © 2017 Elsevier Ltd","Application; Bin packing; General costs; Memetic algorithm; Two-dimensional vector packing","shipping",2-s2.0-85011031844
"Polpinij J., Srikanjanapert N., Sopon P.","Word2Vec approach for sentiment classification relating to hotel reviews",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022194078&doi=10.1007%2f978-3-319-60663-7_29&partnerID=40&md5=70b91e5821d4cb61f632339649d7a32d","In general, the existing works in sentiment classification concentrate only the syntactic context of words. It always disregards the sentiment of text. This work addresses this issue by applying Word2Vec to learn sentiment specific words embedded in texts, and then the similar words will be grouped as a same concept (or class) with sentiment information. Simply speaking, the aim of this work is to introduce a new task similar to word expansion or word similarity task, where this approach helps to discover words sharing the same semantics automatically, and then it is able to separate positive or negative sentiment in the end. The proposed method is validated through sentiment classification based on the employing of Support Vector Machine (SVM) algorithm. This approach may enable a more efficient solution for sentiment analysis because it can help to reduce the inherent ambiguity in natural language. © Springer International Publishing AG 2018.","Natural language; Sentiment classification; Support vector machine; Word2Vec","Natural language processing systems; Semantics; Natural languages; Negative sentiments; Sentiment analysis; Sentiment classification; Support vector machine algorithm; Word similarity; Word2Vec; Support vector machines",2-s2.0-85022194078
"Liu T., Duan H., Shang Y., Yuan Z., Zheng N.","Automatic salient object sequence rebuilding for video segment analysis",2018,"Science China Information Sciences",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030850795&doi=10.1007%2fs11432-016-9150-x&partnerID=40&md5=5c40673621a26231f575d105076ab13c","Detection of salient object sequences from video data is challenging when the salient object changes between consecutive frames. In this study, we addressed the salient object sequence rebuilding problem with video segment analysis. We reformulated the problem as a binary labeling problem, analyzed the potential salient object sequences in the video using a clustering method, and separated the salient object sequence from the background by applying an energy optimization method. Our proposed approach determines whether temporal consecutive pixels belong to the same salient object sequence. The conditional random field is then learned to effectively integrate the salient features and the sequence consecutive constraints. A dynamic programming algorithm was developed to resolve the energy minimization problem efficiently. Experimental results confirmed the ability of our approach to address the salient object rebuilding problem in automatic visual attention applications and video content analysis. © 2017, Science China Press and Springer-Verlag GmbH Germany.","conditional random model; salient object; sequence segment analysis; video attention","Behavioral research; Dynamic programming; Image segmentation; Video recording; Conditional random field; Dynamic programming algorithm; Energy minimization problem; Random Model; Salient objects; sequence segment analysis; video attention; Video-content analysis; Object detection",2-s2.0-85030850795
"Li D., Chen X., Sun Q.","The study of population evacuation problems",2018,"Advances in Intelligent Systems and Computing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022224515&doi=10.1007%2f978-3-319-60525-8_64&partnerID=40&md5=4d3cddaaabac80111189e865960dba85","With the rapid development of society around the world, the population of cities such as Beijing and Shanghai has increased dramatically, and large social activities have been increasing. Safeguarding the legitimate rights and interests of citizens and strengthening public safety is one of the most important problems. Therefore, it is a very important research topic to study the aggregation phenomenon and the evacuation characteristics of the public places, to explore the reasonable group organization and evacuation mode, and to find ways and means to reduce the risk of accidents. When a sudden event occurs in a public place, the crowd is evacuated using the particle swarm algorithm. In addition, the shortcomings of the traditional particle swarm optimization are improved, and the influence of obstacle on individual evacuation path selection is fully considered. Finally, the thermodynamic diagram is used to simulate the model, and the feasibility of the model is verified. © Springer International Publishing AG 2018.","Obstacle avoidance mechanism; Particle swarm optimization; Population evacuation; Thermodynamic diagram","Human engineering; Particle swarm optimization (PSO); Thermodynamic properties; Aggregation phenomena; Evacuation problems; Particle swarm algorithm; Population evacuation; Research topics; Risk of accidents; Social activities; Thermodynamic diagrams; Safety engineering",2-s2.0-85022224515
"Ding Z., Sun Q., Liu S., Chen Z.","Iron ore sintering subsection temperature model on the airflow rate by PID control",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031396900&doi=10.1007%2f978-981-10-6499-9_27&partnerID=40&md5=36e58d8144b244d6b98b8c2befd0a6eb","Sintering is a complicated process in which the sintered ores are produced for the blast furnace. In this paper, a subsection temperature model on airflow rate is proposed to explain the effect of the airflow rate on the sinter bed temperature. Furthermore, the sintering process control strategy is put forward applying PID algorithm based on the optimization of airflow rate. The sintering process is divided into 24 stages to track the sinter bed temperature. Experimental results show that the airflow quantity is sufficient for the coke combustion and remarkable effects can be achieved on the electricity consumption saving of the main exhaust fan which is up to 32.6%. © 2018, Springer Nature Singapore Pte Ltd.","Electricity consumption saving; Iron ore sintering; PID control; Subsection airflow rate temperature model","Blast furnaces; Electric power utilization; Intelligent systems; Iron ores; Ore sintering; Process control; Three term control systems; Air flow-rate; Bed temperature; Coke combustion; Electricity-consumption; PID Algorithm; Sintered ores; Sintering process; Temperature modeling; Sintering",2-s2.0-85031396900
"Jing Z., He Y., Li Q., Zhang B., Yang H.","Investigation of aquatic pathogens and diversity analysis of Aeromonas isolates",2018,"Lecture Notes in Electrical Engineering",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032873765&doi=10.1007%2f978-981-10-4801-2_76&partnerID=40&md5=c1b50c726e2f68d38fc72d22cc30c8a9","Epidemic survey and genetic characterization of aquatic pathogens from the aquatic product and sea water samples collected in Tianjin and Xiamen, Fujian, China. Selective media were used for aquatic pathogens isolations and sequence analysis of 16S rRNA gene was used for bacteria identification. Totally, 120 isolates were isolated and identified, including Aeromonas spp. (53), Vibrio spp. (19), Proteus spp. (5), Citrobacter spp. (9), Hafnia spp. (8), Providencia spp. (6), Pseudomonas spp. (3), Kluyvera spp. (2), Enterobacter spp. (2), Bacillus spp. (2), Pantoea sp. (1), Leclercia sp. (1), and Acinetobacter sp. (1). MLST (multilocus sequence typing) was used for discrimination of the Aeromonas spp. isolates and 53 Aeromonas strains were identified having 297 new allelic genes and 45 new sequence types (ST). The eBURST algorithm analysis showed that most STs were distantly related. The isolated pathogens were mainly comprised of Aeromonas spp. and Vibrio spp. A great genetic diversity was observed among the isolated Aeromonas strains. © Springer Nature Singapore Pte Ltd. 2018.","16S rRNA; Aeromonas; Aquatic pathogen; MLST","Bacteria; Bacteriology; Biotechnology; Genes; RNA; Seawater; 16S rRNA; Aeromonas; Algorithm analysis; Bacteria identifications; Diversity analysis; Genetic characterization; MLST; Multilocus sequence typing; Pathogens",2-s2.0-85032873765
